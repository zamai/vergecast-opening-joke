1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 7099d908-8ebf-4179-91eb-0517cabb20da
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-8420802413370376526/-5001133113475488095/s93290-US-4721s-1757298755.mp3
Description: Hooked on LinkedIn’s Queens? Gotta extend your Wordle streak in the New York Times games app before you start your day? You’re in good company on today’s Vergecast episode. Allison Johnson is joined by Simon Anthony and Mark Goodliffe, world-class puzzle champs and hosts of the delightful Cracking the Cryptic, a YouTube channel where they solve a puzzle on camera every single day.

They specialize in Sudoku — and not just the classic number games you might be familiar with. Simon and Mark tackle mind-bending, seemingly impossible puzzles, working through it all in realtime, sometimes over the course of several hours. What happens when you get stuck? How can you tell the difference between a puzzle made by a human and a computer-generated one? Why are we addicted to puzzle games all of a sudden? They help us crack the clues.

Then Allison sits down with Marc Levoy, one of the pioneers of computational photography, to talk about his new camera app: Project Indigo. Levoy is known for his earlier work on the Pixel camera, and was a driving force in shaping phone photography into what it is now. We last caught up with him in 2020 when he left Google for Adobe, so we got up to speed on what the heck he’s been doing for the last five years — and the important difference between HDR and an HDR-ish photo.

Finally, Allison takes a hotline question from someone who is not particular about their phone camera’s image quality, but does have a beef with camera bumps.


  Cracking the Cryptic — YouTube

  This 25-minute video is the most riveting sudoku puzzle you will ever watch

  The Atlantic is making a big push into games

  I regret to inform you that LinkedIn’s games are very fun

  The mastermind of Google’s Pixel camera quietly left the company in March

  The brain behind the Google Pixel camera is building a universal camera app for Adobe

  Marc Levoy on the balance of camera hardware, software, and artistic expression

  Adobe launches a new ‘computational photography’ camera app for iPhones

  Adobe’s new camera app is making me rethink phone photography




Email us at vergecast@theverge.com or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Enabled (25 ads detected)

2
00:00:03,355 --> 00:00:07,085
Speaker 2:  Welcome to The Vergecast, the flagship podcast of looking

3
00:00:07,145 --> 00:00:10,965
Speaker 2:  for naked singles. I'm your host, Alison Johnson, and that makes

4
00:00:10,965 --> 00:00:14,765
Speaker 2:  sense In this context, I promise it is a Sudoku thing. And

5
00:00:14,785 --> 00:00:18,285
Speaker 2:  on today's episode, I'm talking to a couple of world champion puzzle

6
00:00:18,355 --> 00:00:22,165
Speaker 2:  solvers who started their own YouTube channel where they

7
00:00:22,215 --> 00:00:26,045
Speaker 2:  solve a Sudoku every day. They're ridiculously hard and

8
00:00:26,125 --> 00:00:29,845
Speaker 2:  surprisingly fun to watch. After that, I'm talking to Mark

9
00:00:30,015 --> 00:00:33,885
Speaker 2:  LaVoy, who's one of the pioneers of computational photography and

10
00:00:33,985 --> 00:00:37,965
Speaker 2:  really just phone camera technology in general. We're gonna talk about his

11
00:00:38,325 --> 00:00:42,205
Speaker 2:  new camera app called Project Indigo. That's all coming up right

12
00:00:42,205 --> 00:00:42,765
Speaker 2:  after the break.

13
00:02:15,705 --> 00:02:19,515
Speaker 2:  Alright, we're back. I am joined by two very special

14
00:02:19,515 --> 00:02:22,155
Speaker 2:  guests, Simon Anthony. Hi Simon.

15
00:02:22,725 --> 00:02:23,075
Speaker 6:  Hello.

16
00:02:23,695 --> 00:02:27,475
Speaker 2:  And Mark. Good lift. Hey Mark. Hi there they are

17
00:02:28,175 --> 00:02:32,035
Speaker 2:  Puzzle champions, but more importantly, the

18
00:02:32,035 --> 00:02:35,795
Speaker 2:  host of a YouTube channel called Cracking the Cryptic. And

19
00:02:35,915 --> 00:02:39,595
Speaker 2:  I guess I'll let you guys explain what that is, what you do there,

20
00:02:39,885 --> 00:02:43,235
Speaker 2:  Simon, maybe can you give our listeners a quick rundown if they're not familiar?

21
00:02:44,195 --> 00:02:45,835
Speaker 6:  I can, but it'll sound mad

22
00:02:47,515 --> 00:02:51,275
Speaker 6:  Cracking. The Cryptic is a YouTube channel where we

23
00:02:51,485 --> 00:02:55,395
Speaker 6:  solve variant Sudoku puzzles, sort of

24
00:02:55,395 --> 00:02:58,355
Speaker 6:  live on camera a couple of times each day.

25
00:02:59,545 --> 00:03:03,485
Speaker 6:  And the channel's been going now for about eight years. Oh my

26
00:03:03,485 --> 00:03:07,165
Speaker 6:  gosh. And it's become really quite popular.

27
00:03:07,945 --> 00:03:11,685
Speaker 6:  So we have about 650,000 subscribers now,

28
00:03:12,545 --> 00:03:16,365
Speaker 6:  and the average length of a video is perhaps 45

29
00:03:16,365 --> 00:03:20,205
Speaker 6:  minutes to an hour. So people are spending time with us

30
00:03:20,205 --> 00:03:24,125
Speaker 6:  every day having a go at these puzzles and then watching us attempt

31
00:03:24,125 --> 00:03:27,805
Speaker 6:  them. Yeah. And, and because it's live, it's all of the

32
00:03:28,045 --> 00:03:31,525
Speaker 6:  mistakes, you know, all of the poor thinking is there, but in the end,

33
00:03:32,155 --> 00:03:36,125
Speaker 6:  hopefully we solve the puzzle and yeah, that's what

34
00:03:36,285 --> 00:03:36,565
Speaker 6:  we do.

35
00:03:37,515 --> 00:03:41,165
Speaker 7:  Yeah. And we each post a video every day. And in

36
00:03:41,405 --> 00:03:45,285
Speaker 7:  addition to that, there's a weekly cryptic crossword masterclass as well,

37
00:03:46,105 --> 00:03:49,765
Speaker 7:  and we solve wordle every day as well. So there's a lot of content

38
00:03:50,025 --> 00:03:51,325
Speaker 7:  and it keeps us very busy.

39
00:03:52,205 --> 00:03:55,525
Speaker 2:  I really appreciate the wordle videos. They make me feel,

40
00:03:56,155 --> 00:04:00,125
Speaker 2:  they usually make me feel better. I'm like, okay, this,

41
00:04:00,155 --> 00:04:04,085
Speaker 2:  this wasn't as easy as I thought it was. And if you

42
00:04:04,085 --> 00:04:08,045
Speaker 2:  could explain really quickly, so I, I discovered your channel because I

43
00:04:08,065 --> 00:04:12,045
Speaker 2:  got into Sudoku, but I am more familiar with

44
00:04:12,565 --> 00:04:16,365
Speaker 2:  I think what you would call classic Sudoku. Yeah. Could you

45
00:04:17,155 --> 00:04:21,125
Speaker 2:  explain just the basics of classic Sudoku if people

46
00:04:21,125 --> 00:04:25,045
Speaker 2:  are not familiar, but also what, how it escalates from there

47
00:04:25,065 --> 00:04:26,605
Speaker 2:  and the kind of puzzles that you guys tackle?

48
00:04:27,195 --> 00:04:31,165
Speaker 6:  Sure thing. So in, in normal Sudoku, you get a, a grid

49
00:04:31,165 --> 00:04:35,005
Speaker 6:  of nine by nine cells and you have to put the digits

50
00:04:35,005 --> 00:04:38,885
Speaker 6:  one to nine once each in every row, every column. And then

51
00:04:38,885 --> 00:04:42,645
Speaker 6:  there'll be nine three by three boxes in the or nine by nine

52
00:04:42,715 --> 00:04:46,325
Speaker 6:  grid. And each of those three by three boxes mustn't have a repeated digit

53
00:04:46,325 --> 00:04:49,725
Speaker 6:  either. And that's the game that I think most of us are,

54
00:04:50,115 --> 00:04:53,845
Speaker 6:  were familiar with. When it, it first came to the West, I suppose,

55
00:04:53,895 --> 00:04:57,565
Speaker 6:  which was in early two thousands. And

56
00:04:58,005 --> 00:05:01,845
Speaker 6:  variance Sudoku takes that and sort of turns it up to

57
00:05:01,845 --> 00:05:05,805
Speaker 6:  11. So you might have extra graphics in the grid, there might

58
00:05:05,805 --> 00:05:09,125
Speaker 6:  be a thermometer winding its way through the grid,

59
00:05:09,745 --> 00:05:13,605
Speaker 6:  and you'll have to increase the digits along the

60
00:05:13,605 --> 00:05:17,565
Speaker 6:  thermometer from the bulb end, and then it can get crazier

61
00:05:17,585 --> 00:05:21,525
Speaker 6:  and crazier from there. We've got puzzles now where there's a

62
00:05:21,585 --> 00:05:25,245
Speaker 6:  rat in the grid that has to get to a cupcake going along a certain

63
00:05:25,885 --> 00:05:29,845
Speaker 6:  pathways. Oh my gosh. That we've got puzzles where the most of the

64
00:05:29,845 --> 00:05:33,725
Speaker 6:  grid is covered in fog and you can't see it when

65
00:05:33,725 --> 00:05:37,645
Speaker 6:  you get a correct digit. Some of the fog will clear, so the puzzle is

66
00:05:37,885 --> 00:05:41,645
Speaker 6:  revealed to you gradually. And these puzzles have all

67
00:05:41,645 --> 00:05:45,405
Speaker 6:  been handmade. So they're very, very different to

68
00:05:45,555 --> 00:05:49,445
Speaker 6:  most people's experience of Sudoku, which will be on the

69
00:05:49,445 --> 00:05:53,325
Speaker 6:  back of newspapers. All of those puzzles are

70
00:05:53,325 --> 00:05:57,045
Speaker 6:  made by computers. Okay. Whereas the moment you solve

71
00:05:57,245 --> 00:06:00,765
Speaker 6:  a puzzle that's been created by one of these

72
00:06:00,795 --> 00:06:04,605
Speaker 6:  fantastic human brains, it's a

73
00:06:04,605 --> 00:06:08,445
Speaker 6:  different experience altogether. And I think that's why the channel

74
00:06:08,545 --> 00:06:12,405
Speaker 6:  has become popular, is people are suddenly seeing just the art

75
00:06:12,755 --> 00:06:15,885
Speaker 6:  that can be found in the puzzle form.

76
00:06:17,085 --> 00:06:21,005
Speaker 2:  I find that so interesting because maybe one of the things I do when I

77
00:06:21,105 --> 00:06:25,005
Speaker 2:  get into a thing is be like, how is this made? I want to take it

78
00:06:25,005 --> 00:06:28,885
Speaker 2:  apart, you know? So maybe if you could talk a little bit

79
00:06:28,885 --> 00:06:32,365
Speaker 2:  about how, you mentioned a lot of Sudoku classic

80
00:06:32,555 --> 00:06:36,285
Speaker 2:  Sudokus are computer generated. Were they always like that?

81
00:06:36,505 --> 00:06:40,285
Speaker 2:  Is this like a recent thing and how can you tell the

82
00:06:40,285 --> 00:06:41,165
Speaker 2:  difference? You know?

83
00:06:42,115 --> 00:06:45,525
Speaker 6:  Well, I mean, originally the puzzle was invented in Japan

84
00:06:46,985 --> 00:06:50,685
Speaker 6:  by a company there called Nicki, which is a, a wonderful place of

85
00:06:50,685 --> 00:06:54,125
Speaker 6:  innovation. And all of their puzzles are handmade.

86
00:06:54,985 --> 00:06:58,485
Speaker 6:  But when the puzzle came to the West, it was

87
00:06:58,615 --> 00:07:02,565
Speaker 6:  Wayne Gould originally, I think a New Zealander who had invented a

88
00:07:02,765 --> 00:07:06,325
Speaker 6:  computer program that could just churn out zillions and zillions of puzzles.

89
00:07:06,325 --> 00:07:09,965
Speaker 6:  And he managed to sell it to many of the newspapers in the western world.

90
00:07:10,865 --> 00:07:14,685
Speaker 6:  And so it just became accepted that, you know, you could have

91
00:07:15,405 --> 00:07:18,405
Speaker 6:  computer puzzles and everyone seemed fine with that because they'd never

92
00:07:18,475 --> 00:07:21,805
Speaker 6:  experienced anything different. Whereas

93
00:07:22,275 --> 00:07:26,205
Speaker 6:  when, when you solve a Nicki Classic Sudoku, so the classic Sudokus that

94
00:07:26,205 --> 00:07:30,125
Speaker 6:  you were originally used to, Alison, you know, when you, when you solve one

95
00:07:30,125 --> 00:07:33,605
Speaker 6:  of these nickley puzzles, it's, it's completely different because the

96
00:07:33,835 --> 00:07:37,685
Speaker 6:  constructor has built into the puzzle sort of a

97
00:07:37,685 --> 00:07:41,485
Speaker 6:  trail of breadcrumbs, and you can feel what they

98
00:07:41,485 --> 00:07:44,725
Speaker 6:  want you to find at the particular points. And there's normally some really

99
00:07:44,725 --> 00:07:48,485
Speaker 6:  beautiful logic packed in there, which you just don't find

100
00:07:48,705 --> 00:07:52,285
Speaker 6:  in the machine generator puzzle. So yeah, it's a big

101
00:07:52,285 --> 00:07:52,725
Speaker 6:  difference.

102
00:07:53,235 --> 00:07:53,525
Speaker 2:  Yeah.

103
00:07:54,235 --> 00:07:57,805
Speaker 7:  When we started the channel, we were mainly solving classic

104
00:07:58,195 --> 00:08:01,925
Speaker 7:  Sudokus from say, the New York Times or something, and they would all be

105
00:08:02,485 --> 00:08:06,445
Speaker 7:  computer generated and they would often have a, a very standard

106
00:08:06,995 --> 00:08:10,805
Speaker 7:  kind of trick to get them done. And we would go through that. But

107
00:08:10,805 --> 00:08:14,565
Speaker 7:  then gradually as we got going, we, we wondered would it be interesting to

108
00:08:14,565 --> 00:08:18,485
Speaker 7:  show people the sort of variance sudokus from world Championships that we'd

109
00:08:18,485 --> 00:08:21,645
Speaker 7:  experienced that were a bit more interesting in a way? And

110
00:08:22,285 --> 00:08:25,885
Speaker 7:  unbelievably this whole community grew up watching these

111
00:08:25,985 --> 00:08:29,845
Speaker 7:  videos and going, oh no, that's, that's really interesting.

112
00:08:29,985 --> 00:08:33,765
Speaker 7:  Sudoku, And I think almost all the setters that we feature

113
00:08:33,865 --> 00:08:37,685
Speaker 7:  on the channel now. And we, we basically take submissions from

114
00:08:37,685 --> 00:08:41,645
Speaker 7:  people as, as a good puzzle to do on the channel. Almost all of them

115
00:08:41,795 --> 00:08:45,525
Speaker 7:  grew up learnt about variant Sudoku from our channel.

116
00:08:45,705 --> 00:08:48,965
Speaker 7:  So it's Oh wow. It's marvelously organic in a way.

117
00:08:49,995 --> 00:08:53,125
Speaker 2:  Yeah. I was wondering if you could talk a little bit about the community,

118
00:08:53,125 --> 00:08:56,805
Speaker 2:  because I think there, there's an interesting moment,

119
00:08:57,145 --> 00:09:00,685
Speaker 2:  you know, with, with any kind of creator on the web, you know,

120
00:09:00,875 --> 00:09:04,845
Speaker 2:  whether you run a website or a channel where we're sort of

121
00:09:05,845 --> 00:09:09,765
Speaker 2:  discovering just the real value to having a community. And, and

122
00:09:09,905 --> 00:09:13,725
Speaker 2:  that's kind of what people want. So how do people connect with you?

123
00:09:13,865 --> 00:09:17,525
Speaker 2:  You, you mentioned they suggest puzzles, but how else are you

124
00:09:17,805 --> 00:09:18,885
Speaker 2:  interacting with your community?

125
00:09:19,705 --> 00:09:22,765
Speaker 6:  One of the things that happened to us, we have to bear in mind, we're sort

126
00:09:22,765 --> 00:09:26,605
Speaker 6:  of middle aged guys. We're not tapped into things like

127
00:09:26,835 --> 00:09:30,805
Speaker 6:  Discord, but when the channel started to get bigger, we got

128
00:09:31,045 --> 00:09:34,165
Speaker 6:  approached by some people who watched it and said that you really should

129
00:09:34,165 --> 00:09:37,885
Speaker 6:  have a Discord channel associated with your YouTube

130
00:09:37,885 --> 00:09:41,845
Speaker 6:  channel. And we were like, oh, that, well, that sounds good. And they said,

131
00:09:41,845 --> 00:09:45,645
Speaker 6:  oh, well, we'll take on the sort of role of setting it up for you. And we

132
00:09:45,645 --> 00:09:49,405
Speaker 6:  thought, oh, that'll be nice. I think there are now nearly 40,000

133
00:09:49,505 --> 00:09:53,005
Speaker 6:  people in this Discord server. Oh, wow. And

134
00:09:53,705 --> 00:09:57,085
Speaker 6:  all trading ideas, all solving puzzles for each other,

135
00:09:57,385 --> 00:10:01,245
Speaker 6:  trying to push forward the boundaries of what's possible in

136
00:10:01,465 --> 00:10:05,165
Speaker 6:  Sudoku. I mean, I, I shudder to think what the combined

137
00:10:05,385 --> 00:10:09,165
Speaker 6:  IQ is of the people on there, but it is, there is some

138
00:10:09,315 --> 00:10:13,165
Speaker 6:  serious weapon in terms of intellectual firepower.

139
00:10:14,025 --> 00:10:17,525
Speaker 6:  And one of the lovely things about Cracking the Cryptic is that

140
00:10:18,045 --> 00:10:21,685
Speaker 6:  actually the community is remarkably kind.

141
00:10:22,845 --> 00:10:25,885
Speaker 6:  It's something we've always encouraged, you know, kind comments,

142
00:10:26,975 --> 00:10:30,805
Speaker 6:  positivity, and people really seem to take that to

143
00:10:30,805 --> 00:10:34,645
Speaker 6:  heart. And I think most of the internet now is probably a place where

144
00:10:34,695 --> 00:10:38,005
Speaker 6:  blood pressure gets raised, whereas cracking the crypto is a place where

145
00:10:38,005 --> 00:10:41,845
Speaker 6:  it sort of gets calmed a bit. And yeah, it's attracted

146
00:10:41,905 --> 00:10:45,725
Speaker 6:  people to it who are in general very decent

147
00:10:46,105 --> 00:10:49,605
Speaker 6:  and normally very bright as well. So I get a lot of

148
00:10:49,685 --> 00:10:51,885
Speaker 6:  imposter syndrome, at least I do.

149
00:10:53,105 --> 00:10:56,405
Speaker 2:  Oh my gosh. I mean, having to solve

150
00:10:56,455 --> 00:11:00,285
Speaker 2:  everything live and kind of be on your feet like that, is it a

151
00:11:00,285 --> 00:11:02,125
Speaker 2:  challenge every day? Do you get kind of nervous?

152
00:11:03,025 --> 00:11:06,885
Speaker 7:  It is daunting. It is a worry that you, you sit down in

153
00:11:06,885 --> 00:11:10,525
Speaker 7:  front of a puzzle and if it goes wrong, I mean, if it goes

154
00:11:10,525 --> 00:11:14,285
Speaker 7:  completely wrong and you can't solve it, we don't have to put up a video.

155
00:11:14,465 --> 00:11:18,125
Speaker 7:  So there's always that get out. But that's

156
00:11:18,195 --> 00:11:21,565
Speaker 7:  kind of a rarity I think, for both of us. And, and most of the time,

157
00:11:21,985 --> 00:11:25,685
Speaker 7:  if you do make a mistake, well you have to kind of backtrack and find it

158
00:11:25,785 --> 00:11:28,685
Speaker 7:  and work out what you did wrong. And people are very generous about that

159
00:11:28,745 --> 00:11:32,485
Speaker 7:  as well. I think, as Simon said, the levels of kindness

160
00:11:32,665 --> 00:11:36,365
Speaker 7:  are very high and the, the great setters and

161
00:11:36,385 --> 00:11:40,325
Speaker 7:  theory creators seem very keen to still interact with

162
00:11:40,325 --> 00:11:44,205
Speaker 7:  us, even though I suspect we've been revealed as not the, not the

163
00:11:44,205 --> 00:11:47,445
Speaker 7:  great brains that people maybe thought we were at the beginning.

164
00:11:48,065 --> 00:11:51,965
Speaker 7:  But it is just a pleasure to deal with almost everybody

165
00:11:52,265 --> 00:11:56,005
Speaker 7:  on the site through Discord in the comments. We get

166
00:11:56,005 --> 00:11:59,885
Speaker 7:  emails, we, we put our email address out every day and we get

167
00:11:59,885 --> 00:12:03,685
Speaker 7:  hundreds of emails, as I say, puzzle suggestions, but also lots of

168
00:12:03,875 --> 00:12:07,645
Speaker 7:  general comment. I think we were amazed at the beginning when it started

169
00:12:07,705 --> 00:12:11,085
Speaker 7:  to grow and people would tell us something like, oh, I fall asleep to you

170
00:12:11,085 --> 00:12:14,205
Speaker 7:  every night. And we weren't sure whether that was a compliment or an insult.

171
00:12:14,535 --> 00:12:18,445
Speaker 7:  Right. But gradually there was a period, and it's probably

172
00:12:18,445 --> 00:12:22,325
Speaker 7:  still ongoing, where we get about one email a day

173
00:12:22,495 --> 00:12:25,525
Speaker 7:  about how we've seriously helped someone's mental health

174
00:12:26,425 --> 00:12:30,205
Speaker 7:  to, to, you know, from extreme levels of stress

175
00:12:30,205 --> 00:12:33,885
Speaker 7:  sometimes. Mm. We've had at least three

176
00:12:33,885 --> 00:12:37,565
Speaker 7:  doctors tell us that they would've given up their course, but the calm logic

177
00:12:37,635 --> 00:12:41,405
Speaker 7:  that we allowed them to see enabled them to keep going

178
00:12:41,505 --> 00:12:45,325
Speaker 7:  in their studies. And it's just, it's an amazing thing to have

179
00:12:45,325 --> 00:12:49,165
Speaker 7:  that kind of impact with no, no thought or plan of doing

180
00:12:49,185 --> 00:12:49,405
Speaker 7:  so.

181
00:12:49,915 --> 00:12:53,805
Speaker 2:  Yeah. Yeah. There is kind of, strikes me as like,

182
00:12:53,805 --> 00:12:57,605
Speaker 2:  solving a puzzle is a pretty solitary activity. I mean,

183
00:12:57,605 --> 00:13:01,205
Speaker 2:  it ha kind of has to be, unless you're doing a jigsaw puzzle with your friends

184
00:13:01,205 --> 00:13:04,965
Speaker 2:  or something, and sort of personal in a way. Like when I

185
00:13:05,225 --> 00:13:09,125
Speaker 2:  sit down to do Wordle every morning, I feel

186
00:13:09,245 --> 00:13:12,885
Speaker 2:  a little embarrassed to like show other people my guesses. You know,

187
00:13:13,105 --> 00:13:16,845
Speaker 2:  you're, you're sort of like, it's sort of like when you talk on the,

188
00:13:16,845 --> 00:13:20,365
Speaker 2:  you're like ordering a pizza on the phone And I don't, I'm like, I don't

189
00:13:20,365 --> 00:13:23,525
Speaker 2:  want anyone else to hear me like working this out.

190
00:13:24,145 --> 00:13:28,085
Speaker 2:  So I wonder if there's an element of just, it, it

191
00:13:28,085 --> 00:13:31,725
Speaker 2:  feels like you're exposing something a little bit and people are

192
00:13:31,815 --> 00:13:35,725
Speaker 2:  connecting to that in a way where it resonates, I

193
00:13:35,725 --> 00:13:35,845
Speaker 2:  guess.

194
00:13:36,845 --> 00:13:40,525
Speaker 6:  I think there, there's definitely something to that. I mean, it is nerve

195
00:13:40,525 --> 00:13:44,325
Speaker 6:  wracking to actually solve and,

196
00:13:44,325 --> 00:13:47,685
Speaker 6:  and because all of the thinking you're doing is live, I mean, I, I still

197
00:13:47,685 --> 00:13:51,125
Speaker 6:  get this, this shot of adrenaline if I have to do mental

198
00:13:51,485 --> 00:13:54,885
Speaker 6:  arithmetic. 'cause some of the arithmetic we have to do, it's, it's,

199
00:13:56,385 --> 00:14:00,365
Speaker 6:  you know, you could be multiplying some reasonably big, you know, two digit

200
00:14:00,365 --> 00:14:03,605
Speaker 6:  numbers or something like that, but you might be having to find the prime

201
00:14:03,605 --> 00:14:06,725
Speaker 6:  factors of something that's not trivial.

202
00:14:08,585 --> 00:14:12,485
Speaker 6:  And it's, it's, you're sort of there thinking, people are gonna be

203
00:14:12,725 --> 00:14:16,485
Speaker 6:  watching me thinking he's so stupid, why can't he do it

204
00:14:16,485 --> 00:14:20,285
Speaker 6:  more quickly? And you, you know, you've got this devil on your

205
00:14:20,485 --> 00:14:24,325
Speaker 6:  shoulder the whole time chirping away about how, how you're being dumb and

206
00:14:24,325 --> 00:14:27,965
Speaker 6:  you have to ignore him because he's, he's just a very annoying

207
00:14:28,405 --> 00:14:30,725
Speaker 6:  creature, but he's definitely there.

208
00:14:32,235 --> 00:14:32,525
Speaker 2:  Yeah.

209
00:14:33,025 --> 00:14:36,125
Speaker 7:  We also have different strengths. I think Allison, well sometimes

210
00:14:36,865 --> 00:14:40,805
Speaker 7:  I'm marvel at Simon's instinct for a break in, in a puzzle

211
00:14:40,865 --> 00:14:44,365
Speaker 7:  that's complicated to start, And I just

212
00:14:44,575 --> 00:14:48,245
Speaker 7:  can't see how he's honing in on the right spots as he so often does.

213
00:14:49,475 --> 00:14:53,375
Speaker 7:  He's, I understand jealous of my sort of basic Sudoku

214
00:14:53,655 --> 00:14:57,495
Speaker 7:  mechanics and, and maybe some of that mental arithmetic as well.

215
00:14:57,635 --> 00:15:01,575
Speaker 7:  But, you know, these are the skills that I think are trivial. Whereas he

216
00:15:01,595 --> 00:15:05,175
Speaker 7:  has skills that, you know, I can sit in front of a really hard puzzle

217
00:15:05,395 --> 00:15:09,255
Speaker 7:  for 20 minutes, half an hour, 40 minutes, just not knowing what

218
00:15:09,535 --> 00:15:12,615
Speaker 7:  to do. And it just feels dreadful in a way. But

219
00:15:13,355 --> 00:15:16,895
Speaker 7:  you, you know, you learn over time that if you keep worrying away at it,

220
00:15:16,995 --> 00:15:20,415
Speaker 7:  you can. And this is very important to remember that the

221
00:15:20,615 --> 00:15:24,215
Speaker 7:  constructors are setting you a puzzle that they want you to have fun with

222
00:15:24,215 --> 00:15:27,775
Speaker 7:  and struggle with, but they want you to get there. So there is this

223
00:15:28,345 --> 00:15:32,295
Speaker 7:  trail of logic defined, and when you do light on it,

224
00:15:32,355 --> 00:15:35,695
Speaker 7:  you get this wonderful epiphany. And I think that's what keeps people coming

225
00:15:35,765 --> 00:15:39,535
Speaker 7:  back to the channel, is watching those moments where you

226
00:15:39,775 --> 00:15:42,215
Speaker 7:  suddenly understand something and that's joyful.

227
00:15:43,595 --> 00:15:47,575
Speaker 8:  No, hang on. Maybe it's, no, it is the same. If

228
00:15:47,575 --> 00:15:50,535
Speaker 8:  that's a six, I can't put a one here.

229
00:15:51,435 --> 00:15:54,735
Speaker 8:  And this is a six in box five, which puts a one here, so you can't put a

230
00:15:54,735 --> 00:15:58,495
Speaker 8:  one either side of it. So here we go. So now I've got, now

231
00:15:58,695 --> 00:16:01,415
Speaker 8:  I know that there's a six in this domino, which means this is not a six,

232
00:16:01,685 --> 00:16:05,575
Speaker 8:  this is a six, which means this is a one, this is a two,

233
00:16:06,075 --> 00:16:08,495
Speaker 8:  and we are cooking with gas all of a sudden.

234
00:16:09,705 --> 00:16:13,435
Speaker 2:  Yeah. I don't know if I'm just like keying into this because

235
00:16:13,545 --> 00:16:17,355
Speaker 2:  I've been interested in Sudoku, but there's

236
00:16:17,435 --> 00:16:21,035
Speaker 2:  a lot of, like puzzles seem to be having a moment. Like

237
00:16:21,355 --> 00:16:25,315
Speaker 2:  I know, yeah. A friend of mine is addicted to the puzzles

238
00:16:25,315 --> 00:16:28,795
Speaker 2:  in the LinkedIn app and like Yeah. Opens

239
00:16:29,075 --> 00:16:32,835
Speaker 2:  LinkedIn every day. And I, I'm sure there's an element of they've

240
00:16:33,075 --> 00:16:36,635
Speaker 2:  discovered, you know, they can keep people coming back every day and get

241
00:16:36,635 --> 00:16:40,555
Speaker 2:  those like daily user numbers up. But what do you think

242
00:16:40,555 --> 00:16:44,355
Speaker 2:  that says about like BBR moment culturally,

243
00:16:44,535 --> 00:16:46,355
Speaker 2:  or what puzzles are doing for people?

244
00:16:47,475 --> 00:16:51,235
Speaker 6:  I think there's a, there's a lot to unpack there. I mean, I think LinkedIn

245
00:16:51,735 --> 00:16:55,555
Speaker 6:  has really, it, it dodges most office firewalls

246
00:16:55,555 --> 00:16:59,075
Speaker 6:  of course, which means that it's absolutely brilliant if you, if you're,

247
00:16:59,375 --> 00:17:03,195
Speaker 6:  if you enjoy having a few minutes out every day and you

248
00:17:03,195 --> 00:17:06,755
Speaker 6:  can, a lot of puzzle websites tend to be blocked from my

249
00:17:06,755 --> 00:17:10,715
Speaker 6:  experience, but LinkedIn probably won't be, you know, so

250
00:17:10,715 --> 00:17:14,675
Speaker 6:  that's a good thing. But I also, I sense that there is being

251
00:17:14,755 --> 00:17:18,275
Speaker 6:  a bit geeky or nerdy, which I've been throughout my life. I mean,

252
00:17:19,425 --> 00:17:19,715
Speaker 2:  Same,

253
00:17:19,985 --> 00:17:23,315
Speaker 6:  Yeah, I've never, never been cool popular,

254
00:17:25,075 --> 00:17:28,795
Speaker 6:  I mean, my sister has relished throughout my life, you know, telling me

255
00:17:28,895 --> 00:17:31,955
Speaker 6:  how, you know, useless, I am in all social situations,

256
00:17:33,055 --> 00:17:36,435
Speaker 6:  but now it just feels, I, I dunno whether it's AI

257
00:17:36,855 --> 00:17:40,755
Speaker 6:  or, you know, computer programming becoming, it's

258
00:17:40,755 --> 00:17:44,275
Speaker 6:  everywhere, isn't it? And so necessary for so many parts of life.

259
00:17:45,175 --> 00:17:48,835
Speaker 6:  But it feels like, oh, the popularity of things like

260
00:17:49,080 --> 00:17:53,005
Speaker 6:  escape rooms as well. Mm. Or maybe it's the mindfulness that

261
00:17:53,005 --> 00:17:56,845
Speaker 6:  comes with doing puzzles as you've found. You, you're sort of, when you,

262
00:17:56,845 --> 00:18:00,445
Speaker 6:  when you actually have to focus on a puzzle, you're taken away

263
00:18:00,635 --> 00:18:04,205
Speaker 6:  from maybe the worries of life for a few minutes, you have to focus on what

264
00:18:04,205 --> 00:18:07,845
Speaker 6:  you're doing or you probably won't get very far and it brings a

265
00:18:07,845 --> 00:18:11,165
Speaker 6:  calmness. And maybe people value that in this

266
00:18:11,625 --> 00:18:15,325
Speaker 6:  day and age more than they perhaps would've done 15,

267
00:18:15,325 --> 00:18:16,725
Speaker 6:  20 years ago. Yeah.

268
00:18:17,365 --> 00:18:20,205
Speaker 7:  I think the way you expressed it, Alison, is absolutely right. Puzzles are

269
00:18:20,205 --> 00:18:23,125
Speaker 7:  having their moment. But in a way, what it is, is I think people are

270
00:18:24,105 --> 00:18:28,085
Speaker 7:  in this moment discovering puzzles and finding out how, how much

271
00:18:28,105 --> 00:18:32,005
Speaker 7:  fun they are. I come from originally before Sudoku from a

272
00:18:32,005 --> 00:18:35,405
Speaker 7:  world of cry crosswords, and people have often asked me, why,

273
00:18:35,985 --> 00:18:39,565
Speaker 7:  you know, why are you doing, oh now, now it's obvious. But in the old days

274
00:18:39,565 --> 00:18:42,685
Speaker 7:  they would ask me, why are you doing this old man's pursuit? And I was saying,

275
00:18:42,685 --> 00:18:46,405
Speaker 7:  well, it's not, doesn't have to be. Basically, once you find the joy of

276
00:18:46,405 --> 00:18:50,165
Speaker 7:  cryptic crosswords, there's no reason ever to stop doing them. And people

277
00:18:50,255 --> 00:18:54,045
Speaker 7:  don't, and therefore the average age tends to skew older

278
00:18:54,075 --> 00:18:57,485
Speaker 7:  than for pursuits that people will give up when they've had their fill. But

279
00:18:58,025 --> 00:19:01,285
Speaker 7:  you don't do that. And I think it's true about Sudoku as well. People stay

280
00:19:01,315 --> 00:19:04,805
Speaker 7:  with it even if they don't stay with our channel. I think they stay with

281
00:19:04,985 --> 00:19:08,605
Speaker 7:  Sudoku and with puzzles and, you know, we've been part,

282
00:19:08,635 --> 00:19:12,445
Speaker 7:  perhaps of leading people to discover puzzles. And that's

283
00:19:12,445 --> 00:19:16,405
Speaker 7:  great. And I think it's more that people are sort of free to enjoy them now

284
00:19:16,405 --> 00:19:19,485
Speaker 7:  rather than that they, that they hadn't thought of them before.

285
00:19:20,265 --> 00:19:24,005
Speaker 2:  I'm curious actually about kind of the tools you use

286
00:19:24,065 --> 00:19:27,965
Speaker 2:  in your puzzles, because I think Mamie, Simon, you

287
00:19:27,965 --> 00:19:31,885
Speaker 2:  mentioned in a video that you sort of prefer puzzles

288
00:19:31,995 --> 00:19:35,885
Speaker 2:  that you can just think through and there are

289
00:19:36,295 --> 00:19:39,525
Speaker 2:  tools that exist for super hard

290
00:19:39,905 --> 00:19:43,885
Speaker 2:  Sudoku that like help you math your way

291
00:19:43,885 --> 00:19:47,405
Speaker 2:  out of it. I don't know, can you, can you kind of talk me through like the

292
00:19:47,405 --> 00:19:50,805
Speaker 2:  tools you do and don't use when you are solving puzzles?

293
00:19:51,675 --> 00:19:55,365
Speaker 6:  Yeah. I mean, we both use compute obviously because we're, we're

294
00:19:55,365 --> 00:19:59,285
Speaker 6:  recording something we're doing on a computer. We have some great software

295
00:19:59,285 --> 00:20:03,085
Speaker 6:  that's been created by VE Neumann, which

296
00:20:03,185 --> 00:20:06,085
Speaker 6:  is very, very good. It allows us to

297
00:20:06,785 --> 00:20:10,685
Speaker 6:  employ some techniques that are much harder to do if you've just got a pencil.

298
00:20:11,765 --> 00:20:15,045
Speaker 6:  So for example, we can color in cells or we could even

299
00:20:15,475 --> 00:20:19,285
Speaker 6:  draw lines through cells. And when we're solving these

300
00:20:19,285 --> 00:20:22,965
Speaker 6:  harder puzzles, things like that, they're pretty useful.

301
00:20:23,785 --> 00:20:27,445
Speaker 6:  The software even I, I mean, we don't use it, but it'll allow you to

302
00:20:28,385 --> 00:20:32,195
Speaker 6:  compute all the different ways of adding up to 25 with four digits.

303
00:20:32,205 --> 00:20:35,195
Speaker 6:  It'll actually give you a list of all the ways that, that you can do that.

304
00:20:35,215 --> 00:20:38,875
Speaker 6:  So if you don't like doing the arithmetic, you can still,

305
00:20:39,335 --> 00:20:42,995
Speaker 6:  you know, access the puzzle. But I think as, as with

306
00:20:43,235 --> 00:20:47,035
Speaker 6:  anything, what you find is you build up your own personal tool

307
00:20:47,145 --> 00:20:50,725
Speaker 6:  of, I don't know, tricks, techniques, and you

308
00:20:50,855 --> 00:20:54,765
Speaker 6:  cycle through those. And that only really comes with experience.

309
00:20:55,785 --> 00:20:59,765
Speaker 6:  And I guess now Mark And I have a lot of experience, so we've got something

310
00:20:59,765 --> 00:21:01,685
Speaker 6:  like 4,000 videos now, mark,

311
00:21:02,065 --> 00:21:02,645
Speaker 2:  Oh my gosh,

312
00:21:03,245 --> 00:21:04,765
Speaker 7:  I think it may be 5,000 now.

313
00:21:05,075 --> 00:21:06,605
Speaker 6:  Okay. 5,000 now. It's incredible.

314
00:21:06,745 --> 00:21:07,605
Speaker 2:  Oh, wow. Yeah.

315
00:21:08,195 --> 00:21:11,205
Speaker 6:  Yeah. It's, it's a back catalog.

316
00:21:12,195 --> 00:21:16,005
Speaker 7:  Yeah. It, it's, you do build up a lot of experience and it's often very helpful.

317
00:21:16,345 --> 00:21:20,085
Speaker 7:  And yet still, every few months, something completely new

318
00:21:20,665 --> 00:21:24,525
Speaker 7:  is kind of forced in upon us by a brilliant constructor.

319
00:21:24,665 --> 00:21:28,565
Speaker 7:  And we learned something totally new about even sometimes about a

320
00:21:28,565 --> 00:21:32,445
Speaker 7:  basic Sudoku grid that it, it must have some property that we didn't know

321
00:21:32,445 --> 00:21:36,245
Speaker 7:  before. And that, you know, I still think in some ways this is

322
00:21:36,825 --> 00:21:39,085
Speaker 7:  the dawn of Sudoku, which is brilliant

323
00:21:39,665 --> 00:21:43,045
Speaker 6:  Mark's. Right. I mean, there, there was a mad thing we discovered the other

324
00:21:43,065 --> 00:21:46,445
Speaker 6:  day for the first time, which is sort of, if you check, imagine that you've

325
00:21:46,445 --> 00:21:50,325
Speaker 6:  checkerboarded your Sudoku, the sort

326
00:21:50,325 --> 00:21:54,245
Speaker 6:  of internal checkerboard you've created, any digit

327
00:21:54,245 --> 00:21:57,925
Speaker 6:  you put in that has to appear an even number of times in that internal

328
00:21:57,925 --> 00:22:01,645
Speaker 6:  checkerboard, which it's like, why, why,

329
00:22:01,745 --> 00:22:02,285
Speaker 6:  why is that

330
00:22:02,285 --> 00:22:02,485
Speaker 2:  True?

331
00:22:02,985 --> 00:22:06,525
Speaker 6:  And, and yet sort of geometrically mathematically it is true,

332
00:22:07,105 --> 00:22:10,525
Speaker 6:  but we, we didn't know it. I didn't know it before I did that puzzle. It

333
00:22:10,525 --> 00:22:13,965
Speaker 6:  was completely, it's like, it's, it's a truth that exists

334
00:22:14,095 --> 00:22:15,965
Speaker 6:  underneath the surface of the puzzle.

335
00:22:16,675 --> 00:22:20,605
Speaker 7:  It's not gonna help you solve a classic Sudoku, but it's there and it's

336
00:22:20,605 --> 00:22:24,165
Speaker 7:  just sitting there like a, a mathematical truth. It's extraordinary.

337
00:22:24,435 --> 00:22:24,725
Speaker 7:  Yeah.

338
00:22:24,795 --> 00:22:28,445
Speaker 2:  Yeah. There, there is something really satisfying, I think, in, in

339
00:22:28,685 --> 00:22:32,605
Speaker 2:  discovering new layers of something you've been enjoying. Yeah. I do

340
00:22:32,605 --> 00:22:35,605
Speaker 2:  wanna touch on a puzzle you did, and this was,

341
00:22:36,685 --> 00:22:40,485
Speaker 2:  I guess, went viral. We wrote about it on The

342
00:22:40,605 --> 00:22:44,445
Speaker 2:  Verge. Oh, this was the Miracle Sudoku, is that right? Yeah.

343
00:22:44,465 --> 00:22:48,125
Speaker 2:  Can you, and Simon, you, you solved this one. Can you describe

344
00:22:49,275 --> 00:22:52,565
Speaker 2:  what this puzzle was and kind of how it went?

345
00:22:52,845 --> 00:22:56,605
Speaker 6:  Well, I, I can, I mean, but really it was Mark's fault. So

346
00:22:56,835 --> 00:23:00,645
Speaker 6:  what what happened was we got sent a

347
00:23:00,645 --> 00:23:03,725
Speaker 6:  puzzle by a structor called Mitchell Lee.

348
00:23:04,825 --> 00:23:08,525
Speaker 6:  And the very, very unusual thing at the time about this puzzle was, it looked

349
00:23:08,525 --> 00:23:11,965
Speaker 6:  like a normal Sudoku, except rather than having several digits in the grid,

350
00:23:12,215 --> 00:23:16,125
Speaker 6:  there were only two digits in the grid. It was a one

351
00:23:16,305 --> 00:23:20,045
Speaker 6:  and a two, and that was it. And Mark

352
00:23:20,635 --> 00:23:24,165
Speaker 6:  sent me an email and said, it would be good if you opened this live on camera.

353
00:23:25,265 --> 00:23:29,205
Speaker 6:  So I took him at his word, set up my machine, loaded it, having

354
00:23:29,205 --> 00:23:33,065
Speaker 6:  started the recording and was faced with this at that

355
00:23:33,065 --> 00:23:36,505
Speaker 6:  time, it just looked, it looked stupid. I thought he'd just done it as a

356
00:23:36,505 --> 00:23:37,545
Speaker 6:  joke. Let me

357
00:23:37,545 --> 00:23:41,505
Speaker 9:  Just see if I can put that in there. Let's see

358
00:23:41,505 --> 00:23:43,385
Speaker 9:  what we get. Right.

359
00:23:46,945 --> 00:23:48,005
Speaker 9:  He is got to be joking.

360
00:23:49,615 --> 00:23:49,965
Speaker 9:  There

361
00:23:51,505 --> 00:23:55,045
Speaker 9:  is no way that this, well, it might have a unique

362
00:23:55,405 --> 00:23:57,645
Speaker 9:  solution, but it's not gonna be findable by a human being.

363
00:23:59,445 --> 00:24:02,885
Speaker 9:  I suspect this is going to be a short video because he is

364
00:24:03,245 --> 00:24:03,805
Speaker 9:  trolling me.

365
00:24:05,825 --> 00:24:09,805
Speaker 6:  And so I very nearly thank goodness I didn't, I very nearly turned

366
00:24:09,805 --> 00:24:13,485
Speaker 6:  off the webcam and sort of called him in high dungeon.

367
00:24:13,865 --> 00:24:17,565
Speaker 6:  But no, I, I could see one thing at the start that I could possibly do.

368
00:24:18,145 --> 00:24:22,005
Speaker 6:  And so I did the thing, and then it was amazing after,

369
00:24:22,545 --> 00:24:26,485
Speaker 6:  you know, a few more steps, I could see something else. And it was one

370
00:24:26,485 --> 00:24:30,245
Speaker 6:  of those puzzles where you sort of, it was like a snowball, you starting

371
00:24:30,305 --> 00:24:34,165
Speaker 6:  an avalanche, all of a sudden you could, this pattern emerged

372
00:24:34,405 --> 00:24:38,045
Speaker 6:  and you could, at the end, I did solve it. And I think the reason it was

373
00:24:38,045 --> 00:24:41,965
Speaker 6:  popular was just my sheer astonishment that, that

374
00:24:41,965 --> 00:24:45,845
Speaker 6:  this could exist. That that, that you could, yeah. That,

375
00:24:45,915 --> 00:24:48,805
Speaker 6:  that somebody had had the idea that somebody had made it,

376
00:24:49,265 --> 00:24:53,045
Speaker 7:  And also that this impossibility was actually solved in about

377
00:24:53,045 --> 00:24:56,605
Speaker 7:  25 minutes. It was just bizarre. It was bizarre

378
00:24:56,795 --> 00:25:00,725
Speaker 7:  exactly my finding when I, when I tried it before Simon had

379
00:25:00,725 --> 00:25:01,085
Speaker 7:  seen it.

380
00:25:02,515 --> 00:25:06,365
Speaker 2:  Yeah. And something if, if people aren't familiar with the channel, you

381
00:25:06,365 --> 00:25:09,245
Speaker 2:  can solve along with these puzzles. So

382
00:25:09,945 --> 00:25:13,885
Speaker 2:  that's exactly what I did, you know, watched you get started with

383
00:25:13,885 --> 00:25:17,805
Speaker 2:  it, and then yeah, you, you look at it, you're like, there's no way

384
00:25:17,875 --> 00:25:21,765
Speaker 2:  this could be solvable, but I saw you, you know, go through the first kind

385
00:25:21,765 --> 00:25:25,725
Speaker 2:  of steps and tried it on my own. And it, you

386
00:25:25,725 --> 00:25:29,365
Speaker 2:  know, I had to like rewind a couple times and see what you were doing.

387
00:25:29,505 --> 00:25:33,325
Speaker 2:  But it's so cool to kind of go on that journey with you where I'm like,

388
00:25:33,825 --> 00:25:37,645
Speaker 2:  oh my God, I am solving this, this. Yeah. Just,

389
00:25:37,845 --> 00:25:38,965
Speaker 2:  I had a lot of fun with it.

390
00:25:39,195 --> 00:25:42,485
Speaker 6:  Yeah. I mean, it was, it was remarkable. I mean, we, we got,

391
00:25:43,225 --> 00:25:47,165
Speaker 6:  we got emails from all over the world as a result of that. It was, it

392
00:25:47,165 --> 00:25:50,965
Speaker 6:  was like a moment where, you know, they say everyone, everybody has their

393
00:25:50,965 --> 00:25:54,645
Speaker 6:  15 or five minutes of fame. It was like that spotlight

394
00:25:55,045 --> 00:25:58,885
Speaker 6:  suddenly turned on us for a, for just a, just a scintilla of time. And

395
00:25:58,885 --> 00:26:02,845
Speaker 6:  you sort of got a bit of the glare of a little bit of publicity, and it was,

396
00:26:03,105 --> 00:26:06,325
Speaker 6:  it was very enjoyable because it was so brief and unexpected.

397
00:26:07,325 --> 00:26:10,965
Speaker 2:  Hmm. Yeah. And a, a positive, I think, you know, of people

398
00:26:11,185 --> 00:26:14,725
Speaker 2:  are discovering it and having like a

399
00:26:14,785 --> 00:26:18,485
Speaker 2:  joyful moment of like, I can't believe I just watched this 25 minute

400
00:26:18,795 --> 00:26:22,685
Speaker 2:  long video, which is, I think, interesting, and you

401
00:26:22,685 --> 00:26:26,645
Speaker 2:  kind of touched on this. I think that your videos are long,

402
00:26:26,795 --> 00:26:29,925
Speaker 2:  like, you know, comparatively in, in the age of

403
00:26:30,275 --> 00:26:34,125
Speaker 2:  certainly TikTok, where you watch for a few seconds

404
00:26:34,305 --> 00:26:37,405
Speaker 2:  and scroll on, can you talk a little bit about

405
00:26:38,225 --> 00:26:42,005
Speaker 2:  why you're able to enjoy having such a long

406
00:26:42,005 --> 00:26:45,925
Speaker 2:  amount of time to show what you're doing and talk about what

407
00:26:45,925 --> 00:26:46,605
Speaker 2:  you're doing? And

408
00:26:47,185 --> 00:26:50,365
Speaker 7:  We, we thought that people would just wanna see the technique, would just

409
00:26:50,365 --> 00:26:53,285
Speaker 7:  want the lesson. And then we kind of thought, well, they won't wanna watch

410
00:26:53,305 --> 00:26:57,165
Speaker 7:  the rest of the solve that's just filling in the numbers. And we, we would

411
00:26:57,225 --> 00:27:01,045
Speaker 7:  try things like speeding it up or putting music to it, and they got

412
00:27:01,045 --> 00:27:04,285
Speaker 7:  really annoyed. They said, no, no, no, no, we wanna see you solve it till

413
00:27:04,285 --> 00:27:08,125
Speaker 7:  the end. And it is, I think it's what you said earlier, that

414
00:27:08,125 --> 00:27:11,765
Speaker 7:  people want to come on the journey of the solve, and they want to be part

415
00:27:11,765 --> 00:27:15,405
Speaker 7:  of it all the way. Some people treat it like sport, like a spectator

416
00:27:15,415 --> 00:27:19,205
Speaker 7:  sport. And until you put the last digit in, the final whistle doesn't blow.

417
00:27:19,705 --> 00:27:23,485
Speaker 7:  So it's, it's still going. And, and

418
00:27:23,485 --> 00:27:26,925
Speaker 7:  that extends into the longer videos. I mean, Simon's done videos,

419
00:27:27,465 --> 00:27:31,325
Speaker 7:  is it three hours you've done now, Simon, in a, in a

420
00:27:31,325 --> 00:27:31,965
Speaker 7:  single puzzle,

421
00:27:32,555 --> 00:27:36,365
Speaker 6:  Four hours, 10 minutes, gosh, is the longest puzzle.

422
00:27:37,345 --> 00:27:41,125
Speaker 6:  And wow, you, you'd think, oh, well that can't be popular because how could,

423
00:27:41,185 --> 00:27:45,085
Speaker 6:  how could it possibly be the case that anybody would want to watch a

424
00:27:45,105 --> 00:27:49,085
Speaker 6:  man solve a Sudoku puzzle for longer than the extended

425
00:27:49,115 --> 00:27:52,965
Speaker 6:  edition of Return of the King or something? It cannot be, it

426
00:27:52,965 --> 00:27:56,835
Speaker 6:  cannot be. Right. And yet, and yet it's one of our

427
00:27:56,915 --> 00:27:59,595
Speaker 6:  most popular videos of recent times.

428
00:28:01,105 --> 00:28:05,035
Speaker 6:  It's like they, people get invested in it. And then In fact,

429
00:28:05,175 --> 00:28:09,115
Speaker 6:  on that video, as one of my favorite comments underneath the

430
00:28:09,115 --> 00:28:10,395
Speaker 6:  video that we've ever had,

431
00:28:54,255 --> 00:28:54,895
Speaker 7:  I think they love

432
00:29:31,175 --> 00:29:34,855
Speaker 2:  come back, we're gonna be talking to Mark LaVoy about his new camera app,

433
00:29:34,855 --> 00:29:37,015
Speaker 2:  Project Indigo. It's coming right up.

434
00:32:20,875 --> 00:32:24,555
Speaker 2:  I am joined by someone who, for a portion of our

435
00:32:24,835 --> 00:32:28,035
Speaker 2:  audience will not need an introduction, but we'll do an anyway, I'm here

436
00:32:28,035 --> 00:32:29,555
Speaker 2:  with Mark LaVoy. Hey Mark.

437
00:32:30,095 --> 00:32:31,355
Speaker 14:  Hi, nice to be with you.

438
00:32:31,655 --> 00:32:35,515
Speaker 2:  Thanks for joining. Mark LaVoy is a professor

439
00:32:35,795 --> 00:32:39,605
Speaker 2:  emeritus of computer science at Stanford, but right now and

440
00:32:39,605 --> 00:32:43,085
Speaker 2:  what we're gonna be talking about, he is a VP and fellow at Adobe

441
00:32:43,655 --> 00:32:47,485
Speaker 2:  where he has been working on a new camera app, also known

442
00:32:47,505 --> 00:32:51,485
Speaker 2:  to a lot of people in our audience in particular for his work on Google

443
00:32:51,495 --> 00:32:55,325
Speaker 2:  Pixel camera for for many years. So thank you for joining

444
00:32:55,345 --> 00:32:55,565
Speaker 2:  me.

445
00:32:56,275 --> 00:32:57,525
Speaker 14:  It's great to be here. So

446
00:32:57,685 --> 00:33:00,925
Speaker 2:  I was wondering if you could give us maybe a

447
00:33:01,195 --> 00:33:05,165
Speaker 2:  shortened version of your bio. There's a lot of interesting stuff on

448
00:33:05,165 --> 00:33:09,005
Speaker 2:  there, you know, some of which I just touched on, but then catch

449
00:33:09,005 --> 00:33:12,485
Speaker 2:  us up a little bit on what you've been doing since you've been at Adobe.

450
00:33:13,955 --> 00:33:17,765
Speaker 14:  Shortened version of the bio. Well, I seem to

451
00:33:17,795 --> 00:33:21,685
Speaker 14:  have wandered from topic to topic roughly every 10 years. Okay.

452
00:33:21,745 --> 00:33:25,605
Speaker 14:  So in the seventies, I worked on computer assisted cartoon animation

453
00:33:26,225 --> 00:33:29,765
Speaker 14:  at, at Cornell in the eighties. I worked on medical imaging

454
00:33:30,065 --> 00:33:33,725
Speaker 14:  at University of North Carolina, and then at Stanford in the

455
00:33:34,725 --> 00:33:38,205
Speaker 14:  1990s, I worked on three dimensional scanning, including the digital

456
00:33:38,205 --> 00:33:42,005
Speaker 14:  Michelangelo project. In the two thousands, I worked on light fields

457
00:33:42,105 --> 00:33:45,725
Speaker 14:  and camera arrays, built some big camera arrays at Stanford.

458
00:33:46,185 --> 00:33:49,605
Speaker 14:  And in the 2010s, largely at Google, I worked on

459
00:33:49,605 --> 00:33:53,405
Speaker 14:  computational photography, including, as you said, for the pixel

460
00:33:53,415 --> 00:33:53,765
Speaker 14:  phone.

461
00:33:54,275 --> 00:33:57,885
Speaker 2:  Yeah. You joined Adobe in 2020, is that right?

462
00:33:58,255 --> 00:34:00,405
Speaker 14:  Right, during the height of the pandemic.

463
00:34:00,825 --> 00:34:03,525
Speaker 2:  Ah, an interesting time to switch jobs. I did it too.

464
00:34:05,025 --> 00:34:06,085
Speaker 14:  Indeed. Indeed.

465
00:34:06,155 --> 00:34:09,725
Speaker 2:  Yeah. So, and you spoke to our, our editor in chief,

466
00:34:09,875 --> 00:34:13,805
Speaker 2:  Neil Patel around that time, and the

467
00:34:13,805 --> 00:34:17,205
Speaker 2:  stated goal was to create a universal camera app.

468
00:34:17,825 --> 00:34:21,685
Speaker 2:  And it's been five years since then you've released

469
00:34:22,395 --> 00:34:26,245
Speaker 2:  that camera app called Project Indigo. Can you give people the quick

470
00:34:26,525 --> 00:34:29,485
Speaker 2:  elevator pitch if they're not familiar with it? I know a lot of our audience

471
00:34:29,485 --> 00:34:29,685
Speaker 2:  is.

472
00:34:30,355 --> 00:34:33,645
Speaker 14:  Yeah. It depends how long the elevator it is. So the basic idea there

473
00:34:34,145 --> 00:34:38,085
Speaker 14:  is, there are a number of limitations of most smartphone camera apps.

474
00:34:38,385 --> 00:34:42,285
Speaker 14:  I'm certainly familiar with those limitations. There's a smartphone

475
00:34:42,675 --> 00:34:46,525
Speaker 14:  look that a lot of people don't like that might look okay on the

476
00:34:46,525 --> 00:34:49,805
Speaker 14:  small screen or in bad lighting, but don't look okay. If you look at that

477
00:34:49,805 --> 00:34:52,925
Speaker 14:  same image, large, it's very bright, it's

478
00:34:53,325 --> 00:34:57,285
Speaker 14:  contrasty. The shadows have been raised a lot. The edges are very

479
00:34:57,285 --> 00:35:00,885
Speaker 14:  sharp, the saturation is boosted. It, it's a certain look,

480
00:35:01,145 --> 00:35:04,765
Speaker 14:  as I said, it might look fine on your screen, but not if you're trying to

481
00:35:05,115 --> 00:35:08,445
Speaker 14:  make something larger out of it or even look at it on a large screen.

482
00:35:09,005 --> 00:35:12,645
Speaker 14:  Another issue with most smartphone camera apps is they don't offer much

483
00:35:12,645 --> 00:35:16,285
Speaker 14:  in the way of manual control. Some of the third party apps do, but

484
00:35:16,355 --> 00:35:20,245
Speaker 14:  then they don't offer the third thing, which is computational photography.

485
00:35:20,865 --> 00:35:24,765
Speaker 14:  So our computational photography, meaning combining multiple images to

486
00:35:24,765 --> 00:35:28,165
Speaker 14:  make a better quality image regardless of the look.

487
00:35:28,865 --> 00:35:32,765
Speaker 14:  So we wanted to combine all three of those things, a more natural

488
00:35:32,955 --> 00:35:36,685
Speaker 14:  look, full manual controls, and the best computational

489
00:35:36,850 --> 00:35:38,710
Speaker 14:  photography the state of the art allows.

490
00:35:39,315 --> 00:35:39,605
Speaker 2:  Okay.

491
00:35:39,745 --> 00:35:43,565
Speaker 14:  We also wanted to release some fun stuff on the side. So

492
00:35:43,565 --> 00:35:46,925
Speaker 14:  we have synthetic lung exposure, we have removing window

493
00:35:46,925 --> 00:35:49,965
Speaker 14:  reflections, which also ships in light room and camera raw.

494
00:35:50,265 --> 00:35:54,125
Speaker 2:  You call this look kind of HDR ish, which is

495
00:35:54,845 --> 00:35:58,805
Speaker 2:  I think a different thing from HDR as a term.

496
00:35:59,265 --> 00:36:03,085
Speaker 2:  Am I right in thinking that, do you have that same kind of sense of it? Yeah,

497
00:36:03,085 --> 00:36:03,445
Speaker 2:  yeah, yeah.

498
00:36:03,445 --> 00:36:06,965
Speaker 14:  It, it's a little bit confusing. So HDR just means that there's some way

499
00:36:06,985 --> 00:36:10,605
Speaker 14:  you can display stuff that's really bright and

500
00:36:10,985 --> 00:36:14,925
Speaker 14:  to some extent just the hardware of the, of the phones allow

501
00:36:14,925 --> 00:36:18,285
Speaker 14:  this. They are very, very bright and certainly some

502
00:36:18,435 --> 00:36:21,445
Speaker 14:  display screens, computer monitor screens are also very bright.

503
00:36:21,955 --> 00:36:25,885
Speaker 14:  They're these great ads or reviews where someone puts on a pair of sunglasses

504
00:36:25,905 --> 00:36:29,685
Speaker 14:  before they even look at their screen. So that gives the capability to

505
00:36:29,685 --> 00:36:33,565
Speaker 14:  display HDR, but the real world can

506
00:36:33,565 --> 00:36:37,285
Speaker 14:  be even brighter and not all phones can

507
00:36:37,285 --> 00:36:41,085
Speaker 14:  display HDR as being really bright. So in either one of those cases,

508
00:36:41,565 --> 00:36:45,365
Speaker 14:  a scene that's really bright or a display that's not so bright,

509
00:36:45,785 --> 00:36:49,565
Speaker 14:  you need to tone map it in a way that fits all of the dynamic

510
00:36:49,655 --> 00:36:53,565
Speaker 14:  range, meaning the range from black to white into whatever

511
00:36:53,705 --> 00:36:57,405
Speaker 14:  the display can do that usually involves lowering the

512
00:36:57,405 --> 00:37:01,045
Speaker 14:  highlights and raising the shadows. If you do too

513
00:37:01,195 --> 00:37:04,925
Speaker 14:  much of that, that's what people call the HDR ish

514
00:37:04,925 --> 00:37:05,205
Speaker 14:  look.

515
00:37:06,385 --> 00:37:09,925
Speaker 2:  Can you talk a little bit about like how we ended up here with this look?

516
00:37:11,015 --> 00:37:14,825
Speaker 14:  Well, they want the whole image to be readable and they

517
00:37:14,825 --> 00:37:18,505
Speaker 14:  want people to be able to take photographs in very challenging lighting.

518
00:37:18,965 --> 00:37:22,865
Speaker 14:  So they'll take a backlit portrait with a sunset in the background

519
00:37:22,865 --> 00:37:25,585
Speaker 14:  at the beach, but they still want to be able to see the features of the

520
00:37:25,725 --> 00:37:29,705
Speaker 14:  person who is silhouetted. That's a very high

521
00:37:29,705 --> 00:37:33,665
Speaker 14:  dynamic range situation, and they'd like to be able to share it. So

522
00:37:33,695 --> 00:37:37,505
Speaker 14:  they want it to look readable. And so they'll raise the

523
00:37:37,505 --> 00:37:40,985
Speaker 14:  shadows a lot. And that can lead to this HDR ish look.

524
00:37:41,485 --> 00:37:45,145
Speaker 14:  In particular, if you're looking at a small screen in bad lighting. So bad

525
00:37:45,305 --> 00:37:48,945
Speaker 14:  lighting might, for example, be a very bright day where there is glare

526
00:37:49,245 --> 00:37:53,225
Speaker 14:  on the phone surface. Then they want to make

527
00:37:53,225 --> 00:37:56,945
Speaker 14:  sure it's readable there too. And so they'll raise the shadows and lower

528
00:37:56,945 --> 00:38:00,705
Speaker 14:  highlights. But if you take that same image and look at it in a slightly

529
00:38:00,705 --> 00:38:04,545
Speaker 14:  darkened room or on a larger screen, then that's where it

530
00:38:04,545 --> 00:38:08,465
Speaker 14:  begins to look, as you said, grayish or too squished toward the

531
00:38:08,465 --> 00:38:08,585
Speaker 14:  middle.

532
00:38:09,205 --> 00:38:12,985
Speaker 2:  In the past few years, maybe it's been kind of brewing longer than this.

533
00:38:13,765 --> 00:38:17,745
Speaker 2:  You know, the ultra HDR format has kind of come to

534
00:38:18,385 --> 00:38:22,305
Speaker 2:  prominence, which is related and sort of in the mix here,

535
00:38:22,305 --> 00:38:26,145
Speaker 2:  but is a different thing than, than the two things we were just talking

536
00:38:26,145 --> 00:38:29,825
Speaker 2:  about. Can you explain what that is? I know you know,

537
00:38:29,895 --> 00:38:33,665
Speaker 2:  Android supports ultra HDR, apple has a version

538
00:38:33,735 --> 00:38:36,405
Speaker 2:  they support just what is this at the basics?

539
00:38:36,625 --> 00:38:40,605
Speaker 14:  So both of those are closely related to, and we're

540
00:38:40,685 --> 00:38:44,485
Speaker 14:  co-developed with Adobe's format for

541
00:38:45,125 --> 00:38:48,205
Speaker 14:  representing hydrodynamic range images. As a matter of fact,

542
00:38:48,635 --> 00:38:52,045
Speaker 14:  Apple's, Paul Huble and Adobe's, Eric Chan

543
00:38:52,275 --> 00:38:56,245
Speaker 14:  presented the format together at a conference. Okay. So it's really

544
00:38:56,285 --> 00:39:00,045
Speaker 14:  a co-development. Ultra HDR is just a brand name. The

545
00:39:00,045 --> 00:39:03,605
Speaker 14:  basic idea is that a file ought to contain

546
00:39:04,145 --> 00:39:08,085
Speaker 14:  two images, a base image, which is what

547
00:39:08,085 --> 00:39:11,285
Speaker 14:  you would display if you only had a standard dynamic range display.

548
00:39:12,345 --> 00:39:15,725
Speaker 14:  In other words, not a super bright display, SDR

549
00:39:16,265 --> 00:39:20,205
Speaker 14:  for short. And a separate image, which is what's often called

550
00:39:20,325 --> 00:39:23,805
Speaker 14:  a gain map. Meaning how much would I add to that

551
00:39:24,345 --> 00:39:28,325
Speaker 14:  if I had a brighter display? And that's the, the highlights part of it.

552
00:39:29,145 --> 00:39:32,165
Speaker 14:  Now it's a little bit more complicated than that. It can be done as either

553
00:39:32,185 --> 00:39:35,205
Speaker 14:  an addition or a subtraction. But that's kind of the basic idea that there

554
00:39:35,205 --> 00:39:38,925
Speaker 14:  are these two images and if you have an HDR display, then the

555
00:39:38,955 --> 00:39:42,605
Speaker 14:  idea is that the viewer, meaning, for example, the browser software

556
00:39:42,895 --> 00:39:46,605
Speaker 14:  would add the two together and then display that. So that's what all of

557
00:39:46,605 --> 00:39:50,045
Speaker 14:  these HDR formats have. There are other

558
00:39:50,625 --> 00:39:54,605
Speaker 14:  HDR formats, A VV has one, but the world seems to be

559
00:39:54,605 --> 00:39:58,405
Speaker 14:  moving gradually toward either the ultra HDR or Apple's H

560
00:39:58,405 --> 00:40:02,205
Speaker 14:  format or ours, which is this JPEG

561
00:40:02,205 --> 00:40:06,165
Speaker 14:  that has a base image, which is SDR and A base plus

562
00:40:06,315 --> 00:40:09,085
Speaker 14:  gain a gain map, which gives you HDR.

563
00:40:09,545 --> 00:40:12,685
Speaker 2:  Why does this one seem to be the one we're landing on? And

564
00:40:13,355 --> 00:40:17,205
Speaker 2:  does it solve our problems with HDR and HDR

565
00:40:17,205 --> 00:40:19,765
Speaker 2:  displays and HDR ish photos?

566
00:40:21,395 --> 00:40:24,325
Speaker 14:  It's arguably better than the other ones because it really kind of separates

567
00:40:24,325 --> 00:40:28,125
Speaker 14:  out, here's what you would see if you had it only at SDR display and here's

568
00:40:28,125 --> 00:40:32,005
Speaker 14:  what you would see if you had an HDR display. And it also means that

569
00:40:32,585 --> 00:40:36,565
Speaker 14:  in image editors like Lightroom, you could separately

570
00:40:36,715 --> 00:40:40,685
Speaker 14:  tune the two looks. Mm. Because you might want a different crushing

571
00:40:40,685 --> 00:40:44,205
Speaker 14:  of shadows or lowering of highlights for standard dynamic range

572
00:40:44,235 --> 00:40:48,165
Speaker 14:  display and for hydrodynamic range display. Or you might

573
00:40:48,235 --> 00:40:52,205
Speaker 14:  just want an SDR image and you never want the highlights to be bright. And

574
00:40:52,205 --> 00:40:56,165
Speaker 14:  so in Lightroom, again, you could toggle off the HDR

575
00:40:56,745 --> 00:41:00,565
Speaker 14:  and just sit there and adjust for SDR. So it's a good

576
00:41:00,565 --> 00:41:03,805
Speaker 14:  format. I don't know if it's the best ever, but it's a good format.

577
00:41:04,485 --> 00:41:07,485
Speaker 14:  And it's nice to see that it's being gradually adopted.

578
00:41:08,235 --> 00:41:12,125
Speaker 14:  Gradually of course is very gradually in this fragmented world

579
00:41:12,125 --> 00:41:15,725
Speaker 14:  of ours. So social media apps are only slowly

580
00:41:15,745 --> 00:41:17,925
Speaker 14:  coming on board with this format.

581
00:41:18,875 --> 00:41:22,725
Speaker 2:  Yeah. There's so many components to it. There's the, you know,

582
00:41:22,745 --> 00:41:26,605
Speaker 2:  the camera, there's the display on the camera, there's where

583
00:41:26,665 --> 00:41:30,565
Speaker 2:  the photo eventually ends up the display of the person who's

584
00:41:30,565 --> 00:41:34,085
Speaker 2:  looking at that photo on Instagram. And I think

585
00:41:34,715 --> 00:41:38,645
Speaker 2:  something I've seen in me, I, you can let me know if, if you've seen

586
00:41:38,645 --> 00:41:41,845
Speaker 2:  this too or not, but I'm seeing kind of an

587
00:41:41,995 --> 00:41:45,525
Speaker 2:  association from photography kind of like

588
00:41:45,525 --> 00:41:49,485
Speaker 2:  literate people where they, they have just gotten a bad taste in

589
00:41:49,485 --> 00:41:53,445
Speaker 2:  their mouth with HDR and they sort of say HDR

590
00:41:53,445 --> 00:41:57,085
Speaker 2:  is a be like a dirty word. I'm trying to

591
00:41:57,175 --> 00:42:00,925
Speaker 2:  evangelize the ultra HDR a little bit. You know, like this is a different

592
00:42:00,925 --> 00:42:04,045
Speaker 2:  thing. Do you see that conflation happening?

593
00:42:05,205 --> 00:42:08,605
Speaker 14:  Absolutely. I think you're, you're right. But what they're conflating is

594
00:42:08,605 --> 00:42:12,405
Speaker 14:  the ability to display HDR and the particular

595
00:42:13,155 --> 00:42:16,645
Speaker 14:  tone mapping and look that has been used on

596
00:42:17,145 --> 00:42:20,965
Speaker 14:  HDR capable photographs. And that's this overtone mapped

597
00:42:21,015 --> 00:42:24,845
Speaker 14:  thing. And so I think it's possible to display HDR

598
00:42:24,845 --> 00:42:27,525
Speaker 14:  images in a way that doesn't have this look.

599
00:42:29,005 --> 00:42:32,965
Speaker 14:  Interestingly, it's also possible to overdo the look on purpose in a way

600
00:42:32,965 --> 00:42:36,605
Speaker 14:  that's actually artistic. And one person I think of

601
00:42:36,735 --> 00:42:40,285
Speaker 14:  there is Trey Ratcliffe and stuck in customs. He's got this

602
00:42:40,415 --> 00:42:44,365
Speaker 14:  great image, one of his signature images of the landscaper

603
00:42:44,365 --> 00:42:48,325
Speaker 14:  on Guin in China that is ultra wide ankle

604
00:42:48,745 --> 00:42:52,685
Speaker 14:  and very overtone mapped on purpose and made saturated

605
00:42:52,825 --> 00:42:56,645
Speaker 14:  in a way that makes it look like a fairytale landscape. So that's

606
00:42:56,645 --> 00:43:00,565
Speaker 14:  art, right? It's obviously not the way it looked, but everyone

607
00:43:00,565 --> 00:43:03,765
Speaker 14:  knows that when they look at it. So I'm separating out this art

608
00:43:04,315 --> 00:43:07,765
Speaker 14:  from it. But for ordinary photography, I think you're right.

609
00:43:08,385 --> 00:43:11,165
Speaker 14:  But the answer is that it's, it's in the tone mapping. Yeah. There's nothing

610
00:43:11,165 --> 00:43:13,525
Speaker 14:  inherently wrong with the HDR capability.

611
00:43:14,155 --> 00:43:18,085
Speaker 2:  Okay. Well I'm telling everyone that Mark LaVoy says I'm right and

612
00:43:18,085 --> 00:43:19,565
Speaker 2:  I'll, I'll take that to my grave.

613
00:43:19,865 --> 00:43:23,485
Speaker 14:  You know, the, the one funny thing about this is there were videos made

614
00:43:23,485 --> 00:43:27,405
Speaker 14:  while I was at Google about, oh, the look of pixel phones is learning from

615
00:43:27,405 --> 00:43:30,885
Speaker 14:  Italian art. Hmm. And I talked about my preference for

616
00:43:30,935 --> 00:43:34,725
Speaker 14:  Caravaggio and so on and so on. Well, those are all standard

617
00:43:34,725 --> 00:43:38,525
Speaker 14:  dynamic range images. They're just reflective, they're not luminous.

618
00:43:38,635 --> 00:43:42,125
Speaker 14:  They can't do anything brighter than the white of the gallery wall.

619
00:43:43,065 --> 00:43:46,725
Speaker 14:  And so we sort of do need different models

620
00:43:46,865 --> 00:43:50,765
Speaker 14:  and artistic models and a different artistic exploration as

621
00:43:50,765 --> 00:43:54,405
Speaker 14:  we start to do hydrodynamic range. And I think the world is still

622
00:43:54,635 --> 00:43:57,165
Speaker 14:  experimenting Yeah. With what it ought to look like.

623
00:43:57,915 --> 00:44:01,765
Speaker 2:  Yeah. How far is too far? What do, what do we all like

624
00:44:02,145 --> 00:44:05,845
Speaker 2:  and dislike? Yeah. Right. How did you think about that going

625
00:44:05,995 --> 00:44:09,885
Speaker 2:  into developing your camera app? You know, I've used the app

626
00:44:09,885 --> 00:44:13,645
Speaker 2:  certainly quite a bit. I know a lot of our readers have, but the

627
00:44:13,645 --> 00:44:16,605
Speaker 2:  kinds of things that people can expect maybe as far as

628
00:44:17,425 --> 00:44:20,605
Speaker 2:  HDR processing when they use Project Indigo.

629
00:44:21,255 --> 00:44:25,005
Speaker 14:  Right. So I led a team of people

630
00:44:25,105 --> 00:44:29,085
Speaker 14:  who determined the taste for the early pixel cameras. I, I

631
00:44:29,085 --> 00:44:32,165
Speaker 14:  don't know if I would go so far as to say I was the taste, but I was one

632
00:44:32,165 --> 00:44:36,045
Speaker 14:  of them here at Adobe. I've let Florian kinds

633
00:44:36,045 --> 00:44:40,005
Speaker 14:  who co-wrote the blog with me be the lead tastemaker. And

634
00:44:40,185 --> 00:44:43,925
Speaker 14:  you can see his taste in, in all the photographs that are on the blog.

635
00:44:44,475 --> 00:44:48,405
Speaker 14:  They look natural. They look like, oh, if I were there, I know what

636
00:44:48,405 --> 00:44:52,245
Speaker 14:  I would've seen. They don't look like there's been some deliberate adjustment

637
00:44:52,245 --> 00:44:56,125
Speaker 14:  in tone mapping. They look like if I had an SLR with

638
00:44:56,125 --> 00:44:59,445
Speaker 14:  enough dynamic range, mm. That might've been what the picture looked like.

639
00:45:00,265 --> 00:45:03,845
Speaker 14:  And so one of the characteristics is let dark

640
00:45:03,875 --> 00:45:07,325
Speaker 14:  shadows be dark. Hmm. Amen. And I think a lot of

641
00:45:07,845 --> 00:45:08,805
Speaker 14:  people just like that.

642
00:45:09,835 --> 00:45:10,845
Speaker 2:  Yeah, I know I do.

643
00:45:11,915 --> 00:45:15,725
Speaker 14:  There's, to be honest, we've kind of fell into this moment

644
00:45:16,105 --> 00:45:19,965
Speaker 14:  of a trend toward retro and toward film looks,

645
00:45:20,175 --> 00:45:24,165
Speaker 14:  which are more natural looks because there's no adjustable

646
00:45:24,315 --> 00:45:28,205
Speaker 14:  tone mapping or there's very, there are fewer ways of doing adjustable tone

647
00:45:28,205 --> 00:45:32,125
Speaker 14:  mapping in film and people like that. And they sort

648
00:45:32,125 --> 00:45:36,045
Speaker 14:  of hea asiah of relief like, okay, you know, that looks like a

649
00:45:36,045 --> 00:45:39,965
Speaker 14:  plausible scene and the darks are dark and we

650
00:45:39,965 --> 00:45:43,765
Speaker 14:  like dark because it's the et cetera principle. You know,

651
00:45:43,765 --> 00:45:47,485
Speaker 14:  what's the mystery in that dark area there? And

652
00:45:48,325 --> 00:45:52,245
Speaker 14:  I like that and Florian likes that. So that's kind of what

653
00:45:52,245 --> 00:45:56,165
Speaker 14:  we allowed to happen on on Indigo. Yeah. I should point out though,

654
00:45:56,165 --> 00:46:00,085
Speaker 14:  that it's a profile, if you load it into a Lightroom or camera

655
00:46:00,225 --> 00:46:04,045
Speaker 14:  raw, it shows up, says Indigo, and you

656
00:46:04,125 --> 00:46:07,885
Speaker 14:  can change it. In particular, if you've been capturing dgs,

657
00:46:07,885 --> 00:46:11,725
Speaker 14:  which means raw images, you can change it to any profile you want.

658
00:46:11,985 --> 00:46:15,845
Speaker 14:  You can add presets to it, you can make your own look. So it's not

659
00:46:15,845 --> 00:46:19,565
Speaker 14:  like we're demanding that this is the look that you would produce

660
00:46:19,595 --> 00:46:22,805
Speaker 14:  with that app. It's our suggested look, but you can change it.

661
00:46:23,075 --> 00:46:27,005
Speaker 2:  Yeah. And kind of along the same lines, I wonder if you can talk about

662
00:46:27,005 --> 00:46:30,885
Speaker 2:  the raw capabilities. I am someone who kind of

663
00:46:31,285 --> 00:46:35,085
Speaker 2:  poo-poos shooting raw on a smartphone. I am tend to wanna

664
00:46:35,145 --> 00:46:38,845
Speaker 2:  let, let it just do its thing. And that might be maybe, maybe

665
00:46:39,045 --> 00:46:42,445
Speaker 2:  a older way of thinking about smartphone photography,

666
00:46:43,015 --> 00:46:46,885
Speaker 2:  especially with Computational Raw, which you've brought into

667
00:46:46,885 --> 00:46:50,725
Speaker 2:  Project Indigo. Could you explain quickly what that is and

668
00:46:51,025 --> 00:46:52,765
Speaker 2:  why that was important to have?

669
00:46:53,375 --> 00:46:56,925
Speaker 14:  Right. So if you do JPEG only with Indigo,

670
00:46:57,265 --> 00:47:00,605
Speaker 14:  you'll get our look. If you bring it into

671
00:47:01,065 --> 00:47:04,925
Speaker 14:  an image editor, a Lightroom or any other editor, you can make

672
00:47:05,415 --> 00:47:08,885
Speaker 14:  minor tweaks on it, but you can't do anything really major

673
00:47:09,355 --> 00:47:12,485
Speaker 14:  because the characteristic of any of these tone mapping methods

674
00:47:13,145 --> 00:47:17,085
Speaker 14:  is that the highlights in one part of the image

675
00:47:17,415 --> 00:47:21,205
Speaker 14:  might be the same pixel value as the shadows in another part of the

676
00:47:21,205 --> 00:47:25,165
Speaker 14:  image. And So if you use sliders or tone curves

677
00:47:25,165 --> 00:47:28,925
Speaker 14:  or anything to raise one or lower one, you might

678
00:47:29,005 --> 00:47:32,885
Speaker 14:  raise or lower other things you didn't want to lower or raise. Even though

679
00:47:32,885 --> 00:47:36,525
Speaker 14:  they were actually different brightnesses in the original scene, they got

680
00:47:36,525 --> 00:47:40,205
Speaker 14:  tone mapped to be the same pixel value. So this is

681
00:47:40,665 --> 00:47:44,125
Speaker 14:  the main reason why people like shooting raw, because the,

682
00:47:44,825 --> 00:47:48,565
Speaker 14:  the numbers that are in the file represent relative

683
00:47:48,695 --> 00:47:51,925
Speaker 14:  scene brightnesses just as sensed.

684
00:47:52,505 --> 00:47:56,245
Speaker 14:  And then you can keep the shadows separate from the highlights if you wanted

685
00:47:56,305 --> 00:47:59,645
Speaker 14:  to. So that's the main reason for shooting raw. Now

686
00:48:00,185 --> 00:48:03,645
Speaker 14:  you say you don't really like or have not really shot raw on

687
00:48:03,715 --> 00:48:07,485
Speaker 14:  smartphones. So the reason for that is that the raws

688
00:48:07,485 --> 00:48:11,005
Speaker 14:  have not been very good. They both don't come with a very good look.

689
00:48:11,505 --> 00:48:15,365
Speaker 14:  And they often don't come with computational photography or enough

690
00:48:15,365 --> 00:48:18,965
Speaker 14:  computational photography. So in low light they look noisy

691
00:48:19,865 --> 00:48:23,605
Speaker 14:  on some phones, which I won't name. If you switched into raw

692
00:48:23,605 --> 00:48:27,405
Speaker 14:  mode, it would take a single frame and end up

693
00:48:27,405 --> 00:48:30,325
Speaker 14:  being very noisy because the smartphone sensors are small.

694
00:48:31,385 --> 00:48:34,845
Speaker 14:  So the right thing is do this computational

695
00:48:34,845 --> 00:48:38,205
Speaker 14:  photography where you align and combine multiple frames

696
00:48:38,755 --> 00:48:42,725
Speaker 14:  even to produce the raw. Now some purists would say,

697
00:48:42,725 --> 00:48:46,605
Speaker 14:  well that's not raw anymore because it was captured over a number of frames.

698
00:48:46,825 --> 00:48:50,725
Speaker 14:  That's true. But it still has the major characteristic of

699
00:48:50,785 --> 00:48:54,565
Speaker 14:  raw that it's proportional to seen brightness. And you can do any

700
00:48:54,565 --> 00:48:57,485
Speaker 14:  editing you want without worrying that you're adjusting both shadows and

701
00:48:57,485 --> 00:48:58,205
Speaker 14:  highlights at the same time.

702
00:48:59,295 --> 00:48:59,585
Speaker 2:  Yeah.

703
00:48:59,685 --> 00:49:03,465
Speaker 14:  So I do recommend that you try raw in

704
00:49:03,565 --> 00:49:04,865
Speaker 14:  Indigo. I think you'll like it.

705
00:49:05,175 --> 00:49:08,665
Speaker 2:  Yeah. Yeah. And I have made an exception for Indigo, definitely.

706
00:49:09,105 --> 00:49:13,025
Speaker 2:  Just, just knowing I'm not throwing away a bunch of extra frames and extra

707
00:49:13,025 --> 00:49:16,825
Speaker 2:  data. Yeah. It's been a totally different experience shooting with the phone.

708
00:49:17,105 --> 00:49:20,785
Speaker 2:  I, I use the phone cameras on every major

709
00:49:20,785 --> 00:49:24,745
Speaker 2:  phone, you know, released in this country. And this app

710
00:49:24,745 --> 00:49:28,105
Speaker 2:  really made me think about it differently. So one

711
00:49:28,105 --> 00:49:31,265
Speaker 14:  Characteristic, I mean, there, there are trade-offs, you know, why didn't

712
00:49:31,385 --> 00:49:34,905
Speaker 14:  everyone else do the same thing we did? Well, we're capturing more frames.

713
00:49:35,405 --> 00:49:38,905
Speaker 14:  It takes longer to put them together. You have to be a bit more patient

714
00:49:39,175 --> 00:49:42,865
Speaker 14:  between shots, particularly in low light. So there are

715
00:49:42,865 --> 00:49:46,185
Speaker 14:  trade-offs to be made. Yeah. And we made a particular trade off

716
00:49:46,505 --> 00:49:50,345
Speaker 14:  favoring the more serious photographer, the one who cared more

717
00:49:50,345 --> 00:49:53,065
Speaker 14:  about image quality and adjustment after the fact.

718
00:49:54,385 --> 00:49:57,985
Speaker 2:  I think someone who really wants to get into the nuts and bolts of

719
00:49:58,095 --> 00:50:02,065
Speaker 2:  photography, it sort of speaks that love language where just

720
00:50:02,065 --> 00:50:05,825
Speaker 2:  right from the onboarding screens, you know, you, you

721
00:50:05,955 --> 00:50:09,745
Speaker 2:  learn a lot about what the camera's doing and how things

722
00:50:09,745 --> 00:50:13,665
Speaker 2:  will be processed. And with your background as a a

723
00:50:13,665 --> 00:50:17,505
Speaker 2:  teacher, I wonder how that, did this feel like a

724
00:50:17,505 --> 00:50:21,185
Speaker 2:  natural kind of fit? Did you find as you were developing this app, you

725
00:50:21,605 --> 00:50:24,825
Speaker 2:  you were sort of bringing that part of your background along too?

726
00:50:25,495 --> 00:50:29,325
Speaker 14:  Yeah, I love teaching. Maybe I sometimes talk too much,

727
00:50:29,805 --> 00:50:33,605
Speaker 14:  but I want people to understand. And so the last course

728
00:50:33,765 --> 00:50:37,325
Speaker 14:  I taught before I left Stanford first for Google and then for Adobe

729
00:50:37,705 --> 00:50:41,605
Speaker 14:  was a course on digital photography. And I would teach both the art

730
00:50:41,745 --> 00:50:45,165
Speaker 14:  and the science. You know, why do we want to combine images?

731
00:50:45,775 --> 00:50:49,725
Speaker 14:  Where does this noise come from? What are aberrations on

732
00:50:49,725 --> 00:50:53,565
Speaker 14:  lenses and things like that. And so that kind

733
00:50:53,565 --> 00:50:57,485
Speaker 14:  of spilled over onto the explanations that I made both in the blog and

734
00:50:57,485 --> 00:51:00,685
Speaker 14:  on the opening screens in Indigo. I want people to understand,

735
00:51:02,345 --> 00:51:06,245
Speaker 2:  How do you think about that? Maybe line is the wrong word, like a

736
00:51:06,245 --> 00:51:10,005
Speaker 2:  line between the art and the science. I think in photography

737
00:51:10,015 --> 00:51:13,805
Speaker 2:  especially, people can get kind of, they'll wanna

738
00:51:13,805 --> 00:51:17,405
Speaker 2:  dive into one or the other and they'll see, you know, they wanna know everything

739
00:51:17,405 --> 00:51:21,285
Speaker 2:  about how the, the camera's working and they get into the, the nuts and

740
00:51:21,285 --> 00:51:25,085
Speaker 2:  bolts or they don't wanna get into all that and they feel like

741
00:51:25,085 --> 00:51:29,045
Speaker 2:  it detracts from enjoying the art. How do you see that?

742
00:51:29,145 --> 00:51:32,965
Speaker 2:  Are those two opposing things? Can you exist

743
00:51:33,025 --> 00:51:34,645
Speaker 2:  in two different states at once?

744
00:51:36,325 --> 00:51:40,205
Speaker 14:  I don't consider them opposing at all. I do understand tastes that some

745
00:51:40,205 --> 00:51:43,485
Speaker 14:  people are just nerds about the science and some people are nerds about

746
00:51:43,485 --> 00:51:47,445
Speaker 14:  the art. One of my heroes is Ansel Adams.

747
00:51:47,845 --> 00:51:51,605
Speaker 14:  Hmm. So Ansel Adams, first of all was a teacher in addition to being a great

748
00:51:51,605 --> 00:51:55,405
Speaker 14:  artist, but he also embraced both the art and the

749
00:51:55,405 --> 00:51:58,805
Speaker 14:  science of photography. He wrote three amazing books,

750
00:51:59,785 --> 00:52:03,685
Speaker 14:  the camera, the Negative, and the print, which are quite

751
00:52:03,775 --> 00:52:07,565
Speaker 14:  scientific and full of careful illustrations of how

752
00:52:07,565 --> 00:52:11,365
Speaker 14:  perspective works and the zone system for exposure and so

753
00:52:11,385 --> 00:52:15,365
Speaker 14:  on. I had a chance once to ask one of his assistants, his longtime

754
00:52:15,365 --> 00:52:18,845
Speaker 14:  assistants, would he have embraced digital photography?

755
00:52:19,285 --> 00:52:23,245
Speaker 14:  Hmm. He did have a chance to test a very early digital camera, but would

756
00:52:23,245 --> 00:52:26,925
Speaker 14:  have, he, would he have embraced it for his photography? And without a moment's

757
00:52:26,925 --> 00:52:30,885
Speaker 14:  hesitation, the the assistant said, of course he would've. Hmm.

758
00:52:30,915 --> 00:52:33,085
Speaker 14:  Just look at his work and his books.

759
00:52:33,635 --> 00:52:37,405
Speaker 2:  Yeah, it, it makes sense. And I think a lot of photography

760
00:52:37,405 --> 00:52:41,205
Speaker 2:  conversations go back to Ansel Adams sort of inevitably when you

761
00:52:41,205 --> 00:52:44,965
Speaker 2:  talk about processing Photoshop, you know,

762
00:52:45,975 --> 00:52:49,485
Speaker 2:  maybe even the moment we're in right now with generative ai,

763
00:52:49,655 --> 00:52:52,925
Speaker 2:  there, you, you kind of can trace back to like,

764
00:52:53,675 --> 00:52:57,605
Speaker 2:  when we think of photography as this, you know, you're

765
00:52:57,605 --> 00:53:01,565
Speaker 2:  just, it's just photons hitting a piece of film or a sensor.

766
00:53:02,145 --> 00:53:05,845
Speaker 2:  But the way Ansel Adams, you know, manipulated images and

767
00:53:06,185 --> 00:53:10,165
Speaker 2:  the things he did in the dark room, people are maybe not aware

768
00:53:10,165 --> 00:53:10,325
Speaker 2:  of.

769
00:53:10,715 --> 00:53:14,445
Speaker 14:  Exactly. And not only that, so, so first of all, you're exactly right about

770
00:53:14,445 --> 00:53:18,165
Speaker 14:  the manipulations in the dark room. His dodging and burning, which

771
00:53:18,275 --> 00:53:22,245
Speaker 14:  many photographers know about is local tone mapping. It's the same as this

772
00:53:22,835 --> 00:53:26,285
Speaker 14:  raising the shadows in one part of the image and lowering the highlights

773
00:53:26,385 --> 00:53:29,285
Speaker 14:  in another part of the image, but maybe not in all parts of the image that's

774
00:53:29,285 --> 00:53:33,085
Speaker 14:  just dodging and burning. But more than that, he was open

775
00:53:33,085 --> 00:53:36,845
Speaker 14:  about it and taught about it. He has one great book that is

776
00:53:36,945 --> 00:53:40,565
Speaker 14:  the making of 40 photographs I think it's called. And he shows the

777
00:53:40,805 --> 00:53:44,725
Speaker 14:  original and the version after he has fiddled with it

778
00:53:44,725 --> 00:53:48,685
Speaker 14:  in the darkroom or interpret it in the darkroom. In fact, one of

779
00:53:48,685 --> 00:53:51,925
Speaker 14:  his most famous pictures, the Clearing winter storm in Yosemite is a great

780
00:53:51,925 --> 00:53:55,245
Speaker 14:  example that I used to show in my photography course at Stanford

781
00:53:55,985 --> 00:53:59,885
Speaker 14:  of the original, which is surprisingly, I wouldn't say

782
00:54:00,175 --> 00:54:03,925
Speaker 14:  bland, but fairly even toned and

783
00:54:04,145 --> 00:54:07,965
Speaker 14:  not nearly as exciting as his version after dodging and burning. Yeah.

784
00:54:08,065 --> 00:54:09,725
Speaker 14:  And he would explain what he did and why

785
00:54:10,235 --> 00:54:14,165
Speaker 2:  It's such a joy to hear someone who is so immersed

786
00:54:14,225 --> 00:54:17,885
Speaker 2:  in what they do and has such a love for it and the, the

787
00:54:17,885 --> 00:54:21,805
Speaker 2:  technical mastery I think so, yeah, I definitely

788
00:54:21,805 --> 00:54:25,405
Speaker 2:  need to to check more of that out. I have some other questions

789
00:54:25,575 --> 00:54:29,045
Speaker 2:  about Project Indigo before we stray too far into

790
00:54:29,855 --> 00:54:33,685
Speaker 2:  philosophy of photography and art. I'm wondering

791
00:54:33,875 --> 00:54:36,885
Speaker 2:  your thoughts on generative AI

792
00:54:37,705 --> 00:54:41,605
Speaker 2:  and particularly it's on my mind because I've just been

793
00:54:41,605 --> 00:54:45,245
Speaker 2:  using the Pixel 10 Pro and there is

794
00:54:46,045 --> 00:54:50,005
Speaker 2:  a Zoom feature on the camera that instead of using

795
00:54:50,675 --> 00:54:54,005
Speaker 2:  just digital Zoom, which is has a lot of limitations,

796
00:54:54,455 --> 00:54:58,085
Speaker 2:  takes your image in, uses a diffusion

797
00:54:58,575 --> 00:55:01,925
Speaker 2:  generative AI model to kind of fill in the gaps. And

798
00:55:02,385 --> 00:55:06,005
Speaker 2:  as your former colleague Isaac Reynolds said, squash the artifacts.

799
00:55:06,745 --> 00:55:10,605
Speaker 2:  So that's sort of out there now, is

800
00:55:10,605 --> 00:55:13,965
Speaker 2:  that something you would consider bringing into Project Indigo?

801
00:55:15,685 --> 00:55:19,405
Speaker 14:  A lot to unpack there? Yeah, it really is. So first of all, in general,

802
00:55:19,735 --> 00:55:23,445
Speaker 14:  generative AI definitely has a place in the future

803
00:55:23,585 --> 00:55:27,285
Speaker 14:  of art, the future of photography. The Gen Remove

804
00:55:27,285 --> 00:55:31,165
Speaker 14:  feature in Lightroom is generative ai And I use it

805
00:55:31,165 --> 00:55:34,805
Speaker 14:  to remove tractors in many of my personal

806
00:55:34,805 --> 00:55:38,525
Speaker 14:  photographs. It's very useful, of course it can be used to make

807
00:55:38,965 --> 00:55:42,485
Speaker 14:  entirely new stuff and there's a place for that as well. So

808
00:55:43,505 --> 00:55:47,125
Speaker 14:  as far as digital zooming goes, I don't wanna talk

809
00:55:47,405 --> 00:55:51,205
Speaker 14:  specifically about Pixel, but there are other smartphone vendors

810
00:55:51,705 --> 00:55:55,645
Speaker 14:  who have explored extreme zooming like

811
00:55:55,645 --> 00:55:59,605
Speaker 14:  that. Any smartphone that does say 100 x is of course

812
00:55:59,775 --> 00:56:03,605
Speaker 14:  using digital zooming of one, digital scaling of one

813
00:56:03,605 --> 00:56:07,405
Speaker 14:  kind or another. So maybe I can answer it by giving

814
00:56:07,525 --> 00:56:11,045
Speaker 14:  a general way to think about this. If they are

815
00:56:11,685 --> 00:56:15,485
Speaker 14:  claiming 10 x zoom over the, over what the lens

816
00:56:15,505 --> 00:56:19,485
Speaker 14:  can do or 20 x over what the lens can do. If it

817
00:56:19,625 --> 00:56:23,565
Speaker 14:  is a native resolution, that's a five x lens. But let's take the

818
00:56:23,625 --> 00:56:27,525
Speaker 14:  the 10 X case then The way to think about it is every

819
00:56:27,855 --> 00:56:31,565
Speaker 14:  10th pixel horizontally and vertically is real,

820
00:56:32,775 --> 00:56:36,405
Speaker 14:  which means that considering both horizontal and vertical,

821
00:56:37,025 --> 00:56:40,695
Speaker 14:  one out of 100 pixels is real, the other

822
00:56:40,995 --> 00:56:44,975
Speaker 14:  99 have to be made up. Now

823
00:56:45,355 --> 00:56:49,255
Speaker 14:  how do you make up pixels? You could just interpolate

824
00:56:49,455 --> 00:56:53,335
Speaker 14:  smoothly and make a blurry image. You could try to

825
00:56:53,365 --> 00:56:57,175
Speaker 14:  sharpen edges. Now why would you sharpen edges? Because

826
00:56:57,515 --> 00:57:01,495
Speaker 14:  you have some prior knowledge that the world is composed of

827
00:57:01,675 --> 00:57:05,135
Speaker 14:  mostly smooth areas and sharp edges. That's

828
00:57:05,345 --> 00:57:09,255
Speaker 14:  prior knowledge. That's a buzzword in artificial intelligence.

829
00:57:09,755 --> 00:57:13,415
Speaker 14:  If you have a large training set, you have more prior knowledge

830
00:57:13,525 --> 00:57:17,215
Speaker 14:  Sure. About the world. And these diffusion models have a lot

831
00:57:17,635 --> 00:57:21,015
Speaker 14:  of training data and therefore a lot of prior knowledge.

832
00:57:21,555 --> 00:57:25,295
Speaker 14:  So they'll look at every 10th pixel or every hundredth pixel

833
00:57:25,475 --> 00:57:29,375
Speaker 14:  in area and say, oh, that looks like a building.

834
00:57:29,855 --> 00:57:33,615
Speaker 14:  Buildings have windows. The windows have sharp edges. I

835
00:57:33,765 --> 00:57:37,455
Speaker 14:  will sharpen all that up and make it stucco facade

836
00:57:37,595 --> 00:57:41,495
Speaker 14:  and then a dark window. And so they're clearly making stuff

837
00:57:41,515 --> 00:57:45,415
Speaker 14:  up. When you're using a generative ai, I think all of the

838
00:57:45,415 --> 00:57:48,615
Speaker 14:  smartphone vendors will admit that they're making stuff up. The question

839
00:57:48,615 --> 00:57:52,535
Speaker 14:  is, is it useful? What are you doing with

840
00:57:52,535 --> 00:57:56,335
Speaker 14:  the image? And that determines whether it's okay to do that kind of

841
00:57:56,335 --> 00:58:00,055
Speaker 14:  stuff. One thing I will say more about Pixel is

842
00:58:00,085 --> 00:58:01,535
Speaker 14:  they do say they're not doing it for people.

843
00:58:02,015 --> 00:58:02,495
Speaker 2:  Correct.

844
00:58:02,755 --> 00:58:06,695
Speaker 14:  And that is an admission that it does matter what the gen AI is

845
00:58:06,695 --> 00:58:10,575
Speaker 14:  used for. But getting back to the general argument, it's

846
00:58:10,755 --> 00:58:14,655
Speaker 14:  useful for some things and not useful or even a misleading for other

847
00:58:14,655 --> 00:58:18,615
Speaker 14:  things. And so I think that'll be the discussion that everyone has

848
00:58:18,665 --> 00:58:22,575
Speaker 14:  going forward about the use of gen AI and digital scaling is what's it being

849
00:58:22,575 --> 00:58:26,375
Speaker 14:  used for and does it work or does it make up stuff that's

850
00:58:26,375 --> 00:58:27,135
Speaker 14:  objectionable?

851
00:58:27,865 --> 00:58:31,635
Speaker 2:  Yeah, I think there's maybe a, a parallel to the, the moment

852
00:58:31,645 --> 00:58:35,275
Speaker 2:  we're in with AI generally, and, And I, my

853
00:58:35,275 --> 00:58:38,635
Speaker 2:  framework is what is the features on the phone

854
00:58:38,855 --> 00:58:42,635
Speaker 2:  mostly. And there's sort of a, a rush to have a bunch of

855
00:58:42,895 --> 00:58:46,275
Speaker 2:  AI stuff and sort of flashy, but not that useful.

856
00:58:46,775 --> 00:58:50,755
Speaker 2:  And I, I think, I hope we're getting to a place with it where we can

857
00:58:51,325 --> 00:58:55,275
Speaker 2:  think of it more as a tool that is just sort of there when we need

858
00:58:55,275 --> 00:58:59,195
Speaker 2:  it and is helpful and then we don't think about it when we,

859
00:58:59,345 --> 00:59:02,435
Speaker 2:  when we don't need it. Yeah. It it sounds like that's kind of what you're,

860
00:59:02,625 --> 00:59:03,595
Speaker 2:  what you're hinting into.

861
00:59:03,595 --> 00:59:06,715
Speaker 14:  Right. And let me make one further distinction. There's AI and there's gen

862
00:59:06,855 --> 00:59:10,595
Speaker 14:  ai. Now those terms are kind of fuzzy themselves,

863
00:59:11,375 --> 00:59:14,715
Speaker 14:  but when we think of text to image or text to video, everyone thinks of

864
00:59:14,755 --> 00:59:18,595
Speaker 14:  a certain kind of gen ai and let's use that definition. But AI

865
00:59:18,595 --> 00:59:22,335
Speaker 14:  is much more general than that. AI can just help you answer any

866
00:59:22,575 --> 00:59:26,055
Speaker 14:  question where you might benefit from prior knowledge. So

867
00:59:26,835 --> 00:59:30,575
Speaker 14:  the 10 x multi frame super resolution

868
00:59:30,925 --> 00:59:34,775
Speaker 14:  that Indigo has is using an ai, it's not using

869
00:59:34,775 --> 00:59:38,375
Speaker 14:  an AI to propose what the pixels ought to be, but to help

870
00:59:38,665 --> 00:59:42,375
Speaker 14:  align the multiple frames, the multiple frames all look a little bit different

871
00:59:42,375 --> 00:59:45,855
Speaker 14:  because when you hold your phone, you naturally shake a little bit, and

872
00:59:45,855 --> 00:59:49,775
Speaker 14:  so it gets different views of the world and that actually provides

873
00:59:50,025 --> 00:59:53,575
Speaker 14:  additional real information about the scene. And the AI helps us

874
00:59:53,705 --> 00:59:57,615
Speaker 14:  align it and predict how we should weight those different images. So

875
00:59:57,615 --> 01:00:01,415
Speaker 14:  that's an ai, it's being used as a tool, but it's not gen

876
01:00:01,595 --> 01:00:05,375
Speaker 14:  ai. So one more thing I'll say about that is, well,

877
01:00:05,555 --> 01:00:09,175
Speaker 14:  why can't you just keep doing that and take more and more frames and get

878
01:00:09,175 --> 01:00:13,135
Speaker 14:  a hundred x and you can't, and the reason you can't is because there is

879
01:00:13,215 --> 01:00:16,895
Speaker 14:  a fundamental limit on how much detail gets through a lens.

880
01:00:17,415 --> 01:00:21,255
Speaker 14:  Hmm. It's called the diffraction limit. And every lens has a

881
01:00:21,255 --> 01:00:25,055
Speaker 14:  diffraction limit. And for most smartphones, there

882
01:00:25,065 --> 01:00:28,775
Speaker 14:  might be two x more information in each of

883
01:00:28,775 --> 01:00:32,735
Speaker 14:  horizontal and vertical than the pixels normally allow.

884
01:00:32,945 --> 01:00:36,735
Speaker 14:  There might not, depending on the lens, there isn't 10 x

885
01:00:37,205 --> 01:00:40,935
Speaker 14:  more in each of X and y Right. For each job, horizontal, vertical.

886
01:00:41,155 --> 01:00:43,455
Speaker 14:  So at that point you definitely are making stuff up.

887
01:00:43,845 --> 01:00:47,615
Speaker 2:  Yeah. Right. That, that sort of relates to

888
01:00:47,805 --> 01:00:51,655
Speaker 2:  something I think about a lot with smartphone cameras is the

889
01:00:51,655 --> 01:00:55,615
Speaker 2:  role of hardware versus software. It kind

890
01:00:55,615 --> 01:00:59,535
Speaker 2:  of seems like, especially in the, the major players

891
01:00:59,595 --> 01:01:03,575
Speaker 2:  in the US that we've sort of leveled out on the hardware, you know, we're

892
01:01:03,575 --> 01:01:07,215
Speaker 2:  not talking about a new bigger camera sensor

893
01:01:07,225 --> 01:01:10,695
Speaker 2:  every single year. You know, it's sort of like the same sensor

894
01:01:11,405 --> 01:01:15,255
Speaker 2:  with some tweaks to the software, which is not quite the

895
01:01:15,255 --> 01:01:18,615
Speaker 2:  case. I think if you look outside the us, my

896
01:01:19,165 --> 01:01:22,975
Speaker 2:  colleague Dominic Preston gets to play with the, you know, the X

897
01:01:22,995 --> 01:01:26,695
Speaker 2:  me phones that come out and they seem to be trying

898
01:01:26,765 --> 01:01:30,575
Speaker 2:  some really interesting stuff with the hardware, the really big

899
01:01:31,075 --> 01:01:35,055
Speaker 2:  one inch type sensors. You were going back to attachments

900
01:01:35,055 --> 01:01:38,495
Speaker 2:  that you put on your smartphone that turn it into more of a camera.

901
01:01:39,195 --> 01:01:43,055
Speaker 14:  So I assume you realize that the major limitation there is the

902
01:01:43,055 --> 01:01:46,655
Speaker 14:  thickness of the phone. Yeah, that's what it's all about. The, the fundamental

903
01:01:46,655 --> 01:01:50,175
Speaker 14:  optics of a camera says that if you want a larger sensor,

904
01:01:50,435 --> 01:01:54,415
Speaker 14:  you've got to have more space between the lens and the

905
01:01:54,415 --> 01:01:58,335
Speaker 14:  sensor. Right. And you can do a quite a variety of hardware tricks

906
01:01:58,355 --> 01:02:01,735
Speaker 14:  to finesse that a little bit, but not a lot.

907
01:02:02,275 --> 01:02:06,215
Speaker 14:  And so basically a larger sensor means a thicker phone

908
01:02:07,275 --> 01:02:11,215
Speaker 2:  And it, yeah. Maybe our, our sensibilities are

909
01:02:11,285 --> 01:02:15,095
Speaker 2:  that we, we just don't want that and we're gonna kind of settle on, you know,

910
01:02:15,635 --> 01:02:18,975
Speaker 2:  we get what we get. Do you think there is innovation

911
01:02:19,545 --> 01:02:23,325
Speaker 2:  to be had in the camera? Hardware, you know, is within the

912
01:02:23,445 --> 01:02:27,405
Speaker 2:  bounds of what will tolerate as, you know, how thick a phone can be,

913
01:02:27,465 --> 01:02:29,085
Speaker 2:  how big a camera bump can be?

914
01:02:30,025 --> 01:02:33,605
Speaker 14:  So far, all that innovation has been incremental, but very useful.

915
01:02:34,165 --> 01:02:37,925
Speaker 14:  As a specific example, when I was working on Pixel, we used

916
01:02:38,115 --> 01:02:42,005
Speaker 14:  Sony sensors and every year the Sony sensors would get better, just

917
01:02:42,045 --> 01:02:45,165
Speaker 14:  a little bit better, but they really would get better. One of the ways they

918
01:02:45,165 --> 01:02:48,285
Speaker 14:  got better is that what's called the read noise. The

919
01:02:49,015 --> 01:02:52,725
Speaker 14:  extra random stuff that gets introduced when the pixels are read

920
01:02:52,945 --> 01:02:56,925
Speaker 14:  off of the sensor would get less and less. And so

921
01:02:57,265 --> 01:03:00,565
Speaker 14:  in the last couple of years that I was at Google, we could do

922
01:03:00,825 --> 01:03:04,285
Speaker 14:  astrophotography where it's very, very dark and you need that

923
01:03:04,595 --> 01:03:08,085
Speaker 14:  read noise to be small. We could successfully do it.

924
01:03:08,235 --> 01:03:11,365
Speaker 14:  Whereas a few years before, we really couldn't. And so these

925
01:03:11,715 --> 01:03:15,525
Speaker 14:  incremental improvements are useful on the

926
01:03:15,555 --> 01:03:19,405
Speaker 14:  telephoto lenses. Many of the smartphone vendors, including iPhone,

927
01:03:19,405 --> 01:03:23,165
Speaker 14:  have gone to what's called a periscope or a, a

928
01:03:23,165 --> 01:03:26,925
Speaker 14:  bended optics. Yeah, that's an interesting development. So there are

929
01:03:27,205 --> 01:03:30,965
Speaker 14:  hardware developments to be had. They're slow, they're incremental, but

930
01:03:30,965 --> 01:03:31,405
Speaker 14:  they're useful.

931
01:03:31,995 --> 01:03:35,845
Speaker 2:  Yeah. Okay. Well that, that gives me hope. I don't know, there's

932
01:03:35,845 --> 01:03:39,765
Speaker 2:  something fun about new hardware as much as, you know,

933
01:03:40,365 --> 01:03:44,285
Speaker 2:  software is important on the subject of innovations and

934
01:03:44,285 --> 01:03:47,925
Speaker 2:  things coming up. I wonder if you can give us a, a taste of what you're working

935
01:03:47,925 --> 01:03:51,485
Speaker 2:  on next for Project Indigo. I know it, it's, would you call it a beta? It's

936
01:03:51,765 --> 01:03:55,645
Speaker 2:  in the Adobe Labs kind of under development state, if that's correct.

937
01:03:56,255 --> 01:03:59,805
Speaker 14:  Right. I wouldn't, the the blog doesn't even characterize it as beta. It

938
01:03:59,805 --> 01:04:00,645
Speaker 14:  says experimental.

939
01:04:01,035 --> 01:04:01,645
Speaker 2:  Okay. Yeah.

940
01:04:02,115 --> 01:04:05,805
Speaker 14:  Meaning this might or might not turn into a product for Adobe.

941
01:04:06,195 --> 01:04:06,485
Speaker 2:  Yeah.

942
01:04:06,825 --> 01:04:10,685
Speaker 14:  So in the blog, we talk about a few things. One of them is, I would

943
01:04:10,685 --> 01:04:14,445
Speaker 14:  love to do exposure bracketing where you, there are some scenes

944
01:04:14,445 --> 01:04:18,045
Speaker 14:  that are so high dynamic range that just under

945
01:04:18,325 --> 01:04:21,285
Speaker 14:  exposing and to, to reduce clipping of highlights

946
01:04:22,105 --> 01:04:26,045
Speaker 14:  and averaging of more frames to reduce noise in the shadows isn't enough.

947
01:04:27,185 --> 01:04:30,805
Speaker 14:  The example that we have in the blog is a moon over a moonlit

948
01:04:30,805 --> 01:04:34,765
Speaker 14:  landscape. So the full moon over a

949
01:04:34,795 --> 01:04:38,325
Speaker 14:  moonlit landscape, the difference in brightness between those two is

950
01:04:38,805 --> 01:04:42,485
Speaker 14:  19 F stops, meaning two to the 19th power

951
01:04:42,675 --> 01:04:46,525
Speaker 14:  meaning about half a million to one. That's

952
01:04:46,525 --> 01:04:50,205
Speaker 14:  beyond the dynamic range of any camera, even an SLR.

953
01:04:50,825 --> 01:04:54,805
Speaker 14:  So if you wanted to capture a full moon and a moonlit landscape, you

954
01:04:54,875 --> 01:04:58,405
Speaker 14:  need to bracket by bracketing, I mean capturing multiple images

955
01:04:58,715 --> 01:05:02,525
Speaker 14:  with different shutter speeds. And so of course, s SLRs

956
01:05:02,585 --> 01:05:06,445
Speaker 14:  let you do that. There's some of that in the smartphone industry. We

957
01:05:06,685 --> 01:05:10,605
Speaker 14:  would like to do a lot more of it in Indigo. Yeah. Okay.

958
01:05:10,635 --> 01:05:14,565
Speaker 14:  Another similar thing that is also mentioned in the blog is focus

959
01:05:14,855 --> 01:05:18,355
Speaker 14:  bracketing, meaning let's move the lens

960
01:05:18,935 --> 01:05:22,795
Speaker 14:  in between captures and then combine them to

961
01:05:22,795 --> 01:05:26,675
Speaker 14:  make what is called an all in focus image. So you would think,

962
01:05:26,675 --> 01:05:30,595
Speaker 14:  well, you know, in a smartphone, everything's in focus more or less. Well

963
01:05:30,595 --> 01:05:33,635
Speaker 14:  that's true for things that are far away, but not for things that are close.

964
01:05:34,375 --> 01:05:38,315
Speaker 14:  So I don't know what your killer app for all in focus might be, but I

965
01:05:38,315 --> 01:05:42,195
Speaker 14:  know my killer app is food, my Dinner. Oh, yeah. At a nice

966
01:05:42,435 --> 01:05:45,875
Speaker 14:  restaurant where it's worth photographing, it's very hard to get the whole

967
01:05:46,055 --> 01:05:49,555
Speaker 14:  dinner plate in focus. Yeah. Yeah. You can do it if you shoot from above

968
01:05:49,555 --> 01:05:52,755
Speaker 14:  looking down, but not if you shoot obliquely. Yeah.

969
01:05:53,295 --> 01:05:56,915
Speaker 2:  You're so close and yeah, you're like, is the, the tomato

970
01:05:57,135 --> 01:06:00,835
Speaker 2:  on the top of the salad or the plate behind it gonna be in focus?

971
01:06:01,025 --> 01:06:01,315
Speaker 2:  Yeah.

972
01:06:01,735 --> 01:06:05,515
Speaker 14:  So those are two things that are kind of obvious. There are a number of

973
01:06:05,515 --> 01:06:09,435
Speaker 14:  other things that, that we're exploring. They basically fall into

974
01:06:09,435 --> 01:06:13,355
Speaker 14:  the same camp of, let's take a bit more time during capture, try

975
01:06:13,355 --> 01:06:17,275
Speaker 14:  a number of different things, combine them computationally. What I'd love

976
01:06:17,275 --> 01:06:20,595
Speaker 14:  to do, as the blog says, is to keep all the data,

977
01:06:21,335 --> 01:06:25,275
Speaker 14:  not just one image, so that you could also play with it later in an

978
01:06:25,275 --> 01:06:25,515
Speaker 14:  editor.

979
01:06:26,335 --> 01:06:26,625
Speaker 2:  Yeah.

980
01:06:26,805 --> 01:06:30,345
Speaker 14:  And that's, that's a great example of where the camera app and the

981
01:06:30,415 --> 01:06:32,105
Speaker 14:  editing app can work in synergy.

982
01:06:32,935 --> 01:06:36,865
Speaker 2:  Yeah. A little bit of a, of a nice advantage when you work for

983
01:06:36,865 --> 01:06:37,185
Speaker 2:  Adobe.

984
01:06:38,135 --> 01:06:38,625
Speaker 14:  Exactly.

985
01:06:40,295 --> 01:06:43,785
Speaker 2:  Okay. But I have to ask for my Android people. Is there an Android version

986
01:06:43,895 --> 01:06:44,385
Speaker 2:  come in?

987
01:06:45,455 --> 01:06:49,425
Speaker 14:  It's definitely on the want list. Okay. I

988
01:06:49,425 --> 01:06:53,225
Speaker 14:  used to work on building Android camera apps, of course, right at Google.

989
01:06:53,525 --> 01:06:56,985
Speaker 14:  As a matter of fact, the API, the application programming interface

990
01:06:57,325 --> 01:07:00,865
Speaker 14:  for the camera was something that I and my graduate students at Stanford

991
01:07:01,345 --> 01:07:05,105
Speaker 14:  designed. The, the so-called camera two programming interface

992
01:07:05,445 --> 01:07:09,425
Speaker 14:  for Android came out of a, a project at Stanford called

993
01:07:09,425 --> 01:07:10,745
Speaker 14:  the Franken Camera Project.

994
01:07:11,245 --> 01:07:11,745
Speaker 2:  Oh, nice.

995
01:07:12,445 --> 01:07:15,785
Speaker 14:  And it's a great interface And I would love to address it,

996
01:07:44,225 --> 01:07:46,705
Speaker 14:  by calling it Universal five years ago, didn't I?

997
01:08:16,425 --> 01:08:16,845
Speaker 14:  Reddit

998
01:10:42,165 --> 01:10:45,935
Speaker 2:  Alright, we're back. We're gonna take a hotline question

999
01:10:46,075 --> 01:10:50,055
Speaker 2:  now, and as always, the number for that is 8 6 6 VERGE

1000
01:10:50,115 --> 01:10:53,855
Speaker 2:  one one and our email is vergecast at The Verge dot com.

1001
01:10:54,235 --> 01:10:58,215
Speaker 2:  We love the questions, keep them coming and we answer at least one on

1002
01:10:58,215 --> 01:11:02,095
Speaker 2:  every show. So definitely write in or call in. This

1003
01:11:02,095 --> 01:11:05,975
Speaker 2:  week's question comes from someone who isn't that concerned about image

1004
01:11:05,975 --> 01:11:09,855
Speaker 2:  quality on their phone, but they're a little bit bothered by the camera

1005
01:11:09,925 --> 01:11:10,215
Speaker 2:  bump.

1006
01:11:13,425 --> 01:11:17,385
Speaker 18:  I am Ogo, I'm calling to talk about

1007
01:11:17,975 --> 01:11:21,825
Speaker 18:  cameras on phones. I, for one, don't

1008
01:11:21,825 --> 01:11:25,745
Speaker 18:  care much about the quality of the camera to be honest. And

1009
01:11:25,945 --> 01:11:29,705
Speaker 18:  I assume that if I want to get the

1010
01:11:29,705 --> 01:11:33,385
Speaker 18:  best phone available in the market, I have

1011
01:11:33,525 --> 01:11:37,465
Speaker 18:  to basically live with a bump that is almost to

1012
01:11:37,465 --> 01:11:40,945
Speaker 18:  the size of the overall phone. So I just wonder about

1013
01:11:41,195 --> 01:11:44,905
Speaker 18:  where are we going with this, because it seems that these camera bumps just

1014
01:11:44,905 --> 01:11:48,545
Speaker 18:  keep getting bigger and bigger and somehow the phones get

1015
01:11:48,775 --> 01:11:52,585
Speaker 18:  thinner on the other side, but then the size of the bump is not

1016
01:11:52,585 --> 01:11:56,065
Speaker 18:  taken into account from the overall side. So the phone, when things get

1017
01:11:56,265 --> 01:11:59,705
Speaker 18:  reviewed, measure. So that seems pretty weird that

1018
01:12:00,395 --> 01:12:04,305
Speaker 18:  let's say that the phone size is an overall five or whatever and

1019
01:12:04,305 --> 01:12:07,985
Speaker 18:  then the bump is at two on top of that. But then somehow it gets

1020
01:12:08,905 --> 01:12:12,825
Speaker 18:  reported that besides, oh, the phone is just the lower number. So

1021
01:12:13,775 --> 01:12:17,655
Speaker 18:  I don't know, I just, I I just wondering if there's like any

1022
01:12:18,525 --> 01:12:22,455
Speaker 18:  hope out there for at top of the line phone to just basically

1023
01:12:22,455 --> 01:12:25,575
Speaker 18:  start moving away from the bump and then having the,

1024
01:12:26,355 --> 01:12:29,935
Speaker 18:  having been the case that we can have a phone that has the text

1025
01:12:30,355 --> 01:12:34,335
Speaker 18:  of a top of the line, but not the oversized phone, that would allow

1026
01:12:34,335 --> 01:12:37,815
Speaker 18:  us to at least have the phone sit like fresh on the table.

1027
01:12:38,355 --> 01:12:41,495
Speaker 18:  So I guess yes, just full for thought. Thank you.

1028
01:12:43,065 --> 01:12:47,045
Speaker 2:  So I need to start with mostly bad news.

1029
01:12:47,275 --> 01:12:51,245
Speaker 2:  Osvaldo, I am so sorry. I don't think the camera bumps are going away, but

1030
01:12:51,325 --> 01:12:55,005
Speaker 2:  I love this question because A, I appreciate the honesty.

1031
01:12:55,385 --> 01:12:58,845
Speaker 2:  Really don't care about the image quality, just tired of living with a big

1032
01:12:58,845 --> 01:13:02,805
Speaker 2:  camera bump. And b, I think it's just saying out loud what

1033
01:13:02,925 --> 01:13:06,605
Speaker 2:  a lot of us are thinking or bothered by. But

1034
01:13:07,165 --> 01:13:10,925
Speaker 2:  I know I, for one, just want all the best image quality I can get.

1035
01:13:11,105 --> 01:13:14,645
Speaker 2:  So it's sort of something I, I've shoved into the back of my head that I

1036
01:13:14,645 --> 01:13:18,565
Speaker 2:  can live with. But I think there's a few reasons why the camera bump

1037
01:13:18,585 --> 01:13:22,165
Speaker 2:  is not going away, especially on the pro in the

1038
01:13:22,505 --> 01:13:25,685
Speaker 2:  higher tier models that Asalto was talking about.

1039
01:13:26,425 --> 01:13:30,205
Speaker 2:  So these are the phones that tend to have the

1040
01:13:30,205 --> 01:13:33,525
Speaker 2:  best camera, you know, the best of the best, and

1041
01:13:34,335 --> 01:13:38,165
Speaker 2:  those cameras have bigger sensors. That is a huge benefit

1042
01:13:38,235 --> 01:13:41,605
Speaker 2:  when you're taking pictures in low light or really any

1043
01:13:42,085 --> 01:13:45,845
Speaker 2:  situation. But a bigger sensor means it needs a bigger

1044
01:13:46,035 --> 01:13:49,805
Speaker 2:  lens, hence a big camera bump. So

1045
01:13:50,475 --> 01:13:53,205
Speaker 2:  there's a little bit of a caveat to this that

1046
01:13:54,355 --> 01:13:57,485
Speaker 2:  outside of the US this is maybe even a worse problem

1047
01:13:58,375 --> 01:14:01,965
Speaker 2:  where some of the xmi of the world are,

1048
01:14:02,625 --> 01:14:06,525
Speaker 2:  you know, betting on really big image sensors and big lenses

1049
01:14:06,945 --> 01:14:10,845
Speaker 2:  and just sort of going all the way into, you know, the heck with

1050
01:14:10,925 --> 01:14:14,365
Speaker 2:  a, a camera bump is gonna be huge and people will just live with that.

1051
01:14:14,985 --> 01:14:18,845
Speaker 2:  So I think what we have to deal with here is maybe a little

1052
01:14:18,845 --> 01:14:22,445
Speaker 2:  bit better. And I do think the point about phones

1053
01:14:22,445 --> 01:14:26,245
Speaker 2:  getting thinner, but the camera bump kind of remaining

1054
01:14:26,365 --> 01:14:30,325
Speaker 2:  a problem is legitimate. I tested the Galaxy S

1055
01:14:30,325 --> 01:14:34,125
Speaker 2:  25 Edge, which is a, a super thin phone, But

1056
01:14:34,125 --> 01:14:37,805
Speaker 2:  that camera bump is maybe as thick as the phone

1057
01:14:37,985 --> 01:14:41,925
Speaker 2:  itself. And something that really bothered me when I tested

1058
01:14:42,065 --> 01:14:45,885
Speaker 2:  it is putting it on the table as, as Faldo mentioned,

1059
01:14:46,115 --> 01:14:49,645
Speaker 2:  does not sit flush on a table and it wobbles like

1060
01:14:49,905 --> 01:14:53,765
Speaker 2:  all heck when you tap on it. This is made worse by

1061
01:14:54,065 --> 01:14:58,045
Speaker 2:  my habit of not putting cases on phones, which I think

1062
01:14:58,625 --> 01:15:02,405
Speaker 2:  is one of the solutions here. So I don't think the camera bumps are going

1063
01:15:02,475 --> 01:15:06,125
Speaker 2:  away, putting a case on your phone, depending on the phone in

1064
01:15:06,405 --> 01:15:10,125
Speaker 2:  the case, you know, you can shop around a little bit for something that

1065
01:15:10,125 --> 01:15:13,965
Speaker 2:  sort of evens out the camera bump. I think a, you know, a

1066
01:15:14,025 --> 01:15:17,885
Speaker 2:  pop socket or a a case with a built-in stand could help

1067
01:15:18,025 --> 01:15:21,925
Speaker 2:  if you're really bothered by setting your phone down and having

1068
01:15:21,945 --> 01:15:25,765
Speaker 2:  it wobble on the tabletop. Those would be things to look at. If you

1069
01:15:25,765 --> 01:15:29,285
Speaker 2:  haven't already, there's maybe good news coming

1070
01:15:29,745 --> 01:15:33,565
Speaker 2:  or bad. I can't really tell the, the rumors

1071
01:15:33,945 --> 01:15:37,405
Speaker 2:  of the iPhone, the impending iPhone 17

1072
01:15:38,435 --> 01:15:42,005
Speaker 2:  show, like in elongated camera bump. That might

1073
01:15:42,195 --> 01:15:45,965
Speaker 2:  help even out the wobble situation. I just tested

1074
01:15:46,745 --> 01:15:50,405
Speaker 2:  the Pixel 10 Pro and pixel phones

1075
01:15:50,475 --> 01:15:54,365
Speaker 2:  have that long kind of elongated oval of

1076
01:15:54,405 --> 01:15:58,285
Speaker 2:  a camera bump and it's big and chunky for sure, but when you

1077
01:15:58,285 --> 01:16:01,765
Speaker 2:  set it on a table, it's a little bit of a, a stable

1078
01:16:02,615 --> 01:16:06,525
Speaker 2:  stand for the phone. So it props it up a little bit, doesn't

1079
01:16:06,525 --> 01:16:09,765
Speaker 2:  wobble around. So there are trade-offs there.

1080
01:16:10,475 --> 01:16:14,325
Speaker 2:  Perhaps the iPhone is moving to something similar. It's still a

1081
01:16:14,325 --> 01:16:18,285
Speaker 2:  big camera bump. So I think you've gotta look at a case that's maybe

1082
01:16:18,285 --> 01:16:22,085
Speaker 2:  going to help if all else fails. I find

1083
01:16:22,205 --> 01:16:25,845
Speaker 2:  a drink coaster is my friend. I am always

1084
01:16:25,845 --> 01:16:29,805
Speaker 2:  putting my phone on a drink coaster when I'm sitting at the table

1085
01:16:29,985 --> 01:16:33,045
Speaker 2:  and I'm tired of it wobbling around. So

1086
01:16:33,935 --> 01:16:37,525
Speaker 2:  we've always got that oswaldo, I'm sorry. I hope that helps, but

1087
01:16:38,095 --> 01:16:42,005
Speaker 2:  maybe the help is in just saying it out loud and knowing that

1088
01:16:42,005 --> 01:16:45,325
Speaker 2:  you're not suffering alone. So thanks for calling in.

1089
01:16:46,875 --> 01:16:50,845
Speaker 2:  Alright, that's it for The Vergecast today. To read more about the

1090
01:16:50,845 --> 01:16:54,125
Speaker 2:  topics we covered, check the show notes or head to The Verge dot com.

1091
01:16:54,865 --> 01:16:58,205
Speaker 2:  And if you like what we do here, consider buying a paid subscription.

1092
01:16:58,705 --> 01:17:02,525
Speaker 2:  The show is produced by Eric Gomez, Brendan Kiefer, Travis EK,

1093
01:17:02,545 --> 01:17:06,485
Speaker 2:  and Andrew Marino. The Vergecast is The Verge production and part of the

1094
01:17:06,545 --> 01:17:10,445
Speaker 2:  Vox Media podcast network. Jake Aki and the team will be

1095
01:17:10,445 --> 01:17:13,365
Speaker 2:  here Friday to talk about the news. Thanks for listening.

