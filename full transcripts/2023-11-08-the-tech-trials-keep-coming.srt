1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: caaef0fa-7f4e-4445-9b5b-ac381a79e16d
Status: Done
Stage: Done
Title: The tech trials keep coming
Audio URL: https://jfe93e.s3.amazonaws.com/-4888164994119905567/2230149004350387477/s93290-US-4342s-1699442863.mp3
Description: Today on the flagship podcast of anti-steering provisions:
02:57 - The Verge's David Pierce and Makena Kelly discuss Epic v. Google, a trial about the future of app stores.

The Epic v. Google trial may come down to simple v. complicated

Epic v. Google: a battle over Fortnite fees goes to court 


28:49 - Liz Lopatto joins the show to detail her experience covering the Sam Bankman-Fried trial from start to finish.

FTX founder Sam Bankman-Fried is guilty of fraud 

Sam Bankman-Fried gambled on a trial and his parents lost


58:27 - Richard Lawler helps answer this week's Vergecast Hotline question.

Disney’s new vision for ESPN might include part ownership by the NBA, NFL 

Disney finally revealed how many billions ESPN pulls in. 


Email us at vergecast@theverge.com or leave a voicemail at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Disabled

2
00:00:02,555 --> 00:00:06,125
Speaker 2:  Welcome To The Vergecast, the flagship podcast of Anti steering

3
00:00:06,125 --> 00:00:09,885
Speaker 2:  provisions. I'm your friend David Pierce and I am currently

4
00:00:09,885 --> 00:00:13,685
Speaker 2:  getting ready to travel. It's 6:47 PM

5
00:00:13,905 --> 00:00:17,165
Speaker 2:  on Monday night. I have a flight Tuesday morning. We're recording all of

6
00:00:17,165 --> 00:00:20,885
Speaker 2:  this a little bit early as a result, I'm going San Francisco And. what that

7
00:00:20,885 --> 00:00:24,485
Speaker 2:  means is I'm about to spend five or so hours on a plane.

8
00:00:25,105 --> 00:00:28,845
Speaker 2:  So I'm doing of course what you always have to do, which is bring

9
00:00:29,175 --> 00:00:33,005
Speaker 2:  45 different devices to use on the plane. I have an iPad,

10
00:00:33,405 --> 00:00:37,125
Speaker 2:  I have a switch, I have my laptop, I have my phone, I have

11
00:00:37,195 --> 00:00:40,765
Speaker 2:  another iPad that I'm just now realizing I don't need to bring. I have a

12
00:00:40,765 --> 00:00:44,605
Speaker 2:  Kindle. Did I mention my Kindle? All of that is full of content. I'm

13
00:00:44,805 --> 00:00:48,565
Speaker 2:  downloading stuff, I'm charging everything. I have Super Mario Wonder

14
00:00:48,665 --> 00:00:51,125
Speaker 2:  to play on the plane, which is the only thing I'm gonna do for the whole

15
00:00:51,125 --> 00:00:53,765
Speaker 2:  flight and I know that already. And yet I'm doing all of this other work.

16
00:00:54,085 --> 00:00:57,725
Speaker 2:  I also have to charge all my gadgets. I have to make sure I have all of the

17
00:00:57,725 --> 00:01:00,965
Speaker 2:  cables that I need, which is a lot easier than it used to be. But there's

18
00:01:00,965 --> 00:01:04,365
Speaker 2:  always still one Stray Lightning cable or micro

19
00:01:04,605 --> 00:01:08,325
Speaker 2:  USB thing I have to bring. It's just a lot. And it turns out that whenever

20
00:01:08,405 --> 00:01:11,965
Speaker 2:  I travel, half the stuff in my bag is gadgets and the other half is just

21
00:01:11,965 --> 00:01:15,525
Speaker 2:  like one pair of jeans no matter how long I'm traveling for.

22
00:01:15,745 --> 00:01:19,725
Speaker 2:  Listen, this is not the life anyone should live, but it's the one I've signed

23
00:01:19,725 --> 00:01:23,525
Speaker 2:  up for. So here we go. Anyway, we have an awesome show coming up for you

24
00:01:23,525 --> 00:01:27,485
Speaker 2:  today. We are gonna talk almost entirely about trials because

25
00:01:27,485 --> 00:01:30,805
Speaker 2:  like we've been talking about on this show all fall, we're in the midst of

26
00:01:31,125 --> 00:01:34,845
Speaker 2:  a couple of really interesting, really important, potentially really

27
00:01:34,845 --> 00:01:38,565
Speaker 2:  consequential things happening in court around the tech industry.

28
00:01:38,895 --> 00:01:42,765
Speaker 2:  Today we're gonna talk about two in particular, Epic v Google, the latest

29
00:01:43,075 --> 00:01:46,445
Speaker 2:  antitrust trial against Google, not to be confused with the other

30
00:01:46,475 --> 00:01:49,685
Speaker 2:  antitrust trial that's happening against Google. And then we're gonna talk

31
00:01:49,685 --> 00:01:53,365
Speaker 2:  about SBF, the trial of Sam. Banin Freed is finally

32
00:01:53,475 --> 00:01:57,325
Speaker 2:  over. He was convicted and we're gonna talk about how we got there

33
00:01:57,545 --> 00:02:01,045
Speaker 2:  And, what it means going forward. All that is coming up in just a sec. But

34
00:02:01,045 --> 00:02:04,925
Speaker 2:  first I have to find the charger for my Kindle because I have

35
00:02:04,925 --> 00:02:08,805
Speaker 2:  two Kindles with two different chargers and I'm just gonna bring whichever

36
00:02:08,805 --> 00:02:12,485
Speaker 2:  one is leased Dead. There's just a lot going on. This is The Vergecast. We'll

37
00:02:12,485 --> 00:02:12,845
Speaker 2:  be right back.

38
00:02:15,895 --> 00:02:19,465
Speaker 3:  This podcast is brought to you by Meta Quest three, the new mixed reality

39
00:02:19,465 --> 00:02:23,385
Speaker 3:  headset from Meta. Expand Your World in ways you never Thought Possible with

40
00:02:23,385 --> 00:02:27,225
Speaker 3:  the new Meta Quest. Three, put on the most powerful quest yet and jump

41
00:02:27,225 --> 00:02:31,145
Speaker 3:  into fully immersive games like Assassin's Creed Nexus or

42
00:02:31,145 --> 00:02:34,385
Speaker 3:  blend virtual elements into your surroundings in games like Stranger Things

43
00:02:34,525 --> 00:02:38,065
Speaker 3:  vr. With over 500 titles, it's easy to dive into

44
00:02:38,425 --> 00:02:42,345
Speaker 3:  whatever you're into. Expand your world with Meta Quest three. See child

45
00:02:42,345 --> 00:02:44,825
Speaker 3:  safety guidance online accounts for 10 and up certain apps, games and experiences

46
00:02:44,825 --> 00:02:47,785
Speaker 3:  may be suitable for a more mature audience. Learn more@meta.com.

47
00:02:51,895 --> 00:02:55,795
Speaker 4:  Lauren, Mike. So we host a podcast for Wired called Gadget

48
00:02:55,795 --> 00:02:58,915
Speaker 4:  Lab. We do, we do. Yes, that is correct.

49
00:02:59,555 --> 00:03:01,125
Speaker 4:  Tell the good people some more about it.

50
00:03:01,195 --> 00:03:03,725
Speaker 5:  Well I think the good people should definitely tune in every week because

51
00:03:03,725 --> 00:03:07,685
Speaker 5:  they get to hear me roasting you. Hey now All, right? No, really what

52
00:03:07,685 --> 00:03:11,605
Speaker 5:  Gadget Lab is is Mike and I tackling the biggest questions in the

53
00:03:11,605 --> 00:03:15,405
Speaker 5:  world of technology. We cover the big news of the week in Tech Land,

54
00:03:15,425 --> 00:03:19,285
Speaker 5:  but we also offer our expert and opinions on all things

55
00:03:19,725 --> 00:03:19,965
Speaker 5:  consumer

56
00:03:20,195 --> 00:03:23,805
Speaker 4:  Tech. We release a new episode of Gadget Lab every week and you can listen

57
00:03:23,905 --> 00:03:25,325
Speaker 4:  and follow us wherever you pod

58
00:03:30,775 --> 00:03:34,425
Speaker 2:  Welcome back. I have like 65 different things plugged in right now.

59
00:03:34,645 --> 00:03:38,145
Speaker 2:  Two different devices are doing software updates and I think I'm downloading

60
00:03:38,385 --> 00:03:42,265
Speaker 2:  like half of Netflix to my iPad. I am ready for this

61
00:03:42,265 --> 00:03:45,945
Speaker 2:  flight. Y'all All right? Let's get into the trials. The first one I wanna

62
00:03:45,945 --> 00:03:49,905
Speaker 2:  talk about today is Epic v Google, which is a trial fundamentally about the

63
00:03:49,905 --> 00:03:53,865
Speaker 2:  future of app stores. Epic says basically that Google charging a

64
00:03:53,865 --> 00:03:57,825
Speaker 2:  30% commission on in-app purchases is anti-competitive and it

65
00:03:57,825 --> 00:04:01,705
Speaker 2:  wants to blow up the app store model altogether. Google says You know

66
00:04:02,085 --> 00:04:05,825
Speaker 2:  no thanks to all of that. If this is ringing deja vu bells in your brain,

67
00:04:05,915 --> 00:04:09,625
Speaker 2:  there is a good reason for that. In 2021, Epic went to trial against

68
00:04:09,675 --> 00:04:13,585
Speaker 2:  Apple alleging pretty much the exact same stuff. This trial

69
00:04:13,605 --> 00:04:17,345
Speaker 2:  has a lot in common with that one, but also some important differences

70
00:04:17,605 --> 00:04:21,265
Speaker 2:  and there's a decent chance that we're gonna get a different kind of outcome

71
00:04:21,295 --> 00:04:24,825
Speaker 2:  here. The trial is already a couple of days old as you're hearing this,

72
00:04:24,995 --> 00:04:28,025
Speaker 2:  we're covering it really closely. Sean Hollister is in the courtroom and

73
00:04:28,025 --> 00:04:31,625
Speaker 2:  the rgs Makena Kelly is here now to help me figure out what to make of all

74
00:04:31,625 --> 00:04:35,425
Speaker 2:  of it. Hi Makena. Hi. I don't know where to start with this trial.

75
00:04:35,745 --> 00:04:39,105
Speaker 2:  I was going back and trying to figure out where do we need to start to catch

76
00:04:39,105 --> 00:04:42,585
Speaker 2:  people up on what is going on between Epic and Google? And I feel like to

77
00:04:42,585 --> 00:04:44,745
Speaker 2:  some extent the answer is we have to go all the way back to the beginning

78
00:04:44,745 --> 00:04:48,425
Speaker 2:  of Epic versus everybody, right? Which is like 2020 mid

79
00:04:48,665 --> 00:04:52,465
Speaker 2:  pandemic. Everybody's outta their mind. Life is pure chaos and

80
00:04:52,655 --> 00:04:56,265
Speaker 2:  Epic just sort of decides to pull the

81
00:04:56,265 --> 00:04:59,705
Speaker 2:  ripcord and pick a giant fight with the two biggest companies in tech all

82
00:04:59,705 --> 00:05:03,665
Speaker 2:  at once. Can you just give us like the 62nd backstory kind of

83
00:05:03,825 --> 00:05:06,225
Speaker 2:  starting there, And, what happened between these companies?

84
00:05:06,775 --> 00:05:10,665
Speaker 6:  Sure. So what happened in 2020 like you're describing is

85
00:05:11,135 --> 00:05:14,945
Speaker 6:  Epic games. The Fortnite maker decided that they were going to just

86
00:05:14,965 --> 00:05:18,705
Speaker 6:  say screw you to Google and Apple in their app stores.

87
00:05:19,015 --> 00:05:19,305
Speaker 6:  That

88
00:05:19,305 --> 00:05:22,185
Speaker 2:  Was like the official plan by the way. That was not, that's not really editorializing

89
00:05:22,185 --> 00:05:23,865
Speaker 2:  like that is what they were attempting to do.

90
00:05:24,645 --> 00:05:28,065
Speaker 6:  It totally was. And Sweeney, I mean that is so like Tim

91
00:05:28,215 --> 00:05:32,105
Speaker 6:  Sweeney. Yeah. Like to do anyways. And so he said Screw you. We are

92
00:05:32,105 --> 00:05:35,625
Speaker 6:  going to allow people to make in-app purchases in our game without it going

93
00:05:35,625 --> 00:05:39,025
Speaker 6:  through the app stores and being subject to this like 15 to 30% tax.

94
00:05:39,725 --> 00:05:43,385
Speaker 6:  And immediately Google and Apple pulled Fortnite

95
00:05:43,695 --> 00:05:46,945
Speaker 6:  from their app stores. And so as a result,

96
00:05:47,495 --> 00:05:51,385
Speaker 6:  Epic Games sued them for that, alleging that they hold these

97
00:05:51,385 --> 00:05:54,785
Speaker 6:  monopolies in the app store markets and that these You know

98
00:05:54,785 --> 00:05:58,725
Speaker 6:  30% taxes are unlawful and should be

99
00:05:58,925 --> 00:06:02,805
Speaker 6:  challenged. And so we're three years from that and the Google one is

100
00:06:02,805 --> 00:06:04,205
Speaker 6:  just going to trial right now.

101
00:06:04,595 --> 00:06:08,325
Speaker 2:  Yeah, it's been a, it's been a long three years. So and then in between we

102
00:06:08,325 --> 00:06:12,205
Speaker 2:  had Epic versus Apple, which is I think not exactly the same thing as

103
00:06:12,205 --> 00:06:14,965
Speaker 2:  the trial we're about to have and we should talk about the differences. But

104
00:06:15,305 --> 00:06:19,245
Speaker 2:  in a lot of ways the bones of the trial are very similar. One

105
00:06:19,245 --> 00:06:22,405
Speaker 2:  side is the app store and one side is Epic. Trying to say the app store is

106
00:06:22,435 --> 00:06:26,245
Speaker 2:  illegal and I would say Epic didn't completely lose

107
00:06:26,265 --> 00:06:29,805
Speaker 2:  the Apple trial. It won the sort of anti steering provision which says you

108
00:06:29,805 --> 00:06:33,365
Speaker 2:  can now link to other ways to make payments, but in general

109
00:06:34,035 --> 00:06:37,845
Speaker 2:  it's fight against App Store monopolies pretty much came

110
00:06:37,845 --> 00:06:41,565
Speaker 2:  up short. So if I'm Epic, why on earth do I keep picking

111
00:06:41,595 --> 00:06:45,285
Speaker 2:  this fight after more or less losing it the first time?

112
00:06:45,635 --> 00:06:49,245
Speaker 6:  Well, to look at Tim Sweeney, I think he really does like to tick these people

113
00:06:49,305 --> 00:06:53,245
Speaker 6:  off. He's kind of a hardheaded CEOI don't think he's worried

114
00:06:53,245 --> 00:06:56,965
Speaker 6:  about losing face in these at all to be honest with you.

115
00:06:57,425 --> 00:07:01,325
Speaker 6:  And so for them, these like taxes that these

116
00:07:01,385 --> 00:07:05,165
Speaker 6:  app stores put on software, what requires them to

117
00:07:05,165 --> 00:07:08,325
Speaker 6:  raise? Well what they'll say is it requires them to raise prices for consumers

118
00:07:08,705 --> 00:07:12,485
Speaker 6:  and it makes whatever it is, V bucks or whatever more expensive in

119
00:07:12,485 --> 00:07:16,285
Speaker 6:  Fortnite. It makes it more expensive for you to, I don't know, get Tinder

120
00:07:16,395 --> 00:07:19,565
Speaker 6:  gold or whatever they're calling it nowadays and all that kind of stuff.

121
00:07:19,785 --> 00:07:23,685
Speaker 6:  So they continue to push this because they don't wanna give

122
00:07:23,785 --> 00:07:27,205
Speaker 6:  any of these profits, any of this money to Apple or Google.

123
00:07:27,395 --> 00:07:31,045
Speaker 6:  They're just operating an app store in their opinion. And it should be You

124
00:07:31,045 --> 00:07:34,165
Speaker 6:  know free for people to access and use as an open

125
00:07:34,355 --> 00:07:35,045
Speaker 6:  marketplace.

126
00:07:35,665 --> 00:07:39,565
Speaker 2:  What's your sense of what's different about this case sort of at a very high

127
00:07:39,565 --> 00:07:43,125
Speaker 2:  level, the two sides of the fight like we were saying are more or less the

128
00:07:43,125 --> 00:07:46,525
Speaker 2:  same thing. Is there anything different about Google Google as an opponent

129
00:07:47,105 --> 00:07:49,125
Speaker 2:  as Apple as opponent a couple years ago?

130
00:07:49,475 --> 00:07:53,365
Speaker 6:  Sure. So I mean looking at Google, the

131
00:07:53,365 --> 00:07:57,125
Speaker 6:  Play store is so huge. Yeah. As much as we talk about

132
00:07:57,145 --> 00:08:01,085
Speaker 6:  You know iPhones being like the elite whatever device to be using,

133
00:08:01,475 --> 00:08:05,445
Speaker 6:  more people use Android. Like it really is just everywhere. And So, I

134
00:08:05,445 --> 00:08:09,125
Speaker 6:  think that lends itself more to Epic's argument here.

135
00:08:09,345 --> 00:08:12,525
Speaker 6:  And then also we already had the ruling in the anti steering provision and

136
00:08:12,525 --> 00:08:16,245
Speaker 6:  that's in in appeals right now with having to be able to link out. So

137
00:08:16,245 --> 00:08:20,205
Speaker 6:  another decision similar, similar to that would really offer some more precedent

138
00:08:20,505 --> 00:08:23,325
Speaker 6:  in whatever appeal comes from the Apple case as well.

139
00:08:23,715 --> 00:08:26,805
Speaker 2:  Yeah, the the Play store thing is so interesting to me 'cause I think if

140
00:08:26,865 --> 00:08:30,645
Speaker 2:  I'm remembering back, apple basically tried to make a security

141
00:08:31,005 --> 00:08:34,965
Speaker 2:  argument about iOS that like if you allow people to side load

142
00:08:34,995 --> 00:08:38,525
Speaker 2:  apps on their phone, bad things will happen. People will install malware.

143
00:08:38,705 --> 00:08:42,125
Speaker 2:  All kinds of awful things will happen to your phone. And essentially

144
00:08:42,535 --> 00:08:46,445
Speaker 2:  users and developers cannot be trusted to do things outside of the

145
00:08:46,445 --> 00:08:50,165
Speaker 2:  app store. And it seems like Google is making a similar

146
00:08:50,395 --> 00:08:53,445
Speaker 2:  case in this case, which is sort of funny because the Play store is like

147
00:08:53,475 --> 00:08:57,405
Speaker 2:  notoriously kind of a disaster. But also Google is slightly

148
00:08:57,405 --> 00:09:01,245
Speaker 2:  different because like you can kind of get around the play store,

149
00:09:01,245 --> 00:09:04,925
Speaker 2:  like you can sort of side load apps on Android, the Samsung

150
00:09:05,175 --> 00:09:08,845
Speaker 2:  store exists, which seems like a really weird sort of wrench in this

151
00:09:09,015 --> 00:09:12,805
Speaker 2:  trial. So even at a platform level, it just seems to me that the

152
00:09:13,155 --> 00:09:17,125
Speaker 2:  case against Google is stronger because the Play Store, like you said,

153
00:09:17,125 --> 00:09:20,925
Speaker 2:  is so big and so important on this platform but also is so

154
00:09:20,925 --> 00:09:24,285
Speaker 2:  much sort of messier and easier to get around

155
00:09:24,675 --> 00:09:28,605
Speaker 2:  than like the unbelievably tight fist that it Apple has

156
00:09:28,985 --> 00:09:31,645
Speaker 2:  on the app store. Does that feel different to you going into this?

157
00:09:31,985 --> 00:09:35,685
Speaker 6:  Oh yeah. I mean 'cause it's, it's easier. You can just download another

158
00:09:35,785 --> 00:09:39,685
Speaker 6:  app store or You know or use like the Samsung Play store or be able to it.

159
00:09:39,755 --> 00:09:42,805
Speaker 6:  It's so much easier. People talk about customization and having more control

160
00:09:42,805 --> 00:09:46,685
Speaker 6:  of your devices. Google has let you do that for a very long time on Android.

161
00:09:46,945 --> 00:09:50,685
Speaker 6:  And so people do of course have more options and I You know it'll be interesting

162
00:09:50,685 --> 00:09:51,845
Speaker 6:  to see how that plays out.

163
00:09:52,265 --> 00:09:55,565
Speaker 2:  And this goes back to, I think one of the things we learned from the Apple

164
00:09:55,565 --> 00:09:59,485
Speaker 2:  case is so much of this is about the fight we end up having. Which

165
00:09:59,485 --> 00:10:01,925
Speaker 2:  is part of the thing I think this is that's gonna be so interesting about

166
00:10:01,925 --> 00:10:05,045
Speaker 2:  this case is like every time you and I talk, I feel like we end up talking

167
00:10:05,045 --> 00:10:08,565
Speaker 2:  about market definitions because all anybody ever wants to talk about

168
00:10:08,945 --> 00:10:11,805
Speaker 2:  in these cases is market definitions because the market you define is so

169
00:10:11,805 --> 00:10:15,765
Speaker 2:  important. And it was some like it was the last time there were

170
00:10:15,885 --> 00:10:18,885
Speaker 2:  questions about like is it mobile apps, is it games? And we ended up talking

171
00:10:18,885 --> 00:10:22,845
Speaker 2:  about the market was like mobile digital transactions or something

172
00:10:22,845 --> 00:10:25,765
Speaker 2:  goofy and in this case it feels like we're we're about to just re-litigate

173
00:10:25,765 --> 00:10:28,845
Speaker 2:  all the same stuff, right? Like what, what is it that we're actually fighting

174
00:10:28,845 --> 00:10:32,645
Speaker 2:  about here? And I wonder if I am Epic if I've learned

175
00:10:33,045 --> 00:10:36,885
Speaker 2:  anything from that first fight that is gonna make them do a

176
00:10:36,885 --> 00:10:38,845
Speaker 2:  better job in this case.

177
00:10:39,635 --> 00:10:43,565
Speaker 6:  Yeah and I mean when you talk about continuing to pick this fight last week,

178
00:10:43,815 --> 00:10:47,685
Speaker 6:  match.com and You know other plaintiffs on this case

179
00:10:47,685 --> 00:10:51,365
Speaker 6:  dropped out seemingly You know settling with Apple. It's interesting how

180
00:10:51,365 --> 00:10:54,965
Speaker 6:  Tim Sweeney and Epic games is continuing to purs pursue this especially with

181
00:10:55,485 --> 00:10:58,325
Speaker 6:  whatever settlements You know Google is trying to make behind closed doors

182
00:10:58,325 --> 00:10:59,285
Speaker 6:  right now. Yeah.

183
00:10:59,285 --> 00:11:01,565
Speaker 2:  What do you make of the match thing? They were the other company that has

184
00:11:01,565 --> 00:11:05,045
Speaker 2:  been really loud in this fight. I feel like it's been Epic, Spotify

185
00:11:05,705 --> 00:11:09,165
Speaker 2:  and Match have been the three companies sort of most aggressively fighting

186
00:11:09,455 --> 00:11:13,245
Speaker 2:  these app store monopolies and Match in particular seems to have just kind

187
00:11:13,245 --> 00:11:15,165
Speaker 2:  of given up the fight. What do you make of that?

188
00:11:15,595 --> 00:11:18,645
Speaker 6:  Yeah, I think this case like you're saying is going to be a bit more challenging

189
00:11:18,905 --> 00:11:22,205
Speaker 6:  for these companies to take on. And I'm sure You know whatever agreement

190
00:11:22,915 --> 00:11:26,845
Speaker 6:  they were able to get from Google on this was enough to satisfy You know

191
00:11:26,845 --> 00:11:30,685
Speaker 6:  their concerns with this and that kind of You know lends

192
00:11:30,685 --> 00:11:33,845
Speaker 6:  to the question of what is Epic games? What is their opening argument going

193
00:11:33,845 --> 00:11:36,765
Speaker 6:  to look like this week? What is it that they're You know continuing to push

194
00:11:36,765 --> 00:11:39,445
Speaker 6:  and to continue to fight for that. They probably couldn't have gotten You

195
00:11:39,445 --> 00:11:42,325
Speaker 6:  know in its settlement and it's probably that challenging that monopoly.

196
00:11:42,785 --> 00:11:45,925
Speaker 2:  Do you believe Tim Sweeney when he makes these sort of grand pronouncements?

197
00:11:46,005 --> 00:11:49,645
Speaker 2:  I mean I think one way to look at this is just two very greedy companies

198
00:11:49,805 --> 00:11:52,965
Speaker 2:  fighting over money, right? Like big company wants to keep its money, other

199
00:11:53,120 --> 00:11:57,005
Speaker 2:  big company wants to take some who wins like the Occam's razor version of

200
00:11:57,005 --> 00:12:00,925
Speaker 2:  this argument is that, but the flip side of this is that Tim Sweeney

201
00:12:00,925 --> 00:12:04,885
Speaker 2:  has said resolutely and for years at this point that this is bigger than

202
00:12:04,885 --> 00:12:08,165
Speaker 2:  Epic, this is bigger than money. This is about like principles

203
00:12:08,745 --> 00:12:12,285
Speaker 2:  and software development and who gets to

204
00:12:12,545 --> 00:12:16,405
Speaker 2:  win in society. And normally I would find that to be

205
00:12:16,645 --> 00:12:20,565
Speaker 2:  nonsense but at this point Tim Sweeney seems maybe more likely than most

206
00:12:20,865 --> 00:12:24,365
Speaker 2:  to not be full of it when he says that. I don't know. What do you think?

207
00:12:24,675 --> 00:12:28,565
Speaker 6:  Yeah, it's hard to read into the hearts and minds of people like this, but

208
00:12:28,945 --> 00:12:32,445
Speaker 6:  if I was Tim Sweeney and I brought this case, these cases

209
00:12:32,735 --> 00:12:36,685
Speaker 6:  three years ago, even if I didn't buy it in the first place, I definitely

210
00:12:36,705 --> 00:12:40,405
Speaker 6:  had convinced myself by now. Yeah. I have internalized these arguments in

211
00:12:40,405 --> 00:12:43,685
Speaker 6:  a way that I literally cannot give them up after being so loud.

212
00:12:44,465 --> 00:12:48,125
Speaker 6:  So like at the forefront of this issue for so long. Yeah,

213
00:12:48,125 --> 00:12:50,925
Speaker 2:  That is fair. And I think at some point you've said it at enough times that

214
00:12:50,925 --> 00:12:53,205
Speaker 2:  you just kind of have to keep saying it. Yeah. Like at some point if he just

215
00:12:53,205 --> 00:12:56,485
Speaker 2:  testifies and he's like, look I just wanna keep our 30%, I I want more money

216
00:12:56,505 --> 00:13:00,005
Speaker 2:  for my shareholders. Like the whole courtroom is just gonna start booing

217
00:13:00,005 --> 00:13:02,285
Speaker 2:  at him and it's, he can't, he can't do that now.

218
00:13:02,555 --> 00:13:06,485
Speaker 6:  Yeah. The thing about this case that I found really interesting back when

219
00:13:06,485 --> 00:13:10,405
Speaker 6:  it was first announced and we had that big like Apple 1984 yeah

220
00:13:10,405 --> 00:13:14,245
Speaker 6:  Epic games thing is that for the past You know how many

221
00:13:14,245 --> 00:13:18,125
Speaker 6:  years I have been waiting for the tech policy arguments that we're having

222
00:13:18,145 --> 00:13:21,685
Speaker 6:  in antitrust content moderation or whatever to have its like net neutrality

223
00:13:21,685 --> 00:13:25,325
Speaker 6:  moment. Like it's 2015 net neutrality 2017 net

224
00:13:25,485 --> 00:13:29,445
Speaker 6:  neutrality moment. And when I saw that video and I thought about You know

225
00:13:29,445 --> 00:13:32,645
Speaker 6:  how big Fortnite was and think about the player base and the people behind

226
00:13:32,645 --> 00:13:36,325
Speaker 6:  it, I really, I really was like, okay, if it's gonna happen, You know in

227
00:13:36,325 --> 00:13:40,165
Speaker 6:  any case in antitrust it's gonna happen right now. Now. And it

228
00:13:40,165 --> 00:13:43,845
Speaker 6:  didn't necessarily happen. I was waiting to see, 'cause You know, if you

229
00:13:44,085 --> 00:13:47,725
Speaker 6:  remember like the old net neutrality stuff like Google's website, You know

230
00:13:48,165 --> 00:13:51,765
Speaker 6:  Reddit's website where it's plastered with all this stuff and just to have

231
00:13:51,765 --> 00:13:54,845
Speaker 6:  like, I mean Epic games, You know in Fortnite the biggest game Yeah You know

232
00:13:54,845 --> 00:13:57,925
Speaker 6:  that so many young people are playing. I was really hoping that we were going

233
00:13:57,925 --> 00:14:01,565
Speaker 6:  to see that and it just, it never grew to that size.

234
00:14:01,945 --> 00:14:05,925
Speaker 6:  It makes me think about You know what would happen, like if we actually

235
00:14:05,945 --> 00:14:09,845
Speaker 6:  did have a bunch of like young kids and teenagers and young people

236
00:14:09,845 --> 00:14:13,605
Speaker 6:  like riled up over app store markets and like how different

237
00:14:13,675 --> 00:14:16,765
Speaker 6:  this would look right now. Yeah. But yeah, I I'm always wait, I'm always

238
00:14:16,765 --> 00:14:20,605
Speaker 6:  looking for that kind of You know emergence of like this as like a, I don't

239
00:14:20,605 --> 00:14:22,845
Speaker 6:  know, like a public protest movement. Yeah,

240
00:14:22,925 --> 00:14:25,925
Speaker 2:  I mean it's really interesting 'cause I think the thing in recent times that

241
00:14:25,925 --> 00:14:29,805
Speaker 2:  has gotten the closest to that was the, the like would be TikTok ban

242
00:14:30,585 --> 00:14:34,525
Speaker 2:  in terms of like real sort of grassroots rage among young people.

243
00:14:34,945 --> 00:14:38,285
Speaker 2:  That's the closest one I've seen is a lot of people fighting about

244
00:14:38,785 --> 00:14:42,605
Speaker 2:  the TikTok ban for creators and for free expression and all this stuff.

245
00:14:42,825 --> 00:14:45,805
Speaker 2:  But the antitrust thing is really interesting to me because it feels like

246
00:14:45,915 --> 00:14:49,845
Speaker 2:  this right now should be the moment you have the US

247
00:14:49,845 --> 00:14:53,805
Speaker 2:  versus Google antitrust trial ongoing. Like as we speak right now

248
00:14:54,225 --> 00:14:58,205
Speaker 2:  you have Epic versus Google another antitrust trial starting right now. You

249
00:14:58,205 --> 00:15:02,005
Speaker 2:  have this suit filed against Amazon that is increasingly

250
00:15:02,025 --> 00:15:05,765
Speaker 2:  the more we learn about it, the weirder and sketchier and more problematic

251
00:15:05,765 --> 00:15:09,645
Speaker 2:  and all consuming, it seems this should be the moment where antitrust

252
00:15:09,645 --> 00:15:13,205
Speaker 2:  becomes this like big mainstream, everybody's talking about it

253
00:15:13,335 --> 00:15:17,205
Speaker 2:  issue. I certainly don't see that like in the world. Like the people

254
00:15:17,325 --> 00:15:21,125
Speaker 2:  I talk to are not interested in antitrust legislation at this moment. But

255
00:15:21,235 --> 00:15:24,405
Speaker 2:  also I don't even necessarily get the sense that there's a ton of energy

256
00:15:24,405 --> 00:15:28,365
Speaker 2:  like among politicians and in Washington right now about this. What

257
00:15:28,365 --> 00:15:29,005
Speaker 2:  is going on here?

258
00:15:29,635 --> 00:15:32,445
Speaker 6:  Yeah, so when I'm think I'm going back to

259
00:15:32,445 --> 00:15:36,365
Speaker 6:  20 19, 20 20 in the heat of that election cycle when

260
00:15:36,365 --> 00:15:39,965
Speaker 6:  we were in the heat of the Democratic primary and we had Elizabeth Warren

261
00:15:40,025 --> 00:15:44,005
Speaker 6:  and whoever putting out these giant antitrust packages saying that big tech

262
00:15:44,005 --> 00:15:47,965
Speaker 6:  needs to be broken up, all of a sudden we have people who are taking the

263
00:15:47,965 --> 00:15:51,925
Speaker 6:  thoughts of like Lena Kahn and Tim Wu and mainstreaming it in

264
00:15:51,965 --> 00:15:55,165
Speaker 6:  a way that was getting people really, really excited. And

265
00:15:55,865 --> 00:15:59,405
Speaker 6:  as legislation got introduced and as that

266
00:15:59,405 --> 00:16:02,805
Speaker 6:  continued to move in Congress, I think there was one bill that got passed

267
00:16:02,985 --> 00:16:06,725
Speaker 6:  and it was just like a merger filing fee thing, right? Sure. And so it

268
00:16:06,725 --> 00:16:10,565
Speaker 6:  wasn't that major progress and then a lot of the conversations

269
00:16:10,585 --> 00:16:14,285
Speaker 6:  around this has been, okay, well we will wait and see what the

270
00:16:14,285 --> 00:16:18,005
Speaker 6:  courts do You know to see what legislation is necessary

271
00:16:18,145 --> 00:16:21,485
Speaker 6:  for this You know, you would think that people would be paying maybe a bit

272
00:16:21,485 --> 00:16:25,365
Speaker 6:  more closer attention You know to this and maybe talking about it a bit more.

273
00:16:25,825 --> 00:16:29,725
Speaker 6:  But I, it seems like people are just kind of getting ready to see what

274
00:16:29,725 --> 00:16:33,325
Speaker 6:  happens And, what steps that they should take. I know I've been trying to

275
00:16:33,325 --> 00:16:37,125
Speaker 6:  check in and I, there's like bills, like the open apps market act and that

276
00:16:37,125 --> 00:16:39,765
Speaker 6:  would open up the marketplaces. This was something that came out of You know

277
00:16:39,765 --> 00:16:43,565
Speaker 6:  all of these apps store suits. There was that piece of legislation,

278
00:16:43,585 --> 00:16:46,965
Speaker 6:  it didn't really go anywhere. I've heard some stuff about them reworking

279
00:16:46,965 --> 00:16:50,845
Speaker 6:  that and then reintroducing it at some point in time. But again, maybe they're

280
00:16:50,845 --> 00:16:54,485
Speaker 6:  waiting to see what happens in the Google case. It's really unclear to me

281
00:16:54,485 --> 00:16:54,805
Speaker 6:  right now.

282
00:16:54,955 --> 00:16:58,365
Speaker 2:  Yeah, it does seem like there was this underlying argument for a while that

283
00:16:58,955 --> 00:17:02,685
Speaker 2:  Lena Khan in particular was ready to lose some of these

284
00:17:02,755 --> 00:17:06,365
Speaker 2:  antitrust fights in order to make broader, longer term

285
00:17:06,475 --> 00:17:09,645
Speaker 2:  legislative changes. That it's like you need a different kind of precedent

286
00:17:09,645 --> 00:17:13,565
Speaker 2:  and a different kind of case if we're gonna start to make Congress

287
00:17:13,565 --> 00:17:17,405
Speaker 2:  make laws in order to win these fights that the FTC can't win based on

288
00:17:17,405 --> 00:17:20,845
Speaker 2:  like hundred year old law that had nothing to do with tech companies and

289
00:17:21,585 --> 00:17:25,325
Speaker 2:  so far it doesn't seem to have happened. I understand that it's a long game

290
00:17:25,345 --> 00:17:28,165
Speaker 2:  and I feel like one thing you've drilled into my head on this show over and

291
00:17:28,165 --> 00:17:31,885
Speaker 2:  over is that there's just only so much time and

292
00:17:31,885 --> 00:17:35,045
Speaker 2:  energy in Congress to do things and getting anything

293
00:17:35,825 --> 00:17:39,525
Speaker 2:  in tech to be the most important thing at the moment in order for people

294
00:17:39,525 --> 00:17:42,325
Speaker 2:  to actually get something done takes a lot of work. Like I was thinking about

295
00:17:42,325 --> 00:17:45,325
Speaker 2:  this over this weekend because it was daylight saving time and there was

296
00:17:45,325 --> 00:17:47,605
Speaker 2:  the, was it the Sunshine Protection Act every

297
00:17:47,605 --> 00:17:47,845
Speaker 6:  Year?

298
00:17:47,915 --> 00:17:51,485
Speaker 2:  Yeah. Like and as far as I can tell, no one is against this. It's just like

299
00:17:52,105 --> 00:17:56,005
Speaker 2:  no one cares enough to bring it up in Congress and do something about it

300
00:17:56,005 --> 00:17:58,645
Speaker 2:  even though they would be a national hero and they should do something about

301
00:17:58,645 --> 00:18:01,765
Speaker 2:  it. This feels in a certain way, like kind of the same thing. More and more

302
00:18:01,765 --> 00:18:05,245
Speaker 2:  people I think in politics and in the government agree that something should

303
00:18:05,245 --> 00:18:08,285
Speaker 2:  be done and and that changes need to be made. But even right now there's

304
00:18:08,285 --> 00:18:12,005
Speaker 2:  so much more heat on like AI regulation that it just feels like yet

305
00:18:12,005 --> 00:18:15,765
Speaker 2:  again we've bumped what do we do about big tech down the

306
00:18:15,765 --> 00:18:19,605
Speaker 2:  pecking order of tech issues. And I, it just, it feels like as long

307
00:18:19,605 --> 00:18:22,925
Speaker 2:  as it is never the most interesting thing, which if it's not right now, I

308
00:18:22,925 --> 00:18:26,485
Speaker 2:  don't know how it's ever gonna be. It's hard to see what happens there in

309
00:18:26,485 --> 00:18:27,285
Speaker 2:  the immediate future.

310
00:18:27,755 --> 00:18:31,725
Speaker 6:  Yeah. And I do think that there might be a turning point. I

311
00:18:32,065 --> 00:18:35,805
Speaker 6:  was listening to this funny enough AI hearing in the house

312
00:18:35,965 --> 00:18:39,605
Speaker 6:  a couple weeks ago and in it republicans and

313
00:18:39,885 --> 00:18:43,045
Speaker 6:  Democrats were both talking about well okay AI regulation, we need that,

314
00:18:43,345 --> 00:18:46,485
Speaker 6:  but how do we even start thinking about that without a

315
00:18:46,775 --> 00:18:50,205
Speaker 6:  nationwide federal privacy framework? You know some lawmakers are

316
00:18:50,365 --> 00:18:53,165
Speaker 6:  reconsidering like, okay, maybe we need to go back to basics. Things are

317
00:18:53,165 --> 00:18:56,885
Speaker 6:  getting too complicated. We have too many issues. Why don't we attack

318
00:18:56,915 --> 00:19:00,485
Speaker 6:  something that will have maybe the best outcome

319
00:19:00,745 --> 00:19:04,525
Speaker 6:  for consumers and for Americans by like going back and

320
00:19:04,675 --> 00:19:07,845
Speaker 6:  looking at an American You know a federal data privacy law and then maybe

321
00:19:07,845 --> 00:19:11,285
Speaker 6:  going back and like rethinking antitrust more holistically

322
00:19:11,475 --> 00:19:14,845
Speaker 6:  instead of doing these You know these bills that just attack little pieces

323
00:19:15,305 --> 00:19:19,245
Speaker 6:  of this rather than just going after AI like Chuck Schumer and all

324
00:19:19,245 --> 00:19:22,845
Speaker 6:  these AI summits, they've been targeting different things. So there's been

325
00:19:22,845 --> 00:19:26,565
Speaker 6:  like innovation ones and work You know labor and workforce ones.

326
00:19:26,945 --> 00:19:30,805
Speaker 6:  And it just, that almost feels like it's making the issue like too complicated

327
00:19:31,145 --> 00:19:35,125
Speaker 6:  at the same time. Like you're trying to teach lawmakers, You know about AI

328
00:19:35,345 --> 00:19:39,125
Speaker 6:  and then you're just completely inundating them with all this information

329
00:19:39,585 --> 00:19:43,525
Speaker 6:  and like how do you make sense of that and turn You know legislation into

330
00:19:43,525 --> 00:19:47,485
Speaker 6:  that and like decide exactly what to focus on. Of course when it comes to

331
00:19:47,585 --> 00:19:51,565
Speaker 6:  AI regulation then it seems like open AI and all the companies are

332
00:19:51,565 --> 00:19:55,205
Speaker 6:  a bit more concerned with Congress going after election focused stuff

333
00:19:55,985 --> 00:19:59,845
Speaker 6:  and like political ads maybe. But at some point, and I think

334
00:19:59,845 --> 00:20:03,645
Speaker 6:  we're starting to see it now, picking these little fights is not gonna be

335
00:20:03,645 --> 00:20:07,405
Speaker 6:  enough. They're going to have to decide to like come back, lay the foundation

336
00:20:07,785 --> 00:20:09,485
Speaker 6:  and then maybe think about those things later.

337
00:20:10,085 --> 00:20:12,925
Speaker 2:  I totally agree with that, but it does seem like there is a certain element

338
00:20:13,105 --> 00:20:17,085
Speaker 2:  of the perfect being the enemy of the good in all of that. Where

339
00:20:17,085 --> 00:20:20,765
Speaker 2:  it feels like with so many of these conversations, I think data privacy probably

340
00:20:20,765 --> 00:20:24,525
Speaker 2:  chief among them, we've had this debate over and over and it just seems like

341
00:20:24,525 --> 00:20:26,845
Speaker 2:  we land in this place where it's like, well if you can't solve the whole

342
00:20:26,845 --> 00:20:30,245
Speaker 2:  problem we, we don't have anything. And so we've gotten to this point where

343
00:20:30,245 --> 00:20:34,205
Speaker 2:  the only solution is just like we have to rewrite the American constitution

344
00:20:34,225 --> 00:20:37,485
Speaker 2:  to explicitly reference Apple and Google and i's like, well we're not gonna,

345
00:20:37,505 --> 00:20:41,245
Speaker 2:  that's not gonna happen. And so nothing happens and it, it just feels like

346
00:20:41,245 --> 00:20:44,405
Speaker 2:  at some point, one of the things I have thought over the last couple of years

347
00:20:44,465 --> 00:20:48,285
Speaker 2:  is that maybe some of these antitrust fights might be a thing

348
00:20:48,285 --> 00:20:52,245
Speaker 2:  where you can actually pick one chunk of what's going

349
00:20:52,265 --> 00:20:55,245
Speaker 2:  on and do something about it. And part of me, like the, one of the reasons

350
00:20:55,275 --> 00:20:58,885
Speaker 2:  I've been so interested in this us versus Google search defaults thing is

351
00:20:58,885 --> 00:21:02,605
Speaker 2:  like that that is a finite sized thing that you could regulate.

352
00:21:02,605 --> 00:21:06,365
Speaker 2:  Right? And and I think like Benedict Evans, the the venture capitalist said

353
00:21:06,365 --> 00:21:09,085
Speaker 2:  this to me years ago and and I think he's right that it's like we don't regulate

354
00:21:09,085 --> 00:21:12,085
Speaker 2:  cars, we regulate every single thing inside of a car and that's how we regulate

355
00:21:12,085 --> 00:21:15,885
Speaker 2:  cars. His case was that's how we should regulate privacy and the internet.

356
00:21:15,885 --> 00:21:19,085
Speaker 2:  We shouldn't regulate the internet, we should regulate all of the things

357
00:21:19,085 --> 00:21:22,725
Speaker 2:  that happen piece by piece because regulating the internet or

358
00:21:22,735 --> 00:21:26,445
Speaker 2:  technology is impossible and it's too big. And I think with all this

359
00:21:26,445 --> 00:21:30,245
Speaker 2:  antitrust stuff, and I think the, the Epic Apple thing is a good example

360
00:21:30,245 --> 00:21:34,085
Speaker 2:  because anti steering is another tiny sort of finite piece

361
00:21:34,435 --> 00:21:37,805
Speaker 2:  that you can break off and make decisions about that has real meaningful

362
00:21:37,805 --> 00:21:41,485
Speaker 2:  change for the industry. And I guess the question is like can you build up

363
00:21:41,525 --> 00:21:45,325
Speaker 2:  a bunch of those over time or are we eventually gonna need this sort of

364
00:21:45,425 --> 00:21:49,405
Speaker 2:  one big giant sweeping something that just like blows everything up and then

365
00:21:49,405 --> 00:21:53,285
Speaker 2:  we see what happens, which tends to be like every 25 years it seems like

366
00:21:53,285 --> 00:21:55,005
Speaker 2:  we get one of those from the government. Yeah,

367
00:21:55,075 --> 00:21:58,085
Speaker 6:  Well also when it comes to enforcement, I think people have been waiting

368
00:21:58,085 --> 00:22:00,925
Speaker 6:  for that too. Like I think that's why we're waiting on legislation, that's

369
00:22:00,925 --> 00:22:04,525
Speaker 6:  why we're waiting on a lot of things. The problem with enforcement is that

370
00:22:04,525 --> 00:22:07,245
Speaker 6:  our enforcers don't have that many resources.

371
00:22:07,435 --> 00:22:10,565
Speaker 2:  Yeah. They're on like Windows 98 computers trying to figure this out.

372
00:22:10,635 --> 00:22:14,365
Speaker 6:  Exactly. So I, that's one problem. And then even if they do go ahead

373
00:22:14,465 --> 00:22:18,365
Speaker 6:  and win a case that is one company You know, look at I, I like to

374
00:22:18,365 --> 00:22:22,005
Speaker 6:  think about all the stuff Facebook had to agree to

375
00:22:22,385 --> 00:22:25,525
Speaker 6:  You know after Cambridge Analytica, there was some AI stuff in there if I

376
00:22:25,765 --> 00:22:28,605
Speaker 6:  remember correctly and all this kind of stuff in this You know agreement

377
00:22:28,605 --> 00:22:32,405
Speaker 6:  with the FTC. The same thing with Twitter. Twitter with its security and

378
00:22:32,405 --> 00:22:36,365
Speaker 6:  safety practices. The reason why the FTC is investigating Elon Musk's Twitter

379
00:22:36,365 --> 00:22:39,645
Speaker 6:  right now is because of this 2011 consent decree

380
00:22:40,075 --> 00:22:43,965
Speaker 6:  with the agency. You know about these things and it gives them the leverage

381
00:22:43,965 --> 00:22:47,685
Speaker 6:  and the authority to go ahead and reinvestigate, but of course You know it's

382
00:22:47,695 --> 00:22:51,165
Speaker 6:  these specific agreements with specific companies and

383
00:22:51,635 --> 00:22:55,605
Speaker 6:  it's a lot harder right, to do something new or like to continue

384
00:22:55,605 --> 00:22:59,445
Speaker 6:  and like investigate everyone. You have to kind of target the

385
00:22:59,445 --> 00:23:03,205
Speaker 6:  people who you feel are the worst actors and then fix things there.

386
00:23:03,625 --> 00:23:07,165
Speaker 6:  But it You know it's, it's one company. It's maybe setting a standard

387
00:23:07,545 --> 00:23:10,765
Speaker 6:  and like a precedent for how other companies act, but they're not going to

388
00:23:10,765 --> 00:23:13,485
Speaker 6:  be You know breaking the law if they act similarly later.

389
00:23:13,715 --> 00:23:16,645
Speaker 2:  Yeah, that that's very fair. One of the things I think is different about

390
00:23:16,685 --> 00:23:20,605
Speaker 2:  a lot of these fights and Epic versus Google is that this is a

391
00:23:20,635 --> 00:23:23,605
Speaker 2:  jury trial, which strikes me as very different from a lot of the stuff that

392
00:23:23,605 --> 00:23:27,525
Speaker 2:  we've seen, which is not essentially the government arguing one side

393
00:23:27,525 --> 00:23:30,365
Speaker 2:  and the company arguing another side and a judge having to decide who's right.

394
00:23:30,365 --> 00:23:33,965
Speaker 2:  Like that's a, that's a thing we've come to understand. There have been a

395
00:23:33,965 --> 00:23:37,645
Speaker 2:  lot of those, this is just gonna be like a dozen random

396
00:23:37,645 --> 00:23:41,365
Speaker 2:  people off the street who are deciding what's going on here. Is

397
00:23:41,425 --> 00:23:45,405
Speaker 2:  is that potentially as different a thing as it seems like it might be to

398
00:23:45,405 --> 00:23:46,765
Speaker 2:  me in terms of how this case might go?

399
00:23:46,955 --> 00:23:50,805
Speaker 6:  Yeah, I mean like you're saying antitrust trials are typically bench trials,

400
00:23:50,805 --> 00:23:54,245
Speaker 6:  right? Like it is the judge making the decision and I can't remember

401
00:23:54,745 --> 00:23:58,525
Speaker 6:  really anything else in recent history where we've seen this

402
00:23:58,915 --> 00:24:02,485
Speaker 6:  with people being forced to reckon with like Congress

403
00:24:02,855 --> 00:24:06,765
Speaker 6:  can't even make sense of like old antitrust laws and how we should apply

404
00:24:06,765 --> 00:24:10,565
Speaker 6:  them to tech technology companies right now. And hell I have

405
00:24:10,565 --> 00:24:14,525
Speaker 6:  issues with it sometimes too because it's like having faith that

406
00:24:14,545 --> 00:24:18,525
Speaker 6:  You know these attorneys make the proper case and these

407
00:24:18,525 --> 00:24:22,325
Speaker 6:  folks can make the right decision. But again, like your average

408
00:24:22,325 --> 00:24:26,005
Speaker 6:  person is not stupid either. I think what Epic really

409
00:24:26,005 --> 00:24:29,205
Speaker 6:  wants here is to not get into the weeds on the numbers

410
00:24:29,905 --> 00:24:33,525
Speaker 6:  and You know the sheer size and all of these You know very like

411
00:24:33,925 --> 00:24:37,165
Speaker 6:  granular arguments we can have and they probably wanna see You know the the

412
00:24:37,235 --> 00:24:40,765
Speaker 6:  grander argument, the bigger argument how these app markets should

413
00:24:40,795 --> 00:24:44,725
Speaker 6:  operate And, what these You know taxes and fees and all these things mean

414
00:24:44,825 --> 00:24:48,285
Speaker 6:  and how You know the average person like me and you, the average consumer

415
00:24:48,335 --> 00:24:52,325
Speaker 6:  wants to interact with these You know platforms day in and day out. And I

416
00:24:52,325 --> 00:24:55,765
Speaker 6:  think that lends itself better to this. I think it's like a 10 person yeah

417
00:24:56,355 --> 00:24:59,645
Speaker 6:  jury that will start hearing these arguments on Monday.

418
00:25:00,225 --> 00:25:04,045
Speaker 2:  It seems to me, and this is based on nothing but just the gut

419
00:25:04,045 --> 00:25:07,845
Speaker 2:  feeling that I'm having, that the fact that it's a jury trial would stand

420
00:25:07,845 --> 00:25:11,805
Speaker 2:  to benefit Epic a lot more than it would stand to benefit Google because

421
00:25:11,885 --> 00:25:15,605
Speaker 2:  I feel like if I'm the prosecutor, all I have to do now

422
00:25:15,785 --> 00:25:19,645
Speaker 2:  is tell a convincing story basically about David and Goliath,

423
00:25:19,645 --> 00:25:23,325
Speaker 2:  right? About a gigantic tech company that is preventing not just me

424
00:25:23,745 --> 00:25:27,285
Speaker 2:  but I'm fighting on behalf of every small developer everywhere who is having

425
00:25:27,305 --> 00:25:31,165
Speaker 2:  to essentially give a portion of our earnings to the king, right?

426
00:25:31,165 --> 00:25:34,765
Speaker 2:  Like that is borderline on American that that's how we have to do this.

427
00:25:35,145 --> 00:25:38,965
Speaker 2:  And I feel like again, I think you're right, we're gonna get away from a

428
00:25:38,965 --> 00:25:41,885
Speaker 2:  lot of the technicalities and like being in the courtroom for USV Google,

429
00:25:42,025 --> 00:25:45,885
Speaker 2:  it is all about technicalities. Like all they talk about is deal structure

430
00:25:46,265 --> 00:25:50,245
Speaker 2:  and revenue sharing and the like tiny little mechanical economic details

431
00:25:50,245 --> 00:25:53,765
Speaker 2:  of how this stuff works. I would assume, and it's totally possible I end

432
00:25:53,765 --> 00:25:57,645
Speaker 2:  up being wrong that this ends up being a much less technical trial because

433
00:25:57,755 --> 00:26:01,085
Speaker 2:  what they have to do, like you were saying, is essentially tell a story to

434
00:26:01,165 --> 00:26:05,005
Speaker 2:  a jury that is going to have to then apply it to a hundred year old precedent.

435
00:26:05,005 --> 00:26:08,605
Speaker 2:  That arguably doesn't make any sense in the current context and

436
00:26:09,045 --> 00:26:12,125
Speaker 2:  I assume whatever way this goes, it is going to be absolutely ripe for appeal

437
00:26:12,145 --> 00:26:15,405
Speaker 2:  and everything's gonna get weird even more so than most of these cases because

438
00:26:15,435 --> 00:26:18,725
Speaker 2:  it's a jury trial. But it just seems like we're gonna get much more

439
00:26:19,245 --> 00:26:23,125
Speaker 2:  feelings and sort of grand storytelling as opposed to like a parade of

440
00:26:23,265 --> 00:26:26,685
Speaker 2:  expert witnesses telling you how contracts work,

441
00:26:26,815 --> 00:26:30,125
Speaker 6:  Right? I mean it makes the most sense. If I was Epic's attorney right now,

442
00:26:30,125 --> 00:26:33,925
Speaker 6:  that would be my, my approach is focus

443
00:26:33,925 --> 00:26:37,805
Speaker 6:  more on storytelling than like overwhelming people with

444
00:26:37,975 --> 00:26:41,925
Speaker 6:  these ridiculous You know numbers and economic data and everything.

445
00:26:42,355 --> 00:26:45,885
Speaker 2:  Yeah, it's gonna be really interesting to see, I'm sort of sad we're not

446
00:26:45,885 --> 00:26:49,725
Speaker 2:  gonna get as much access to this one as we did Epic v Apple, which you

447
00:26:49,725 --> 00:26:53,645
Speaker 2:  could like because it was covid, it was ironically more publicly available.

448
00:26:53,995 --> 00:26:56,765
Speaker 2:  This one we we're back to much more closed down, but Sean Hollister is gonna

449
00:26:56,765 --> 00:26:59,325
Speaker 2:  be in the courtroom store. We're gonna see a bunch of stuff we are you looking

450
00:26:59,425 --> 00:27:03,405
Speaker 2:  for in in this one? Like is there is, are we looking to see

451
00:27:03,545 --> 00:27:07,485
Speaker 2:  if Epic can get another version of kind of the small wins it got an Apple,

452
00:27:07,865 --> 00:27:11,805
Speaker 2:  is this gonna be a much bigger win or lose? Like how would you sort of

453
00:27:12,005 --> 00:27:13,285
Speaker 2:  handicap the odds here? Yeah,

454
00:27:13,545 --> 00:27:16,765
Speaker 6:  I'd want to first hear the arguments on like you were bringing up earlier

455
00:27:17,055 --> 00:27:20,965
Speaker 6:  about the Samsung store, the ability to load apps and stuff on

456
00:27:20,965 --> 00:27:24,605
Speaker 6:  outside of the Play store. I'm curious how those arguments are made. What

457
00:27:24,605 --> 00:27:28,205
Speaker 6:  we hear from the Judge You know and the You know the mind reading of the

458
00:27:28,205 --> 00:27:32,165
Speaker 6:  jury on that of reporters in the room. And I think that will really

459
00:27:32,175 --> 00:27:35,765
Speaker 6:  color what we can expect because if

460
00:27:35,975 --> 00:27:39,685
Speaker 6:  we're right here and we're talking about You know something that is focused

461
00:27:39,685 --> 00:27:43,405
Speaker 6:  more on storytelling than You know this like granular evidence,

462
00:27:44,045 --> 00:27:47,885
Speaker 6:  I think that is where we are going to get the best idea of what

463
00:27:47,885 --> 00:27:49,285
Speaker 6:  You know this end result will look like.

464
00:27:49,715 --> 00:27:53,525
Speaker 2:  Alright. Sean Hollister is gonna be in the courtroom so we'll grab him on

465
00:27:53,525 --> 00:27:55,845
Speaker 2:  this show at some point in the next, I think this supposed to be five weeks

466
00:27:56,105 --> 00:27:57,405
Speaker 2:  is the plan for this one.

467
00:27:57,555 --> 00:27:59,205
Speaker 6:  Yeah, it's supposed to end right before

468
00:27:59,445 --> 00:28:02,805
Speaker 2:  Christmas. Okay, well God help us all for the next five weeks. I know,

469
00:28:03,745 --> 00:28:06,485
Speaker 2:  but yeah, we'll we'll check back in and, and keep it locked on the site.

470
00:28:06,485 --> 00:28:09,245
Speaker 2:  Sean's gonna be covering it for us. Makena, thank you as always. Yeah,

471
00:28:09,245 --> 00:28:09,605
Speaker 6:  No problem.

472
00:28:10,355 --> 00:28:14,005
Speaker 2:  Alright, we gotta take a break and then we will be back to talk Sam. Bankman

473
00:28:14,005 --> 00:28:15,285
Speaker 2:  free. We'll be right back.

474
00:28:20,565 --> 00:28:24,375
Speaker 7:  Support for this show comes from Wix web agencies. You're gonna like this

475
00:28:24,375 --> 00:28:28,295
Speaker 7:  one. Let me tell you about Wix Studio. The platform that gives agencies total

476
00:28:28,535 --> 00:28:32,175
Speaker 7:  creative freedom to deliver complex client sites while still smashing

477
00:28:32,455 --> 00:28:36,335
Speaker 7:  deadlines. How? First, let's talk about the advanced design capabilities.

478
00:28:36,565 --> 00:28:40,415
Speaker 7:  With Wix Studio you can build unique layouts with a revolutionary grid

479
00:28:40,415 --> 00:28:44,335
Speaker 7:  experience and watch those elements scale proportionally by default. No code

480
00:28:44,335 --> 00:28:48,095
Speaker 7:  animations at sparks of delight while custom CSS gives total design

481
00:28:48,095 --> 00:28:51,535
Speaker 7:  control, but it doesn't stop there. Bring ambitious client projects to life

482
00:28:51,635 --> 00:28:55,175
Speaker 7:  in any industry with a fully integrated suite of business solutions

483
00:28:55,365 --> 00:28:59,095
Speaker 7:  from e-comm to events bookings and more and extend the capabilities

484
00:28:59,095 --> 00:29:02,655
Speaker 7:  even further with hundreds of APIs and integrations and You know what else

485
00:29:02,875 --> 00:29:06,855
Speaker 7:  The workflows, they just make sense. There's the built-in AI

486
00:29:06,855 --> 00:29:10,615
Speaker 7:  tools, the centralized workspace, the on canvas collaborating, the

487
00:29:10,815 --> 00:29:14,415
Speaker 7:  reuse of assets across sites, the seamless client handover. And that's not

488
00:29:14,435 --> 00:29:17,295
Speaker 7:  all. Find out more at Wix dot com slash studio

489
00:29:19,925 --> 00:29:23,895
Speaker 7:  Support for The. Vergecast comes from IRLA new show from Mozilla. For

490
00:29:23,895 --> 00:29:26,775
Speaker 7:  all the noise out there about ai, it's more than worth considering the real

491
00:29:26,775 --> 00:29:30,655
Speaker 7:  people behind it. All policies and practices are taking shape right now.

492
00:29:30,765 --> 00:29:34,335
Speaker 7:  They'll define how we talk about AI for the next generation. The podcast

493
00:29:34,695 --> 00:29:38,255
Speaker 7:  IRL is all about that. It's hosted by Bridget Todd and their current season

494
00:29:38,315 --> 00:29:42,125
Speaker 7:  is all about people over profit. Some questions they tackle. How do you

495
00:29:42,125 --> 00:29:45,885
Speaker 7:  build a truly trustworthy and responsible ai? What does innovation look like

496
00:29:45,885 --> 00:29:49,125
Speaker 7:  when a trillion dollar company and investors aren't calling all the shots

497
00:29:49,385 --> 00:29:53,205
Speaker 7:  and the people come first? In one episode of IRL, you'll hear the stories

498
00:29:53,225 --> 00:29:56,565
Speaker 7:  of people pushing back against companies that hired millions of quote unquote

499
00:29:56,755 --> 00:30:00,285
Speaker 7:  invisible workers. Sometimes for as little as $2 an hour

500
00:30:00,545 --> 00:30:04,205
Speaker 7:  to review toxic disturbing content in order to keep it off. Generative AI

501
00:30:04,205 --> 00:30:08,045
Speaker 7:  like chat GPT, you'll hear about those people developing AI tools that

502
00:30:08,045 --> 00:30:11,885
Speaker 7:  don't rely on putting laborers in those positions. Instead they try to empower

503
00:30:11,905 --> 00:30:14,765
Speaker 7:  the folks working behind the scenes to make machine learning systems that

504
00:30:14,765 --> 00:30:18,605
Speaker 7:  can work for the rest of us. Search for Mozilla IRL in your podcast

505
00:30:18,705 --> 00:30:21,485
Speaker 7:  player or visit irl podcast.org.

506
00:30:27,085 --> 00:30:30,665
Speaker 2:  All right, we're back last week after a truly wild

507
00:30:30,795 --> 00:30:34,745
Speaker 2:  trial that lasted more than a month and a saga in general that lasted

508
00:30:35,005 --> 00:30:38,785
Speaker 2:  almost exactly to the day a year. FTX founder

509
00:30:38,925 --> 00:30:42,865
Speaker 2:  Sam Bankman Freed was found guilty on seven counts, which included wire

510
00:30:42,865 --> 00:30:46,465
Speaker 2:  fraud conspiracy to commit wire fraud and conspiracy to commit money

511
00:30:46,625 --> 00:30:50,545
Speaker 2:  laundering. The short version of a really long story is that SBF was accused

512
00:30:50,565 --> 00:30:54,225
Speaker 2:  and convicted of using Ft X's customer deposits to shore up his crypto

513
00:30:54,225 --> 00:30:58,105
Speaker 2:  trading firm called Alameda Research. Throughout the whole trial, his

514
00:30:58,105 --> 00:31:01,745
Speaker 2:  former colleagues testified that FTX falsified numbers gave

515
00:31:01,985 --> 00:31:05,905
Speaker 2:  Alameda special privileges including to lose billions of dollars and that

516
00:31:05,905 --> 00:31:09,025
Speaker 2:  he lied to the public and users about where their money was.

517
00:31:09,215 --> 00:31:12,865
Speaker 2:  Prosecutors said FTX was a fraud from the start and a jury

518
00:31:12,865 --> 00:31:16,505
Speaker 2:  agreed in a certain sense the SBF story is now over

519
00:31:16,845 --> 00:31:20,145
Speaker 2:  or at least almost over, given that he's set to be sentenced in March. And

520
00:31:20,145 --> 00:31:23,665
Speaker 2:  the verges, Liz Lipato has watched it all go down. She was in the courtroom

521
00:31:23,685 --> 00:31:27,585
Speaker 2:  for the entire trial watching the whole thing unravel So I brought

522
00:31:27,585 --> 00:31:31,305
Speaker 2:  her in to see what she saw, how it felt. And what happens next. Liz.

523
00:31:31,755 --> 00:31:32,105
Speaker 2:  Hello.

524
00:31:32,605 --> 00:31:33,745
Speaker 6:  Hi David. How's it going?

525
00:31:34,165 --> 00:31:35,985
Speaker 2:  You survived. I'm so proud of you.

526
00:31:36,385 --> 00:31:36,905
Speaker 6:  I made it.

527
00:31:37,405 --> 00:31:41,145
Speaker 2:  How do you, how is your like head space after what, six weeks of sitting

528
00:31:41,145 --> 00:31:41,745
Speaker 2:  in a courtroom?

529
00:31:42,285 --> 00:31:46,065
Speaker 6:  Oh man. Well I'm very ready to do something else.

530
00:31:46,615 --> 00:31:50,585
Speaker 6:  Fair. But it was intense. I mean it was like a You know a I

531
00:31:50,585 --> 00:31:53,625
Speaker 6:  wasn't just sitting in the courtroom, I was also standing outside the courtroom

532
00:31:53,685 --> 00:31:57,545
Speaker 6:  at the wee hours of the morning. Many mornings. Yeah. So I.

533
00:31:57,745 --> 00:32:01,065
Speaker 6:  I am excited to have a life again 'cause this was like sort of an aesthetic

534
00:32:01,065 --> 00:32:02,385
Speaker 6:  experience for about a month.

535
00:32:02,535 --> 00:32:05,745
Speaker 2:  Yeah. I do actually wanna talk about the sort of spectacle of this. 'cause

536
00:32:05,785 --> 00:32:09,065
Speaker 2:  I remember one of the things we talked about I think on the show before it

537
00:32:09,065 --> 00:32:12,585
Speaker 2:  started was how much kind of

538
00:32:13,095 --> 00:32:16,465
Speaker 2:  outside interest there was gonna be. Like we, it was obviously gonna be a

539
00:32:16,465 --> 00:32:19,945
Speaker 2:  very high profile trial, but the question of like, are there gonna be crypto

540
00:32:20,285 --> 00:32:24,185
Speaker 2:  fan boys outside the courtroom every morning or like are there gonna

541
00:32:24,185 --> 00:32:26,945
Speaker 2:  be there, there were like the Elizabeth Holmes cosplay that the Theranos

542
00:32:26,945 --> 00:32:30,745
Speaker 2:  trial. Are we gonna get some of that? The only bit of story that I heard

543
00:32:30,805 --> 00:32:34,625
Speaker 2:  was that we literally had to hire a line sitter for you at one point because

544
00:32:34,725 --> 00:32:38,545
Speaker 2:  the line for the Sam bits of testimony was so early

545
00:32:38,855 --> 00:32:42,765
Speaker 2:  that it was like untenable for you to be there early

546
00:32:42,765 --> 00:32:46,005
Speaker 2:  enough to get in line. So like was it like that the whole trial, how crazy

547
00:32:46,065 --> 00:32:46,565
Speaker 2:  did it get?

548
00:32:47,185 --> 00:32:50,605
Speaker 6:  So the Sam testimony was the peak, especially the Sam cross. And

549
00:32:51,185 --> 00:32:54,645
Speaker 6:  the way that line sitter thing worked was like I got in line

550
00:32:55,225 --> 00:32:58,925
Speaker 6:  on Sunday night for Monday. Like I got in line at like,

551
00:32:59,445 --> 00:33:03,165
Speaker 6:  I don't know, 1145 on Sunday night. Good

552
00:33:03,275 --> 00:33:07,165
Speaker 6:  Lord. Because I knew there was going to be a lot of interest and I was to

553
00:33:07,165 --> 00:33:11,045
Speaker 6:  be clear like fourth. Wow. Yeah. So the

554
00:33:11,045 --> 00:33:14,605
Speaker 6:  first person who had gotten there had gotten there around 10 30 and You know

555
00:33:14,665 --> 00:33:18,245
Speaker 6:  the day ended. I was like so tired. I felt drunk and I still had a story

556
00:33:18,245 --> 00:33:21,765
Speaker 6:  to write. Yeah. And I remember going in to

557
00:33:22,355 --> 00:33:25,605
Speaker 6:  like, 'cause nobody's up yet. Like, we're going into the building, it's seven

558
00:33:25,605 --> 00:33:29,445
Speaker 6:  30, the editors haven't logged on. And I was just texting them like, I

559
00:33:29,445 --> 00:33:32,965
Speaker 6:  can't do this Tuesday. Like Tuesday You know I'm gonna, I'm gonna write.

560
00:33:33,105 --> 00:33:36,525
Speaker 6:  And then I, I don't have enough time to like have dinner and sleep because

561
00:33:36,525 --> 00:33:39,485
Speaker 2:  You would literally have to walk out of the courtroom, file your story and

562
00:33:39,485 --> 00:33:40,645
Speaker 2:  then walk back to the courtroom.

563
00:33:40,985 --> 00:33:44,645
Speaker 6:  That's right. So that's how we ended up with a line center on Tuesday. I,

564
00:33:44,805 --> 00:33:48,085
Speaker 6:  I got like six hours of sleep and it was like the best six hours of sleep

565
00:33:48,085 --> 00:33:51,045
Speaker 6:  I've ever had in my life. It was so rewarding. It felt amazing. That's

566
00:33:51,045 --> 00:33:54,205
Speaker 2:  Very good. So it wasn't like that the whole time. That was just the, the

567
00:33:54,305 --> 00:33:54,525
Speaker 2:  Sam

568
00:33:54,955 --> 00:33:58,885
Speaker 6:  Bits. Oh yeah. I mean like You know Caroline Ellison was the other sort

569
00:33:58,885 --> 00:34:02,845
Speaker 6:  of big draw and that was like, that was a much more reasonable 4:00 AM

570
00:34:03,355 --> 00:34:05,965
Speaker 6:  time to get line super chill. There was just, there were a lot of people

571
00:34:05,965 --> 00:34:09,165
Speaker 6:  there. It was, especially for the Sam testimony, there were a lot of people

572
00:34:09,225 --> 00:34:13,205
Speaker 6:  who were You know they worked in tech or they worked in finance or they like

573
00:34:13,205 --> 00:34:17,085
Speaker 6:  had an interest in crypto. A lot of reporters obviously. So

574
00:34:17,085 --> 00:34:20,645
Speaker 6:  there was just a, it was a pretty big draw from the general public and there

575
00:34:20,645 --> 00:34:24,125
Speaker 6:  were like a couple of people who were in town from

576
00:34:24,465 --> 00:34:28,365
Speaker 6:  London or from Ireland who had stopped by the

577
00:34:28,365 --> 00:34:31,845
Speaker 6:  trial. And so that was like pretty remarkable to me. It

578
00:34:31,845 --> 00:34:33,485
Speaker 2:  Was like a tourist attraction. Yeah.

579
00:34:34,025 --> 00:34:37,965
Speaker 6:  So there was absolutely, there was a certain amount of like spectacle.

580
00:34:37,965 --> 00:34:40,805
Speaker 6:  There weren't any cos players like there were at the Holmes trial. We didn't

581
00:34:40,805 --> 00:34:44,285
Speaker 6:  see like You know the art students who were setting up like

582
00:34:44,445 --> 00:34:48,365
Speaker 6:  Theranos themed like gift shops or anything like that. But there was

583
00:34:48,685 --> 00:34:52,645
Speaker 6:  some very, very intense interest from a lot of people who

584
00:34:52,665 --> 00:34:54,485
Speaker 6:  had been following this. That's

585
00:34:54,635 --> 00:34:58,125
Speaker 2:  Just nuts. So, and I'm, I'm particularly curious, we've obviously, we know

586
00:34:58,125 --> 00:35:01,645
Speaker 2:  how the trial ended, which we're gonna get to in a minute, but I'm, I'm super

587
00:35:01,645 --> 00:35:04,445
Speaker 2:  curious about the vibes in the courtroom, which I feel like is one of the

588
00:35:04,445 --> 00:35:08,325
Speaker 2:  things you wrote a lot about was you spent a lot of time watching

589
00:35:08,385 --> 00:35:12,205
Speaker 2:  one person's testimony while watching somebody else just sort of be in the

590
00:35:12,205 --> 00:35:15,685
Speaker 2:  courtroom. That's right. And especially Sam and

591
00:35:16,365 --> 00:35:19,645
Speaker 2:  Caroline for a chunk of it. And Sam's parents, I feel like were kind of your

592
00:35:19,645 --> 00:35:22,925
Speaker 2:  main characters for obvious reasons throughout the whole trial. And I'm really

593
00:35:22,925 --> 00:35:26,765
Speaker 2:  curious how the kind of vibes shifted from the beginning

594
00:35:26,765 --> 00:35:30,245
Speaker 2:  of the trial to the end of the trial just as like a person in the room in

595
00:35:30,245 --> 00:35:30,685
Speaker 2:  the courtroom.

596
00:35:31,105 --> 00:35:33,925
Speaker 6:  So this is why I wanted to be in the courtroom is that there are things that

597
00:35:33,925 --> 00:35:37,885
Speaker 6:  play really differently in the courtroom than they do even in the overflow

598
00:35:37,885 --> 00:35:41,725
Speaker 6:  rooms or in the transcript or on Twitter. And I was really struck by

599
00:35:41,725 --> 00:35:45,165
Speaker 6:  that throughout this trial. You know we had moments of levity that like people

600
00:35:45,185 --> 00:35:48,725
Speaker 6:  didn't think were funny outside of the courtroom, for instance. So like the

601
00:35:48,725 --> 00:35:52,285
Speaker 6:  best example was when Sam was testifying and his lawyer successfully

602
00:35:52,285 --> 00:35:56,165
Speaker 6:  objected to a question and Sam responded anyway that he

603
00:35:56,165 --> 00:35:59,805
Speaker 6:  thought You know embezzling money was not protecting customer assets. And

604
00:35:59,805 --> 00:36:02,285
Speaker 6:  his lawyer was kinda like, Sam, you've been here for a couple weeks, You

605
00:36:02,285 --> 00:36:05,325
Speaker 6:  know you don't have to answer that. And Sam was like, yeah, but I, I felt

606
00:36:05,325 --> 00:36:08,245
Speaker 6:  like it was important. And that was like a big laugh line in the courtroom.

607
00:36:08,545 --> 00:36:12,325
Speaker 6:  And the way that it seemed to play elsewhere was that he was getting scolded,

608
00:36:12,735 --> 00:36:16,565
Speaker 6:  which like, it was like a little bit of a scolding, but it was, it was playful

609
00:36:16,705 --> 00:36:20,685
Speaker 6:  You know. So there were these moments that I i, that's part of the

610
00:36:20,685 --> 00:36:24,365
Speaker 6:  reason why I was getting up at those kind of insane hours was I wanted to

611
00:36:24,545 --> 00:36:28,085
Speaker 6:  really sort of describe what was happening in the room because

612
00:36:28,745 --> 00:36:32,045
Speaker 6:  the text only version of that doesn't give you how people are feeling.

613
00:36:32,865 --> 00:36:36,805
Speaker 6:  And part of it was that I wanted to keep an eye on the jury and by the

614
00:36:36,865 --> 00:36:40,765
Speaker 6:  end of the prosecution's case, the jury was really fed up with Sam

615
00:36:40,765 --> 00:36:44,365
Speaker 6:  Bankman Fried. And this was before he took the stand. I wanna be clear. Yeah.

616
00:36:44,365 --> 00:36:48,325
Speaker 6:  Like You know we have, we have Caroline testifying to You

617
00:36:48,325 --> 00:36:52,245
Speaker 6:  know the sort of arc of her, her time at Alameda and ending

618
00:36:52,315 --> 00:36:55,365
Speaker 6:  with this all hands meeting where she essentially confesses to her staff

619
00:36:55,365 --> 00:36:58,845
Speaker 6:  what has happened. And then immediately afterwards we have Christian

620
00:36:58,945 --> 00:37:02,565
Speaker 6:  droppy getting up on the stand. He's a former

621
00:37:03,045 --> 00:37:06,725
Speaker 6:  employee, he's got the recording of her You know doing it.

622
00:37:07,185 --> 00:37:11,165
Speaker 6:  And the jury was really wrapped for that. I know that it played

623
00:37:11,245 --> 00:37:14,205
Speaker 6:  a little differently again for other people who like was like, oh, she's

624
00:37:14,205 --> 00:37:18,045
Speaker 6:  like giggling You know. But the jury was absolutely locked

625
00:37:18,065 --> 00:37:20,605
Speaker 6:  in You know this was something that they took very seriously. And part of

626
00:37:20,605 --> 00:37:23,365
Speaker 6:  the reason he had been called was to talk about the way that she was speaking

627
00:37:23,365 --> 00:37:26,965
Speaker 6:  on the tape. He, he noted that she has a habit of giggling

628
00:37:27,035 --> 00:37:30,845
Speaker 6:  nervously. Like when there are times of tension, she, she tends to laugh

629
00:37:30,845 --> 00:37:34,165
Speaker 6:  uncomfortably and like, so that was part of the reason I think that he was

630
00:37:34,165 --> 00:37:37,965
Speaker 6:  giving the ta that testimony was to to say like, she's not laughing like

631
00:37:38,025 --> 00:37:41,765
Speaker 6:  out of joy or anything. Like this is a, a very uncomfortable moment for her.

632
00:37:41,765 --> 00:37:45,205
Speaker 6:  Nice. Right. As that tape was playing, I was watching members of the jury

633
00:37:45,235 --> 00:37:49,205
Speaker 6:  like shaking their heads Mm. Like no. And like

634
00:37:49,485 --> 00:37:52,405
Speaker 6:  I saw them shake their heads again at the sort of towards the end of the

635
00:37:52,405 --> 00:37:55,845
Speaker 6:  prosecution's case where can's son, who is one of

636
00:37:56,185 --> 00:38:00,125
Speaker 6:  the FTX lawyers was testifying that Sam, Beckman Fried had come

637
00:38:00,125 --> 00:38:03,365
Speaker 6:  to him and talked about wanting to find an excuse to give

638
00:38:03,905 --> 00:38:07,725
Speaker 6:  Apollo the private equity group. He was trying to raise money from an

639
00:38:07,725 --> 00:38:11,685
Speaker 6:  explanation legally for how all of this money had gone missing. And

640
00:38:11,985 --> 00:38:14,805
Speaker 6:  Kane's Sun like ran through three explanations. It was like none of them,

641
00:38:15,275 --> 00:38:18,405
Speaker 6:  none of them do it. Like, and then he quit. Oh boy. And

642
00:38:19,395 --> 00:38:23,125
Speaker 6:  this, this is sort of a recurring theme. Yeah. You know. We immediately saw

643
00:38:23,825 --> 00:38:27,405
Speaker 6:  Sam Bick Madre in a December interview with George Stephanopoulos

644
00:38:27,405 --> 00:38:31,085
Speaker 6:  running through one of these explanations and saying, oh it was the margin

645
00:38:31,085 --> 00:38:34,965
Speaker 6:  lending program, which Canson had been very clear with him. Like it was so

646
00:38:35,085 --> 00:38:38,965
Speaker 6:  much more money than was in the margin lending program. There's no good explanation

647
00:38:38,965 --> 00:38:41,925
Speaker 6:  for this. And again, during this video clip you could see members of the

648
00:38:41,925 --> 00:38:45,365
Speaker 6:  jury like shaking their heads like, no, like this, this is,

649
00:38:45,635 --> 00:38:49,485
Speaker 6:  this is ridiculous. So there was sort of You know this sense

650
00:38:49,485 --> 00:38:53,245
Speaker 6:  of almost absurdity Hmm. By the end of the prosecution's

651
00:38:53,405 --> 00:38:56,925
Speaker 6:  case because every day I would come in and then there would be like

652
00:38:57,365 --> 00:39:01,325
Speaker 6:  a new crime. And like at one point I remember turning

653
00:39:01,325 --> 00:39:03,725
Speaker 6:  to another reporter, like when we were standing in line and being like, look,

654
00:39:03,765 --> 00:39:06,885
Speaker 6:  I knew he was guilty but didn didn't know. He was like guilty. Guilty. He

655
00:39:06,885 --> 00:39:10,645
Speaker 6:  is like guiltier than I thought. The prosecution easily could have arrested

656
00:39:10,645 --> 00:39:14,445
Speaker 6:  their case after the second week and we had two more weeks. So

657
00:39:14,505 --> 00:39:17,845
Speaker 6:  it was, it was a lot of evidence. It was really like an overwhelming amount

658
00:39:17,845 --> 00:39:21,725
Speaker 6:  of evidence. And You know by the end we had a pretty good idea of what

659
00:39:21,725 --> 00:39:25,565
Speaker 6:  had happened. And then I guess the idea behind Sam testifying is

660
00:39:25,715 --> 00:39:29,205
Speaker 6:  sort of something that you get in these white collar cases where intent really

661
00:39:29,205 --> 00:39:32,485
Speaker 6:  matters. You may remember that Elizabeth Holmes testified in her own trial

662
00:39:32,545 --> 00:39:36,285
Speaker 6:  too. Yep. And who can speak to the intent better than the person who

663
00:39:36,745 --> 00:39:37,805
Speaker 6:  is is there

664
00:39:38,105 --> 00:39:41,845
Speaker 2:  And the defense just a button on that the, the defense in that case

665
00:39:41,875 --> 00:39:45,765
Speaker 2:  basically is either I didn't know or I

666
00:39:45,765 --> 00:39:49,685
Speaker 2:  didn't mean to essentially Right. Because it, it kind of boils down to like,

667
00:39:49,685 --> 00:39:52,845
Speaker 2:  did you do this on purpose or not? And if you can convincingly say you didn't

668
00:39:52,845 --> 00:39:54,725
Speaker 2:  do it on purpose, you might get away with it.

669
00:39:54,905 --> 00:39:58,245
Speaker 6:  That's right. Good intentions are a complete defense. Like it's not illegal

670
00:39:58,245 --> 00:40:01,925
Speaker 6:  to be an idiot, which is lucky for me. The lying is the illegal part.

671
00:40:01,955 --> 00:40:04,885
Speaker 6:  It's not that he lost all this money, it's that he lied to people. That's

672
00:40:04,885 --> 00:40:08,805
Speaker 6:  the fraud piece of it. So if he had believed what he was saying,

673
00:40:08,945 --> 00:40:12,845
Speaker 6:  if he hadn't known that it was untrue, that would be a complete

674
00:40:12,845 --> 00:40:16,725
Speaker 6:  defense. That would be enough. And the problem with putting your defendant

675
00:40:16,785 --> 00:40:20,445
Speaker 6:  on the stand in that way is you open them up to cross examination

676
00:40:20,865 --> 00:40:24,765
Speaker 6:  and that can be really gnarly. And that was really gnarly. Like that was,

677
00:40:25,635 --> 00:40:29,245
Speaker 6:  I've seen a lot of cross examinations and that was probably the nastiest

678
00:40:29,245 --> 00:40:33,045
Speaker 6:  I think I've ever seen. Wow. Danielle Sassoon, who was the prosecutor, she

679
00:40:33,045 --> 00:40:36,965
Speaker 6:  clearly knew just backwards and forwards everything Sam, begman,

680
00:40:36,965 --> 00:40:40,165
Speaker 6:  Fried had ever said in public. Just like all indexed in her brain.

681
00:40:40,295 --> 00:40:44,005
Speaker 2:  Which is a lot by the way that man has talked in public so much.

682
00:40:44,825 --> 00:40:48,605
Speaker 6:  So much. Yeah. So we had, we had like a long section of her saying,

683
00:40:48,705 --> 00:40:51,885
Speaker 6:  did you say this? And him being like, I don't recall. And then her playing

684
00:40:51,885 --> 00:40:55,685
Speaker 6:  it and then her saying, did you say this? And him saying, I don't recall.

685
00:40:55,825 --> 00:40:59,565
Speaker 6:  And her playing it, oh boy You know, it was like a couple hours of this

686
00:40:59,865 --> 00:41:03,485
Speaker 6:  and it really established him as like an unreliable narrator. Particularly

687
00:41:03,725 --> 00:41:07,685
Speaker 6:  because he wasn't saying something like, I don't remember saying that specifically,

688
00:41:07,705 --> 00:41:11,045
Speaker 6:  but it sounds like something I would've said. It was just like, I don't recall.

689
00:41:11,125 --> 00:41:14,005
Speaker 6:  I don't recall. I don't recall. And like after a certain point again you

690
00:41:14,005 --> 00:41:17,445
Speaker 6:  see like the jury starting to make like prolonged eye contact with each other.

691
00:41:17,475 --> 00:41:20,725
Speaker 6:  Like You know when somebody's misbehaving on the subway and you make eye

692
00:41:20,725 --> 00:41:23,885
Speaker 6:  contact with a stranger. Like do you see the shit? Yeah. Like it was very

693
00:41:23,885 --> 00:41:27,845
Speaker 6:  that so that was not great. No and it's

694
00:41:27,845 --> 00:41:28,965
Speaker 6:  not what you want. It's not

695
00:41:29,195 --> 00:41:32,685
Speaker 2:  Well and it also seems like that specific thing is part of the shift

696
00:41:33,085 --> 00:41:36,285
Speaker 2:  I think that you covered in a lot of your stories is like at the beginning

697
00:41:36,285 --> 00:41:39,485
Speaker 2:  of the trial, Sam thought and a big part of his whole

698
00:41:39,985 --> 00:41:43,885
Speaker 2:  shtick had been that you can get an awfully long way with

699
00:41:43,995 --> 00:41:47,445
Speaker 2:  this kind of moppy haired, slightly

700
00:41:47,985 --> 00:41:51,965
Speaker 2:  spacey genius weirdo. And that that affectation ironically, like

701
00:41:52,085 --> 00:41:54,165
Speaker 2:  you and I have been covering this space a long time, like there's no better

702
00:41:54,165 --> 00:41:57,885
Speaker 2:  way to be a billionaire than to have that specific deal. People

703
00:41:57,885 --> 00:42:01,685
Speaker 2:  will just throw money at you if you seem like you don't care how you dress

704
00:42:01,705 --> 00:42:04,485
Speaker 2:  or what you look like or whatever. But then at some point over the course

705
00:42:04,485 --> 00:42:07,285
Speaker 2:  of that trial that went from being like his greatest asset or at least what

706
00:42:07,285 --> 00:42:11,205
Speaker 2:  he thought was his asset to like the thing that destroyed him in a

707
00:42:11,205 --> 00:42:11,565
Speaker 2:  lot of ways

708
00:42:12,385 --> 00:42:16,085
Speaker 6:  So, I wanna put a little button on that. It's not people that will give you

709
00:42:16,085 --> 00:42:19,965
Speaker 6:  a lot of money, it's specifically VCs that will give you a lot of money.

710
00:42:20,185 --> 00:42:21,685
Speaker 2:  That's a very good distinction. Yes.

711
00:42:22,625 --> 00:42:25,885
Speaker 6:  VCs have like a specific model of what they think a genius looks like. And

712
00:42:26,265 --> 00:42:29,965
Speaker 6:  he played very much into that. The problem is if you are

713
00:42:29,965 --> 00:42:33,605
Speaker 6:  marketing yourself as a genius, if you're saying you're brilliant, if you

714
00:42:33,945 --> 00:42:37,725
Speaker 6:  You know are putting yourself forth as like someone who is really, really

715
00:42:37,725 --> 00:42:41,445
Speaker 6:  smart, you have a harder time showing

716
00:42:41,685 --> 00:42:44,245
Speaker 6:  yourself to be stupid. Like, I mean that's like part of what's going on here,

717
00:42:44,245 --> 00:42:47,605
Speaker 6:  right? Like he doesn't have ACFO at this company even though

718
00:42:47,955 --> 00:42:51,005
Speaker 6:  it's a financial company. And that's like very important. He doesn't have

719
00:42:51,005 --> 00:42:54,885
Speaker 6:  any risk management, which you're running a futures exchange risk

720
00:42:54,885 --> 00:42:58,805
Speaker 6:  is what you do. Yeah. And trying to, to hold those two things

721
00:42:59,005 --> 00:43:02,045
Speaker 6:  together in your mind that this guy's a genius and that there's no risk management,

722
00:43:02,045 --> 00:43:05,605
Speaker 6:  there's no CFO, there are no no adults in the room that

723
00:43:05,805 --> 00:43:09,085
Speaker 6:  starts to look damning, that starts to look like you did something on purpose.

724
00:43:09,345 --> 00:43:12,805
Speaker 6:  It starts to look like you don't want risk management because you think risk

725
00:43:12,805 --> 00:43:16,605
Speaker 6:  management won't approve of what you did. And so that's sort of,

726
00:43:16,685 --> 00:43:20,125
Speaker 6:  I think one of the specific ways where this backfired. Like I

727
00:43:20,455 --> 00:43:23,245
Speaker 6:  think that there could have been a lot more understanding

728
00:43:24,345 --> 00:43:27,965
Speaker 6:  if he had been an ordinary person. Ironically

729
00:43:28,305 --> 00:43:32,085
Speaker 6:  You know where it's like, oh yeah, ordinarily ordinary people like misplaced

730
00:43:32,085 --> 00:43:35,805
Speaker 6:  things. Like they'd sometimes do dumb stuff. But You know if you're presenting

731
00:43:36,005 --> 00:43:39,805
Speaker 6:  yourself as like this genius and he was You know, he was leaning very

732
00:43:39,805 --> 00:43:43,565
Speaker 6:  heavily on like having gone to MIT having

733
00:43:43,565 --> 00:43:46,925
Speaker 6:  worked at Jane Street, which is a pretty exclusive firm on Wall Street,

734
00:43:47,225 --> 00:43:50,725
Speaker 6:  having been this like startup founder having done this incredible like

735
00:43:50,795 --> 00:43:54,325
Speaker 6:  arbitrage trade to get his money. Like if your whole

736
00:43:54,535 --> 00:43:58,125
Speaker 6:  story is that you're brilliant and then $8 billion

737
00:43:58,435 --> 00:44:01,685
Speaker 6:  goes missing, people are not going to think you lost it.

738
00:44:01,915 --> 00:44:05,885
Speaker 2:  Yeah. And then a bunch of people get up on the stand and testify how you

739
00:44:06,065 --> 00:44:06,405
Speaker 2:  did it.

740
00:44:06,985 --> 00:44:08,605
Speaker 6:  In fact, you did not lose it. That's right.

741
00:44:08,755 --> 00:44:12,525
Speaker 2:  Yeah. And I think so much of what it seems

742
00:44:12,555 --> 00:44:16,165
Speaker 2:  that he thought, and I, I am curious, like I generally am not

743
00:44:16,165 --> 00:44:20,125
Speaker 2:  interested in trying to like psychoanalyze people in his

744
00:44:20,365 --> 00:44:23,725
Speaker 2:  position, but like my guy just like got up on the stand for three days and

745
00:44:23,725 --> 00:44:27,525
Speaker 2:  did it so we're gonna do it to him. You got the sense he felt like

746
00:44:27,525 --> 00:44:31,405
Speaker 2:  through this whole process he could sort of smart guy his way out

747
00:44:31,405 --> 00:44:34,605
Speaker 2:  of everything. And like, again, not to keep coming back to the Theranos thing,

748
00:44:34,605 --> 00:44:37,805
Speaker 2:  but I think it's like there was this sense of if we can just get away with

749
00:44:37,805 --> 00:44:39,645
Speaker 2:  it long enough, we'll eventually get where we're going and everything will

750
00:44:39,645 --> 00:44:42,565
Speaker 2:  be fine and it'll be worth it. And like that's not even to bring in all of

751
00:44:42,565 --> 00:44:45,725
Speaker 2:  the effective altruism, I'm gonna save the world stuff. Which like I'm just,

752
00:44:45,785 --> 00:44:48,445
Speaker 2:  I'm done with that. Like I don't think, I don't care anymore that he was

753
00:44:48,445 --> 00:44:51,445
Speaker 2:  an effective altruist. I'm no longer interested in that fact about him. But

754
00:44:51,485 --> 00:44:54,805
Speaker 2:  I do think he thought he could just like smart guy his way through these

755
00:44:54,805 --> 00:44:58,325
Speaker 2:  troubles and he was so smart that everything was gonna be fine and

756
00:44:58,675 --> 00:45:02,525
Speaker 2:  that just, it just doesn't work. And I think even in this trial you

757
00:45:02,525 --> 00:45:06,125
Speaker 2:  get the sense that he thought he could just get up there and smart guy his

758
00:45:06,125 --> 00:45:09,525
Speaker 2:  way through it and that he would win in the end. And that was so

759
00:45:09,915 --> 00:45:13,685
Speaker 2:  spectacularly the wrong call in this trial it seems.

760
00:45:14,325 --> 00:45:17,365
Speaker 6:  I mean, watching his parents during the cross-examination was

761
00:45:18,105 --> 00:45:18,325
Speaker 6:  sad

762
00:45:18,745 --> 00:45:19,085
Speaker 2:  I'm sure.

763
00:45:19,385 --> 00:45:23,165
Speaker 6:  And they, they left for the end of it. And I don't blame them

764
00:45:23,165 --> 00:45:26,925
Speaker 6:  because it was, it was really nasty. It was

765
00:45:27,005 --> 00:45:30,405
Speaker 6:  obvious what was happening. It was obvious what the outcome was going to

766
00:45:30,405 --> 00:45:34,285
Speaker 6:  be and I wouldn't wanna watch that happen to my child either. But it

767
00:45:34,285 --> 00:45:38,005
Speaker 6:  felt like throughout the course of the trial there was like

768
00:45:38,205 --> 00:45:42,165
Speaker 6:  a delusion almost on at least Sam's part and maybe the part of his

769
00:45:42,165 --> 00:45:46,005
Speaker 6:  parents as well that You know everything was going to be okay

770
00:45:46,005 --> 00:45:49,205
Speaker 6:  because Sam was a really good guy and he never would've done anything wrong.

771
00:45:49,745 --> 00:45:53,645
Speaker 6:  And that was, as far as I could tell, the entire defense

772
00:45:53,905 --> 00:45:57,885
Speaker 6:  was like You know Sam talked about how he didn't drink when

773
00:45:57,885 --> 00:46:01,565
Speaker 6:  he was in college and he You know, liked to play board

774
00:46:01,565 --> 00:46:05,085
Speaker 6:  games and he was very wholesome and like

775
00:46:05,465 --> 00:46:09,365
Speaker 6:  You know he was, he's a good boy. And I

776
00:46:09,365 --> 00:46:13,045
Speaker 6:  think there was an understanding that Bateman Fried has of

777
00:46:13,045 --> 00:46:16,365
Speaker 6:  himself and that his parents have of him that ran pretty much

778
00:46:16,645 --> 00:46:20,325
Speaker 6:  headlong into the rest of the world and the way the rest of the world

779
00:46:20,325 --> 00:46:24,245
Speaker 6:  understood him to be working. And certainly by the time of the

780
00:46:24,245 --> 00:46:26,845
Speaker 6:  closing statements, I think everybody understood what was going to happen.

781
00:46:27,485 --> 00:46:31,085
Speaker 2:  I was just about to ask that, like at what point did the whole room sort

782
00:46:31,085 --> 00:46:35,045
Speaker 2:  of realize, oh, he's gonna be convicted. Was it closing arguments? I

783
00:46:35,045 --> 00:46:37,445
Speaker 2:  kind of felt like reading your stories, it felt like it might've happened

784
00:46:37,445 --> 00:46:38,085
Speaker 2:  before that.

785
00:46:38,465 --> 00:46:42,405
Speaker 6:  It definitely happened before that for me. Okay. I think it happened before

786
00:46:42,405 --> 00:46:45,565
Speaker 6:  that for several members of the jury, they weren't out very long. They were

787
00:46:45,565 --> 00:46:47,845
Speaker 6:  out for four and a half hours. That's not a long time.

788
00:46:48,265 --> 00:46:51,445
Speaker 2:  No, that's long enough to like have a coffee, look around the room and be

789
00:46:51,445 --> 00:46:54,805
Speaker 2:  like, we good. And then go back in. Like that's not, that's not a group of

790
00:46:54,805 --> 00:46:57,325
Speaker 2:  people who had a lot to talk about for four hours.

791
00:46:57,845 --> 00:47:01,045
Speaker 6:  I mean they did, they did send in for like a couple of questions. They had

792
00:47:01,045 --> 00:47:04,325
Speaker 6:  some questions around the investor testimony they wanted portions of that

793
00:47:04,355 --> 00:47:08,285
Speaker 6:  sent in. But that was fast. You know something like this, a

794
00:47:08,285 --> 00:47:12,245
Speaker 6:  complicated trial like this. I actually wasn't expecting a verdict until

795
00:47:12,245 --> 00:47:15,085
Speaker 6:  the next week. I was expecting a verdict the following like Monday or Tuesday

796
00:47:16,145 --> 00:47:19,725
Speaker 6:  and we just went right through and that was it. So 8:00 PM like

797
00:47:19,945 --> 00:47:23,485
Speaker 6:  we had a verdict. But the reason I I come back to the, the closing

798
00:47:23,485 --> 00:47:27,245
Speaker 6:  statements was that I was really struck by Sam

799
00:47:27,345 --> 00:47:30,685
Speaker 6:  who had turned towards the jury and So I could see the side of his face

800
00:47:31,385 --> 00:47:35,245
Speaker 6:  and he looked like he either had been crying or was about to cry.

801
00:47:35,345 --> 00:47:39,325
Speaker 6:  You know his nose was red. He, he looked devastated basically.

802
00:47:39,825 --> 00:47:43,045
Speaker 6:  And So I think, that's why I think he knew there was this very emotional

803
00:47:43,045 --> 00:47:46,685
Speaker 6:  moment from him, of his attorney reading this closing

804
00:47:46,685 --> 00:47:50,165
Speaker 6:  statement and him just looking terrified and

805
00:47:50,195 --> 00:47:54,045
Speaker 6:  perhaps crying You know. And his parents throughout seemed

806
00:47:54,045 --> 00:47:57,925
Speaker 6:  really horrified by the testimony. At

807
00:47:57,925 --> 00:48:00,725
Speaker 6:  times You know, I could see his mother with her, her head and her hands.

808
00:48:01,105 --> 00:48:04,565
Speaker 6:  It was rough and You know, one of the sort of recurring themes throughout

809
00:48:04,565 --> 00:48:08,125
Speaker 6:  my cover like coverage is I just couldn't figure out why we were there. Like,

810
00:48:08,125 --> 00:48:11,245
Speaker 6:  I don't know why you, you wouldn't just plead like that's the part that's

811
00:48:11,245 --> 00:48:14,965
Speaker 6:  wild to me, right? Like, okay, maybe you're not gonna get a deal, but

812
00:48:15,145 --> 00:48:18,485
Speaker 6:  if you plead guilty and you throw yourself on the mercy of the judge and

813
00:48:18,485 --> 00:48:22,405
Speaker 6:  you say, I'm very very sorry, I heard a lot of people I did wrong, I wanna

814
00:48:22,405 --> 00:48:25,965
Speaker 6:  be punished. Maybe you get a shorter sentence that way.

815
00:48:26,385 --> 00:48:30,365
Speaker 6:  And even if you don't, you haven't dragged everybody you

816
00:48:30,365 --> 00:48:34,125
Speaker 6:  love through this spectacle of a trial. Because if you think about it, like

817
00:48:34,125 --> 00:48:37,925
Speaker 6:  the scale of destruction here is unusual. I mean,

818
00:48:37,925 --> 00:48:41,445
Speaker 6:  there's obviously all of these customers who've lost money

819
00:48:41,865 --> 00:48:45,765
Speaker 6:  and many of whom maybe don't wanna go public about how much money they've

820
00:48:45,765 --> 00:48:49,725
Speaker 6:  lost because they feel silly about it. But like those people You know they

821
00:48:49,725 --> 00:48:53,445
Speaker 6:  deserve our sympathy. I think the investors who've lost money,

822
00:48:53,785 --> 00:48:57,605
Speaker 6:  the lenders who lost money, like one of them block fi ended

823
00:48:57,605 --> 00:49:01,205
Speaker 6:  up going bankrupt. And it wasn't, this wasn't the only thing that pushed

824
00:49:01,405 --> 00:49:04,965
Speaker 6:  them into bankruptcy, but it sure didn't help You know. And then on top of

825
00:49:04,965 --> 00:49:08,845
Speaker 6:  sort of all of that, like destruction, You know a lot of the

826
00:49:08,985 --> 00:49:12,885
Speaker 6:  FTX employees kept their money on the exchange. So they're the people

827
00:49:13,025 --> 00:49:16,525
Speaker 6:  who are also wrapped up in this bankruptcy. Like they, they, they had no

828
00:49:16,525 --> 00:49:20,205
Speaker 6:  idea most of them that anything was going wrong. That you think about Adam

829
00:49:20,305 --> 00:49:24,205
Speaker 6:  ya DIA's testimony and like there was this horrible sort of

830
00:49:24,205 --> 00:49:27,445
Speaker 6:  moment towards the end of it where one of the text messages he had read to

831
00:49:27,785 --> 00:49:30,485
Speaker 6:  was read aloud. You know it was, he was telling Sam he loved him, he would

832
00:49:30,485 --> 00:49:34,285
Speaker 6:  stand by him, he would try to like fix FTX. And then he found out what had

833
00:49:34,485 --> 00:49:37,525
Speaker 6:  actually happened and he immediately quit. Wow. I want you to think about

834
00:49:37,525 --> 00:49:41,445
Speaker 6:  this. This is like one of Sam's best friends from college. They were like

835
00:49:41,845 --> 00:49:45,685
Speaker 6:  frat boys together. They shared a You know they were roommates in college,

836
00:49:45,685 --> 00:49:49,045
Speaker 6:  they were roommates in The Bahamas. Like this is like one of his closest

837
00:49:49,045 --> 00:49:52,685
Speaker 6:  friends. I want you to just hold that in your mind for a minute. Think about

838
00:49:52,685 --> 00:49:55,885
Speaker 6:  your closest friend and how pissed off they would have to be at you, how

839
00:49:55,885 --> 00:49:59,805
Speaker 6:  betrayed they would have to feel to testify against you at

840
00:49:59,805 --> 00:50:00,085
Speaker 6:  trial.

841
00:50:00,475 --> 00:50:04,325
Speaker 2:  Yeah. And, and there was so much of that. I mean, I think the extent to

842
00:50:04,325 --> 00:50:07,765
Speaker 2:  which, and, and you wrote about this at one point that like, I think you

843
00:50:07,765 --> 00:50:11,045
Speaker 2:  called it like summer camp syndrome. Yeah. That it's just a group of friends

844
00:50:11,585 --> 00:50:15,165
Speaker 2:  who all essentially turned all at once

845
00:50:15,665 --> 00:50:19,365
Speaker 2:  on Sam at the end of this. I, I like, I think you're right. It it is

846
00:50:19,555 --> 00:50:23,085
Speaker 2:  sort of unusual that everybody told the exact same story,

847
00:50:23,375 --> 00:50:27,245
Speaker 2:  which I think in the end made it really easy in a lot of ways. Like

848
00:50:27,245 --> 00:50:30,925
Speaker 2:  the prosecutor's story was so simple and so straightforward and so

849
00:50:31,205 --> 00:50:35,125
Speaker 2:  corroborated by so many people. And then Sam's story was like

850
00:50:35,705 --> 00:50:38,845
Speaker 2:  the Sam's story, but he just said he didn't know about any of it,

851
00:50:39,175 --> 00:50:39,525
Speaker 6:  Right?

852
00:50:39,945 --> 00:50:43,485
Speaker 2:  He, he clearly deserved to be convicted because all the evidence that so,

853
00:50:43,485 --> 00:50:47,405
Speaker 2:  but the it it also just seemed like he was the, the weight of

854
00:50:47,405 --> 00:50:51,365
Speaker 2:  the evidence against him was so sort of uniquely pointed and

855
00:50:51,365 --> 00:50:52,405
Speaker 2:  strong in that sense.

856
00:50:52,795 --> 00:50:56,005
Speaker 6:  Well and even assuming there hadn't been testimony

857
00:50:56,595 --> 00:51:00,485
Speaker 6:  from his conspirators, You know his co-conspirators, all

858
00:51:00,485 --> 00:51:03,285
Speaker 6:  of whom were like, yeah we worked together with Sam on this.

859
00:51:04,315 --> 00:51:08,285
Speaker 6:  Just looking at where the money went and who benefited

860
00:51:08,715 --> 00:51:12,565
Speaker 6:  from that money. Sam benefited more than anyone You know.

861
00:51:12,565 --> 00:51:16,445
Speaker 6:  These were investments that he wanted to make. His parents got a home in

862
00:51:16,445 --> 00:51:20,365
Speaker 6:  The Bahamas and that was traced back to FTX investor money. He got a

863
00:51:20,365 --> 00:51:24,325
Speaker 6:  bunch of Robinhood shares and a personally owned vehicle like

864
00:51:24,635 --> 00:51:28,325
Speaker 6:  just looking at You know who benefits like not even

865
00:51:28,325 --> 00:51:32,205
Speaker 6:  thinking about like the blow by blow of how it happened. It's kind

866
00:51:32,205 --> 00:51:36,045
Speaker 6:  of open and shut. And so to me You know there were all of these

867
00:51:36,045 --> 00:51:39,285
Speaker 6:  moments where I kept being like, why are we here? Like literally why are

868
00:51:39,285 --> 00:51:42,805
Speaker 6:  we here? You know like plead guilty and

869
00:51:43,095 --> 00:51:46,885
Speaker 6:  spare You. know your family and friends this humiliation and maybe they'll

870
00:51:46,885 --> 00:51:47,805
Speaker 6:  come visit you in jail.

871
00:51:48,385 --> 00:51:51,885
Speaker 2:  So speaking of the, the ramifications of all of this, I feel like I've seen

872
00:51:51,985 --> 00:51:55,405
Speaker 2:  two narratives over the last few days start to come out. One is that

873
00:51:55,715 --> 00:51:59,605
Speaker 2:  Silicon Valley, as it does, will just move on. The VC

874
00:51:59,685 --> 00:52:03,605
Speaker 2:  class is not going to do the self introspection that everybody always

875
00:52:03,605 --> 00:52:06,165
Speaker 2:  wants them to do In moments like this. They didn't do it with Theranos, they're

876
00:52:06,165 --> 00:52:08,885
Speaker 2:  not gonna do it now you just move on to the next thing. They're all pouring

877
00:52:08,885 --> 00:52:12,725
Speaker 2:  money into AI stuff. And then on the flip side, there is this sense

878
00:52:12,755 --> 00:52:16,725
Speaker 2:  that this is kind of a broader crypto reckoning. One

879
00:52:16,725 --> 00:52:19,245
Speaker 2:  of the things we talked about at the beginning of the trial was how much

880
00:52:19,665 --> 00:52:23,285
Speaker 2:  crypto industry dirt was gonna come out of this one way or the other about

881
00:52:23,425 --> 00:52:27,085
Speaker 2:  how kind of unwatched and unmanaged a lot of this space is.

882
00:52:27,645 --> 00:52:31,565
Speaker 2:  I have a hard time figuring out kind of what the macro

883
00:52:32,305 --> 00:52:35,805
Speaker 2:  legacy of this trial is gonna be. Do you have a sense even just a few days

884
00:52:35,805 --> 00:52:36,565
Speaker 2:  out? I

885
00:52:36,885 --> 00:52:40,565
Speaker 6:  Think I do. And part of it is because there were crypto industry people who

886
00:52:40,565 --> 00:52:44,085
Speaker 6:  were coming to the trial and so during Gary Wong's

887
00:52:44,285 --> 00:52:47,805
Speaker 6:  testimony about the faked insurance fund,

888
00:52:48,485 --> 00:52:52,045
Speaker 6:  'cause like this was just like Russian nesting dolls of crime.

889
00:52:52,665 --> 00:52:55,565
Speaker 6:  But there, there was a random number generator that they had that was their

890
00:52:55,565 --> 00:52:58,645
Speaker 6:  insurance fund. There was no insurance fund. Alameda was paying stuff out.

891
00:52:59,065 --> 00:53:02,925
Speaker 6:  One of the people who I was talking to who was a crypto investor was like,

892
00:53:02,985 --> 00:53:06,805
Speaker 6:  oh, Binance has an insurance fund. I wonder if that's

893
00:53:06,805 --> 00:53:10,285
Speaker 6:  real too. Mm. Some things that are different, right? Like for instance there

894
00:53:10,285 --> 00:53:14,205
Speaker 6:  are exchanges where You know which ones are the omnibus wallets. You

895
00:53:14,285 --> 00:53:18,165
Speaker 6:  can watch them, you can sort of see on chain what's going on. But there

896
00:53:18,225 --> 00:53:22,165
Speaker 6:  are going to be I think larger questions of who's telling the

897
00:53:22,165 --> 00:53:25,645
Speaker 6:  truth. Because Sam said all the right things in terms of wanting

898
00:53:25,695 --> 00:53:29,525
Speaker 6:  regulation, in terms of trying to be safe and trustworthy for

899
00:53:29,805 --> 00:53:33,605
Speaker 6:  customers. And there is going to be because the scale

900
00:53:33,625 --> 00:53:37,285
Speaker 6:  of this fraud was so enormous. I think there is going to be a question for

901
00:53:37,735 --> 00:53:41,445
Speaker 6:  regulators, for customers, for everyone. The next time someone says

902
00:53:41,445 --> 00:53:45,085
Speaker 6:  something like, oh yeah, we want regulation. Like is that true?

903
00:53:45,785 --> 00:53:49,685
Speaker 6:  Sam said that, is that real? And So I think that that's

904
00:53:49,685 --> 00:53:53,485
Speaker 6:  sort of going to be one of the lingering things from this trial more so than

905
00:53:53,765 --> 00:53:57,405
Speaker 6:  anything else is this. This question of like how

906
00:53:57,405 --> 00:54:01,045
Speaker 6:  trustworthy is the crypto industry? And You know this is an

907
00:54:01,245 --> 00:54:05,165
Speaker 6:  industry that is like very, I think proudly full of pirates.

908
00:54:05,215 --> 00:54:09,125
Speaker 6:  These are people who have been operating in sort of legal gray areas, many

909
00:54:09,125 --> 00:54:12,605
Speaker 6:  of whom were excited about that. And that was like part of the joy

910
00:54:12,785 --> 00:54:16,325
Speaker 6:  almost of the industry for a long time. And now it's cutting the other way

911
00:54:16,325 --> 00:54:18,725
Speaker 6:  where it's like, okay, but like do you wanna give your money to pirates?

912
00:54:18,725 --> 00:54:22,525
Speaker 6:  Right? So, I. I think that that's, that's certainly going to be a

913
00:54:22,525 --> 00:54:26,485
Speaker 6:  long-term ramification. As for the VCs, I don't know. I

914
00:54:26,485 --> 00:54:29,205
Speaker 6:  would like to say that I think it might be different. And part of the reason

915
00:54:29,645 --> 00:54:33,485
Speaker 6:  I might say that is that interest rates have been going up

916
00:54:34,025 --> 00:54:38,005
Speaker 6:  and that means that there's less money sloshing into VC than there

917
00:54:38,005 --> 00:54:41,725
Speaker 6:  used to be. And there was this whole period where they had so much money

918
00:54:41,725 --> 00:54:45,525
Speaker 6:  they had to figure out how to invest it somehow. And so like you had

919
00:54:45,765 --> 00:54:48,005
Speaker 6:  mattress companies that were suddenly tech companies 'cause they were selling

920
00:54:48,005 --> 00:54:51,565
Speaker 6:  stuff online, right? You had WeWork, which to Adam

921
00:54:51,565 --> 00:54:54,325
Speaker 6:  Newman's credit, like that was not a fraud. He told everybody that he was

922
00:54:54,525 --> 00:54:57,925
Speaker 6:  planning to benefit disproportionate from WeWork like that and they, they

923
00:54:57,925 --> 00:55:01,805
Speaker 6:  funded it anyway. So there was this period where like the balance of

924
00:55:01,805 --> 00:55:05,325
Speaker 6:  power had really shifted to founders. There was a real sense of FOMO in the

925
00:55:05,325 --> 00:55:08,685
Speaker 6:  investing community. Then you could sort of pressure them into doing deals

926
00:55:08,685 --> 00:55:12,565
Speaker 6:  without due diligence. And So I think as the money is

927
00:55:12,645 --> 00:55:16,445
Speaker 6:  receding, which it has been and as the valuations are getting

928
00:55:16,545 --> 00:55:20,285
Speaker 6:  cut and as like the tide is kind of going out, I think

929
00:55:20,875 --> 00:55:24,485
Speaker 6:  that as well as the sort of profound embarrassments

930
00:55:24,785 --> 00:55:28,205
Speaker 6:  of these major fraud trials may contribute to

931
00:55:29,155 --> 00:55:32,805
Speaker 6:  more careful evaluation. Do I think that that's a guarantee?

932
00:55:33,545 --> 00:55:37,525
Speaker 6:  No, I don't You know, I, I certainly have heard a lot of

933
00:55:37,755 --> 00:55:41,405
Speaker 6:  wild VC talk about like how Elizabeth Holmes

934
00:55:41,545 --> 00:55:45,445
Speaker 6:  wasn't really a product of Silicon Valley and they didn't really do

935
00:55:45,645 --> 00:55:49,365
Speaker 6:  anything wrong and FGX was a standalone fraud and like

936
00:55:49,425 --> 00:55:52,765
Speaker 6:  You know, I think there's a lot of denial, but I certainly think that

937
00:55:53,215 --> 00:55:56,925
Speaker 6:  among the people who are using VC as an investment

938
00:55:56,955 --> 00:56:00,845
Speaker 6:  vehicle You know whether those are family offices, retirement funds,

939
00:56:01,095 --> 00:56:04,405
Speaker 6:  endowments, whatever. If they provide enough pressure

940
00:56:04,995 --> 00:56:08,925
Speaker 6:  that will change things. And so the question is sort of You know who's upstream

941
00:56:08,925 --> 00:56:12,205
Speaker 6:  from the VCs and how much pressure are they putting on, especially now that

942
00:56:12,325 --> 00:56:16,005
Speaker 6:  we are out of this low interest rate environment and there are less risky

943
00:56:16,005 --> 00:56:17,205
Speaker 6:  places for you to make money.

944
00:56:17,675 --> 00:56:21,125
Speaker 2:  Yeah, my, my only worry about that outcome

945
00:56:21,375 --> 00:56:25,285
Speaker 2:  would be that we've been through this in smaller

946
00:56:25,355 --> 00:56:28,885
Speaker 2:  ways a bunch of times now, right? Like I think if you're still a crypto

947
00:56:29,285 --> 00:56:33,125
Speaker 2:  believer, your tolerance for chaos and risk and fraud is so

948
00:56:33,275 --> 00:56:36,845
Speaker 2:  high at this point that I wonder what would

949
00:56:37,125 --> 00:56:39,965
Speaker 2:  possibly turn you off if you're a person who like earnestly believes that

950
00:56:39,965 --> 00:56:43,765
Speaker 2:  crypto is the future of everything, what on earth is left to convince you?

951
00:56:44,155 --> 00:56:48,045
Speaker 2:  This one's a pretty big one. And I think what it might do to your point

952
00:56:48,265 --> 00:56:51,965
Speaker 2:  is it might instill worry in a lot of

953
00:56:52,465 --> 00:56:56,365
Speaker 2:  people like two concentric circles out from the believers, the

954
00:56:56,365 --> 00:56:58,805
Speaker 2:  kinds of people who were like setting up Coinbase accounts two years ago,

955
00:56:58,805 --> 00:57:02,445
Speaker 2:  right? Who were like, what's this? I'm not like a diamond hands crypto

956
00:57:02,865 --> 00:57:05,845
Speaker 2:  maniac, but I'm just like a person who wants to invest my money. And I think

957
00:57:05,845 --> 00:57:09,805
Speaker 2:  you're definitely right that those people are going to remember FTX in a,

958
00:57:09,825 --> 00:57:13,365
Speaker 2:  in a pretty real and pretty damning way for the crypto industry.

959
00:57:13,595 --> 00:57:17,205
Speaker 6:  Yeah, I think the true believers, I mean the true believers are the true

960
00:57:17,205 --> 00:57:19,885
Speaker 6:  believers. They're still gonna be there. This is an internet subculture that

961
00:57:19,925 --> 00:57:22,805
Speaker 6:  I think we're going to continue to see for a long time. You know they're

962
00:57:22,805 --> 00:57:24,965
Speaker 6:  already talking about the next cycle.

963
00:57:25,275 --> 00:57:26,605
Speaker 2:  Yeah. This is just crypto winter.

964
00:57:26,945 --> 00:57:29,885
Speaker 6:  That's right. So You know, I don't, I don't know that crypto's gone forever.

965
00:57:30,085 --> 00:57:33,445
Speaker 6:  I certainly don't think that's true. And I also think the approval of a Bitcoin

966
00:57:33,605 --> 00:57:36,565
Speaker 6:  ETF, which is something that the crypto community has really been keeping

967
00:57:36,665 --> 00:57:40,485
Speaker 6:  an eye on that might potentially be a help to them. Like that might be

968
00:57:40,485 --> 00:57:43,885
Speaker 6:  something that gets institutional investors involved, You know your

969
00:57:43,935 --> 00:57:47,445
Speaker 6:  BlackRocks and so on. Is that a guarantee? I don't know.

970
00:57:47,615 --> 00:57:51,525
Speaker 6:  Again, we're in a different investing environment now where there are easier

971
00:57:51,675 --> 00:57:55,525
Speaker 6:  ways, less risky ways to make money because part

972
00:57:55,685 --> 00:57:59,365
Speaker 6:  of what really fueled the last boom was that

973
00:58:00,385 --> 00:58:04,365
Speaker 6:  VCs were able to cash out much more quickly in crypto than they were in a

974
00:58:04,365 --> 00:58:08,005
Speaker 6:  lot of other investments. And so that gave them a pretty quick return and

975
00:58:08,005 --> 00:58:11,885
Speaker 6:  that gave them an incentive to work with a lot of crypto companies.

976
00:58:12,705 --> 00:58:16,685
Speaker 6:  And I think that's less true now. So we'll

977
00:58:16,685 --> 00:58:20,405
Speaker 6:  see. You know and I don't, and I don't necessarily mind weird internet subcultures.

978
00:58:20,425 --> 00:58:20,645
Speaker 6:  I'm

979
00:58:20,645 --> 00:58:22,245
Speaker 2:  Those are your people. Yeah. Yeah.

980
00:58:22,405 --> 00:58:24,805
Speaker 6:  I love the crypto True believers, they're a lot of fun to hang out with.

981
00:58:25,405 --> 00:58:28,365
Speaker 6:  I don't necessarily agree with them, but they're a great time You know these

982
00:58:28,365 --> 00:58:32,085
Speaker 6:  people. They're not stupid, they're not, they're smart and thoughtful and

983
00:58:32,085 --> 00:58:34,005
Speaker 6:  they don't like the current financial system.

984
00:58:34,155 --> 00:58:37,965
Speaker 2:  Totally All, right? We have to go and you have to go on vacation,

985
00:58:39,265 --> 00:58:43,245
Speaker 2:  but thank you for coming on. You did truly ridiculous work over the last

986
00:58:43,245 --> 00:58:46,005
Speaker 2:  four weeks, so thank you for all of that and for coming on the show. And

987
00:58:46,285 --> 00:58:48,645
Speaker 2:  I have a feeling we're gonna be doing this again. What is it? In March when

988
00:58:48,645 --> 00:58:50,005
Speaker 2:  sentencing happens, March

989
00:58:50,005 --> 00:58:51,405
Speaker 6:  Is when sentencing happens. It's

990
00:58:51,525 --> 00:58:55,445
Speaker 2:  Right. We are not done with this story just yet, so we'll, we'll we'll do

991
00:58:55,445 --> 00:58:57,125
Speaker 2:  this again, but thanks Liz All,

992
00:58:57,125 --> 00:58:57,725
Speaker 6:  Right? Thank you. David

993
00:58:58,385 --> 00:59:00,925
Speaker 2:  All. right. We gotta take one more break and then we'll get to the Hotline.

994
00:59:06,785 --> 00:59:10,395
Speaker 3:  This podcast is brought to you by Meta Quest three, the new mixed reality

995
00:59:10,395 --> 00:59:14,315
Speaker 3:  headset from Meta. Now you can expand your world in ways you never thought

996
00:59:14,635 --> 00:59:18,555
Speaker 3:  possible with the new Meta Quest three, put on the sleek most powerful

997
00:59:18,715 --> 00:59:22,685
Speaker 3:  quest yet and jump into fully immersive games or blend virtual elements

998
00:59:22,685 --> 00:59:26,365
Speaker 3:  into your physical surroundings with mixed reality. Instantly go from

999
00:59:26,605 --> 00:59:29,285
Speaker 3:  watching to playing the part in your favorite show with Stranger Things vr,

1000
00:59:29,995 --> 00:59:33,245
Speaker 3:  live the action and really feel what it's like to step into the shoes of

1001
00:59:33,245 --> 00:59:36,805
Speaker 3:  an assassin, an Assassin's Creed nexus, even turn your couch

1002
00:59:37,115 --> 00:59:41,045
Speaker 3:  into court side seats with X stadium and watch your favorite NBA

1003
00:59:41,045 --> 00:59:44,965
Speaker 3:  team. With over 500 titles, it's easy to dive into whatever

1004
00:59:44,965 --> 00:59:48,925
Speaker 3:  you're into, expand your world with Meta Quest three, see child

1005
00:59:48,925 --> 00:59:51,525
Speaker 3:  safety guidance online accounts for 10 and up certain apps, games and experiences

1006
00:59:51,525 --> 00:59:54,365
Speaker 3:  may be suitable for a more mature audience. Learn more@meta.com.

1007
00:59:59,595 --> 01:00:03,565
Speaker 8:  Support for this episode comes from Justworks. Hey, small business

1008
01:00:03,565 --> 01:00:07,045
Speaker 8:  leaders, do you ever get tired of doing it all? Do you feel like you're too

1009
01:00:07,045 --> 01:00:10,925
Speaker 8:  busy cutting checks, filing forms and browsing benefits to even think

1010
01:00:10,925 --> 01:00:14,605
Speaker 8:  about the rest of your to-do list. Running a business takes a ton of work,

1011
01:00:14,905 --> 01:00:18,725
Speaker 8:  but you don't have to do it alone. Justworks can handle some of the administrative

1012
01:00:18,725 --> 01:00:22,285
Speaker 8:  work you don't love with their easy to use platform. You can manage

1013
01:00:22,285 --> 01:00:26,205
Speaker 8:  onboarding payroll and PTO all in one place. They specialize

1014
01:00:26,205 --> 01:00:29,965
Speaker 8:  in tackling tough tasks like filing tax documents, generating reports,

1015
01:00:30,225 --> 01:00:33,645
Speaker 8:  and sorting out state by state regulations to help ensure your business stays

1016
01:00:34,005 --> 01:00:37,765
Speaker 8:  compliant so you can focus on doing what you do best. Whether your teams

1017
01:00:37,785 --> 01:00:41,405
Speaker 8:  are remote in person or both, they'll help you find health insurance plans

1018
01:00:41,405 --> 01:00:45,125
Speaker 8:  that meet your needs and your budget. And if that's not enough, their expert

1019
01:00:45,125 --> 01:00:48,365
Speaker 8:  staff is standing by 24 7 to answer any questions.

1020
01:00:48,985 --> 01:00:51,445
Speaker 8:  So if you ever feel like your business is running, you visit

1021
01:00:51,555 --> 01:00:55,485
Speaker 8:  justworks.com/podcast to see how just works can

1022
01:00:55,485 --> 01:00:56,445
Speaker 8:  help you run your business

1023
01:01:04,615 --> 01:01:08,115
Speaker 2:  All, right? We're back. Let's get to The. Vergecast Hotline as always, the

1024
01:01:08,115 --> 01:01:12,035
Speaker 2:  number is eight six six Verge one, one call and ask us all of your weirdest,

1025
01:01:12,035 --> 01:01:15,915
Speaker 2:  deepest, darkest secrets and questions about technology. I don't know

1026
01:01:15,915 --> 01:01:19,355
Speaker 2:  how to ask us a secret, but you can do it if you want to. This week we have

1027
01:01:19,355 --> 01:01:21,835
Speaker 2:  a question about sports. So Richard Lawler is here to help me answer. Hi

1028
01:01:21,835 --> 01:01:22,675
Speaker 2:  Richard. Always

1029
01:01:22,675 --> 01:01:23,635
Speaker 3:  Love to talk sports.

1030
01:01:23,985 --> 01:01:27,435
Speaker 2:  Yeah man, we don't get to do it that often, so when it's just us we get to

1031
01:01:27,435 --> 01:01:29,955
Speaker 2:  talk about sports. This is gonna be a six hour long segment, it's gonna be

1032
01:01:29,955 --> 01:01:33,315
Speaker 2:  great. All, right? Let me just play the question, which I think is a very

1033
01:01:33,315 --> 01:01:34,555
Speaker 2:  fun one and then we're gonna get into it.

1034
01:01:35,895 --> 01:01:39,635
Speaker 9:  Hey David, this is Jeff from North Carolina. I recently listened to

1035
01:01:39,635 --> 01:01:43,475
Speaker 9:  your Friday episode where you were talking about the Hulu deal

1036
01:01:43,705 --> 01:01:47,435
Speaker 9:  with Disney and Comcast and I'm wondering, you mentioned that you think Disney

1037
01:01:47,435 --> 01:01:51,195
Speaker 9:  wants to sell ESPN and I'm curious if you

1038
01:01:51,195 --> 01:01:55,115
Speaker 9:  think that Disney would potentially not sell ESPN

1039
01:01:55,115 --> 01:01:58,915
Speaker 9:  and instead look for a strategic partnership like Apple

1040
01:01:59,615 --> 01:02:03,595
Speaker 9:  to run ESPN with them or do you think ESPN

1041
01:02:03,595 --> 01:02:07,275
Speaker 9:  would ever get sold to Apple altogether? Thanks so much the show.

1042
01:02:07,415 --> 01:02:07,635
Speaker 9:  Bye.

1043
01:02:08,305 --> 01:02:11,795
Speaker 2:  Okay, I love this question because A, it's about ESPN, which I very much

1044
01:02:11,795 --> 01:02:15,475
Speaker 2:  enjoy talking about, but B it brings up, I think a thing you and I have talked

1045
01:02:15,515 --> 01:02:19,445
Speaker 2:  a bunch about, which is why ESPN is kind of a harbinger of

1046
01:02:19,465 --> 01:02:23,365
Speaker 2:  the whole streaming universe. We talked about Disney and Hulu last

1047
01:02:23,365 --> 01:02:27,245
Speaker 2:  week. Disney is gonna be required to pay somewhere north of eight

1048
01:02:27,245 --> 01:02:30,485
Speaker 2:  and a half billion dollars to buy the rest of Hulu. That's very expensive.

1049
01:02:30,625 --> 01:02:34,085
Speaker 2:  Disney is not a company that is full of cash right now. But I'm curious hearing

1050
01:02:34,085 --> 01:02:38,045
Speaker 2:  this question, what if Disney doesn't sell ESPN? Could it sell to Apple?

1051
01:02:38,045 --> 01:02:39,685
Speaker 2:  Could it partner with Apple? What do you think

1052
01:02:40,055 --> 01:02:43,885
Speaker 10:  Apple is the always, oh they could buy it for every

1053
01:02:44,165 --> 01:02:45,245
Speaker 10:  question you ever have. They

1054
01:02:45,245 --> 01:02:45,885
Speaker 2:  Just have all the money

1055
01:02:45,885 --> 01:02:49,245
Speaker 10:  Because they have all of the money, every bit of money that there is

1056
01:02:49,395 --> 01:02:53,085
Speaker 10:  belongs to Apple. Tim Cook is just sitting on it presumably in a cave like

1057
01:02:53,085 --> 01:02:56,965
Speaker 10:  small I assume will they buy it? The answer is

1058
01:02:56,965 --> 01:03:00,605
Speaker 10:  almost always no. And I think for ESPN the answer is probably no.

1059
01:03:01,065 --> 01:03:04,525
Speaker 10:  You can never rule it out. But it's an interesting question. Okay, so like

1060
01:03:04,555 --> 01:03:08,045
Speaker 10:  what is Disney going to do? But I don't think they have an answer. That's

1061
01:03:08,045 --> 01:03:10,365
Speaker 10:  why we got these weird rumors about they wanna partner with different sports

1062
01:03:10,365 --> 01:03:14,285
Speaker 10:  leagues. Maybe because I, I don't know how that works with the sports

1063
01:03:14,405 --> 01:03:17,885
Speaker 10:  leagues owning part of the broadcaster that they sell broadcast to.

1064
01:03:18,475 --> 01:03:22,245
Speaker 10:  That seems strange and I don't know where the money comes from, but

1065
01:03:22,295 --> 01:03:26,045
Speaker 10:  Apple buying them is just one of those things where yes, it could technically

1066
01:03:26,045 --> 01:03:29,045
Speaker 10:  happen and yes, it would open up all of these things with Apple TVs that

1067
01:03:29,045 --> 01:03:31,365
Speaker 10:  they would love to do and it would give them something that everyone needs

1068
01:03:31,365 --> 01:03:35,245
Speaker 10:  to have, but they don't actually do those things. It's just, it's just generally

1069
01:03:35,245 --> 01:03:38,645
Speaker 10:  not the way that Apple operates for Disney, it would narrow the availability

1070
01:03:38,785 --> 01:03:42,085
Speaker 10:  of ESPN if it were suddenly somehow exclusive. Maybe even if they could

1071
01:03:42,085 --> 01:03:45,965
Speaker 10:  still sell it to cable operators, it would be weird. And

1072
01:03:45,965 --> 01:03:48,765
Speaker 10:  I think that what we've seen, like we saw with their, their deal with I

1073
01:03:48,765 --> 01:03:52,285
Speaker 10:  think Cable Vision, they kind of worked it out so that you have streaming

1074
01:03:52,665 --> 01:03:55,405
Speaker 10:  and you have cable and that's, it seems like that's the way that they're

1075
01:03:55,405 --> 01:03:58,045
Speaker 10:  going at least for the future. Because the other thing that we know now

1076
01:03:58,305 --> 01:04:02,165
Speaker 10:  is exactly how profitable ESPN is and that answer to that is a

1077
01:04:02,165 --> 01:04:03,365
Speaker 10:  lot. It makes a ton of money

1078
01:04:03,865 --> 01:04:06,565
Speaker 2:  So profitable. I think that's the thing that actually gets lost in a lot

1079
01:04:06,565 --> 01:04:10,285
Speaker 2:  of this because Disney has made fairly clear that it

1080
01:04:10,405 --> 01:04:14,085
Speaker 2:  would like to find some more money for ESPN, which people make

1081
01:04:14,185 --> 01:04:18,045
Speaker 2:  out to be because ESPN is not a good business. That's not true. ESPN

1082
01:04:18,045 --> 01:04:21,805
Speaker 2:  is such an unbelievably good business. They just started breaking

1083
01:04:21,825 --> 01:04:25,765
Speaker 2:  out how much money ESPN makes because it is so much money that like Disney

1084
01:04:25,785 --> 01:04:26,765
Speaker 2:  is trying to make the point

1085
01:04:27,105 --> 01:04:30,405
Speaker 10:  And that's now, that's now after everyone has cut the cord, after everyone

1086
01:04:30,405 --> 01:04:33,965
Speaker 10:  You know has stopped subscribing to cable, ESPN is still making just

1087
01:04:34,285 --> 01:04:36,085
Speaker 10:  absolute billions and billions and billions of dollars.

1088
01:04:36,355 --> 01:04:40,205
Speaker 2:  Yeah, and I do think it's true that if you cast out far enough,

1089
01:04:40,425 --> 01:04:44,405
Speaker 2:  you can see where ESPN gets harder because the, the rights deals that

1090
01:04:44,485 --> 01:04:48,325
Speaker 2:  ESPN is fighting for are getting more and more expensive. The number of

1091
01:04:48,375 --> 01:04:52,365
Speaker 2:  cable subscribers who are essentially paying for ESPN twice are going

1092
01:04:52,365 --> 01:04:56,245
Speaker 2:  down. So like you cast out another what, 10, 15 years

1093
01:04:56,425 --> 01:04:59,845
Speaker 2:  and ESPN is maybe a less good business right now. It's still an

1094
01:05:00,245 --> 01:05:03,925
Speaker 2:  unbelievably great business. I I'm with you. I don't think it would be

1095
01:05:03,925 --> 01:05:07,645
Speaker 2:  Apple because like I was thinking a lot about the the deal that Apple made

1096
01:05:07,645 --> 01:05:11,565
Speaker 2:  with the MLS and the deal that Apple didn't make to get Sunday ticket and

1097
01:05:11,705 --> 01:05:14,845
Speaker 2:  it seems like what Apple is all about and this makes sense given what Apple

1098
01:05:14,845 --> 01:05:18,285
Speaker 2:  is, is control, right? Apple wants a thing thing it can do itself.

1099
01:05:18,665 --> 01:05:22,605
Speaker 2:  So the idea of having a thing that is fundamentally about making a million

1100
01:05:22,605 --> 01:05:25,725
Speaker 2:  different partnerships with a million different people or being like a minority

1101
01:05:25,725 --> 01:05:28,845
Speaker 2:  owner in a thing, it doesn't actually control all of feels very

1102
01:05:29,275 --> 01:05:33,045
Speaker 2:  unapply to me. But like Amazon, I can absolutely imagine

1103
01:05:33,045 --> 01:05:36,645
Speaker 2:  making roughly that exact deal where Amazon is like, we're gonna put all

1104
01:05:36,645 --> 01:05:40,205
Speaker 2:  the sports on Prime. You can subscribe to ESPN through Prime, you get ESPN

1105
01:05:40,205 --> 01:05:43,165
Speaker 2:  if you're a prime subscriber, we're gonna make Prime $8 a month more expensive.

1106
01:05:43,165 --> 01:05:46,605
Speaker 2:  There's your cable difference right there. Like I can totally imagine a world

1107
01:05:46,605 --> 01:05:49,645
Speaker 2:  in which that happens. I don't think it would be Apple. I agree with you.

1108
01:05:49,725 --> 01:05:53,485
Speaker 2:  I think Apple's much more likely to like buy a sports league than it is

1109
01:05:53,905 --> 01:05:55,125
Speaker 2:  to buy ESPN.

1110
01:05:55,515 --> 01:05:58,045
Speaker 10:  Yeah. Something where they actually can control. And I think that's the,

1111
01:05:58,065 --> 01:06:01,725
Speaker 10:  the number one most important word for what Apple likes is control.

1112
01:06:02,065 --> 01:06:05,845
Speaker 10:  And the other part of ESPN is their deals with the different leagues

1113
01:06:06,015 --> 01:06:08,605
Speaker 10:  means that Apple would have no control because all of these arrangements

1114
01:06:08,605 --> 01:06:12,085
Speaker 10:  have are old and have been made in different ways and have a lot of compromises

1115
01:06:12,085 --> 01:06:15,925
Speaker 10:  and all the leagues have different things like people talk about Apple will

1116
01:06:15,925 --> 01:06:18,845
Speaker 10:  buy Formula One rights. It's one of those things that people say but I think

1117
01:06:19,065 --> 01:06:23,005
Speaker 10:  is unlikely Formula One broadcast itself, it does

1118
01:06:23,005 --> 01:06:25,285
Speaker 10:  all of it through its own broadcast center and sends it around the world.

1119
01:06:25,695 --> 01:06:29,565
Speaker 10:  Apple doesn't really want to deal with Formula One telling it what to do

1120
01:06:29,905 --> 01:06:32,525
Speaker 10:  and I think it's as you go down the line, that's just really what you run

1121
01:06:32,525 --> 01:06:35,565
Speaker 10:  into and that's what what makes it less and less and less likely. But yes,

1122
01:06:35,565 --> 01:06:38,605
Speaker 10:  like a company like Amazon, what if Microsoft is like You know what we should

1123
01:06:38,795 --> 01:06:42,565
Speaker 10:  combine ESPN and Game Pass. Let's do it. Yeah. ESPN game

1124
01:06:42,565 --> 01:06:44,085
Speaker 10:  pass Binging bundle. Done

1125
01:06:44,725 --> 01:06:48,565
Speaker 2:  The weirdest way to spend $20 a month that you've ever encountered. I love

1126
01:06:48,565 --> 01:06:52,405
Speaker 2:  it. The reason I continue to think ESPN is so interesting is because it is

1127
01:06:52,495 --> 01:06:56,325
Speaker 2:  right smack in the middle of this thing where what ESPN wants is to be

1128
01:06:56,325 --> 01:07:00,125
Speaker 2:  everywhere, right? Because the crazy part about this is ESPN

1129
01:07:00,295 --> 01:07:04,245
Speaker 2:  isn't gonna get the right deals that it wants if it doesn't have the

1130
01:07:04,485 --> 01:07:08,325
Speaker 2:  distribution that you get through cable. This is why CBS and Fox keep getting

1131
01:07:08,325 --> 01:07:12,085
Speaker 2:  deals because they're everywhere. Like no one but old

1132
01:07:12,085 --> 01:07:15,565
Speaker 2:  people watches CBS anymore. But CBS keeps getting football deals

1133
01:07:15,835 --> 01:07:19,725
Speaker 2:  because it's free over the air television that absolutely everybody

1134
01:07:19,725 --> 01:07:22,365
Speaker 2:  can get, which means you can charge more for ads, which means you get more

1135
01:07:22,365 --> 01:07:26,245
Speaker 2:  reach like everybody wins. So ESPN needs that, but it also

1136
01:07:26,575 --> 01:07:30,445
Speaker 2:  needs to figure out what a streaming only world looks

1137
01:07:30,445 --> 01:07:34,405
Speaker 2:  like because it's coming. But if ESPN in 10 years that world comes and

1138
01:07:34,485 --> 01:07:37,965
Speaker 2:  ESPN doesn't have any rights deals, ESPN is dead anyway. So it's caught in,

1139
01:07:38,225 --> 01:07:41,725
Speaker 2:  in this transition that we're in, nobody has a harder time of navigating

1140
01:07:41,725 --> 01:07:44,925
Speaker 2:  it than ESPN, even as it continues to just throw off billions of billions

1141
01:07:45,165 --> 01:07:47,045
Speaker 2:  of dollars for Disney. Yeah,

1142
01:07:47,045 --> 01:07:50,325
Speaker 10:  Being in the lead means that making a decision about changing something

1143
01:07:50,585 --> 01:07:51,645
Speaker 10:  is so much more difficult.

1144
01:07:51,795 --> 01:07:55,685
Speaker 2:  Totally. So, okay, real quick before we go, 12 months from now,

1145
01:07:56,025 --> 01:07:58,685
Speaker 2:  you have to answer, does Disney still own ESPN?

1146
01:07:59,105 --> 01:08:01,205
Speaker 10:  Yes, majority. Ah,

1147
01:08:01,225 --> 01:08:05,125
Speaker 2:  See that's good. That's good. I think I'm with you. I think if, if, if

1148
01:08:05,165 --> 01:08:08,925
Speaker 2:  I put the number at like five years, I think I'd have a hard time

1149
01:08:08,925 --> 01:08:12,525
Speaker 2:  answering the question. I think 12 months. It's just too big a thing

1150
01:08:12,945 --> 01:08:16,765
Speaker 2:  to change in that period of time and I think people really underrate

1151
01:08:16,785 --> 01:08:20,205
Speaker 2:  how messy sports deals are and just like the

1152
01:08:20,235 --> 01:08:24,045
Speaker 2:  paperwork involved in selling ESPN will, I think just like blow people's

1153
01:08:24,045 --> 01:08:24,285
Speaker 2:  minds

1154
01:08:24,505 --> 01:08:27,445
Speaker 10:  And I think the money that it brings in simply makes a lot of things that

1155
01:08:27,445 --> 01:08:30,845
Speaker 10:  Disney wants to do a lot easier. It is something that we know now that we

1156
01:08:30,845 --> 01:08:34,765
Speaker 10:  always suspected, but we know now like all those Marvel movies

1157
01:08:34,825 --> 01:08:37,005
Speaker 10:  are like ESPN paid for those you're welcome

1158
01:08:37,465 --> 01:08:40,805
Speaker 2:  In like a very real way. ESPN paid for all of that stuff

1159
01:08:41,265 --> 01:08:45,045
Speaker 2:  and now the question is gonna be can Disney find another

1160
01:08:45,105 --> 01:08:48,805
Speaker 2:  way to pay for all that stuff without ESPN and is it going to have to,

1161
01:08:48,945 --> 01:08:52,725
Speaker 2:  and all of that is so unknown, which is why it's very weird to be at Disney

1162
01:08:52,725 --> 01:08:56,005
Speaker 2:  right now because it's, it's dealing in like a thousand concurrent hypotheticals

1163
01:08:56,355 --> 01:08:59,765
Speaker 2:  that none of which are true now. Like right now Disney's fine. Wall Street

1164
01:08:59,765 --> 01:09:03,445
Speaker 2:  doesn't think so because they're terrified about like some future streaming

1165
01:09:03,845 --> 01:09:07,165
Speaker 2:  universe that doesn't actually exist yet. But like right now as a business,

1166
01:09:07,165 --> 01:09:08,085
Speaker 2:  Disney's doing great,

1167
01:09:08,525 --> 01:09:10,165
Speaker 10:  Bringing in just tons of money.

1168
01:09:10,635 --> 01:09:14,485
Speaker 2:  It's just hosed in so many ways. It doesn't yet understand, it

1169
01:09:14,485 --> 01:09:15,565
Speaker 2:  makes it very complicated.

1170
01:09:15,795 --> 01:09:18,685
Speaker 10:  What that future looks like is something that You know if, if you have an

1171
01:09:18,685 --> 01:09:21,525
Speaker 10:  answer, I'm sure Bob Iger will take your call. Yeah,

1172
01:09:21,675 --> 01:09:25,005
Speaker 2:  Yeah. Hit him up Bob at Disney dot com. I'm sure he'll take your email.

1173
01:09:25,625 --> 01:09:27,485
Speaker 2:  All, right? Richard, thank you as always. Appreciate it bud.

1174
01:09:29,025 --> 01:09:31,805
Speaker 2:  All, right. That's it for The Vergecast today. Thanks to everybody who was

1175
01:09:31,805 --> 01:09:35,685
Speaker 2:  on the show, and thank you as always for listening. There's lots more from

1176
01:09:35,685 --> 01:09:38,925
Speaker 2:  everything we talked about, all of Liz's SBF coverage is amazing. You should

1177
01:09:38,925 --> 01:09:42,245
Speaker 2:  go back and read it all. Everything Sean is doing from the courtroom for

1178
01:09:42,245 --> 01:09:45,205
Speaker 2:  Epic v Google has been great so far. We'll put some links in the show notes,

1179
01:09:45,205 --> 01:09:48,765
Speaker 2:  but also keep an eye on the website. There's all kinds of stuff still going

1180
01:09:48,765 --> 01:09:52,725
Speaker 2:  down and as always, if you have thoughts, questions, feelings, or

1181
01:09:53,115 --> 01:09:57,085
Speaker 2:  curiosities about the jury in these trials, let us know. You can always email

1182
01:09:57,085 --> 01:10:00,805
Speaker 2:  us at Vergecast at The Verge dot com or keep calling the Hotline 8 6 6

1183
01:10:01,005 --> 01:10:04,365
Speaker 2:  Verge one. One. Like I said before, I love hearing from you. It is one of

1184
01:10:04,365 --> 01:10:07,805
Speaker 2:  my favorite things we get to do on The Vergecast. This show is produced by

1185
01:10:07,805 --> 01:10:10,885
Speaker 2:  Andrew Marino and Liam James The. Vergecast is The Verge production and part

1186
01:10:10,885 --> 01:10:14,365
Speaker 2:  of the Vox Media podcast network. Neli. Alex and I will be back on Friday

1187
01:10:14,545 --> 01:10:18,405
Speaker 2:  to talk about everything happening at OpenAI, the new MacBook, the PS five

1188
01:10:18,515 --> 01:10:21,365
Speaker 2:  slim, and a whole bunch more. We'll see you then. Rock and roll. We,

1189
01:10:32,055 --> 01:10:35,145
Speaker 11:  From the moment Twitter was founded, no one knew what it was supposed to

1190
01:10:35,145 --> 01:10:37,985
Speaker 11:  be exactly, which was kind of great.

1191
01:10:38,415 --> 01:10:41,705
Speaker 12:  Some people would look at it and say, this is the future of communications.

1192
01:10:41,705 --> 01:10:44,385
Speaker 12:  Others would look at it and say, this is the public square.

1193
01:10:44,955 --> 01:10:47,545
Speaker 11:  Eventually it became not so great.

1194
01:10:48,055 --> 01:10:51,905
Speaker 13:  What we didn't foresee was that everybody having

1195
01:10:52,025 --> 01:10:55,585
Speaker 13:  a voice might produce a global

1196
01:10:56,545 --> 01:11:00,385
Speaker 13:  voracious mob, and there was only one place that that was happening.

1197
01:11:00,485 --> 01:11:01,065
Speaker 13:  It was Twitter

1198
01:11:02,505 --> 01:11:06,225
Speaker 11:  A year ago in what was essentially the world's most expensive impulse

1199
01:11:06,585 --> 01:11:10,025
Speaker 11:  purchase. Elon Musk bought Twitter that made him

1200
01:11:10,025 --> 01:11:13,885
Speaker 11:  Twitter's most important user, but he's certainly not the only

1201
01:11:14,025 --> 01:11:17,285
Speaker 11:  one to fall for. Its spell a spell that promises attention,

1202
01:11:17,495 --> 01:11:18,845
Speaker 11:  connection, and power.

1203
01:11:21,745 --> 01:11:25,325
Speaker 11:  I'm Peter Kafka and I'm hosting Land of the Giants, the Twitter fantasy.

1204
01:11:25,875 --> 01:11:29,645
Speaker 11:  It's from Vox on the Vox Media Podcast Network. This season is sponsored

1205
01:11:29,645 --> 01:11:33,445
Speaker 11:  by Mint Mobile to learn how Twitter got started, how it got

1206
01:11:33,445 --> 01:11:37,365
Speaker 11:  where it is today, and where it's going next. Follow land of the

1207
01:11:37,365 --> 01:11:40,525
Speaker 11:  Giants wherever you listen and get new episodes every Wednesday.

1208
01:11:46,275 --> 01:11:49,965
Speaker 3:  This podcast is brought to you by Meta Quest three, the new mixed reality

1209
01:11:49,965 --> 01:11:53,885
Speaker 3:  headset from Meta. Expand your World in ways you never thought Possible with

1210
01:11:53,885 --> 01:11:57,725
Speaker 3:  the new Meta Quest. Three, put on the most powerful quest yet and

1211
01:11:57,725 --> 01:12:01,605
Speaker 3:  jump into fully immersive games like Assassin's Creed Nexus, or

1212
01:12:01,605 --> 01:12:04,725
Speaker 3:  blend virtual elements into your surroundings in games like Stranger Things

1213
01:12:04,825 --> 01:12:08,565
Speaker 3:  vr. With over 500 titles, it's easy to dive into

1214
01:12:08,925 --> 01:12:12,805
Speaker 3:  whatever you're into. Expand your world with Meta Quest three. See child

1215
01:12:12,805 --> 01:12:15,445
Speaker 3:  safety guidance online accounts for 10 and up. Certain apps, games and experiences

1216
01:12:15,445 --> 01:12:18,485
Speaker 3:  may be suitable for a more mature audience. Learn more@meta.com.

