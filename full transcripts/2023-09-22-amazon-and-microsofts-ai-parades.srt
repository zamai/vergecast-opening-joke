1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 55eff9b7-94bc-450b-b034-7bdd4ba20a48
Status: Done
Stage: Done
Title: Amazon and Microsoft's AI parades
Audio URL: https://jfe93e.s3.amazonaws.com/-8694654348120022283/-178136986552068307/s93290-US-4658s-1695419558.mp3
Description: The Verge's Nilay Patel, Alex Cranz, and David Pierce discuss all the announcements from Amazon's fall product launch event and Microsoft's Surface and AI event.

2
00:01:24,330 --> 00:01:27,080
Speaker 4:  Hello and welcome to Vergecast, the flagship podcast

3
00:01:28,580 --> 00:01:31,600
Speaker 4:  of a scandal that's taking over the pole dancing, not the pole dancing community.

4
00:01:32,060 --> 00:01:35,240
Speaker 4:  The flagship podcast. Yeah. Of Ed Sheeran

5
00:01:35,830 --> 00:01:39,720
Speaker 4:  tearing the line dancing community apart. What this is, this is just

6
00:01:39,720 --> 00:01:41,000
Speaker 4:  random TikTok knowledge I have

7
00:01:41,000 --> 00:01:43,880
Speaker 5:  Now. Oh, have you entered Shiver TikTok? Yeah. Yeah. Welcome. Wow.

8
00:01:44,390 --> 00:01:47,520
Speaker 4:  It's just, it just follows me around the internet now there's people line

9
00:01:47,520 --> 00:01:51,280
Speaker 4:  dancing to shivers by Ed Sheeran and then the comments are like,

10
00:01:51,950 --> 00:01:54,480
Speaker 4:  this isn't real line dancing, like

11
00:01:54,480 --> 00:01:56,440
Speaker 6:  Doing the electric slide and the little doey d

12
00:01:56,800 --> 00:01:59,080
Speaker 4:  The the line dancing situa. It's the next big trend. It's

13
00:01:59,080 --> 00:02:00,400
Speaker 6:  Coming to a honky tonking view.

14
00:02:00,460 --> 00:02:04,440
Speaker 4:  But shivers by Ed Sheeran is, David appears to know, oh yeah.

15
00:02:04,550 --> 00:02:08,400
Speaker 5:  I've been, I've been deep in, in shiver dancing TikTok for a long time, as

16
00:02:08,400 --> 00:02:09,080
Speaker 5:  we call it. And

17
00:02:09,080 --> 00:02:11,160
Speaker 4:  It's deeply controversial because

18
00:02:11,280 --> 00:02:12,640
Speaker 6:  It's Ed Sheeran. 'cause

19
00:02:12,640 --> 00:02:13,880
Speaker 4:  It's Ed Sheeran. That's

20
00:02:13,880 --> 00:02:14,960
Speaker 6:  Not what I wanna listen to.

21
00:02:15,170 --> 00:02:18,920
Speaker 4:  There are entire people who built careers off of line dancing

22
00:02:18,980 --> 00:02:20,400
Speaker 4:  to shivers by Ed Sheeran.

23
00:02:21,340 --> 00:02:21,560
Speaker 6:  No.

24
00:02:21,700 --> 00:02:24,760
Speaker 4:  And the commenters are like, this isn't country music. And their response

25
00:02:24,760 --> 00:02:28,520
Speaker 4:  to the commenters are, I post other songs. Only shivers gets

26
00:02:28,570 --> 00:02:28,920
Speaker 4:  views.

27
00:02:29,520 --> 00:02:30,000
Speaker 6:  I hate it.

28
00:02:31,920 --> 00:02:33,120
Speaker 6:  I don't like it. It's very good.

29
00:02:33,120 --> 00:02:36,560
Speaker 4:  This is not good. No, it's a, it's, it is easily my favorite low

30
00:02:36,700 --> 00:02:39,520
Speaker 4:  stakes internet drama is

31
00:02:40,500 --> 00:02:43,720
Speaker 4:  why, like do you know how there's a theory that like the Chinese government

32
00:02:43,720 --> 00:02:46,280
Speaker 4:  is manipulating TikTok to destabilize America? That's

33
00:02:46,460 --> 00:02:47,000
Speaker 6:  How they're doing

34
00:02:47,000 --> 00:02:49,600
Speaker 4:  It. The algorithm is like, you will dance to shivers.

35
00:02:49,820 --> 00:02:51,200
Speaker 6:  That's where we get our civil war.

36
00:02:51,990 --> 00:02:54,800
Speaker 4:  It's very good. Hello, I'm your friend. Neli Alex. Cranz is here in the studio

37
00:02:54,800 --> 00:02:55,000
Speaker 4:  with

38
00:02:55,000 --> 00:02:57,000
Speaker 6:  Me. I'm just really upset today. It's all good.

39
00:02:57,130 --> 00:02:59,340
Speaker 4:  We're gonna play shivers later. David Pierce is, is here.

40
00:02:59,380 --> 00:03:02,720
Speaker 5:  Hi. My theory about the shiver thing is that this is this

41
00:03:02,720 --> 00:03:06,560
Speaker 5:  generation's cotton eye Joe, in that it's a song and a

42
00:03:06,560 --> 00:03:09,440
Speaker 5:  dance that don't make any sense in context. And no one should ever do that.

43
00:03:09,440 --> 00:03:11,080
Speaker 5:  Involves like leg kicking. That doesn't

44
00:03:11,150 --> 00:03:11,920
Speaker 6:  Work. You gotta slap the

45
00:03:11,920 --> 00:03:15,400
Speaker 5:  Leg. But it has taken over the universe. This is it's Cotton Eye Joe

46
00:03:15,460 --> 00:03:16,080
Speaker 5:  2.0

47
00:03:16,940 --> 00:03:20,520
Speaker 6:  And it's there. I nevermind. I love this trend now with like that re

48
00:03:20,520 --> 00:03:22,520
Speaker 5:  Yeah. Oh no, it's all good. Beautiful. There's no downside.

49
00:03:23,060 --> 00:03:26,920
Speaker 4:  I'm expecting a 10,000 word shivers feature. How Shivers

50
00:03:26,920 --> 00:03:28,000
Speaker 4:  is tearing country music apart.

51
00:03:28,000 --> 00:03:28,760
Speaker 6:  David and I are on it.

52
00:03:28,980 --> 00:03:31,840
Speaker 4:  The country music has gone through quite a lot. Right now. I'm saying shivers

53
00:03:31,840 --> 00:03:33,600
Speaker 4:  is the sea plot. It

54
00:03:33,600 --> 00:03:37,240
Speaker 6:  Is because there's like, there's the guy who's like the alternative

55
00:03:37,250 --> 00:03:40,840
Speaker 6:  music version Yeah. Of country. And he is taken on bro country.

56
00:03:41,140 --> 00:03:41,520
Speaker 6:  We have

57
00:03:41,520 --> 00:03:43,920
Speaker 4:  So much to get through in the show. Oh my god. We're here at Shivers. Okay.

58
00:03:43,920 --> 00:03:47,120
Speaker 4:  There's a lot on the show today. A lot.

59
00:03:47,860 --> 00:03:50,680
Speaker 4:  Amazon had a big event. They announced not as much stuff as they usually

60
00:03:50,680 --> 00:03:53,880
Speaker 4:  announced their events, but a bunch of stuff. Big push and generative ai.

61
00:03:54,840 --> 00:03:58,760
Speaker 4:  Microsoft had an event, YouTube had an event. Microsoft

62
00:03:58,860 --> 00:04:02,080
Speaker 4:  had massive product leaks, which were vastly more interesting than their

63
00:04:02,080 --> 00:04:05,760
Speaker 4:  event. Yes, yes. There's other stuff going on. There's

64
00:04:05,900 --> 00:04:09,760
Speaker 4:  the Google antitrust case just in the background of all of this,

65
00:04:10,090 --> 00:04:14,070
Speaker 4:  which has its own controversy embedded in it. And the next week

66
00:04:14,070 --> 00:04:17,830
Speaker 4:  is the code conference. So just quite a lot going on in Virg. Like

67
00:04:18,070 --> 00:04:21,190
Speaker 4:  September is here. Yeah. We're no longer getting ready for September.

68
00:04:21,950 --> 00:04:24,470
Speaker 4:  There's enough going on in Virgil this week that the Wednesday show is all

69
00:04:24,470 --> 00:04:26,710
Speaker 4:  about the I iPhone reviews. 'cause we need to just clear the decks for today's

70
00:04:26,710 --> 00:04:29,590
Speaker 4:  show. Yeah, yeah. All right. So lemme give you the quick update on the Google

71
00:04:29,600 --> 00:04:32,510
Speaker 4:  trial and it will be quick because it is deeply

72
00:04:33,710 --> 00:04:36,270
Speaker 4:  frustrating. No one knows what's going on in the Google trial,

73
00:04:37,420 --> 00:04:38,630
Speaker 6:  Including both sides.

74
00:04:38,890 --> 00:04:42,470
Speaker 4:  No, I think they might have an idea. So most federal court cases

75
00:04:43,130 --> 00:04:46,830
Speaker 4:  are locked down. This is true. If you look back over the past

76
00:04:46,860 --> 00:04:49,990
Speaker 4:  year or so, more and more of them are starting to open up, right? They're

77
00:04:50,430 --> 00:04:54,350
Speaker 4:  allowing documents to be posted. There's some cases, audio's being streamed.

78
00:04:54,350 --> 00:04:58,110
Speaker 4:  Certainly reporters are in the courtroom. Just look at the Microsoft case,

79
00:04:58,480 --> 00:05:01,990
Speaker 4:  which has resulted in this giant leak, which we we'll get to. But you know

80
00:05:01,990 --> 00:05:04,630
Speaker 4:  what happened in FTC versus Microsoft, we were able to cover it for you.

81
00:05:04,770 --> 00:05:07,550
Speaker 4:  You know what happened in Epic versus Apple. We were able to cover for you.

82
00:05:08,210 --> 00:05:12,190
Speaker 4:  Do you know what's happening in Google versus the D O J or the

83
00:05:12,190 --> 00:05:15,790
Speaker 4:  D O J versus Google? You don't because reporters in the courtroom are not

84
00:05:15,790 --> 00:05:19,230
Speaker 4:  allowed to have devices, which means they have to take notes by hand and

85
00:05:19,930 --> 00:05:23,710
Speaker 4:  Google, the judge, the D O J are in some extremely

86
00:05:24,150 --> 00:05:27,790
Speaker 4:  annoying fight about public access to documents.

87
00:05:28,250 --> 00:05:31,350
Speaker 4:  So Google published a bunch of documents on it website about its opening

88
00:05:31,630 --> 00:05:35,590
Speaker 4:  arguments, et da da da da. The D O J tried to do that. Google

89
00:05:35,770 --> 00:05:39,470
Speaker 4:  got mad at them. All those documents have now come down off the DO J'S

90
00:05:39,470 --> 00:05:41,270
Speaker 4:  website. And there is some sort of

91
00:05:42,840 --> 00:05:46,640
Speaker 4:  argument happening amongst the two parties and the judge about whether

92
00:05:46,660 --> 00:05:49,680
Speaker 4:  the documents will come back. In particular one document,

93
00:05:50,690 --> 00:05:53,920
Speaker 4:  which we don't know what it is, which is quote embarrassing to Google.

94
00:05:54,120 --> 00:05:55,400
Speaker 6:  I want that one. It's the

95
00:05:55,400 --> 00:05:58,760
Speaker 4:  What I want. One of Google's financial executives was testifying that was

96
00:05:58,760 --> 00:06:02,320
Speaker 4:  closed to reporters. So reporters taking notes by longhand weren't even allowed

97
00:06:02,320 --> 00:06:06,240
Speaker 4:  in the room. We believe that as you're hearing this

98
00:06:06,240 --> 00:06:10,120
Speaker 4:  on Friday, that Apple executives will be in the courtroom. But no one has

99
00:06:10,120 --> 00:06:13,400
Speaker 4:  posted a schedule So. we don't know. It's just

100
00:06:13,750 --> 00:06:14,240
Speaker 4:  bonkers.

101
00:06:14,240 --> 00:06:18,000
Speaker 5:  Yeah. And even the like semi haphazard ways

102
00:06:18,070 --> 00:06:21,920
Speaker 5:  that information was being shared have all sort of disappeared in

103
00:06:21,920 --> 00:06:25,560
Speaker 5:  part, I think because of these behind the scenes machinations going on, but

104
00:06:25,590 --> 00:06:29,440
Speaker 5:  also because Judge Meta seemed to get so angry

105
00:06:29,780 --> 00:06:33,320
Speaker 5:  at these documents going up that now everything is gonna get

106
00:06:33,600 --> 00:06:37,240
Speaker 5:  even more locked down for the foreseeable future.

107
00:06:37,310 --> 00:06:40,960
Speaker 5:  Like we're what we're what, two weeks into a 10 week trial? And

108
00:06:41,330 --> 00:06:44,120
Speaker 5:  other than those first couple of days, we basically don't know anything.

109
00:06:44,480 --> 00:06:47,160
Speaker 5:  Somebody sent me a picture of a a like old school typewriter and was like,

110
00:06:47,160 --> 00:06:50,480
Speaker 5:  take this courtroom. They can't stop you. It's not an electronic And I think

111
00:06:50,480 --> 00:06:54,360
Speaker 5:  that's the coolest flex of all time. But it is very weird. Yeah.

112
00:06:54,840 --> 00:06:58,680
Speaker 5:  I get why Google in particular would very much

113
00:06:58,680 --> 00:07:02,520
Speaker 5:  like for it to be this way because it's not interested in losing

114
00:07:03,190 --> 00:07:06,360
Speaker 5:  this fight in the court of public opinion. I don't know for sure that they're

115
00:07:06,360 --> 00:07:09,480
Speaker 5:  the ones driving this, but I can certainly see why they would. But it's very

116
00:07:09,480 --> 00:07:11,760
Speaker 5:  strange that this is where we've landed in this process.

117
00:07:12,090 --> 00:07:15,160
Speaker 4:  Addie Robertson is covering the case very closely, closely as we can

118
00:07:15,930 --> 00:07:19,520
Speaker 4:  who's been in the courtroom for us. I'm like, we should write this story

119
00:07:19,520 --> 00:07:21,720
Speaker 4:  that's like Google's trying to hide and she's like, that's not what's happening.

120
00:07:21,720 --> 00:07:25,560
Speaker 4:  It's the judge. Right? Right. Her opinion of this is, it's the judge is

121
00:07:25,560 --> 00:07:29,400
Speaker 4:  like, I'm gonna be in control of this and I get it. And you

122
00:07:29,400 --> 00:07:32,960
Speaker 4:  could make a case from sort of an outcome basis

123
00:07:33,590 --> 00:07:36,880
Speaker 4:  that not making the trial into the circus will allow the court to reach a

124
00:07:36,880 --> 00:07:39,200
Speaker 4:  good and fair outcome. And Then we can like check their work in the end.

125
00:07:39,520 --> 00:07:42,600
Speaker 4:  'cause all of it's public rec. But there's also the fact that like one of

126
00:07:42,600 --> 00:07:46,520
Speaker 4:  the biggest companies in America is facing antitrust charges that may

127
00:07:46,520 --> 00:07:50,440
Speaker 4:  or may not result in it being broken up or the structure of its

128
00:07:50,440 --> 00:07:54,120
Speaker 4:  deals with apple change. And we just don't know. Like we do not know

129
00:07:54,120 --> 00:07:57,920
Speaker 4:  what's going on in that trial right now. I think that's absurd. But that

130
00:07:57,920 --> 00:08:01,630
Speaker 4:  is the state of the Google trial. That's the update, which is

131
00:08:01,700 --> 00:08:02,990
Speaker 4:  it's Schrodinger's trial.

132
00:08:04,890 --> 00:08:08,830
Speaker 4:  Is there an antitrust trial in that? Who knows? Probably is Google, who

133
00:08:08,830 --> 00:08:11,670
Speaker 4:  knows. So that's that. The other update I wanna give everybody is the code

134
00:08:11,670 --> 00:08:15,510
Speaker 4:  conference is next week. Ooh. I'm hosting it with Casey Newton and Julia

135
00:08:15,790 --> 00:08:18,670
Speaker 4:  Rson from C N B C. It's gonna be great. I've been speaking to some of the

136
00:08:18,670 --> 00:08:21,310
Speaker 4:  people to prepare who are gonna appear on stage. So I'm very excited about

137
00:08:21,310 --> 00:08:24,390
Speaker 4:  Getty's gonna show off. I'm very excited about what Microsoft's gonna show

138
00:08:24,390 --> 00:08:27,030
Speaker 4:  off. Adobe asked some stuff they've told us they're gonna show off. I think

139
00:08:27,030 --> 00:08:30,990
Speaker 4:  it's all gonna be really fun. Here's the news though. The u a w is on

140
00:08:30,990 --> 00:08:34,910
Speaker 4:  strike against three major American automakers and Mary Berra, C O G

141
00:08:35,030 --> 00:08:38,910
Speaker 4:  M dropped out today. Aw. She doesn't, she doesn't wanna give any fodder to

142
00:08:38,910 --> 00:08:42,710
Speaker 4:  the negotiations, which I sort of understand. She took with her. I

143
00:08:42,780 --> 00:08:46,510
Speaker 4:  look, it's sort of under, I just wanna be clear. I,

144
00:08:46,830 --> 00:08:50,710
Speaker 4:  I can intellectually understand why she, I do not understand why

145
00:08:50,710 --> 00:08:53,710
Speaker 4:  she doesn't wanna just say what she needs to say. But whatever she took with

146
00:08:53,710 --> 00:08:57,320
Speaker 4:  her, Mike Abbott, their new executive vice president of software, who is

147
00:08:57,320 --> 00:09:00,160
Speaker 4:  gonna, because why does GM wanna be at the code conference? Yeah. Talk about

148
00:09:00,460 --> 00:09:04,080
Speaker 4:  EVs. Talk about the fact that they dropped CarPlay. And so

149
00:09:04,960 --> 00:09:08,800
Speaker 4:  I, I have said to our team, the only moment that matters at code is

150
00:09:08,800 --> 00:09:12,520
Speaker 4:  me asking Mary Bear why she took CarPlay outta the Escalade. Yep. We were

151
00:09:12,520 --> 00:09:16,000
Speaker 4:  like prepared for it and now I cannot deliver that moment to you. Did you

152
00:09:16,000 --> 00:09:16,120
Speaker 4:  have

153
00:09:16,120 --> 00:09:17,920
Speaker 6:  Like four versions of the question for her?

154
00:09:17,980 --> 00:09:21,840
Speaker 4:  Oh yeah. You can't evade, you can't dodge it. I think it sucks, but the

155
00:09:21,840 --> 00:09:24,480
Speaker 4:  people love it. Right? Like what are you gonna do? It shivers it. I brought

156
00:09:24,500 --> 00:09:28,440
Speaker 4:  an Escalade out on stage, here it is. Explain. That's

157
00:09:28,440 --> 00:09:32,120
Speaker 4:  true. We have the c e O of Monarch tractor by the way, an EV tractor.

158
00:09:32,860 --> 00:09:35,720
Speaker 4:  And I was like, will you drive the tractor on stage? And he goes, it's very

159
00:09:35,720 --> 00:09:39,640
Speaker 4:  heavy. That was the end of that conversation. It's gonna

160
00:09:39,640 --> 00:09:41,880
Speaker 4:  be cool. The Polestar three is gonna be a code, which I think is gonna be

161
00:09:41,880 --> 00:09:45,480
Speaker 4:  really cool. We'll you'll see some of that. It's, that is basically just

162
00:09:45,720 --> 00:09:48,360
Speaker 4:  released. I'm just excited about a bunch of stuff that's happening at code,

163
00:09:48,500 --> 00:09:51,640
Speaker 4:  but Mary Bear is leaving that said and will not reveal it at this moment.

164
00:09:52,300 --> 00:09:56,280
Speaker 4:  We are 99% sure that another c

165
00:09:56,280 --> 00:09:59,920
Speaker 4:  e o of an EV company will be there. Like a good one. Okay.

166
00:10:00,360 --> 00:10:01,280
Speaker 6:  I was like Elon. No,

167
00:10:01,340 --> 00:10:04,760
Speaker 4:  No, it's, well like it's funny how you can interpret like a good one in many

168
00:10:04,760 --> 00:10:08,360
Speaker 4:  ways. Yeah. But a good one. Okay. Like one that you wanna hear from. Okay.

169
00:10:08,360 --> 00:10:10,720
Speaker 4:  And then I got another idea that I'm working on, which I think will be cool.

170
00:10:10,860 --> 00:10:14,720
Speaker 4:  So that's the code update. It's September 26th and 27th. We'll have like

171
00:10:14,720 --> 00:10:17,800
Speaker 4:  wall to wall coverage on The. Verge. I'll be there with Casey and Julia.

172
00:10:18,500 --> 00:10:22,320
Speaker 4:  You can buy, you go to vme.com/code. You can buy virtual tickets now. There's

173
00:10:22,320 --> 00:10:24,880
Speaker 4:  seven, five bucks if you wanna like follow along. Otherwise tons of coverage

174
00:10:24,880 --> 00:10:28,860
Speaker 4:  on the site. We, you know, pay attention to code. It's the thing I'm doing.

175
00:10:29,130 --> 00:10:32,620
Speaker 4:  Okay. Let's talk about the news. Should we start with Amazon?

176
00:10:32,650 --> 00:10:36,100
Speaker 6:  Yeah. There was an Amazon event. David and I went, we hung out. You went?

177
00:10:36,100 --> 00:10:39,100
Speaker 6:  Yeah, I took the train down. That was the worst decision of my life.

178
00:10:40,050 --> 00:10:41,780
Speaker 6:  That was horrible. I took two trains out. So

179
00:10:41,780 --> 00:10:45,260
Speaker 4:  There's like a lot of drama with these Amazon and Microsoft events. Yeah.

180
00:10:45,410 --> 00:10:48,020
Speaker 4:  Like meta drama. Yeah. Oh it's so fun.

181
00:10:48,170 --> 00:10:51,500
Speaker 6:  It's, it's my favorite part of this. Like I think that was the big conversation

182
00:10:51,500 --> 00:10:54,500
Speaker 6:  of the week because the gadgets and, and there was a lot of cool gadgets

183
00:10:54,500 --> 00:10:56,740
Speaker 6:  and the gadgets are deep and we're gonna talk about the gadgets, but the

184
00:10:56,740 --> 00:11:00,660
Speaker 6:  big thing was Panos Pane is he runs

185
00:11:00,660 --> 00:11:04,580
Speaker 6:  all the devices and Windows at Microsoft. Or he did

186
00:11:04,770 --> 00:11:08,580
Speaker 6:  because this week sudden announcement he's leaving. Which is wild

187
00:11:08,820 --> 00:11:12,380
Speaker 6:  'cause there's a Microsoft event this week. Yeah. David Limp left Amazon

188
00:11:12,420 --> 00:11:16,380
Speaker 6:  a couple of months ago and Bloomberg reports, Panos Pane is

189
00:11:16,380 --> 00:11:20,100
Speaker 6:  gonna be taking over his job. David Lim's job at Amazon.

190
00:11:20,360 --> 00:11:23,900
Speaker 6:  So then the Amazon event happened on Wednesday. Microsoft event happens on

191
00:11:24,180 --> 00:11:27,580
Speaker 6:  Thursday. And meanwhile we've got these two guys who've been running these

192
00:11:27,580 --> 00:11:31,540
Speaker 6:  departments, running these events, deciding what's gonna be on

193
00:11:31,550 --> 00:11:35,500
Speaker 6:  stage, figuring out how these things work and operate are

194
00:11:35,500 --> 00:11:39,100
Speaker 6:  both like huge mixup. Huge changeup. Yeah. And it's just like you are,

195
00:11:39,460 --> 00:11:42,540
Speaker 4:  I wish there was, I wish there was a true swap. Yeah. That's really what

196
00:11:42,610 --> 00:11:46,380
Speaker 4:  what it's like, it would be perfect if, if Limp was gonna Microsoft and Panos

197
00:11:46,380 --> 00:11:48,220
Speaker 4:  is going to this just start. But Limp is just out.

198
00:11:48,290 --> 00:11:51,980
Speaker 6:  Yeah. Limps done. He's, he seems very happy. He seems

199
00:11:52,030 --> 00:11:54,160
Speaker 6:  chill to be, to be moving on with his life.

200
00:11:54,160 --> 00:11:57,520
Speaker 4:  So I I, I like Dave limp a lot. Yeah. We, we've talked to him a bunch. He's

201
00:11:57,520 --> 00:12:00,840
Speaker 4:  been on decoder. He's a very smart guy. He, he has always said the right

202
00:12:00,840 --> 00:12:04,640
Speaker 4:  things to us. I would say looking at his tenure over Amazon devices,

203
00:12:06,150 --> 00:12:07,330
Speaker 4:  not a lot of heat there. Oh

204
00:12:07,330 --> 00:12:08,170
Speaker 5:  That's not fair. His

205
00:12:08,370 --> 00:12:11,130
Speaker 6:  Strategy was interesting. What do you mean? Because the strategy was about

206
00:12:11,260 --> 00:12:14,330
Speaker 6:  we're gonna see what sticks we wanna, like we're new in this department.

207
00:12:14,330 --> 00:12:15,770
Speaker 4:  Wait, I wanna hear why David says it's not fair.

208
00:12:15,950 --> 00:12:19,570
Speaker 5:  The Echo has been a gigantic success. The Kindle has been a gigantic success.

209
00:12:19,640 --> 00:12:19,930
Speaker 5:  Wait,

210
00:12:19,930 --> 00:12:23,850
Speaker 4:  The Kindle has been a gigantic success. The Echo is not a gigantic success

211
00:12:23,850 --> 00:12:26,970
Speaker 4:  and Alexa is not a gigantic, it does not make any money. Fair.

212
00:12:27,040 --> 00:12:29,090
Speaker 5:  Sure. That's a, those are two different questions

213
00:12:29,390 --> 00:12:31,290
Speaker 4:  And you would not even say that people are,

214
00:12:31,290 --> 00:12:31,810
Speaker 6:  It's a cultural

215
00:12:31,810 --> 00:12:33,610
Speaker 4:  Success passionate about these products.

216
00:12:33,670 --> 00:12:37,130
Speaker 5:  Oh, Dave Limp would say that. Dave Limp said that to me to my face after

217
00:12:37,270 --> 00:12:41,210
Speaker 5:  the Amazon event that people love their echoes. I mean one

218
00:12:41,210 --> 00:12:44,410
Speaker 5:  of the questions I asked him, they had this whole run about generative AI

219
00:12:44,430 --> 00:12:48,050
Speaker 5:  and wanting their AI to seem like human

220
00:12:48,100 --> 00:12:51,170
Speaker 5:  right? Like that's their big thing. They wanted to say ums and ahs. Yes.

221
00:12:51,230 --> 00:12:54,330
Speaker 5:  And feel like a member of your family. And I feel like if we've learned one

222
00:12:54,330 --> 00:12:57,890
Speaker 5:  thing about AI over the last 12 months, it's that that's a bad,

223
00:12:58,290 --> 00:13:01,970
Speaker 5:  dangerous, problematic idea. So I asked him that. I was like, why should

224
00:13:02,160 --> 00:13:05,290
Speaker 5:  this thing just be a tool that I use when I need it? Why should it be my

225
00:13:05,290 --> 00:13:09,170
Speaker 5:  friend that seems scary. And he

226
00:13:09,170 --> 00:13:11,850
Speaker 5:  was like, that's how people do it. They say they love you to their Echo and,

227
00:13:11,910 --> 00:13:15,650
Speaker 5:  and we're gonna keep leaning into that. Like there is

228
00:13:15,650 --> 00:13:18,850
Speaker 5:  real affinity for that stuff. Most people just like play timers and ask silly

229
00:13:19,090 --> 00:13:23,050
Speaker 5:  questions. But like that's, that thing is real Amazon's problem is that it's

230
00:13:23,050 --> 00:13:26,610
Speaker 5:  not a hardware company. Right. Like their whole thing has always been, we

231
00:13:26,900 --> 00:13:29,570
Speaker 5:  don't make money when you buy our product. We make money when you use our

232
00:13:29,570 --> 00:13:32,130
Speaker 5:  product. Right. So like they don't make money on the Kindle. They make money

233
00:13:32,130 --> 00:13:34,810
Speaker 5:  when you buy books on the Kindle. The problem is they never found a way for

234
00:13:34,810 --> 00:13:37,210
Speaker 5:  you to buy anything. Yeah. Through the Echo.

235
00:13:37,510 --> 00:13:40,650
Speaker 4:  But this is just what I mean, I we're agreeing more than disagreeing when

236
00:13:40,650 --> 00:13:44,570
Speaker 4:  I say there's not a lot of heat on these products. The Kindle is its own

237
00:13:44,570 --> 00:13:48,450
Speaker 4:  thing. It's its own weird closed ecosystem. They put out new Kindles every

238
00:13:48,450 --> 00:13:48,850
Speaker 4:  couple of years

239
00:13:48,850 --> 00:13:49,450
Speaker 6:  Monstrously

240
00:13:49,450 --> 00:13:53,370
Speaker 4:  Successful and people just buy new ones. Yeah. And fine. And it is a

241
00:13:53,530 --> 00:13:57,410
Speaker 4:  cultural product in its way. Although I think the, the sort of cultural impact

242
00:13:57,410 --> 00:14:00,970
Speaker 4:  of print books continues and grows in its own way. Which I think is

243
00:14:01,250 --> 00:14:04,970
Speaker 4:  fascinating. The Echo people set timers with and it's really

244
00:14:05,070 --> 00:14:08,850
Speaker 4:  useful and little kids ask it to tell it jokes and you can dress what an

245
00:14:08,850 --> 00:14:12,610
Speaker 4:  Echo dot up like a Mickey and like all that stuff. But it has just been

246
00:14:12,680 --> 00:14:16,490
Speaker 4:  that for the longest time and maybe

247
00:14:16,490 --> 00:14:20,010
Speaker 4:  some of this generative AI stuff will change that. But they haven't grown

248
00:14:20,010 --> 00:14:22,410
Speaker 4:  it into a business. They haven't figured out how to get people to do anything

249
00:14:22,410 --> 00:14:26,210
Speaker 4:  other than set timers and play music at like at all.

250
00:14:26,830 --> 00:14:30,290
Speaker 4:  The smart home stuff has kind of petered out and we're all waiting for matter

251
00:14:30,310 --> 00:14:33,490
Speaker 4:  to do whatever. And they've made some of those spens And then the hardware

252
00:14:33,490 --> 00:14:35,210
Speaker 4:  itself is like somewhat stagnated. Oh

253
00:14:35,210 --> 00:14:37,970
Speaker 5:  Yeah. Not even somewhat. It has fully stagnated. Even The new stuff they're

254
00:14:37,970 --> 00:14:41,570
Speaker 5:  launching is just like big plushy screens. Just like the other big

255
00:14:41,570 --> 00:14:42,970
Speaker 5:  plushie screens like with

256
00:14:42,970 --> 00:14:43,890
Speaker 6:  Thread routers.

257
00:14:44,480 --> 00:14:48,290
Speaker 4:  Yeah, sure, sure. Yeah. Like they've updated the stuff. And again, I like

258
00:14:48,290 --> 00:14:50,890
Speaker 4:  Dave and I think he has the right ideas and when you talk to him about smart

259
00:14:50,890 --> 00:14:54,640
Speaker 4:  home home stuff in particular, he's like all in on

260
00:14:55,660 --> 00:14:59,480
Speaker 4:  the good standards and making sure the stuff works right. Like he's, he says

261
00:14:59,480 --> 00:15:02,440
Speaker 4:  all the right things and he's honest. Which is like the highest compliment

262
00:15:02,560 --> 00:15:06,440
Speaker 4:  I can give. Yeah. But I think that the fire, that's a

263
00:15:06,440 --> 00:15:10,320
Speaker 4:  good pun frame his on devices, it just seems like they hit a dead end

264
00:15:10,320 --> 00:15:14,080
Speaker 4:  and they didn't know what to do next. And I think you bring in Panos Penne.

265
00:15:14,190 --> 00:15:18,040
Speaker 4:  Yeah. Who's all fire all the time and he's going to go

266
00:15:18,100 --> 00:15:21,360
Speaker 4:  and like try some stuff and be bold about it. Which I think is great.

267
00:15:22,160 --> 00:15:25,440
Speaker 4:  I think his tenure at Surface in particular has been

268
00:15:26,220 --> 00:15:27,080
Speaker 4:  underappreciated.

269
00:15:27,380 --> 00:15:28,480
Speaker 5:  Oh I agree. Like

270
00:15:28,620 --> 00:15:32,480
Speaker 4:  He completely rebooted the idea of Windows laptops from his position at Microsoft.

271
00:15:32,480 --> 00:15:36,080
Speaker 4:  Yeah. And we've talked about it a bunch on the show, but basically

272
00:15:36,340 --> 00:15:40,160
Speaker 4:  he walked into Best Buy and said why are every

273
00:15:40,160 --> 00:15:42,960
Speaker 4:  Windows Laptop here? Why is it under a thousand dollars? And we have just

274
00:15:42,960 --> 00:15:46,880
Speaker 4:  seeded the high end to to Apple. Yeah. And then they invented a bunch

275
00:15:46,880 --> 00:15:50,280
Speaker 4:  of stuff and importantly I think this is totally undercovered, they gave

276
00:15:50,280 --> 00:15:54,000
Speaker 4:  that technology away to the Windows OEMs. Yep. So I've walked around

277
00:15:54,160 --> 00:15:57,760
Speaker 4:  c e s with Panos and he's like, those are my hinges and pointing at

278
00:15:57,760 --> 00:16:00,400
Speaker 4:  laptops. Like those are my hinges, those are my key. Like here's all the

279
00:16:00,400 --> 00:16:02,040
Speaker 4:  stuff we made that we just gave away. He

280
00:16:02,040 --> 00:16:05,640
Speaker 5:  Pulled off the thing Google has been trying to do with Pixel for years, which

281
00:16:05,640 --> 00:16:09,520
Speaker 5:  is like teach the ecosystem how to make better stuff. Yeah. Like he, he did

282
00:16:09,520 --> 00:16:12,800
Speaker 5:  that to the Windows ecosystem. Yeah. Like if you have a Windows Laptop it

283
00:16:12,800 --> 00:16:16,760
Speaker 5:  is better because of anos pane. Like it just, it just is. Yeah. And I

284
00:16:16,760 --> 00:16:20,600
Speaker 5:  think that's really cool. Can I tell you my most Galaxy brainin take about

285
00:16:20,600 --> 00:16:24,120
Speaker 5:  all of this? I've been talking to people and asking around, and I have

286
00:16:24,460 --> 00:16:28,200
Speaker 5:  no actual evidence for this, but I'm increasingly convinced that I'm right.

287
00:16:28,200 --> 00:16:32,160
Speaker 5:  Do you wanna hear my theory? Yes. My theory is that Panos

288
00:16:32,180 --> 00:16:36,000
Speaker 5:  Pne wants nothing more than to make a next generation

289
00:16:36,000 --> 00:16:39,880
Speaker 5:  smartphone. He has been toying with this, with the Surface duo. He's

290
00:16:39,880 --> 00:16:43,360
Speaker 5:  been goofing around with this idea with a bunch of different Windows things

291
00:16:43,360 --> 00:16:47,280
Speaker 5:  over the years. He has like tried desperately to figure out what is the smartphone

292
00:16:47,280 --> 00:16:51,240
Speaker 5:  thing that comes right after Candy bar smartphones. Microsoft I don't think

293
00:16:51,240 --> 00:16:53,640
Speaker 5:  has any interest in making smartphones anymore.

294
00:16:53,640 --> 00:16:55,320
Speaker 4:  That's Or even supporting the one that it made.

295
00:16:55,320 --> 00:16:59,040
Speaker 5:  Yeah. It's over that, you know, who desperately, desperately would love a

296
00:16:59,040 --> 00:17:02,520
Speaker 5:  reason to get back into the smartphone game is Amazon. Because the reason

297
00:17:02,730 --> 00:17:06,640
Speaker 5:  Alexa can't win is because it's not on your

298
00:17:06,640 --> 00:17:10,280
Speaker 5:  phone in a meaningful device integrated, super

299
00:17:10,300 --> 00:17:13,360
Speaker 5:  useful way. It is the single most important device you have. And it is the

300
00:17:13,360 --> 00:17:17,240
Speaker 5:  worst Alexa device. And if you gave Jeff Bezos and Andy

301
00:17:17,250 --> 00:17:19,880
Speaker 5:  Jassy like all the money in the world, they would go back and make the fire

302
00:17:19,880 --> 00:17:23,040
Speaker 5:  phone better because it would've changed Amazon forever. And I think

303
00:17:23,760 --> 00:17:26,720
Speaker 5:  somebody came up to PATOS and said, we are going to let you build the foldable

304
00:17:26,720 --> 00:17:30,040
Speaker 5:  phone of your dreams and it's, we're gonna kick ass with it. And that's why

305
00:17:30,040 --> 00:17:31,280
Speaker 5:  he's going to Amazon. This

306
00:17:31,280 --> 00:17:31,760
Speaker 4:  Is your theory.

307
00:17:31,990 --> 00:17:32,720
Speaker 5:  This is my theory.

308
00:17:32,920 --> 00:17:33,640
Speaker 4:  I mean it's a good theory.

309
00:17:34,040 --> 00:17:38,000
Speaker 5:  I I I like it. I know for sure the phone thing at Amazon is right. I

310
00:17:38,160 --> 00:17:41,840
Speaker 5:  I am a hundred percent sure that Amazon believes very strongly

311
00:17:41,870 --> 00:17:45,840
Speaker 5:  that if it wants to win, it should figure out how to make phones and that

312
00:17:45,840 --> 00:17:47,680
Speaker 5:  that is a way to do this. We

313
00:17:47,680 --> 00:17:51,480
Speaker 6:  Saw them set the table for that at the Amazon event. 'cause the Amazon event

314
00:17:51,780 --> 00:17:55,360
Speaker 6:  was about the, the show eight, which seems really nice. I wasn't

315
00:17:55,360 --> 00:17:58,920
Speaker 6:  enthusiastic about it until I spent an hour with Jen and now I'm like, yeah,

316
00:17:58,920 --> 00:18:00,000
Speaker 6:  that's cool as hell.

317
00:18:00,930 --> 00:18:01,960
Speaker 4:  Jen's good like that. Like

318
00:18:02,210 --> 00:18:05,040
Speaker 6:  She's very good at like that. And you know, there was that and there was

319
00:18:05,040 --> 00:18:08,760
Speaker 6:  the Hub and, and all of that. But most of that event was on

320
00:18:08,930 --> 00:18:12,920
Speaker 6:  Alexa and on how Alexa is different than,

321
00:18:12,990 --> 00:18:16,840
Speaker 6:  than Siri and Google assistant and better. And I don't know if that's true

322
00:18:16,910 --> 00:18:20,080
Speaker 6:  because we didn't get to actually play around with it a lot. 'cause all of

323
00:18:20,080 --> 00:18:23,960
Speaker 6:  the the demos were had massive guardrails. Really? Yeah. Like I,

324
00:18:24,040 --> 00:18:25,760
Speaker 6:  I was like, I wanna go break the, that's

325
00:18:25,760 --> 00:18:29,720
Speaker 4:  How you know that generative AI is like about to say some crazy stuff. Yeah.

326
00:18:29,870 --> 00:18:33,320
Speaker 4:  Yeah. It's like we want actually because it'll be like you wanna bang. Yeah.

327
00:18:34,080 --> 00:18:36,480
Speaker 6:  I wanted to define some weird, I wanna, I was like how can I make

328
00:18:36,480 --> 00:18:40,000
Speaker 4:  It your, what if we set a timer for five minutes to get it on, you know,

329
00:18:40,310 --> 00:18:40,600
Speaker 4:  just

330
00:18:40,600 --> 00:18:41,080
Speaker 6:  Plain abusive.

331
00:18:44,150 --> 00:18:48,120
Speaker 4:  What about you and me? Seven minutes from night? I have to stop it.

332
00:18:49,240 --> 00:18:50,000
Speaker 6:  I just hear the guitar.

333
00:18:50,100 --> 00:18:52,360
Speaker 4:  I'm just saying, look, if you're listening and you're at Amazon, you're on

334
00:18:52,360 --> 00:18:52,840
Speaker 4:  the Alexa team.

335
00:18:53,190 --> 00:18:53,920
Speaker 6:  Make it horny,

336
00:18:54,160 --> 00:18:57,920
Speaker 4:  Horny binging, rebooted Microsoft on the front

337
00:18:57,950 --> 00:19:01,160
Speaker 4:  page of The new York Times. Just send one Alexa to Kevin Ru.

338
00:19:02,020 --> 00:19:03,000
Speaker 4:  It could happen to you

339
00:19:03,540 --> 00:19:04,880
Speaker 6:  But not one of the kid exes.

340
00:19:05,180 --> 00:19:05,400
Speaker 4:  No.

341
00:19:07,520 --> 00:19:09,840
Speaker 4:  Wait, so wait, why? Why did Jen get you so excited about that?

342
00:19:12,440 --> 00:19:16,400
Speaker 6:  I think her enthusiasm for it as a Hub. 'cause she, the

343
00:19:16,400 --> 00:19:19,680
Speaker 6:  poor woman is on a quest to find something that will actually work as a Hub.

344
00:19:19,730 --> 00:19:23,080
Speaker 6:  Where you don't have to say, yeah this'll work, but 'cause that's with all

345
00:19:23,080 --> 00:19:25,680
Speaker 6:  smart home hubs. Yeah. Every single smart home Hub, you're like perfect.

346
00:19:25,940 --> 00:19:29,840
Speaker 6:  You will not need anything else except actually you're gonna need this.

347
00:19:30,100 --> 00:19:32,840
Speaker 4:  Can I, can I give you my tiny little example of this right now? Yes. So,

348
00:19:32,840 --> 00:19:36,200
Speaker 4:  we have a new house. So Jen and I, there are lots of backhanding which Oh

349
00:19:36,200 --> 00:19:39,320
Speaker 4:  yeah. And it's not, it's not great Matter is not ready

350
00:19:40,340 --> 00:19:44,120
Speaker 4:  do not buy. Look, it's a bad time to buy a house for a lot of reasons. But

351
00:19:44,120 --> 00:19:46,800
Speaker 4:  if you're listening to the show, it's a bad time to buy a house. 'cause you're

352
00:19:46,800 --> 00:19:50,160
Speaker 4:  gonna want to put smart stuff in it. And the standard is not ready. Yeah.

353
00:19:50,160 --> 00:19:53,760
Speaker 4:  Nope. It is just not ready. So you are trapped

354
00:19:54,270 --> 00:19:58,200
Speaker 4:  into buying obsolete technology. It is the worst feeling in the world. Yeah.

355
00:19:58,220 --> 00:20:01,840
Speaker 4:  You're like, I'm gonna go all in on HomeKit. Like whatever. Except

356
00:20:02,060 --> 00:20:05,640
Speaker 4:  here's what HomeKit can't do. You can't tell HomeKit where you live.

357
00:20:06,310 --> 00:20:10,080
Speaker 4:  What? Nope. So you just can't, there's no Yeah. Direct

358
00:20:10,150 --> 00:20:14,000
Speaker 4:  interface. It doesn't understand where like my house is here. It just

359
00:20:14,000 --> 00:20:17,320
Speaker 4:  detects it off your phone. And if you set up new routers

360
00:20:17,910 --> 00:20:21,840
Speaker 4:  with new Mac addresses, apple TV doesn't have a G P S

361
00:20:21,840 --> 00:20:25,800
Speaker 4:  in it. So it just decides where your house is gonna be when you set

362
00:20:25,800 --> 00:20:28,560
Speaker 4:  it up as a home. It's like, I've never seen that Mac address before on this

363
00:20:28,560 --> 00:20:31,500
Speaker 4:  router. You probably live in your old house. Right.

364
00:20:33,330 --> 00:20:37,260
Speaker 4:  Just bonkers and every, every smart home thing.

365
00:20:37,330 --> 00:20:40,980
Speaker 4:  Like it's just missing one thing. Yeah. For example, a home kit missing an

366
00:20:40,980 --> 00:20:44,660
Speaker 4:  address field. Minor detail. Minor detail.

367
00:20:44,690 --> 00:20:47,760
Speaker 4:  It's a little one. You look at the, the Reddit threads of people who are

368
00:20:47,760 --> 00:20:51,280
Speaker 4:  like, HomeKit doesn't know where I live. It's like five years deep

369
00:20:52,300 --> 00:20:55,720
Speaker 4:  and the workarounds are ridiculous. But it's true. Most things are

370
00:20:55,940 --> 00:20:59,040
Speaker 4:  matter or thread or is it, they're missing one piece of the puzzle. Right.

371
00:20:59,260 --> 00:21:02,880
Speaker 4:  Matter itself. Just, you know, like when you're like building a new city

372
00:21:02,880 --> 00:21:05,640
Speaker 4:  in Sim City and you're like, I'll just fi finish that road at some other

373
00:21:05,640 --> 00:21:06,920
Speaker 4:  time matter.

374
00:21:07,500 --> 00:21:11,440
Speaker 5:  Yep. It's a good road. It's like a beautiful four blocks of

375
00:21:11,440 --> 00:21:12,600
Speaker 5:  a road. Yeah. Yeah.

376
00:21:12,620 --> 00:21:14,880
Speaker 4:  And you're like, something good's gonna happen and

377
00:21:14,880 --> 00:21:15,760
Speaker 6:  You just stop, park

378
00:21:15,900 --> 00:21:19,000
Speaker 4:  The car and that's like matter and doorbells. It's like you're just an area

379
00:21:19,000 --> 00:21:22,560
Speaker 4:  of your town labeled that and you, you come back around to it later. Yeah.

380
00:21:23,300 --> 00:21:26,640
Speaker 6:  And it sounds like the show eight is gonna be a little bit more

381
00:21:27,030 --> 00:21:29,880
Speaker 6:  inclusive. It's gonna have, it's gonna have the stuff,

382
00:21:30,730 --> 00:21:34,240
Speaker 6:  it'll work and theoretically if this

383
00:21:34,330 --> 00:21:38,280
Speaker 6:  generative AI works Yeah. Then, then yeah. We're that

384
00:21:38,620 --> 00:21:42,000
Speaker 6:  one step closer to the Star Trek computer

385
00:21:42,530 --> 00:21:45,640
Speaker 6:  dream, which is kind of how I understand Amazon's dream.

386
00:21:45,670 --> 00:21:48,480
Speaker 4:  Yeah. I mean that that Dave's limb stream, like he has talked to us about

387
00:21:48,480 --> 00:21:52,240
Speaker 4:  ambient computing quite a lot. Yeah. But you weren't able

388
00:21:52,480 --> 00:21:54,280
Speaker 4:  actually to try out these generative AI features.

389
00:21:54,380 --> 00:21:58,240
Speaker 6:  Not really. I tried to, I tried it with a fire TV and I wasn't allowed to

390
00:21:58,240 --> 00:22:02,120
Speaker 6:  ask questions, which Oh. And it was just super, super

391
00:22:02,120 --> 00:22:04,840
Speaker 6:  guardrail. He clearly had like, okay, these are the ones I'm gonna show you

392
00:22:04,840 --> 00:22:07,640
Speaker 6:  to showcase his stuff. Which is fine. I think that's very normal for these

393
00:22:07,640 --> 00:22:11,520
Speaker 6:  kind of situations. The, the Internet's really crappy as we saw when

394
00:22:11,990 --> 00:22:15,920
Speaker 6:  like limp had struggles on stage because it seemed like

395
00:22:15,920 --> 00:22:19,200
Speaker 6:  the, oh boy, the Alexa like lost connection at one point. And he was just

396
00:22:19,200 --> 00:22:22,560
Speaker 6:  like, I'm just gonna stand here awkwardly and wait,

397
00:22:22,660 --> 00:22:26,400
Speaker 4:  See this is why I prefer live demos to whatever Apple's doing. Oh yeah. That's,

398
00:22:26,400 --> 00:22:28,800
Speaker 4:  it's, that's like even that just hearing that is like makes this whole thing

399
00:22:28,800 --> 00:22:28,960
Speaker 4:  much.

400
00:22:28,980 --> 00:22:32,240
Speaker 6:  It was nice and but you have to remember, okay, well you know this is one

401
00:22:32,240 --> 00:22:34,760
Speaker 6:  of the most challenging networking environments you can have. 'cause you

402
00:22:34,760 --> 00:22:38,440
Speaker 6:  have a hundred journalists all with like cameras and

403
00:22:38,470 --> 00:22:42,160
Speaker 6:  laptops uploading a ton of stuff all at once in one

404
00:22:42,160 --> 00:22:44,520
Speaker 6:  small room you destroy the internet.

405
00:22:44,840 --> 00:22:47,120
Speaker 5:  Whatever. Yeah. If Taylor Swift can do it for the ERAS tour. I

406
00:22:47,120 --> 00:22:48,040
Speaker 4:  Don't care. Five G baby.

407
00:22:48,900 --> 00:22:52,440
Speaker 5:  No, I will say the, the thing Dave Limp told me is that most of this stuff

408
00:22:52,440 --> 00:22:56,200
Speaker 5:  is not live yet and finished. Like the, even the folks who

409
00:22:56,580 --> 00:23:00,000
Speaker 5:  buy some of these products early on may not get the full

410
00:23:00,490 --> 00:23:04,360
Speaker 5:  generative AI piece of it. It's all backend stuff, right?

411
00:23:04,360 --> 00:23:08,280
Speaker 5:  Like all the stuff is happening on Amazon's side of things. That's

412
00:23:08,280 --> 00:23:12,200
Speaker 5:  why a lot of this tech is coming to like the original Echo, which yeah

413
00:23:12,200 --> 00:23:16,120
Speaker 5:  obviously doesn't have the hardware to like run LLMs locally, but it

414
00:23:16,120 --> 00:23:18,200
Speaker 5:  doesn't have to 'cause all this stuff is happening in the cloud and just

415
00:23:18,200 --> 00:23:22,160
Speaker 5:  being ported back to you through Alexa. But it's, it's

416
00:23:22,160 --> 00:23:26,040
Speaker 5:  gonna be a pretty slow process for Amazon. Like, Alexa is basically this

417
00:23:26,510 --> 00:23:30,040
Speaker 5:  compilation of like thousands of different little things. We think of it

418
00:23:30,040 --> 00:23:33,680
Speaker 5:  as like one character, but it's actually just a million different pipes all

419
00:23:33,680 --> 00:23:37,600
Speaker 5:  kind of coming into the voice and they're gonna do it

420
00:23:37,620 --> 00:23:40,640
Speaker 5:  as far as I understand kind of bit by bit as it goes

421
00:23:41,700 --> 00:23:45,240
Speaker 5:  before this all becomes sort of fully generative ai. And

422
00:23:45,580 --> 00:23:47,360
Speaker 5:  my understanding is that's gonna take a little while.

423
00:23:47,550 --> 00:23:48,720
Speaker 6:  Yeah. It's gonna come with the phone.

424
00:23:48,990 --> 00:23:52,160
Speaker 4:  It's gonna come with the phone. There is this new eye Gaze thing where you

425
00:23:52,160 --> 00:23:54,760
Speaker 4:  can just like look at the displays and control them with your eyes, which

426
00:23:54,760 --> 00:23:58,160
Speaker 4:  is a little terrifying. A little Amazon seems much more comfortable with

427
00:23:58,160 --> 00:24:00,760
Speaker 4:  the idea of putting cameras and smart assistant

428
00:24:00,760 --> 00:24:04,400
Speaker 6:  Devices. They have drone that you could fly around your house for

429
00:24:04,640 --> 00:24:08,600
Speaker 6:  security. Like their, their concept of security and and and stuff is way

430
00:24:08,600 --> 00:24:09,280
Speaker 6:  different. Yeah.

431
00:24:09,280 --> 00:24:11,360
Speaker 4:  They're like what if Robocop was in your home? There's

432
00:24:11,390 --> 00:24:14,240
Speaker 6:  Like three people in the world who are like, yes. Yeah. And the rest of us

433
00:24:14,240 --> 00:24:14,680
Speaker 6:  are like, mm no.

434
00:24:14,680 --> 00:24:17,520
Speaker 4:  And they're listening right now. Welcome. We appreciate you, we love you.

435
00:24:17,800 --> 00:24:20,040
Speaker 4:  But no, Amazon's just very comfortable with the idea that these things should

436
00:24:20,040 --> 00:24:23,840
Speaker 4:  have cameras as well as microphones. I am hard Stop at

437
00:24:23,840 --> 00:24:26,520
Speaker 4:  cameras. Yeah. Just no thank you. You

438
00:24:26,520 --> 00:24:30,000
Speaker 6:  Don't want a camera owned by someone else in your bedroom at all times. No

439
00:24:30,000 --> 00:24:33,200
Speaker 4:  Thank you. Shocking. I'm good. But you know, when you ask people would you

440
00:24:33,200 --> 00:24:35,400
Speaker 4:  ever put a camera in your bathroom? They're like, no. And they're like, you

441
00:24:35,400 --> 00:24:37,840
Speaker 4:  know, you carry like seven of them in your bathroom every time you, your

442
00:24:37,940 --> 00:24:38,560
Speaker 6:  Foot's free time

443
00:24:39,060 --> 00:24:40,680
Speaker 4:  And there's like, yeah. And

444
00:24:40,760 --> 00:24:43,240
Speaker 6:  Then they lie. That's fine. And they're like, it's in my pocket the whole

445
00:24:43,240 --> 00:24:44,040
Speaker 6:  time. It's not.

446
00:24:44,430 --> 00:24:48,120
Speaker 4:  Yeah. I, I hide it. I I wrap it in a little towel like a baby and put it

447
00:24:48,120 --> 00:24:48,360
Speaker 4:  away.

448
00:24:49,500 --> 00:24:51,680
Speaker 5:  But wait, Neli, the, the camera thing is really interesting. 'cause like

449
00:24:52,520 --> 00:24:56,360
Speaker 5:  I, I'm with you on the would not put a camera in like my

450
00:24:56,360 --> 00:24:59,960
Speaker 5:  bedroom that, that's been a non-starter for us for forever. I, we don't even

451
00:24:59,960 --> 00:25:00,800
Speaker 5:  have any cameras in the house.

452
00:25:02,610 --> 00:25:03,710
Speaker 5:  But like you

453
00:25:03,710 --> 00:25:05,150
Speaker 4:  Have seven of them in your pocket right now is

454
00:25:05,150 --> 00:25:07,390
Speaker 5:  What I'm saying. Hey, I mean I have seven. I have one right here. Like, you

455
00:25:07,390 --> 00:25:10,630
Speaker 5:  know what I mean? Yeah. We don't have any like smart home camera things.

456
00:25:10,860 --> 00:25:14,590
Speaker 5:  Yeah. But then there are questions like, okay not a camera,

457
00:25:14,690 --> 00:25:18,270
Speaker 5:  but what about like a radar detector that knows

458
00:25:18,540 --> 00:25:21,590
Speaker 5:  when you're getting close and can change the interface so that you can use

459
00:25:21,590 --> 00:25:22,590
Speaker 5:  it. That's

460
00:25:24,180 --> 00:25:28,040
Speaker 5:  not the same but it's not totally different either. It's like my

461
00:25:28,040 --> 00:25:31,720
Speaker 5:  device being aware of me all the way down to like my device

462
00:25:31,820 --> 00:25:35,520
Speaker 5:  can see precisely what facial expression I'm making somewhere on that spectrum

463
00:25:35,540 --> 00:25:38,360
Speaker 5:  is where I get uncomfortable and I don't know exactly where it is. Yeah.

464
00:25:38,360 --> 00:25:41,240
Speaker 5:  But I think, and like Amazon is doing this too. They have the, these really

465
00:25:41,440 --> 00:25:44,480
Speaker 5:  interesting ideas with things like the, the Hub Max, the big new smart home

466
00:25:44,480 --> 00:25:48,280
Speaker 5:  controller about when you're far away it should show you one thing,

467
00:25:48,280 --> 00:25:51,080
Speaker 5:  right? Like probably status information. It'll look like a thermostat, show

468
00:25:51,080 --> 00:25:54,240
Speaker 5:  you temperature or whatever. As you get closer, it can start to show you

469
00:25:54,240 --> 00:25:56,800
Speaker 5:  more information and when you get right up to it, it should show you buttons

470
00:25:56,800 --> 00:25:58,640
Speaker 5:  because that's what you're gonna do when you're standing right next to it.

471
00:25:58,900 --> 00:26:02,800
Speaker 5:  And to do that, they have to be able to do presence detection. It has to

472
00:26:02,800 --> 00:26:06,760
Speaker 5:  know where, who you are and where you are. And full

473
00:26:06,760 --> 00:26:10,600
Speaker 5:  color camera for that little much for my taste. But

474
00:26:10,600 --> 00:26:14,440
Speaker 5:  like, I still have not figured out where I go from like, this is a

475
00:26:14,440 --> 00:26:17,200
Speaker 5:  useful way to do a useful thing to like, eh, that's a little much.

476
00:26:17,560 --> 00:26:20,920
Speaker 6:  I like that they're, they're trying to figure it out. 'cause the Echo itself,

477
00:26:20,920 --> 00:26:24,560
Speaker 6:  like the original one was already kind of invasive and people had to,

478
00:26:24,700 --> 00:26:27,760
Speaker 6:  to reconcile that, right? Like, I'm gonna have an always on microphone in

479
00:26:27,760 --> 00:26:31,040
Speaker 6:  my house. That's way more than anybody had had before that.

480
00:26:31,040 --> 00:26:33,800
Speaker 5:  Well and the lesson learned was people got used to that really fast. Right.

481
00:26:33,800 --> 00:26:36,600
Speaker 5:  Like Amazon was like, oh we can just do this 'cause it's fine.

482
00:26:36,820 --> 00:26:40,480
Speaker 6:  And so Amazon is clearly like trying to find, okay, what's we, we have to

483
00:26:40,480 --> 00:26:43,440
Speaker 6:  do this presence detection. We have to do something because you cannot have

484
00:26:43,480 --> 00:26:46,840
Speaker 6:  a super successful smart home without some sort of like surveillance.

485
00:26:47,340 --> 00:26:50,880
Speaker 6:  That's just, you need it. Yeah. And if you want the convenience, you're gonna

486
00:26:50,880 --> 00:26:53,280
Speaker 6:  have to give that up. And so they're clearly trying to figure out, okay,

487
00:26:53,280 --> 00:26:56,880
Speaker 6:  where's, where's most people's line drone that flies around your house

488
00:26:57,170 --> 00:26:59,920
Speaker 6:  robot that drives around your house and gives you beer too much.

489
00:27:01,150 --> 00:27:04,960
Speaker 4:  Well, something those are different. I would say those are different. One

490
00:27:04,960 --> 00:27:08,720
Speaker 4:  was the robot was useful. Yeah. The drone is terrifying. Was the

491
00:27:08,720 --> 00:27:09,320
Speaker 6:  Robot useful?

492
00:27:09,630 --> 00:27:12,240
Speaker 4:  Well I'm saying well I mean it could have been useful but it wasn't useful.

493
00:27:12,240 --> 00:27:12,640
Speaker 4:  It brings me

494
00:27:12,640 --> 00:27:12,840
Speaker 5:  Beer.

495
00:27:13,410 --> 00:27:16,360
Speaker 4:  Right. I think if you, I I think if you can actually solve the it brings

496
00:27:16,360 --> 00:27:20,120
Speaker 4:  me beer problem. Like a lot of people will sign up for that at under a thousand

497
00:27:20,120 --> 00:27:23,520
Speaker 4:  dollars. Yeah, that's fair. The like there's a drone that looks at stuff

498
00:27:23,520 --> 00:27:26,880
Speaker 4:  in my house. A lot of people are like, yeah, I dunno man, just rob the place.

499
00:27:26,880 --> 00:27:28,280
Speaker 4:  Like I I can't be doing this.

500
00:27:29,180 --> 00:27:31,040
Speaker 6:  You are welcome to everything. Yeah.

501
00:27:31,780 --> 00:27:35,240
Speaker 4:  But I'm with, I I I'm with you David, that there's like some Yeah,

502
00:27:35,240 --> 00:27:36,720
Speaker 6:  There's that, there's that point. It's fuzzy.

503
00:27:36,790 --> 00:27:37,080
Speaker 4:  Yeah.

504
00:27:37,340 --> 00:27:41,080
Speaker 6:  And it seems like Amazon is trying to find that point by

505
00:27:41,240 --> 00:27:45,000
Speaker 6:  throwing things, by doing like the limp strategy, which is like, okay, well

506
00:27:45,000 --> 00:27:47,440
Speaker 6:  we're just gonna release, we can afford to release things so we're gonna

507
00:27:47,440 --> 00:27:49,240
Speaker 6:  release things and see where that line is.

508
00:27:50,320 --> 00:27:52,520
Speaker 4:  I think this is the thing that we'll change on our panas penne the most.

509
00:27:52,520 --> 00:27:52,800
Speaker 4:  Yep. Yeah.

510
00:27:52,800 --> 00:27:54,080
Speaker 6:  I think he's gonna have more focus, right?

511
00:27:54,080 --> 00:27:57,600
Speaker 4:  Like Amazon is like, we'll put a mic and speakers in it, Alexa

512
00:27:57,730 --> 00:28:01,680
Speaker 4:  light switches, whatever. And the idea that the market would settle

513
00:28:01,820 --> 00:28:05,000
Speaker 4:  on an idea I think has just not come to fruition.

514
00:28:06,110 --> 00:28:08,340
Speaker 4:  Especially 'cause Alexa hasn't been worth it.

515
00:28:08,630 --> 00:28:08,980
Speaker 6:  Right?

516
00:28:09,370 --> 00:28:12,900
Speaker 4:  Like I, man again, I'm, I'm out here trying to buy a thermostat man. Like

517
00:28:13,120 --> 00:28:17,060
Speaker 4:  the eco b I want is like it has Alexa in it. I'm like, but I don't want that.

518
00:28:17,160 --> 00:28:17,660
Speaker 4:  You can turn

519
00:28:17,660 --> 00:28:19,300
Speaker 6:  It off. I never used it.

520
00:28:19,560 --> 00:28:21,860
Speaker 4:  But why, why does it, why is it even there? I

521
00:28:21,860 --> 00:28:22,660
Speaker 6:  Don't want it. I don't know.

522
00:28:22,770 --> 00:28:26,740
Speaker 4:  Like I don't need a microphone in my thermostat man. I'm trying to tell

523
00:28:26,740 --> 00:28:30,620
Speaker 4:  this to you d it than it has whatever. It's, it's just like, but that

524
00:28:30,620 --> 00:28:34,380
Speaker 4:  was the idea. We'll just like put it everywhere. I suspect Panos will bring

525
00:28:34,380 --> 00:28:37,420
Speaker 4:  much more focus to that program. Yeah. There's a little bit of reporting

526
00:28:37,420 --> 00:28:40,620
Speaker 4:  in Reuters that like morale is low in that team. I think that's to be expected

527
00:28:40,620 --> 00:28:44,580
Speaker 4:  with any gigantic leadership change. But I also think

528
00:28:44,680 --> 00:28:48,630
Speaker 4:  the sort of leadership style is about to go

529
00:28:48,750 --> 00:28:52,670
Speaker 4:  a dramatic change. And if you've been allowed to be like, here's what we're

530
00:28:52,670 --> 00:28:56,430
Speaker 4:  gonna do. We're gonna spend tens of million dollars on a drone that flies

531
00:28:56,430 --> 00:28:59,510
Speaker 4:  around your house and then just put it out there and see what hap like

532
00:29:00,350 --> 00:29:02,270
Speaker 4:  I suspect those days are gonna come to an end.

533
00:29:02,270 --> 00:29:02,710
Speaker 5:  Yeah. I mean

534
00:29:02,730 --> 00:29:03,510
Speaker 6:  I'm gonna be sad about that.

535
00:29:03,750 --> 00:29:07,310
Speaker 5:  I think Neli, the, the truest thing I think about your feeling about Dave

536
00:29:07,360 --> 00:29:09,790
Speaker 5:  Lim's tenure is that the last like

537
00:29:11,200 --> 00:29:15,180
Speaker 5:  big capital and new thing Amazon's hardware division

538
00:29:15,420 --> 00:29:18,220
Speaker 5:  launched was that first Echo in 2014. Yeah.

539
00:29:18,440 --> 00:29:21,340
Speaker 4:  No, I, the Echo shows I think were an important turn.

540
00:29:21,400 --> 00:29:25,140
Speaker 5:  That's fair. Okay, sure. I'll give you that. But, but even that, that's,

541
00:29:25,440 --> 00:29:29,420
Speaker 5:  that's one and a half things in what amounts to a decade and,

542
00:29:29,420 --> 00:29:33,380
Speaker 5:  and everything else has been sort of iterative splinters of

543
00:29:33,380 --> 00:29:37,060
Speaker 5:  the same idea. And I think one thing Panos Pnet is very good at is being

544
00:29:37,100 --> 00:29:39,980
Speaker 5:  a fountain of big new wacky ideas. Yeah.

545
00:29:40,560 --> 00:29:43,880
Speaker 4:  You fire TV's in there actually, and Jen read about this, that Amazon has

546
00:29:43,880 --> 00:29:47,480
Speaker 4:  weirdly sort of discounted the fire TV as the centerpiece of its smart home

547
00:29:47,800 --> 00:29:51,600
Speaker 4:  strategy when it is probably by all, like by

548
00:29:51,600 --> 00:29:55,520
Speaker 4:  most measures, the most used Amazon device in most people's lives.

549
00:29:55,790 --> 00:29:59,000
Speaker 4:  Yeah. If you have a fire TV in your house, it is probably the Amazon thing

550
00:29:59,000 --> 00:30:02,200
Speaker 4:  you interact with the most. Yeah. But it's a TV so like

551
00:30:02,860 --> 00:30:05,680
Speaker 4:  you get it to play whatever you want and usually like move on with your life.

552
00:30:05,690 --> 00:30:09,160
Speaker 4:  Right. And I think there's a gap there that I think is fascinating. And they,

553
00:30:09,160 --> 00:30:10,520
Speaker 4:  they announced a new one, right? Yeah. They

554
00:30:10,520 --> 00:30:14,280
Speaker 6:  Announced two. So they announced the, the, it's The new fire TV

555
00:30:14,390 --> 00:30:17,520
Speaker 6:  four K stick and it's, it's gonna be more powerful. It's gonna be faster,

556
00:30:18,140 --> 00:30:21,960
Speaker 6:  it should have better wifi in it. And then there's gonna be a new

557
00:30:22,030 --> 00:30:26,000
Speaker 6:  fire TV Max and that's gonna have a whole like, like that's gonna

558
00:30:26,000 --> 00:30:29,960
Speaker 6:  be more in competition with the Apple tv. Which is

559
00:30:29,960 --> 00:30:33,800
Speaker 6:  great because fire TVs have notoriously stayed far, far,

560
00:30:33,900 --> 00:30:37,840
Speaker 6:  far away from the premium end of things. Which is really annoying if

561
00:30:37,840 --> 00:30:41,600
Speaker 6:  you wanna experience it. But you don't wanna look at garbage on your TV

562
00:30:41,940 --> 00:30:44,920
Speaker 6:  and like, I paid for Dolby vision, I want Dolby vision. Wait,

563
00:30:44,920 --> 00:30:47,800
Speaker 5:  But but Alex can I tell you the wildest thing about what you just described?

564
00:30:47,870 --> 00:30:51,560
Speaker 5:  What the pr your, your description is exactly Right. And the difference between

565
00:30:51,560 --> 00:30:55,040
Speaker 5:  bottom and top is $10. It's

566
00:30:55,180 --> 00:30:59,040
Speaker 5:  $10. Buy the fancy one. People like wait for our

567
00:30:59,040 --> 00:31:01,320
Speaker 5:  reviews. We'll probably review them. Please

568
00:31:01,340 --> 00:31:01,840
Speaker 6:  Buy the Max.

569
00:31:01,890 --> 00:31:05,600
Speaker 5:  There are many smarter people with Virgin on this stuff than I am. But I'm

570
00:31:05,600 --> 00:31:08,560
Speaker 5:  here to tell you, if you are going to buy one of The new fire TV sticks,

571
00:31:08,890 --> 00:31:12,520
Speaker 5:  spend the $10, get the Dolby, get the better features,

572
00:31:12,820 --> 00:31:15,760
Speaker 5:  get the faster speeds. It will last you longer. It will make you happier.

573
00:31:16,030 --> 00:31:17,480
Speaker 5:  It's $10.

574
00:31:21,030 --> 00:31:24,960
Speaker 5:  It's, I don't understand why this other one exists. Like Amazon

575
00:31:24,960 --> 00:31:27,960
Speaker 5:  likes to do the thing where they're like, this one costs $5 and this one

576
00:31:27,960 --> 00:31:30,640
Speaker 5:  costs $50. And then I'm like, okay these, this is, these are real things

577
00:31:30,820 --> 00:31:34,480
Speaker 5:  and then they discount the one really heavily on prime day and they'll just

578
00:31:34,480 --> 00:31:37,000
Speaker 5:  like give it to you anytime you put anything in your cart. Like whatever.

579
00:31:37,100 --> 00:31:40,360
Speaker 5:  That's all fine and good. This one is, if you're gonna have a $50 one, that's

580
00:31:40,360 --> 00:31:42,880
Speaker 5:  fine and a $60 one. That's very good. Like what are we doing?

581
00:31:43,880 --> 00:31:44,480
Speaker 4:  I don't understand.

582
00:31:44,750 --> 00:31:45,040
Speaker 6:  Yeah.

583
00:31:45,300 --> 00:31:47,520
Speaker 4:  All right. Lastly we have to talk about the Echo. Frames Then. we gotta take

584
00:31:47,520 --> 00:31:50,120
Speaker 4:  a break. We do. Why did they make glasses again? So,

585
00:31:50,120 --> 00:31:53,280
Speaker 5:  Okay, I can answer this question because I asked Dave limp this question.

586
00:31:53,990 --> 00:31:57,880
Speaker 5:  Okay. I literally pointed at them on the table in

587
00:31:57,880 --> 00:32:01,200
Speaker 5:  front of him in this conference room. We were sitting and talking and I was

588
00:32:01,200 --> 00:32:04,520
Speaker 5:  like, smart glasses are these, are these a thing? And he goes,

589
00:32:05,160 --> 00:32:08,920
Speaker 5:  I don't know. So what I can tell you is true is that like the

590
00:32:09,120 --> 00:32:12,800
Speaker 5:  last time Amazon had this run of like weird stuff they were gonna launch,

591
00:32:12,800 --> 00:32:16,600
Speaker 5:  they did a ring, they did a whole bunch of other stuff. All with the idea

592
00:32:16,600 --> 00:32:20,440
Speaker 5:  of like things you have on you all the time that might connect to Alexa.

593
00:32:20,450 --> 00:32:23,800
Speaker 5:  Right? Most of those things didn't find an audience. They're not here. It's

594
00:32:23,800 --> 00:32:26,880
Speaker 5:  not an accident that like the Echo ring to does not exist.

595
00:32:27,900 --> 00:32:31,800
Speaker 5:  The Frames, he said caught on, they're not huge, they're not earth

596
00:32:31,800 --> 00:32:35,560
Speaker 5:  shatteringly popular. But he said he was like, we have found

597
00:32:35,760 --> 00:32:38,320
Speaker 5:  a bunch of kinds of people who really love this

598
00:32:39,640 --> 00:32:41,880
Speaker 5:  outdoorsy people who have always been the target market for this, right?

599
00:32:41,880 --> 00:32:45,400
Speaker 5:  Like you want, you wanna be able to listen to music and talk to your device

600
00:32:45,400 --> 00:32:49,040
Speaker 5:  without having headphones blocking you from the world. That's useful.

601
00:32:49,780 --> 00:32:52,480
Speaker 5:  And like Bose is working on this kind of stuff. Meta is working on this kind

602
00:32:52,480 --> 00:32:56,360
Speaker 5:  of stuff. There's like this there teeny tiny little but kind of growing smart

603
00:32:56,360 --> 00:33:00,040
Speaker 5:  glasses world that I think is sort of fascinating. But

604
00:33:00,700 --> 00:33:04,160
Speaker 5:  he basically was like, what we thought happened the last time was that they

605
00:33:04,160 --> 00:33:07,520
Speaker 5:  were severely limited by the fact that they didn't look very good.

606
00:33:08,070 --> 00:33:11,840
Speaker 5:  That we thought there might be more people who were interested in relatively

607
00:33:11,840 --> 00:33:15,480
Speaker 5:  lightweight, relatively simple glasses that

608
00:33:16,380 --> 00:33:19,080
Speaker 5:  let you talk to Alexa and play music, period.

609
00:33:20,220 --> 00:33:23,240
Speaker 5:  So with this generation we made them nicer looking and they are in fact much

610
00:33:23,240 --> 00:33:25,960
Speaker 5:  nicer looking. They have a bunch of different styles, they have some different

611
00:33:25,960 --> 00:33:29,400
Speaker 5:  lenses. They did a thing with Carrera that looked so bad when I put them

612
00:33:29,400 --> 00:33:33,200
Speaker 5:  on, but I'm sure will look cool on other people's faces. Yeah. But they're

613
00:33:33,200 --> 00:33:36,840
Speaker 5:  like, I, I get the sense that they're like, okay this is the good version

614
00:33:36,900 --> 00:33:40,160
Speaker 5:  of this product that some people seem to have caught onto already.

615
00:33:40,670 --> 00:33:44,280
Speaker 5:  Like let's see if there really is a there there on this one. So I'm

616
00:33:44,480 --> 00:33:47,160
Speaker 5:  fascinated to see how well this thing actually does. I

617
00:33:47,160 --> 00:33:48,240
Speaker 4:  Can't wait to make you review these.

618
00:33:48,980 --> 00:33:52,160
Speaker 5:  I'm down, I went back and looked at our old review and all of the pictures

619
00:33:52,540 --> 00:33:56,480
Speaker 5:  are deter looking very serious. Holding one of the stems of the

620
00:33:56,480 --> 00:33:57,400
Speaker 5:  glasses. It's so

621
00:33:57,400 --> 00:34:00,680
Speaker 4:  Good. Yes, it's good. This is why I'm excited for it. I can't wait. Very

622
00:34:00,680 --> 00:34:04,440
Speaker 4:  serious. Can do the same outfit too. That's Amazon. There's lots of

623
00:34:04,600 --> 00:34:08,440
Speaker 4:  coverage on the site if you're into the, there's an Euro Pro Max with wifi

624
00:34:08,530 --> 00:34:12,440
Speaker 4:  7, 2 10 gig ports and two 2.5 gig ports.

625
00:34:12,470 --> 00:34:12,960
Speaker 4:  It's huge.

626
00:34:13,270 --> 00:34:13,560
Speaker 5:  It's

627
00:34:13,580 --> 00:34:17,440
Speaker 4:  Do you need that's it's $1,700 for a three pack. It's

628
00:34:17,440 --> 00:34:18,200
Speaker 4:  great. I love it.

629
00:34:18,200 --> 00:34:19,400
Speaker 5:  You're gonna buy it for sure.

630
00:34:19,990 --> 00:34:23,800
Speaker 4:  Like you know there's like a No you have one gig internet service. Although

631
00:34:23,800 --> 00:34:26,280
Speaker 4:  we could get eight gig optimum service, I just couldn't figure out what for

632
00:34:26,420 --> 00:34:29,680
Speaker 4:  and now I'm like, oh it's so I couldn't buy this router. Yeah, it's a horrible

633
00:34:29,780 --> 00:34:33,560
Speaker 4:  way. It's a horrible way to spend $1,700 is switching to

634
00:34:33,560 --> 00:34:37,320
Speaker 4:  Optimum. No thank you. No thank you. But

635
00:34:37,320 --> 00:34:41,240
Speaker 4:  it's great. The Echo Hub Max, go look on

636
00:34:41,240 --> 00:34:44,840
Speaker 4:  the site. It's all fun stuff to look at. But the real news here is that

637
00:34:45,230 --> 00:34:48,240
Speaker 4:  this is like the end of one line of thinking. Yes.

638
00:34:48,890 --> 00:34:52,600
Speaker 4:  Which is just utterly fascinating to me. Yeah and it all happened on the

639
00:34:52,600 --> 00:34:56,000
Speaker 4:  same day. It is. Great. Okay, so we're gonna take a break, we're gonna come

640
00:34:56,000 --> 00:34:58,800
Speaker 4:  back, we're gonna talk about Microsoft's event, which is on the other end

641
00:34:59,180 --> 00:35:00,200
Speaker 4:  of all this Trump we

642
00:37:11,600 --> 00:37:14,570
Speaker 4:  Okay, we're back. Should we do the leaks first with Microsoft or should we

643
00:37:14,570 --> 00:37:15,450
Speaker 4:  do the event first? Let's

644
00:37:15,450 --> 00:37:16,170
Speaker 6:  Event and Then we. Yeah,

645
00:37:16,170 --> 00:37:18,690
Speaker 5:  Let's do the event and then we'll do the leaks because that's way more interesting

646
00:37:18,750 --> 00:37:21,530
Speaker 5:  and the event will seem like a super bummer if we talk about the leaks

647
00:37:21,530 --> 00:37:24,890
Speaker 4:  First. So Microsoft had a a Surface event today. Mm.

648
00:37:25,310 --> 00:37:26,890
Speaker 6:  Is that fair to call it a Surface event?

649
00:37:27,480 --> 00:37:30,890
Speaker 4:  Well, not anymore. 'cause Panos is gone. Exactly. So Panos was like tweeting

650
00:37:30,890 --> 00:37:33,410
Speaker 4:  about this a couple weeks ago. I I'm excited to be in New York. Do the thing,

651
00:37:33,410 --> 00:37:36,570
Speaker 4:  da da da show off The new Surface. We've all seen these events. Yeah.

652
00:37:37,470 --> 00:37:40,330
Speaker 4:  One of them, he was like, I made The new Surface, I made it for you Joanna

653
00:37:40,330 --> 00:37:43,250
Speaker 4:  Stern and like pointed at her. It was great. It's like an all time great

654
00:37:43,250 --> 00:37:47,130
Speaker 4:  tech event moment. And she was like me And he's like, yeah it's you. It was

655
00:37:47,250 --> 00:37:47,410
Speaker 4:  great.

656
00:37:48,990 --> 00:37:52,890
Speaker 4:  He bailed on Monday, just tweet I'm out. Yep. And then there was

657
00:37:52,930 --> 00:37:55,330
Speaker 4:  a scramble and as you said Bloomberg report. He is going Amazon, no one's

658
00:37:55,330 --> 00:37:58,570
Speaker 4:  confirming anything. There's a lot of speculation. What? Whatever. So the

659
00:37:58,770 --> 00:38:02,570
Speaker 4:  Microsoft has to like do this event and they scrambled up

660
00:38:02,720 --> 00:38:06,610
Speaker 4:  some people Nadella showed up. Yeah. And what'd

661
00:38:06,770 --> 00:38:10,690
Speaker 4:  they do? They said it's all about AI now. So what happened at this

662
00:38:10,690 --> 00:38:10,890
Speaker 4:  event?

663
00:38:11,000 --> 00:38:14,450
Speaker 6:  They didn't announce the Surface Pro but we weren't expecting that. They

664
00:38:14,450 --> 00:38:17,490
Speaker 6:  announced a new Surface studio Laptop.

665
00:38:18,070 --> 00:38:18,610
Speaker 4:  It looks cool,

666
00:38:18,710 --> 00:38:22,290
Speaker 6:  But they didn't talk about the plinth. Remember the plinth? Yeah. That was

667
00:38:22,290 --> 00:38:25,010
Speaker 6:  a big part of the last one. The flat part. The flat part.

668
00:38:26,310 --> 00:38:27,850
Speaker 4:  Plinth. It's a good word.

669
00:38:27,880 --> 00:38:28,650
Speaker 6:  Yeah, it's a good word.

670
00:38:28,840 --> 00:38:31,690
Speaker 4:  More thing you should, you should pull over your car right now and make a

671
00:38:31,690 --> 00:38:35,120
Speaker 4:  list of five things you wish to describe as a plinth and then go to wherever

672
00:38:35,120 --> 00:38:36,920
Speaker 4:  you're going and just say it. Yeah. All the time.

673
00:38:37,340 --> 00:38:40,320
Speaker 6:  If Panos had been there he would've said plinth. Yeah it would, it would've

674
00:38:40,320 --> 00:38:44,000
Speaker 6:  been great. But they announced a new Surface Laptop go three.

675
00:38:44,500 --> 00:38:48,320
Speaker 6:  So that's nice little upgrade there. And they announced a new Surface go

676
00:38:48,430 --> 00:38:52,040
Speaker 6:  four. And I love a Surface go. That's one of my favorite devices in the world.

677
00:38:52,380 --> 00:38:55,680
Speaker 6:  But it's also one of the most disappointing devices in the world. 'cause

678
00:38:55,680 --> 00:38:59,440
Speaker 6:  it's so cute. Yeah. And it's so small and then it's so expensive

679
00:38:59,460 --> 00:39:00,600
Speaker 6:  for what it is. Yeah.

680
00:39:00,670 --> 00:39:04,520
Speaker 5:  It's also not meant for regular humans like this. This is like a business

681
00:39:04,520 --> 00:39:07,520
Speaker 5:  device for business people. Right? Didn't they? They explicitly pitched it

682
00:39:07,520 --> 00:39:09,160
Speaker 5:  to frontline workers this year. Yeah.

683
00:39:09,260 --> 00:39:13,040
Speaker 6:  So this year it is not gonna be sold to us, us normal folks. You're gonna

684
00:39:13,040 --> 00:39:16,400
Speaker 6:  have to like go through your ID it department or something like that. It

685
00:39:16,400 --> 00:39:20,080
Speaker 6:  is still gonna be outrageously expensive at $550. It is still gonna be

686
00:39:20,080 --> 00:39:20,640
Speaker 6:  outrageous. Yeah.

687
00:39:20,640 --> 00:39:22,360
Speaker 4:  But if you're provisioning u p s

688
00:39:22,780 --> 00:39:26,200
Speaker 6:  No but it's overpriced because it's got an Intel in 200.

689
00:39:26,860 --> 00:39:28,080
Speaker 4:  Brutal. It's

690
00:39:28,080 --> 00:39:31,720
Speaker 6:  Just like y'all did you try Monica

691
00:39:31,940 --> 00:39:35,000
Speaker 6:  got to chest it out. She was not enthusiastic. It was, it was, it was still,

692
00:39:35,140 --> 00:39:38,080
Speaker 6:  she could see the slow slowness of it. She, she and Tom. I

693
00:39:38,080 --> 00:39:41,480
Speaker 5:  Love that. This is the device you've chosen to focus on so far. Cranz

694
00:39:41,860 --> 00:39:45,560
Speaker 5:  the one device that people can't buy and the worst one by far. And you're

695
00:39:45,560 --> 00:39:47,200
Speaker 5:  like, let's talk about that for a while. That

696
00:39:47,200 --> 00:39:50,600
Speaker 6:  One's my favorite. 'cause it's so cute. And you're just like, want, it

697
00:39:50,600 --> 00:39:53,640
Speaker 4:  Is cute. Everyone loves a cute little tablet. That sucks. All right. Yeah.

698
00:39:53,660 --> 00:39:56,480
Speaker 4:  We all, we've all done it. We all, everybody every who hasn't bought a cute

699
00:39:56,480 --> 00:39:57,920
Speaker 4:  little tablet? That sucks. I've, we've got

700
00:39:57,950 --> 00:40:00,920
Speaker 6:  Four fire key like fire pads.

701
00:40:01,110 --> 00:40:02,680
Speaker 4:  I've heard of Nexus seven for god's sake.

702
00:40:02,880 --> 00:40:04,280
Speaker 5:  Okay, that didn't suck. How dare you

703
00:40:07,710 --> 00:40:10,880
Speaker 4:  Come in? Like we wrapped it in leather, like a motorcycle. I was like, I

704
00:40:10,880 --> 00:40:12,160
Speaker 4:  love you. And I was like, mm.

705
00:40:14,190 --> 00:40:15,320
Speaker 6:  Leather's. Nice. All

706
00:40:15,320 --> 00:40:18,280
Speaker 4:  Right. Tell me about the actual Laptop studio too. Does it have a good chip

707
00:40:18,280 --> 00:40:20,320
Speaker 4:  in it? This is always the the crime. Yeah.

708
00:40:20,670 --> 00:40:23,080
Speaker 6:  With Surface devices. So this was interesting 'cause it sounds like the the,

709
00:40:23,080 --> 00:40:26,720
Speaker 6:  the Laptop too. They actually put the real chip in it. They put, they put

710
00:40:27,480 --> 00:40:31,320
Speaker 6:  13th gen instead of 12 gen, which is like Microsoft's hallmark. They

711
00:40:31,470 --> 00:40:34,840
Speaker 6:  love to put last gen stuff in. Yeah. And they're like, don't you wanna pay

712
00:40:34,840 --> 00:40:38,800
Speaker 6:  the exact same price? No, no one wants to do that. So it

713
00:40:38,800 --> 00:40:41,960
Speaker 6:  was really, really nice that they did that this time. I think the G P U is

714
00:40:41,960 --> 00:40:44,240
Speaker 6:  still an older generation.

715
00:40:44,300 --> 00:40:46,200
Speaker 4:  Of course. I mean it's always, there's always something. Oh

716
00:40:46,200 --> 00:40:50,120
Speaker 6:  No it's, it's an R T X 40 50 or an R T X 40 60 G P U. So that's not

717
00:40:50,120 --> 00:40:54,080
Speaker 6:  too bad and it's real pretty. The

718
00:40:54,080 --> 00:40:56,040
Speaker 6:  last one was really cool like yeah

719
00:40:56,520 --> 00:40:58,040
Speaker 4:  I was gonna get a Windows. Laptop I would get this one.

720
00:40:58,190 --> 00:41:02,120
Speaker 6:  Yeah, it's the coolest one. Yeah. Is it really expensive? Do

721
00:41:02,120 --> 00:41:05,640
Speaker 6:  most people need it? Probably not. But is it really, really, really cool?

722
00:41:05,790 --> 00:41:08,120
Speaker 5:  It's a MacBook Pro, right? Like this is, this is

723
00:41:08,230 --> 00:41:08,720
Speaker 6:  With a

724
00:41:08,720 --> 00:41:12,480
Speaker 5:  Plin. This is actually a thing that the Windows

725
00:41:12,550 --> 00:41:16,320
Speaker 5:  ecosystem doesn't have enough of. When you get to really powerful computers,

726
00:41:17,060 --> 00:41:20,520
Speaker 5:  way too many of them tend to either get really big and really heavy or super

727
00:41:20,780 --> 00:41:24,680
Speaker 5:  gamery and both of those things are for valid reasons and there are

728
00:41:24,680 --> 00:41:28,280
Speaker 5:  real markets there. But I think one thing Microsoft

729
00:41:28,280 --> 00:41:32,120
Speaker 5:  correctly sussed out with this line was we need a thing

730
00:41:32,120 --> 00:41:36,080
Speaker 5:  that is very attractive. The the size is about right for

731
00:41:36,080 --> 00:41:39,680
Speaker 5:  what it is and it's powerful And it does like

732
00:41:39,890 --> 00:41:43,160
Speaker 5:  nifty surfacey things like the pull forward screen that it has. Yeah. Where

733
00:41:43,340 --> 00:41:46,480
Speaker 5:  it sort of comes off its hinge and you can like drape it over the keyboard

734
00:41:46,820 --> 00:41:50,320
Speaker 5:  is very cool. And if you're a person who uses a Surface pen a lot, it's really

735
00:41:50,340 --> 00:41:54,160
Speaker 5:  useful. And it's like that to me is, I'm like this is how you make the MacBook

736
00:41:54,400 --> 00:41:58,280
Speaker 5:  a touch device Apple. Like there it is. Yes that's the answer. But I feel

737
00:41:58,280 --> 00:42:02,240
Speaker 5:  like I agree that this is not the one for most people but like this is

738
00:42:02,280 --> 00:42:06,240
Speaker 5:  a good thing that should exist and it's good that Microsoft finally got it

739
00:42:06,240 --> 00:42:10,080
Speaker 5:  right. I have the first Laptop studio here, it's my like go-to Windows

740
00:42:10,080 --> 00:42:13,760
Speaker 5:  machine and I love it to bits but anytime you try to do

741
00:42:14,040 --> 00:42:18,000
Speaker 5:  anything like intense on it, it just kind of falls apart. And I'm

742
00:42:18,000 --> 00:42:21,280
Speaker 5:  kind, it seems like Microsoft went after this one. It has more ports that

743
00:42:21,280 --> 00:42:24,280
Speaker 5:  has better power. Like it could be a win if they can get the battery life

744
00:42:24,280 --> 00:42:26,160
Speaker 5:  right. That's gonna be the question. Do you think

745
00:42:26,160 --> 00:42:29,680
Speaker 4:  His Panos is walking out the door? He's scratched out the previous

746
00:42:29,680 --> 00:42:33,000
Speaker 4:  generation processor and was like put a good one in it. He,

747
00:42:33,340 --> 00:42:35,520
Speaker 5:  He just turned the 12 into a 13 and said

748
00:42:35,520 --> 00:42:39,400
Speaker 4:  Goodbye everybody with a bit Surface fan. He's peace. He was

749
00:42:39,400 --> 00:42:42,320
Speaker 4:  like I got like one more thing by the good one.

750
00:42:42,500 --> 00:42:45,120
Speaker 5:  The most interesting thing about this event by far to me was that it took

751
00:42:45,120 --> 00:42:49,080
Speaker 5:  them 40 out of 60 minutes to even talk about hardware. Yeah.

752
00:42:49,230 --> 00:42:53,160
Speaker 5:  Like this was not a devices event in the way that we're used

753
00:42:53,160 --> 00:42:56,840
Speaker 5:  to. And the same is true of the Amazon event. Like both of these were events

754
00:42:56,890 --> 00:43:00,880
Speaker 5:  about ai, right? Like the Microsoft spent the vast majority of this event

755
00:43:00,880 --> 00:43:04,520
Speaker 5:  talking about Copilot and the idea that you're gonna have this AI

756
00:43:04,520 --> 00:43:08,200
Speaker 5:  assistant that works in all of your apps and on your computer and on your

757
00:43:08,200 --> 00:43:11,800
Speaker 5:  phone and understands everything about you and can just sort of stitch your

758
00:43:11,800 --> 00:43:15,560
Speaker 5:  life together in this helpful AI way. And part of it was like

759
00:43:15,800 --> 00:43:19,040
Speaker 5:  relaunching products we've heard a bunch about already, which was odd. They

760
00:43:19,040 --> 00:43:22,920
Speaker 5:  like announced a new version of Windows but only in sort of passing as they

761
00:43:22,920 --> 00:43:26,840
Speaker 5:  were talking about Copilot. Like this was with Copilot event in which they

762
00:43:27,000 --> 00:43:30,960
Speaker 5:  launched hardware on which you might do co-pilot things. Which I think is

763
00:43:31,120 --> 00:43:34,680
Speaker 5:  fascinating 'cause there was also this business insider story I believe today

764
00:43:34,960 --> 00:43:38,840
Speaker 5:  Thursday as we're recording this, about why Panos left Microsoft. And one

765
00:43:38,840 --> 00:43:42,800
Speaker 5:  of the answers was because he was frustrated that in this huge

766
00:43:42,800 --> 00:43:46,760
Speaker 5:  switch to ai, Microsoft was devaluing its hardware because it's

767
00:43:46,920 --> 00:43:49,520
Speaker 5:  building these things that work everywhere and who cares about having like

768
00:43:49,600 --> 00:43:53,400
Speaker 5:  a flagship device. It's very funny that he would then go to Amazon,

769
00:43:53,400 --> 00:43:56,600
Speaker 5:  which just spent a whole event doing the exact same thing. But like

770
00:43:56,990 --> 00:44:00,240
Speaker 5:  clearly that's what Microsoft is doing, right? Like it's every Yeah. Big

771
00:44:00,420 --> 00:44:03,720
Speaker 5:  bet it's making is about ai. Well

772
00:44:03,720 --> 00:44:07,480
Speaker 6:  It's kind of interesting because this also all came on the same week that

773
00:44:07,480 --> 00:44:11,320
Speaker 6:  there was a whole bunch of leaks about Microsoft

774
00:44:11,700 --> 00:44:14,600
Speaker 6:  and in those leaks they were, it was some of those leaks were about the strategy

775
00:44:14,620 --> 00:44:17,760
Speaker 6:  for Microsoft. And last year, as soon as last year they were all sitting

776
00:44:17,760 --> 00:44:21,720
Speaker 6:  there, Satya was saying we have to have a unified strategy that pushes our

777
00:44:21,880 --> 00:44:24,880
Speaker 6:  hardware, that pushes our software that does it all together. And for us

778
00:44:24,950 --> 00:44:28,880
Speaker 6:  it's gonna be hybrid cloud computing. And so it

779
00:44:28,880 --> 00:44:31,370
Speaker 6:  was this whole thing about game computing and how you were gonna gonna be

780
00:44:31,370 --> 00:44:33,920
Speaker 6:  able to like do some of the processing on the computer and some of it in

781
00:44:33,920 --> 00:44:37,880
Speaker 6:  the cloud. And that was the whole thing. And it seems like AI kind of like

782
00:44:38,860 --> 00:44:42,160
Speaker 6:  has pushed that to the side and they're like, oh we now have a new unified

783
00:44:42,160 --> 00:44:46,000
Speaker 6:  vision and it's AI and then Panos leaves and now it's like okay but the

784
00:44:46,200 --> 00:44:47,560
Speaker 6:  hardware, what's happening with the hardware?

785
00:44:47,790 --> 00:44:51,000
Speaker 4:  Yeah. There's no, like I said, it'd be better if they switch places. Yeah.

786
00:44:51,660 --> 00:44:55,600
Speaker 4:  But no one is in charge of hardware. I mean we have a memo and it's like

787
00:44:55,600 --> 00:44:57,640
Speaker 4:  some people but they're shuffling new people into it. Dave

788
00:44:57,670 --> 00:45:00,920
Speaker 5:  Limp coming in to be the Copilot guy actually makes a certain amount of sense

789
00:45:00,920 --> 00:45:02,920
Speaker 5:  given what he's been up to at Amazon all these

790
00:45:02,920 --> 00:45:04,800
Speaker 4:  Years. Do it just drive your cars in different direction guys. Yeah.

791
00:45:05,110 --> 00:45:05,400
Speaker 6:  Wave

792
00:45:05,710 --> 00:45:07,040
Speaker 4:  Just like high five on the highway.

793
00:45:09,640 --> 00:45:12,950
Speaker 4:  Let's talk about this Copilot stuff 'cause there's quite a bit of it, but

794
00:45:12,950 --> 00:45:16,670
Speaker 4:  like David said, a lot of it's been announced already. Yeah. So Windows Copilot

795
00:45:16,670 --> 00:45:20,430
Speaker 4:  seems like a big idea. Like the computer will use our computer for you,

796
00:45:20,490 --> 00:45:22,790
Speaker 4:  but it also seems fairly limited. I think it's

797
00:45:22,830 --> 00:45:26,590
Speaker 6:  A terrifying idea. I was talking with Tom about it before we came to

798
00:45:26,590 --> 00:45:30,470
Speaker 6:  record The Vergecast and we were both like, yeah Copilot

799
00:45:30,470 --> 00:45:34,350
Speaker 6:  seems really cool, but how are you gonna trust this AI that we

800
00:45:34,350 --> 00:45:38,030
Speaker 6:  don't know is finished with your spreadsheets for your Fortune 500

801
00:45:38,030 --> 00:45:38,430
Speaker 6:  company?

802
00:45:39,300 --> 00:45:40,150
Speaker 4:  Yeah, you shouldn't do that.

803
00:45:40,160 --> 00:45:44,070
Speaker 6:  Don't do that. And and so I, I really am kind of worried that their,

804
00:45:44,120 --> 00:45:47,990
Speaker 6:  their ambition to show that they are the kings of AI and they're hip and

805
00:45:47,990 --> 00:45:51,830
Speaker 6:  cool now and they beat Google is gonna shoot them in the

806
00:45:51,830 --> 00:45:53,510
Speaker 6:  foot if they piss off all of,

807
00:45:53,620 --> 00:45:56,990
Speaker 4:  Well I think it's important again, Google anti trial is going on. Yeah. The

808
00:45:57,150 --> 00:46:00,910
Speaker 4:  punching bag in this trial is big, at least in secret. Yep. Somewhere in

809
00:46:00,910 --> 00:46:04,790
Speaker 4:  secret. The United States government is just punching Bing in the face and

810
00:46:04,790 --> 00:46:08,150
Speaker 4:  we don't know about it, but we know it's happening. We can detect that Bing

811
00:46:08,150 --> 00:46:11,310
Speaker 4:  is being punched in the face but we can't actually wait. See it. Did you

812
00:46:11,310 --> 00:46:11,590
Speaker 4:  hear it

813
00:46:12,540 --> 00:46:12,990
Speaker 6:  Just got

814
00:46:12,990 --> 00:46:16,150
Speaker 4:  Punched. But what is true is that Microsoft launched all this stuff with

815
00:46:16,150 --> 00:46:19,790
Speaker 4:  Bing that made all this noise front page article in The, new York Times

816
00:46:20,090 --> 00:46:22,470
Speaker 4:  and binging has gained zero market share.

817
00:46:22,930 --> 00:46:23,150
Speaker 6:  Yep.

818
00:46:23,890 --> 00:46:25,350
Speaker 4:  At least as far as anyone can tell. It doesn't case

819
00:46:25,420 --> 00:46:29,070
Speaker 5:  It's zero, but it's gone from no one cares to, no one cares.

820
00:46:30,650 --> 00:46:31,470
Speaker 6:  But now horny,

821
00:46:31,880 --> 00:46:32,390
Speaker 4:  Right? Yeah.

822
00:46:33,940 --> 00:46:35,070
Speaker 4:  It's pretty weird in that room

823
00:46:36,690 --> 00:46:40,630
Speaker 4:  no one goes into, it's like that car on the subway, you know, just don't,

824
00:46:40,720 --> 00:46:43,510
Speaker 4:  don't go in that one. Don't go in that one. But like that's the answer, right?

825
00:46:43,540 --> 00:46:46,310
Speaker 4:  It's like this stuff isn't working. So Microsoft's putting it more and more

826
00:46:46,310 --> 00:46:49,470
Speaker 4:  places in the hopes that it will work. But the turn that is really interesting

827
00:46:49,470 --> 00:46:53,110
Speaker 4:  for me is in Windows where you're like, change my display resolution

828
00:46:53,690 --> 00:46:57,510
Speaker 4:  and it will just do it. Yeah. I, that's like a meaningful, the

829
00:46:57,510 --> 00:47:01,470
Speaker 4:  last digital assistant that attempted to do this was Bixby,

830
00:47:02,090 --> 00:47:05,990
Speaker 4:  but on Windows where it is pretty byzantine I think that might actually

831
00:47:05,990 --> 00:47:08,390
Speaker 4:  make a big difference in how people use Windows. I mean,

832
00:47:08,620 --> 00:47:12,550
Speaker 6:  Windows menus are garbage. And remember how for the longest

833
00:47:12,580 --> 00:47:16,510
Speaker 6:  time they all still had like Windows seven ui even though they're like,

834
00:47:16,510 --> 00:47:20,230
Speaker 6:  we have this new thing and it's great except for all of these really important

835
00:47:20,480 --> 00:47:24,190
Speaker 6:  menus you have to use if you're testing laptops every day. Alex, Cranz,

836
00:47:25,060 --> 00:47:29,030
Speaker 6:  that was just for me. But yeah, I, I just get so

837
00:47:29,160 --> 00:47:32,600
Speaker 6:  nervous about how fast they're moving on AI at Microsoft.

838
00:47:32,990 --> 00:47:36,800
Speaker 6:  Like I just spend a lot of time thinking about this seems like a bad

839
00:47:36,800 --> 00:47:39,880
Speaker 6:  idea. It seems like you're going way too fast and this is gonna bite you

840
00:47:39,880 --> 00:47:43,720
Speaker 6:  in the ass because you, they haven't had the ability to test this as

841
00:47:43,720 --> 00:47:46,520
Speaker 6:  extensively as they'd like. And that's why we're seeing, like, that's why

842
00:47:46,540 --> 00:47:49,760
Speaker 6:  Amazon is going kind of slow here. Even though Amazon did this big announcement

843
00:47:49,980 --> 00:47:52,840
Speaker 6:  and showed all this stuff, they're still going slow and Microsoft is like

844
00:47:53,270 --> 00:47:56,600
Speaker 6:  full Steam ahead on releasing this and bringing this stuff to market and

845
00:47:56,600 --> 00:47:59,400
Speaker 6:  putting this in everybody's hands. And it does need to be in hands, right?

846
00:47:59,400 --> 00:48:02,680
Speaker 6:  Like it needs to be tested, but is the best place to test it.

847
00:48:03,940 --> 00:48:07,840
Speaker 6:  The, the install base for all of the companies that

848
00:48:07,840 --> 00:48:11,720
Speaker 6:  currently pay you lots of money to use your software. I don't think

849
00:48:11,720 --> 00:48:12,760
Speaker 6:  that's the best. Well,

850
00:48:12,760 --> 00:48:16,680
Speaker 4:  You have to pay $30 a seat to use in an office. Yeah. So I, I think

851
00:48:16,680 --> 00:48:18,960
Speaker 4:  that pricing is a bit of a test. I also think it's a bit of a barrier.

852
00:48:19,290 --> 00:48:20,400
Speaker 6:  It'll keep a lot of people out, but

853
00:48:20,400 --> 00:48:22,640
Speaker 4:  The only person who should be using AI and Excel at your company is the person

854
00:48:22,640 --> 00:48:26,520
Speaker 4:  who is best to excel right at this moment. Yeah. To just let you know

855
00:48:26,520 --> 00:48:27,880
Speaker 4:  what it can and can't do. Well,

856
00:48:27,880 --> 00:48:30,800
Speaker 5:  And, and that's actually, that's a pretty good example, right? And I, 'cause

857
00:48:30,800 --> 00:48:34,560
Speaker 5:  I think what Microsoft would say, and I think did say at a, at a

858
00:48:34,560 --> 00:48:38,120
Speaker 5:  panel they did after their event today was basically like,

859
00:48:38,810 --> 00:48:42,600
Speaker 5:  don't trust this thing to do something you can't do

860
00:48:42,960 --> 00:48:46,800
Speaker 5:  yourself. Yes. Just trust it to help you. Right. And I think that

861
00:48:46,800 --> 00:48:50,480
Speaker 5:  is the right, like having the Excel expert say, okay,

862
00:48:51,220 --> 00:48:54,960
Speaker 5:  here's this menial thing I do a hundred times a day. Can the AI do it for

863
00:48:54,960 --> 00:48:58,800
Speaker 5:  me? Is actually a pretty useful and like instructive test. But for me to

864
00:48:58,800 --> 00:49:02,680
Speaker 5:  just go in and be like, Hey Copilot, we making money

865
00:49:02,740 --> 00:49:06,320
Speaker 5:  or what? It's like that's a bad idea. We shouldn't do that. You should do

866
00:49:06,320 --> 00:49:06,840
Speaker 5:  that all the time.

867
00:49:07,510 --> 00:49:09,080
Speaker 4:  I'll pay $30 a seat for you to

868
00:49:09,080 --> 00:49:09,280
Speaker 9:  Do that.

869
00:49:10,890 --> 00:49:12,200
Speaker 5:  How's the money Copilot?

870
00:49:13,980 --> 00:49:17,880
Speaker 5:  And, and I think we're in this place now where with so much ai,

871
00:49:17,880 --> 00:49:21,870
Speaker 5:  it's like if you wanna do dumb stuff, it's gonna

872
00:49:21,970 --> 00:49:25,550
Speaker 5:  go poorly for you and people will do dumb stuff

873
00:49:26,090 --> 00:49:28,790
Speaker 5:  and it's gonna go poorly for them. And I think there are really interesting

874
00:49:28,950 --> 00:49:32,910
Speaker 5:  questions to be asked about whether we should be protected from that as people,

875
00:49:33,460 --> 00:49:36,070
Speaker 5:  it's like, it's the, the self-driving stuff, right? Like if you have a thing

876
00:49:36,070 --> 00:49:39,230
Speaker 5:  that's called a self-driving car, people are gonna do dumb, they're gonna

877
00:49:39,230 --> 00:49:42,990
Speaker 5:  fall asleep and have sex in the backseat and that is not what they should

878
00:49:42,990 --> 00:49:45,710
Speaker 5:  be doing, but they're gonna do it. And so what's your responsibility as the

879
00:49:45,710 --> 00:49:48,590
Speaker 5:  one making that? It's a really interesting question, but I think at some

880
00:49:48,590 --> 00:49:52,470
Speaker 5:  point if I'm Microsoft, you just have

881
00:49:52,470 --> 00:49:56,430
Speaker 5:  to like throw it out there and do your best. And

882
00:49:56,430 --> 00:49:58,870
Speaker 5:  I think the way they're pitching it is really interesting because it's like,

883
00:49:59,380 --> 00:50:02,750
Speaker 5:  it's not a tool for doing

884
00:50:03,020 --> 00:50:06,990
Speaker 5:  spectacular business calculations. It's like a way to

885
00:50:06,990 --> 00:50:10,310
Speaker 5:  play a Spotify playlist, right? Yeah. It's like doing the things that are

886
00:50:10,310 --> 00:50:14,030
Speaker 5:  easy and and tractable and you know how to do, but take 12 clicks,

887
00:50:15,250 --> 00:50:18,630
Speaker 5:  you can just do it with a command now. And that's the kind of stuff that

888
00:50:18,630 --> 00:50:22,150
Speaker 5:  this stuff is generally pretty good at. But then like

889
00:50:22,790 --> 00:50:25,310
Speaker 5:  I think Microsoft has been trying to do this with binging all year too, is

890
00:50:25,310 --> 00:50:28,440
Speaker 5:  figure out how to put a ceiling on that that where it's like, okay, we want

891
00:50:28,440 --> 00:50:31,160
Speaker 5:  you to be able to do this stuff without doing all the dumb shit we know people

892
00:50:31,160 --> 00:50:34,320
Speaker 5:  are gonna do as soon as they're allowed to. And I don't think anybody has

893
00:50:34,320 --> 00:50:35,680
Speaker 5:  figured out that answer yet.

894
00:50:36,320 --> 00:50:39,960
Speaker 6:  I don't think there, there is an answer to that. Like people don't like it

895
00:50:39,960 --> 00:50:42,840
Speaker 6:  when you say, oh you have all of this access to technology, you only get

896
00:50:42,840 --> 00:50:45,040
Speaker 6:  this little bit, right? Yeah. No one like that. That's what bar did

897
00:50:45,260 --> 00:50:46,280
Speaker 5:  And it sucks. Yeah.

898
00:50:46,910 --> 00:50:48,440
Speaker 6:  Yeah. You hate it. Yeah. So

899
00:50:48,760 --> 00:50:52,640
Speaker 4:  Someone told me that LLMs are uniquely good at teaching you

900
00:50:52,640 --> 00:50:55,680
Speaker 4:  how to make chemical weapons because there's so much information about building

901
00:50:55,920 --> 00:50:59,120
Speaker 4:  chemical weapons in the quad that they've just learned it all. And like now

902
00:50:59,120 --> 00:51:02,600
Speaker 4:  we're at the point where like, you shouldn't let them do that. No. But like

903
00:51:02,660 --> 00:51:04,280
Speaker 4:  now it's just built into the sidebar of Windows.

904
00:51:05,380 --> 00:51:08,400
Speaker 6:  No, you just do it. Well, not yet. Not yet. It's coming

905
00:51:08,960 --> 00:51:09,720
Speaker 6:  September 26th.

906
00:51:10,180 --> 00:51:14,110
Speaker 4:  All right, so that's, that was this Microsoft event. Copilot everywhere.

907
00:51:14,110 --> 00:51:17,590
Speaker 4:  Basically a little bit of new hardware. Then there's the other Microsoft

908
00:51:17,590 --> 00:51:17,870
Speaker 4:  event,

909
00:51:18,050 --> 00:51:19,070
Speaker 6:  The big event, the

910
00:51:19,070 --> 00:51:21,710
Speaker 4:  One that you weren't supposed to see, which is, and I want to be very clear

911
00:51:21,710 --> 00:51:25,310
Speaker 4:  about this 'cause there is some narrative out there. The F T C leaked

912
00:51:25,590 --> 00:51:29,350
Speaker 4:  Microsoft's documents. That is absolutely not what happened. So F T C

913
00:51:29,350 --> 00:51:32,790
Speaker 4:  versus Microsoft happens lots and lots of documents are getting uploaded.

914
00:51:33,450 --> 00:51:37,390
Speaker 4:  We can see them all in the docket. The court clarifies Microsoft was

915
00:51:37,390 --> 00:51:40,390
Speaker 4:  asked to do some stuff, failed to redact these documents,

916
00:51:41,740 --> 00:51:45,150
Speaker 4:  just publish them for everyone to see. So Microsoft's just like screwed up

917
00:51:45,150 --> 00:51:45,990
Speaker 4:  in a massive way here.

918
00:51:46,470 --> 00:51:47,590
Speaker 6:  I mean, I'm not complaining,

919
00:51:48,090 --> 00:51:51,310
Speaker 4:  No one's complaining, but the leaks are out of control. There's a new Xbox

920
00:51:51,310 --> 00:51:55,150
Speaker 4:  series X, another new Xbox, a new controller, Phil

921
00:51:55,150 --> 00:51:58,230
Speaker 4:  Spencer idly wanting to buy Nintendo where to begin

922
00:51:59,530 --> 00:52:03,310
Speaker 6:  The controller. Yeah. Yes, I, yeah. Yes. Alex the controller is cool.

923
00:52:03,410 --> 00:52:06,750
Speaker 6:  Yes. Right. It's got the haptics, like the PSS five

924
00:52:06,920 --> 00:52:10,830
Speaker 6:  controller. So it, it'll feel like more real when you

925
00:52:10,830 --> 00:52:14,470
Speaker 6:  do stuff. I don't know if, if all of our listeners have a PS five buy one,

926
00:52:14,470 --> 00:52:18,310
Speaker 6:  it's a lot easier now I we spend that $500 but the haptics feel really

927
00:52:18,430 --> 00:52:21,030
Speaker 6:  cool in it. And this is supposed to have that, it's supposed to be kinda

928
00:52:21,030 --> 00:52:24,830
Speaker 6:  like Stadia where it's got like those haptics also do

929
00:52:24,830 --> 00:52:28,790
Speaker 6:  double as like volume. It's like if you're getting shot or at or something,

930
00:52:28,790 --> 00:52:32,670
Speaker 6:  you'll still feel it and hear it. That's just cool. Like,

931
00:52:32,910 --> 00:52:36,190
Speaker 6:  I don't know, it's just a neat controller. It's gonna have replaceable joysticks

932
00:52:36,770 --> 00:52:40,550
Speaker 6:  out of the box right now you have to spend like what, $250 for a Microsoft

933
00:52:40,550 --> 00:52:44,470
Speaker 6:  Elite controller or one of something from SCUFF or something. And you

934
00:52:44,470 --> 00:52:48,430
Speaker 6:  won't have to do that. It'll just be there. And if you wanna replace the

935
00:52:48,430 --> 00:52:52,150
Speaker 6:  joysticks because you like dig in and kind of distort them because you play

936
00:52:52,150 --> 00:52:56,030
Speaker 6:  too hard, I don't know anybody who does that. But if you do, you'll be

937
00:52:56,030 --> 00:52:57,030
Speaker 6:  able to replace it. That's neat.

938
00:52:57,030 --> 00:53:00,590
Speaker 5:  Yeah, it's a cool controller. And also I think the, the vision

939
00:53:00,690 --> 00:53:04,230
Speaker 5:  behind it is super rad, which is basically like Microsoft is in this place

940
00:53:04,230 --> 00:53:08,070
Speaker 5:  now where they want you to be able to play all of your games,

941
00:53:08,130 --> 00:53:11,550
Speaker 5:  all of the places, right? Like it's cloud gaming is, is a huge part of this.

942
00:53:11,550 --> 00:53:15,310
Speaker 5:  There was a leak in here that Microsoft is planning to stream PC games

943
00:53:15,310 --> 00:53:18,830
Speaker 5:  through cloud gaming. And there's this line

944
00:53:19,130 --> 00:53:22,550
Speaker 5:  in the roadmap document that came out that says,

945
00:53:22,800 --> 00:53:26,720
Speaker 5:  controller becomes the hero. The new Xbox controller is the only thing you

946
00:53:26,720 --> 00:53:30,240
Speaker 5:  need to play on every device. And the idea is that the

947
00:53:30,240 --> 00:53:34,080
Speaker 5:  controller connects to wifi itself or to your console

948
00:53:34,180 --> 00:53:38,040
Speaker 5:  or over Bluetooth. And so it becomes the console in a

949
00:53:38,040 --> 00:53:41,880
Speaker 5:  super real way. And all you need is a screen and a controller and suddenly

950
00:53:41,880 --> 00:53:45,840
Speaker 5:  you're up and running. It's a very like Stadia vision of the world. And I

951
00:53:45,840 --> 00:53:48,440
Speaker 5:  think that was the single smartest thing about Stadia that ever existed.

952
00:53:48,540 --> 00:53:52,040
Speaker 5:  And I think this idea of like the controller being the thing and you can

953
00:53:52,040 --> 00:53:55,480
Speaker 5:  play anywhere as long as you have the controller is so cool. And I really

954
00:53:55,480 --> 00:53:56,240
Speaker 5:  hope it becomes real.

955
00:53:56,800 --> 00:54:00,560
Speaker 6:  I really, I like that's the thing that I really hope this AI stuff that

956
00:54:00,840 --> 00:54:04,640
Speaker 6:  Microsoft has focused on doesn't distract that much from the cloud gaming

957
00:54:04,640 --> 00:54:06,520
Speaker 6:  things that they're doing because it's so cool.

958
00:54:06,780 --> 00:54:09,880
Speaker 4:  So in these leaks over and over again, Microsoft is like

959
00:54:10,820 --> 00:54:14,480
Speaker 4:  the Xbox is our play for the consumer. Yeah. Yeah. They're not

960
00:54:14,620 --> 00:54:17,960
Speaker 4:  shy about it. Yeah. Phil, Spencer is like, this is the thing that we do for

961
00:54:17,960 --> 00:54:21,720
Speaker 4:  the consumer and like Nadella is like, this is the thing we do for a consumer

962
00:54:21,720 --> 00:54:25,040
Speaker 4:  and also it all runs in Azure. So just like keep that in mind. Yeah,

963
00:54:25,830 --> 00:54:27,480
Speaker 4:  just that's where the money is filled.

964
00:54:29,250 --> 00:54:30,120
Speaker 6:  Don't get too ahead of

965
00:54:30,240 --> 00:54:32,480
Speaker 4:  Yourself. So that's a controller. Tell me about these consoles

966
00:54:32,990 --> 00:54:36,800
Speaker 6:  Disc free. Like that's a big deal. Like I guess for the Xbox series

967
00:54:36,880 --> 00:54:40,760
Speaker 6:  X because the original one had the DISC player separates it

968
00:54:40,760 --> 00:54:44,280
Speaker 6:  from a lot of the other stuff, including PlayStation. Most people don't actually

969
00:54:44,280 --> 00:54:47,200
Speaker 6:  need or want the DISC player. Yeah. Like it's great if you wanna watch movies.

970
00:54:47,400 --> 00:54:51,320
Speaker 4:  I have a digital PSS five and just never comes up. Yeah.

971
00:54:51,950 --> 00:54:55,920
Speaker 6:  Most people just go and more storage, which is crucial. I think

972
00:54:55,920 --> 00:54:59,560
Speaker 6:  it's going from one terabyte to two terabytes theoretically.

973
00:54:59,560 --> 00:55:03,000
Speaker 6:  Obviously this is leaked, it could totally change before it comes to market

974
00:55:03,420 --> 00:55:07,320
Speaker 6:  if it comes to market. But yeah. And it sounds like there's another

975
00:55:07,640 --> 00:55:11,040
Speaker 6:  Microsoft Elite controller in the works, which I'm really curious to see

976
00:55:11,040 --> 00:55:13,880
Speaker 6:  how it's gonna build on on this. This leaked

977
00:55:14,970 --> 00:55:18,120
Speaker 6:  cloud gaming controller like just seems cool as hell.

978
00:55:18,500 --> 00:55:21,760
Speaker 5:  It does. There's also apparently an Xbox that has been planned for

979
00:55:21,760 --> 00:55:25,280
Speaker 5:  2028. And we should say by the way, that these are all older

980
00:55:25,720 --> 00:55:29,600
Speaker 5:  documents that may or may not exist in the current

981
00:55:29,600 --> 00:55:32,680
Speaker 5:  reality. Yeah. Like a lot of stuff people were planning a couple of years

982
00:55:32,680 --> 00:55:36,560
Speaker 5:  ago when like Bitcoin was a billion dollars

983
00:55:36,700 --> 00:55:40,640
Speaker 5:  and money was free and everything was fantastic. Like the vibes are

984
00:55:40,640 --> 00:55:42,200
Speaker 5:  very different now and people have made very income

985
00:55:42,200 --> 00:55:44,160
Speaker 6:  Plans and we've seen some of the stuff already canceled. Like the,

986
00:55:44,160 --> 00:55:47,840
Speaker 4:  By the way, in the grand scheme of leaks, the best leak to get is the email

987
00:55:47,890 --> 00:55:51,880
Speaker 4:  about the leaks that leaks. Yes. So Phil Spencer emailed Xbox

988
00:55:51,880 --> 00:55:55,000
Speaker 4:  team Tom Got it. Because you know Yeah. Yeah.

989
00:55:55,900 --> 00:55:59,360
Speaker 4:  And Phil says the Xbox team. I know this is disappointing even if many of

990
00:55:59,360 --> 00:56:02,570
Speaker 4:  the documents are over a year old and our plans have evolved.

991
00:56:02,580 --> 00:56:05,810
Speaker 5:  Right. But lemme just say, so the the one other Xbox that was, yeah.

992
00:56:06,550 --> 00:56:07,370
Speaker 4:  Now back to the real estate. Now

993
00:56:07,510 --> 00:56:10,690
Speaker 5:  Who cares? Whatever. Let's assume all of this is real. 'cause I want most

994
00:56:10,690 --> 00:56:14,250
Speaker 5:  of it to be, 'cause it seems very cool. There's this plan for

995
00:56:14,610 --> 00:56:18,410
Speaker 5:  a whole new, it seems generation of consoles in 2028

996
00:56:18,720 --> 00:56:22,570
Speaker 5:  that is basically, I think they call it a hybrid gaming

997
00:56:23,120 --> 00:56:23,320
Speaker 5:  platform.

998
00:56:23,670 --> 00:56:27,120
Speaker 6:  Yeah, yeah. This was what we were talking about earlier in the show. They

999
00:56:27,120 --> 00:56:30,880
Speaker 6:  wanna basically have it. So the really big processing, the

1000
00:56:30,880 --> 00:56:34,840
Speaker 6:  really hard stuff happens in the cloud and Then, we do some of the other

1001
00:56:34,840 --> 00:56:38,440
Speaker 6:  stuff smaller locally. And we've heard this talked about before. Sean's written

1002
00:56:38,440 --> 00:56:42,080
Speaker 6:  about it. I definitely have said on this show, it's stupid and will never

1003
00:56:42,080 --> 00:56:45,840
Speaker 6:  happen. I guess I'm wrong. That's totally fine. And

1004
00:56:46,020 --> 00:56:49,280
Speaker 6:  it, it's, it's a really compelling idea if they can make it work. But it's

1005
00:56:49,280 --> 00:56:52,320
Speaker 6:  gonna require like a bunch, like they talk about this in their roadmap and,

1006
00:56:52,320 --> 00:56:55,920
Speaker 6:  and in the story that Sean wrote about this, that it is really

1007
00:56:55,950 --> 00:56:58,920
Speaker 6:  complex issue. There's a lot of like silicon stuff they, they have to do

1008
00:56:59,320 --> 00:57:02,520
Speaker 6:  a lot of processor stuff they have to figure out. That will make it really,

1009
00:57:02,520 --> 00:57:06,040
Speaker 6:  really tricky. But if it works then you can have like

1010
00:57:07,060 --> 00:57:10,800
Speaker 6:  the really expensive quality of a pc. Like you know, those

1011
00:57:10,800 --> 00:57:14,680
Speaker 6:  $3,000 PC rigs that people do, four K, gorgeous,

1012
00:57:14,690 --> 00:57:18,400
Speaker 6:  everything turned to ultra. You could have that on an Xbox,

1013
00:57:18,770 --> 00:57:22,680
Speaker 6:  which is currently totally incapable of that. And you could have it at

1014
00:57:22,680 --> 00:57:26,600
Speaker 6:  that Xbox price. And that's, that would be very compelling for a lot of

1015
00:57:26,600 --> 00:57:26,760
Speaker 6:  people.

1016
00:57:27,140 --> 00:57:30,080
Speaker 5:  Or even further down. I mean there's a, there's a line in one of those documents

1017
00:57:30,080 --> 00:57:33,720
Speaker 5:  that says they want to sell something for under $99

1018
00:57:33,900 --> 00:57:37,880
Speaker 5:  as like a handheld device. And if anyone ever gets this right,

1019
00:57:38,460 --> 00:57:41,720
Speaker 5:  it basically means anything with a screen

1020
00:57:42,230 --> 00:57:45,840
Speaker 5:  becomes a powerful gaming system. And if you have more local power,

1021
00:57:46,090 --> 00:57:49,320
Speaker 5:  it'll do more locally. And so you'll get a slightly better experience if

1022
00:57:49,320 --> 00:57:52,040
Speaker 5:  you have less power, it'll do more in the cloud. So you'll have a slightly

1023
00:57:52,040 --> 00:57:55,960
Speaker 5:  worse experience but still get functionally the same thing. And if we get

1024
00:57:55,960 --> 00:57:59,440
Speaker 5:  to the like, holy God, is that a hard technical thing to do for so, so, so

1025
00:57:59,440 --> 00:58:03,120
Speaker 5:  many reasons. But if we get there that kicks ass like that is the

1026
00:58:03,220 --> 00:58:07,120
Speaker 5:  future of how we use computers that I would very much like to live in. I

1027
00:58:07,120 --> 00:58:07,440
Speaker 5:  mean it's,

1028
00:58:07,440 --> 00:58:11,200
Speaker 6:  It's essentially the like Kindle Ling of of

1029
00:58:11,470 --> 00:58:12,720
Speaker 6:  Xbox where you

1030
00:58:12,720 --> 00:58:14,680
Speaker 5:  Could play games on your Kindle where

1031
00:58:14,840 --> 00:58:16,360
Speaker 4:  It's like, we got it. Anything with a screen bro,

1032
00:58:16,770 --> 00:58:19,840
Speaker 6:  We're just trying to get you some hardware so that you can actually go do

1033
00:58:19,840 --> 00:58:23,800
Speaker 6:  what we want you to do. Which is buy a lot of games, spend money in our marketplaces.

1034
00:58:23,800 --> 00:58:27,600
Speaker 6:  That's like, that's always been the big get for Sony and for Microsoft

1035
00:58:28,100 --> 00:58:31,800
Speaker 6:  and moving into that cloud gaming would really like making

1036
00:58:31,810 --> 00:58:35,640
Speaker 6:  cloud gaming actually succeed in this fashion would

1037
00:58:35,640 --> 00:58:39,480
Speaker 6:  do that. 'cause okay, I spent a hundred bucks and I get the exact same,

1038
00:58:39,550 --> 00:58:42,600
Speaker 6:  like a very similar experience to my friend who spent 500 bucks or my friend

1039
00:58:42,600 --> 00:58:46,400
Speaker 6:  who spent yeah 3000 and built it all himself. Like just makes things a lot

1040
00:58:46,400 --> 00:58:47,720
Speaker 6:  more equitable. So

1041
00:58:47,720 --> 00:58:51,570
Speaker 4:  What's funny about all of this, does all this happening, we're we

1042
00:58:51,570 --> 00:58:54,970
Speaker 4:  we're Microsoft's running ahead with these plans contextually

1043
00:58:55,660 --> 00:58:59,610
Speaker 4:  right now Apple's like the phone is the best game console ever

1044
00:58:59,610 --> 00:59:02,850
Speaker 4:  made. Sure iPhone Pro is best, right? And they're all local all the time.

1045
00:59:03,070 --> 00:59:06,690
Speaker 4:  And Microsoft can never put a cloud gaming service on the iPhone for like

1046
00:59:06,690 --> 00:59:07,810
Speaker 4:  a billion different reasons. Through

1047
00:59:07,810 --> 00:59:09,010
Speaker 6:  The web browser, through through

1048
00:59:09,010 --> 00:59:10,930
Speaker 4:  The web press fine.

1049
00:59:11,190 --> 00:59:11,890
Speaker 6:  Go through Safari.

1050
00:59:12,270 --> 00:59:16,210
Speaker 4:  That's like one pressure on this. Yeah. Then the other pressure is that Nintendo

1051
00:59:16,210 --> 00:59:19,330
Speaker 4:  exists. Mm. And Nintendo's relationship with the internet

1052
00:59:20,510 --> 00:59:21,690
Speaker 4:  is shaky.

1053
00:59:21,930 --> 00:59:23,330
Speaker 5:  Nintendo knows the exists.

1054
00:59:23,330 --> 00:59:27,250
Speaker 6:  It acknowledges. Yeah. Yeah. I was about to say it knows it exists. Does

1055
00:59:27,250 --> 00:59:30,970
Speaker 6:  it want to use it? No. It took so long to get to cloud gaming was, I think

1056
00:59:30,970 --> 00:59:33,450
Speaker 6:  it was like last year or the year before that. Yeah. Before it was finally

1057
00:59:33,450 --> 00:59:37,090
Speaker 6:  like you can save things on the cloud and use it on your knees.

1058
00:59:37,270 --> 00:59:37,530
Speaker 6:  I'm just

1059
00:59:37,530 --> 00:59:39,970
Speaker 4:  Saying look at the structure of the game industry right now. The structure

1060
00:59:39,970 --> 00:59:43,930
Speaker 4:  of the games in the iPhone. Yeah. All Candy Crush Freeda

1061
00:59:43,930 --> 00:59:47,570
Speaker 4:  plays Dlcss, the whole thing. Nintendo biggest game

1062
00:59:47,990 --> 00:59:51,890
Speaker 4:  of the century in tears of the Kingdom announces

1063
00:59:51,890 --> 00:59:55,660
Speaker 4:  it will not have a D L C because it is complete and just an

1064
00:59:55,660 --> 00:59:57,260
Speaker 4:  incredible like beautiful,

1065
00:59:57,360 --> 01:00:01,100
Speaker 5:  The flex that that is is so, so powerful. It's like, what

1066
01:00:01,100 --> 01:00:01,540
Speaker 5:  more do you

1067
01:00:01,540 --> 01:00:03,340
Speaker 4:  Want it So? we don't need to make more money off this game.

1068
01:00:03,480 --> 01:00:07,340
Speaker 5:  The last line was to keep exploring high rules. It's like hell yeah. No,

1069
01:00:08,890 --> 01:00:12,100
Speaker 4:  It's like you haven't found habit but it's like just incredible weird competitive

1070
01:00:12,260 --> 01:00:15,420
Speaker 4:  pressures, right? Yeah. That are nothing to do with this like hybrid future

1071
01:00:15,440 --> 01:00:19,340
Speaker 4:  of computing idea one apple's like it's all local and you No, no

1072
01:00:19,340 --> 01:00:21,460
Speaker 4:  thank you sir. And Nintendo's like, what

1073
01:00:22,320 --> 01:00:23,460
Speaker 6:  Put is internet, please

1074
01:00:23,740 --> 01:00:27,700
Speaker 4:  Continue exploring my roll on our console that has like the

1075
01:00:27,700 --> 01:00:31,420
Speaker 4:  processing power of like a mid-range H T C phone from 2011. Like

1076
01:00:32,020 --> 01:00:35,820
Speaker 4:  whatever, you know. So then in just in, I'm putting that in

1077
01:00:35,940 --> 01:00:39,820
Speaker 4:  context to tell you about this email from Phil Spencer where

1078
01:00:39,850 --> 01:00:43,740
Speaker 4:  he's like buying Nintendo would be a career moment. He says, I totally

1079
01:00:44,030 --> 01:00:48,020
Speaker 4:  agree that Nintendo is the capital V prime asset for us in

1080
01:00:48,020 --> 01:00:50,780
Speaker 4:  gaming. And today gaming is our most likely path to consumer Rev relevance.

1081
01:00:51,010 --> 01:00:54,940
Speaker 4:  I've had numerous conversations with what we think is lt.

1082
01:00:55,290 --> 01:00:58,820
Speaker 4:  I've had numerous conversations with the leadership team of Nintendo about

1083
01:00:58,820 --> 01:01:02,380
Speaker 4:  tighter collaboration and feel like if any US company would have a chance

1084
01:01:02,380 --> 01:01:05,900
Speaker 4:  with Nintendo, we are probably in the best position. The

1085
01:01:06,410 --> 01:01:10,140
Speaker 4:  unfortunate situation or fortunate for Nintendo, he says in parentheses

1086
01:01:10,360 --> 01:01:14,180
Speaker 4:  is that they're sitting on a big pile of cash and they have a board of directors

1087
01:01:14,210 --> 01:01:17,940
Speaker 4:  that Intel recently has not pushed for further increases in market growth

1088
01:01:18,320 --> 01:01:19,420
Speaker 4:  or stock appreciation.

1089
01:01:19,560 --> 01:01:21,740
Speaker 5:  The problem with Nintendo is that Nintendo's good.

1090
01:01:22,130 --> 01:01:25,420
Speaker 4:  Yeah. They're like, Nintendo is a bunch of money and the people who run it

1091
01:01:25,420 --> 01:01:26,420
Speaker 4:  are like pretty happy with it.

1092
01:01:28,250 --> 01:01:31,060
Speaker 4:  It's like, okay, good luck.

1093
01:01:31,330 --> 01:01:35,100
Speaker 5:  It's the most like ruthless capitalist VC

1094
01:01:35,120 --> 01:01:39,020
Speaker 5:  funded thing I've ever heard in my life. They're like, how you, you

1095
01:01:39,030 --> 01:01:41,020
Speaker 5:  don't want my money? What do I do?

1096
01:01:41,770 --> 01:01:45,140
Speaker 4:  Yeah. It's like your board of re So then he is like, this guy's been buying

1097
01:01:45,140 --> 01:01:48,820
Speaker 4:  up shares and hopefully he'll do it. And he is like, I, we've shown the full

1098
01:01:48,820 --> 01:01:52,540
Speaker 4:  write up on Nintendo and Valve, interestingly to the Microsoft board of

1099
01:01:52,740 --> 01:01:56,420
Speaker 4:  directors and they're fully supportive. S m i, but that it's just like all

1100
01:01:56,420 --> 01:01:59,860
Speaker 4:  this stuff, all this technology stuff just sort of falls down in the face

1101
01:01:59,960 --> 01:02:03,060
Speaker 4:  of, well, the biggest platform on earth and, and mobile

1102
01:02:03,730 --> 01:02:07,240
Speaker 4:  they can't do the thing with and then the best game

1103
01:02:07,640 --> 01:02:11,610
Speaker 4:  platform. It's just like whatever. I mean like focus on

1104
01:02:11,610 --> 01:02:11,890
Speaker 4:  the games.

1105
01:02:12,310 --> 01:02:15,730
Speaker 6:  That's why they've been pretty actively on Epic side

1106
01:02:16,190 --> 01:02:18,970
Speaker 6:  for every single one of these Google and, and Apple V

1107
01:02:19,460 --> 01:02:22,280
Speaker 4:  By wait, when I say the best game player don't come for me. I'm quoting Phil

1108
01:02:22,280 --> 01:02:26,160
Speaker 4:  Spencer saying Nintendo is the prime asset for us in gaming

1109
01:02:26,210 --> 01:02:29,880
Speaker 4:  today. That's what the head of Xbox thinks about Nintendo. Not me.

1110
01:02:30,400 --> 01:02:34,280
Speaker 4:  I play Madden and I quit playing Zelda right when I got to can.

1111
01:02:35,720 --> 01:02:39,360
Speaker 4:  'cause I didn't want to grind for shit so I could beat him. You're it's up.

1112
01:02:39,360 --> 01:02:41,600
Speaker 4:  Which apparently is like extraordinarily common in this game.

1113
01:02:42,830 --> 01:02:46,430
Speaker 6:  I think that's most people. Yeah. I only did it in like, it was like late

1114
01:02:46,430 --> 01:02:49,870
Speaker 6:  at night one day and I went, okay, I'm just gonna do it. Why not? Let's just

1115
01:02:49,870 --> 01:02:50,030
Speaker 6:  go.

1116
01:02:50,310 --> 01:02:52,870
Speaker 4:  I was like, look, I have a job, all right. I don't, I'm not gonna go look

1117
01:02:52,870 --> 01:02:56,750
Speaker 4:  for fruit to kill this guy. Like whatever. You just know that I could

1118
01:02:56,890 --> 01:03:00,390
Speaker 4:  Gannon and I shut down my switch and I walked away.

1119
01:03:01,160 --> 01:03:02,190
Speaker 6:  Never touched it again.

1120
01:03:03,570 --> 01:03:06,350
Speaker 4:  But I just think that's a weird position for the ex especially 'cause they're

1121
01:03:06,350 --> 01:03:07,070
Speaker 4:  a third place console.

1122
01:03:07,430 --> 01:03:10,910
Speaker 6:  I don't necessarily think it's a weird position because I think they, they

1123
01:03:10,930 --> 01:03:14,870
Speaker 6:  are really like, they have a strategy to deal with Apple and their

1124
01:03:15,110 --> 01:03:18,990
Speaker 6:  strategy is to say Epic fix it. And and they've they've

1125
01:03:18,990 --> 01:03:21,510
Speaker 6:  put a lot of effort into that, right? Like, like they've, they've been on

1126
01:03:21,530 --> 01:03:25,510
Speaker 6:  Epic's side for the majority of both of these trials saying, no, no,

1127
01:03:25,510 --> 01:03:28,910
Speaker 6:  they're right because they need cloud gaming to appear on these platforms.

1128
01:03:28,910 --> 01:03:32,150
Speaker 6:  And they have their work around now with, with streaming and stuff like that.

1129
01:03:32,290 --> 01:03:35,670
Speaker 6:  And Apple's doing its whole gaming thing. But Apple's gaming thing, as much

1130
01:03:35,670 --> 01:03:37,310
Speaker 6:  as it says it's where gaming happens,

1131
01:03:39,020 --> 01:03:40,310
Speaker 6:  game developers have different

1132
01:03:40,310 --> 01:03:42,790
Speaker 4:  Feelings. Oh no, we're we're starting to get the emails from the iPhone gamers.

1133
01:03:42,900 --> 01:03:45,550
Speaker 6:  Yeah. They're they're there, they're starting to come in. They're there and

1134
01:03:45,550 --> 01:03:49,390
Speaker 6:  you guys exist and I love you, but like, you're not like,

1135
01:03:50,250 --> 01:03:52,950
Speaker 4:  Wow. Yeah, yeah. Watch it. You're

1136
01:03:53,050 --> 01:03:54,190
Speaker 6:  You're, you're different.

1137
01:03:56,250 --> 01:03:58,790
Speaker 4:  We gotta take a break. Yeah, we gotta take a break. Come back and talk about

1138
01:03:58,790 --> 01:04:00,590
Speaker 4:  YouTube and do a little light. Send

1139
01:04:00,590 --> 01:04:02,830
Speaker 6:  All of all of your feelings about that to Neli. No

1140
01:04:02,830 --> 01:04:03,150
Speaker 4:  Thank you.

1141
01:04:03,340 --> 01:04:04,630
Speaker 6:  Neli Patel at the

1142
01:04:04,950 --> 01:04:07,150
Speaker 4:  T com. Look, here's what I know. You can talk about Android gamers like,

1143
01:04:07,470 --> 01:04:10,990
Speaker 4:  'cause they don't exist. You mention that it's silly that Apple thinks the

1144
01:04:10,990 --> 01:04:14,190
Speaker 4:  word pro. I means mobile gaming and the emails come

1145
01:04:14,370 --> 01:04:17,470
Speaker 6:  And I know you guys, you can use the controller and you can play it. And

1146
01:04:17,470 --> 01:04:20,550
Speaker 6:  I, I think that's great. I wanna use my phone for phone stuff.

1147
01:04:21,430 --> 01:04:25,270
Speaker 6:  I don't wanna use it for game stuff. That's why I've got a switch and

1148
01:04:25,520 --> 01:04:28,750
Speaker 6:  40,000 other consoles get with the program. I just would

1149
01:04:28,750 --> 01:04:32,430
Speaker 5:  Like it on the record that everything Alex just said is wrong and I do not

1150
01:04:32,430 --> 01:04:35,190
Speaker 5:  agree with it. Yeah. And I would not like to be associated with the emails

1151
01:04:35,190 --> 01:04:35,950
Speaker 5:  that you're going to send.

1152
01:04:36,060 --> 01:04:37,790
Speaker 6:  Come at me. You're all incorrect.

1153
01:04:38,270 --> 01:04:39,990
Speaker 4:  I have a family. We're taking a break.

1154
01:04:43,930 --> 01:04:44,190
Speaker 4:  All right.

1155
01:07:02,920 --> 01:07:05,620
Speaker 4:  All right, we're back. Should we do this YouTube thing very quickly and then

1156
01:07:05,620 --> 01:07:08,060
Speaker 4:  do a lightning round? Yeah, we can do it fast. Yeah. So YouTube ad event

1157
01:07:08,060 --> 01:07:11,940
Speaker 4:  today made on YouTube a bunch of influencers. I told Charlie

1158
01:07:12,010 --> 01:07:15,500
Speaker 4:  Poth was there, Mia who went told me that photos and videos were not not

1159
01:07:15,500 --> 01:07:19,060
Speaker 4:  allowed and then Charlie PO came out and all decorum went to the

1160
01:07:19,150 --> 01:07:22,620
Speaker 4:  woods and people were just like, I'm doing it. Nah. And he was like, what

1161
01:07:22,620 --> 01:07:25,500
Speaker 4:  about a song that went like this? Two, two dude. Like he did the thing Charlie

1162
01:07:25,520 --> 01:07:26,100
Speaker 4:  Po. It's great

1163
01:07:28,020 --> 01:07:29,420
Speaker 4:  Nature's original creator.

1164
01:07:31,200 --> 01:07:32,540
Speaker 4:  What's the call? Right? I've

1165
01:07:32,540 --> 01:07:35,900
Speaker 5:  Been trying to profile Charlie Poth for like four years. Charlie, if you're

1166
01:07:35,900 --> 01:07:37,500
Speaker 5:  listening, get at me. Let's do

1167
01:07:37,500 --> 01:07:41,340
Speaker 4:  This. Yeah, we we're in for it. Our people will obey the no

1168
01:07:41,340 --> 01:07:44,900
Speaker 4:  photos and videos. Scroll or will they? Ooh. See

1169
01:07:45,070 --> 01:07:48,940
Speaker 4:  every pitch needs a little danger in it. All right, so they announced a bunch

1170
01:07:48,940 --> 01:07:52,580
Speaker 4:  of AI stuff. Big theme of all these events. Yep. AI stuff. So this is

1171
01:07:52,580 --> 01:07:55,740
Speaker 4:  Google's turn, right with YouTube. So dream screen,

1172
01:07:56,350 --> 01:08:00,300
Speaker 4:  which lets you create a background for shorts, generative ai, they showed

1173
01:08:00,340 --> 01:08:04,100
Speaker 4:  a bunch of silly stuff. Mia asked a bunch of questions about what the guardrails

1174
01:08:04,100 --> 01:08:07,460
Speaker 4:  on that would be. For example, what if you ask it to generate a background

1175
01:08:07,460 --> 01:08:09,500
Speaker 4:  for YouTube Short that violates YouTube's policies?

1176
01:08:10,460 --> 01:08:11,420
Speaker 8:  I just thought of four.

1177
01:08:12,330 --> 01:08:16,140
Speaker 4:  It's not hard. For example, what if you would like a say a

1178
01:08:16,140 --> 01:08:18,740
Speaker 4:  Dukes of Hazard themed background for YouTube before

1179
01:08:18,860 --> 01:08:20,140
Speaker 6:  I went in a different direction? But yeah.

1180
01:08:20,290 --> 01:08:24,020
Speaker 4:  Yeah. It's just like that's a even that's just a challenging question

1181
01:08:25,160 --> 01:08:27,500
Speaker 4:  for a million horrible reasons. So

1182
01:08:27,500 --> 01:08:27,700
Speaker 5:  Many.

1183
01:08:28,800 --> 01:08:32,740
Speaker 4:  But so it goes, so you two has to figure that out. They said it won't do

1184
01:08:32,740 --> 01:08:35,820
Speaker 4:  any of that stuff, but we'll see. Yeah. So that's really interesting. David,

1185
01:08:35,840 --> 01:08:37,180
Speaker 4:  you were quite taken with Dream screen.

1186
01:08:37,460 --> 01:08:40,500
Speaker 5:  I think it's really interesting. I think this question of

1187
01:08:41,480 --> 01:08:45,220
Speaker 5:  how do you give creators tools to use generative

1188
01:08:45,320 --> 01:08:49,220
Speaker 5:  AI without giving them tools to make so

1189
01:08:49,290 --> 01:08:52,980
Speaker 5:  much awful generated crap that it ruins your

1190
01:08:53,220 --> 01:08:56,860
Speaker 5:  platform is like the question of the internet right now. Yeah.

1191
01:08:57,100 --> 01:09:00,940
Speaker 5:  And it's one we've talked about a lot and I think YouTube is way behind on

1192
01:09:00,940 --> 01:09:04,500
Speaker 5:  giving its creators native tools to make things. And

1193
01:09:05,090 --> 01:09:08,020
Speaker 5:  this is a way to get into that I just think is really interesting. And like

1194
01:09:08,700 --> 01:09:12,420
Speaker 5:  starting with backgrounds is clever, but there's also a thing where

1195
01:09:12,880 --> 01:09:16,420
Speaker 5:  the AI tools in the YouTube studio will start to generate

1196
01:09:16,630 --> 01:09:20,500
Speaker 5:  topic ideas for creators that it says are personalized to the things that

1197
01:09:20,500 --> 01:09:23,940
Speaker 5:  those creators are doing that already work. So like

1198
01:09:24,460 --> 01:09:27,020
Speaker 5:  I have a thousand things I hate about that, but I think it's fascinating.

1199
01:09:27,020 --> 01:09:30,020
Speaker 5:  And we're in this place now. We're like, everybody is trying to like relentlessly

1200
01:09:30,020 --> 01:09:33,980
Speaker 5:  game the algorithm to be successful on YouTube and now the algorithm is

1201
01:09:33,980 --> 01:09:35,500
Speaker 5:  just gonna tell you what to do.

1202
01:09:36,080 --> 01:09:36,780
Speaker 4:  Yes. That's nuts.

1203
01:09:36,780 --> 01:09:37,300
Speaker 5:  This is the thing.

1204
01:09:37,730 --> 01:09:41,650
Speaker 4:  This is the most incredible announcement of the entire thing. And it

1205
01:09:41,650 --> 01:09:44,890
Speaker 4:  was buried, right? They did dream screen, they did The new editor on mobile,

1206
01:09:45,420 --> 01:09:48,370
Speaker 4:  which is basically cap cut, it's called YouTube Create.

1207
01:09:48,510 --> 01:09:51,170
Speaker 5:  The only thing to say about that is it's bonkers that that didn't exist a

1208
01:09:51,170 --> 01:09:51,690
Speaker 5:  decade ago.

1209
01:09:51,920 --> 01:09:55,490
Speaker 4:  They did. They had a thing, YouTube capture or whatever it was called, it

1210
01:09:55,490 --> 01:09:58,810
Speaker 4:  was just really bad. Yeah. And it doesn't count, right? Yeah, it isn't nuts

1211
01:09:58,830 --> 01:10:02,450
Speaker 4:  by the way. The YouTube is the platform. It is. And basically Final

1212
01:10:02,670 --> 01:10:06,530
Speaker 4:  Cut Pro and iMovie and Adobe Premiere Yeah. Are the native CRE

1213
01:10:06,930 --> 01:10:08,930
Speaker 4:  creation tools for you. Like that's crazy. Yeah. This

1214
01:10:08,990 --> 01:10:12,610
Speaker 6:  Pre, it predates phones being like the primary computing device for people.

1215
01:10:12,720 --> 01:10:15,810
Speaker 5:  Yeah. But we've been doing this a while now. But sorry, Neli, I derailed

1216
01:10:15,810 --> 01:10:16,970
Speaker 5:  you. What were you about to say? So

1217
01:10:16,970 --> 01:10:20,330
Speaker 4:  This thing, this automated AI insights thing,

1218
01:10:21,470 --> 01:10:25,390
Speaker 4:  I am obsessed with it. It's we, it they buried it, right? It's not like the

1219
01:10:25,390 --> 01:10:29,190
Speaker 4:  big flashy consumer feature, but basically, if I'm getting it right,

1220
01:10:29,830 --> 01:10:33,040
Speaker 4:  YouTube is gonna look at a creator's analytics. They're gonna say, here's

1221
01:10:33,040 --> 01:10:35,800
Speaker 4:  what's working well for you. Then they're gonna look at everyone else's analytics

1222
01:10:36,140 --> 01:10:40,000
Speaker 4:  and say, Hey, inside of your library is stuff, you should make

1223
01:10:40,000 --> 01:10:43,560
Speaker 4:  more stuff like this. 'cause it performs better for all the other people,

1224
01:10:44,770 --> 01:10:48,560
Speaker 4:  which is Right. There's a universe in which creators could hire analytics

1225
01:10:48,560 --> 01:10:52,520
Speaker 4:  people. You, you can get there, right? And like big

1226
01:10:52,520 --> 01:10:55,760
Speaker 4:  media companies have analytics people that do this stuff, but then there's

1227
01:10:55,760 --> 01:10:59,680
Speaker 4:  just the robot telling people make this stuff

1228
01:10:59,680 --> 01:11:00,760
Speaker 4:  to get views. Well,

1229
01:11:00,760 --> 01:11:04,320
Speaker 5:  And I mean we, we've been through this in so many sort of specific instances,

1230
01:11:04,320 --> 01:11:07,760
Speaker 5:  right? Like the, the Johnny Depp Amber Heard trial was one where all kinds

1231
01:11:07,760 --> 01:11:09,920
Speaker 5:  of people just started doing that because it was obvious. That's how you

1232
01:11:09,920 --> 01:11:13,600
Speaker 5:  get views. This robot is just gonna tell everybody to make Mr. Beast videos.

1233
01:11:13,910 --> 01:11:15,000
Speaker 5:  Like that's just what it's

1234
01:11:15,000 --> 01:11:17,080
Speaker 4:  Gonna be. We don't know what we think. We don't know.

1235
01:11:17,270 --> 01:11:19,480
Speaker 6:  Will it be mouth open or closed on the thumbnail?

1236
01:11:19,880 --> 01:11:23,000
Speaker 5:  Unbelievable question. If Mr. Beast isn't getting a cut of this for being

1237
01:11:23,000 --> 01:11:26,280
Speaker 5:  the one like training at the best with the best stuff. It's a real shame.

1238
01:11:26,420 --> 01:11:30,320
Speaker 5:  But no, I think you're right. And I think this question of whether YouTube

1239
01:11:30,380 --> 01:11:34,200
Speaker 5:  can build a system that is like creative and personalized

1240
01:11:34,220 --> 01:11:38,120
Speaker 5:  and helpful, or if it's just going to tell people

1241
01:11:38,180 --> 01:11:41,880
Speaker 5:  to do more of what's already working everywhere on YouTube until

1242
01:11:41,880 --> 01:11:45,360
Speaker 5:  everybody is doing the same thing with the same generative AI tools and the

1243
01:11:45,360 --> 01:11:48,680
Speaker 5:  same music library that looks the same. Like unclear,

1244
01:11:49,030 --> 01:11:52,920
Speaker 6:  Kind of feels like it's gonna be that given our

1245
01:11:53,030 --> 01:11:56,960
Speaker 6:  extensive history. Well, no, with every other push in social media one

1246
01:11:57,090 --> 01:11:58,040
Speaker 6:  based on algorithms,

1247
01:11:58,280 --> 01:12:01,680
Speaker 4:  Time remains undefeated. Okay. And people get older. It's

1248
01:12:01,680 --> 01:12:01,760
Speaker 6:  True.

1249
01:12:02,450 --> 01:12:03,600
Speaker 4:  These kids, I hate

1250
01:12:03,600 --> 01:12:04,720
Speaker 6:  It, but true. Yeah.

1251
01:12:04,940 --> 01:12:08,920
Speaker 4:  And people get bored. And so, you know, I am a

1252
01:12:08,920 --> 01:12:12,480
Speaker 4:  firm believer that data can only tell you about the past. This is like what

1253
01:12:12,520 --> 01:12:16,000
Speaker 4:  I believe in my heart. If, if we followed our own analytics,

1254
01:12:16,580 --> 01:12:20,360
Speaker 4:  we would only cover the iPhone. Yes. That's all we would do. It is the

1255
01:12:20,460 --> 01:12:22,960
Speaker 4:  it is, we're not doing that. I know, I know you're mad at me for saying it.

1256
01:12:23,500 --> 01:12:27,440
Speaker 4:  The end of this f has gotten real spiky. But I promise

1257
01:12:27,500 --> 01:12:31,200
Speaker 4:  you, if I just did what people clicked on, we would write about the iPhone

1258
01:12:31,200 --> 01:12:35,120
Speaker 4:  fi find one case 500 times a day and Elon Musk for the rest

1259
01:12:35,120 --> 01:12:38,720
Speaker 4:  of our lives. Yep. And we, we don't do it 'cause we're bored. We don't wanna

1260
01:12:38,720 --> 01:12:41,400
Speaker 4:  do it. Yeah. We can, you know, like there's a thing here that we do where

1261
01:12:41,400 --> 01:12:45,120
Speaker 4:  we're like, decide what we're gonna do. But if you're fully analytics

1262
01:12:45,240 --> 01:12:49,210
Speaker 4:  driven, you just, that's a narrowing, right? It's just the,

1263
01:12:49,310 --> 01:12:52,890
Speaker 4:  the aperture of your interest just falls down and eventually you just make

1264
01:12:52,890 --> 01:12:56,850
Speaker 4:  one thing. Yeah. And I think most YouTubers are people and they have

1265
01:12:56,880 --> 01:13:00,850
Speaker 4:  that like instinct where they like push against it, but then there's a lot

1266
01:13:00,850 --> 01:13:02,650
Speaker 4:  of people who are there to just make money. Yeah. I was

1267
01:13:02,650 --> 01:13:06,330
Speaker 6:  About to like, my, my my big concern here is the people who wanna make money

1268
01:13:06,760 --> 01:13:10,530
Speaker 6:  tend to be really good at it and they tend to dominate the algorithm. And

1269
01:13:10,530 --> 01:13:14,010
Speaker 6:  then what we saw with Facebook, what we saw with even Google Ss e o is over

1270
01:13:14,010 --> 01:13:17,250
Speaker 6:  and over and over again. The thing that rises to the top isn't the quality

1271
01:13:17,260 --> 01:13:19,290
Speaker 6:  stuff. Yeah. It's the algorithm, the

1272
01:13:19,290 --> 01:13:21,090
Speaker 4:  Garbage. But that's thing, like David said at the very beginning, this is

1273
01:13:21,090 --> 01:13:24,890
Speaker 4:  the thing that kills your platform. Yeah. Like the dream screen generative

1274
01:13:25,070 --> 01:13:28,690
Speaker 4:  AI background is not the thing that kills YouTube. The

1275
01:13:28,910 --> 01:13:32,890
Speaker 4:  AI powered analytics that flattens all of YouTube into people just

1276
01:13:33,170 --> 01:13:36,850
Speaker 4:  fighting for the same kinds of attention. Well, on the other end is like

1277
01:13:36,850 --> 01:13:40,570
Speaker 4:  people as an audience. And if you only get one kind of thing from the

1278
01:13:40,810 --> 01:13:44,690
Speaker 4:  platform, eventually the audience gets bored too. Yeah. And I

1279
01:13:44,690 --> 01:13:48,510
Speaker 4:  don't, I don't know that YouTube is contended with that cycle, or, which

1280
01:13:48,550 --> 01:13:51,630
Speaker 4:  I think is a fair approach for YouTube. They're just like, it'll be fine.

1281
01:13:51,750 --> 01:13:53,750
Speaker 4:  'cause there's enough people who wanna be YouTubers. Well, and

1282
01:13:54,210 --> 01:13:57,830
Speaker 5:  The the optimistic take on this for YouTube would be that YouTube is not

1283
01:13:57,830 --> 01:14:01,750
Speaker 5:  just one thing, right? Like you, you can be a guy who stands in front

1284
01:14:01,750 --> 01:14:04,990
Speaker 5:  of your furnace and tells people how to use it and like make a career out

1285
01:14:04,990 --> 01:14:08,910
Speaker 5:  of being a YouTuber and to that person, if this tool is any good,

1286
01:14:08,910 --> 01:14:12,160
Speaker 5:  it's going to suggest new ways to make videos about furnaces. Right. But

1287
01:14:12,160 --> 01:14:15,800
Speaker 5:  it's like, yeah, if, if we get to the point where every creator on YouTube

1288
01:14:15,820 --> 01:14:19,720
Speaker 5:  is just being told to like, go livestream Taylor Swift's eras tour,

1289
01:14:19,720 --> 01:14:23,400
Speaker 5:  because that's how you make money on YouTube at this moment in time, we're

1290
01:14:23,400 --> 01:14:26,680
Speaker 5:  hosted and it's a perfectly plausible reality that that's where we land.

1291
01:14:27,070 --> 01:14:27,360
Speaker 5:  Yeah.

1292
01:14:27,360 --> 01:14:30,960
Speaker 6:  Do you think they start to change the surfacing though? For, for like what

1293
01:14:30,960 --> 01:14:34,520
Speaker 6:  you actually see? Like, will it be harder to find the guy

1294
01:14:34,980 --> 01:14:36,160
Speaker 6:  who does the TIS videos?

1295
01:14:36,590 --> 01:14:40,400
Speaker 4:  Well, no. 'cause that's search, you know, and like, I don't know. I just

1296
01:14:40,400 --> 01:14:44,040
Speaker 4:  think that, that this thing, like these recommendation algorithms, these,

1297
01:14:44,730 --> 01:14:46,240
Speaker 4:  these metrics

1298
01:14:47,920 --> 01:14:51,030
Speaker 4:  drive the dynamics of the platform more than anyone ever really wants to

1299
01:14:51,030 --> 01:14:54,830
Speaker 4:  admit. And so here the platform is gonna start interpreting the metrics for

1300
01:14:54,830 --> 01:14:58,630
Speaker 4:  you. And that's like some crazy shit's about to happen.

1301
01:14:59,430 --> 01:15:02,790
Speaker 4:  I like, I It's exciting in one way. It's also just like, I hope you're ready

1302
01:15:02,790 --> 01:15:05,110
Speaker 4:  for it. Yeah. You know? Yeah. All right. Let's do a really fast lightning

1303
01:15:05,110 --> 01:15:07,710
Speaker 4:  round. And Then, we gotta we gotta get outta the studio.

1304
01:15:07,740 --> 01:15:10,070
Speaker 5:  Yeah. There's like 40 more tech events to go to. Yeah,

1305
01:15:10,070 --> 01:15:13,870
Speaker 6:  Yeah. We're, we're busy. My lightning round is, I'm gonna selfishly say

1306
01:15:13,870 --> 01:15:17,190
Speaker 6:  go read my blog. I wrote about how the future of cable bundling is here,

1307
01:15:17,190 --> 01:15:20,350
Speaker 6:  which is a David headline, by the way. It's pretty good. Beautiful. David

1308
01:15:20,550 --> 01:15:20,830
Speaker 6:  headline.

1309
01:15:20,830 --> 01:15:23,430
Speaker 4:  Oh, and it, it's so here, by the way, we are hearing Rivers. The strikes

1310
01:15:23,430 --> 01:15:24,710
Speaker 4:  might be over soon. We are.

1311
01:15:25,300 --> 01:15:29,230
Speaker 6:  Yeah. They were saying as soon as today. But it is now we're recording.

1312
01:15:29,260 --> 01:15:31,910
Speaker 6:  It's about 4:00 PM We haven't heard anything. We'll see. All right,

1313
01:15:31,910 --> 01:15:32,430
Speaker 4:  David, what's yours?

1314
01:15:32,580 --> 01:15:36,270
Speaker 5:  Mine is the Google Bard chatbot can now

1315
01:15:36,270 --> 01:15:39,710
Speaker 5:  integrate with your Gmail and Docs and Google Drive

1316
01:15:40,090 --> 01:15:43,590
Speaker 5:  and actually like, go find information for you

1317
01:15:44,010 --> 01:15:47,990
Speaker 5:  in your other apps. And you look at that and it's like, oh, scary

1318
01:15:47,990 --> 01:15:51,230
Speaker 5:  privacy stuff. It's like my guys, it's all Google. They all have it anyway.

1319
01:15:51,480 --> 01:15:55,390
Speaker 5:  Don't worry about it. And genuinely, I have found it's totally useless

1320
01:15:55,410 --> 01:15:58,550
Speaker 5:  in some ways. But in, in the thing where you're like, I have an email about

1321
01:15:58,550 --> 01:16:02,350
Speaker 5:  a thing I don't really remember, but can you find that

1322
01:16:02,350 --> 01:16:06,270
Speaker 5:  email for me? It is like surprisingly good as a resource to just

1323
01:16:06,330 --> 01:16:10,230
Speaker 5:  dig through all my crap and find that one thing I was looking for. So this

1324
01:16:10,230 --> 01:16:13,430
Speaker 5:  is the time where I'm like, okay, this is like a, a digital assistant that

1325
01:16:13,430 --> 01:16:16,790
Speaker 5:  we're actually making into something. It's still Bard, so it's still not

1326
01:16:16,790 --> 01:16:20,710
Speaker 5:  very good, but it's, this was like the first step forward

1327
01:16:20,820 --> 01:16:22,950
Speaker 5:  I've seen for Bard where I'm like, all right, there's, there's something

1328
01:16:22,950 --> 01:16:23,070
Speaker 5:  here.

1329
01:16:23,170 --> 01:16:26,950
Speaker 4:  All right. I've done enough big thinky thinks on this episode. My lightning

1330
01:16:26,950 --> 01:16:30,790
Speaker 4:  round is that I'm sitting here holding a iPhone 15 pro in a fine loving

1331
01:16:30,790 --> 01:16:34,390
Speaker 4:  case. And my initials are fully scratched into the back of this case.

1332
01:16:34,590 --> 01:16:35,430
Speaker 6:  I can see them and

1333
01:16:35,430 --> 01:16:35,750
Speaker 4:  It's not

1334
01:16:35,750 --> 01:16:37,790
Speaker 5:  Great. It's as bad as advertised really. It's

1335
01:16:37,790 --> 01:16:41,230
Speaker 4:  As bad as advertised. I mean, it's, it's fine, but it's not great.

1336
01:16:41,540 --> 01:16:41,830
Speaker 5:  It's

1337
01:16:41,830 --> 01:16:44,350
Speaker 6:  Fine. I wanna see you eat fried chicken and then pick it up.

1338
01:16:44,570 --> 01:16:45,230
Speaker 4:  No, thank you.

1339
01:16:46,050 --> 01:16:46,990
Speaker 6:  That's all I want.

1340
01:16:47,130 --> 01:16:50,110
Speaker 4:  All right. That's it. That's The Vergecast thing. We, it's, it's, September

1341
01:16:50,510 --> 01:16:53,870
Speaker 4:  continues. Next week we're at the code conference. We'll have links, lots

1342
01:16:53,870 --> 01:16:56,710
Speaker 4:  of coverage, lots of stuff has continues to go down here in the craziest

1343
01:16:57,070 --> 01:17:00,550
Speaker 4:  September. A fight careers tech journalist. That's it. We gotta go rock and

1344
01:17:00,550 --> 01:17:00,710
Speaker 4:  roll.

1345
01:17:05,410 --> 01:17:08,790
Speaker 8:  And that's a wrap for Vergecast this week. We'd love to hear from you. Shoot

1346
01:17:08,790 --> 01:17:12,680
Speaker 8:  us an email at Vergecast at The Verge dot com. The Vergecast is a

1347
01:17:12,680 --> 01:17:16,320
Speaker 8:  production of The Verge and the Vox Media Podcast network. The show is produced

1348
01:17:16,320 --> 01:17:20,280
Speaker 8:  by me, Liam James, and our senior audio director, Andrew Marino. Our

1349
01:17:20,280 --> 01:17:23,600
Speaker 8:  editorial director is Brooke Miners. That's it. We'll see you next week.

