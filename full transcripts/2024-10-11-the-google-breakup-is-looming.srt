1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 03bfc60b-0101-445c-8e44-363ea1443cde
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/2914124582103806465/-7065658135529835/s93290-US-6292s-1728650709.mp3
Description: Nilay and David make some predictions about Thursday evening’s Tesla event — which you’ve already seen, but we haven’t! Then they talk about the week’s gadget news, from Nintendo’s new Alarmo alarm clock to Apple’s upcoming iPads and Macs. Then Lauren Feiner joins to talk about the latest on all fronts in Google’s antitrust fight, and how the government might be planning to break up the company altogether. Then it’s time for a lightning round about Google Docs tabs, FEMA misinformation, and Zoom AI avatars.

2
00:01:48,825 --> 00:01:51,885
Speaker 2:  in the studio. This is my second studio. Time in the studio. But the first

3
00:01:51,885 --> 00:01:54,765
Speaker 2:  time that you've been here when I've been in the studio. Well, the other

4
00:01:54,765 --> 00:01:58,325
Speaker 2:  thing, you typically run away from me when I arrive in New York. You flee

5
00:01:58,325 --> 00:02:02,085
Speaker 2:  upstate somewhere. Yeah, that's, that's my entire goal in life is to flee.

6
00:02:02,115 --> 00:02:05,965
Speaker 2:  Yeah. Flee to the woods. Later on the show, Lauren Finder's gonna join us.

7
00:02:05,965 --> 00:02:09,785
Speaker 2:  We're gonna talk about Google, which has attracted the attention

8
00:02:09,845 --> 00:02:13,465
Speaker 2:  of our nation's regulators. The, the white hot

9
00:02:13,465 --> 00:02:16,625
Speaker 2:  attention, the nations court system, potentially like historic way. Yeah.

10
00:02:16,655 --> 00:02:20,585
Speaker 2:  Yeah. And it's like going, it's, I would say it's not making a blip.

11
00:02:21,585 --> 00:02:24,605
Speaker 2:  No. Like what if we break up Google and everyone's like, huh.

12
00:02:26,305 --> 00:02:29,765
Speaker 2:  So Lauren's gonna explain why it's much more than a blip because there's

13
00:02:30,065 --> 00:02:32,885
Speaker 2:  two different cases that are gonna result in major changes to how Google

14
00:02:32,885 --> 00:02:36,575
Speaker 2:  works. And then we're gonna have lightning round and boy do we have a lot

15
00:02:36,575 --> 00:02:39,855
Speaker 2:  of stuff in the lightning round, which remains, I would say. Unsponsored.

16
00:02:40,565 --> 00:02:43,775
Speaker 2:  Also, there's at least one thing here is titled Microsoft Word. Final. Final

17
00:02:43,775 --> 00:02:44,895
Speaker 2:  Google Remedy Framework.

18
00:02:46,615 --> 00:02:50,315
Speaker 2:  Listen, that's how justice gets done in this country. You, I Final,

19
00:02:50,325 --> 00:02:53,475
Speaker 2:  final two. Yeah. Alright, let's start with the news.

20
00:02:54,785 --> 00:02:57,835
Speaker 2:  There's one piece of news that I really want to talk about the most important

21
00:02:57,835 --> 00:03:00,645
Speaker 2:  news of the week, which is Nintendo be a a hundred dollars alarm clock. Yes.

22
00:03:00,855 --> 00:03:04,845
Speaker 2:  We'll get to that. Then there's the news that has not happened yet

23
00:03:04,945 --> 00:03:08,445
Speaker 2:  as we are recording, but by the time you listen to this

24
00:03:09,355 --> 00:03:13,005
Speaker 2:  will have occurred. And by occurred, I mean

25
00:03:13,345 --> 00:03:17,005
Speaker 2:  people will make you promises that will not come true. And

26
00:03:17,325 --> 00:03:20,845
Speaker 2:  specifically what I mean is Tesla's gonna have its robax event. It's long

27
00:03:21,075 --> 00:03:24,845
Speaker 2:  awaited once delayed, twice delayed,

28
00:03:25,045 --> 00:03:28,845
Speaker 2:  I mean delayed since 2016. Fair. Yeah. Delayed

29
00:03:28,845 --> 00:03:31,805
Speaker 2:  several times at this point. But yeah, they've been promising this

30
00:03:32,675 --> 00:03:36,645
Speaker 2:  Elon Musk, not they fair. Elon in particular has been promising

31
00:03:36,645 --> 00:03:40,525
Speaker 2:  this for like a long, long, long time. and it

32
00:03:40,525 --> 00:03:44,325
Speaker 2:  was supposed to happen what in August and then that got

33
00:03:44,325 --> 00:03:48,185
Speaker 2:  delayed and now it it between when we record and when you hear

34
00:03:48,185 --> 00:03:51,975
Speaker 2:  this, it is supposedly going to happen. Yeah. I think it's like 10:00 PM

35
00:03:51,975 --> 00:03:55,935
Speaker 2:  at night on the east coast for us. It's happening on a movie studio lot in

36
00:03:55,935 --> 00:03:59,375
Speaker 2:  California and they're gonna unveil what looks like a

37
00:03:59,385 --> 00:04:03,175
Speaker 2:  two-seater car with like Lambo doors. Yeah.

38
00:04:03,495 --> 00:04:06,895
Speaker 2:  I mean it seems, it seems like it's going to be a Tesla.

39
00:04:08,455 --> 00:04:10,855
Speaker 2:  I don't know what I was expecting. Part of me was like, you know, if the

40
00:04:10,855 --> 00:04:14,095
Speaker 2:  robot taxi is gonna be the thing, maybe they're gonna take this huge swing.

41
00:04:14,095 --> 00:04:16,655
Speaker 2:  And we've seen all these concepts that are like, what if we completely reinvent

42
00:04:16,655 --> 00:04:19,575
Speaker 2:  the whole idea of what it means to be in a car? And instead of everybody

43
00:04:19,575 --> 00:04:23,215
Speaker 2:  facing forward, it's just gonna be like lounges inside that everybody hangs

44
00:04:23,215 --> 00:04:26,895
Speaker 2:  out in. And I, it looks an awful lot. Like they're just gonna be like, here's

45
00:04:26,895 --> 00:04:29,985
Speaker 2:  a car. Well, it's a weird looking car. It's like, there was a picture of

46
00:04:29,985 --> 00:04:33,745
Speaker 2:  it in the Elon Musk biography by Walter Isaacson. It's just,

47
00:04:33,845 --> 00:04:37,545
Speaker 2:  it looks like a, like a tricycle car, like a backwards, like a three wheel

48
00:04:37,545 --> 00:04:40,425
Speaker 2:  car, two wheels in front, one wheel in the back, two seats, and then doors

49
00:04:40,455 --> 00:04:42,025
Speaker 2:  that kind of open up into the side.

50
00:04:43,695 --> 00:04:47,505
Speaker 2:  Sure. Yeah. I think the car is the least important part of this.

51
00:04:47,865 --> 00:04:51,625
Speaker 2:  I think in classic Tesla fashion, we're all

52
00:04:51,705 --> 00:04:55,385
Speaker 2:  gonna look at the weird car idea and no one will look at the

53
00:04:55,515 --> 00:04:59,505
Speaker 2:  underlying does it work idea? Right. Well, and this has

54
00:04:59,505 --> 00:05:03,025
Speaker 2:  kind of been Tesla's thing for a long time. Like I think, I don't remember

55
00:05:03,025 --> 00:05:04,865
Speaker 2:  if this was the last time we talked about Tesla, but not that long ago. We

56
00:05:04,865 --> 00:05:07,345
Speaker 2:  talked about Tesla and I got very upset about the door handles on a Tesla.

57
00:05:08,465 --> 00:05:11,585
Speaker 2:  A lot of people got very angry at me for thinking the door handles on a Tesla

58
00:05:11,685 --> 00:05:15,625
Speaker 2:  are stupid. They are stupid. And I was right. And

59
00:05:15,665 --> 00:05:19,625
Speaker 2:  I think one of the strange things that Tesla has been doing for

60
00:05:19,705 --> 00:05:23,625
Speaker 2:  a long time now is trying to like reinvent all the things about cars

61
00:05:23,625 --> 00:05:27,585
Speaker 2:  that we mostly figured out a while ago. Like the cyber truck is just a lot

62
00:05:27,585 --> 00:05:31,465
Speaker 2:  of new ideas about things that we've already solved. And

63
00:05:31,605 --> 00:05:35,585
Speaker 2:  to your point so far, not doing, ultimately the only thing that matters

64
00:05:36,375 --> 00:05:39,625
Speaker 2:  both to Tesla and ostensibly to Elon Musk, which is solving

65
00:05:39,905 --> 00:05:43,585
Speaker 2:  self-driving like that has been the thing for so long

66
00:05:44,255 --> 00:05:47,865
Speaker 2:  that you could kind of argue everything else has been just a diversion along

67
00:05:47,865 --> 00:05:51,745
Speaker 2:  the way towards making self-driving actually work. Yeah. Like that

68
00:05:51,745 --> 00:05:55,385
Speaker 2:  is the thing. So Andy Hawkins wrote us, I would say

69
00:05:55,385 --> 00:05:59,245
Speaker 2:  somewhere between a timeline and a primal scream. Yeah, that's about

70
00:05:59,245 --> 00:06:02,925
Speaker 2:  right. Like If, you can organize a primal scream in

71
00:06:02,925 --> 00:06:06,085
Speaker 2:  chronological order that is Andy's piece,

72
00:06:06,885 --> 00:06:10,045
Speaker 2:  which by the way, was immediately brigade by people who started their commenting

73
00:06:10,045 --> 00:06:13,205
Speaker 2:  accounts that day to tell us, If, you were hand at Yohan. What's a tell guys?

74
00:06:13,225 --> 00:06:16,925
Speaker 2:  You gotta start the bot accounts and lie 'em and wait. Yeah. Play a long

75
00:06:16,925 --> 00:06:19,925
Speaker 2:  game here people. And what you should do in the meantime is be a thoughtful

76
00:06:20,105 --> 00:06:23,605
Speaker 2:  and constructive VERGE commenter so that when it's time to strike,

77
00:06:23,855 --> 00:06:27,605
Speaker 2:  we're not expecting, you don't start your account that day and be like, I'm

78
00:06:27,605 --> 00:06:29,605
Speaker 2:  never reading The Verge again. We, we just, we're gonna Yeah. That's like

79
00:06:29,605 --> 00:06:33,285
Speaker 2:  a 2016 strategy. Like we've come a long way. Yeah. You gotta again, thoughtful,

80
00:06:33,845 --> 00:06:37,205
Speaker 2:  constructive commenter for years and then you strike.

81
00:06:37,615 --> 00:06:41,525
Speaker 2:  Think about that. Yeah. All right. So Andy wrote a timeline, and

82
00:06:41,545 --> 00:06:45,365
Speaker 2:  I'm just gonna read you the first paragraph. In 2016, Elon Musk had Tesla

83
00:06:45,365 --> 00:06:49,165
Speaker 2:  self-driving cars were two years away in 27. In 2017 it was quote

84
00:06:49,225 --> 00:06:53,045
Speaker 2:  six months. Definitely. And customers were able to sleep in their

85
00:06:53,045 --> 00:06:56,885
Speaker 2:  Teslas while driving in two years. In 2018, Elon Musk said it was

86
00:06:56,885 --> 00:07:00,245
Speaker 2:  quote a year away and would be 200% safer than human driving in

87
00:07:00,245 --> 00:07:04,165
Speaker 2:  2019. He said there would be feature complete full self-driving

88
00:07:04,165 --> 00:07:07,765
Speaker 2:  this year. That's 2019. He still

89
00:07:07,765 --> 00:07:11,565
Speaker 2:  talked about it. He's renamed full self-driving to full self-driving

90
00:07:11,995 --> 00:07:15,925
Speaker 2:  parentheses supervised, which is so funny. Full self-driving

91
00:07:16,045 --> 00:07:19,885
Speaker 2:  narrator voice, not full self-driving. and it, it, it doesn't

92
00:07:19,915 --> 00:07:23,725
Speaker 2:  work like If, you use full self-driving in a model three today, say you

93
00:07:23,825 --> 00:07:26,565
Speaker 2:  are the chances that you will have to grab the wheel in anything but a highway

94
00:07:26,565 --> 00:07:29,765
Speaker 2:  environment are, are basically guaranteed. Yeah. That's just how it goes.

95
00:07:29,825 --> 00:07:33,165
Speaker 2:  And the accidents that it gets into or the mistakes that that system makes

96
00:07:33,905 --> 00:07:37,005
Speaker 2:  are funny if you're watching them on a YouTube video and I think not so funny

97
00:07:37,005 --> 00:07:40,725
Speaker 2:  if you're in the car. Yeah. Agreed. Meanwhile, and to be clear, a lot of

98
00:07:40,725 --> 00:07:43,285
Speaker 2:  these things that are happening with self-driving cars are not limited to

99
00:07:43,285 --> 00:07:46,645
Speaker 2:  Tesla. Like, it's just that Tesla gets so much more

100
00:07:47,275 --> 00:07:51,045
Speaker 2:  crap for it because Tesla is the one most confidently saying it has solved

101
00:07:51,105 --> 00:07:55,085
Speaker 2:  the problem. Like Waymo is not out here being like, we did it. We're

102
00:07:55,165 --> 00:07:58,885
Speaker 2:  finished. The job is done. Yeah. years ago, I would say

103
00:07:59,425 --> 00:08:03,125
Speaker 2:  10 years ago, Waymo was just as ambitious as Tesla was and then

104
00:08:03,125 --> 00:08:07,085
Speaker 2:  pretty quickly started to rewind and be like, actually we've realized this

105
00:08:07,205 --> 00:08:11,125
Speaker 2:  is a much longer like asymptotic problem than we realized

106
00:08:11,125 --> 00:08:14,405
Speaker 2:  where we're gonna get really good. And then the last 1% of this is going

107
00:08:14,405 --> 00:08:17,325
Speaker 2:  to go from like a two year problem to maybe like a two decade problem. And

108
00:08:17,325 --> 00:08:20,925
Speaker 2:  to your point, Waymo had no aspirations of reinventing the car.

109
00:08:20,975 --> 00:08:23,605
Speaker 2:  Right. They're like, their early ones are like, you know what, it's a Chrysler

110
00:08:23,645 --> 00:08:27,445
Speaker 2:  Pacifica. Yeah. A car, like car What? When you

111
00:08:27,445 --> 00:08:31,405
Speaker 2:  imagine a car that can hold six people Chrysler, Pacifica. And then I

112
00:08:31,405 --> 00:08:35,125
Speaker 2:  think later on they're like, okay, it's some Jaguar F type. Yes. And now

113
00:08:35,235 --> 00:08:39,045
Speaker 2:  they only operate in San Francisco, Phoenix, Los Angeles, and Austin, notably

114
00:08:39,045 --> 00:08:42,885
Speaker 2:  cities with good weather and except for San Francisco pretty flat.

115
00:08:43,075 --> 00:08:46,885
Speaker 2:  Yeah. And so pretty easy terrain for the most, they, they have just like

116
00:08:47,035 --> 00:08:50,885
Speaker 2:  radically constricted their effort, right? Can we make a

117
00:08:51,085 --> 00:08:55,005
Speaker 2:  Chrysler Pacifica turn left? And that took them I think three years can,

118
00:08:55,085 --> 00:08:57,785
Speaker 2:  can this thing make a left turn at a busy intersection? and it, the answer

119
00:08:57,805 --> 00:09:01,705
Speaker 2:  for a long time was maybe, and they just diligently solved that

120
00:09:01,705 --> 00:09:04,505
Speaker 2:  problem. Now you can get Waymo in all those cities and it's fine. People

121
00:09:04,505 --> 00:09:06,945
Speaker 2:  really like them. People actually prefer them. They're paying a premium to

122
00:09:06,945 --> 00:09:10,875
Speaker 2:  ride our own in way modes. Well, and again, like I, I think I, I keep

123
00:09:10,875 --> 00:09:14,715
Speaker 2:  coming back to like, everybody drags us for dragging Tesla.

124
00:09:14,975 --> 00:09:18,395
Speaker 2:  And I think at this particular moment, the thing that has changed is If,

125
00:09:18,395 --> 00:09:22,315
Speaker 2:  you rewind back to 2016 when, when Elon and everybody else was saying

126
00:09:22,315 --> 00:09:26,115
Speaker 2:  that stuff, everybody was saying that stuff, right? Like there was this industry

127
00:09:26,185 --> 00:09:29,595
Speaker 2:  wide belief that by 2020 we were all gonna be riding around in rot taxis.

128
00:09:29,705 --> 00:09:32,635
Speaker 2:  Uber was making that bet. Lyft was making that bet. Car companies were making

129
00:09:32,635 --> 00:09:36,395
Speaker 2:  that bet. And then pretty quickly over the next

130
00:09:36,395 --> 00:09:40,195
Speaker 2:  couple of years, a as the money for

131
00:09:40,195 --> 00:09:43,595
Speaker 2:  saying that started to dry up and b, as the

132
00:09:43,745 --> 00:09:47,635
Speaker 2:  realities of like the world and the regulatory state and people being

133
00:09:47,705 --> 00:09:50,915
Speaker 2:  dumb at driving started to appear, everybody else

134
00:09:51,345 --> 00:09:53,955
Speaker 2:  started to slow down. and it was like, okay, this is the thing we have to

135
00:09:53,955 --> 00:09:57,675
Speaker 2:  do thoughtfully and methodically. and it, it caused them

136
00:09:57,675 --> 00:10:00,155
Speaker 2:  trouble. Like there are people out there who are like, Google needs to shut

137
00:10:00,155 --> 00:10:02,595
Speaker 2:  down Waymo, it's a waste of money. Why on earth are they still at this?

138
00:10:03,935 --> 00:10:06,915
Speaker 2:  But they've all started to push more

139
00:10:07,625 --> 00:10:10,995
Speaker 2:  carefully with some exceptions. I think like Cruz got out over at skis in

140
00:10:10,995 --> 00:10:14,035
Speaker 2:  some ways and like there have been issues, but in huge ways. Yeah. But like

141
00:10:14,295 --> 00:10:18,235
Speaker 2:  for the most part, a lot of these companies were at least starting to recognize

142
00:10:18,235 --> 00:10:20,955
Speaker 2:  like, okay, this is a bigger problem than we thought. Let's try to be more

143
00:10:20,955 --> 00:10:24,795
Speaker 2:  thoughtful. Elon Musk is the only one who has continued to come out and tell

144
00:10:24,795 --> 00:10:28,595
Speaker 2:  us that it's going to be any minute now and calling things full

145
00:10:28,595 --> 00:10:32,035
Speaker 2:  self-driving and like, and it's, we've just gotten to the point where it's

146
00:10:32,035 --> 00:10:35,515
Speaker 2:  like he's just been either wrong or lying

147
00:10:36,095 --> 00:10:40,035
Speaker 2:  so many times in a row now that on this particular thing he has

148
00:10:40,065 --> 00:10:43,075
Speaker 2:  just lost all benefit of the doubt Yeah. To talk about any of this stuff.

149
00:10:43,375 --> 00:10:46,515
Speaker 2:  And the really interesting dynamic in what you're describing is all these

150
00:10:46,715 --> 00:10:49,875
Speaker 2:  companies are promising that they will do robotaxis. Well that was

151
00:10:50,135 --> 00:10:54,075
Speaker 2:  2016 ish. The height of zero interest rate

152
00:10:54,075 --> 00:10:57,875
Speaker 2:  Exactly. VC funding into everything. And the whole plan was, we'll

153
00:10:57,875 --> 00:11:01,755
Speaker 2:  flood these markets with VC dollars, we will take them over, we

154
00:11:01,755 --> 00:11:05,595
Speaker 2:  will just predatorily price everybody else out. Right. We'll kill public

155
00:11:05,595 --> 00:11:08,355
Speaker 2:  transportation. We'll get all the taxis off the road and we'll make it stupid

156
00:11:08,375 --> 00:11:10,995
Speaker 2:  for you to buy a car and then you'll have no choice but to use. And then,

157
00:11:10,995 --> 00:11:13,795
Speaker 2:  then we'll raise the price on Uber. And by then we'll get, and Travis Kanick

158
00:11:13,795 --> 00:11:16,755
Speaker 2:  said this on stage of code. He said, my problem is the other guy in the car,

159
00:11:17,395 --> 00:11:20,555
Speaker 2:  I gotta get rid of the other guy in the car. Right. The driver and then the

160
00:11:20,765 --> 00:11:24,755
Speaker 2:  robot can drive the car and then I will make more money. And

161
00:11:24,815 --> 00:11:28,195
Speaker 2:  he said this with, I was in the room and he said this with such pride on

162
00:11:28,195 --> 00:11:32,075
Speaker 2:  his face to Kara Swisher. And everyone else was like, what about

163
00:11:32,075 --> 00:11:35,875
Speaker 2:  the guys? Right? Like the guys in the car and it was like huge

164
00:11:35,875 --> 00:11:39,635
Speaker 2:  protests, you know, like walk it back. But what they were all chasing is

165
00:11:40,555 --> 00:11:44,475
Speaker 2:  software style margins in hardware. Right. So we, we have

166
00:11:44,475 --> 00:11:48,395
Speaker 2:  this one car, we're just gonna run it 24 7, it's gonna produce money while

167
00:11:48,395 --> 00:11:51,765
Speaker 2:  it lasts and then we'll throw it away and we'll we'll make a new car. And

168
00:11:51,765 --> 00:11:55,165
Speaker 2:  they, no one has gotten there. No. Like Waymo's are still very expensive,

169
00:11:55,165 --> 00:11:58,605
Speaker 2:  except if you're listening to this maybe Tesla, maybe they didn't. Right.

170
00:11:58,605 --> 00:12:02,205
Speaker 2:  And, and then along the way there's been these like enabling technology fights,

171
00:12:02,205 --> 00:12:06,045
Speaker 2:  right? Should we have lidar? Can we do it all with vision? Can we do it with

172
00:12:06,045 --> 00:12:09,845
Speaker 2:  just a handful of like half a megapixel video cameras on the sides of Teslas?

173
00:12:10,145 --> 00:12:13,245
Speaker 2:  No, we should probably upgrade those cameras. Like all of these little fights

174
00:12:13,245 --> 00:12:16,765
Speaker 2:  along the way. And really what you have is Waymo with the full lidar sensor

175
00:12:16,815 --> 00:12:20,805
Speaker 2:  suite. You have a handful of other companies that are also

176
00:12:20,805 --> 00:12:23,805
Speaker 2:  trying lidar stuff but haven't shipped anything. And then

177
00:12:24,965 --> 00:12:28,605
Speaker 2:  whatever happened between the time we are talking and the time you're listening,

178
00:12:29,185 --> 00:12:32,585
Speaker 2:  and I am just guessing that it's nothing.

179
00:12:33,335 --> 00:12:36,825
Speaker 2:  Wait, okay. Let's, this is fun. Let's do this. So this is the rare time when

180
00:12:38,325 --> 00:12:41,985
Speaker 2:  we don't know the answers to something, but everyone listening to this is

181
00:12:41,985 --> 00:12:44,945
Speaker 2:  going to know like you're, you're at the part of the murder mystery where

182
00:12:44,965 --> 00:12:47,985
Speaker 2:  the audience has seen the murderer, but the people have not. It's a good

183
00:12:47,985 --> 00:12:51,665
Speaker 2:  time. So let's do this. Let's, let's just make predictions about what's gonna

184
00:12:51,665 --> 00:12:54,945
Speaker 2:  happen at this Tesla event. Yeah. And everyone who listens can tell us how

185
00:12:54,945 --> 00:12:58,865
Speaker 2:  right or wrong we were, this is our only move, right. I feel

186
00:12:58,865 --> 00:13:02,825
Speaker 2:  like we have to do this. All right. You, what's your first prediction? Okay.

187
00:13:03,205 --> 00:13:07,145
Speaker 2:  My my first prediction is that there will

188
00:13:07,145 --> 00:13:10,945
Speaker 2:  be a live demo and it won't work in some

189
00:13:11,555 --> 00:13:15,345
Speaker 2:  meaningful way. It will not work. I'm thinking

190
00:13:15,345 --> 00:13:19,065
Speaker 2:  about the person in the optimist robot costume

191
00:13:19,785 --> 00:13:23,425
Speaker 2:  that counts as a demo. That didn't work. Throwing the ball at the cyber truck

192
00:13:23,425 --> 00:13:26,625
Speaker 2:  window. That's a thing that didn't work. I think there is going to be

193
00:13:27,375 --> 00:13:30,705
Speaker 2:  some way in which this thing tries to move itself. And it's not,

194
00:13:31,095 --> 00:13:34,825
Speaker 2:  it's not gonna work in, in some defensible but

195
00:13:35,045 --> 00:13:38,875
Speaker 2:  fairly problematic way. Can, can I make a sub prediction

196
00:13:38,875 --> 00:13:41,755
Speaker 2:  please? I think there will be a live demo and it will work and it will be

197
00:13:41,755 --> 00:13:44,955
Speaker 2:  later revealed that the car was just being remote controlled off stage.

198
00:13:45,895 --> 00:13:49,635
Speaker 2:  The, the, the Nicola truck rolling down the hill. Yeah. Yeah. Kind of vibes.

199
00:13:49,745 --> 00:13:53,155
Speaker 2:  Okay. That's, that's my, that's my sub prediction. There literally was a

200
00:13:53,155 --> 00:13:56,315
Speaker 2:  person in the trunk. Yeah. There's a guy with an RC controller, you know,

201
00:13:56,785 --> 00:14:00,355
Speaker 2:  just doing it. I would be shocked. And we, we'll see it is true that Tesla

202
00:14:00,625 --> 00:14:03,475
Speaker 2:  cars can do summon in a parking lot. They can operate.

203
00:14:04,985 --> 00:14:07,445
Speaker 2:  But I think, but so this is the thing, right? This is the reason I think

204
00:14:07,445 --> 00:14:10,805
Speaker 2:  this, because if you're going to show off what it can do, you have to do

205
00:14:10,805 --> 00:14:14,165
Speaker 2:  something more than that. Because that basic stuff, they're, they're good

206
00:14:14,165 --> 00:14:16,565
Speaker 2:  at and they've been good at for a long time. So if you're gonna show we made

207
00:14:16,565 --> 00:14:20,475
Speaker 2:  a robo taxii, then I think they're gonna show a robo taxii

208
00:14:20,475 --> 00:14:24,315
Speaker 2:  and they're gonna show it driving around a parking lot and then let everybody,

209
00:14:24,575 --> 00:14:26,475
Speaker 2:  let all the fanboy imaginations go wild.

210
00:14:28,125 --> 00:14:31,905
Speaker 2:  See what I'm saying? Yeah. I don't think So I think it like hits a cone

211
00:14:32,085 --> 00:14:34,505
Speaker 2:  in the parking lot. Alright, that's your prediction's. Like, oh, it's just

212
00:14:34,505 --> 00:14:38,225
Speaker 2:  a cone. My prediction, no matter what,

213
00:14:39,405 --> 00:14:42,865
Speaker 2:  he will not announce an arrival date before 2027. That's

214
00:14:43,595 --> 00:14:47,285
Speaker 2:  two years. That's essentially two years. Okay. First of all, wild that that's

215
00:14:47,285 --> 00:14:50,805
Speaker 2:  only two years. Second of all sub question,

216
00:14:52,545 --> 00:14:56,485
Speaker 2:  if I'm giving you the over under on July 1st, 2027 for when this

217
00:14:56,725 --> 00:15:00,245
Speaker 2:  actually ships, are you taking the over the under over way, way over. Okay.

218
00:15:00,785 --> 00:15:04,725
Speaker 2:  And that, and that's what I'm, what I'm pinning that to is it took

219
00:15:04,745 --> 00:15:07,645
Speaker 2:  how long to ship the cyber truck, he's gotta make a whole new car. Right?

220
00:15:07,715 --> 00:15:10,525
Speaker 2:  He's gotta make this little taxi that's gonna distract everybody from whether

221
00:15:10,525 --> 00:15:13,925
Speaker 2:  or not it can actually drive itself. And they're not great at that

222
00:15:15,215 --> 00:15:19,085
Speaker 2:  right now. Okay. All right. So 2027 is your, is your prediction?

223
00:15:19,085 --> 00:15:22,045
Speaker 2:  That's my prediction. Are we, are we saying after 27 or are you just calling

224
00:15:22,045 --> 00:15:25,685
Speaker 2:  your shot? It's 2027 is the, I'm saying the announced date. Yeah, not the

225
00:15:25,685 --> 00:15:28,565
Speaker 2:  act I'm not taking any No, but I mean the one he's gonna say he's gonna say

226
00:15:28,565 --> 00:15:32,245
Speaker 2:  2027. Okay. All right. I love it. My second

227
00:15:32,385 --> 00:15:35,845
Speaker 2:  one, and this is, this is only half formed because I haven't all the way

228
00:15:35,845 --> 00:15:39,525
Speaker 2:  figured it out. I think the optimist robot is going to be featured in this

229
00:15:39,525 --> 00:15:42,805
Speaker 2:  product somehow. I don't, I don't. That's the guy in the trunk. It's the

230
00:15:42,805 --> 00:15:42,885
Speaker 2:  guy.

231
00:15:44,555 --> 00:15:48,165
Speaker 2:  Yeah. The back of open it up. It's, it's, it's full self-driving.

232
00:15:48,425 --> 00:15:52,125
Speaker 2:  But then if, if it all goes wrong, something just springs out of the truck

233
00:15:52,985 --> 00:15:56,605
Speaker 2:  in through the sunroof and starts driving, there is a debate slash rumor

234
00:15:57,475 --> 00:16:00,925
Speaker 2:  that they have to certify level five

235
00:16:00,965 --> 00:16:04,925
Speaker 2:  self-driving without a steering wheel to pull this off. And

236
00:16:04,925 --> 00:16:08,845
Speaker 2:  that is really hard. So the, the rumor slash debate

237
00:16:08,985 --> 00:16:12,805
Speaker 2:  is, will there be like a steering wheel that pops up when you need intervention?

238
00:16:12,905 --> 00:16:16,875
Speaker 2:  So it's still a level three or level four because you can't,

239
00:16:17,135 --> 00:16:19,755
Speaker 2:  you can't not have a steering wheel. You pull a brick record in the steering

240
00:16:19,755 --> 00:16:23,475
Speaker 2:  wheel at the others. Yeah, that's, I'm just saying that's like, I've heard

241
00:16:23,475 --> 00:16:25,995
Speaker 2:  this debate like, will it have a steering wheel? 'cause a picture we've seen

242
00:16:25,995 --> 00:16:28,075
Speaker 2:  from the Isaacson book has no steering wheel. Right. But if you're gonna

243
00:16:28,075 --> 00:16:30,955
Speaker 2:  have no steering wheel, that means you have now launched level five autonomy,

244
00:16:32,295 --> 00:16:36,045
Speaker 2:  which means a bunch of people get to decide if that thing is safe.

245
00:16:36,825 --> 00:16:40,725
Speaker 2:  Or you can have something less than that. And like a steering

246
00:16:40,725 --> 00:16:43,365
Speaker 2:  wheel appears, or optimist is in the back being like

247
00:16:44,475 --> 00:16:48,435
Speaker 2:  something I, I honestly would believe

248
00:16:49,145 --> 00:16:52,675
Speaker 2:  Elon Musk being like, and the beauty of this is because there's an optimist

249
00:16:52,675 --> 00:16:56,115
Speaker 2:  robot in the driver's seat. You always get to be in HOV lanes so you can

250
00:16:56,115 --> 00:16:59,155
Speaker 2:  go even faster. Oh, that's good. Like I could, it's just sitting right there.

251
00:16:59,355 --> 00:17:02,315
Speaker 2:  I could see it. So, I think, I think If, you get one of these,

252
00:17:03,455 --> 00:17:06,835
Speaker 2:  you will get, there will be an optimist robot involved somehow. I haven't

253
00:17:06,835 --> 00:17:10,755
Speaker 2:  figured it all the way out, but it's just, that is a, that is a prediction.

254
00:17:10,865 --> 00:17:14,235
Speaker 2:  It's just in there somewhere. It's just somewhere in there is hand wavy optimist.

255
00:17:14,235 --> 00:17:17,515
Speaker 2:  Yeah. What's yours? Is it a guy in a suit optimist or an actual optimist?

256
00:17:17,515 --> 00:17:21,275
Speaker 2:  No, it's an actual optimist. Okay. That's pushes way out past 27 in

257
00:17:21,435 --> 00:17:25,015
Speaker 2:  my mind. I'm not saying any of this is gonna ship. To be clear,

258
00:17:25,325 --> 00:17:29,255
Speaker 2:  none of this is predicated on actually shipping. Okay. My third prediction,

259
00:17:29,455 --> 00:17:32,895
Speaker 2:  I think is the one that will cause the most consternation.

260
00:17:33,595 --> 00:17:37,535
Speaker 2:  So for years, Tesla's evaluation in the stock market and with a bunch of

261
00:17:37,535 --> 00:17:40,935
Speaker 2:  Tesla fans has been predicated on the idea

262
00:17:41,405 --> 00:17:45,215
Speaker 2:  that the model threes and Ys sitting in driveways around the world and

263
00:17:45,215 --> 00:17:48,135
Speaker 2:  country will suddenly turn into the robotaxis fleet.

264
00:17:50,055 --> 00:17:53,785
Speaker 2:  This is the promise. Yeah. People have bought these cars expecting that

265
00:17:53,785 --> 00:17:57,105
Speaker 2:  they'll go to bed and their model threes will wander the streets

266
00:17:57,435 --> 00:18:01,325
Speaker 2:  being taxis making them money. Right. And that is, that is

267
00:18:01,325 --> 00:18:02,485
Speaker 2:  the multiplier of the stock price.

268
00:18:04,325 --> 00:18:07,525
Speaker 2:  I am saying they're gonna have this launch event and they will say existing

269
00:18:07,665 --> 00:18:11,485
Speaker 2:  Teslas will not be robotaxis. No. No way. No

270
00:18:11,505 --> 00:18:15,365
Speaker 2:  way. Why That would immediate, that is the worst possible,

271
00:18:15,995 --> 00:18:19,845
Speaker 2:  like investor move Elon Musk could make. Oh, oh, I know. But it's the,

272
00:18:20,525 --> 00:18:23,885
Speaker 2:  I think they, they're gonna have to come clean and be like, here's the cyber

273
00:18:23,955 --> 00:18:26,845
Speaker 2:  taxi, here's our other weird triangle car that we've made.

274
00:18:28,035 --> 00:18:31,805
Speaker 2:  It's, it's the future of the Roboto Taxii program. And a model three

275
00:18:31,835 --> 00:18:35,685
Speaker 2:  from 2018 that we promised would turn into a taxi 2020.

276
00:18:36,245 --> 00:18:39,725
Speaker 2:  I think this the, the, the height of this was around 2020. I only know this

277
00:18:39,725 --> 00:18:42,765
Speaker 2:  because it was one of those like pandemic feelings that I had. Sure. Like

278
00:18:42,875 --> 00:18:46,365
Speaker 2:  I've, I've been drunk for four days and Elna sing. All the cars are

279
00:18:46,535 --> 00:18:49,565
Speaker 2:  taxis. Like whatever that swirl of feeling is

280
00:18:50,415 --> 00:18:53,915
Speaker 2:  2020. Let's say people bought these cars in 2020, assuming they would turn

281
00:18:53,915 --> 00:18:57,555
Speaker 2:  into taxis that run on Bitcoin or whatever they were doing in the middle

282
00:18:57,555 --> 00:19:01,515
Speaker 2:  of the pandemic, obviously. And he's gonna have to show up and

283
00:19:01,615 --> 00:19:05,515
Speaker 2:  say, and the robo taxii is only works

284
00:19:05,615 --> 00:19:08,475
Speaker 2:  on our cyber triangle or whatever he is gonna call it.

285
00:19:10,385 --> 00:19:13,445
Speaker 2:  Ah, I just don't buy it. I'm gonna make my prediction the opposite. Okay.

286
00:19:13,805 --> 00:19:17,645
Speaker 2:  I think, I think he might be slightly hand wavy about it.

287
00:19:17,755 --> 00:19:21,365
Speaker 2:  Like I I could imagine being like, this is the one, this is the future

288
00:19:21,915 --> 00:19:24,885
Speaker 2:  also random sub prediction. Do you think this is gonna be a thing that regular

289
00:19:24,885 --> 00:19:28,765
Speaker 2:  people can buy? No. No, no, no, no. Absolutely not.

290
00:19:28,835 --> 00:19:32,585
Speaker 2:  Okay. The idea that you would buy a two seater cyber taxi

291
00:19:33,135 --> 00:19:36,865
Speaker 2:  that you are like the landlord of, have you seen the cyber truck on the road?

292
00:19:36,865 --> 00:19:39,665
Speaker 2:  Dude? Like yeah. People will buy that. But that's a status symbol. This is

293
00:19:39,665 --> 00:19:40,545
Speaker 2:  a taxi cab,

294
00:19:42,325 --> 00:19:45,305
Speaker 2:  but it's your personal taxi cab that you let other people. Are you telling

295
00:19:45,485 --> 00:19:48,385
Speaker 2:  if I was like, Nila, do you wanna buy my yellow cab from me? You wouldn't

296
00:19:48,385 --> 00:19:48,745
Speaker 2:  buy it.

297
00:19:50,725 --> 00:19:53,905
Speaker 2:  I'm just saying the cyber truck is a status symbol. Sure. The

298
00:19:54,115 --> 00:19:57,705
Speaker 2:  ridiculous status symbol. Yeah. What status it confers. We can debate Sure.

299
00:19:57,705 --> 00:20:01,065
Speaker 2:  But Yeah. But this is literally meant to be a taxi. Yeah.

300
00:20:01,885 --> 00:20:05,305
Speaker 2:  So the idea is that you, a regular person would buy a taxi

301
00:20:05,805 --> 00:20:09,305
Speaker 2:  and let it loose in the streets of your suburb at night. Oh. I don't know.

302
00:20:09,305 --> 00:20:13,235
Speaker 2:  The, the frame of that is like, it's,

303
00:20:13,235 --> 00:20:17,155
Speaker 2:  it's your own personal robot driver. Right. And then when it's not working

304
00:20:17,155 --> 00:20:20,395
Speaker 2:  for you, it can go work for somebody else. That's, I don't see that pitch

305
00:20:20,515 --> 00:20:22,555
Speaker 2:  as being all that different from what they've been saying about Teslas for

306
00:20:22,555 --> 00:20:26,435
Speaker 2:  four years. But I I would be so shocked if he gets up and

307
00:20:26,435 --> 00:20:29,595
Speaker 2:  he's like, oh, I bait and switched all you clowns the last four years. You

308
00:20:29,595 --> 00:20:33,535
Speaker 2:  would be shocked if Elon Musk, would I be shocked if he did it? No. Okay.

309
00:20:33,535 --> 00:20:37,375
Speaker 2:  Would I be shocked if he said that? Yeah. And I think my

310
00:20:37,375 --> 00:20:40,775
Speaker 2:  guess would be there will be a lot of focus on this and some like

311
00:20:41,505 --> 00:20:45,055
Speaker 2:  vague gesture toward it's coming

312
00:20:46,075 --> 00:20:49,485
Speaker 2:  for all the Teslas exist today. Yeah. I, but I cannot imagine a world in

313
00:20:49,485 --> 00:20:53,475
Speaker 2:  which they just cut bait because people would go nuts. Maybe not cut

314
00:20:53,475 --> 00:20:57,115
Speaker 2:  bait, but they will hand wavy. But I I, my prediction

315
00:20:57,455 --> 00:21:01,435
Speaker 2:  is that whatever robax program they announced today will not work on the

316
00:21:01,435 --> 00:21:03,635
Speaker 2:  Teslas that exist on the road today. All right. I'm going with it. Will,

317
00:21:03,635 --> 00:21:05,995
Speaker 2:  this is good. We're now, we're we're directing. That's it. And you let us

318
00:21:05,995 --> 00:21:09,795
Speaker 2:  know, but maybe they won't address it directly, but it will be, I think it

319
00:21:09,795 --> 00:21:13,355
Speaker 2:  will just, it'll be one of those things like becomes obvious. Yeah.

320
00:21:13,655 --> 00:21:16,635
Speaker 2:  You know, like you're, you're just like brushing away. They're like, oh,

321
00:21:16,635 --> 00:21:19,475
Speaker 2:  this dinosaur sucks. Yeah. I think it's by the end of this event it'll be

322
00:21:19,475 --> 00:21:22,275
Speaker 2:  obvious. I am just really looking forward to this being like 90 minutes of

323
00:21:22,275 --> 00:21:25,555
Speaker 2:  optimist, robots driving around and my victory lap is going to be incredible.

324
00:21:26,115 --> 00:21:28,915
Speaker 2:  I will say that in the lead up to the event, there's been some reporting

325
00:21:31,065 --> 00:21:34,515
Speaker 2:  that basically all the Tesla executives are leaving.

326
00:21:35,175 --> 00:21:38,315
Speaker 2:  So four Tesla executives, this is reported in Business Insider. Four Tesla

327
00:21:38,315 --> 00:21:41,715
Speaker 2:  executives announced In the past week they were leaving or had already left.

328
00:21:42,055 --> 00:21:45,755
Speaker 2:  Oh boy. Some had been there for nearly a decade. How high executive are we

329
00:21:45,755 --> 00:21:49,315
Speaker 2:  talking company's chief information officers leaving after 12

330
00:21:49,525 --> 00:21:49,875
Speaker 2:  years.

331
00:21:52,785 --> 00:21:56,385
Speaker 2:  Director of public policy and business development announced on October one

332
00:21:56,385 --> 00:22:00,185
Speaker 2:  that he was leaving on Sunday. The global vehicle automation and

333
00:22:00,185 --> 00:22:03,185
Speaker 2:  safety policy lead also announced that he'd left Tesla.

334
00:22:05,925 --> 00:22:09,755
Speaker 2:  Those are people who would be quite important to the idea

335
00:22:09,855 --> 00:22:13,595
Speaker 2:  of like a global rollout of robo taxis. Yeah. You would think that public

336
00:22:13,595 --> 00:22:17,195
Speaker 2:  policy guy who's running self-driving and, you know, information systems

337
00:22:17,255 --> 00:22:20,475
Speaker 2:  and automation would, he would stuff matters. He would, this should be your

338
00:22:20,475 --> 00:22:23,595
Speaker 2:  time to shine. Interesting. And then the former model S and model X program

339
00:22:23,595 --> 00:22:27,275
Speaker 2:  manager also left, which is fine. Whatever the model.

340
00:22:27,745 --> 00:22:30,435
Speaker 2:  He's like, you know, we're not making another model XI un I understand what's

341
00:22:30,435 --> 00:22:33,675
Speaker 2:  happening here. We're we're just doing triangles now just doing cyber things.

342
00:22:35,585 --> 00:22:38,435
Speaker 2:  Yeah. These are all people who are leaving right before

343
00:22:39,845 --> 00:22:43,675
Speaker 2:  presumably a giant increase in the stock price because you're gonna

344
00:22:43,675 --> 00:22:46,795
Speaker 2:  unveil the robot taxi program, which is the valuation of the company. And

345
00:22:46,795 --> 00:22:49,915
Speaker 2:  I really mean this. I we don't often talk about stock prices on The Vergecast,

346
00:22:50,375 --> 00:22:54,315
Speaker 2:  but the entire story of Tesla right now is it's just another

347
00:22:54,415 --> 00:22:58,355
Speaker 2:  car maker that is struggling to move cars. They just had a pretty good

348
00:22:58,355 --> 00:23:01,435
Speaker 2:  quarter, but they are struggl they've been struggling to move cars. There's

349
00:23:01,435 --> 00:23:04,925
Speaker 2:  a lot of competition coming for them. Hyundai will just be like, it's a hundred

350
00:23:04,925 --> 00:23:08,605
Speaker 2:  dollars a month here, take an ionic five, get it outta my face. So there's

351
00:23:08,605 --> 00:23:12,325
Speaker 2:  just competition coming from all corners. And the stock price

352
00:23:13,345 --> 00:23:17,005
Speaker 2:  has just been based on the idea that it's a tech company

353
00:23:17,425 --> 00:23:21,085
Speaker 2:  and a tech company valuation is we're gonna run a robo

354
00:23:21,095 --> 00:23:25,045
Speaker 2:  taxii program. Right. There isn't another one. And this is in

355
00:23:25,045 --> 00:23:28,725
Speaker 2:  a, in a pretty real way, like the tech company launch of

356
00:23:28,975 --> 00:23:31,765
Speaker 2:  Tesla. Yeah. We should probably stop talking about this. 'cause now everything

357
00:23:31,765 --> 00:23:34,525
Speaker 2:  we've said is now woefully out of date already. I see. We should move on.

358
00:23:34,865 --> 00:23:37,445
Speaker 2:  But I'm just saying that it the That's the stakes. Those are the stakes.

359
00:23:37,445 --> 00:23:39,485
Speaker 2:  I totally, and we, we'll pick it up again next Friday. We'll have Andy come

360
00:23:39,485 --> 00:23:42,045
Speaker 2:  on. Yeah. And tell us what actually happened. But those are our predictions.

361
00:23:42,105 --> 00:23:44,645
Speaker 2:  Let us know. If, you got 'em right or wrong. Optimist. Robots in the trunk.

362
00:23:45,065 --> 00:23:48,925
Speaker 2:  All right. Now onto something that is extremely real. Like the

363
00:23:48,925 --> 00:23:52,685
Speaker 2:  most real. We already, Chris Welch already went out and bought one reel.

364
00:23:53,635 --> 00:23:57,035
Speaker 2:  Nintendo made it a hundred dollars alarm clock called Alarm O It's fantastic.

365
00:23:57,125 --> 00:24:00,635
Speaker 2:  First of all, all alarm clocks should have names from now on If. you make

366
00:24:00,635 --> 00:24:04,475
Speaker 2:  a, like Cassio made one this week that's like a blown up

367
00:24:04,745 --> 00:24:07,875
Speaker 2:  version of one of its watches. Looks very cool. Only available in Japan.

368
00:24:08,575 --> 00:24:11,715
Speaker 2:  Its name is like 16 Hexa decimal things.

369
00:24:12,535 --> 00:24:15,475
Speaker 2:  No, I'm done with that. If your product doesn't have a cool name anymore,

370
00:24:16,355 --> 00:24:19,215
Speaker 2:  get outta my face alarm mow or nothing. I

371
00:24:20,575 --> 00:24:24,215
Speaker 2:  I love this thing and I do not for one second, understand why it exists.

372
00:24:24,285 --> 00:24:27,375
Speaker 2:  Yeah, that's right. It's, it's just,

373
00:24:28,125 --> 00:24:31,895
Speaker 2:  it's just an alarm clock. Like it's not even well has some sleep tracking

374
00:24:31,895 --> 00:24:35,495
Speaker 2:  in it. You can download some detection, sleep tracking, which like an app

375
00:24:35,495 --> 00:24:37,935
Speaker 2:  on your phone that you can do. Like, that's not that it's fine, but it's

376
00:24:37,935 --> 00:24:41,615
Speaker 2:  not anything particularly exciting. But it, it's a, it's adorable as all

377
00:24:41,615 --> 00:24:45,415
Speaker 2:  hell. It's got a screen. It does the like Nintendo fonts. It'll like

378
00:24:45,415 --> 00:24:48,575
Speaker 2:  yell at you in very cute ways when you need to get outta bed. It has some

379
00:24:48,575 --> 00:24:51,415
Speaker 2:  fun sounds that'll make, like, this thing is very charming and I want one

380
00:24:51,415 --> 00:24:55,015
Speaker 2:  and I I will get one I'm sure. But like, what,

381
00:24:55,205 --> 00:24:58,535
Speaker 2:  what was it like a week ago that there was a, it came through the FCC that

382
00:24:58,535 --> 00:25:01,655
Speaker 2:  Nintendo Nintendo was doing some new hardware device and everybody got all

383
00:25:01,655 --> 00:25:04,255
Speaker 2:  excited and they were like, is this the next switch? What's Nintendo doing?

384
00:25:04,255 --> 00:25:05,335
Speaker 2:  It could be anything. and it,

385
00:25:07,535 --> 00:25:11,455
Speaker 2:  I will say the the, there's a thing on the top that

386
00:25:11,455 --> 00:25:15,295
Speaker 2:  looks like a bell and it's a dial that lights up so revolutionary and it

387
00:25:15,295 --> 00:25:15,575
Speaker 2:  device,

388
00:25:17,195 --> 00:25:20,815
Speaker 2:  the fact that that is not the snooze button is a huge miss. Wait, is it not?

389
00:25:20,855 --> 00:25:23,375
Speaker 2:  I literally assumes news button. It's SNOO button. What is it? The SNOO is

390
00:25:23,375 --> 00:25:27,255
Speaker 2:  automatic to you. It ha because it has motion detection in

391
00:25:27,255 --> 00:25:31,135
Speaker 2:  it. You can snooze it by just like waving your hand at it. Oh, I do

392
00:25:31,135 --> 00:25:33,455
Speaker 2:  like that. And Then it when you get out of bed, it stops the alarm clock.

393
00:25:33,455 --> 00:25:36,255
Speaker 2:  So like the motion you do when you're trying to like find your phone to shut

394
00:25:36,255 --> 00:25:39,495
Speaker 2:  it up. Yeah. That will shut it up. So again, I like that So I have plugged

395
00:25:39,525 --> 00:25:42,055
Speaker 2:  this app on the show so many times. The alarm clock I use,

396
00:25:43,475 --> 00:25:46,765
Speaker 2:  it's called Sleep cycle and the snooze button is a motion detector on the

397
00:25:46,765 --> 00:25:50,005
Speaker 2:  phone. So you can just smack the table and make the phone bounce and it'll

398
00:25:50,045 --> 00:25:53,525
Speaker 2:  snooze. That's cool. Oh, or If, you are particularly lazy. You can

399
00:25:53,835 --> 00:25:57,805
Speaker 2:  grab the USB BBC cord that is charging your iPhone and just give that

400
00:25:57,845 --> 00:26:01,365
Speaker 2:  a wave and just go B boop that snooze it. All right. And this all works.

401
00:26:02,425 --> 00:26:06,285
Speaker 2:  But the idea that the alarm o that the dial on top of the LAO is not a

402
00:26:06,285 --> 00:26:09,885
Speaker 2:  classic bash it snooze button, but is instead a dial that lights up.

403
00:26:10,865 --> 00:26:14,745
Speaker 2:  I think this product is doomed because of it. That's my hot What it,

404
00:26:14,865 --> 00:26:18,665
Speaker 2:  what it should be is like one of the, the money bricks from a

405
00:26:18,665 --> 00:26:20,945
Speaker 2:  Mario game. That's And you should, that's good. You should be able to hit

406
00:26:20,945 --> 00:26:23,905
Speaker 2:  it. You, you bounce on it and stuff comes out. Yeah. That's, that's what

407
00:26:23,905 --> 00:26:26,625
Speaker 2:  I want from this. Why the only rea the only reason I really wanted to talk

408
00:26:26,625 --> 00:26:30,425
Speaker 2:  about this is because I came up as a gadget

409
00:26:30,425 --> 00:26:33,385
Speaker 2:  writer in the time of a device called the Chumby.

410
00:26:34,435 --> 00:26:38,095
Speaker 2:  Oh. Some of our listen don't do that to Alarm o some of our people will remember

411
00:26:38,095 --> 00:26:42,055
Speaker 2:  the Chumby. This is just a weird closed source proprietary chumby. I'm telling

412
00:26:42,055 --> 00:26:44,410
Speaker 2:  you right now. That's what it, what it is. It's alarm clock with a screen

413
00:26:44,745 --> 00:26:48,125
Speaker 2:  has a weird little app story download stuff that you can put on it.

414
00:26:48,545 --> 00:26:52,525
Speaker 2:  It has high-minded ideas about motion controls. The Chumby was a alarm clock

415
00:26:52,525 --> 00:26:56,245
Speaker 2:  that ran Linux. It was endless story as successful

416
00:26:56,345 --> 00:26:59,645
Speaker 2:  as you could imagine that sense to be. Some people still have Humes, they're

417
00:26:59,645 --> 00:27:03,245
Speaker 2:  still running them out in the world. But the idea that you would have a connected

418
00:27:03,265 --> 00:27:06,445
Speaker 2:  device in your kitchen or by your bedside in 2006

419
00:27:07,045 --> 00:27:10,915
Speaker 2:  revolutionary. Yeah. And that was, I was like, I grew up being

420
00:27:10,915 --> 00:27:14,835
Speaker 2:  like, I have to write about this every day. Chumby also were in

421
00:27:14,875 --> 00:27:18,435
Speaker 2:  a certain way very charming in a way that then like died with the

422
00:27:18,725 --> 00:27:22,395
Speaker 2:  Alexa generation of Yeah. You know, cans of tennis

423
00:27:22,445 --> 00:27:26,315
Speaker 2:  balls. So like kudos to bring it back. One other thing

424
00:27:26,315 --> 00:27:29,075
Speaker 2:  that this has in common with Chumby is that the screen is way worse than

425
00:27:29,075 --> 00:27:32,875
Speaker 2:  you think. Yep. and it looks like it, it, it's a round little

426
00:27:32,875 --> 00:27:36,355
Speaker 2:  face, but it's a square screen inside of said round little face. And

427
00:27:37,305 --> 00:27:41,235
Speaker 2:  it's just a lie. Like the screen, the screen's a lie and that's fine.

428
00:27:41,415 --> 00:27:43,955
Speaker 2:  And I'm okay with it. It's $99.

429
00:27:45,305 --> 00:27:48,705
Speaker 2:  I still don't understand why it exists. Why does this exist? Like if you're,

430
00:27:48,725 --> 00:27:52,565
Speaker 2:  if you're running Nintendo, why do you make

431
00:27:52,565 --> 00:27:56,195
Speaker 2:  this Just 'cause you can and you're a Nintendo. Yeah. Okay.

432
00:27:56,555 --> 00:28:00,455
Speaker 2:  I think fundamentally Nintendo does cute stuff and they're like, we can

433
00:28:00,455 --> 00:28:04,365
Speaker 2:  put Mario by your bedside and people will pay us $100

434
00:28:04,465 --> 00:28:08,085
Speaker 2:  for that service. I mean that's Yeah. When you put it like that. But

435
00:28:08,085 --> 00:28:12,045
Speaker 2:  Nintendo is so weird because it's like if If, you take

436
00:28:12,105 --> 00:28:16,085
Speaker 2:  the cynical, not even cynical, but the sort of ruthless read of that that

437
00:28:16,085 --> 00:28:19,965
Speaker 2:  is like, we want to be everywhere that you are and be like

438
00:28:20,005 --> 00:28:21,925
Speaker 2:  a lifestyle business. Ambient Nintendo.

439
00:28:23,715 --> 00:28:27,165
Speaker 2:  There's a million things they would've done by now, right? Like yeah.

440
00:28:27,325 --> 00:28:31,205
Speaker 2:  Nintendo could have made smart everything for your whole house for the

441
00:28:31,205 --> 00:28:33,805
Speaker 2:  last decade and people would've eaten. No, that would require technological

442
00:28:33,805 --> 00:28:37,325
Speaker 2:  innovation. This is much more like we have a box of motion sensors

443
00:28:38,105 --> 00:28:42,005
Speaker 2:  and we're gonna put them in alarm clock. Like what is it? What

444
00:28:42,005 --> 00:28:45,925
Speaker 2:  can we do? Switch outcast with a 12-year-old arm chip. And it's like,

445
00:28:45,925 --> 00:28:49,845
Speaker 2:  well we can make a switch alarm clock. That's about the only other thing

446
00:28:49,845 --> 00:28:53,605
Speaker 2:  you can do. They just took apart a bunch of DSS and then put them back together

447
00:28:53,675 --> 00:28:57,325
Speaker 2:  into alarm clocks. As Kranz was saying on the show last week, the switch

448
00:28:57,385 --> 00:29:01,285
Speaker 2:  two, it feels like the switch emulators can already run switch

449
00:29:01,305 --> 00:29:05,005
Speaker 2:  two games. Right. Because Nintendo's cracking down on switch emulators. It

450
00:29:05,005 --> 00:29:07,085
Speaker 2:  does not feel like Nintendo wants to be the bleeding edge of the curve. So

451
00:29:07,085 --> 00:29:09,885
Speaker 2:  what can you do with a bunch of old hardware? It's an alarm clock. Fair enough.

452
00:29:09,955 --> 00:29:13,725
Speaker 2:  They just, they found a bunch of chums. Right? Here you go.

453
00:29:13,785 --> 00:29:17,485
Speaker 2:  Here's some chumby. Yeah. I do think Nintendo is more ruthless

454
00:29:17,485 --> 00:29:21,245
Speaker 2:  about selling its IP in various, like you can buy Mario anything.

455
00:29:21,435 --> 00:29:25,325
Speaker 2:  Yeah. Nintendo collects its money. Yeah. If. you wanna do total doo and gloom.

456
00:29:25,625 --> 00:29:28,725
Speaker 2:  One thing this might signal is they don't have a switch to for the holidays

457
00:29:29,305 --> 00:29:33,045
Speaker 2:  so they have an alarm clock instead. Oh. Because you gotta sell

458
00:29:33,045 --> 00:29:36,955
Speaker 2:  something. It's a pretty good little stocking stuffer. Yeah.

459
00:29:37,055 --> 00:29:40,795
Speaker 2:  As these things go, it has Mario in the box. That actually makes

460
00:29:40,975 --> 00:29:44,705
Speaker 2:  quite a lot of sense to me. I mean, I I hope they have a switch too.

461
00:29:44,865 --> 00:29:47,265
Speaker 2:  I hope so too. I'm ready to buy one. But If, you wanna If you wanna play

462
00:29:47,325 --> 00:29:49,905
Speaker 2:  be the most negative. That's what you would say. But even like there, there

463
00:29:49,905 --> 00:29:53,145
Speaker 2:  are a lot of people with switches who don't wanna upgrade and like the, the

464
00:29:53,145 --> 00:29:56,585
Speaker 2:  timing Sure. Suggests that they intend this as like a big holiday victory.

465
00:29:56,775 --> 00:30:00,305
Speaker 2:  Yeah. And it's mar big ass Mario on the bag that

466
00:30:00,435 --> 00:30:04,345
Speaker 2:  Chris Welch bought. Like I could see it. Yeah. And again, I find

467
00:30:04,345 --> 00:30:06,985
Speaker 2:  this thing so charming. I just think Nintendo is like the least

468
00:30:08,055 --> 00:30:12,025
Speaker 2:  like every other company, company that we cover in ways that are mostly

469
00:30:12,025 --> 00:30:15,505
Speaker 2:  really fun and occasionally just completely inscrutable. And this is one

470
00:30:15,505 --> 00:30:18,305
Speaker 2:  of those moments for me. Yeah. What are you doing? But I'm, I wish more companies

471
00:30:18,305 --> 00:30:22,145
Speaker 2:  were weird. Oh, for sure. In this specific way. We got like eight stories

472
00:30:22,145 --> 00:30:25,265
Speaker 2:  about alarm OI would love to cover things like, we're gonna have a full review

473
00:30:25,265 --> 00:30:29,185
Speaker 2:  of this alarm clock. Absolutely. It's gonna be amazing. Some Apple rumors

474
00:30:29,185 --> 00:30:32,825
Speaker 2:  we should talk about. Oh yeah. That kind of lead into, I wanna talk about

475
00:30:32,825 --> 00:30:36,065
Speaker 2:  the Met Raybans for one second, but the Apple rumors are that sometime

476
00:30:36,735 --> 00:30:40,025
Speaker 2:  this month or early November, I'm guessing it'll be early November,

477
00:30:40,395 --> 00:30:44,065
Speaker 2:  we'll get New Mac minis that are in the form factor of like an Apple TV or

478
00:30:44,065 --> 00:30:47,945
Speaker 2:  on that size and a new iPad mini for all the pilots out there who listen

479
00:30:47,945 --> 00:30:50,865
Speaker 2:  to the show and email. David, please stop.

480
00:30:52,135 --> 00:30:55,785
Speaker 2:  I've started getting creep shot photos from people who take

481
00:30:55,825 --> 00:30:59,785
Speaker 2:  pictures of the iPads that they see their pilots having and send it

482
00:30:59,785 --> 00:31:02,385
Speaker 2:  to me. That's good. So I just have, that's how you get arrested by the air

483
00:31:02,385 --> 00:31:05,945
Speaker 2:  marshal. Yeah. Civil, whole library of pilots now. It's not good.

484
00:31:06,385 --> 00:31:10,145
Speaker 2:  I don't want that. But yeah. The, the rumor or from

485
00:31:10,175 --> 00:31:13,305
Speaker 2:  Mark Gerberman, the, the reporting that he has had is that I think they're

486
00:31:13,545 --> 00:31:16,505
Speaker 2:  launching on November 1st. At least the Mac Mini will be.

487
00:31:17,485 --> 00:31:20,705
Speaker 2:  I'm very excited about this Mac Mini. I have an M1 Mac mini that I love very

488
00:31:20,705 --> 00:31:24,065
Speaker 2:  much and I'm very excited to upgrade to an M four Mac mini.

489
00:31:24,825 --> 00:31:28,465
Speaker 2:  I don't understand the compulsion to make the box smaller.

490
00:31:28,655 --> 00:31:32,145
Speaker 2:  Like, yeah. No one is mad about the size of their Mac. Mini Liam

491
00:31:32,685 --> 00:31:36,185
Speaker 2:  in the control room. Liam just started at me waving. Liam is the only person

492
00:31:36,185 --> 00:31:38,625
Speaker 2:  that's more activity in the control room than we seen in, was angry about

493
00:31:38,625 --> 00:31:42,425
Speaker 2:  the size of his Mac Mini. That was a lot. I take it all back.

494
00:31:42,745 --> 00:31:46,385
Speaker 2:  Everyone is so upset about the size of their Mac mini. It's,

495
00:31:46,495 --> 00:31:48,905
Speaker 2:  it's way too big. Make it smaller or else

496
00:31:50,445 --> 00:31:53,945
Speaker 1:  To be clear, I was agreeing with you. Oh, okay. I I'm a

497
00:31:54,065 --> 00:31:57,985
Speaker 1:  longtime lover of the Mac Mini. I've had many over the years as Plex servers

498
00:31:58,445 --> 00:32:01,825
Speaker 1:  and I just don't understand why it needs to be smaller. Okay. There you go.

499
00:32:01,825 --> 00:32:05,625
Speaker 1:  There's absolutely no reason for it. Sure. Let's, let's make it less versatile.

500
00:32:05,755 --> 00:32:09,145
Speaker 1:  Let's take away ports that people use for weird.

501
00:32:09,505 --> 00:32:13,185
Speaker 2:  You're gonna get one USBC port and the highest performance M four processor

502
00:32:13,185 --> 00:32:16,465
Speaker 2:  available and you're gonna like it lean and I'm gonna plug in my like

503
00:32:16,465 --> 00:32:20,345
Speaker 2:  8-year-old USBC hub that threatens to catch on fire every time I use it.

504
00:32:20,885 --> 00:32:24,385
Speaker 2:  And I'm gonna compute the hell out of it. It's gonna be great. I think this

505
00:32:24,385 --> 00:32:28,305
Speaker 2:  is gonna be great. I think the Mac mini is like a sneaky hit for

506
00:32:28,345 --> 00:32:31,875
Speaker 2:  Apple in a way that it never really talks about but like, just sort of

507
00:32:31,945 --> 00:32:35,835
Speaker 2:  anecdotally. Yeah. People love the Mack Mini in a way that the iPad

508
00:32:35,835 --> 00:32:39,605
Speaker 2:  mini has. Its like devoted really loud followers but

509
00:32:39,625 --> 00:32:43,365
Speaker 2:  not that many of them. I think the M mini is like just sort of around.

510
00:32:43,515 --> 00:32:46,965
Speaker 2:  Yeah, it's the, it's everybody who needs I You bought your M1 because I,

511
00:32:47,045 --> 00:32:50,805
Speaker 2:  I basically was like shut up and buy an M1 M mini You literally I was, I

512
00:32:50,805 --> 00:32:54,765
Speaker 2:  was getting off a plane in DC from somewhere and you

513
00:32:54,765 --> 00:32:58,645
Speaker 2:  sent me a link because it was on sale on Amazon and I had bought it before

514
00:32:58,685 --> 00:33:02,485
Speaker 2:  I got off the plane. I was literally, I'm sitting there on the tarmac and

515
00:33:02,485 --> 00:33:05,645
Speaker 2:  you're like, the Mac mini's on sale. Buy this shut up. I bought it. I was

516
00:33:05,645 --> 00:33:08,765
Speaker 2:  like, stop complaining about your computer. Buy this Mac mini and it worked.

517
00:33:09,945 --> 00:33:13,365
Speaker 2:  I'm excited for it. I, you know, we run the decoder studio in a Mac mini.

518
00:33:13,755 --> 00:33:17,685
Speaker 2:  What is wrong with your M1 that you want an M four? Nothing It's,

519
00:33:17,685 --> 00:33:21,605
Speaker 2:  it's fine. Like, okay. Just checking. Really what it is is I have set

520
00:33:21,605 --> 00:33:25,405
Speaker 2:  up a beautiful thing where I get to get new things and then

521
00:33:25,435 --> 00:33:29,365
Speaker 2:  gift all of my gently used things to family members. And so really

522
00:33:29,365 --> 00:33:33,085
Speaker 2:  what it is is my 2011 iMac.

523
00:33:34,115 --> 00:33:38,055
Speaker 2:  No, 2013 maybe somewhere in there. iMac is finally starting to

524
00:33:38,055 --> 00:33:41,895
Speaker 2:  die on my sister So. I have to start the whole process again by buying

525
00:33:41,895 --> 00:33:45,855
Speaker 2:  an M four Mac mini and and passing things down such that she gets a workable

526
00:33:46,015 --> 00:33:49,055
Speaker 2:  computer. I'm doing this for them. Yeah, I see what you're doing. I'm a very

527
00:33:49,055 --> 00:33:52,735
Speaker 2:  good Are you gonna do their project where you turn the iMac into a

528
00:33:52,975 --> 00:33:56,835
Speaker 2:  standalone display? Oh that's actually a good idea. So I have

529
00:33:56,835 --> 00:33:59,915
Speaker 2:  looked into this. It's a 27 inch screen. I really should. I have a bunch

530
00:33:59,915 --> 00:34:03,515
Speaker 2:  of parts sitting around my house. You have to figure out exactly what model

531
00:34:03,535 --> 00:34:07,195
Speaker 2:  of display is in the iMac. Okay. And then you can literally just buy

532
00:34:07,195 --> 00:34:10,555
Speaker 2:  adapters that you can use it as a display. You have to take it all apart.

533
00:34:10,725 --> 00:34:13,555
Speaker 2:  Right. But I'm like excited to apart It's fine if I break it, it's broken.

534
00:34:13,625 --> 00:34:17,515
Speaker 2:  Like whatever. Yeah. Oh no. This 2013 iMac is broken. So I have all the

535
00:34:17,515 --> 00:34:21,435
Speaker 2:  parts of my house. I just have not done the thing. That's where

536
00:34:21,435 --> 00:34:24,155
Speaker 2:  I like take a heat gun and suction cups to an iMac to take it all apart.

537
00:34:25,175 --> 00:34:28,915
Speaker 2:  We should maybe like bring that into the studio and both do it. Both. Both

538
00:34:28,915 --> 00:34:31,675
Speaker 2:  of Neli and David both break their iMac today.

539
00:34:32,975 --> 00:34:36,955
Speaker 2:  But yeah, my 2015 iMac is just sitting waiting for this to happen to

540
00:34:36,955 --> 00:34:39,875
Speaker 2:  it. Yeah. One day it's pretty good. But yeah. But then there's also,

541
00:34:40,645 --> 00:34:44,435
Speaker 2:  we're supposed to get an M four MacBook Pro I think in both sizes

542
00:34:44,915 --> 00:34:47,955
Speaker 2:  supposedly and weirdly it's already leaked. People think, oh, So I like Russian

543
00:34:48,035 --> 00:34:51,915
Speaker 2:  YouTuber has a 14 inch M four, oh I missed this. But

544
00:34:51,915 --> 00:34:55,155
Speaker 2:  then there's a controversy 'cause the box has the old,

545
00:34:56,135 --> 00:34:59,515
Speaker 2:  the old wallpaper on it. Okay. So people think the whole thing is fake. Huh.

546
00:35:00,625 --> 00:35:03,365
Speaker 2:  And people are like, this is the biggest leaks in HUN for And I'm like, I

547
00:35:03,365 --> 00:35:07,325
Speaker 2:  don't even if it's real, like it's not. No, I feel like it

548
00:35:07,325 --> 00:35:11,125
Speaker 2:  also tells you a lot about what to expect that no one can really tell

549
00:35:11,955 --> 00:35:15,165
Speaker 2:  like fast computer now faster.

550
00:35:15,755 --> 00:35:19,645
Speaker 2:  Yeah. Here you go. I mean I'm kind of ready. There's no reason to upgrade

551
00:35:19,645 --> 00:35:23,485
Speaker 2:  this. Which one is that? This is an M1 PRO 16. Okay. I have an

552
00:35:23,565 --> 00:35:27,205
Speaker 2:  M1 error sitting here that I'm like Yeah, that's a 16 inch MacBook Pro with

553
00:35:27,365 --> 00:35:31,325
Speaker 2:  an M1 Pro in it. Okay. Not the M1 max. Oh. So that thing is still, but it's

554
00:35:31,325 --> 00:35:34,525
Speaker 2:  still, that's a pretty beefy computer. It's It's killing it. Yeah. So this

555
00:35:34,525 --> 00:35:37,925
Speaker 2:  is the best laptop I've ever had. I'm like, what if I got rid of you? What

556
00:35:37,925 --> 00:35:41,445
Speaker 2:  if I got an M four for no reason? For me it's colors. Every time I look at

557
00:35:41,445 --> 00:35:45,085
Speaker 2:  the really like dark MacBooks, I'm like, ah, I want one

558
00:35:45,085 --> 00:35:48,965
Speaker 2:  silver stupid. Who wants silver? I want more fingerprints in my computer.

559
00:35:48,965 --> 00:35:51,845
Speaker 2:  Yeah, exactly. So we'll see. That is the rumor for the next couple weeks.

560
00:35:51,845 --> 00:35:55,485
Speaker 2:  It's all coming out now. It does feel like we are ready for an Apple upgrade

561
00:35:55,485 --> 00:35:59,045
Speaker 2:  cycle. So keep an eye on that. Yeah. Lastly, there's some other little

562
00:35:59,135 --> 00:36:03,045
Speaker 2:  Apple news that I want to try to connect to Meta

563
00:36:03,145 --> 00:36:06,365
Speaker 2:  and what it's doing. Okay. So it was announced this week Dan Riccio who used

564
00:36:06,365 --> 00:36:09,605
Speaker 2:  to be SVP of all hardware engineering at Apple and is now in charge of vision.

565
00:36:09,605 --> 00:36:12,885
Speaker 2:  Bro, he's retiring and it's like retirement season for a lot of Apple executives.

566
00:36:12,885 --> 00:36:16,365
Speaker 2:  They've all been there a long time. Being at Apple for 20 years is like,

567
00:36:16,365 --> 00:36:19,725
Speaker 2:  oh you're just a baby. Truly. Like there are people stick around. Yeah. So

568
00:36:19,725 --> 00:36:22,925
Speaker 2:  it makes sense that he is retiring. The Vision Pro is announced. It is released,

569
00:36:22,925 --> 00:36:26,485
Speaker 2:  it's out in the world. And he took over

570
00:36:26,885 --> 00:36:30,425
Speaker 2:  engineering that project in 2021. So the thing is out in the world, it's

571
00:36:30,425 --> 00:36:33,865
Speaker 2:  gonna go do its thing. He's been there a long time. Goodbye everybody. Yeah.

572
00:36:33,865 --> 00:36:37,705
Speaker 2:  Presumably numbers two, three and four are deep in the works. Like Yeah.

573
00:36:37,765 --> 00:36:41,065
Speaker 2:  And he had been at Apple for 26 years. Yeah. He ran iPad. There are a lot

574
00:36:41,065 --> 00:36:44,825
Speaker 2:  of ways that as not problematic, but what I would say

575
00:36:45,045 --> 00:36:48,985
Speaker 2:  is the Vision Pro itself in a weird spot.

576
00:36:49,965 --> 00:36:53,945
Speaker 2:  The Apple just announced a new movie for it submerged like

577
00:36:54,165 --> 00:36:57,425
Speaker 2:  its first immersive movie. Yeah. At the same time it announced that Apple

578
00:36:57,525 --> 00:37:00,865
Speaker 2:  TV Plus will not be available on Amazon channels, which is a pretty huge

579
00:37:00,865 --> 00:37:04,625
Speaker 2:  indictment at Apple TV plus. Yep. As a thing that is selling any Apple products.

580
00:37:05,185 --> 00:37:08,545
Speaker 2:  Do you remember all the controversy a while back? I think it was Lucas shot

581
00:37:08,545 --> 00:37:12,425
Speaker 2:  Bloomberg, just like Offhandedly tweeted something about like nobody

582
00:37:12,425 --> 00:37:16,225
Speaker 2:  watches Apple TV plus and people just like ran him down over

583
00:37:16,225 --> 00:37:19,945
Speaker 2:  it. I would say every available piece of evidence suggests

584
00:37:20,255 --> 00:37:23,225
Speaker 2:  that Lucas Sha was right. And yeah, no one really watches Apple TV plus,

585
00:37:23,275 --> 00:37:25,945
Speaker 2:  especially now that they're gonna sell it on Amazon to get more reach. Yeah.

586
00:37:26,925 --> 00:37:30,905
Speaker 2:  But so all that, there's just a swirl of stuff at Apple and

587
00:37:31,005 --> 00:37:34,625
Speaker 2:  one of the things in the swirl I think is a Vision Pro and this big decision

588
00:37:34,655 --> 00:37:37,785
Speaker 2:  over whether Apple wants to keep selling what is essentially VR headsets.

589
00:37:38,155 --> 00:37:42,145
Speaker 2:  Especially now that Meta not Orion. Orion is

590
00:37:42,145 --> 00:37:45,985
Speaker 2:  vaporware no matter what Alex seats says, it's fully vaporware. Yes. It is

591
00:37:46,065 --> 00:37:48,545
Speaker 2:  a thing that doesn't exist no matter how proud of it meta appears to be,

592
00:37:48,925 --> 00:37:52,265
Speaker 2:  but it's like here's some vision of the future that is in this headset. Sure.

593
00:37:52,485 --> 00:37:56,465
Speaker 2:  Meta's pushing in front. And much more importantly, the Ray

594
00:37:56,515 --> 00:38:00,465
Speaker 2:  bands appear to be a success. Hard to tell if they're

595
00:38:00,465 --> 00:38:03,905
Speaker 2:  really a success, but that form factor is much more successful than here's

596
00:38:03,905 --> 00:38:07,665
Speaker 2:  a giant headset that has an external battery pack. And so it just feels

597
00:38:07,665 --> 00:38:11,105
Speaker 2:  like we're gonna see some reset on Vision Pro. That's just very much, and

598
00:38:11,305 --> 00:38:14,465
Speaker 2:  Gerin has reported this, apple has to make some decisions. It hasn't figured

599
00:38:14,465 --> 00:38:17,665
Speaker 2:  out what it wants to do. And now the guy in charge of it is leaving. Yeah.

600
00:38:17,785 --> 00:38:21,305
Speaker 2:  I, I forget who it was that I was reading a while back, but basically what

601
00:38:21,305 --> 00:38:24,745
Speaker 2:  they said was, I can't remember the last time

602
00:38:25,395 --> 00:38:29,305
Speaker 2:  Apple was ahead, but completely on the wrong

603
00:38:29,305 --> 00:38:32,425
Speaker 2:  path. And I've been thinking about that ever since. Like it it is, it's still

604
00:38:32,525 --> 00:38:35,420
Speaker 2:  so true that the Vision Pro was like an incredible technical achievement

605
00:38:35,825 --> 00:38:39,725
Speaker 2:  and increasingly it seems like who cares that

606
00:38:39,725 --> 00:38:43,005
Speaker 2:  like maybe the technical achievement was the wrong thing to do and that,

607
00:38:43,005 --> 00:38:46,845
Speaker 2:  like, I keep going back to the, the early days of the iPhone where it was

608
00:38:46,845 --> 00:38:50,725
Speaker 2:  like, do we do a, a more impressive iPod with the click wheel and

609
00:38:50,725 --> 00:38:54,045
Speaker 2:  everything? Or do we like build this brand new

610
00:38:54,795 --> 00:38:58,365
Speaker 2:  epic thing that no one has ever tried before? And they picked that path and

611
00:38:58,365 --> 00:39:01,645
Speaker 2:  it worked super well and I think it taught Apple that the only swings you

612
00:39:01,645 --> 00:39:04,765
Speaker 2:  should make are the biggest ones possible. and it really seems like the lesson

613
00:39:04,785 --> 00:39:07,805
Speaker 2:  of this generation of hardware is like build the iPod with the click wheel.

614
00:39:07,915 --> 00:39:11,805
Speaker 2:  Yeah. Like that bring people along with you

615
00:39:11,825 --> 00:39:15,485
Speaker 2:  in a way that is get people used to wearing computer on their face all the

616
00:39:15,485 --> 00:39:18,085
Speaker 2:  time. Right. And the other thing is like when the iPhone came out, people

617
00:39:18,085 --> 00:39:20,885
Speaker 2:  had been using cell phones for a long time. Yeah. Right. Like we don't have

618
00:39:20,885 --> 00:39:24,485
Speaker 2:  that history yet. And so you have to do the first cell phones before you

619
00:39:24,485 --> 00:39:27,325
Speaker 2:  can do the iPhone and Apple just tried to skip all the way there. And so

620
00:39:27,325 --> 00:39:30,725
Speaker 2:  it feels like If, you wanted to If, you were to tell me

621
00:39:31,725 --> 00:39:34,965
Speaker 2:  somebody is two generations away from getting it right. It it seems like

622
00:39:34,965 --> 00:39:38,245
Speaker 2:  it's pretty clearly the meta ray bands, right? Like

623
00:39:38,745 --> 00:39:42,565
Speaker 2:  in terms of like mainstream success two generations from now,

624
00:39:42,635 --> 00:39:45,845
Speaker 2:  that one feels like the easy betting favorite. Okay. Except

625
00:39:47,375 --> 00:39:51,175
Speaker 2:  I bought the clear ones and I'm sending them back. No, everybody

626
00:39:51,175 --> 00:39:55,095
Speaker 2:  loves them. Sean Holster's sending his back too. They're, they're

627
00:39:55,095 --> 00:39:57,735
Speaker 2:  fine. They're fine. They're a fine product and I know people who love them.

628
00:39:57,735 --> 00:40:00,535
Speaker 2:  Janist Stern loves hers. Do they look cooler in pictures than they do in

629
00:40:00,535 --> 00:40:03,055
Speaker 2:  reality? They super look cooler in pictures than they do in reality because

630
00:40:03,055 --> 00:40:06,375
Speaker 2:  they look so cool in pictures. They like

631
00:40:06,495 --> 00:40:10,415
Speaker 2:  Wayfairs are very classic shape. And I think they're

632
00:40:10,415 --> 00:40:14,295
Speaker 2:  meant to be classic and black and then you make them clear and they're, at

633
00:40:14,295 --> 00:40:17,935
Speaker 2:  least in my face, they're, they're too curvy. Mm.

634
00:40:18,325 --> 00:40:22,175
Speaker 2:  Like the, when they are, when I have worn a lot of wafers in my life and

635
00:40:22,175 --> 00:40:24,895
Speaker 2:  when they're expressed in black, they're like, they're this very cool shape.

636
00:40:25,235 --> 00:40:28,775
Speaker 2:  And then you make them clear and it's just like, huh, I'm wearing C eye glasses.

637
00:40:28,835 --> 00:40:31,775
Speaker 2:  That's one thing. Did you see all the Yeah, all the movements. I guess that

638
00:40:31,775 --> 00:40:34,535
Speaker 2:  makes sense. So it's, there's one thing. Yeah, maybe clear, maybe I should

639
00:40:34,535 --> 00:40:38,495
Speaker 2:  buy these again in black. But then they only ship the

640
00:40:38,495 --> 00:40:41,775
Speaker 2:  clear ones with transition lenses because they want you to wear them all

641
00:40:41,775 --> 00:40:44,295
Speaker 2:  the time. But they supposed to inside supposed to good transitions. Now they

642
00:40:44,295 --> 00:40:47,135
Speaker 2:  don't get dark enough outside and they also only turn blue, which is weird.

643
00:40:48,115 --> 00:40:50,335
Speaker 2:  And then you're like, why am I wearing these glasses all the time? And then

644
00:40:50,335 --> 00:40:53,775
Speaker 2:  as I have said many times, I have a huge head and the,

645
00:40:53,925 --> 00:40:57,495
Speaker 2:  they're just like not, they're just like uncomfortable on my face. And I

646
00:40:57,495 --> 00:40:59,175
Speaker 2:  think even though I got the bigger ones, it would still be uncomfortable

647
00:40:59,175 --> 00:41:01,255
Speaker 2:  on my face. And this was Sean's complaint. He's like, I've tried them in

648
00:41:01,255 --> 00:41:05,175
Speaker 2:  both sizes and the big ones are loose and still uncomfortable.

649
00:41:05,715 --> 00:41:09,455
Speaker 2:  And the other ones are, and this is the other which you tied and this is

650
00:41:09,455 --> 00:41:13,335
Speaker 2:  the fundamental problem with all of this stuff. Yeah. Is our bodies are not

651
00:41:13,395 --> 00:41:16,735
Speaker 2:  really designed to mount hardware on. And

652
00:41:16,775 --> 00:41:20,735
Speaker 2:  particularly face is a very challenging Yeah. Mounting environment.

653
00:41:21,555 --> 00:41:24,975
Speaker 2:  And so I'm sending back and I think I'm just coming back to my graph,

654
00:41:26,035 --> 00:41:29,775
Speaker 2:  my matrix of wearable bullshit, that face penalty is just huge. Yeah.

655
00:41:29,875 --> 00:41:32,855
Speaker 2:  No matter how useful it's, oh also the camera's not so whatever. I've, I've

656
00:41:32,855 --> 00:41:35,965
Speaker 2:  got a camera in my pocket all the time and like kudos to meta for having

657
00:41:36,665 --> 00:41:40,005
Speaker 2:  better options. But it is very true that you're still not solving it with

658
00:41:40,005 --> 00:41:43,885
Speaker 2:  two styles. Yeah. And then the last piece, which I think Alex

659
00:41:43,885 --> 00:41:47,325
Speaker 2:  brought up when he was on the show last time, it is also true

660
00:41:47,835 --> 00:41:51,525
Speaker 2:  that iOS and Apple keep these glasses

661
00:41:52,115 --> 00:41:55,285
Speaker 2:  from being actually integrated with your phone. Oh, a hundred percent. Like

662
00:41:55,345 --> 00:41:58,765
Speaker 2:  the weird Bluetooth to wifi pairing switch you have to do

663
00:41:59,545 --> 00:42:03,445
Speaker 2:  on Android, it just syns with your phone because the operating

664
00:42:03,445 --> 00:42:06,085
Speaker 2:  system allows it to apple's. Like you're, you will never get close to this.

665
00:42:06,865 --> 00:42:10,765
Speaker 2:  You have to switch your phone to the glasses wifi network to it's garbage.

666
00:42:11,265 --> 00:42:14,365
Speaker 2:  I'm actually super annoyed at Heath because he brought

667
00:46:29,965 --> 00:46:32,565
Speaker 2:  I was waiting patiently. I talk about Google. We'll be right back with her.

668
00:46:36,855 --> 00:46:40,805
Speaker 2:  We're back. David still here. Still here. I didn't

669
00:46:40,915 --> 00:46:44,605
Speaker 2:  kick him. The auction robots haven't gotten me yet. Lauren fines here. Hey

670
00:46:44,605 --> 00:46:48,525
Speaker 2:  Lauren. Hi. Welcome back. Every time we talk to you on the

671
00:46:48,525 --> 00:46:52,285
Speaker 2:  show, it feels like some legal catastrophe has befall

672
00:46:52,285 --> 00:46:52,605
Speaker 2:  Google.

673
00:46:54,375 --> 00:46:57,555
Speaker 2:  Wow. That's true. We have to break this pattern. We like talking to you.

674
00:46:58,015 --> 00:47:01,995
Speaker 2:  But right now you're a bit of an omen. Lauren, what

675
00:47:01,995 --> 00:47:04,835
Speaker 2:  do you think about Nintendo alarm box? Yeah. Did you buy the Nintendo alarm

676
00:47:04,895 --> 00:47:05,115
Speaker 2:  box?

677
00:47:06,235 --> 00:47:09,035
Speaker 6:  I did not. I unfortunately have to talk about Google.

678
00:47:10,295 --> 00:47:13,395
Speaker 2:  No. Well, at least this time we didn't make you sit in a courthouse all week,

679
00:47:14,035 --> 00:47:17,715
Speaker 2:  which is, we have been doing this time a little more

680
00:47:17,955 --> 00:47:21,835
Speaker 2:  procedural. So there was the big Google search antitrust case, which

681
00:47:22,455 --> 00:47:25,395
Speaker 2:  the government won. Google lost. We didn't know what the remedies would be.

682
00:47:25,415 --> 00:47:29,365
Speaker 2:  The government has put forth, its not the actual

683
00:47:29,565 --> 00:47:32,405
Speaker 2:  proposal, but it's like framework of a proposal. It's concepts of a plan,

684
00:47:32,615 --> 00:47:36,205
Speaker 2:  quote Donald Trump. It's very much con, it's 11 pages of concepts of a plan.

685
00:47:36,235 --> 00:47:40,085
Speaker 2:  Yeah. And the plan I want, Lauren, I I want you to go into it in

686
00:47:40,085 --> 00:47:43,885
Speaker 2:  detail, but the plan right now is like everything, every idea is on the table

687
00:47:43,945 --> 00:47:47,445
Speaker 2:  for us. So we'll we, let's talk about that and what those ideas are.

688
00:47:47,835 --> 00:47:51,525
Speaker 2:  Then Google also lost the antitrust case that Epic

689
00:47:51,535 --> 00:47:55,485
Speaker 2:  filed against it around the Play store and the court has a plan

690
00:47:55,485 --> 00:47:58,685
Speaker 2:  for some remedies in that case. Which amount to

691
00:47:59,625 --> 00:48:02,715
Speaker 2:  just like having to open things up and share apps with other app stores and

692
00:48:02,715 --> 00:48:06,595
Speaker 2:  all that. And then next to it is the big ad take case, which where

693
00:48:06,595 --> 00:48:09,795
Speaker 2:  you were just in the courtroom for weeks and I dunno what's gonna happen

694
00:48:09,795 --> 00:48:13,555
Speaker 2:  there. That's a lot. and we were joking at the top of the show

695
00:48:13,855 --> 00:48:17,755
Speaker 2:  and Lauren, I'm very curious for your perspective on this. That's a lot of

696
00:48:17,755 --> 00:48:21,675
Speaker 2:  stuff happening to Google that doesn't appear to be like

697
00:48:21,675 --> 00:48:25,555
Speaker 2:  having an impact. Like people, I, I can't tell if everyone knows that

698
00:48:25,955 --> 00:48:29,875
Speaker 2:  whatever we think of as Google today is going

699
00:48:29,875 --> 00:48:33,355
Speaker 2:  away. Like it's going to change in some way over the next X years

700
00:48:33,665 --> 00:48:36,275
Speaker 2:  because of all this activity. Is that what you see as well?

701
00:48:36,745 --> 00:48:40,595
Speaker 6:  Yeah, I, I agree. I think the key is maybe that it is

702
00:48:40,595 --> 00:48:44,355
Speaker 6:  in X years, which could be a very large number

703
00:48:45,115 --> 00:48:48,995
Speaker 6:  because you know, now that these things are in the

704
00:48:48,995 --> 00:48:52,195
Speaker 6:  remedies phase, at least in the case of Epic and

705
00:48:52,855 --> 00:48:56,635
Speaker 6:  the search case, you know, Google can then appeal

706
00:48:57,295 --> 00:49:01,115
Speaker 6:  and then we have a whole other process there. So it's still gonna take quite

707
00:49:01,115 --> 00:49:05,035
Speaker 6:  a bit of time to see any real change here.

708
00:49:06,035 --> 00:49:09,915
Speaker 6:  I think in the Epic case, it depends on if they get a

709
00:49:09,915 --> 00:49:13,835
Speaker 6:  stay on remedies while they appeal, but you

710
00:49:13,835 --> 00:49:17,315
Speaker 6:  know, it's still, you know, it's not something that consumers are necessarily

711
00:49:17,315 --> 00:49:20,355
Speaker 6:  gonna see a change on super quickly.

712
00:49:21,095 --> 00:49:24,955
Speaker 6:  But yeah, I think it hasn't really settled in for a lot of

713
00:49:24,955 --> 00:49:28,915
Speaker 6:  people that, you know, Google is definitely going to change. Yeah.

714
00:49:29,015 --> 00:49:32,555
Speaker 6:  Or at least it, it seems like it will based on how these cases have turned

715
00:49:32,555 --> 00:49:33,035
Speaker 6:  out so far.

716
00:49:33,655 --> 00:49:36,875
Speaker 2:  And to be fair, Google has said it will appeal all of the cases and it has

717
00:49:36,965 --> 00:49:40,915
Speaker 2:  asked for a stay, which means a delay on the remedies in the Epic

718
00:49:40,915 --> 00:49:44,235
Speaker 2:  case being applied while it goes off and appeals and the blog posts are appropriately

719
00:49:44,235 --> 00:49:46,875
Speaker 2:  outraged. If, you read Google's blog posts,

720
00:49:48,135 --> 00:49:51,595
Speaker 2:  but, so it's like something's gonna happen, right? Like

721
00:49:52,175 --> 00:49:55,835
Speaker 2:  all of this stuff is happening at once and maybe Google can delay some of

722
00:49:55,835 --> 00:49:59,635
Speaker 2:  it and maybe Google can appeal its way out of some of it, but it can't do

723
00:49:59,635 --> 00:50:02,755
Speaker 2:  it to all of it. Yeah, it seems very hard to imagine at this moment

724
00:50:03,345 --> 00:50:07,275
Speaker 2:  that Google is able to just play it all

725
00:50:07,275 --> 00:50:10,115
Speaker 2:  the way out and just litigate its way out of trouble.

726
00:50:11,255 --> 00:50:14,955
Speaker 2:  And the sense I get just from talking to people at Google is that part

727
00:50:15,475 --> 00:50:19,235
Speaker 2:  of what is confusing for Google right now is that it's not

728
00:50:19,235 --> 00:50:22,675
Speaker 2:  clear what is gonna stick and what isn't that there's like, and Lauren, I

729
00:50:22,675 --> 00:50:24,635
Speaker 2:  don't know if this is the sense you're getting from folks involved in this

730
00:50:24,635 --> 00:50:27,640
Speaker 2:  too, but it, there's something going on where there's, there's, there is

731
00:50:27,640 --> 00:50:31,445
Speaker 2:  so much all happening at once that it's almost like you kind of

732
00:50:31,445 --> 00:50:35,205
Speaker 2:  can't pick where to focus your energy and so you are, you're just like, well

733
00:50:36,135 --> 00:50:39,525
Speaker 2:  we're just gonna kind of let all this wash over us and then something will

734
00:50:39,525 --> 00:50:42,645
Speaker 2:  stick and we'll deal with that when it comes. But everybody I talk to even

735
00:50:42,715 --> 00:50:45,525
Speaker 2:  like sort of in and around all of this is just like

736
00:50:46,475 --> 00:50:49,765
Speaker 2:  yeah. Thrown by the volume of it all. Like, is is that what you're hearing

737
00:50:49,765 --> 00:50:50,245
Speaker 2:  too, Lauren?

738
00:50:50,515 --> 00:50:54,485
Speaker 6:  Yeah, no I think that seems right. I think you know it,

739
00:50:54,805 --> 00:50:58,565
Speaker 6:  a lot of all of these different cases are in different parts of Google's

740
00:50:58,685 --> 00:51:02,605
Speaker 6:  business. So you know, I guess Google could say, alright, we're gonna

741
00:51:02,755 --> 00:51:06,685
Speaker 6:  make some proactive changes in some of these businesses. But you

742
00:51:06,685 --> 00:51:10,605
Speaker 6:  know, even if they think, even if they think they won't win everything, they

743
00:51:10,605 --> 00:51:14,445
Speaker 6:  don't know which things will stick necessarily. So it's sort

744
00:51:14,445 --> 00:51:16,205
Speaker 6:  of difficult to get in front of right now.

745
00:51:16,435 --> 00:51:19,205
Speaker 2:  Well, and I feel like that's actually a really good segue to the search remedies,

746
00:51:19,205 --> 00:51:21,765
Speaker 2:  which I, I want to talk about Lauren now. Yeah. I want, I want you to help

747
00:51:21,765 --> 00:51:25,165
Speaker 2:  us go through, because I think what, what I get from that is

748
00:51:26,625 --> 00:51:30,245
Speaker 2:  the DOJ in particular is like, no Google, you

749
00:51:30,295 --> 00:51:34,245
Speaker 2:  can't just make teeny tiny changes and sort of wiggle your way out of this.

750
00:51:34,245 --> 00:51:38,085
Speaker 2:  Like we, we are coming for you and we are coming for all of it. Yeah. It's

751
00:51:38,085 --> 00:51:41,805
Speaker 2:  like I, I could not believe reading this filing how big

752
00:51:42,165 --> 00:51:45,605
Speaker 2:  a window the DOJ is giving itself or would like to give itself

753
00:51:46,145 --> 00:51:48,725
Speaker 2:  to mess with Google. And I think it's because of what you just said, Lauren,

754
00:51:48,725 --> 00:51:52,285
Speaker 2:  that Google is like, this touches lots of pieces of our business, we'll sort

755
00:51:52,285 --> 00:51:55,645
Speaker 2:  of noodle around the edges and we'll we'll build a firewall back between

756
00:51:55,645 --> 00:51:59,325
Speaker 2:  things and we'll let Congress yell at somebody three times a year and then

757
00:51:59,325 --> 00:52:02,245
Speaker 2:  everything will be fine. And the DOJ seems very clearly to be like,

758
00:52:03,125 --> 00:52:07,085
Speaker 2:  absolutely not like we are, we are going to burn you down. And like

759
00:52:07,085 --> 00:52:10,005
Speaker 2:  that's what James and out of the Epic judge has essentially said. Yeah. He's

760
00:52:10,005 --> 00:52:13,485
Speaker 2:  like, I'm going to tear this company open. And that is like the, the vibe

761
00:52:13,545 --> 00:52:17,445
Speaker 2:  is so aggressive on that front from the government side of this. It's wild.

762
00:52:17,555 --> 00:52:21,285
Speaker 2:  Yeah. So let's talk about the search remedies. It, it is a 32 page

763
00:52:21,285 --> 00:52:25,205
Speaker 2:  filing only 11 pages of which are actually substantive. 20

764
00:52:25,205 --> 00:52:28,245
Speaker 2:  pages are just state attorney general signing it, which I think is great.

765
00:52:28,805 --> 00:52:31,325
Speaker 2:  Everyone just like joined the club at That's what I aspire to. Yeah. Just

766
00:52:31,325 --> 00:52:34,605
Speaker 2:  to be like helped the 11th signatory of everything I cut down,

767
00:52:35,205 --> 00:52:39,165
Speaker 2:  I helped. But it is, it starts with, we should break up

768
00:52:39,165 --> 00:52:42,925
Speaker 2:  Google. It's on our minds all the way down to, I don't know, you should appoint

769
00:52:43,005 --> 00:52:45,925
Speaker 2:  a compliance officer for us to yell at Lauren. Take us through it. What are,

770
00:52:45,925 --> 00:52:47,085
Speaker 2:  what are the approaches in here?

771
00:52:47,355 --> 00:52:50,085
Speaker 6:  Yeah, so basically there's four high level,

772
00:52:51,555 --> 00:52:55,445
Speaker 6:  high level categories that the DOJ lays out that they're looking for

773
00:52:55,985 --> 00:52:59,485
Speaker 6:  in terms of remedies here. So, you know, the first one is

774
00:52:59,735 --> 00:53:03,445
Speaker 6:  about the search distribution and revenue sharing

775
00:53:03,495 --> 00:53:07,085
Speaker 6:  deals. I think these are kind of like the most closely

776
00:53:07,395 --> 00:53:11,245
Speaker 6:  tied to like the surface level of what this case was about, which was like

777
00:53:11,725 --> 00:53:14,725
Speaker 6:  contracts with phone makers and browser makers

778
00:53:16,425 --> 00:53:19,925
Speaker 6:  to make Google the default on their products. And

779
00:53:20,435 --> 00:53:23,925
Speaker 6:  basically the DOJ says like, we'd wanna put some limits on

780
00:53:24,585 --> 00:53:28,525
Speaker 6:  the kinds of contracts that Google can make. So, you know,

781
00:53:28,525 --> 00:53:31,205
Speaker 6:  that seems like probably the lowest hanging fruit here

782
00:53:32,705 --> 00:53:36,485
Speaker 6:  and, but it's also something that doesn't really

783
00:53:36,485 --> 00:53:39,045
Speaker 6:  like fundamentally change Google's business.

784
00:53:40,745 --> 00:53:44,245
Speaker 6:  But another part of that section they talk about,

785
00:53:46,105 --> 00:53:50,085
Speaker 6:  you know, making change structural changes, which means a breakup

786
00:53:50,715 --> 00:53:54,365
Speaker 6:  involving Google's, Google's ownership of

787
00:53:54,785 --> 00:53:58,405
Speaker 6:  Chrome, Android and the Play store. And so it's basically saying like

788
00:53:58,975 --> 00:54:02,645
Speaker 6:  there are these other channels where

789
00:54:02,865 --> 00:54:06,565
Speaker 6:  Google distributes its search engine that Google

790
00:54:06,665 --> 00:54:10,245
Speaker 6:  has an advantage in that its rivals don't, and you know,

791
00:54:10,265 --> 00:54:13,965
Speaker 6:  that's fundamentally a problem. So that's kind of where,

792
00:54:14,145 --> 00:54:17,885
Speaker 6:  you know, we get from this more surface level

793
00:54:18,145 --> 00:54:22,005
Speaker 6:  remedy of contracts to something that really would like go

794
00:54:22,005 --> 00:54:23,885
Speaker 6:  into Google's business and change it up.

795
00:54:24,035 --> 00:54:26,565
Speaker 2:  Just to pause on that one, I there, I wanna get to the other ones, but I

796
00:54:26,565 --> 00:54:30,485
Speaker 2:  think the, the, the move from the first

797
00:54:30,485 --> 00:54:33,645
Speaker 2:  part of that to the second I think is what's so interesting about this whole

798
00:54:33,985 --> 00:54:37,845
Speaker 2:  filing because it's like If, you take the argument to be that

799
00:54:38,065 --> 00:54:42,005
Speaker 2:  Google made illegal amounts of money from its

800
00:54:42,005 --> 00:54:45,725
Speaker 2:  search engine, which is like not exactly the argument but is like

801
00:54:46,755 --> 00:54:50,325
Speaker 2:  it's, it's, you can get there pretty easily, right? Like you have to, you

802
00:54:50,325 --> 00:54:53,525
Speaker 2:  have to make some things up and not be right, but you can get there. No,

803
00:54:53,525 --> 00:54:56,045
Speaker 2:  but it's like that that is what they're, what part of what they're saying

804
00:54:56,045 --> 00:54:59,325
Speaker 2:  is it's not an illegal amount of money, it's they illegally protected their

805
00:54:59,565 --> 00:55:03,505
Speaker 2:  monopoly and thus made a ton of money. Right. Like's but

806
00:55:03,505 --> 00:55:06,065
Speaker 2:  they're not so worried about the money. No, but they are. But the but the

807
00:55:06,065 --> 00:55:09,985
Speaker 2:  point is the what they're doing and they, there's all

808
00:55:09,985 --> 00:55:13,265
Speaker 2:  this setup at the top of the document that is like, not only do we have to

809
00:55:13,295 --> 00:55:17,145
Speaker 2:  stop Google from doing what it's doing, we have to undo it and fix it. Yeah.

810
00:55:17,165 --> 00:55:20,665
Speaker 2:  And, and pull the market back. And you, there's like, they have a quote from

811
00:55:20,825 --> 00:55:23,585
Speaker 2:  somebody that's like, you know, we can't go back in history, but we have

812
00:55:23,585 --> 00:55:26,785
Speaker 2:  to, we have to do our best to fix it. And so it's like that's how you arrive

813
00:55:26,845 --> 00:55:30,785
Speaker 2:  at, we have to split off Android because Lauren, I think you're exactly right

814
00:55:30,785 --> 00:55:34,625
Speaker 2:  that like the, the obvious thing to come out of this or one

815
00:55:34,625 --> 00:55:38,385
Speaker 2:  obvious outcome would be no more search deals, right? You can't pay it to

816
00:55:38,385 --> 00:55:41,745
Speaker 2:  be the default anymore. That seems like a very straightforward answer to

817
00:55:41,745 --> 00:55:45,025
Speaker 2:  what Judge Meta clearly had issues with. But then

818
00:55:45,455 --> 00:55:49,185
Speaker 2:  it's, it's a surprisingly small number of steps from that to

819
00:55:49,695 --> 00:55:52,785
Speaker 2:  even If. you let Google be the default search engine in the thing that it

820
00:55:52,785 --> 00:55:56,465
Speaker 2:  already owns. It's still too powerful. And so it's like that,

821
00:55:56,535 --> 00:56:00,265
Speaker 2:  that leap feels wild, but I was surprised at how quickly

822
00:56:00,365 --> 00:56:03,505
Speaker 2:  the government got there. Yeah. I would say. So it's not, to me it's not

823
00:56:03,505 --> 00:56:07,425
Speaker 2:  money, it's data. The money is like related to data. Well that's

824
00:56:07,425 --> 00:56:09,145
Speaker 2:  make a good that, that's one of the four things too, right? You can't make

825
00:56:09,145 --> 00:56:11,945
Speaker 2:  a good search engine without all the data that Google collects and if they

826
00:56:12,185 --> 00:56:15,945
Speaker 2:  continue to own Chrome, you're hooped. Right?

827
00:56:16,015 --> 00:56:19,865
Speaker 2:  Like, but I agree with you there. It's a small jump from these search

828
00:56:19,865 --> 00:56:23,645
Speaker 2:  deals are illegally being made to,

829
00:56:23,825 --> 00:56:27,405
Speaker 2:  we should tear Google the shreds, right? Because Chrome makes you too powerful

830
00:56:27,405 --> 00:56:29,805
Speaker 2:  because Chrome makes you too powerful. Yeah, I, I agree with that. Okay.

831
00:56:29,805 --> 00:56:33,685
Speaker 2:  Lauren, what are the other two remedies proposed or concepts of a

832
00:56:33,685 --> 00:56:34,205
Speaker 2:  plan of remedy?

833
00:56:35,435 --> 00:56:38,925
Speaker 6:  Yeah, so the next one kind of what we were just talking about was the

834
00:56:39,005 --> 00:56:42,885
Speaker 6:  accumulation and use of data. So, you know, during the trial the

835
00:56:42,885 --> 00:56:46,445
Speaker 6:  government kind of described this like self-reinforcing cycle where

836
00:56:46,825 --> 00:56:50,685
Speaker 6:  you know, users go to Google because

837
00:56:50,955 --> 00:56:54,925
Speaker 6:  it's the default and it's what they're used to using and they enter

838
00:56:54,925 --> 00:56:58,725
Speaker 6:  their search queries and then Google gets a lot of information from what

839
00:56:58,725 --> 00:57:02,445
Speaker 6:  you click on about what's actually a useful

840
00:57:02,445 --> 00:57:06,245
Speaker 6:  answer. And that's, and because it, you know, kind of

841
00:57:06,745 --> 00:57:10,605
Speaker 6:  has this basically has all of these distribution

842
00:57:10,605 --> 00:57:14,565
Speaker 6:  channels pretty much set to itself as

843
00:57:14,705 --> 00:57:18,365
Speaker 6:  the default. You know, most people are going to

844
00:57:18,445 --> 00:57:22,005
Speaker 6:  Google and then other search rivals are kind of being

845
00:57:22,045 --> 00:57:25,685
Speaker 6:  deprived of that query click information and then,

846
00:57:26,065 --> 00:57:29,525
Speaker 6:  you know, aren't able to improve their services as much and then, you know,

847
00:57:29,635 --> 00:57:32,805
Speaker 6:  they're not, they don't feel as good to users and then they go back to Google.

848
00:57:33,065 --> 00:57:36,365
Speaker 6:  So that's kind of the cycle that was described at trial,

849
00:57:36,595 --> 00:57:40,485
Speaker 2:  Including by Satya Nadella. Yeah. Yeah. That was very,

850
00:57:40,665 --> 00:57:41,685
Speaker 2:  he was not messing around.

851
00:57:42,355 --> 00:57:46,245
Speaker 6:  Yeah. Yeah. So basically go the government

852
00:57:46,245 --> 00:57:49,885
Speaker 6:  wants to offset that a advantage by

853
00:57:50,345 --> 00:57:53,285
Speaker 6:  making it so, you know, Google has to kind of share

854
00:57:54,035 --> 00:57:56,485
Speaker 6:  certain information. You know, they might have to,

855
00:57:58,025 --> 00:58:02,005
Speaker 6:  you know, license some information or make APIs to

856
00:58:03,335 --> 00:58:06,565
Speaker 6:  share some of the information on how it trains

857
00:58:07,345 --> 00:58:10,805
Speaker 6:  its search engine with that query data

858
00:58:10,805 --> 00:58:14,525
Speaker 6:  essentially. And you know, the DOJ says like they know that

859
00:58:14,525 --> 00:58:18,205
Speaker 6:  there are privacy concerns here with sharing that kind of

860
00:58:18,205 --> 00:58:22,165
Speaker 6:  information, but they also say, you know, we need to kind

861
00:58:22,165 --> 00:58:26,125
Speaker 6:  of parse out what is really a privacy concern and what is just like

862
00:58:26,845 --> 00:58:28,045
Speaker 6:  a big tech defense.

863
00:58:28,465 --> 00:58:31,285
Speaker 2:  Yep. That comes up a few times where the, the government is like, yeah, we

864
00:58:31,285 --> 00:58:35,085
Speaker 2:  know there are privacy issues, eh, we'll figure it out. It comes up a lot.

865
00:58:35,085 --> 00:58:38,645
Speaker 2:  You know, Jonathan Canter, the assistant attorney general for antitrust has

866
00:58:38,645 --> 00:58:42,445
Speaker 2:  been on decoder twice now and he's very careful. He's very,

867
00:58:42,555 --> 00:58:45,685
Speaker 2:  he's a government lawyer. He's very good at this. Yeah. Politician. But you

868
00:58:45,685 --> 00:58:49,525
Speaker 2:  can hear his frustration with privacy as a defense to

869
00:58:49,525 --> 00:58:53,485
Speaker 2:  every problem. Just it's blindingly clear. He's like, we

870
00:58:53,485 --> 00:58:56,325
Speaker 2:  know Apple wants to protect your data. That doesn't mean they can do illegal

871
00:58:56,325 --> 00:58:59,805
Speaker 2:  things. We can figure it out. And I think that's kind of what they're saying

872
00:58:59,805 --> 00:59:03,525
Speaker 2:  to Google here too. Like, yes, other companies

873
00:59:03,525 --> 00:59:06,205
Speaker 2:  need this data to compete. They need to know what's going on the internet

874
00:59:06,205 --> 00:59:10,105
Speaker 2:  too. You can't say only we can protect you. Like we're just

875
00:59:10,225 --> 00:59:13,465
Speaker 2:  not, that's not a rational defense right. To the government. Right. I have

876
00:59:13,465 --> 00:59:16,665
Speaker 2:  no idea how that's gonna play out, but I will say that I've, I've interviewed

877
00:59:16,845 --> 00:59:20,425
Speaker 2:  Cantor twice and he is very frustrated about that

878
00:59:20,425 --> 00:59:24,285
Speaker 2:  particular wall going up. Yeah, yeah. And they do, like

879
00:59:24,285 --> 00:59:27,365
Speaker 2:  Lauren was saying, there are a few times where it's like, and before you

880
00:59:27,365 --> 00:59:27,765
Speaker 2:  say privacy,

881
00:59:29,855 --> 00:59:33,765
Speaker 2:  don't say privacy. All right. What's the fourth one? There's two more.

882
00:59:33,765 --> 00:59:36,205
Speaker 2:  There's two more? Yeah, two more. Yeah, she's only said two. Oh

883
00:59:37,705 --> 00:59:39,485
Speaker 6:  The first was like a parter.

884
00:59:39,765 --> 00:59:40,005
Speaker 2:  I gotcha.

885
00:59:41,185 --> 00:59:44,925
Speaker 6:  So the third is about generation and display of search

886
00:59:44,925 --> 00:59:47,605
Speaker 6:  results. So this one is pretty much about AI

887
00:59:48,705 --> 00:59:52,565
Speaker 6:  and you know, the government kind of says, you know, Google, Google

888
00:59:52,665 --> 00:59:53,925
Speaker 6:  is creating these like new

889
00:59:55,465 --> 00:59:59,365
Speaker 6:  AI products that are, you know, integrated in search and a feature in

890
00:59:59,365 --> 01:00:03,285
Speaker 6:  search that basically come from scraping data from

891
01:00:03,335 --> 01:00:07,125
Speaker 6:  sites that they say have quote little to no bargaining

892
01:00:07,125 --> 01:00:11,045
Speaker 6:  power against Google's monopoly. So they're basically wanting to make sure

893
01:00:11,075 --> 01:00:14,885
Speaker 6:  that, you know, sites can maybe opt

894
01:00:14,945 --> 01:00:18,285
Speaker 6:  out of having their information being trained on

895
01:00:18,945 --> 01:00:20,365
Speaker 6:  AI data and things like that.

896
01:00:20,995 --> 01:00:24,865
Speaker 2:  This one feels to me like the government being like not

897
01:00:25,185 --> 01:00:28,945
Speaker 2:  entirely sure what problem it's trying to solve here because I think the

898
01:00:28,945 --> 01:00:32,545
Speaker 2:  thing we heard in both these trials, both in the search trial and in the

899
01:00:32,565 --> 01:00:36,425
Speaker 2:  ad tech trial was there's this whole group of round

900
01:00:36,425 --> 01:00:39,705
Speaker 2:  Google on the internet that just feels powerless, right? And there's, there's

901
01:00:39,705 --> 01:00:43,585
Speaker 2:  a sense that one of the things that is monopolistic about Google is that

902
01:00:43,605 --> 01:00:47,105
Speaker 2:  you just have to play Google's games all the time. And so you can feel this

903
01:00:47,105 --> 01:00:50,945
Speaker 2:  energy from the government saying we wanna level the playing field and

904
01:00:50,945 --> 01:00:53,785
Speaker 2:  give people more tools and more stuff to do. And like

905
01:00:54,525 --> 01:00:58,145
Speaker 2:  you've actually been able to opt out of Google for a pretty long time. It's

906
01:00:58,145 --> 01:01:01,985
Speaker 2:  just that no one wanted to Yeah. Because it wasn't a good trade for the

907
01:01:01,985 --> 01:01:05,345
Speaker 2:  most part. And now that trade is different and it's worse, but like

908
01:01:06,005 --> 01:01:09,505
Speaker 2:  the tools are still kind of there. So I. I feel like to me this was the least

909
01:01:09,505 --> 01:01:12,585
Speaker 2:  compelling part of this document. The government basically just trying to

910
01:01:12,585 --> 01:01:15,785
Speaker 2:  be like, we want everyone else to feel

911
01:01:17,485 --> 01:01:17,705
Speaker 2:  big.

912
01:01:19,335 --> 01:01:23,065
Speaker 6:  Yeah. This was the shortest section in the remedies and

913
01:01:23,165 --> 01:01:26,345
Speaker 6:  it does feel like the one that like maybe they're gonna have to figure out

914
01:01:26,345 --> 01:01:28,185
Speaker 6:  how to flush out a little bit more. Yeah,

915
01:01:28,215 --> 01:01:32,185
Speaker 2:  Yeah. This one one and it, it's hard. I mean like it's, it's easier in

916
01:01:32,185 --> 01:01:36,025
Speaker 2:  this instance to sort of bring Google down a peg than it is to

917
01:01:36,025 --> 01:01:38,825
Speaker 2:  bring everybody else up, right? And I think they're, they're trying to do

918
01:01:38,825 --> 01:01:41,785
Speaker 2:  both and I think that that makes sense in this moment. I think they're trying

919
01:01:41,785 --> 01:01:44,905
Speaker 2:  to push Apple into making a search engine. If I had to, interesting. If I

920
01:01:44,905 --> 01:01:48,665
Speaker 2:  had to describe the shape of the outcome that everyone wants

921
01:01:48,685 --> 01:01:52,625
Speaker 2:  the most, it's we knock Google down a peg, we make

922
01:01:52,625 --> 01:01:56,305
Speaker 2:  it illegal for you to, to just pay the money and Apple looks around and says,

923
01:01:56,305 --> 01:01:59,265
Speaker 2:  well we should just do a search engine of our own and we'll use some of this

924
01:01:59,275 --> 01:02:03,065
Speaker 2:  innovative new i AI technology to do it well. Wait, can I, can I read you

925
01:02:03,105 --> 01:02:06,985
Speaker 2:  a thing that might actually point at that? So one

926
01:02:06,985 --> 01:02:09,465
Speaker 2:  of the things in the generation display of search results

927
01:02:10,735 --> 01:02:14,665
Speaker 2:  section says that they're considering remedies that

928
01:02:14,665 --> 01:02:18,465
Speaker 2:  would require Google to make available in whole or through an API the indexes

929
01:02:18,465 --> 01:02:21,685
Speaker 2:  data feeds and models used for Google search, including those used in AI

930
01:02:21,805 --> 01:02:25,085
Speaker 2:  assisted search features and Google search results, features and ads including

931
01:02:25,085 --> 01:02:29,045
Speaker 2:  the underlying ranking signals, especially on mobile. So that's like a,

932
01:02:29,045 --> 01:02:32,925
Speaker 2:  that is bananas. That's, that's, that's it. Give Google away for

933
01:02:32,925 --> 01:02:36,485
Speaker 2:  free. You open source Google. Alright. But

934
01:02:36,845 --> 01:02:40,805
Speaker 2:  like that that, what that clearly says is we wanna spin up a

935
01:02:40,805 --> 01:02:44,725
Speaker 2:  whole bunch of Google competitors right away because anyone with 10 minutes

936
01:02:44,725 --> 01:02:47,445
Speaker 2:  of coding experience is now going to be able to build a Google level search

937
01:02:47,445 --> 01:02:51,405
Speaker 2:  engine like on the back of Google. Right. Like wild.

938
01:02:51,905 --> 01:02:54,565
Speaker 2:  But it does, it does suggest that one of the things they want to do is very

939
01:02:54,565 --> 01:02:58,445
Speaker 2:  quickly create a lot of competitors in the search industry. Yeah. And

940
01:02:58,445 --> 01:02:58,605
Speaker 2:  to

941
01:02:58,605 --> 01:03:01,925
Speaker 6:  The point of Apple at trial, the government

942
01:03:02,385 --> 01:03:04,925
Speaker 6:  did kind of suggest that Google had

943
01:03:06,395 --> 01:03:10,165
Speaker 6:  made it in its contract so that it would make sure Apple would not compete

944
01:03:10,165 --> 01:03:13,405
Speaker 6:  with it directly in search. So, I. I could definitely see that being something

945
01:03:13,715 --> 01:03:17,365
Speaker 6:  that the government would like to see, you know, opening up the opportunity

946
01:03:17,465 --> 01:03:21,285
Speaker 6:  for even, you know, a very well positioned competitor to just like

947
01:03:21,305 --> 01:03:23,485
Speaker 6:  get going here and crack open the ecosystem.

948
01:03:23,835 --> 01:03:26,165
Speaker 2:  Yeah. That was when they were talking about Spotlight, right. And there were

949
01:03:26,165 --> 01:03:30,005
Speaker 2:  all these internal emails where Apple was trying to decide whether the stuff

950
01:03:30,005 --> 01:03:33,365
Speaker 2:  they were doing in Spotlight was like too close to Google and people at Google

951
01:03:33,395 --> 01:03:37,005
Speaker 2:  were worried that Spotlight was becoming too googly and like there these

952
01:03:37,025 --> 01:03:40,445
Speaker 2:  two things were actively trying to not run into each other

953
01:03:41,505 --> 01:03:44,525
Speaker 2:  and, and you could, you could tell the whole time this came up in trial,

954
01:03:44,785 --> 01:03:48,245
Speaker 2:  the government's just sitting there being like, yeah we got,

955
01:03:49,605 --> 01:03:52,765
Speaker 2:  I can't tell you the number of times I've walked out of a WW C, which is

956
01:03:52,765 --> 01:03:55,885
Speaker 2:  where Apple does its operating system updates. And I've gotten texts from

957
01:03:55,885 --> 01:03:58,525
Speaker 2:  Google employees that are like, they're coming in for searching. And my response

958
01:03:58,545 --> 01:04:02,285
Speaker 2:  is always like, why are you talking to me? Right? Right. Like

959
01:04:02,705 --> 01:04:06,045
Speaker 2:  you're Google and it's because Apple has the click data, right? They have

960
01:04:06,045 --> 01:04:08,925
Speaker 2:  the captive audience, particularly in the iPhone that is just searching in

961
01:04:09,085 --> 01:04:12,325
Speaker 2:  Safari and right now that goes to Google and the second that's diverted,

962
01:04:12,345 --> 01:04:15,645
Speaker 2:  Google knows it's in trouble. So it pays the money. And I,

963
01:04:16,485 --> 01:04:20,245
Speaker 2:  I think generally I've heard both Jonathan

964
01:04:20,265 --> 01:04:23,565
Speaker 2:  Cantor and Lena Kahn at the FTC say all these like

965
01:04:24,405 --> 01:04:28,125
Speaker 2:  programs where we install a babysitter to tell a company they're doing

966
01:04:28,125 --> 01:04:31,805
Speaker 2:  something bad and they fix it like don't work, like these compliance

967
01:04:31,915 --> 01:04:35,125
Speaker 2:  regimes don't work. We want structural remedies, which means we're gonna

968
01:04:35,125 --> 01:04:38,125
Speaker 2:  break up your dumb company and now you're two companies. And what we want

969
01:04:38,125 --> 01:04:40,765
Speaker 2:  is actual competition in the market. And the reason I'm saying I think they

970
01:04:40,765 --> 01:04:43,445
Speaker 2:  want Apple to launch a competitor to Google is like, that is the easiest

971
01:04:43,625 --> 01:04:47,565
Speaker 2:  fix to this problem. Yeah. Like without question it's Google should

972
01:04:47,645 --> 01:04:51,525
Speaker 2:  have a competitor where can I just drag one into existence? It is on

973
01:04:51,525 --> 01:04:55,485
Speaker 2:  the iPhone with Apple intelligence and you're talking to Siri and you've

974
01:04:55,485 --> 01:04:58,965
Speaker 2:  got new search results and new things to query all that stuff.

975
01:05:00,125 --> 01:05:03,855
Speaker 2:  Just do it Well and it's also the exact same logic that

976
01:05:04,005 --> 01:05:07,975
Speaker 2:  doesn't make it make sense for Apple to have not launched a

977
01:05:07,975 --> 01:05:10,695
Speaker 2:  search engine. Yeah. There were a lot of negatives in that sentence. But

978
01:05:10,965 --> 01:05:14,575
Speaker 2:  basically the, the point is like, given all of that evidence,

979
01:05:14,995 --> 01:05:18,320
Speaker 2:  the only obvious reason Apple wouldn't have launched the search engine is

980
01:05:18,320 --> 01:05:20,965
Speaker 2:  because Google pays it lots of money. And that was like Lauren, I think you

981
01:05:20,965 --> 01:05:24,605
Speaker 2:  and I both heard that was the implication at trial that like they have successfully

982
01:05:24,635 --> 01:05:28,205
Speaker 2:  with $20 billion a year kept a huge and

983
01:05:28,205 --> 01:05:32,085
Speaker 2:  well-funded and immediately at scale competitor from

984
01:05:32,645 --> 01:05:35,765
Speaker 2:  existing and now we're just gonna give them all of Google's other data.

985
01:05:37,015 --> 01:05:40,885
Speaker 2:  We're just gonna fix it. Yeah. All right. I think that's three. One more.

986
01:05:40,885 --> 01:05:42,205
Speaker 2:  Yeah, one more. One more. All right.

987
01:05:42,425 --> 01:05:46,405
Speaker 6:  So the last one is about kind of a different part of

988
01:05:46,405 --> 01:05:50,285
Speaker 6:  this case, which was Google's monopoly

989
01:05:50,385 --> 01:05:54,325
Speaker 6:  in general search text ads. So

990
01:05:54,405 --> 01:05:56,765
Speaker 6:  this is like a super specific part of the

991
01:05:56,765 --> 01:05:58,565
Speaker 2:  Case. We love a market definition podcast,

992
01:06:00,785 --> 01:06:04,645
Speaker 6:  But basically in this area, you know, this is

993
01:06:04,645 --> 01:06:08,605
Speaker 6:  like the the sponsored blue links that you see when you enter a search

994
01:06:08,605 --> 01:06:08,885
Speaker 6:  query.

995
01:06:10,545 --> 01:06:14,405
Speaker 6:  And you know, the government here is thinking

996
01:06:14,405 --> 01:06:15,125
Speaker 6:  about maybe

997
01:06:16,825 --> 01:06:20,605
Speaker 6:  making Google license or syndicate its ad feed even like

998
01:06:20,925 --> 01:06:24,445
Speaker 6:  separately from its search results to allow for more

999
01:06:24,445 --> 01:06:27,805
Speaker 6:  competition in that really particular part of the market.

1000
01:06:28,385 --> 01:06:32,045
Speaker 2:  You should see if, if you're not watching this, you should see the squinting

1001
01:06:32,155 --> 01:06:36,085
Speaker 2:  Neli is doing listening to explanation. Yeah. I mean

1002
01:06:36,395 --> 01:06:40,125
Speaker 2:  I've been spending a lot of time talking to ad people lately. You have, it's

1003
01:06:40,125 --> 01:06:43,645
Speaker 2:  changed you because I see them, you're wearing a tie. God I'm wearing a tie

1004
01:06:43,645 --> 01:06:46,885
Speaker 2:  because of a secret VERGE project that will soon be revealed. And I decided

1005
01:06:46,885 --> 01:06:48,325
Speaker 2:  to just keep wearing a tie today.

1006
01:06:50,585 --> 01:06:53,885
Speaker 2:  But I've been just sort of like watching like the influencer advertising

1007
01:06:53,885 --> 01:06:55,805
Speaker 2:  market. So I've been talking to a lot of people like where's this money going?

1008
01:06:55,805 --> 01:06:58,725
Speaker 2:  Like what is happening on these platforms? I promise I'll write a story about

1009
01:06:58,725 --> 01:07:02,445
Speaker 2:  this. But the thing that they're all saying is search ads on Google

1010
01:07:02,505 --> 01:07:06,405
Speaker 2:  are not so valuable to us anymore. Hmm. That this all

1011
01:07:06,405 --> 01:07:10,045
Speaker 2:  the action, all the young people, the money is in like TikTok shop or whatever

1012
01:07:10,305 --> 01:07:13,165
Speaker 2:  and so the money's moving. So it's just like this last piece of the puzzle

1013
01:07:13,575 --> 01:07:17,475
Speaker 2:  where you're googling running shoes and Google is

1014
01:07:17,475 --> 01:07:20,555
Speaker 2:  gonna show you search results for running shoes with a sponsored link at

1015
01:07:20,555 --> 01:07:23,395
Speaker 2:  the top. Like it's still very valuable, it's very lucrative, it hasn't moved

1016
01:07:24,215 --> 01:07:28,155
Speaker 2:  in any meaningful way, but it's the thing that is changing all on

1017
01:07:28,175 --> 01:07:31,955
Speaker 2:  its own without any intervention. Right? Right. Because the dollars are,

1018
01:07:32,015 --> 01:07:35,835
Speaker 2:  are just going somewhere else. And so this one just seems

1019
01:07:35,835 --> 01:07:39,155
Speaker 2:  like do what is what I want to feed of Google Ads.

1020
01:07:39,975 --> 01:07:43,795
Speaker 2:  That's my, that's the plan. Like we're fine, it's good. But it goes back

1021
01:07:43,795 --> 01:07:47,595
Speaker 2:  to kind of the this same idea of like how do we undo

1022
01:07:47,615 --> 01:07:50,555
Speaker 2:  the thing that has made Google unstoppable, which is that it just has this

1023
01:07:50,875 --> 01:07:54,675
Speaker 2:  gigantic lead on everybody. It has so much scale, it has so much

1024
01:07:55,045 --> 01:07:58,915
Speaker 2:  click data, it has so much query data, it has so much user data and it

1025
01:07:58,915 --> 01:08:02,635
Speaker 2:  really seems like the only thing the government has figured out to do here

1026
01:08:02,855 --> 01:08:06,315
Speaker 2:  is just give all that data to everybody else in order to level the playing

1027
01:08:06,315 --> 01:08:09,835
Speaker 2:  field. I'm not a lawyer, but that doesn't seem like a real plausible.

1028
01:08:10,135 --> 01:08:13,795
Speaker 2:  So there's this idea Sarah, John and I've been talking this lot.

1029
01:08:13,795 --> 01:08:17,765
Speaker 2:  There's this idea that you can't force a company to do something,

1030
01:08:17,765 --> 01:08:21,245
Speaker 2:  you can't force someone to do anything. It's called specific

1031
01:08:21,275 --> 01:08:25,245
Speaker 2:  performance. It's very nerdy, but it's like it's the thing you, it's

1032
01:08:25,245 --> 01:08:28,645
Speaker 2:  like the hardest thing to get. Like I,

1033
01:08:29,025 --> 01:08:32,645
Speaker 2:  you're, I'm mad at you because your tree is hanging on my

1034
01:08:33,045 --> 01:08:35,885
Speaker 2:  property and like I need you to cut down the tree and it's much more likely

1035
01:08:36,315 --> 01:08:40,245
Speaker 2:  that the judge will move our property lines than to force you

1036
01:08:40,245 --> 01:08:43,285
Speaker 2:  to cut down the tree. Interesting. Right? Like that's a, if you're a first

1037
01:08:43,285 --> 01:08:46,405
Speaker 2:  year lawyer, I know there's a million problems with that example, but that's

1038
01:08:46,405 --> 01:08:50,285
Speaker 2:  the shape of it, right? Like it is very hard to force a force someone

1039
01:08:50,345 --> 01:08:54,235
Speaker 2:  to do anything in an ongoing way. It's just the last thing you

1040
01:08:54,235 --> 01:08:58,155
Speaker 2:  can ask for. And I think in this context, and Lauren, I'm curious what

1041
01:08:58,155 --> 01:09:01,795
Speaker 2:  your reporting has revealed. It feels like the government's like, yeah, we're

1042
01:09:01,795 --> 01:09:05,355
Speaker 2:  gonna break it up along the way. We're gonna ask for a bunch of like duty

1043
01:09:05,415 --> 01:09:08,955
Speaker 2:  to deal. You have to do these deals. We're gonna force your business to do

1044
01:09:09,195 --> 01:09:12,435
Speaker 2:  business with that business. We're gonna force you to do these things, which

1045
01:09:12,455 --> 01:09:16,275
Speaker 2:  are the other choice. Either Judge,

1046
01:09:16,575 --> 01:09:20,155
Speaker 2:  you can break up Google, you can take YouTube and Chrome and

1047
01:09:20,155 --> 01:09:23,395
Speaker 2:  Android, just break 'em up. Now you got three companies clean. If we can

1048
01:09:23,395 --> 01:09:27,235
Speaker 2:  all go to dinner or we can force these companies

1049
01:09:27,855 --> 01:09:30,835
Speaker 2:  in a slap in the face, you're gonna slap George Washington in the face. The

1050
01:09:30,835 --> 01:09:33,955
Speaker 2:  most anti-American thing you do. And so you have to do deals with your competitors,

1051
01:09:33,955 --> 01:09:37,855
Speaker 2:  right? It and it just feels like that's the setup. And I don't, I

1052
01:09:37,855 --> 01:09:41,535
Speaker 2:  don't know what's gonna happen but like you have to license all of your data

1053
01:09:41,635 --> 01:09:44,695
Speaker 2:  and your search results generations and your ad stack so that Apple can build

1054
01:09:44,735 --> 01:09:48,575
Speaker 2:  a thing and you have to keep that going. And where the American economy depends

1055
01:09:48,635 --> 01:09:51,335
Speaker 2:  on your doing this deal because we forced you to

1056
01:09:52,515 --> 01:09:55,855
Speaker 2:  That's tough. That's a tough one. Yeah. And Lord knows, and it might be easier,

1057
01:09:55,855 --> 01:09:59,575
Speaker 2:  there's no way around getting that deal done correctly in the spirit of the

1058
01:09:59,575 --> 01:10:03,455
Speaker 2:  law and it just might be easier to be like cut it in three. And I, I

1059
01:10:03,455 --> 01:10:07,415
Speaker 2:  kind of think that this whole concept of a plan thing is like just setting

1060
01:10:07,435 --> 01:10:09,695
Speaker 2:  up the, oh that seems hard. We should just break up a little,

1061
01:10:10,165 --> 01:10:13,695
Speaker 6:  Well the government does say they think that there needs to be like

1062
01:10:14,075 --> 01:10:17,855
Speaker 6:  pretty, the judge needs to consider remedies from like

1063
01:10:18,235 --> 01:10:21,935
Speaker 6:  Mo at least most of these buckets. Like it can't just be like

1064
01:10:22,155 --> 01:10:26,135
Speaker 6:  one thing and obviously you know, this is early days, they're

1065
01:10:26,135 --> 01:10:29,855
Speaker 6:  asking for as much as they think they might be able to get and they

1066
01:10:29,855 --> 01:10:33,775
Speaker 6:  haven't even gotten into specifics yet. But you know, I think

1067
01:10:33,925 --> 01:10:37,575
Speaker 6:  they feel like they need to attack this from multiple angles and

1068
01:10:37,845 --> 01:10:41,615
Speaker 6:  also attack the network effects. Which I think is what our licensing aspects

1069
01:10:41,675 --> 01:10:45,375
Speaker 6:  of this get to is like, yeah, okay, once Google

1070
01:10:45,635 --> 01:10:49,615
Speaker 6:  has all this query information, no one else is really able to get

1071
01:10:49,615 --> 01:10:53,175
Speaker 6:  it and get in there unless they're able to access that in some way.

1072
01:10:54,075 --> 01:10:57,655
Speaker 2:  Do these things typically get filed as like a negotiating

1073
01:10:57,935 --> 01:11:00,415
Speaker 2:  tactic? I'm, I'm realizing as you're talking that the way I read this is

1074
01:11:00,835 --> 01:11:04,575
Speaker 2:  the government sort of vastly overshooting what it thinks it can do just

1075
01:11:04,575 --> 01:11:08,415
Speaker 2:  as kind of a, a first overbid in, in the game

1076
01:11:08,515 --> 01:11:11,335
Speaker 2:  to try and land somewhere in the middle. Is that actually how this works?

1077
01:11:11,655 --> 01:11:15,445
Speaker 2:  I I, I don't know to whatever extent, although I think that DOJ

1078
01:11:15,445 --> 01:11:18,685
Speaker 2:  does not want to settle this one. I think they want, okay, they want it.

1079
01:11:18,685 --> 01:11:21,565
Speaker 2:  They've won. They won, right? They won a trial, they, they want to see what

1080
01:11:21,565 --> 01:11:25,245
Speaker 2:  remedies they will win whatever. I think the weirdness here is

1081
01:11:25,275 --> 01:11:28,995
Speaker 2:  this was a two part trial. So they had the first trial

1082
01:11:28,995 --> 01:11:32,795
Speaker 2:  that's just like, are you bad? And the answer is yes. Yes. Did you do it?

1083
01:11:33,015 --> 01:11:36,555
Speaker 2:  Oh you super did. And the second part is what should the remedies be? And

1084
01:11:36,555 --> 01:11:37,275
Speaker 2:  a lot of this filing

1085
01:11:39,295 --> 01:11:42,435
Speaker 2:  is here's what we think the remedy should be. Now we're gonna have another

1086
01:11:42,435 --> 01:11:45,675
Speaker 2:  trial and we're gonna get more information about how bad they are to support

1087
01:11:45,675 --> 01:11:46,475
Speaker 2:  these. I

1088
01:11:46,475 --> 01:11:50,275
Speaker 6:  There's also gonna be a whole other discovery process for this phase. So

1089
01:11:50,575 --> 01:11:54,275
Speaker 6:  the government's gonna get even more information about what's possible, what

1090
01:11:54,275 --> 01:11:57,875
Speaker 6:  Google thinks actually gives it the power that it does

1091
01:11:58,055 --> 01:12:02,035
Speaker 6:  and you know how it could get at that So I think that will be refined

1092
01:12:02,055 --> 01:12:03,315
Speaker 6:  as they get that information.

1093
01:12:03,575 --> 01:12:06,995
Speaker 2:  So that's the reason you go super broad in this first one is to essentially

1094
01:12:06,995 --> 01:12:10,835
Speaker 2:  give yourself leeway to go every possible direction

1095
01:12:11,175 --> 01:12:15,115
Speaker 2:  in this remedies trial. Yeah. Okay. That makes sense. And the the and

1096
01:12:15,115 --> 01:12:17,395
Speaker 2:  then the thing, and people are probably listening to me, I'm like, you're,

1097
01:12:17,395 --> 01:12:20,355
Speaker 2:  you just wanna break up Google, you hate Google. The thing that is right

1098
01:12:20,355 --> 01:12:24,195
Speaker 2:  next to it is Google is generally terrified of all of this and has gotten

1099
01:12:24,195 --> 01:12:27,835
Speaker 2:  itself into trouble throughout all of these antitrust cases for constantly

1100
01:12:27,835 --> 01:12:30,435
Speaker 2:  deleting emails and like saying things like

1101
01:12:31,265 --> 01:12:35,235
Speaker 2:  antitrust take this chat to private, which is weird. Or the

1102
01:12:35,235 --> 01:12:38,395
Speaker 2:  putting attorney-client privilege at the top of every email even when it's

1103
01:12:38,395 --> 01:12:41,795
Speaker 2:  obviously not attorney-client privileged. Yeah. Like there like If, you can't

1104
01:12:41,795 --> 01:12:45,035
Speaker 2:  talk about your own business without having to say we shouldn't talk about

1105
01:12:45,475 --> 01:12:48,155
Speaker 2:  this. Like something is going wrong

1106
01:12:49,615 --> 01:12:52,795
Speaker 2:  all the way up, all the way up to Shai who is like, we should take this offline.

1107
01:12:52,825 --> 01:12:56,715
Speaker 2:  Like so there's just this overwhelming sense inside of

1108
01:12:56,715 --> 01:13:00,675
Speaker 2:  this case in particular that like the government's gonna just

1109
01:13:00,675 --> 01:13:04,425
Speaker 2:  run it to the end. Yeah. I don't know if that's the sense in the Epic case.

1110
01:13:04,585 --> 01:13:08,305
Speaker 2:  So that's this case. Well again there's another poor Lauren and David are

1111
01:13:08,305 --> 01:13:11,625
Speaker 2:  both gonna have to sit in DC courtrooms some more. They see that coming.

1112
01:13:11,925 --> 01:13:15,885
Speaker 2:  That's just one of the cases. The ad tech case we

1113
01:13:15,885 --> 01:13:18,565
Speaker 2:  can set aside. 'cause nothing has really happened in the past couple weeks.

1114
01:13:18,665 --> 01:13:21,245
Speaker 2:  We think November right for next moves on that one though.

1115
01:13:21,565 --> 01:13:25,405
Speaker 6:  November 25th is when closing arguments are happening.

1116
01:13:25,505 --> 01:13:25,725
Speaker 6:  Ah,

1117
01:13:25,875 --> 01:13:28,965
Speaker 2:  Sick Thanksgiving present for everybody. Yeah. That's gonna be so fun. You

1118
01:13:28,965 --> 01:13:32,205
Speaker 2:  can just be like, you know the judge is like, I, I cannot hear about CPMs

1119
01:13:32,205 --> 01:13:35,885
Speaker 2:  anymore. We're all taking a break and then you can come back and do your

1120
01:13:35,885 --> 01:13:36,725
Speaker 2:  closing arguments.

1121
01:13:38,625 --> 01:13:41,525
Speaker 2:  So that's, that other case is happening over there. That's Google's money.

1122
01:13:41,665 --> 01:13:45,645
Speaker 2:  So that's a big deal. And then there's the Epic case,

1123
01:13:45,645 --> 01:13:49,005
Speaker 2:  which is the weird one. It's like the weird outlier 'cause it wasn't brought

1124
01:13:49,005 --> 01:13:52,085
Speaker 2:  by the government, it was brought by Tim Sweeney epic. They lost against

1125
01:13:52,085 --> 01:13:55,925
Speaker 2:  Apple and basically the same theory, but they super won against

1126
01:13:55,925 --> 01:13:59,685
Speaker 2:  Google because in order to keep the Android ecosystem in line, Google had

1127
01:13:59,685 --> 01:14:03,605
Speaker 2:  to go make contracts. And there's just a huge paper trail

1128
01:14:03,605 --> 01:14:06,245
Speaker 2:  of what those contracts are and what they restrict companies from doing and

1129
01:14:06,245 --> 01:14:09,805
Speaker 2:  how they work. And now we're at the same part where the judge is like, how

1130
01:14:09,805 --> 01:14:13,245
Speaker 2:  do I fix it? And Lauren, it feels like the remedies in this case are their

1131
01:14:13,305 --> 01:14:17,245
Speaker 2:  own kind of extremely complicated multi-port system.

1132
01:14:18,305 --> 01:14:22,085
Speaker 6:  Yes, that is true. And but I guess basically the high level

1133
01:14:22,265 --> 01:14:25,965
Speaker 6:  is that the judge is allowing for other app stores on Android

1134
01:14:26,785 --> 01:14:30,725
Speaker 6:  to have you know, kind of more equal footing with the Play store.

1135
01:14:31,145 --> 01:14:35,045
Speaker 2:  And I think Google has to give the entire catalog of play store apps to other

1136
01:14:35,065 --> 01:14:39,005
Speaker 2:  app stores for three years. Which is just back to that, how

1137
01:14:39,005 --> 01:14:42,365
Speaker 2:  do I make it fair? I'm gonna force this to be fair. Yeah, Google has to

1138
01:14:42,875 --> 01:14:46,765
Speaker 2:  give third party developers access to all the apps

1139
01:14:46,785 --> 01:14:50,645
Speaker 2:  in Google Play and list those third party app

1140
01:14:50,645 --> 01:14:54,525
Speaker 2:  stores in Google Play. So it's this, it turns the app

1141
01:14:54,525 --> 01:14:58,445
Speaker 2:  store into this crazy like, or boros of apps that

1142
01:14:58,445 --> 01:15:02,165
Speaker 2:  you're like, oh you wanna download Instagram? You can do it from 900

1143
01:15:02,225 --> 01:15:06,125
Speaker 2:  places now knock yourself out. But

1144
01:15:06,125 --> 01:15:10,085
Speaker 2:  yeah, I mean there's a lot of like little things also that, that the judge

1145
01:15:10,095 --> 01:15:13,805
Speaker 2:  ruled here. Like there's some of the, the steering or the anti

1146
01:15:14,005 --> 01:15:16,925
Speaker 2:  steering stuff where it's, it's now easier to link to billing outside of

1147
01:15:17,315 --> 01:15:19,965
Speaker 2:  Android with these remedies. There's a lot of,

1148
01:15:22,085 --> 01:15:26,045
Speaker 2:  I guess I would call it like weird contract ness that that's trying to

1149
01:15:26,045 --> 01:15:29,845
Speaker 2:  be undone in terms of like how app revenue gets shared

1150
01:15:30,025 --> 01:15:33,965
Speaker 2:  and what developers get from Google to do things or in some

1151
01:15:33,965 --> 01:15:37,565
Speaker 2:  cases not to do things. But yeah, it seems like basically

1152
01:15:37,955 --> 01:15:41,845
Speaker 2:  what the judge is trying to do here is just say there are a

1153
01:15:41,845 --> 01:15:45,765
Speaker 2:  lot of apps on Android and everyone should have all of them

1154
01:15:46,185 --> 01:15:49,485
Speaker 2:  and they should all be able to peacefully coexist. And that is like

1155
01:15:50,085 --> 01:15:54,005
Speaker 2:  I think a really fascinating UI experiment we're

1156
01:15:54,005 --> 01:15:57,885
Speaker 2:  about to have. Because like I just, I think most people are

1157
01:15:57,885 --> 01:15:59,965
Speaker 2:  going to have trouble figuring out how any of that is actually supposed to

1158
01:15:59,965 --> 01:16:03,845
Speaker 2:  work. But it also does mean If, you run a competitive

1159
01:16:03,845 --> 01:16:07,705
Speaker 2:  app store, you have a lot of new advantages going

1160
01:16:07,705 --> 01:16:11,105
Speaker 2:  for you. Well it's, let me, I mean this case is Epic's case.

1161
01:16:12,505 --> 01:16:16,035
Speaker 2:  They, they're the ones who want all these outcomes. So Epic gets to start

1162
01:16:16,055 --> 01:16:19,955
Speaker 2:  the Epic app store, epic game store on Android. Tim Sweeney has already,

1163
01:16:20,025 --> 01:16:23,835
Speaker 2:  they're gonna do this. Yep. That's gonna have Fortnite in it. Yep. The

1164
01:16:24,075 --> 01:16:27,635
Speaker 2:  argument as far as I can tell, and Lauren correct me if I'm wrong, is the

1165
01:16:27,635 --> 01:16:31,475
Speaker 2:  Epic game store is at a huge disadvantage if the only app and it is Fortnite.

1166
01:16:32,135 --> 01:16:35,635
Speaker 2:  So you need some other apps. Okay Google, you have to give the entire catalog.

1167
01:16:35,785 --> 01:16:38,635
Speaker 2:  Well and If, you can't download the Epic game store through the app store

1168
01:16:38,635 --> 01:16:41,355
Speaker 2:  that comes built into your right without the warning screens. Right. Okay.

1169
01:16:41,575 --> 01:16:45,195
Speaker 2:  So to get the Epic game store, you gotta go through the Play Store. And so

1170
01:16:45,195 --> 01:16:47,835
Speaker 2:  now it feels like it's on par everybody else now you got the Epic game store,

1171
01:16:48,055 --> 01:16:50,795
Speaker 2:  you go in there to get Fortnite and if the only thing in there is Fortnite,

1172
01:16:50,795 --> 01:16:53,835
Speaker 2:  you're never gonna use it again. And Google retains its advantage, they've

1173
01:16:53,835 --> 01:16:57,395
Speaker 2:  just made it harder to get Fortnite. So instead we're gonna demand that Google

1174
01:16:57,395 --> 01:17:00,875
Speaker 2:  give the entire catalog of the Play Store to Epic. So when you open the Epic

1175
01:17:00,875 --> 01:17:04,445
Speaker 2:  game store, you can see all the apps that are available on Android

1176
01:17:05,415 --> 01:17:09,155
Speaker 2:  and Fortnite and Fortnite, but the Play store doesn't get Fortnite.

1177
01:17:09,875 --> 01:17:13,755
Speaker 2:  Yeah, it actually disadvantages the Play store Right. In a lot

1178
01:17:13,755 --> 01:17:17,115
Speaker 2:  of ways because now If, you have an app that is so compelling that you can

1179
01:17:17,115 --> 01:17:18,315
Speaker 2:  pull people into your ecosystem.

1180
01:17:20,375 --> 01:17:24,265
Speaker 2:  It's still gonna be a lot of work and maintenance to build an app store of

1181
01:17:24,265 --> 01:17:28,105
Speaker 2:  your own. But like you now have pretty strong incentives to do it because

1182
01:17:28,305 --> 01:17:29,945
Speaker 2:  there aren't a lot of downsides.

1183
01:17:30,645 --> 01:17:34,545
Speaker 6:  But going back to the search case, you know the Play Store

1184
01:17:34,805 --> 01:17:38,465
Speaker 6:  is preloaded on a lot of Android phones, so

1185
01:17:38,895 --> 01:17:41,625
Speaker 6:  there's still that advantage for the Play store.

1186
01:17:42,015 --> 01:17:45,905
Speaker 2:  Yeah. It just seems like what we're gonna get is Epic gets to launch the

1187
01:17:46,065 --> 01:17:49,875
Speaker 2:  Epic game store and maybe Microsoft will launch a Microsoft

1188
01:17:49,875 --> 01:17:53,475
Speaker 2:  store and maybe Amazon will try again. Maybe

1189
01:17:53,475 --> 01:17:57,195
Speaker 2:  Amazon will notice that it runs the Amazon app store, I dunno the Silk

1190
01:17:57,195 --> 01:18:00,595
Speaker 2:  browser. Yeah. Like and those will become more viable.

1191
01:18:00,905 --> 01:18:04,595
Speaker 2:  Yeah. Because just by default Instagram will be in them as well

1192
01:18:05,215 --> 01:18:06,315
Speaker 2:  in a way that right now

1193
01:18:07,835 --> 01:18:10,115
Speaker 2:  whatever, like they're not gonna go make those deals and they, no one has

1194
01:18:10,115 --> 01:18:13,915
Speaker 2:  any incentive to chase that down. Right. Does that,

1195
01:18:14,025 --> 01:18:15,915
Speaker 2:  does that, does this matter for anybody? But Epic,

1196
01:18:16,715 --> 01:18:20,515
Speaker 6:  I think it matters for any developers that want to make a

1197
01:18:20,775 --> 01:18:24,595
Speaker 6:  app store. But you know, I don't know how

1198
01:18:24,755 --> 01:18:28,555
Speaker 6:  many developers are out there who want that. And I guess it also

1199
01:18:28,555 --> 01:18:31,755
Speaker 6:  matters for developers who want options

1200
01:18:32,335 --> 01:18:36,195
Speaker 6:  to be in other app stores that don't have

1201
01:18:36,195 --> 01:18:37,875
Speaker 6:  the same rules as the Play store.

1202
01:18:38,345 --> 01:18:42,235
Speaker 2:  Yeah. So on on the iOS side, this has been expressed pretty directly, right?

1203
01:18:42,695 --> 01:18:46,675
Speaker 2:  So there's Alt store because the EU mandated alternative app stores

1204
01:18:46,675 --> 01:18:50,555
Speaker 2:  in iOS immediately Alt store came out, the bunch of emulators

1205
01:18:50,555 --> 01:18:54,035
Speaker 2:  showed up and then Apple changed the rules in its app store because of some

1206
01:18:54,035 --> 01:18:57,835
Speaker 2:  competition that has sort of been already like

1207
01:18:57,835 --> 01:19:00,395
Speaker 2:  available on Android. Like you could side load all the stuff in Android.

1208
01:19:00,575 --> 01:19:04,395
Speaker 2:  It hasn't changed the rules of the Play store. So is it that

1209
01:19:04,445 --> 01:19:08,365
Speaker 2:  we'll have another app store with more permissive rules about

1210
01:19:08,365 --> 01:19:12,285
Speaker 2:  what's allowed or better payment splits? I don't know,

1211
01:19:12,285 --> 01:19:15,885
Speaker 2:  like this one because Android was already openish, it's like a weird

1212
01:19:17,315 --> 01:19:21,245
Speaker 2:  paradox of this case. Yeah. Like because Google doesn't control the

1213
01:19:21,245 --> 01:19:24,725
Speaker 2:  ecosystem, the evidence of it trying to control the ecosystem is much more

1214
01:19:24,725 --> 01:19:27,685
Speaker 2:  available. 'cause it's just like sending emails to Samsung being like, we

1215
01:19:27,685 --> 01:19:31,405
Speaker 2:  control your phone. Well, and there were a couple of things that Epic

1216
01:19:31,545 --> 01:19:35,165
Speaker 2:  was asking for that it didn't get, that I think might have potentially been

1217
01:19:35,165 --> 01:19:39,045
Speaker 2:  bigger deals. Like one of their things, I forget exactly how they expressed

1218
01:19:39,045 --> 01:19:42,325
Speaker 2:  it, but the idea was basically you should be able to side load an app as

1219
01:19:42,325 --> 01:19:44,845
Speaker 2:  easily as you can download an app from the play store. And they didn't get

1220
01:19:44,845 --> 01:19:48,045
Speaker 2:  that. And if they've gotten that, that becomes a big deal because now,

1221
01:19:48,785 --> 01:19:52,685
Speaker 2:  and it just becomes trivially easy to distribute an Android app

1222
01:19:52,795 --> 01:19:56,645
Speaker 2:  outside of any app store. Yeah. And that becomes very powerful for lots of

1223
01:19:56,645 --> 01:19:59,925
Speaker 2:  good and bad reasons. And then there was the one where they wanted

1224
01:20:00,665 --> 01:20:04,565
Speaker 2:  to decouple a lot of the Android APIs from Google Play so

1225
01:20:04,565 --> 01:20:08,005
Speaker 2:  that in theory you could buy a device that has the full Android experience

1226
01:20:08,025 --> 01:20:11,685
Speaker 2:  except it doesn't have Google play at all. And so then if you're Epic,

1227
01:20:12,465 --> 01:20:16,285
Speaker 2:  you sell a gaming handheld that is full Android but only the Epic game store

1228
01:20:16,525 --> 01:20:19,805
Speaker 2:  or something like it, right? Like you can see how you get down the road from

1229
01:20:19,805 --> 01:20:23,085
Speaker 2:  that. I think the world in which we're

1230
01:20:23,575 --> 01:20:27,045
Speaker 2:  gonna live, which is that the Play store is still very powerful and still

1231
01:20:27,045 --> 01:20:30,085
Speaker 2:  exists. You just have more control inside of it.

1232
01:20:30,955 --> 01:20:34,285
Speaker 2:  That one feels a little, a little less obvious to me. And I think

1233
01:20:34,985 --> 01:20:38,605
Speaker 2:  one weird possible outcome of all of this is that you get some of the big

1234
01:20:38,765 --> 01:20:42,645
Speaker 2:  companies you're talking about, like in theory Microsoft and Meta

1235
01:20:43,065 --> 01:20:46,765
Speaker 2:  and a handful of other companies are powerful enough to say

1236
01:20:47,625 --> 01:20:50,565
Speaker 2:  we are doing our own app store. We're not, we're not gonna play the rest

1237
01:20:50,585 --> 01:20:54,325
Speaker 2:  of your games and we're gonna offer you better terms If, you come buy apps

1238
01:20:54,355 --> 01:20:57,285
Speaker 2:  from our store instead of the play store or whatever. And then you start

1239
01:20:57,285 --> 01:21:01,085
Speaker 2:  to have real weird tiers of competition inside of

1240
01:21:01,085 --> 01:21:04,045
Speaker 2:  Android where like, I'm gonna get to the point as a user where I have to

1241
01:21:04,205 --> 01:21:07,685
Speaker 2:  download five app stores just to have my side. And that sucks. Like that's

1242
01:21:07,685 --> 01:21:11,605
Speaker 2:  a bad consumer outcome and that is what Google has been railing against

1243
01:21:11,605 --> 01:21:15,315
Speaker 2:  this whole time. And I think that is a reasonable part of its defense. But

1244
01:21:15,315 --> 01:21:18,835
Speaker 2:  the truth is, I, I just think Epic got what it wanted. Yeah. Which is we

1245
01:21:18,835 --> 01:21:22,675
Speaker 2:  can do Fortnite on our own terms and there's gonna be a lot of fallout,

1246
01:21:22,975 --> 01:21:26,885
Speaker 2:  but I don't think there are that many epics out there.

1247
01:21:27,025 --> 01:21:29,285
Speaker 2:  You know what I mean? What we'll see, even the way that there are a million

1248
01:21:29,285 --> 01:21:32,885
Speaker 2:  search engines that would like to be powerful. I don't know that there are

1249
01:21:34,215 --> 01:21:38,135
Speaker 2:  a million other Epic, well there's a Sony, there's a Microsoft, there's a

1250
01:21:38,135 --> 01:21:40,175
Speaker 2:  bunch of game companies that really watch, there are a bunch of game companies.

1251
01:21:41,435 --> 01:21:44,575
Speaker 2:  I'm just saying that the little with a weird paradox here is because it was

1252
01:21:44,575 --> 01:21:45,015
Speaker 2:  already open

1253
01:21:46,595 --> 01:21:50,495
Speaker 2:  to control it, Google had to do a bunch of aggressive stuff that created

1254
01:21:50,495 --> 01:21:53,735
Speaker 2:  the evidence that is like, now you have to be more open. Which is weird.

1255
01:21:54,075 --> 01:21:57,935
Speaker 2:  And I can tell you because I had this exact reaction, a bunch of our listeners

1256
01:21:58,115 --> 01:22:01,575
Speaker 2:  are screaming in their cars right now that it is already somewhat trivial

1257
01:22:01,575 --> 01:22:05,255
Speaker 2:  to download an a PK an Android phone outside of an app store. Sure. Right.

1258
01:22:05,255 --> 01:22:08,615
Speaker 2:  And that it's weird 'cause that openness exists. When Sonos was broken,

1259
01:22:09,215 --> 01:22:12,455
Speaker 2:  I just got the AP PK of the old version of the Sonos app and my Sonos was

1260
01:22:12,455 --> 01:22:16,055
Speaker 2:  fine for a week. It's easier, but you can't go to a website tap install this

1261
01:22:16,055 --> 01:22:19,135
Speaker 2:  app on my phone and it installs the app on your phone. You can, but you also

1262
01:22:19,135 --> 01:22:22,775
Speaker 2:  have to accidentally run like a Bitcoin mining scam. That's fine.

1263
01:22:23,935 --> 01:22:27,295
Speaker 2:  Actually you brought up Google's responses to this, Lauren, I'm looking at

1264
01:22:27,295 --> 01:22:30,895
Speaker 2:  a blog post that from Google that says do j's radical and sweeping proposals,

1265
01:22:30,895 --> 01:22:34,295
Speaker 2:  risk hurting consumers, businesses and developers. That seems like it's sums

1266
01:22:34,295 --> 01:22:37,655
Speaker 2:  up the response, but you've been doing some reporting, you've read this more

1267
01:22:37,655 --> 01:22:39,695
Speaker 2:  closely than I have. What is Google's response to all this?

1268
01:22:40,165 --> 01:22:44,055
Speaker 6:  Yeah, that's their response to the, the search remedies

1269
01:22:44,215 --> 01:22:48,015
Speaker 6:  I believe. And yeah, they, they basically think,

1270
01:22:48,035 --> 01:22:51,535
Speaker 6:  you know, this is a big overreach. You know, this case is about,

1271
01:22:52,475 --> 01:22:56,375
Speaker 6:  you know, a a set of search distribution contracts and

1272
01:22:56,395 --> 01:23:00,295
Speaker 6:  you know, here's the government going and like reaching out into all these

1273
01:23:00,295 --> 01:23:04,055
Speaker 6:  different businesses that it has. And you know, this is, you know, really

1274
01:23:04,055 --> 01:23:07,965
Speaker 6:  going beyond what this case is about. So I

1275
01:23:07,965 --> 01:23:11,845
Speaker 6:  think, you know, we're gonna be seeing a lot more from them. I

1276
01:23:11,845 --> 01:23:15,725
Speaker 6:  believe they have to file something about

1277
01:23:15,725 --> 01:23:19,645
Speaker 6:  their response at some point. So, you know, I think we're not gonna

1278
01:23:19,905 --> 01:23:23,645
Speaker 6:  really see them backing down from this and they have to go through this remedies

1279
01:23:23,655 --> 01:23:27,605
Speaker 6:  phase before they can appeal. But I think we're gonna

1280
01:23:27,605 --> 01:23:29,165
Speaker 6:  see a big fight from them down the road.

1281
01:23:29,595 --> 01:23:33,285
Speaker 2:  Yeah. Am I being too hard on Google to just read this blog post as Google

1282
01:23:33,285 --> 01:23:37,045
Speaker 2:  yelling, but privacy over and over and over? They do kind of yell,

1283
01:23:37,065 --> 01:23:41,005
Speaker 2:  but China once in here, but mostly it seems to me that they're

1284
01:23:41,005 --> 01:23:44,925
Speaker 2:  just like, it's all the stuff that we've been saying, the the judges

1285
01:23:45,025 --> 01:23:47,205
Speaker 2:  in these cases are not finding compelling.

1286
01:23:47,525 --> 01:23:51,325
Speaker 6:  I think it, it's privacy, it's, you know, we're gonna hold

1287
01:23:51,325 --> 01:23:55,165
Speaker 6:  back American innovation and also just this is a

1288
01:23:55,165 --> 01:23:58,165
Speaker 6:  big overreach, So I think those are kind of some of their key

1289
01:23:59,405 --> 01:24:00,525
Speaker 6:  arguments here. Yeah.

1290
01:24:00,525 --> 01:24:04,165
Speaker 2:  They also say that if Android and Chrome were their own companies,

1291
01:24:04,605 --> 01:24:08,535
Speaker 2:  there would be no incentive to keep them open source, which is a, a

1292
01:24:08,535 --> 01:24:12,495
Speaker 2:  big deal. And I feel like we could make a hard left turn in talking

1293
01:24:12,495 --> 01:24:14,935
Speaker 2:  about WordPress right now, but we should not do that. We should not do that.

1294
01:24:15,675 --> 01:24:18,495
Speaker 2:  But there's a lot there that, that Google's response to this will, we'll

1295
01:24:18,495 --> 01:24:19,055
Speaker 2:  link the blog

1296
01:27:52,705 --> 01:27:55,365
Speaker 2:  Hey, we gotta take a break, Lauren, stick around. We want you on the lightning

1297
01:27:55,365 --> 01:27:57,685
Speaker 2:  round with us. Sounds good. All right, we'll be right back.

1298
01:28:02,305 --> 01:28:04,845
Speaker 2:  All right, we're back. Unsponsored lightning round.

1299
01:28:06,075 --> 01:28:09,605
Speaker 2:  It's never gonna happen. We've gotten some very nice emails, but I'm not

1300
01:28:09,605 --> 01:28:10,325
Speaker 2:  allowed to make the deals.

1301
01:28:11,925 --> 01:28:15,765
Speaker 2:  I just walk into rooms of Vox Media demanding and no one, no one takes

1302
01:28:15,765 --> 01:28:16,605
Speaker 2:  me seriously for

1303
01:28:16,605 --> 01:28:19,805
Speaker 1:  All you guys know, this is a sponsored lightning round. I, I won't tell you

1304
01:28:19,865 --> 01:28:23,725
Speaker 2:  That's true. That's true. Sponsored by Liam. Alright,

1305
01:28:24,375 --> 01:28:27,525
Speaker 2:  David, you're gonna start with the first one. It's, it's another Google story,

1306
01:28:27,525 --> 01:28:31,205
Speaker 2:  but I will tell you one, it's a pallet cleanser and two shockingly

1307
01:28:31,365 --> 01:28:35,125
Speaker 2:  popular story. Okay. Not shocking because it's the greatest

1308
01:28:35,195 --> 01:28:38,805
Speaker 2:  news in, in years

1309
01:28:39,705 --> 01:28:43,245
Speaker 2:  If, you are a person who cares about your documents and, and don't we all

1310
01:28:43,245 --> 01:28:47,085
Speaker 2:  care about our documents. So Google announced this feature

1311
01:28:47,145 --> 01:28:50,925
Speaker 2:  in April and I completely miss it, but is now rolling out a thing

1312
01:28:51,315 --> 01:28:55,165
Speaker 2:  that basically it's the docs equivalent of the thing

1313
01:28:55,385 --> 01:28:59,005
Speaker 2:  in Sheets or Excel where you can have sort of multiple tabs open

1314
01:28:59,395 --> 01:29:03,285
Speaker 2:  that, that kind of interact with each other. It's, it's just a pain

1315
01:29:03,285 --> 01:29:07,165
Speaker 2:  on the side that you can open tabs and sub tabs,

1316
01:29:07,165 --> 01:29:10,045
Speaker 2:  but it's essentially like having multiple documents inside of one document.

1317
01:29:11,275 --> 01:29:14,005
Speaker 2:  Does that sound like a big deal to you? That will completely change your

1318
01:29:14,005 --> 01:29:17,845
Speaker 2:  life? You're wrong. 'cause it is and it will, this is as

1319
01:29:17,885 --> 01:29:21,725
Speaker 2:  a, as a person who creates infinite Google Docs.

1320
01:29:21,725 --> 01:29:25,485
Speaker 2:  Yeah. For my job, this is the greatest thing that has ever happened to me.

1321
01:29:26,865 --> 01:29:30,265
Speaker 2:  I knew it was a big deal when I saw Wired staffers who I know and love

1322
01:29:30,815 --> 01:29:34,145
Speaker 2:  like freaking out on threads about our story about it. Yeah. Because they

1323
01:29:34,145 --> 01:29:37,745
Speaker 2:  like immediately needed to share it. So the thing that's great about this

1324
01:29:37,845 --> 01:29:41,705
Speaker 2:  is a thing that is more and more popular all

1325
01:29:41,705 --> 01:29:45,505
Speaker 2:  the time it seems is the like public Google document. Yes. More and more

1326
01:29:45,505 --> 01:29:48,585
Speaker 2:  you're, you're seeing like there's a great newsletter that I subscribe to

1327
01:29:48,585 --> 01:29:52,505
Speaker 2:  that the newsletter every month is just a link to a Google doc and you go

1328
01:29:52,505 --> 01:29:55,385
Speaker 2:  read the Google Doc and it's kind of a great experience. This is, it's great

1329
01:29:55,385 --> 01:29:58,825
Speaker 2:  for navigation, it's great for putting lots of docs together. There has been

1330
01:29:58,825 --> 01:30:02,145
Speaker 2:  that table of contents thing you can do on the side where it'll let you just

1331
01:30:02,145 --> 01:30:05,785
Speaker 2:  jump from header to header. This is just that, but like better

1332
01:30:05,965 --> 01:30:09,425
Speaker 2:  and more navigable and less awful on big

1333
01:30:09,705 --> 01:30:13,265
Speaker 2:  documents. But I think it, it's Google Docs is like

1334
01:30:13,455 --> 01:30:17,185
Speaker 2:  used for a lot of really interesting things. Public docs are everywhere.

1335
01:30:17,215 --> 01:30:20,945
Speaker 2:  It's a super collaborative thing. I see things where like groups of hundreds

1336
01:30:20,945 --> 01:30:24,825
Speaker 2:  of people are like planning things together in a single Google doc and like

1337
01:30:25,135 --> 01:30:28,505
Speaker 2:  this is a, a kind of structure that Docs has just never had and is going

1338
01:30:28,505 --> 01:30:31,985
Speaker 2:  to make a lot of type A people very, very happy and they are very happy,

1339
01:30:31,985 --> 01:30:35,625
Speaker 2:  they're so happy. They are just reading and sharing the story. We, if we

1340
01:30:35,625 --> 01:30:38,465
Speaker 2:  did nothing but write about tabs and Google Docs the rest of the year, we'd

1341
01:30:38,465 --> 01:30:41,625
Speaker 2:  be set. It's real. And that's what we're doing. It's Google antitrust and

1342
01:30:41,625 --> 01:30:44,145
Speaker 2:  tabs and Google docs. You could make com you can make them emojis.

1343
01:30:45,755 --> 01:30:49,205
Speaker 2:  When I was a a just a pup, there was this piece of software that came with

1344
01:30:49,205 --> 01:30:53,165
Speaker 2:  almost every mat called HyperCard and it was, I don't

1345
01:30:53,165 --> 01:30:56,845
Speaker 2:  even know how to describe it. It was the internet, but local and expressed

1346
01:30:56,845 --> 01:31:00,325
Speaker 2:  as like virtual index cards. And you could like program hyper, they were

1347
01:31:00,325 --> 01:31:02,885
Speaker 2:  called stacks. You could program hyper card stacks. Some of our audience

1348
01:31:02,885 --> 01:31:04,805
Speaker 2:  is freaking out 'cause know what we're talking about when I tell you other

1349
01:31:04,805 --> 01:31:07,725
Speaker 2:  people think I sound like an ancient wizard. This involves hyper cards in

1350
01:31:07,725 --> 01:31:11,485
Speaker 2:  a surprisingly me meaningful way. This is just HyperCard. Oh, a hundred percent.

1351
01:31:11,485 --> 01:31:14,085
Speaker 2:  Google's making HyperCard. Yeah, they're turning Google Docs into HyperCard.

1352
01:31:14,585 --> 01:31:18,325
Speaker 2:  Or if another less successful comparison Google

1353
01:31:18,355 --> 01:31:21,885
Speaker 2:  wave. Ooh, they're doing just the modular. That's good. I mean, Google has

1354
01:31:21,885 --> 01:31:24,885
Speaker 2:  been trying to do Google wave in various forms for an extremely, we gotta

1355
01:31:24,885 --> 01:31:28,735
Speaker 2:  just Google, it's an impossible thing to Google, to Google the word Google

1356
01:31:28,875 --> 01:31:32,775
Speaker 2:  and the word wave. It's hard. We'll, we'll find a link to some ancient

1357
01:31:32,975 --> 01:31:36,495
Speaker 2:  coverage or this thing Google made. Yeah. years ago it was like, what if

1358
01:31:36,495 --> 01:31:39,815
Speaker 2:  we blew up all, all email and docs and it was all the same thing and no one

1359
01:31:39,815 --> 01:31:42,415
Speaker 2:  could figure it out. And now we're, we're just back. Lauren, are you as excited

1360
01:31:42,415 --> 01:31:43,695
Speaker 2:  about tabs as I am? Be honest,

1361
01:31:44,535 --> 01:31:47,855
Speaker 6:  I can't say I am the person who has like a million

1362
01:31:48,355 --> 01:31:50,175
Speaker 6:  chrome tabs open at the same time.

1363
01:31:50,635 --> 01:31:51,455
Speaker 2:  You guys are the problem.

1364
01:31:52,315 --> 01:31:56,295
Speaker 1:  As someone who's somehow missed a story, I'm like freaking out in the

1365
01:31:56,295 --> 01:31:58,655
Speaker 1:  control. I'm so excited. There are

1366
01:31:58,845 --> 01:32:01,245
Speaker 2:  Workflows in my head right now that are now possible.

1367
01:32:02,665 --> 01:32:06,585
Speaker 2:  I'm gonna just share. Was that a threat? William just threatened us.

1368
01:32:06,585 --> 01:32:09,345
Speaker 2:  Yeah, he did. All right. We're toast. It's lightning around. We gotta move

1369
01:32:09,345 --> 01:32:12,505
Speaker 2:  on. Yeah. All right. Lauren, what do you got? Next tab? Yeah,

1370
01:32:12,785 --> 01:32:16,585
Speaker 6:  Next tab. Yeah, I mean we sure everyone

1371
01:32:16,585 --> 01:32:19,905
Speaker 6:  heard there was a major hurricane in Florida this week

1372
01:32:21,325 --> 01:32:25,225
Speaker 6:  and FEMA is out there cleaning up, fighting

1373
01:32:26,405 --> 01:32:30,225
Speaker 6:  the storm and also now fighting disinformation about the

1374
01:32:30,225 --> 01:32:33,945
Speaker 6:  storm as well, including some false claims spread by

1375
01:32:34,165 --> 01:32:38,105
Speaker 6:  former President Trump. And you know, I think

1376
01:32:38,375 --> 01:32:41,905
Speaker 6:  FEMA kind of always knew this was gonna be a problem, but the FEMA

1377
01:32:41,905 --> 01:32:44,825
Speaker 6:  administrator said, this is absolutely the worst I've ever seen

1378
01:32:45,835 --> 01:32:48,865
Speaker 6:  about misinformation around the storms recently.

1379
01:32:50,285 --> 01:32:53,985
Speaker 6:  So, you know, it's just kind of wild that they've had to do all this

1380
01:32:54,265 --> 01:32:58,065
Speaker 6:  fact checking while just trying to literally

1381
01:32:58,275 --> 01:33:00,585
Speaker 6:  clean up a major disaster.

1382
01:33:01,425 --> 01:33:04,905
Speaker 2:  I think we did a, a link to a Rolling Stone story on the homepage today,

1383
01:33:05,175 --> 01:33:08,385
Speaker 2:  just about meteorologists who are getting death threats because people believe

1384
01:33:08,385 --> 01:33:11,505
Speaker 2:  they can control the weather. Marjorie Taylor Greene out there saying that

1385
01:33:11,505 --> 01:33:15,385
Speaker 2:  they can control the weather. Oh great. Which is an incredible

1386
01:33:16,055 --> 01:33:19,845
Speaker 2:  like retcon of climate change. Like do you

1387
01:33:20,185 --> 01:33:23,485
Speaker 2:  Yes, it's true. We can control the weather just not the way that you think.

1388
01:33:23,865 --> 01:33:27,405
Speaker 2:  It just takes 40 years of burning fossil fuels. It's true.

1389
01:33:27,865 --> 01:33:30,925
Speaker 2:  We did in fact control the weather in one very specific way.

1390
01:33:32,725 --> 01:33:36,005
Speaker 2:  I, I don't know, If, you, we've run a bunch of stories about just moderation,

1391
01:33:36,005 --> 01:33:39,805
Speaker 2:  failures lately, like threads moderation is way too heavy handed. Yep.

1392
01:33:39,865 --> 01:33:43,605
Speaker 2:  It appears to be partially AI driven in a way that no one can control

1393
01:33:43,665 --> 01:33:47,605
Speaker 2:  at least of all the people at Meta X obviously not moderating any of

1394
01:33:47,605 --> 01:33:51,525
Speaker 2:  this misinformation. It is weird to be in a social media

1395
01:33:51,525 --> 01:33:54,925
Speaker 2:  environment where I'm like, they did kind of a good job during covid

1396
01:33:55,115 --> 01:33:58,685
Speaker 2:  because they, they didn't like that was a nightmare.

1397
01:33:59,425 --> 01:34:03,125
Speaker 2:  And this is so much worse and it feels like people are going

1398
01:34:03,195 --> 01:34:07,085
Speaker 2:  even one step farther away from reality into

1399
01:34:07,875 --> 01:34:11,725
Speaker 2:  they're controlling the weather in Florida to influence the election.

1400
01:34:13,085 --> 01:34:16,805
Speaker 2:  I I, I mean all of, like, I I don't think we were doing a great

1401
01:34:16,865 --> 01:34:20,855
Speaker 2:  job when we were bringing Jack Dorsey

1402
01:34:20,855 --> 01:34:24,815
Speaker 2:  in front of Congress so that people could yell at him and then bad

1403
01:34:24,815 --> 01:34:28,295
Speaker 2:  tweets and then people were yelling at Mark Zuckerberg about Twitter. Like

1404
01:34:28,365 --> 01:34:31,135
Speaker 2:  Yeah. That accomplished broadly nothing. I think Lauren,

1405
01:34:32,675 --> 01:34:36,615
Speaker 2:  you covered all that. Not nothing, nothing was accomplished and some

1406
01:34:36,615 --> 01:34:39,735
Speaker 2:  weird first Amendment problems there, but it taught these companies that

1407
01:34:39,735 --> 01:34:43,655
Speaker 2:  what if doing nothing was a more viable strategy and now it feels like we're

1408
01:34:43,655 --> 01:34:46,495
Speaker 2:  just reaping the dividend of doing nothing.

1409
01:34:47,205 --> 01:34:50,935
Speaker 6:  Well it feels like these companies are just very reactionary

1410
01:34:51,075 --> 01:34:55,055
Speaker 6:  and it's like being like yelled at as a kid and

1411
01:34:55,075 --> 01:34:59,045
Speaker 6:  at first you're like, oh, I need to do better. I need

1412
01:34:59,045 --> 01:35:02,885
Speaker 6:  to like do what I'm being asked. And then they're like become

1413
01:35:02,885 --> 01:35:06,085
Speaker 6:  adolescents and are like, wait a minute, why am I just following what you

1414
01:35:06,085 --> 01:35:09,765
Speaker 6:  save? It seems like it gets me in more trouble. And then they decide to back

1415
01:35:09,765 --> 01:35:09,965
Speaker 6:  off.

1416
01:35:10,745 --> 01:35:13,645
Speaker 2:  By the way, that is a perfect description of Mark Zuckerberg and his T-shirts

1417
01:35:13,645 --> 01:35:17,285
Speaker 2:  and chains and seriously flowy, like flowing

1418
01:35:17,355 --> 01:35:20,525
Speaker 2:  logs. Like he's in his adolescent phase of like, eh, screw you.

1419
01:35:21,235 --> 01:35:24,205
Speaker 2:  Well, and I remember yeah, we, we were talking a couple of years ago about

1420
01:35:24,205 --> 01:35:27,965
Speaker 2:  like all of these companies, a few of them in

1421
01:35:27,965 --> 01:35:31,925
Speaker 2:  particular made a real show of doing their

1422
01:35:31,925 --> 01:35:35,885
Speaker 2:  best and trying their hardest and decided that it accomplished nothing Yeah.

1423
01:35:36,105 --> 01:35:40,005
Speaker 2:  For them, for their image. And, and, and we

1424
01:35:40,005 --> 01:35:42,125
Speaker 2:  were even wondering, we were like, okay, what's it gonna look like when they

1425
01:35:42,125 --> 01:35:46,005
Speaker 2:  decide that actually the, the penalty for not caring and

1426
01:35:46,005 --> 01:35:48,485
Speaker 2:  the penalty for caring are basically the same and they're just gonna decide

1427
01:35:48,485 --> 01:35:50,805
Speaker 2:  to not care. No, I'm saying it's worse right now.

1428
01:35:53,645 --> 01:35:57,625
Speaker 2:  It is worse. The penalty for caring was worse

1429
01:35:57,625 --> 01:36:01,545
Speaker 2:  than the penalty for not caring in the world, but they are

1430
01:36:01,545 --> 01:36:04,025
Speaker 2:  paying less of a penalty. They are in their bunkers. That's what I mean.

1431
01:36:04,085 --> 01:36:07,225
Speaker 2:  And on their mega yachts. Right. And they are not paying any price for like

1432
01:36:07,575 --> 01:36:10,985
Speaker 2:  fake AI generated photos of like children with puppies

1433
01:36:11,655 --> 01:36:15,635
Speaker 2:  that don't exist. They're like, oh, this is fine. Right. Whereas

1434
01:36:15,635 --> 01:36:18,875
Speaker 2:  when they tried, they got yelled at. Exactly. That's exactly. And the incentive

1435
01:36:19,155 --> 01:36:22,075
Speaker 2:  structure is like totally backwards. Yes, a hundred percent. And they're

1436
01:36:22,075 --> 01:36:25,795
Speaker 2:  like, we, we have now reached a point where the all of their incentives

1437
01:36:25,855 --> 01:36:28,875
Speaker 2:  are to not try and, and now we know what it looks like. Right. It turns out

1438
01:36:28,935 --> 01:36:32,635
Speaker 2:  trying and failing. And I think we all pretty much agree that content moderation

1439
01:36:32,635 --> 01:36:36,475
Speaker 2:  is a completely unwinnable game and all you can do is try and fail as

1440
01:36:36,585 --> 01:36:40,115
Speaker 2:  well as possible that trying and failing

1441
01:36:40,695 --> 01:36:44,635
Speaker 2:  gained them nothing and they might as well just give up and not care and

1442
01:36:44,705 --> 01:36:48,395
Speaker 2:  wear t-shirts and here we are and it's awful. It is.

1443
01:36:48,505 --> 01:36:52,315
Speaker 2:  It's, I would say the hurricane misinformation story is, it might be a

1444
01:36:52,435 --> 01:36:56,355
Speaker 2:  defining story in, in like the history of media. Like it was just

1445
01:36:56,355 --> 01:36:59,275
Speaker 2:  fully outta control. I mean the the other aspect of that that I, I don't

1446
01:36:59,275 --> 01:37:02,915
Speaker 2:  know If, you guys have seen this, but like all of my feeds everywhere are

1447
01:37:02,915 --> 01:37:06,715
Speaker 2:  just creators in Florida who stayed and, and are like

1448
01:37:06,715 --> 01:37:10,635
Speaker 2:  making a show out of not going. Some of them are like outside trying

1449
01:37:10,635 --> 01:37:13,395
Speaker 2:  to sort of journalism the hurricane. But then there's one guy I keep finding

1450
01:37:13,455 --> 01:37:16,515
Speaker 2:  who just wears a headlamp and is just like walking around his house being

1451
01:37:16,515 --> 01:37:19,395
Speaker 2:  like, seems bad. I'm in the eye. I don't care.

1452
01:37:20,415 --> 01:37:23,115
Speaker 2:  And he just has a headlamp and that's, that's like I've seen like 50 of his

1453
01:37:23,115 --> 01:37:26,595
Speaker 2:  baby. We don't have the time to do David and Neil Eli talk about

1454
01:37:26,595 --> 01:37:30,355
Speaker 2:  journalism and really never do we have the time and nor

1455
01:37:30,355 --> 01:37:33,875
Speaker 2:  should we on the show, but drawing the difference between that and Anderson

1456
01:37:33,875 --> 01:37:37,795
Speaker 2:  Cooper being like, it's pretty bad. Yeah. Actually pretty hard to do. That's

1457
01:37:37,795 --> 01:37:41,475
Speaker 2:  what I mean. You can journalism the hurricane just by going outside the hurricane.

1458
01:37:42,415 --> 01:37:46,315
Speaker 2:  Can I get it? It's like they're like, I'm staying here to do, to get eyeballs

1459
01:37:46,535 --> 01:37:50,435
Speaker 2:  and Anderson Cooper's like I'm going there to get eyeballs. And it's a

1460
01:37:50,505 --> 01:37:54,355
Speaker 2:  very fine line between those two things. A hundred percent. I do think

1461
01:37:54,355 --> 01:37:58,125
Speaker 2:  these, the platforms are, they've dropped the ball and I, I don't know,

1462
01:37:58,325 --> 01:38:01,885
Speaker 2:  I, I've, all of every vir house listener knows how I feel about the first

1463
01:38:01,885 --> 01:38:04,765
Speaker 2:  amendment, which is everyone else seems to be sick of it. And I think that's

1464
01:38:04,765 --> 01:38:08,285
Speaker 2:  a worrying trend. Like we're banning books and

1465
01:38:09,045 --> 01:38:12,525
Speaker 2:  everyone has bad, everyone's screaming fire in a crowd at theater. Tim Walls

1466
01:38:12,545 --> 01:38:16,085
Speaker 2:  of the debate just randomly blurted it out for no reason. And our entire

1467
01:38:16,085 --> 01:38:19,725
Speaker 2:  newsroom, you saw our entire slack. Everybody's like, no.

1468
01:38:20,595 --> 01:38:23,885
Speaker 2:  Like, I don't know what's going on. It's, it's all bad. But the idea that

1469
01:38:23,885 --> 01:38:27,845
Speaker 2:  our social networks are actually, they actually have an important social

1470
01:38:28,245 --> 01:38:32,125
Speaker 2:  function in our society to try to get accurate information out and not

1471
01:38:32,125 --> 01:38:32,925
Speaker 2:  amplify lies.

1472
01:38:34,475 --> 01:38:38,045
Speaker 2:  They just let go. Not going great. Super let go. Yeah. Alright. I'm gonna

1473
01:38:38,045 --> 01:38:41,805
Speaker 2:  try to clean this up. Yeah. I'm gonna try to end us on a high note. That's

1474
01:38:41,805 --> 01:38:45,285
Speaker 2:  my goal. Okay. Here's the high note. Several months ago, the CEO E of Zoom

1475
01:38:45,635 --> 01:38:48,245
Speaker 2:  came on coder and he said, here's my dream.

1476
01:38:49,465 --> 01:38:52,845
Speaker 2:  All of your Zoom meetings will have AI clones in them. Digital twins.

1477
01:38:53,105 --> 01:38:57,045
Speaker 2:  You're gonna clone yourself and then that clone will go to

1478
01:38:57,045 --> 01:39:00,685
Speaker 2:  the zoom meeting for you while you sit on a beach and drink a daiquiri. And

1479
01:39:00,685 --> 01:39:03,125
Speaker 2:  I was like, how many clones do I have? Could I have 10,000? And he was like,

1480
01:39:03,125 --> 01:39:06,805
Speaker 2:  as many as you want. Unclear how any of this will work. Unclear if he was

1481
01:39:06,925 --> 01:39:10,845
Speaker 2:  building, unclear how, if he had the technology to do it.

1482
01:39:11,885 --> 01:39:15,805
Speaker 2:  I dunno, there were some great YouTube videos made about that specific

1483
01:39:15,805 --> 01:39:18,125
Speaker 2:  interview. Sure. We'll link it.

1484
01:39:20,075 --> 01:39:23,885
Speaker 2:  Zoom has announced AI avatars can talk to your

1485
01:39:23,885 --> 01:39:27,725
Speaker 2:  team on your behalf. The first step towards our goal of

1486
01:39:27,825 --> 01:39:31,645
Speaker 2:  1000 digital neli going to meetings across Fox Media,

1487
01:39:32,035 --> 01:39:35,965
Speaker 2:  demanding to have the lightning round sponsored, but now it's one

1488
01:39:35,965 --> 01:39:38,965
Speaker 2:  digital neli. Yep. I feel like one's too many

1489
01:39:39,955 --> 01:39:42,925
Speaker 2:  Zoom announced. It will soon let you create an AI avatar of yourself that

1490
01:39:42,925 --> 01:39:46,805
Speaker 2:  you can use to send brief messages to your team. And the only message

1491
01:39:47,005 --> 01:39:50,045
Speaker 2:  I wanna send is, when is the lightning round getting sponsored? And I would

1492
01:39:50,045 --> 01:39:52,805
Speaker 2:  like my AI avatar to attend every single meeting at this company.

1493
01:39:53,835 --> 01:39:57,415
Speaker 2:  Ugh. This is nothing you need to, you need to record an initial video of

1494
01:39:57,535 --> 01:40:00,415
Speaker 2:  yourself that Zoom's AI will use to make an avatar that looks even sounds

1495
01:40:00,415 --> 01:40:03,095
Speaker 2:  like you. From there you can write the message you want your avatar to say

1496
01:40:03,095 --> 01:40:06,855
Speaker 2:  and then have it go to meetings and say it. It's voicemail.

1497
01:40:06,855 --> 01:40:09,055
Speaker 2:  It's the same amount of work. It's the same amount

1498
01:40:09,055 --> 01:40:11,175
Speaker 6:  Of work is doing it. Feel like this could have been an email,

1499
01:40:11,915 --> 01:40:15,855
Speaker 2:  Liz. Seriously. And I'm gonna have my AI avatar go to every meeting and

1500
01:40:15,855 --> 01:40:17,015
Speaker 2:  say, this could have been an email.

1501
01:40:18,785 --> 01:40:22,635
Speaker 2:  Okay. A, that's a pretty good idea. B, I have come around to the idea

1502
01:40:22,665 --> 01:40:26,395
Speaker 2:  that actually the solution to our AI problem

1503
01:40:26,735 --> 01:40:30,715
Speaker 2:  is to just ban meetings. Everybody is like, we're gonna make a

1504
01:40:30,715 --> 01:40:33,155
Speaker 2:  thing so that you don't have to go to a meeting, just don't have the meeting.

1505
01:40:33,545 --> 01:40:37,515
Speaker 2:  This is uncomplicated. No 1000 digital AI avatars all having meetings

1506
01:40:37,515 --> 01:40:40,915
Speaker 2:  with each other while we sip daries in the beach. This is the future of the

1507
01:40:40,915 --> 01:40:44,875
Speaker 2:  information economy. Or don't have meetings just daiquiris,

1508
01:40:44,985 --> 01:40:47,715
Speaker 2:  just the daiquiri parts and no meetings. But

1509
01:40:47,715 --> 01:40:51,515
Speaker 6:  Then you have to have a meeting with your AI avatar to learn what happened,

1510
01:40:51,685 --> 01:40:52,355
Speaker 6:  which feels

1511
01:40:52,355 --> 01:40:56,325
Speaker 2:  Worse. It he I would say Eric did not. Yeah. I go from having

1512
01:41:56,595 --> 01:42:00,535
Speaker 2:  don't. I'm gonna make, I'm gonna train one of these on you.

1513
01:42:02,285 --> 01:42:04,175
Speaker 2:  Send David to meetings. That's fine.

1514
01:42:06,015 --> 01:42:08,935
Speaker 2:  It's coming. I'm just telling you these ideas are coming. This is the dream.

1515
01:42:09,445 --> 01:42:12,655
Speaker 2:  This is the last first cast where it will be real me ever again.

1516
01:42:13,645 --> 01:42:17,615
Speaker 2:  Just an AI avatar of David for some reason demanding that the

1517
01:42:17,615 --> 01:42:18,615
Speaker 2:  lightning round could sponsor.

1518
01:42:21,175 --> 01:42:24,935
Speaker 2:  I do think if you're a CEO If, you make an AI of yourself that goes to every

1519
01:42:24,935 --> 01:42:27,775
Speaker 2:  Zoom meeting your company and just says, this meeting should have been an

1520
01:42:27,775 --> 01:42:31,695
Speaker 2:  email. You will have done the greatest service to your company that any

1521
01:42:31,815 --> 01:42:35,465
Speaker 2:  CEO has ever done. A hundred percent. Just be like, why is the CEO here?

1522
01:42:35,465 --> 01:42:38,905
Speaker 2:  and it said, and then like theatrically leaves before they even realize it

1523
01:42:38,905 --> 01:42:42,865
Speaker 2:  was ai. That's pretty good. That's pretty good. There it is. That's your

1524
01:42:42,865 --> 01:42:45,905
Speaker 2:  idea. All right. That's it. We gotta wrap this thing up. We are way over

1525
01:42:46,495 --> 01:42:50,465
Speaker 2:  like crazy over. Lauren, thank you so much for joining us. Thanks for having

1526
01:42:50,485 --> 01:42:54,305
Speaker 2:  me. We have lots and lots to come, including this ROBAX event, which is happening

1527
01:42:54,365 --> 01:42:58,265
Speaker 2:  Yep. Tonight. And then we'll cover it next week on the Vergecast, but we'll

1528
01:42:58,265 --> 01:43:00,785
Speaker 2:  have full coverage on the site in the meantime. So go check that out. Let

1529
01:43:00,785 --> 01:43:04,505
Speaker 2:  us know how we did on our predictions. Optums Robots. That's it.

1530
01:43:04,585 --> 01:43:05,585
Speaker 2:  That's The. Vergecast. Rock and roll.

1531
01:43:09,845 --> 01:43:12,945
Speaker 1:  And that's it for The Vergecast this week. Hey, we'd love to hear from you.

1532
01:43:13,055 --> 01:43:16,945
Speaker 1:  Give us a call at eight six six VERGE one. One The Vergecast is a

1533
01:43:16,945 --> 01:43:20,385
Speaker 1:  production of The Verge and Vox Media Podcast Network. Our show is produced

1534
01:43:20,385 --> 01:43:21,905
Speaker 1:  by Liam James Will Pour

