1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 7a3d2749-2792-4b8f-bc5f-db1346e3adf5
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/4161081232188617450/5249983859168374524/s93290-US-5114s-1738664450.mp3
Description: Today on the show, it’s all about the future of phones… and your data. The Verge’s Allison Johnson joins the show to talk about the new Samsung Galaxy S25, what’s new in this high-end phone, and what it means for all the other smartphones coming this year. After that, Cooper Quintin, a senior staff technologist at the Electronic Frontier Foundation, talks us through how to think about the privacy implications of RedNote, TikTok, DeepSeek, and all the other tech that puts us in contact with China. Finally, we enlist The Verge’s Jennifer Pattison Tuohy to help us answer a question from the Vergecast Hotline all about the Meta Portal. Remember the Meta Portal?? If you’re missing yours, we have some ideas.

2
00:00:03,305 --> 00:00:06,715
Speaker 2:  Welcome To The Vergecast, the flagship podcast of minor

3
00:00:06,805 --> 00:00:10,675
Speaker 2:  smartphone camera upgrades. I'm your friend David Pierce, and I am

4
00:00:10,675 --> 00:00:14,555
Speaker 2:  sitting here once again, repacking my travel electronics

5
00:00:14,555 --> 00:00:18,315
Speaker 2:  bag. I've been traveling a bunch. I've had a lot of like 36 hour trips

6
00:00:18,795 --> 00:00:22,475
Speaker 2:  recently, which is a weird and sort of unique packing challenge, but I've

7
00:00:22,475 --> 00:00:25,355
Speaker 2:  gotten very good. I can do the whole thing in a backpack now, even if I have

8
00:00:25,355 --> 00:00:29,275
Speaker 2:  to bring a camera. And the trick, the key for me has been

9
00:00:29,275 --> 00:00:33,195
Speaker 2:  that I turned this whole gigantic bag full

10
00:00:33,195 --> 00:00:37,115
Speaker 2:  of cables and other assorted crap into two things. I

11
00:00:37,115 --> 00:00:40,675
Speaker 2:  bought these things from Amazon. They're these retractable

12
00:00:41,435 --> 00:00:45,235
Speaker 2:  USB cables. I got one that's six feet long and

13
00:00:45,285 --> 00:00:49,235
Speaker 2:  black, and one that's blue and three feet long. And these are now the only

14
00:00:49,275 --> 00:00:52,955
Speaker 2:  USB cables I carry with me. Anywhere I can plug into walls, I can plug into

15
00:00:52,955 --> 00:00:55,875
Speaker 2:  other devices, I can plug them into almost everything I this thing where

16
00:00:55,875 --> 00:00:59,795
Speaker 2:  everything is USBC. It's great. Like, to be clear, I don't care how you

17
00:00:59,795 --> 00:01:02,275
Speaker 2:  feel about the eu, I don't care how you feel about like Apple wanting to

18
00:01:02,275 --> 00:01:04,915
Speaker 2:  do lightning, whatever. It's better that there's one port for everything.

19
00:01:05,135 --> 00:01:08,755
Speaker 2:  And I'm finally to the point where, actually, other than my AirPods, which

20
00:01:08,795 --> 00:01:12,315
Speaker 2:  I haven't upgraded in a long time, every gadget I own is USBC,

21
00:01:12,815 --> 00:01:16,435
Speaker 2:  and it's fabulous. So now instead of a giant bag, I just have this and it

22
00:01:16,435 --> 00:01:19,195
Speaker 2:  has made everything a whole lot easier. I'll link these in the show notes.

23
00:01:19,195 --> 00:01:22,395
Speaker 2:  They're on Amazon. I don't know if there's any like specific reason to buy

24
00:01:22,395 --> 00:01:25,635
Speaker 2:  this brand over any other, but they're great.

25
00:01:26,335 --> 00:01:29,275
Speaker 2:  Anyway, we are not here to talk about USB cables, although we're a little

26
00:01:29,275 --> 00:01:32,955
Speaker 2:  bit here to talk about USB cables on every single episode of this show. Today,

27
00:01:32,955 --> 00:01:36,115
Speaker 2:  we're gonna do two things on the show. First, we're gonna talk about the

28
00:01:36,135 --> 00:01:40,115
Speaker 2:  Galaxy S 25 and all of the phones coming up this year.

29
00:01:40,265 --> 00:01:44,235
Speaker 2:  What we think is gonna happen in maybe not the

30
00:01:44,235 --> 00:01:47,555
Speaker 2:  most interesting year ever in smartphones, but in a year where a lot of smartphone

31
00:01:47,795 --> 00:01:51,515
Speaker 2:  companies are going to make the case that your phone can be different

32
00:01:51,615 --> 00:01:55,515
Speaker 2:  and new because of ai. So we're gonna get into that. We're

33
00:01:55,515 --> 00:01:58,835
Speaker 2:  also gonna talk about China. With all of this stuff happening with TikTok

34
00:01:58,855 --> 00:02:02,715
Speaker 2:  and RedNote and DeepSeek, this question of how we as internet users

35
00:02:02,855 --> 00:02:06,515
Speaker 2:  should think about China and the Chinese government and apps that come from

36
00:02:06,515 --> 00:02:10,155
Speaker 2:  China and products that come from China is just complicated. And we're gonna

37
00:02:10,155 --> 00:02:12,635
Speaker 2:  try to sort through it with somebody who actually knows what they're talking

38
00:02:12,635 --> 00:02:16,195
Speaker 2:  about. We also have a question from The Vergecast hotline. Lots of fun stuff

39
00:02:16,195 --> 00:02:19,915
Speaker 2:  to get to. This is a particularly fun hotline question, and I feel like I

40
00:02:19,915 --> 00:02:22,395
Speaker 2:  say that a lot, but I really enjoyed this one because it made me think about

41
00:02:22,395 --> 00:02:25,355
Speaker 2:  a gadget I haven't thought about in a long time. All that is coming up in

42
00:02:25,355 --> 00:02:29,115
Speaker 2:  just a sec. But first I'm just gonna can do you see how

43
00:02:29,395 --> 00:02:32,995
Speaker 2:  fun this looks? This look, it just, it's a long cable and you pull

44
00:02:33,215 --> 00:02:36,795
Speaker 2:  and it goes back in. This is what The Vergecast is here for.

45
00:02:37,115 --> 00:02:40,995
Speaker 2:  Retractable USBC cables. This is the dream, this is The Vergecast.

46
00:02:41,165 --> 00:02:41,835
Speaker 2:  We'll be right back.

47
00:04:20,775 --> 00:04:24,355
Speaker 2:  All right, we're back. Let's talk about some gadgets. So last week,

48
00:04:24,355 --> 00:04:28,035
Speaker 2:  Samsung announced the Galaxy S 25 lineup. There's the S

49
00:04:28,035 --> 00:04:30,915
Speaker 2:  25, the S 25 plus the S 25 Ultra.

50
00:04:32,215 --> 00:04:35,835
Speaker 2:  By and large, I think these phones are not the most interesting

51
00:04:35,835 --> 00:04:38,995
Speaker 2:  things that have ever been launched, but they're gonna be very popular and

52
00:04:38,995 --> 00:04:42,635
Speaker 2:  they are the first kind of big mainstream.

53
00:04:43,505 --> 00:04:47,035
Speaker 2:  Lots of people are going to buy them phones that we've seen this year,

54
00:04:47,845 --> 00:04:51,435
Speaker 2:  which makes it a fun moment to, I think look at the rest of the year

55
00:04:51,525 --> 00:04:54,435
Speaker 2:  ahead. We know pretty much what we're gonna get. We're gonna get new pixels,

56
00:04:54,435 --> 00:04:57,355
Speaker 2:  we're gonna get new iPhones, we're gonna get more foldables, we're gonna

57
00:04:57,355 --> 00:05:00,955
Speaker 2:  get more flippable. We're gonna have a lot of new ideas about what a

58
00:05:00,955 --> 00:05:04,675
Speaker 2:  smartphone should do and how AI should figure in. And so I figured

59
00:05:04,695 --> 00:05:08,515
Speaker 2:  Alison Johnson and I should just get into what we think 2025 is

60
00:05:08,715 --> 00:05:12,235
Speaker 2:  going to look like and maybe a little bit what we're hoping for from

61
00:05:12,345 --> 00:05:15,835
Speaker 2:  smartphones in the year to come. So let's talk S 25.

62
00:05:16,205 --> 00:05:20,075
Speaker 2:  Let's talk 2025. Let's get into it. Alison Johnson. Hello.

63
00:05:20,565 --> 00:05:24,555
Speaker 2:  Hello. It's phone time again are, it's January 31st as we're

64
00:05:24,555 --> 00:05:27,235
Speaker 2:  recording this and somehow it's already phone time. It's

65
00:05:27,595 --> 00:05:28,915
Speaker 7:  Phone season baby.

66
00:05:29,865 --> 00:05:33,395
Speaker 2:  This is just the rest of your year. Now this is, you got, oh, don't say that.

67
00:05:33,535 --> 00:05:36,995
Speaker 2:  You got two weeks between CES and right now. And now it's just phones forever.

68
00:05:37,495 --> 00:05:38,835
Speaker 7:  Phones for the rest of time.

69
00:05:39,235 --> 00:05:42,955
Speaker 2:  Yeah. So, okay. So because it's January, I kind of wanna do two things. I

70
00:05:42,955 --> 00:05:46,155
Speaker 2:  wanna talk about your review of the Samsung S 25 Ultra

71
00:05:47,315 --> 00:05:51,275
Speaker 2:  A phone. I find both deeply boring and thoroughly fascinating and

72
00:05:51,675 --> 00:05:55,115
Speaker 2:  I want to peel that apart a little bit. And then I wanna look ahead to the

73
00:05:55,115 --> 00:05:57,805
Speaker 2:  year to come a little bit. I think it's gonna gonna be a really interesting

74
00:05:57,805 --> 00:06:01,685
Speaker 2:  year of phones. And I just wanna talk about that a little bit. But let's

75
00:06:01,685 --> 00:06:04,765
Speaker 2:  start with the S 25. You, you've reviewed the thing, you tried it.

76
00:06:05,885 --> 00:06:09,525
Speaker 2:  I would not say based on the little bit I've heard about your review, you

77
00:06:09,525 --> 00:06:12,045
Speaker 2:  seem wildly enthusiastic about this phone. Is that fair to say?

78
00:06:12,515 --> 00:06:16,445
Speaker 7:  Yeah, that's fair. And I'm, I've been using

79
00:06:16,545 --> 00:06:20,205
Speaker 7:  the, the S 25 Ultra first for the past week.

80
00:06:21,555 --> 00:06:25,525
Speaker 7:  Yeah, it's complicated. It's like, it is a great phone. It's a, it's

81
00:06:25,525 --> 00:06:29,405
Speaker 7:  a very good phone. It's been a good phone, you know, for the past couple

82
00:06:29,425 --> 00:06:32,245
Speaker 7:  of generations. But it just feels like

83
00:06:32,955 --> 00:06:36,925
Speaker 7:  Samsung is kind of losing the plot on, like, they call this

84
00:06:36,925 --> 00:06:40,845
Speaker 7:  phone the ultra, like it should be the everything you

85
00:06:40,845 --> 00:06:44,685
Speaker 7:  could ever want from a phone. And it kind of is. But every, it

86
00:06:44,685 --> 00:06:47,845
Speaker 7:  feels like the past couple years they've just been taking away little things

87
00:06:47,905 --> 00:06:51,725
Speaker 7:  of like, it used to have the 10 x dedicated Zoom

88
00:06:51,785 --> 00:06:55,525
Speaker 7:  and then they're like, well, people didn't really use it that much, so we

89
00:06:55,625 --> 00:06:59,165
Speaker 7:  do a five x and you're like, fine. And then

90
00:06:59,435 --> 00:07:03,205
Speaker 7:  this time around they're like, we took away the, the Bluetooth and the

91
00:07:03,425 --> 00:07:07,205
Speaker 7:  stylus and you can't do the little magic wand things anymore. 'cause no one

92
00:07:07,205 --> 00:07:10,725
Speaker 7:  was doing them. And it's like, fine, I guess I can,

93
00:07:11,285 --> 00:07:15,125
Speaker 7:  I, I'm not gonna miss them. But then you end up with like, what have

94
00:07:15,125 --> 00:07:17,845
Speaker 7:  they been adding? And it's just kind of like

95
00:07:18,755 --> 00:07:22,285
Speaker 7:  stalled out. I feel like we've got all these AI features,

96
00:07:22,895 --> 00:07:26,885
Speaker 7:  which are a real mixed bag still. And they're on

97
00:07:26,885 --> 00:07:30,445
Speaker 7:  every other phone. They're like on all the Samsung phones, right?

98
00:07:30,475 --> 00:07:34,125
Speaker 7:  They're on older Samsung phones, they're on Android phones. So

99
00:07:34,345 --> 00:07:38,325
Speaker 7:  I'm just sort of sitting here like, this is a great phone. Sure. But like,

100
00:07:38,945 --> 00:07:41,285
Speaker 7:  why? What makes it so special? I don't know.

101
00:07:42,065 --> 00:07:45,845
Speaker 2:  So I'm of two minds about all of this, which is part of what I wanna

102
00:07:45,845 --> 00:07:49,445
Speaker 2:  talk through with you. I think on the one hand, the thing that Samsung

103
00:07:49,705 --> 00:07:53,525
Speaker 2:  is describing where it's like, let's take all the confusing and

104
00:07:53,525 --> 00:07:57,245
Speaker 2:  complicated stuff out and just give you a phone that is

105
00:07:57,275 --> 00:08:01,125
Speaker 2:  good and is full of things that people like to do. I think it's good,

106
00:08:01,125 --> 00:08:04,285
Speaker 2:  right? Like it's, it's a thing we ask for in product design all the time.

107
00:08:04,435 --> 00:08:08,125
Speaker 2:  Like stop shipping weird shit and just make a good phone

108
00:08:08,395 --> 00:08:12,285
Speaker 2:  that does things. People like, I think is like a not wrong path.

109
00:08:13,305 --> 00:08:16,365
Speaker 2:  But then on the other hand, I do feel like either

110
00:08:17,485 --> 00:08:20,695
Speaker 2:  Samsung is, like you said, kind of losing the plot and running out of ideas

111
00:08:21,115 --> 00:08:24,895
Speaker 2:  or this is just a sign that there is absolutely nothing left to do

112
00:08:25,175 --> 00:08:29,055
Speaker 2:  in smartphones and, and that maybe our phones are what they

113
00:08:29,055 --> 00:08:33,015
Speaker 2:  are and they're, they have hit laptop territory of like, we pretty

114
00:08:33,015 --> 00:08:36,935
Speaker 2:  much know how this is supposed to go the end. And then I think if you're

115
00:08:36,935 --> 00:08:40,335
Speaker 2:  Samsung continuing to sell a phone that you call the ultra

116
00:08:41,125 --> 00:08:44,655
Speaker 2:  just feels bonkers. Like my, the more I think about

117
00:08:45,125 --> 00:08:48,815
Speaker 2:  your review and your experience, the less I even understand why this phone

118
00:08:48,815 --> 00:08:52,015
Speaker 2:  exists. Because like you're saying, this is supposed to be the one that does

119
00:08:52,035 --> 00:08:54,855
Speaker 2:  all the things. And it's supposed to be the place where Samsung tests its

120
00:08:54,855 --> 00:08:58,565
Speaker 2:  weirdest ideas. And I kind of love Samsung for that. And you, for years they

121
00:08:58,565 --> 00:09:02,125
Speaker 2:  were like, oh, most people don't want a stylists, but some people do.

122
00:09:02,345 --> 00:09:05,325
Speaker 2:  And so we make a note and it's gonna blow up on a plane.

123
00:09:06,335 --> 00:09:06,685
Speaker 7:  Right?

124
00:09:07,385 --> 00:09:09,765
Speaker 2:  But like they, they did that for people. And there's something about that

125
00:09:09,765 --> 00:09:12,125
Speaker 2:  that I actually really appreciate about Samsung that they're like, this is,

126
00:09:12,125 --> 00:09:15,085
Speaker 2:  this is the one where we just said yes to everything.

127
00:09:16,105 --> 00:09:19,805
Speaker 2:  And now that it's not that I'm not super clear on what it even is

128
00:09:19,875 --> 00:09:20,365
Speaker 2:  anymore.

129
00:09:21,275 --> 00:09:25,165
Speaker 7:  Yeah. And it's like I am generally o like of

130
00:09:25,165 --> 00:09:28,925
Speaker 7:  the mind that phones are boring now and that's okay. It's like

131
00:09:28,975 --> 00:09:32,805
Speaker 7:  we've, we just kind of landed on like what a phone is shaped like

132
00:09:32,805 --> 00:09:36,085
Speaker 7:  and what it does. We're not doing a bunch of wacky things anymore with like

133
00:09:36,085 --> 00:09:39,485
Speaker 7:  cameras that pop up or like little things that flip around,

134
00:09:40,425 --> 00:09:41,725
Speaker 7:  you know? Bless lg.

135
00:09:41,735 --> 00:09:43,605
Speaker 2:  Those were fun days though. Yeah. I missed those

136
00:09:43,605 --> 00:09:45,845
Speaker 7:  Times. I know. They were fun. What was the

137
00:09:45,965 --> 00:09:49,725
Speaker 2:  LG one that the, the screen like turned 90 degrees? I think

138
00:09:49,725 --> 00:09:50,565
Speaker 7:  That was the wing.

139
00:09:51,025 --> 00:09:53,645
Speaker 2:  The wing. Ugh. I wish that had been successful.

140
00:09:54,425 --> 00:09:56,245
Speaker 7:  You know, LG was

141
00:09:56,355 --> 00:09:59,805
Speaker 2:  That, I don't think any person on earth bought that phone, but I loved that

142
00:09:59,805 --> 00:10:00,245
Speaker 2:  it existed.

143
00:10:00,715 --> 00:10:02,165
Speaker 7:  Yeah. Bless them.

144
00:10:03,875 --> 00:10:07,645
Speaker 7:  Yeah. Yeah. It's like we're just landed on like the basic

145
00:10:07,915 --> 00:10:11,405
Speaker 7:  idea of like what a phone is shaped like what it does

146
00:10:12,105 --> 00:10:15,965
Speaker 7:  and it's fine. And people, we use it for so many things in our lives.

147
00:10:16,025 --> 00:10:19,045
Speaker 7:  You don't want a bunch of have to learn a bunch of different stuff every

148
00:10:19,045 --> 00:10:20,125
Speaker 7:  time you buy a new phone.

149
00:10:21,745 --> 00:10:25,445
Speaker 7:  So I think that's okay. But yeah, I think the problem comes when

150
00:10:25,445 --> 00:10:28,805
Speaker 7:  Samsung is like, here's the ultra phone

151
00:10:29,385 --> 00:10:33,085
Speaker 7:  and it costs 1299 and you

152
00:10:33,135 --> 00:10:37,045
Speaker 7:  definitely should pay that much money for it. And you're like, okay, what

153
00:10:37,045 --> 00:10:40,925
Speaker 7:  do I get? And it's like, well, you know, you get a

154
00:10:40,925 --> 00:10:44,845
Speaker 7:  five x zoom, but you could get that on a pixel phone. You get a

155
00:10:44,845 --> 00:10:48,765
Speaker 7:  little stylus that like used to do some special stuff and

156
00:10:48,765 --> 00:10:52,525
Speaker 7:  it does it now. Like, I don't know, like give us something like

157
00:10:52,785 --> 00:10:56,685
Speaker 7:  do do something. Make it a little bigger and double the

158
00:10:56,685 --> 00:11:00,285
Speaker 7:  battery life for, I don't know. You know? I'm sure it's that easy,

159
00:11:00,465 --> 00:11:04,285
Speaker 7:  you know, designing engineering phones. Yeah. Yeah.

160
00:11:04,365 --> 00:11:07,965
Speaker 7:  I feel like there's something like, there has to be something and Samsung

161
00:11:08,265 --> 00:11:10,405
Speaker 7:  is just kind of like stalled out.

162
00:11:10,925 --> 00:11:14,005
Speaker 2:  I know, I, I do think, I'm glad you mentioned the battery life 'cause I was

163
00:11:14,005 --> 00:11:17,245
Speaker 2:  thinking about it and I'm like, okay, what, what would work as ultra for

164
00:11:17,245 --> 00:11:20,845
Speaker 2:  me? And it's like twice as thick, twice the battery would do it, right? I

165
00:11:20,845 --> 00:11:24,405
Speaker 2:  think, I think you could, you could feasibly be like, this phone is like

166
00:11:24,445 --> 00:11:26,245
Speaker 2:  a thick boy with two C's,

167
00:11:27,785 --> 00:11:31,445
Speaker 2:  but it lasts for five days. And I actually, I, I think that is like an

168
00:11:31,445 --> 00:11:35,285
Speaker 2:  incredibly interesting idea about a smartphone. Yeah. Then

169
00:11:35,285 --> 00:11:38,045
Speaker 2:  on the flip side, I think the other one they could have done is really gone

170
00:11:38,045 --> 00:11:41,805
Speaker 2:  after durability and, and like, yeah, Motorola,

171
00:11:42,085 --> 00:11:45,205
Speaker 2:  I feel like was really the last company to take a big swing at. Like, we

172
00:11:45,205 --> 00:11:49,005
Speaker 2:  are going to make a phone that you can't break. And it didn't, it

173
00:11:49,005 --> 00:11:51,885
Speaker 2:  didn't really work. But I think that's more for like Motorola reasons than

174
00:11:51,985 --> 00:11:55,245
Speaker 2:  it being a good idea of reasons. Yeah. Right. And so I think if I'm Samsung,

175
00:11:55,355 --> 00:11:59,125
Speaker 2:  like I, I would've been interested to see if Samsung had poked it either

176
00:11:59,125 --> 00:12:02,685
Speaker 2:  of those two and been like, is this, is this a thing people will upgrade

177
00:12:02,705 --> 00:12:05,845
Speaker 2:  for? Because I think it is, but we have no evidence for it because no one

178
00:12:05,845 --> 00:12:08,605
Speaker 2:  has ever really tested it. Like I think if I could say to somebody,

179
00:12:09,605 --> 00:12:13,425
Speaker 2:  here's a phone that will last you from Monday to

180
00:12:13,665 --> 00:12:17,585
Speaker 2:  Thursday reliably, or here is a phone that you

181
00:12:17,825 --> 00:12:20,465
Speaker 2:  slippery handed goofs you, you can't even break.

182
00:12:21,515 --> 00:12:21,865
Speaker 7:  Right.

183
00:12:22,215 --> 00:12:25,345
Speaker 2:  That works. That is the most interesting new idea about a smartphone I've

184
00:12:25,345 --> 00:12:28,345
Speaker 2:  heard in a very long time. And I like, I wish Samsung had picked something

185
00:12:28,345 --> 00:12:29,385
Speaker 2:  like that to do here.

186
00:12:29,735 --> 00:12:33,345
Speaker 7:  Yeah. I feel like we're gonna end up with like the

187
00:12:33,495 --> 00:12:37,465
Speaker 7:  fold, the z fold in the ultra like merge into

188
00:12:37,465 --> 00:12:41,305
Speaker 7:  like here is the ultimate phone that

189
00:12:41,305 --> 00:12:45,185
Speaker 7:  does other things and it's like cut somehow comes with the stylus and

190
00:12:45,195 --> 00:12:48,745
Speaker 7:  folds in half and like if they upgraded the cameras

191
00:12:49,725 --> 00:12:53,625
Speaker 7:  on the fold, like that would be an ultra phone

192
00:12:54,065 --> 00:12:57,945
Speaker 7:  I think. Yeah. If, if such a thing exists. But yeah, as far

193
00:12:57,945 --> 00:13:01,825
Speaker 7:  as things that people actually want in their lives, like battery life

194
00:13:01,825 --> 00:13:02,785
Speaker 7:  would be an easy one.

195
00:13:03,375 --> 00:13:07,025
Speaker 2:  Like Yeah, I totally agree. So the two things I'm particularly curious about

196
00:13:07,285 --> 00:13:11,265
Speaker 2:  on the S 25 Ultra in particular, but kind of the S 25 line in

197
00:13:11,265 --> 00:13:14,585
Speaker 2:  general is as ever the AI and the cameras

198
00:13:16,075 --> 00:13:20,065
Speaker 2:  brand new-ish version of Gemini shipping first on this

199
00:13:20,065 --> 00:13:23,425
Speaker 2:  device is supposed to be the like multi-step multi app

200
00:13:23,685 --> 00:13:27,065
Speaker 2:  action things supposed to be kind of the next AI

201
00:13:27,075 --> 00:13:30,265
Speaker 2:  experience on your phone. You've gotten to test it, how'd it go

202
00:13:31,285 --> 00:13:34,895
Speaker 7:  Good and bad. So I'll start with the good, I finally

203
00:13:35,075 --> 00:13:38,695
Speaker 7:  did the thing where it's like you have something on your screen and you wanna

204
00:13:38,695 --> 00:13:42,655
Speaker 7:  put it on your calendar and that has just not been a thing that Gemini are

205
00:13:42,655 --> 00:13:45,975
Speaker 7:  like any other technology in the world can do apparently.

206
00:13:46,515 --> 00:13:50,415
Speaker 7:  But it finally happened. You like Summon

207
00:13:50,475 --> 00:13:53,935
Speaker 7:  Gemini, which is now the default assistant on Samsung phones,

208
00:13:54,385 --> 00:13:57,615
Speaker 2:  Which we agree is like an extremely good upgrade, right? Yeah. That is the

209
00:13:57,615 --> 00:13:58,575
Speaker 2:  correct. Okay. It

210
00:13:58,575 --> 00:14:02,495
Speaker 7:  It should be this way. Excuse like hanging around in the settings menu,

211
00:14:02,565 --> 00:14:05,895
Speaker 7:  like doing some stuff and that's fine. Like that's, yeah, that's where Bixby

212
00:14:05,895 --> 00:14:06,255
Speaker 7:  belongs.

213
00:14:06,415 --> 00:14:09,335
Speaker 2:  I don't wanna kill Bixby. I just don't wanna like think about Bixby very

214
00:14:09,335 --> 00:14:13,055
Speaker 7:  Often. Yeah. Bixby can just be hanging out. Yeah. Yeah. I had something on

215
00:14:13,055 --> 00:14:16,895
Speaker 7:  my screen, I summon Gemini and there you get a little chip

216
00:14:16,895 --> 00:14:20,615
Speaker 7:  that's like, ask about this screen or get help with the screen. And I was

217
00:14:20,615 --> 00:14:24,335
Speaker 7:  like, add this to my calendar and it frigging did it

218
00:14:24,395 --> 00:14:28,255
Speaker 7:  and it was like the best thing. It was like, finally,

219
00:14:28,965 --> 00:14:32,335
Speaker 7:  this is all I've been wanting, but the, it,

220
00:14:33,195 --> 00:14:36,335
Speaker 7:  it kind of falls apart in other ways when you're like,

221
00:14:37,255 --> 00:14:40,935
Speaker 7:  I am, I'm, I'm a Sudoku now I am

222
00:14:41,035 --> 00:14:44,255
Speaker 7:  in my Sudoku era and I was like asking

223
00:14:44,635 --> 00:14:48,495
Speaker 7:  Gemini for some Sudoku solving. I was like, find some

224
00:14:48,495 --> 00:14:52,325
Speaker 7:  videos on YouTube to help me learn Sudokus

225
00:14:52,905 --> 00:14:56,725
Speaker 7:  and add them to a note and it can do that. Like, it, it

226
00:14:56,875 --> 00:15:00,605
Speaker 7:  follows instructions. It's like, okay. And it goes and gets some videos

227
00:15:01,305 --> 00:15:05,005
Speaker 7:  and then opens a note app. It's like that is all cool to see that

228
00:15:05,005 --> 00:15:08,925
Speaker 7:  happening. But what it created in the notes app was just

229
00:15:09,045 --> 00:15:12,725
Speaker 7:  a list of video, like headlines with, with

230
00:15:12,825 --> 00:15:13,245
Speaker 7:  no link.

231
00:15:13,525 --> 00:15:17,445
Speaker 2:  I I did the same thing. I tried it when, when it first came out just

232
00:15:17,445 --> 00:15:21,165
Speaker 2:  like on Gemini web and was I did the same thing. Mm. I forget it was oh it

233
00:15:21,165 --> 00:15:25,005
Speaker 2:  was, it was like GPU explainers and it pulled, it pulled like

234
00:15:25,075 --> 00:15:28,885
Speaker 2:  five different Google Keep notes that were just the title

235
00:15:28,885 --> 00:15:30,365
Speaker 2:  of the video and nothing else.

236
00:15:30,795 --> 00:15:31,845
Speaker 7:  Yeah, no. He was

237
00:15:31,845 --> 00:15:32,605
Speaker 2:  Like, what, what are we

238
00:15:32,605 --> 00:15:36,085
Speaker 7:  Accomplishing here? I know. Yeah. I was even like add

239
00:15:36,375 --> 00:15:39,885
Speaker 7:  hyperlinks to the videos and it did not do that either.

240
00:15:40,315 --> 00:15:43,125
Speaker 7:  It's rough. Yeah. I have so many examples of just like

241
00:15:44,545 --> 00:15:48,445
Speaker 7:  you guys talked about last week too on, on the Friday verse

242
00:15:48,445 --> 00:15:52,085
Speaker 7:  cast of like, when you're fighting with the tool, it

243
00:15:52,085 --> 00:15:56,045
Speaker 7:  you're just done. Like I had to fight with Gemini so many times

244
00:15:56,635 --> 00:16:00,445
Speaker 7:  that I was like, I don't care that I can, you know, take

245
00:16:00,445 --> 00:16:04,005
Speaker 7:  this detail and have it email my husband or whatever. Like I can't

246
00:16:04,485 --> 00:16:08,285
Speaker 7:  convince it that I am leaving that my flight leaves from

247
00:16:08,345 --> 00:16:11,525
Speaker 7:  San Francisco and not San Jose. Right. It was like

248
00:16:11,875 --> 00:16:14,445
Speaker 7:  arguing with me for five minutes about this.

249
00:16:15,985 --> 00:16:19,765
Speaker 2:  And there's so many things in all of that that it feels

250
00:16:19,995 --> 00:16:23,725
Speaker 2:  very obvious that Gemini should be able to do it. And

251
00:16:23,875 --> 00:16:27,485
Speaker 2:  like I remember back when Siri could tell you some

252
00:16:27,505 --> 00:16:31,125
Speaker 2:  sports scores, but not other sports scores. And there's a thing about that

253
00:16:31,125 --> 00:16:33,965
Speaker 2:  that just feels broken because it's like, well If you know the football scores,

254
00:16:34,025 --> 00:16:37,205
Speaker 2:  why don't you know the baseball scores? And I forget which order it was,

255
00:16:37,205 --> 00:16:39,605
Speaker 2:  but it was, there's just something about that that is like, okay, this, this

256
00:16:39,605 --> 00:16:43,565
Speaker 2:  thing doesn't work and I don't, I I should not have

257
00:16:43,565 --> 00:16:46,485
Speaker 2:  to understand which specific like feature flags have been turned on. Yeah.

258
00:16:46,625 --> 00:16:50,125
Speaker 2:  It just doesn't feel like it works. And I think in reading your review, the

259
00:16:50,125 --> 00:16:53,885
Speaker 2:  experience you had of asking when the someone's flight was

260
00:16:53,885 --> 00:16:57,325
Speaker 2:  landing was one of those where I was like, this ob this so obviously should

261
00:16:57,325 --> 00:17:00,565
Speaker 2:  work that it is just infuriating that it doesn't.

262
00:17:01,115 --> 00:17:04,525
Speaker 7:  Yeah. And it's one of those things that's like, I know I can go to Google

263
00:17:04,785 --> 00:17:08,365
Speaker 7:  and just type in like Alaska Airlines, flight

264
00:17:08,395 --> 00:17:11,885
Speaker 7:  Detroit to Seattle, when does it land? And it's like, boom, gonna be there.

265
00:17:12,425 --> 00:17:16,365
Speaker 7:  Gemini does this whole dance of like, oh, I don't know, I'm a large language

266
00:17:16,365 --> 00:17:20,085
Speaker 7:  model and I'm yelling at it to Google it. I'm like,

267
00:17:20,305 --> 00:17:23,885
Speaker 7:  I'm not going to use this tool Yeah. Anymore.

268
00:17:24,035 --> 00:17:27,965
Speaker 2:  It's like you're Google like if, if, if at the very least it would

269
00:17:27,965 --> 00:17:30,205
Speaker 2:  just fall back on a Google search. Yeah,

270
00:17:30,595 --> 00:17:31,085
Speaker 7:  Exactly.

271
00:17:31,475 --> 00:17:33,805
Speaker 2:  Like the thing that Siri does that sucks is it's like, here's what I found

272
00:17:33,805 --> 00:17:36,045
Speaker 2:  on the web, but it's like always wrong. But like Google is Google.

273
00:17:36,475 --> 00:17:38,085
Speaker 7:  Like I know just, just

274
00:17:38,205 --> 00:17:41,005
Speaker 2:  Be like, oh, I don't know, but here's a Google search for all the words that

275
00:17:41,005 --> 00:17:43,285
Speaker 2:  you just said. Even that we would be somewhere.

276
00:17:43,705 --> 00:17:43,925
Speaker 7:  Yep,

277
00:17:44,585 --> 00:17:48,245
Speaker 2:  Yep. But it can, okay. Yeah. I feel like this is, this just continues to

278
00:17:48,245 --> 00:17:52,005
Speaker 2:  be the Gemini experience like that, the thing with the, the dates and the

279
00:17:52,005 --> 00:17:55,565
Speaker 2:  screen is like amazing. And there are just enough moments like that for me

280
00:17:55,675 --> 00:17:59,605
Speaker 2:  with even things like visual intelligence and, and a lot of these tools are

281
00:17:59,605 --> 00:18:02,245
Speaker 2:  getting good at that kind of thing where it's like, I'm like, here's a list

282
00:18:02,245 --> 00:18:05,805
Speaker 2:  of stuff. Can you add everything on this piece of paper to my grocery list?

283
00:18:05,865 --> 00:18:09,805
Speaker 2:  And like it works and it feels like magic. But then for

284
00:18:09,805 --> 00:18:13,165
Speaker 2:  every one of those I have found three that it's like, this is actually easier

285
00:18:13,315 --> 00:18:17,285
Speaker 2:  than the thing that you did that works and it doesn't work. Yeah. And I

286
00:18:17,285 --> 00:18:21,125
Speaker 2:  can't figure out why and it just makes me want to use the tool less and less.

287
00:18:21,405 --> 00:18:25,365
Speaker 7:  I know. Yeah. It feels like it does a good job when it has very specific

288
00:18:25,775 --> 00:18:28,645
Speaker 7:  parameters where like on the ultra

289
00:18:29,625 --> 00:18:33,525
Speaker 7:  it does a good job with like note summarization. I

290
00:18:33,525 --> 00:18:34,165
Speaker 7:  just was like,

291
00:18:35,945 --> 00:18:39,765
Speaker 7:  my kid was sick and I was trying to type out that note you make for yourself

292
00:18:39,765 --> 00:18:42,965
Speaker 7:  before you go to the pediatrician to be like, here's when

293
00:18:43,685 --> 00:18:47,365
Speaker 7:  symptoms started, blah blah, blah fevers and, and it was all just kinda like

294
00:18:47,515 --> 00:18:50,965
Speaker 7:  blah. And I used the summer, the like

295
00:18:51,325 --> 00:18:55,245
Speaker 7:  rewrite tool to like make it make sense. Oh that's neat.

296
00:18:55,305 --> 00:18:58,565
Speaker 7:  And it did great and it picked up on the fact that it was like

297
00:18:59,285 --> 00:19:03,205
Speaker 7:  a child's illness progression and it kind of like gave it a title

298
00:19:03,275 --> 00:19:06,965
Speaker 7:  like that. I was like, this is good, this is fine

299
00:19:07,235 --> 00:19:11,165
Speaker 7:  that, you know, I I wasn't asking it to go ask three other

300
00:19:11,165 --> 00:19:14,965
Speaker 7:  apps to do anything, but you know, we're we're getting the handle on

301
00:19:14,965 --> 00:19:15,445
Speaker 7:  stuff like that.

302
00:19:15,715 --> 00:19:18,725
Speaker 2:  Yeah. That's something I'll, I'll take that. Yeah. So the other one on the

303
00:19:18,845 --> 00:19:22,725
Speaker 2:  S 25 Ultra is the camera. And I think Samsung made,

304
00:19:22,905 --> 00:19:26,845
Speaker 2:  as far as I understand it, two trades on the

305
00:19:26,845 --> 00:19:30,525
Speaker 2:  camera. It got rid of the 10 x zoom and it added a

306
00:19:30,525 --> 00:19:34,485
Speaker 2:  50 megapixel ultra wide lens. My immediate read of that is

307
00:19:34,785 --> 00:19:38,565
Speaker 2:  I'm very into one of those changes and I am very unhappy about the other

308
00:19:38,565 --> 00:19:40,605
Speaker 2:  one. But what's your experience?

309
00:19:41,195 --> 00:19:45,005
Speaker 7:  Yeah, the 10 x was actually last year. So the S 24 Ultra

310
00:19:45,005 --> 00:19:46,165
Speaker 7:  is when they did the swap.

311
00:19:46,705 --> 00:19:46,925
Speaker 2:  Oh,

312
00:19:46,925 --> 00:19:50,885
Speaker 7:  Okay. Yeah. And they, they added the five x and they're like, well you can

313
00:19:50,885 --> 00:19:54,605
Speaker 7:  just do, you know, digital zoom re

314
00:19:54,845 --> 00:19:57,005
Speaker 7:  mosaic zoom to 10 x, which

315
00:19:57,005 --> 00:20:00,405
Speaker 2:  Is not correct. It's called cropping digital zoom is called cropping.

316
00:20:01,185 --> 00:20:03,165
Speaker 2:  Anyone who says otherwise is selling you something

317
00:20:03,565 --> 00:20:07,085
Speaker 7:  Cropping without upscaling, which is something.

318
00:20:08,115 --> 00:20:09,045
Speaker 7:  Sure. Yeah.

319
00:20:09,345 --> 00:20:13,245
Speaker 2:  But I do think, so I like, I I bring this up in part because I, for the first

320
00:20:13,245 --> 00:20:17,125
Speaker 2:  time this year went from an iPhone pro to an iPhone and so I lost the, the

321
00:20:17,755 --> 00:20:21,685
Speaker 2:  five x zoom and I miss it terribly. Yeah. And I, I'm

322
00:20:21,685 --> 00:20:24,765
Speaker 2:  consistently surprised at how often I miss the five x zoom.

323
00:20:25,985 --> 00:20:29,925
Speaker 2:  And so I guess this is to some extent now a year old question, but

324
00:20:30,425 --> 00:20:34,085
Speaker 2:  do you miss the 10 x or does the five X feel like it does the job for you?

325
00:20:34,925 --> 00:20:38,725
Speaker 7:  I miss it because I am, I'm a sicko

326
00:20:38,865 --> 00:20:42,605
Speaker 7:  and I can see the difference. Like there's just, I think the

327
00:20:42,605 --> 00:20:46,525
Speaker 7:  difference is that you just amplify the fact

328
00:20:46,525 --> 00:20:50,445
Speaker 7:  that you're using a crappy little lens and you can see some of the

329
00:20:50,835 --> 00:20:54,605
Speaker 7:  aberrations from the lens more than you could see it with

330
00:20:54,825 --> 00:20:58,765
Speaker 7:  the 10 x. This is interesting. Sure. This is my theory. I

331
00:20:58,765 --> 00:21:02,725
Speaker 7:  can see a slight difference. Does this matter to most people? Like No,

332
00:21:03,365 --> 00:21:05,085
Speaker 7:  probably not at all. Yeah.

333
00:21:05,605 --> 00:21:08,445
Speaker 2:  I mean, I guess I guess from Samsung's perspective where it's like, okay,

334
00:21:08,445 --> 00:21:12,285
Speaker 2:  we can either add this very expensive thing that makes the

335
00:21:12,285 --> 00:21:14,725
Speaker 2:  phone bigger and all that stuff, or we can get rid of it and people can pinch

336
00:21:14,725 --> 00:21:18,325
Speaker 2:  with their fingers if they really want to. Yeah. I I guess I get that trade,

337
00:21:18,385 --> 00:21:22,365
Speaker 2:  but I absolutely unequivocally do not buy that they're the same

338
00:21:22,365 --> 00:21:26,325
Speaker 2:  thing. Yeah. And, and they aren't. And Samsung is lying and should feel bad

339
00:21:26,325 --> 00:21:29,445
Speaker 2:  about itself. But tell me about the ultra wide, because this seems like it's

340
00:21:29,445 --> 00:21:30,285
Speaker 2:  a, it's a good trade.

341
00:21:30,715 --> 00:21:34,325
Speaker 7:  Yeah. Yeah. They just kind of upgraded it from a,

342
00:21:34,845 --> 00:21:37,885
Speaker 7:  I believe a 12 megapixel to a 50 megapixel now

343
00:21:38,915 --> 00:21:42,685
Speaker 7:  it's got wider aperture, so it's an F1

344
00:21:42,685 --> 00:21:44,125
Speaker 7:  0.9. Oh, I like

345
00:21:44,125 --> 00:21:44,285
Speaker 2:  That.

346
00:21:44,755 --> 00:21:45,045
Speaker 7:  Yeah.

347
00:21:45,785 --> 00:21:49,765
Speaker 2:  So does that in theory mean that with a 50 megapixel Ultra

348
00:21:49,765 --> 00:21:53,645
Speaker 2:  wide you could shoot a lot more often in ultra wide and then just

349
00:21:54,075 --> 00:21:56,725
Speaker 2:  crop as you need to? Like that's actually an interesting use case of like

350
00:21:57,225 --> 00:22:00,885
Speaker 2:  you just shoot the most you can. Hmm. And then

351
00:22:01,655 --> 00:22:04,905
Speaker 2:  because you have more pixels to play with, but then like the, I don't know,

352
00:22:04,905 --> 00:22:07,785
Speaker 2:  the ultra wides always get a little fish ie. For me. So maybe that's not

353
00:22:07,825 --> 00:22:08,505
Speaker 2:  a perfect solution.

354
00:22:08,505 --> 00:22:12,425
Speaker 7:  Yeah. I think you still get a little bit of that and even like, even in

355
00:22:12,425 --> 00:22:16,185
Speaker 7:  kind of like dim light, the main camera is so much better for

356
00:22:16,185 --> 00:22:20,145
Speaker 7:  like yeah. Getting freezing action and all

357
00:22:20,145 --> 00:22:23,985
Speaker 7:  that. But the ultra wide like, you know, apples to apples with the

358
00:22:24,425 --> 00:22:27,785
Speaker 7:  previous ultra wide, it definitely is better and low light it can,

359
00:22:28,275 --> 00:22:32,065
Speaker 7:  it'll complete like a, a night mode exposure

360
00:22:32,295 --> 00:22:35,265
Speaker 7:  like a little quicker Hmm. Than the previous one.

361
00:22:36,335 --> 00:22:40,185
Speaker 7:  There's a little more detail. It's like just kind of like check, check, check

362
00:22:40,205 --> 00:22:43,985
Speaker 7:  all the things you would expect from like a more modern

363
00:22:44,855 --> 00:22:48,385
Speaker 7:  nice pixel bin sensor. So it's like, yeah.

364
00:22:48,695 --> 00:22:48,985
Speaker 7:  Good.

365
00:22:49,715 --> 00:22:53,645
Speaker 2:  Yeah, I'll take that. Okay. So the, the S 25

366
00:22:53,935 --> 00:22:57,285
Speaker 2:  ultra and I think we will reserve judgment in case one of the other S 20

367
00:22:57,285 --> 00:23:00,525
Speaker 2:  fives blows your mind. But I think the story of these is going to be, they're

368
00:23:00,525 --> 00:23:04,485
Speaker 2:  very good phones. If you're in the market for a Galaxy phone, these are the

369
00:23:04,485 --> 00:23:08,325
Speaker 2:  best ones, but there's nothing here that's gonna like blow

370
00:23:08,325 --> 00:23:12,285
Speaker 2:  your socks off or change your life forever. What I'm wondering

371
00:23:12,285 --> 00:23:16,205
Speaker 2:  is, is that just the story of 2025, like is this, is this what

372
00:23:16,205 --> 00:23:20,045
Speaker 2:  we're in for? Because the thing that worries me is that this is supposed

373
00:23:20,045 --> 00:23:23,365
Speaker 2:  to be the year that AI does everything for all of our funds forever. Mm.

374
00:23:23,385 --> 00:23:25,965
Speaker 2:  And I think we can say with pretty strong confidence that that's not this

375
00:23:25,965 --> 00:23:29,205
Speaker 2:  year. It might happen someday. I'm not willing to rule out that maybe someday

376
00:23:29,385 --> 00:23:32,125
Speaker 2:  AI will get very good. I think it's very unlikely that it's gonna happen

377
00:23:32,355 --> 00:23:32,845
Speaker 2:  this year.

378
00:23:34,665 --> 00:23:36,165
Speaker 2:  So what else are we in for this year?

379
00:23:37,685 --> 00:23:41,525
Speaker 7:  I think, yeah, it's gonna be a lot of, I think we're just in this,

380
00:23:42,235 --> 00:23:46,125
Speaker 7:  this like head space of we're so focused

381
00:23:46,185 --> 00:23:50,165
Speaker 7:  on the, the hardware launches and a phone is

382
00:23:50,445 --> 00:23:54,205
Speaker 7:  released, it does X, y, and z new things. And then the next

383
00:23:54,205 --> 00:23:58,045
Speaker 7:  year, new phone, you know, and we're in such a

384
00:23:58,045 --> 00:24:01,245
Speaker 7:  different space now of like the hardware is just

385
00:24:01,985 --> 00:24:05,965
Speaker 7:  the less interesting thing almost. And it's about the

386
00:24:06,205 --> 00:24:09,445
Speaker 7:  software updates that are happening throughout the year. And like in Samsung

387
00:24:09,535 --> 00:24:13,445
Speaker 7:  especially is like, they put a lot of the AI in the software

388
00:24:14,025 --> 00:24:17,645
Speaker 7:  in previous phones. So it's even less important If you have

389
00:24:17,985 --> 00:24:20,965
Speaker 7:  an S 24 and S 25 presumably.

390
00:24:21,865 --> 00:24:25,805
Speaker 7:  So I think that's just gonna be an, an adjustment for all of us and

391
00:24:25,805 --> 00:24:29,445
Speaker 7:  just kind of how we think about these things and even how we cover them

392
00:24:30,385 --> 00:24:33,405
Speaker 7:  and use them. 'cause it's, it's gonna be a lot more like,

393
00:24:34,195 --> 00:24:37,565
Speaker 7:  what does this phone do six months later that it didn't do,

394
00:24:38,105 --> 00:24:41,925
Speaker 7:  you know, when it came out? So seeing things

395
00:24:42,035 --> 00:24:45,125
Speaker 7:  like Gemini getting better

396
00:24:46,225 --> 00:24:50,085
Speaker 7:  at a somewhat slow rate, but like being able

397
00:24:50,085 --> 00:24:53,845
Speaker 7:  to do more for us and trying those things out is going to be like,

398
00:24:54,225 --> 00:24:58,205
Speaker 7:  that's gonna be my focus for the year, honestly. But like

399
00:24:58,505 --> 00:25:02,325
Speaker 7:  in the other corner is the weird, like the

400
00:25:02,395 --> 00:25:06,365
Speaker 7:  slim phone thing, which is, it's like, okay,

401
00:25:07,355 --> 00:25:11,205
Speaker 7:  like we, we've reached a conclusion I guess, and in one side

402
00:25:11,235 --> 00:25:14,685
Speaker 7:  it's like the phone is here is phones look like this.

403
00:25:15,225 --> 00:25:18,645
Speaker 7:  And then they've kind of, they're kind of doing a lateral move of like,

404
00:25:18,955 --> 00:25:21,045
Speaker 7:  what if a phone was really slim? Yeah.

405
00:25:21,545 --> 00:25:24,925
Speaker 2:  I'm, I'm into it honestly. Like any kind of

406
00:25:25,465 --> 00:25:28,525
Speaker 2:  new idea about what a phone should look like, I am psyched about right now.

407
00:25:29,955 --> 00:25:33,365
Speaker 2:  Where's your head on Foldables and Flippable coming into this year? I mean,

408
00:25:33,365 --> 00:25:37,285
Speaker 2:  Samsung kind of teased the trifold thing, I

409
00:25:37,285 --> 00:25:40,605
Speaker 2:  think in that we saw like a outline and that's about all we saw.

410
00:25:42,105 --> 00:25:45,965
Speaker 2:  But you know, we've been on the show for a while talking about is this,

411
00:25:46,065 --> 00:25:49,365
Speaker 2:  is this the time these things are gonna come mainstream? And I do think

412
00:25:50,075 --> 00:25:53,965
Speaker 2:  it's possible to gin up some real excitement about one of

413
00:25:54,245 --> 00:25:58,005
Speaker 2:  those this year specifically because there is

414
00:25:58,025 --> 00:26:01,965
Speaker 2:  not a ton of like wild other cool stuff coming

415
00:26:01,965 --> 00:26:05,765
Speaker 2:  that's gonna blow people's minds. Like Apple intelligence is not going to

416
00:26:06,045 --> 00:26:09,695
Speaker 2:  convince the hundreds of millions of people to run out and get new

417
00:26:09,695 --> 00:26:13,615
Speaker 2:  iPhones. But like, so does that mean there is potential for Google

418
00:26:13,795 --> 00:26:17,135
Speaker 2:  or Samsung or somebody to like do the flip phone thing well enough

419
00:26:17,795 --> 00:26:21,095
Speaker 2:  to pull people in? Like could could this be the year that these things start

420
00:26:21,095 --> 00:26:23,135
Speaker 2:  to really take off? Or am I just wishful thinking?

421
00:26:23,975 --> 00:26:27,935
Speaker 7:  I don't know. I feel like I've kind of said that the past three years where

422
00:26:27,955 --> 00:26:31,815
Speaker 7:  I'm like, you know, I don't know, this could be the year. And I, I

423
00:26:31,935 --> 00:26:35,695
Speaker 7:  just have so many like interactions with people when I'm carrying a

424
00:26:35,695 --> 00:26:39,415
Speaker 7:  folding phone or one of the flip phones. So many people will be like, oh,

425
00:26:39,435 --> 00:26:42,935
Speaker 7:  that's that, you know, Samsung phone or a Google phone. They're like, I almost

426
00:26:42,965 --> 00:26:46,485
Speaker 7:  bought that, but then I just got the whatever, like regular

427
00:26:47,045 --> 00:26:50,605
Speaker 7:  slab phone. Yeah. I think there's like, there's a, there's interest,

428
00:26:50,985 --> 00:26:54,925
Speaker 7:  but there's still like a real hesitation from people. 'cause I

429
00:26:55,075 --> 00:26:58,805
Speaker 7:  like, I kind of chalk it up to the durability. I know,

430
00:26:59,685 --> 00:27:03,205
Speaker 7:  I know someone who has like the third generation

431
00:27:03,315 --> 00:27:07,125
Speaker 7:  Samsung flip and that thing

432
00:27:07,675 --> 00:27:11,165
Speaker 7:  doesn't look great. Like the inner screen is all like

433
00:27:11,425 --> 00:27:15,165
Speaker 7:  peeled and gross. I'm like, girl, you need to trade that in.

434
00:27:15,585 --> 00:27:18,805
Speaker 7:  But yeah, that's the kind of thing I'm like, yeah, if I am,

435
00:27:19,355 --> 00:27:22,805
Speaker 7:  like your phone just has to take so much abuse throughout the day. And

436
00:27:23,245 --> 00:27:27,045
Speaker 7:  I think there's a certain person who's willing to be like, yeah, I

437
00:27:27,045 --> 00:27:31,005
Speaker 7:  want all the benefits of this and I'm willing to like, accept the risks of

438
00:27:31,665 --> 00:27:34,205
Speaker 7:  the inner screen. Might do something wonky.

439
00:27:35,405 --> 00:27:39,285
Speaker 7:  IDI don't know how they, how the manufacturers like really

440
00:27:39,285 --> 00:27:43,125
Speaker 7:  address that. I think they've been pushing forward as much as they can with

441
00:27:43,125 --> 00:27:46,925
Speaker 7:  the, the waterproofing. Dust proofing. Is that even

442
00:27:47,245 --> 00:27:51,205
Speaker 7:  possible? Like with a hinge? You know, I think they mitigate it as

443
00:27:51,205 --> 00:27:54,925
Speaker 7:  much as they can and they're kind of like been beefing up

444
00:27:54,935 --> 00:27:58,445
Speaker 7:  their, their repair programs like Samsung,

445
00:27:59,385 --> 00:28:03,325
Speaker 7:  If you buy their like Care plus plan, they'll just repair

446
00:28:03,325 --> 00:28:06,885
Speaker 7:  the inner screen as many times as you want for free. Or like, oh, that's

447
00:28:06,885 --> 00:28:08,325
Speaker 7:  cool for not extra money,

448
00:28:08,705 --> 00:28:11,925
Speaker 2:  But never a great sign that that's a thing they have to offer though. I know.

449
00:28:11,925 --> 00:28:12,725
Speaker 2:  To your point. Yeah, yeah,

450
00:28:12,955 --> 00:28:15,885
Speaker 7:  Yeah. They weren't exactly shouting that from the rooftops either.

451
00:28:16,675 --> 00:28:18,685
Speaker 7:  Yeah. Ask a few questions. Yeah. I

452
00:28:18,685 --> 00:28:22,455
Speaker 2:  Will say the, the z flip six has

453
00:28:22,735 --> 00:28:26,455
Speaker 2:  appeared in the wild around me more than I

454
00:28:26,455 --> 00:28:29,255
Speaker 2:  would've expected. Hmm. And I think part of it is like, I notice everyone

455
00:28:29,255 --> 00:28:31,055
Speaker 2:  because it's so different looking. Yeah.

456
00:28:32,645 --> 00:28:35,985
Speaker 2:  But they're out there. Like I saw, I saw one in a coffee shop this morning.

457
00:28:36,055 --> 00:28:39,545
Speaker 2:  It's just a person sitting there eating a bacon, egg and cheese. And they

458
00:28:39,545 --> 00:28:41,305
Speaker 2:  had a flip phone on the table. Oh wow. And

459
00:28:41,305 --> 00:28:42,025
Speaker 7:  I was just like, let's

460
00:28:42,025 --> 00:28:44,625
Speaker 2:  Go. I love that. I love they were almost certainly an Amazon employee 'cause

461
00:28:44,625 --> 00:28:48,585
Speaker 2:  I was like at HQ two at this coffee shop. Okay. So make of

462
00:28:48,585 --> 00:28:51,985
Speaker 2:  that, which you will. But I think, I think if it's gonna be anything this

463
00:28:51,985 --> 00:28:55,945
Speaker 2:  year, it's there, there might be a folding phone that gets

464
00:28:56,205 --> 00:28:56,625
Speaker 2:  closer.

465
00:28:58,645 --> 00:29:02,625
Speaker 2:  That's it. It, I I have no particular reason to bet on that, but it feels

466
00:29:02,625 --> 00:29:06,385
Speaker 2:  like that is pushing towards being the right size and

467
00:29:06,385 --> 00:29:10,105
Speaker 2:  shape faster than the foldable phones are. And I say that the, the

468
00:29:10,155 --> 00:29:14,105
Speaker 2:  Pixel nine pro fold stupid name kicks ass. Like

469
00:29:14,105 --> 00:29:16,825
Speaker 2:  it's a great phone. Yeah. Yeah. There's so many good things about it. But

470
00:29:17,005 --> 00:29:20,945
Speaker 2:  the problem with those is they're still $1,800. And so I, I

471
00:29:20,945 --> 00:29:24,425
Speaker 2:  wouldn't be shocked to see Samsung come out and like

472
00:29:24,965 --> 00:29:28,705
Speaker 2:  try to knock that price down substantially. Yeah. But

473
00:29:28,705 --> 00:29:32,385
Speaker 2:  also the fact that these phones now didn't go down

474
00:29:32,385 --> 00:29:35,505
Speaker 2:  substantially doesn't necessarily give me great faith that that's gonna come.

475
00:29:36,105 --> 00:29:39,945
Speaker 7:  I know. And they've been so stagnant on the, the fold.

476
00:29:40,215 --> 00:29:43,885
Speaker 7:  It's like every year for the past three years has been like, well

477
00:29:44,595 --> 00:29:47,325
Speaker 7:  it's like two millimeters wider. Right.

478
00:29:48,715 --> 00:29:52,285
Speaker 2:  Just this is it very slowly pulling at the edges of the thing. Yeah.

479
00:29:52,285 --> 00:29:52,765
Speaker 2:  They're

480
00:29:52,765 --> 00:29:56,205
Speaker 7:  Just stretching it a little bit. Yeah. I don't know. That's the only thing

481
00:29:56,205 --> 00:30:00,085
Speaker 7:  that's making me pessimistic about the

482
00:30:00,115 --> 00:30:03,845
Speaker 7:  foldables, particularly Samsung's foldables

483
00:30:03,905 --> 00:30:07,245
Speaker 7:  is I, I haven't seen it. I don't know.

484
00:30:07,825 --> 00:30:11,765
Speaker 7:  Is there, is there really like a fire there to, to go out and

485
00:30:11,765 --> 00:30:15,485
Speaker 7:  capture the, the market for it? Or they just kinda like, eh, I don't know.

486
00:30:15,485 --> 00:30:17,965
Speaker 7:  People aren't buying these things like we thought they would.

487
00:30:18,465 --> 00:30:21,965
Speaker 2:  It sure seems like it's that, but I think there is a chicken and egg thing

488
00:30:21,965 --> 00:30:25,365
Speaker 2:  going on there. Last question and then I'll let you go. If there was going

489
00:30:25,365 --> 00:30:29,245
Speaker 2:  to be one phone company that shocks us this

490
00:30:29,245 --> 00:30:32,085
Speaker 2:  year, does something no one would've expected, who would you bet it's gonna

491
00:30:32,085 --> 00:30:32,165
Speaker 2:  be?

492
00:30:34,045 --> 00:30:37,605
Speaker 7:  I feel like, well, I feel like the wild card is nothing.

493
00:30:38,265 --> 00:30:41,685
Speaker 7:  That's what I was gonna say too. Yeah. Okay. Yeah, because they've been kind

494
00:30:41,685 --> 00:30:45,645
Speaker 7:  of like not on the radar for a minute and I'm like, what, what they, what

495
00:30:45,645 --> 00:30:49,005
Speaker 7:  might they be doing? I feel like it's a company with like

496
00:30:49,705 --> 00:30:52,605
Speaker 7:  enough interesting ideas and enough kind of like

497
00:30:53,595 --> 00:30:57,405
Speaker 7:  they, they've established connections in supply

498
00:30:57,465 --> 00:31:01,045
Speaker 7:  chains and I think maybe they're gonna be in a place to like

499
00:31:01,755 --> 00:31:05,605
Speaker 7:  flex a little bit. I I would be really interested. I don't have any

500
00:31:05,885 --> 00:31:09,165
Speaker 7:  specific idea of what that could be. It just sort of feels like

501
00:31:10,035 --> 00:31:11,205
Speaker 7:  yeah, they could do something.

502
00:31:11,675 --> 00:31:15,565
Speaker 2:  Yeah. Yeah. Carl pay nothing's. CEO has has always said that

503
00:31:16,075 --> 00:31:19,965
Speaker 2:  they did not exist to be a phone company. And it does seem like

504
00:31:20,675 --> 00:31:24,525
Speaker 2:  they're, they're not like a real competitor in this

505
00:31:24,525 --> 00:31:27,165
Speaker 2:  space yet next to, you know, apple and Samsung. But like, they're, they're

506
00:31:27,165 --> 00:31:29,285
Speaker 2:  like you said, they're established. Like that company has proven they can

507
00:31:29,285 --> 00:31:33,245
Speaker 2:  do the thing. And I kind of hope this is the year that

508
00:31:33,245 --> 00:31:37,005
Speaker 2:  they're like, okay, here's, here are our actual ideas. Yeah. I

509
00:31:37,165 --> 00:31:40,365
Speaker 2:  I, I'm, I'm with you. I think if anybody's gonna do it in a way that is like

510
00:31:40,395 --> 00:31:43,765
Speaker 2:  cool and exciting, I would, I would bet on nothing. I have high hopes on

511
00:31:43,765 --> 00:31:43,885
Speaker 2:  that

512
00:31:43,885 --> 00:31:44,285
Speaker 7:  One. Yeah.

513
00:31:44,865 --> 00:31:47,445
Speaker 2:  All right, Alison, thank you as always. There's gonna

514
00:35:18,035 --> 00:35:21,765
Speaker 2:  Alright, we're back. So one of the questions that has been swirling

515
00:35:21,765 --> 00:35:25,445
Speaker 2:  really in the last few weeks, but also over the last few years

516
00:35:26,345 --> 00:35:29,805
Speaker 2:  is this question about how we should think about China's role

517
00:35:30,185 --> 00:35:33,845
Speaker 2:  on the internet. As we've talked about the TikTok ban, we've talked kind

518
00:35:33,845 --> 00:35:37,700
Speaker 2:  of ad nauseum about this idea of the Chinese government being able to

519
00:35:37,985 --> 00:35:41,645
Speaker 2:  get our personal data from TikTok and do

520
00:35:41,755 --> 00:35:45,405
Speaker 2:  something with it. Then people left TikTok and went to

521
00:35:45,435 --> 00:35:48,565
Speaker 2:  RedNote, which is an app that is much more straightforwardly connected to

522
00:35:48,565 --> 00:35:51,885
Speaker 2:  China. There have been all these questions about DeepSeek connection to China

523
00:35:52,105 --> 00:35:55,925
Speaker 2:  and how we should think about using an AI model

524
00:35:55,995 --> 00:35:59,205
Speaker 2:  from China or an AI model from a company from China.

525
00:36:00,075 --> 00:36:03,845
Speaker 2:  This question of what we should be thinking about China,

526
00:36:04,305 --> 00:36:07,965
Speaker 2:  not like big macro politically, but like as people on the

527
00:36:08,165 --> 00:36:11,965
Speaker 2:  internet, is a thing that I have struggled with and would love to have somebody

528
00:36:12,035 --> 00:36:15,925
Speaker 2:  just talk me through. So that's what we're gonna try and

529
00:36:15,925 --> 00:36:19,725
Speaker 2:  do in the next little while here. I asked Cooper, Quentin, who's a

530
00:36:19,725 --> 00:36:22,965
Speaker 2:  senior staff technologist at the EFF, The Electronic Frontier Foundation

531
00:36:23,505 --> 00:36:27,445
Speaker 2:  to come on and just walk me through how he thinks about all of this. Cooper

532
00:36:27,475 --> 00:36:31,325
Speaker 2:  does things like help activists think about security training,

533
00:36:31,345 --> 00:36:34,645
Speaker 2:  and he works with nonprofits and vulnerable populations,

534
00:36:35,225 --> 00:36:39,125
Speaker 2:  all thinking about how to operate online in a

535
00:36:39,155 --> 00:36:43,045
Speaker 2:  safe and productive and private and useful way. And he's

536
00:36:43,045 --> 00:36:45,845
Speaker 2:  also somebody who's been thinking about China specifically a lot for a long

537
00:36:45,845 --> 00:36:49,005
Speaker 2:  time. And he is just going to walk me through

538
00:36:49,945 --> 00:36:52,645
Speaker 2:  how we're supposed to think about all of this, how it should weigh on our

539
00:36:52,845 --> 00:36:56,605
Speaker 2:  decisions about what we use and what data we reveal and whether we want

540
00:36:56,665 --> 00:37:00,125
Speaker 2:  TikTok to be banned or sold or whatever. We're just gonna try to make sense

541
00:37:00,125 --> 00:37:03,325
Speaker 2:  of it all. So let's just dive in. Cooper, welcome to the show.

542
00:37:03,905 --> 00:37:07,245
Speaker 2:  So I guess maybe the easiest place to start is like, let's just lay the land

543
00:37:07,245 --> 00:37:10,885
Speaker 2:  a little bit in terms of like what are you thinking about

544
00:37:11,145 --> 00:37:14,725
Speaker 2:  and researching and talking to folks about right now as it pertains to

545
00:37:15,255 --> 00:37:18,445
Speaker 2:  China in particular, but also just kind of the internet more broadly. Like

546
00:37:18,445 --> 00:37:19,885
Speaker 2:  what's your angle on this space right now?

547
00:37:20,425 --> 00:37:24,245
Speaker 8:  So for me, there's two topics that I'm interested in and that I think

548
00:37:24,315 --> 00:37:27,125
Speaker 8:  both come up when we're talking about this.

549
00:37:28,345 --> 00:37:31,925
Speaker 8:  One is surveillance capitalism and this

550
00:37:32,115 --> 00:37:35,965
Speaker 8:  sort of industry of data brokers and

551
00:37:36,595 --> 00:37:40,525
Speaker 8:  selling your data and like all of this industry that

552
00:37:40,545 --> 00:37:44,525
Speaker 8:  the internet has really been built on, right? And how

553
00:37:44,555 --> 00:37:48,405
Speaker 8:  your data flows and like whether you have control of it and what can be done

554
00:37:48,405 --> 00:37:52,005
Speaker 8:  with that, right? And there's some really interesting things in there

555
00:37:52,115 --> 00:37:55,805
Speaker 8:  like law enforcement buying access to that data so that they

556
00:37:55,805 --> 00:37:59,765
Speaker 8:  don't have to deal with pesky things like warrants, right?

557
00:38:00,265 --> 00:38:04,205
Speaker 8:  So that's all really interesting to me. The other thing that I've studied

558
00:38:04,205 --> 00:38:08,045
Speaker 8:  pretty extensively in my time at EFF is malware

559
00:38:09,105 --> 00:38:12,965
Speaker 8:  and spyware, specifically the types of spyware they're used to spy

560
00:38:13,145 --> 00:38:17,085
Speaker 8:  on, activists, journalists, human

561
00:38:17,085 --> 00:38:21,045
Speaker 8:  rights defenders, and you know, people who are trying to exercise

562
00:38:21,075 --> 00:38:24,765
Speaker 8:  free expression and trying to, you know,

563
00:38:24,955 --> 00:38:28,565
Speaker 8:  improve their lives and fight against, you know, their

564
00:38:28,565 --> 00:38:31,805
Speaker 8:  governments or governments, you know, of countries which they used to be

565
00:38:31,805 --> 00:38:35,440
Speaker 8:  a part of oftentimes, right? Like oftentimes these are people who, who have

566
00:38:35,440 --> 00:38:39,365
Speaker 8:  left their countries for fear of oppression and are still though doing the

567
00:38:39,365 --> 00:38:42,405
Speaker 8:  work of, you know, fighting against corruption in the country that they left.

568
00:38:42,905 --> 00:38:46,285
Speaker 8:  And so in the conversations around TikTok and around Red Book and around

569
00:38:47,205 --> 00:38:50,245
Speaker 8:  DeepSeek, I see echoes of all of these topics.

570
00:38:51,365 --> 00:38:54,085
Speaker 2:  Interesting. How so where do you, what, what echoes are you seeing right

571
00:38:54,085 --> 00:38:54,205
Speaker 2:  now?

572
00:38:54,975 --> 00:38:58,755
Speaker 8:  To go back a little bit, right? Like I, I think that the

573
00:38:59,435 --> 00:39:03,315
Speaker 8:  reaction to TikTok going away and people starting to

574
00:39:03,315 --> 00:39:07,075
Speaker 8:  join Little Red Book right, is really

575
00:39:07,125 --> 00:39:07,475
Speaker 8:  funny.

576
00:39:07,775 --> 00:39:11,635
Speaker 2:  The fact that RedNote is actually technically called Little Red Book is one

577
00:39:11,635 --> 00:39:15,555
Speaker 2:  of my favorite discoveries of 2025. Enjoyed that to no end.

578
00:39:15,855 --> 00:39:19,835
Speaker 2:  It is the funniest and most like direct beyond parody thing

579
00:39:19,835 --> 00:39:21,275
Speaker 2:  we could have possibly done in that moment.

580
00:39:21,455 --> 00:39:24,955
Speaker 8:  Should we break that down? Because it's, I think it's a, I think it's really

581
00:39:25,235 --> 00:39:27,755
Speaker 8:  interesting, like sure, please, little Red Book is, is

582
00:39:28,965 --> 00:39:32,595
Speaker 8:  Mao's little Red book. This was like one of the main tracks of

583
00:39:32,775 --> 00:39:36,235
Speaker 8:  Maoism that was given out to people in

584
00:39:36,595 --> 00:39:40,315
Speaker 8:  revolutionary China, right? Like this is, this is like

585
00:39:40,895 --> 00:39:44,355
Speaker 8:  the, you know, it'd be, it'd be like calling an American social network the

586
00:39:44,355 --> 00:39:48,235
Speaker 8:  Federalist Papers or something like that, right? Like it's so on the

587
00:39:48,235 --> 00:39:51,915
Speaker 8:  nose, right? Like this is, you know, this, this is an

588
00:39:51,915 --> 00:39:55,675
Speaker 8:  application of the ccp, right? Like absolutely

589
00:39:55,695 --> 00:39:59,395
Speaker 8:  100% we're not, you know, we're not pretending otherwise,

590
00:39:59,445 --> 00:40:03,435
Speaker 8:  right? But the, the reaction to me was so funny. It's such a

591
00:40:03,435 --> 00:40:07,155
Speaker 8:  like, like a prototypical reaction of like a 13-year-old,

592
00:40:07,685 --> 00:40:11,515
Speaker 8:  right? To, to like, well, you know, we're gonna have to ban

593
00:40:11,655 --> 00:40:15,635
Speaker 8:  TikTok because we don't want your data going to China

594
00:40:15,695 --> 00:40:19,275
Speaker 8:  and there's some serious privacy issues and national security issues here.

595
00:40:19,655 --> 00:40:23,195
Speaker 8:  And people's reaction was, oh, you don't want me to like

596
00:40:23,325 --> 00:40:27,315
Speaker 8:  China, you don't want me to like China, guess what? I

597
00:40:27,315 --> 00:40:31,195
Speaker 8:  love China, right? I am gonna give China all my data. I

598
00:40:31,195 --> 00:40:34,875
Speaker 8:  am mailing a copy of my birth certificate to Xi Jinping

599
00:40:35,005 --> 00:40:38,435
Speaker 8:  right now. Like, and I saw videos of people doing like putting,

600
00:40:38,965 --> 00:40:42,275
Speaker 8:  pretending to like, put data in an envelope and like mail it to the Chinese

601
00:40:42,275 --> 00:40:46,155
Speaker 8:  government. Like, and this is, it's a

602
00:40:46,155 --> 00:40:49,435
Speaker 8:  really funny reaction because people are like, yeah,

603
00:40:50,035 --> 00:40:53,465
Speaker 8:  I know, I know that they're taking all my data.

604
00:40:54,305 --> 00:40:58,265
Speaker 8:  I don't care. Why should I care? You took all my

605
00:40:58,265 --> 00:41:02,225
Speaker 8:  data anyway. US companies took all my data, meta took all my

606
00:41:02,225 --> 00:41:05,865
Speaker 8:  data, right? Twitter took all my data. The US government

607
00:41:06,005 --> 00:41:09,865
Speaker 8:  has an, and like it has all my data and is constantly being leaked. So

608
00:41:09,965 --> 00:41:13,945
Speaker 8:  why do I care if China has it? Like, and in fact because you

609
00:41:13,945 --> 00:41:17,935
Speaker 8:  don't like that, it makes me wanna do it even more, right?

610
00:41:18,395 --> 00:41:20,815
Speaker 8:  And that's, it's so interesting to me.

611
00:41:21,595 --> 00:41:25,065
Speaker 2:  I'm forever somewhat compelled by that

612
00:41:25,465 --> 00:41:29,345
Speaker 2:  argument. Like, I, I think it, it's, it's so easy in this time that we

613
00:41:29,345 --> 00:41:33,245
Speaker 2:  live in to fall into that particular brand of nihilism, which is like,

614
00:41:33,245 --> 00:41:36,525
Speaker 2:  look, if, if China wants to know information about me, China has so many

615
00:41:36,525 --> 00:41:40,325
Speaker 2:  ways that are more efficient than developing a social network that

616
00:41:40,325 --> 00:41:43,765
Speaker 2:  like, right? I I I struggle with this personally of like how much

617
00:41:44,505 --> 00:41:48,325
Speaker 2:  is the a how much of this is sort of real threat versus like

618
00:41:48,755 --> 00:41:52,565
Speaker 2:  potential, maybe possible several steps down the road

619
00:41:52,625 --> 00:41:56,565
Speaker 2:  threat and what does it mean in

620
00:41:56,645 --> 00:42:00,445
Speaker 2:  a practical sense that someone in the Chinese government can theoretically

621
00:42:00,445 --> 00:42:03,805
Speaker 2:  find out what I watch on TikTok? Like who cares? Right?

622
00:42:04,325 --> 00:42:08,125
Speaker 2:  I like, I sort of intellectually know that that's an argument that will

623
00:42:08,155 --> 00:42:12,005
Speaker 2:  lead only to ruin and trouble, but I kind of understand how people

624
00:42:12,035 --> 00:42:12,525
Speaker 2:  land there.

625
00:42:13,115 --> 00:42:16,965
Speaker 8:  It's, yeah, definitely. I mean, like, it it is a form of privacy

626
00:42:17,245 --> 00:42:20,845
Speaker 8:  nihilism, right? Yeah, yeah. At the end of the day, absolutely.

627
00:42:21,345 --> 00:42:24,965
Speaker 8:  But like, it's understandable that people have

628
00:42:25,315 --> 00:42:29,125
Speaker 8:  come to privacy nihilism, right? Like we don't, we,

629
00:42:29,185 --> 00:42:32,525
Speaker 8:  we don't have anything that anybody can do in like a,

630
00:42:33,225 --> 00:42:36,245
Speaker 8:  you know, like in terms of laws, in terms of

631
00:42:36,775 --> 00:42:40,285
Speaker 8:  litigation, in terms like there are no legal protections for people's data,

632
00:42:40,295 --> 00:42:44,125
Speaker 8:  right? Zero. Unless you happen to live in California, right?

633
00:42:44,135 --> 00:42:47,605
Speaker 8:  Where there's like some okay. Privacy laws, right?

634
00:42:47,745 --> 00:42:51,685
Speaker 8:  That's still like, don't, don't seem to prevent this

635
00:42:51,685 --> 00:42:54,685
Speaker 8:  data from ending up in the hands of these corporations. It just means that

636
00:42:54,685 --> 00:42:58,205
Speaker 8:  you can go request your data and remove your data, which is better than nothing

637
00:42:58,665 --> 00:43:02,565
Speaker 8:  for sure. But like people, I think it's, it's understandable why

638
00:43:02,565 --> 00:43:05,725
Speaker 8:  people end up with this sort of privacy nihilism, right?

639
00:43:06,905 --> 00:43:10,845
Speaker 8:  And because we've just, like, we've accepted as

640
00:43:11,005 --> 00:43:14,925
Speaker 8:  a, I don't, maybe accepted isn't the right word, but like we've, we have,

641
00:43:15,305 --> 00:43:18,805
Speaker 8:  as a society, this is where we're at, right? Like, you will give up your

642
00:43:18,805 --> 00:43:22,405
Speaker 8:  data in exchange for some kind of crappy

643
00:43:22,805 --> 00:43:26,685
Speaker 8:  services from Facebook and like, there's nothing you can do about

644
00:43:26,685 --> 00:43:30,365
Speaker 8:  it because If you wanna participate in society, you have to be on these kind

645
00:43:30,365 --> 00:43:31,205
Speaker 8:  of crappy services.

646
00:43:31,825 --> 00:43:35,765
Speaker 2:  So how do you understand the difference between what

647
00:43:35,765 --> 00:43:39,345
Speaker 2:  it means to do that to a company like Google or Meta

648
00:43:40,045 --> 00:43:43,715
Speaker 2:  and doing that with a

649
00:43:43,715 --> 00:43:47,435
Speaker 2:  country or a, a government like the Chinese Communist Party? Like are,

650
00:43:47,495 --> 00:43:50,555
Speaker 2:  are those meaningfully different things? I think we have a hard time talking

651
00:43:50,555 --> 00:43:54,515
Speaker 2:  about what China is and what that threat looks like

652
00:43:54,535 --> 00:43:57,915
Speaker 2:  and why that is dangerous in a way that having it in Google servers

653
00:43:59,055 --> 00:44:01,925
Speaker 2:  isn't, or is differently dangerous. Like how do you think through the difference

654
00:44:01,925 --> 00:44:02,085
Speaker 2:  there?

655
00:44:02,845 --> 00:44:06,725
Speaker 8:  I always say it depends on your threat model, right? Like If

656
00:44:06,725 --> 00:44:10,285
Speaker 8:  you have family in China, If you have friends in China, right?

657
00:44:10,515 --> 00:44:14,085
Speaker 8:  Like, or If you, I don't know, work in

658
00:44:15,315 --> 00:44:18,875
Speaker 8:  national security, right? Or if your work is like related to something that

659
00:44:19,535 --> 00:44:23,235
Speaker 8:  has historically been a target of Chinese espionage,

660
00:44:23,805 --> 00:44:27,715
Speaker 8:  right? Then that's one very specific threat model, right? Sure. Where like

661
00:44:28,475 --> 00:44:32,325
Speaker 8:  the CCP actually should be in your threat model, right? Like, you

662
00:44:32,325 --> 00:44:36,245
Speaker 8:  don't want to search for Taiwan

663
00:44:37,545 --> 00:44:41,315
Speaker 8:  and have that or Tiananmen Square and have that come back

664
00:44:41,655 --> 00:44:45,195
Speaker 8:  to investigation of your family in China,

665
00:44:45,755 --> 00:44:49,515
Speaker 8:  right? And like, you know, If you're, if you're in an industry that is

666
00:44:49,715 --> 00:44:53,475
Speaker 8:  the target of Chinese espionage, right? Like this, like information that

667
00:44:53,475 --> 00:44:56,955
Speaker 8:  you give could be used for, you know, phishing or,

668
00:44:57,295 --> 00:45:00,915
Speaker 8:  or you know, other sort of targeted, more targeted

669
00:45:01,225 --> 00:45:03,155
Speaker 8:  espionage attacks, right? Right.

670
00:45:03,195 --> 00:45:06,955
Speaker 2:  Phishing is a really interesting one by the way. I think I've,

671
00:45:06,955 --> 00:45:10,835
Speaker 2:  I've, I've heard a couple of folks mention that in this context in a

672
00:45:10,835 --> 00:45:13,555
Speaker 2:  way that I have actually found really instructive because that's a good example

673
00:45:13,655 --> 00:45:16,955
Speaker 2:  of things, you know, about what I watch on TikTok

674
00:45:17,975 --> 00:45:21,915
Speaker 2:  become ways in which to appear to be someone I know

675
00:45:22,335 --> 00:45:26,075
Speaker 2:  or have information about me that you can then use to get other more

676
00:45:26,355 --> 00:45:29,395
Speaker 2:  dangerous information about me. Sure. And I think like for sure, that to

677
00:45:29,395 --> 00:45:33,155
Speaker 2:  me is, is 'cause it's like if I'm not taking a picture of my bank

678
00:45:33,155 --> 00:45:36,995
Speaker 2:  account information and posting it on TikTok, like the, the sort of

679
00:45:36,995 --> 00:45:40,955
Speaker 2:  direct threat there is lesser, but there's this, this data you can use to

680
00:45:40,955 --> 00:45:43,875
Speaker 2:  understand me better, right? Which you can use to get other information out

681
00:45:43,875 --> 00:45:47,795
Speaker 2:  of me is like, that's the kind of step I think people often fail to understand.

682
00:45:48,215 --> 00:45:51,995
Speaker 8:  But it's still hard for me though to see actually a meaningful difference,

683
00:45:51,995 --> 00:45:55,475
Speaker 8:  right? Like, because this data already exists anyway, right?

684
00:45:56,025 --> 00:45:59,755
Speaker 8:  Meta has this data, Google has this data, right? And like, and so do

685
00:45:59,955 --> 00:46:02,795
Speaker 8:  a dozen data brokers, right? Like you can,

686
00:46:03,735 --> 00:46:07,555
Speaker 8:  you know, journalists keep showing that, that you

687
00:46:07,615 --> 00:46:11,555
Speaker 8:  can get people's location in near real time just

688
00:46:11,625 --> 00:46:15,315
Speaker 8:  from the advertising bid stream, which is where like

689
00:46:15,825 --> 00:46:19,595
Speaker 8:  when you are using an app or whatever, and ads are showing up though, people

690
00:46:19,595 --> 00:46:23,435
Speaker 8:  are bidding in real time on who gets to sell you ads. And that

691
00:46:23,435 --> 00:46:26,595
Speaker 8:  data is like, and there's data in there about like your demographics,

692
00:46:27,255 --> 00:46:30,635
Speaker 8:  how old you are, what kind of phone you have, what your interests are, there's

693
00:46:30,635 --> 00:46:34,595
Speaker 8:  data about your location, right? Like all of this data is just flowing

694
00:46:34,595 --> 00:46:38,195
Speaker 8:  around the internet all the time, and there's no reason that the

695
00:46:39,275 --> 00:46:43,235
Speaker 8:  CCP can't just get that data from that source, right?

696
00:46:43,425 --> 00:46:47,355
Speaker 8:  Like there's no reason that they can't get it by taking out ads

697
00:46:47,655 --> 00:46:51,155
Speaker 8:  in meta, right? Like there's no reason they can't create a US

698
00:46:51,295 --> 00:46:55,155
Speaker 8:  cutout and make a partnership with Meta or, or with

699
00:46:55,215 --> 00:46:58,795
Speaker 8:  Google to get this data so like they can

700
00:46:59,155 --> 00:47:02,555
Speaker 8:  get it directly from, you know, little Red Book or,

701
00:47:02,935 --> 00:47:06,915
Speaker 8:  you know, possibly from, from TikTok. There are

702
00:47:06,915 --> 00:47:10,875
Speaker 8:  easier ways to get the data actually, right? Like yeah, the target audience

703
00:47:10,875 --> 00:47:14,835
Speaker 8:  for Little Red Book was not like data collection of Americans, right?

704
00:47:14,865 --> 00:47:18,635
Speaker 8:  Like this was an, this was like a p kind of Pinterest

705
00:47:18,635 --> 00:47:22,435
Speaker 8:  like application, like a kind of an intersection between like Pinterest and

706
00:47:22,455 --> 00:47:25,795
Speaker 8:  TikTok, right? That was primarily targeted at like

707
00:47:26,255 --> 00:47:30,165
Speaker 8:  people in women in China and people like

708
00:47:30,165 --> 00:47:34,125
Speaker 8:  talking to relatives or whatever in China, right? Like this was targeted

709
00:47:34,225 --> 00:47:38,165
Speaker 8:  at Chinese people in China, right? So like there

710
00:47:38,165 --> 00:47:42,085
Speaker 8:  are other ways to get this data and it's all like, none

711
00:47:42,085 --> 00:47:44,445
Speaker 8:  of it is good to be clear. Right?

712
00:47:44,765 --> 00:47:47,165
Speaker 2:  I was gonna say, you sound an awful lot like a privacy nihilist,

713
00:47:47,855 --> 00:47:49,245
Speaker 8:  Right? No, yeah. I

714
00:47:50,835 --> 00:47:54,405
Speaker 8:  it's so, it's so easy to go into privacy nihilism talking about this, right?

715
00:47:54,405 --> 00:47:58,045
Speaker 8:  Yeah. But like, and I think people are correctly frustrated

716
00:47:58,475 --> 00:48:02,205
Speaker 8:  with Silicon Valley oligarchs and like US surveillance capitalism,

717
00:48:02,295 --> 00:48:05,085
Speaker 8:  right? It's a bad industry

718
00:48:06,155 --> 00:48:10,125
Speaker 8:  that should not exist, right? Like this is not a good thing.

719
00:48:10,965 --> 00:48:14,885
Speaker 8:  I don't think that trading in that

720
00:48:15,425 --> 00:48:19,325
Speaker 8:  for CCP surveillance is going to make

721
00:48:19,325 --> 00:48:23,125
Speaker 8:  anyone's lives meaningfully better. Sure. Like they are

722
00:48:23,125 --> 00:48:26,925
Speaker 8:  both bad. Two things can be bad, right? They are both

723
00:48:27,025 --> 00:48:30,645
Speaker 8:  bad in different ways and, and in a lot of the same ways,

724
00:48:30,815 --> 00:48:34,405
Speaker 8:  right? Like in the end, the most useful, like for

725
00:48:34,405 --> 00:48:38,325
Speaker 8:  99% of people, the most lucrative use of this data

726
00:48:38,865 --> 00:48:42,765
Speaker 8:  is going to, for the CCP, is going to be to sell

727
00:48:42,765 --> 00:48:46,605
Speaker 8:  it and sell advertisements off it the same way that it is for Silicon

728
00:48:46,605 --> 00:48:50,445
Speaker 8:  Valley, right? Right. Like surveillance capitalism cuts both ways for

729
00:48:50,465 --> 00:48:53,725
Speaker 8:  Bo you know, for, for both organizations, right? Yeah.

730
00:48:53,865 --> 00:48:57,325
Speaker 2:  So I guess if, if, if the, if the way of thinking about it is

731
00:48:58,275 --> 00:49:02,245
Speaker 2:  it's, it's definitely not a better choice to give that data to the CCP

732
00:49:02,245 --> 00:49:06,005
Speaker 2:  instead of to Google or meta, is it a substantially worse

733
00:49:06,065 --> 00:49:09,885
Speaker 2:  choice to do that? Again, I I think we, we should, we should

734
00:49:09,885 --> 00:49:12,645
Speaker 2:  carve out the people who have, like you were saying, the sort of obvious

735
00:49:12,645 --> 00:49:16,165
Speaker 2:  threat models. I think there, there's a set of people who

736
00:49:16,305 --> 00:49:19,325
Speaker 2:  should think about all of this like minute to minute and day to day more

737
00:49:19,325 --> 00:49:22,405
Speaker 2:  carefully, right? And, and we can talk about those people, but I think for,

738
00:49:22,505 --> 00:49:25,885
Speaker 2:  for the people who ask you questions like, who cares? I have nothing to hide.

739
00:49:26,625 --> 00:49:27,805
Speaker 2:  Is it that different a trade?

740
00:49:28,525 --> 00:49:32,285
Speaker 8:  I really don't think that it is. Like I don't see any good argument

741
00:49:32,715 --> 00:49:35,885
Speaker 8:  that it's that different of a trade, right? Like, and what we,

742
00:49:36,515 --> 00:49:40,325
Speaker 8:  what we need, and maybe I'm, I'm stop me if I'm jumping the gun here, but

743
00:49:40,325 --> 00:49:44,005
Speaker 8:  like we need desperately federal

744
00:49:44,005 --> 00:49:47,805
Speaker 8:  privacy law. We desperately need federal laws that let

745
00:49:47,865 --> 00:49:51,845
Speaker 8:  us control our data, that stop our, that let us stop

746
00:49:51,845 --> 00:49:55,285
Speaker 8:  our data from being sold that let us actually have meaningful

747
00:49:56,385 --> 00:50:00,005
Speaker 8:  opt-in consent and to, into who we give our data to an

748
00:50:00,005 --> 00:50:03,765
Speaker 8:  understanding of what's being done with that data and a private right of

749
00:50:03,765 --> 00:50:07,685
Speaker 8:  action to sue when companies misuse our data or take our data

750
00:50:07,685 --> 00:50:11,005
Speaker 8:  without our consent. This would go a long way to solving

751
00:50:11,705 --> 00:50:15,245
Speaker 8:  the problem of the CCP stealing people's data.

752
00:50:15,715 --> 00:50:19,605
Speaker 8:  This would go a long way to solving the problem of Silicon Valley surveillance,

753
00:50:19,605 --> 00:50:23,165
Speaker 8:  capitalism and meta and Google stealing people's data, right? This would

754
00:50:23,165 --> 00:50:27,085
Speaker 8:  go a long way to solving the problem of the like constant background noise

755
00:50:27,165 --> 00:50:31,085
Speaker 8:  of data breaches, right? And, and data being breached and

756
00:50:31,085 --> 00:50:34,765
Speaker 8:  then used in phishing campaigns and everything else, right? Data

757
00:50:34,765 --> 00:50:37,525
Speaker 8:  breaches are another angle, like argue one could argue

758
00:50:38,475 --> 00:50:42,085
Speaker 8:  that like, you know, Google and Meta have pretty good

759
00:50:42,445 --> 00:50:45,605
Speaker 8:  security teams and like your data is safer from a data breach

760
00:50:46,235 --> 00:50:50,125
Speaker 8:  with them than it is in, you know, in the hands of some of

761
00:50:50,125 --> 00:50:53,925
Speaker 8:  these Chinese apps. Right? But I don't, I don't know that that's a, I

762
00:50:53,925 --> 00:50:56,965
Speaker 8:  don't think that that's a strong argument because data breaches still happen

763
00:50:57,225 --> 00:51:00,685
Speaker 8:  all the time in the US Yeah. Right? Like there's all sorts of data breaches

764
00:51:00,695 --> 00:51:04,405
Speaker 8:  every day and you know, even if, even if Google and

765
00:51:04,515 --> 00:51:08,165
Speaker 8:  Meta themselves aren't getting breached yet, and I think, you know, on a

766
00:51:08,165 --> 00:51:12,125
Speaker 8:  long enough timeline, the probability approach is a hundred percent that

767
00:51:12,125 --> 00:51:16,005
Speaker 8:  there will be a data breach from one of these companies, right? But

768
00:51:16,005 --> 00:51:19,285
Speaker 8:  like, even if those haven't been data like breached yet, they still have

769
00:51:19,285 --> 00:51:23,125
Speaker 8:  that data and they still sell it in the form of ad targeting, right?

770
00:51:23,265 --> 00:51:25,565
Speaker 8:  So like it doesn't need to be breached when you can just buy it.

771
00:51:26,085 --> 00:51:29,405
Speaker 2:  Right? So I is is it possible then that one

772
00:51:29,665 --> 00:51:30,525
Speaker 2:  reason to

773
00:51:32,375 --> 00:51:35,525
Speaker 2:  think about keeping this data in the United States is that, you know, in

774
00:51:35,525 --> 00:51:38,925
Speaker 2:  theory we live in a democracy that can, in theory pass laws and that

775
00:51:39,685 --> 00:51:42,925
Speaker 2:  I, if we are able to regulate this, at least we can like

776
00:51:42,925 --> 00:51:46,525
Speaker 2:  retroactively make some of this stuff better in a way that whatever you're

777
00:51:46,525 --> 00:51:50,485
Speaker 2:  dumping onto RedNote is, is gone and lost and there's nothing you can do

778
00:51:50,485 --> 00:51:54,325
Speaker 2:  about it. I feel like I just said like 11 glass half full things

779
00:51:54,325 --> 00:51:57,405
Speaker 2:  in a row to get to that point. Yeah. But is that at least, is that at least

780
00:51:57,405 --> 00:51:58,965
Speaker 2:  an argument that sort of makes sense?

781
00:52:00,165 --> 00:52:02,045
Speaker 8:  I think it's a very optimistic argument.

782
00:52:02,445 --> 00:52:02,605
Speaker 2:  Yeah,

783
00:52:02,725 --> 00:52:03,165
Speaker 8:  I would agree.

784
00:52:04,345 --> 00:52:06,365
Speaker 2:  Listen, I said theoretically a bunch of times,

785
00:52:06,825 --> 00:52:10,645
Speaker 8:  But yeah, I mean, you know, certainly

786
00:52:10,865 --> 00:52:14,325
Speaker 8:  if we one day have a functioning congress

787
00:52:14,705 --> 00:52:18,685
Speaker 8:  and you know, certainly if we were ever to

788
00:52:18,685 --> 00:52:22,245
Speaker 8:  get any sort of federal privacy law, right?

789
00:52:22,645 --> 00:52:26,565
Speaker 8:  Domestic privacy law. So yeah, it, it is possible that that could apply to,

790
00:52:26,625 --> 00:52:30,405
Speaker 8:  to retroactively gather data about you. And that is, I guess that is

791
00:52:30,585 --> 00:52:34,525
Speaker 8:  one, one reason it's not, I mean, I think you yourself would

792
00:52:34,525 --> 00:52:36,965
Speaker 8:  admit it's not the most compelling reason. No.

793
00:52:37,165 --> 00:52:38,485
Speaker 2:  Right? It's not. Yeah.

794
00:52:38,875 --> 00:52:42,365
Speaker 8:  There's another compelling reason not to have any of these apps on your phone,

795
00:52:42,775 --> 00:52:46,605
Speaker 8:  which is just that, like what, and the compelling reason is

796
00:52:46,605 --> 00:52:50,485
Speaker 8:  who do you trust to run code on your phone, right? Like, who do you

797
00:52:50,485 --> 00:52:54,445
Speaker 8:  trust to have control of your phone? And I think a lot of people

798
00:52:54,445 --> 00:52:57,845
Speaker 8:  will say, I don't care if Meta or the CCP

799
00:52:58,265 --> 00:53:01,405
Speaker 8:  has control of my phone, right. As a form of, again, privacy nihilism.

800
00:53:02,165 --> 00:53:06,045
Speaker 8:  I don't know. It's, it's, I think each person needs to do a little bit

801
00:53:06,045 --> 00:53:09,525
Speaker 8:  of threat modeling and think about that, right? Like for, for

802
00:53:10,005 --> 00:53:13,125
Speaker 8:  whatever it's worth, Google and Facebook have pretty good

803
00:53:14,365 --> 00:53:17,325
Speaker 8:  security engineering, right? And like people have looked at these apps, whereas

804
00:53:17,395 --> 00:53:21,045
Speaker 8:  like some of these other apps don't have as good a security engineering

805
00:53:21,045 --> 00:53:25,005
Speaker 8:  necessarily, right? So like the, the possibility that you'll be

806
00:53:25,060 --> 00:53:29,045
Speaker 8:  be putting an app on your phone, which is poorly programmed

807
00:53:29,045 --> 00:53:32,965
Speaker 8:  and is not using things like https is not using, you know,

808
00:53:33,025 --> 00:53:36,605
Speaker 8:  is not using other, other kind of standard technologies and is therefore

809
00:53:36,605 --> 00:53:40,285
Speaker 8:  like leaking your data and causing, you know, potential security issues.

810
00:53:40,695 --> 00:53:44,405
Speaker 8:  Right? Like that is a, that is a, a thing that I think people should

811
00:53:44,645 --> 00:53:44,765
Speaker 8:  consider.

812
00:53:45,235 --> 00:53:48,085
Speaker 2:  Yeah, that makes a lot of sense. Can you walk me through how you think about

813
00:53:48,595 --> 00:53:51,725
Speaker 2:  kind of the average person's threat modeling? I mean, you, you, you mentioned

814
00:53:51,725 --> 00:53:55,605
Speaker 2:  kind of that, that first rung of people who have, have some

815
00:53:56,265 --> 00:54:00,125
Speaker 2:  direct threat in, in some like, sort of the one degree removed

816
00:54:00,125 --> 00:54:03,885
Speaker 2:  from like a, a real possible threat. But I think

817
00:54:03,995 --> 00:54:06,325
Speaker 2:  that that's a big group of people. I think that's a bigger group of people

818
00:54:06,325 --> 00:54:08,805
Speaker 2:  than we often give it credit for, but that's not

819
00:54:09,725 --> 00:54:13,295
Speaker 2:  everybody. And I think there are lots of people who are not even sure how

820
00:54:13,295 --> 00:54:17,055
Speaker 2:  to think about those threat models. Like how do you talk people through how

821
00:54:17,055 --> 00:54:17,775
Speaker 2:  to think about that stuff?

822
00:54:19,075 --> 00:54:22,485
Speaker 8:  Sure. Unfortunately, for a large percentage of Americans,

823
00:54:22,905 --> 00:54:25,965
Speaker 8:  the US government is, is a very big

824
00:54:26,475 --> 00:54:30,325
Speaker 8:  obvious threat, right? Like anybody, anybody who is

825
00:54:30,325 --> 00:54:34,165
Speaker 8:  an immigrant here, right? Anybody who is a, you know, not a

826
00:54:34,165 --> 00:54:37,965
Speaker 8:  born citizen, but a, you know, a a a on a visa

827
00:54:38,065 --> 00:54:41,205
Speaker 8:  or a citizen, you know, through a green card or

828
00:54:41,755 --> 00:54:45,445
Speaker 8:  anybody who is trans right? Or

829
00:54:45,445 --> 00:54:49,325
Speaker 8:  gender non-binary, right? Like the, the obvious

830
00:54:49,325 --> 00:54:53,165
Speaker 8:  threats from the American government, unfortunately are

831
00:54:53,235 --> 00:54:56,485
Speaker 8:  much more real than any, you know, sort of perceived threats.

832
00:54:56,955 --> 00:55:00,725
Speaker 8:  Yeah. You know, future threats from the ccp. But like, the way that I,

833
00:55:00,965 --> 00:55:03,765
Speaker 8:  I would kind of walk people through this is to,

834
00:55:04,785 --> 00:55:08,445
Speaker 8:  you know, first think about like what you know, where you work, what access

835
00:55:08,465 --> 00:55:12,445
Speaker 8:  you have, that could be interesting to other people, right? Like for

836
00:55:12,445 --> 00:55:16,365
Speaker 8:  example, If you work in telecom, right? Like If you work at at and

837
00:55:16,445 --> 00:55:20,405
Speaker 8:  t or Verizon, right? Like, or one of those phone companies, look

838
00:55:20,405 --> 00:55:23,365
Speaker 8:  at what just happened with Salt Typhoon, right? Like, you are definitely

839
00:55:24,045 --> 00:55:27,965
Speaker 8:  a potential target for espionage. You know, anybody who works for

840
00:55:27,985 --> 00:55:31,805
Speaker 8:  the government is a potential target for espionage, right? You know, obviously

841
00:55:31,805 --> 00:55:34,325
Speaker 8:  people that have family there, we kind of went over that, right? Like that's

842
00:55:34,325 --> 00:55:37,925
Speaker 8:  a, that's a pretty obvious threat metal there. I think

843
00:55:38,075 --> 00:55:41,885
Speaker 8:  some of the less obvious threat metals are like industry, right? Like,

844
00:55:42,115 --> 00:55:45,845
Speaker 8:  like anybody in any industry can, obviously we target,

845
00:55:45,875 --> 00:55:49,485
Speaker 8:  like we know that, you know, there've been espionage from China

846
00:55:49,665 --> 00:55:53,165
Speaker 8:  on like, you know, the medical or you know, the, the sort of drug industry

847
00:55:53,265 --> 00:55:56,965
Speaker 8:  in America, right? And like aviation industry and things like that.

848
00:55:57,425 --> 00:56:01,405
Speaker 8:  You might also not really care about that, right? Like, you

849
00:56:01,405 --> 00:56:05,125
Speaker 8:  might look at your situation being paid poorly in the drug industry and be

850
00:56:05,125 --> 00:56:08,965
Speaker 8:  like, what do I care If, you know, if if Chinese

851
00:56:09,215 --> 00:56:12,445
Speaker 8:  spies want to use me to get to, to get to patent

852
00:56:12,965 --> 00:56:13,245
Speaker 8:  documents,

853
00:56:13,595 --> 00:56:15,005
Speaker 2:  Fish away friends. Yeah.

854
00:56:15,695 --> 00:56:18,725
Speaker 8:  Right? Like, they should pay me more if they want me to care about that.

855
00:56:19,265 --> 00:56:23,060
Speaker 8:  And that's pretty understandable. The, the consequences for you, you

856
00:56:23,060 --> 00:56:26,565
Speaker 8:  could actually be pretty severe, right? Like even If you were an

857
00:56:26,565 --> 00:56:30,205
Speaker 8:  unwilling participant. So it's, I don't, I don't think it should be

858
00:56:30,485 --> 00:56:34,405
Speaker 8:  actually treated that cavalierly overall. I think that most people

859
00:56:34,795 --> 00:56:38,165
Speaker 8:  like don't face that severe threat of like

860
00:56:38,395 --> 00:56:42,325
Speaker 8:  Chinese espionage. And If you do, I don't think it's going

861
00:56:42,345 --> 00:56:46,285
Speaker 8:  to significantly matter whether you use TikTok or a little Red book or

862
00:56:46,285 --> 00:56:50,005
Speaker 8:  not, right? Yeah. Like the CIA existed long before

863
00:56:51,285 --> 00:56:55,205
Speaker 8:  the internet did. Right. Espionage can be done just fine

864
00:56:55,205 --> 00:56:58,635
Speaker 8:  without, without this sort of data. This sort of data does help.

865
00:56:59,185 --> 00:56:59,875
Speaker 8:  Yeah, for sure.

866
00:57:01,235 --> 00:57:05,085
Speaker 2:  So, so you think there are people who could do a, a

867
00:57:05,225 --> 00:57:09,045
Speaker 2:  pretty rational threat modeling of their own life and

868
00:57:09,045 --> 00:57:10,045
Speaker 2:  come out of it and say,

869
00:57:11,555 --> 00:57:15,105
Speaker 2:  I'm good. Let the CCP have my data, it's gonna be fine.

870
00:57:15,335 --> 00:57:18,905
Speaker 2:  Like you think that's, that there are people for whom that is a, like a reasonable

871
00:57:19,265 --> 00:57:19,825
Speaker 2:  rational outcome.

872
00:57:20,705 --> 00:57:24,625
Speaker 8:  I don't think that that is totally a reasonable, that is a, that is

873
00:57:24,625 --> 00:57:28,305
Speaker 8:  a rational outcome in the lens of privacy nihilism, right?

874
00:57:28,415 --> 00:57:32,265
Speaker 8:  Sure. That's fair. Yeah. Like the rational outcome is I don't want anybody

875
00:57:32,285 --> 00:57:36,265
Speaker 8:  to have my data, right? Like my data is mine, I want to control it. Nobody

876
00:57:36,275 --> 00:57:40,225
Speaker 8:  needs to know what I, what I enjoy thinking about

877
00:57:40,245 --> 00:57:43,825
Speaker 8:  and looking at. Right? Like that's actually just not data that needs to be

878
00:57:43,825 --> 00:57:47,585
Speaker 8:  out there because I don't trust the CCP to handle it any more responsibly

879
00:57:47,585 --> 00:57:51,425
Speaker 8:  than I trust Facebook to handle it. Right? But for

880
00:57:51,665 --> 00:57:54,225
Speaker 8:  somebody who's looking at it through the lens of privacy, nihilism is saying

881
00:57:54,225 --> 00:57:57,865
Speaker 8:  like, Facebook already has all my data anyway. How is it different?

882
00:57:58,545 --> 00:58:02,225
Speaker 8:  I think that there's a large percentage of people out there for whom a reasonable

883
00:58:02,225 --> 00:58:05,585
Speaker 8:  answer is there's not a meaningful difference. Yeah.

884
00:58:05,735 --> 00:58:09,625
Speaker 2:  That, that's totally fair. So given that, then, why do

885
00:58:09,625 --> 00:58:12,725
Speaker 2:  you think kind of societally, we talk about

886
00:58:13,965 --> 00:58:17,635
Speaker 2:  China and data privacy and security so differently

887
00:58:18,145 --> 00:58:21,595
Speaker 2:  than we talk about companies like Meta and Google, and I do think

888
00:58:22,085 --> 00:58:25,835
Speaker 2:  there are maybe more examples than often get credit for

889
00:58:25,895 --> 00:58:29,715
Speaker 2:  of us talking about them the same way, right? Like, I think that the

890
00:58:29,715 --> 00:58:33,515
Speaker 2:  idea that these things are all collecting data they shouldn't be and using

891
00:58:33,515 --> 00:58:37,355
Speaker 2:  it in ways they shouldn't be is, is pretty true across

892
00:58:37,355 --> 00:58:41,345
Speaker 2:  the board. But e even now, like the, the way

893
00:58:41,345 --> 00:58:44,825
Speaker 2:  that people have worked themselves up about the

894
00:58:45,785 --> 00:58:48,825
Speaker 2:  personal data being shared on TikTok and collected by the CCP

895
00:58:49,925 --> 00:58:53,665
Speaker 2:  hit a fever pitch that I don't remember with Google or

896
00:58:53,905 --> 00:58:56,585
Speaker 2:  Facebook or really anything. Why do you think China is so different?

897
00:58:57,265 --> 00:59:00,785
Speaker 8:  I mean, I think there's a couple of reasons. One is

898
00:59:01,885 --> 00:59:05,625
Speaker 8:  the sort of the openness of government

899
00:59:05,865 --> 00:59:09,785
Speaker 8:  surveillance in China, right? Like government surveillance

900
00:59:09,925 --> 00:59:13,185
Speaker 8:  and like control of speech

901
00:59:13,885 --> 00:59:16,905
Speaker 8:  is done openly in a way that

902
00:59:17,595 --> 00:59:21,445
Speaker 8:  makes Americans very uncomfortable with a strong

903
00:59:21,445 --> 00:59:25,405
Speaker 8:  First Amendment history, right? Like we, we are, I I think Americans are

904
00:59:25,405 --> 00:59:28,885
Speaker 8:  definitely uncomfortable with, you know, anytime the government

905
00:59:29,195 --> 00:59:32,885
Speaker 8:  says, like, you're not allowed to say these things, right?

906
00:59:33,035 --> 00:59:36,885
Speaker 8:  Yeah. Anybody who's ideologically consistent right. Should say that

907
00:59:36,885 --> 00:59:40,845
Speaker 8:  right off. Oftentimes people are comfortable with the government

908
00:59:41,175 --> 00:59:44,805
Speaker 8:  truncating speech they don't like, right? Like, people want to

909
00:59:45,035 --> 00:59:49,005
Speaker 8:  make it legal to run over protesters on highways. Right? Or

910
00:59:49,005 --> 00:59:52,405
Speaker 8:  like to, you know, not to seem partisan here. People, you know, aren't comfortable

911
00:59:52,405 --> 00:59:56,045
Speaker 8:  with people talking about guns. Right. But for the most part, we tend to

912
00:59:56,105 --> 01:00:00,085
Speaker 8:  not want the government to curtail that, right? For sure. We also, I

913
01:00:00,085 --> 01:00:03,285
Speaker 8:  think as Americans, like our government surveillance

914
01:00:03,795 --> 01:00:07,765
Speaker 8:  kind of hidden from us, right? Yeah. Like, we don't, we don't

915
01:00:07,765 --> 01:00:10,925
Speaker 8:  really want it in your face, right? We're okay with police having license

916
01:00:10,925 --> 01:00:13,645
Speaker 8:  plate readers and we're okay with, you know,

917
01:00:15,185 --> 01:00:18,965
Speaker 8:  you know, whatever the NSA has to do as long as it's to get the bad

918
01:00:18,965 --> 01:00:22,525
Speaker 8:  guys, you know, in China, the surveillance is very much more in the open,

919
01:00:22,775 --> 01:00:26,545
Speaker 8:  right? It's, it's, it's sort of targeted at

920
01:00:26,545 --> 01:00:30,225
Speaker 8:  everybody, right? And I think that that, even If you could argue like

921
01:00:30,785 --> 01:00:34,385
Speaker 8:  surveillance in America is just as bad, right? Or is just as prevalent, at

922
01:00:34,385 --> 01:00:38,145
Speaker 8:  least I think that there's a, there's a difference in

923
01:00:38,165 --> 01:00:42,025
Speaker 8:  how it feels to Americans. And then the other part of this

924
01:00:42,205 --> 01:00:46,185
Speaker 8:  is of course just, you know, good old fashioned xenophobia,

925
01:00:46,275 --> 01:00:50,225
Speaker 8:  right? Right. China is scary. Like, you know, just,

926
01:00:50,225 --> 01:00:54,145
Speaker 8:  just all this sort of old, you know, like, well you don't

927
01:00:54,145 --> 01:00:57,825
Speaker 8:  wanna be like China, right? Like, this is America, this isn't China.

928
01:00:57,965 --> 01:01:01,865
Speaker 8:  We don't do things like that here. You don't want China to have your data,

929
01:01:01,865 --> 01:01:05,665
Speaker 8:  right? Like it's, it's just kind of like, well that's those

930
01:01:05,665 --> 01:01:09,505
Speaker 8:  other guys and like, you can trust us, but you can't trust them. I honestly,

931
01:01:09,585 --> 01:01:12,665
Speaker 8:  I think it's that, right? Like I think, I think that's a big part of it.

932
01:01:13,325 --> 01:01:17,015
Speaker 8:  At my most cynical, I'd say a big part of it is just is

933
01:01:17,155 --> 01:01:20,945
Speaker 8:  is being mad that they're not

934
01:01:20,945 --> 01:01:24,265
Speaker 8:  getting a cut of the data or a cut of the profits, right? Hmm.

935
01:01:24,735 --> 01:01:28,105
Speaker 8:  Like, you're like, we are, we are okay with

936
01:01:29,065 --> 01:01:32,385
Speaker 8:  Facebook collecting this data and then China

937
01:01:32,645 --> 01:01:36,185
Speaker 8:  buying it from Facebook or buying ad targeting or whatever from Facebook

938
01:01:36,775 --> 01:01:40,505
Speaker 8:  because us companies are getting a cut. We're not, we're not

939
01:01:40,615 --> 01:01:44,385
Speaker 8:  okay with it just going straight to China, right? Like

940
01:01:44,385 --> 01:01:47,625
Speaker 8:  that's, that would be my most cynical take on it, right? Yeah.

941
01:01:48,135 --> 01:01:49,385
Speaker 8:  Like, we gotta get our cut.

942
01:01:49,805 --> 01:01:53,545
Speaker 2:  That's a good take. I had, I hadn't heard that one, but that, that rings

943
01:01:53,545 --> 01:01:54,545
Speaker 2:  truer than I would like it to.

944
01:01:54,925 --> 01:01:55,985
Speaker 8:  It does, and I hate it.

945
01:01:56,085 --> 01:01:59,665
Speaker 2:  It it does. I don't, I don't like it. But I'm gonna keep hearing that in

946
01:01:59,665 --> 01:02:03,225
Speaker 2:  my head for a while. Let's end on a, on a positive and

947
01:02:03,225 --> 01:02:07,095
Speaker 2:  productive note here. Yes. We wanna keep people out of privacy

948
01:02:07,215 --> 01:02:11,095
Speaker 2:  nihilism. I think it is, it is an understandable place to go, but it

949
01:02:11,095 --> 01:02:14,975
Speaker 2:  is a place we should all do our best to avoid going. What, what

950
01:02:14,995 --> 01:02:18,935
Speaker 2:  in, in the absence of these kind of big structural improvements you're

951
01:02:18,935 --> 01:02:22,245
Speaker 2:  talking, talking about that I think we, we absolutely are in agreement ought

952
01:02:22,245 --> 01:02:22,725
Speaker 2:  to exist.

953
01:02:24,355 --> 01:02:28,125
Speaker 2:  What can people do? Like, what's a, what's a useful thing that people

954
01:02:28,145 --> 01:02:31,405
Speaker 2:  can do to start pushing this stuff at least a little bit in the right direction

955
01:02:31,405 --> 01:02:31,885
Speaker 2:  for themselves?

956
01:02:32,305 --> 01:02:36,275
Speaker 8:  So the privacy nihilism is so rampant right now. I think

957
01:02:36,275 --> 01:02:38,995
Speaker 8:  it's more rampant than I've ever seen it. And

958
01:02:40,225 --> 01:02:44,125
Speaker 8:  I'm gonna, I'm gonna say clearly and unequivocally, privacy is

959
01:02:44,185 --> 01:02:48,045
Speaker 8:  not dead. You can still have privacy, right?

960
01:02:48,685 --> 01:02:52,565
Speaker 8:  Surveillance capitalism is not an inevitability. And there

961
01:02:52,565 --> 01:02:56,525
Speaker 8:  are, are lots of things you can do, right? Getting off of

962
01:02:56,635 --> 01:02:59,805
Speaker 8:  meta products is a great place to start, right? Like,

963
01:03:00,465 --> 01:03:04,365
Speaker 8:  you know, uninstall Instagram from your phone, unin, get off Facebook, right?

964
01:03:05,105 --> 01:03:08,565
Speaker 8:  See, see if this improves your life, right? There are a lot of really

965
01:03:09,005 --> 01:03:12,045
Speaker 8:  interesting social networks, which are popping up right now, which are not

966
01:03:12,215 --> 01:03:15,805
Speaker 8:  based on the, the model of surveillance capitalism and which are not owned

967
01:03:15,945 --> 01:03:19,845
Speaker 8:  by tech oligarchs, right? So things like blue

968
01:03:19,905 --> 01:03:23,365
Speaker 8:  sky things like Mastodon I think are really

969
01:03:23,765 --> 01:03:26,445
Speaker 8:  interesting models for what social media

970
01:03:27,395 --> 01:03:31,245
Speaker 8:  without surveillance capitalism could look like. And doing things

971
01:03:31,245 --> 01:03:34,965
Speaker 8:  like looking at what apps are on your phone, right? Like,

972
01:03:35,225 --> 01:03:38,965
Speaker 8:  do you, like If you can uninstall most of the apps on your phone

973
01:03:39,665 --> 01:03:43,245
Speaker 8:  and you can, right? That's a great place to start, right? Like, do I really

974
01:03:43,245 --> 01:03:46,605
Speaker 8:  need an app from my grocery store? No, no, I don't. And I don't need it and

975
01:03:46,605 --> 01:03:50,325
Speaker 8:  I don't want it, right? Like, I think pushing back on those things, right?

976
01:03:50,325 --> 01:03:54,085
Speaker 8:  Like there are so many, so many places now which want us to

977
01:03:54,085 --> 01:03:57,845
Speaker 8:  install an app just to get basic services and just kind of

978
01:03:58,125 --> 01:04:02,005
Speaker 8:  refusing to do that. I'm, I'm with the Boomers on this one, man. No, I refuse

979
01:04:02,005 --> 01:04:05,685
Speaker 8:  to install an app to eat at a restaurant. I refuse to

980
01:04:05,685 --> 01:04:09,085
Speaker 8:  install an app to shop at CVS. Yeah, I will not be doing this.

981
01:04:10,885 --> 01:04:14,685
Speaker 8:  I think that that's a good place to start, right? Installing ad blockers.

982
01:04:14,695 --> 01:04:18,325
Speaker 8:  There are, there are some, some really good ad blockers out there. EFF makes

983
01:04:18,345 --> 01:04:22,245
Speaker 8:  one called Privacy Badger. There's another one called you Block Origin. Those

984
01:04:22,245 --> 01:04:25,765
Speaker 8:  are both great ad blockers, right? If you're a bit more technical,

985
01:04:26,475 --> 01:04:30,365
Speaker 8:  there's a, there's a project called Pie Hole that

986
01:04:30,475 --> 01:04:34,005
Speaker 8:  lets you set up your own sort of ad blocking DNS

987
01:04:35,065 --> 01:04:37,885
Speaker 8:  on your, on your network. You can, so like this is something you can set

988
01:04:37,885 --> 01:04:41,405
Speaker 8:  up on your home network to prevent a lot of the tracking that goes on.

989
01:04:41,745 --> 01:04:44,805
Speaker 8:  If you want to go even a little bit more down the rabbit hole there, like

990
01:04:44,805 --> 01:04:48,525
Speaker 8:  things like turning off location services on your phone, unless you're using

991
01:04:48,525 --> 01:04:52,405
Speaker 8:  it for navigation. Hmm. This is a great way to stop your location from ending

992
01:04:52,465 --> 01:04:55,525
Speaker 8:  up in these, in these sort of data broker

993
01:04:55,685 --> 01:04:59,565
Speaker 8:  repositories, right? There are a lot of services which will delete your

994
01:04:59,565 --> 01:05:02,365
Speaker 8:  data off the internet and try to scrub your data wherever possible. Things

995
01:05:02,365 --> 01:05:05,525
Speaker 8:  like delete me. Hmm. They all have pros and cons, but

996
01:05:06,685 --> 01:05:10,085
Speaker 8:  checking one of those out can definitely be worth it. If you're in California

997
01:05:10,215 --> 01:05:14,085
Speaker 8:  doing things like requesting copies of your data from companies using

998
01:05:14,085 --> 01:05:17,685
Speaker 8:  the California Privacy Rights Act, the CPRA

999
01:05:18,195 --> 01:05:21,445
Speaker 8:  laws, right? Like this can be, this can be really interesting too, right?

1000
01:05:21,445 --> 01:05:24,925
Speaker 8:  Request request copies of your data request to delete your data.

1001
01:05:25,555 --> 01:05:28,565
Speaker 8:  Yeah. There's lots of things you can do, right? And

1002
01:05:29,435 --> 01:05:32,645
Speaker 8:  also the biggest long term that you can do, because these are all bandings,

1003
01:05:32,645 --> 01:05:36,285
Speaker 8:  right? Like, I, I wanna acknowledge that these are all

1004
01:05:36,875 --> 01:05:40,845
Speaker 8:  kind of similar to telling people to like, turn off the lights to stop

1005
01:05:40,915 --> 01:05:44,845
Speaker 8:  climate change, right? Sure. Like the privacy problem that we have is a

1006
01:05:45,125 --> 01:05:49,005
Speaker 8:  systemic problem that's not going to be solved by like individual

1007
01:05:49,005 --> 01:05:52,685
Speaker 8:  piece meal action. We need a systemic solution for this, right? And that

1008
01:05:52,745 --> 01:05:56,245
Speaker 8:  is comprehensive federal privacy law.

1009
01:05:56,665 --> 01:06:00,525
Speaker 8:  And so a good thing you can do is call your representatives,

1010
01:06:00,525 --> 01:06:03,965
Speaker 8:  right? Call your senators, call your congressmen and

1011
01:06:04,115 --> 01:06:07,805
Speaker 8:  explain to them how important this is, how important it is to you, why it's

1012
01:06:07,805 --> 01:06:11,685
Speaker 8:  so important, right? And, and get them to understand that this

1013
01:06:11,685 --> 01:06:14,445
Speaker 8:  is important. Get them to understand that this is important to their constituents,

1014
01:06:14,935 --> 01:06:18,765
Speaker 8:  right? So that maybe one day we actually can have

1015
01:06:18,765 --> 01:06:22,645
Speaker 8:  this systemic real solution to this problem instead of

1016
01:06:22,645 --> 01:06:26,445
Speaker 8:  just, and, you know, having everybody try to solve it for themselves.

1017
01:06:26,745 --> 01:06:30,645
Speaker 8:  But the important takeaway here is If you

1018
01:06:30,645 --> 01:06:34,575
Speaker 8:  do give, If you give up on privacy, they win. Right?

1019
01:06:34,785 --> 01:06:37,935
Speaker 8:  These companies win If you give up on privacy. And if,

1020
01:06:38,665 --> 01:06:42,205
Speaker 8:  if it was impossible to have privacy, they wouldn't spend so much money

1021
01:06:43,065 --> 01:06:46,725
Speaker 8:  on trying to convince you that it was impossible to have privacy and that

1022
01:06:46,725 --> 01:06:48,405
Speaker 8:  it was a great thing to give up on your data.

1023
01:06:49,845 --> 01:06:52,805
Speaker 2:  I, I I like that. That's a, that's a good place to end on

1024
01:06:54,075 --> 01:06:56,725
Speaker 2:  that. I also, you've just made me realize it's been a really long time since

1025
01:06:56,765 --> 01:07:00,645
Speaker 2:  I did like a full delete of all the apps on my phone. It's time to

1026
01:07:00,645 --> 01:07:03,005
Speaker 2:  get rid of some apps. Yeah. This is, this is good advice. This is now my

1027
01:07:03,005 --> 01:07:03,485
Speaker 2:  weekend project.

1028
01:09:06,315 --> 01:09:08,775
Speaker 2:  All right, we're back. Let's get to the hotline as always. The number is

1029
01:09:08,775 --> 01:09:12,455
Speaker 2:  8 6 6 VERGE one one. The email is vergecast at The Verge dot com.

1030
01:09:12,875 --> 01:09:16,215
Speaker 2:  We love all your questions. Thank you again to everybody who has been emailing

1031
01:09:16,215 --> 01:09:20,135
Speaker 2:  and calling about how you use AI in your regular day-to-day

1032
01:09:20,135 --> 01:09:23,935
Speaker 2:  life. It's been so interesting. I have enjoyed every single one that we've

1033
01:09:23,935 --> 01:09:27,175
Speaker 2:  gotten. Please keep all your responses coming on that and on everything else.

1034
01:09:27,765 --> 01:09:31,415
Speaker 2:  This week we have a question about a somewhat surprising

1035
01:09:31,415 --> 01:09:34,135
Speaker 2:  gadget that I haven't thought about in a very long time. Let's hear it.

1036
01:09:35,555 --> 01:09:38,935
Speaker 13:  Hey Vergecast, it is Rob. I might be the only

1037
01:09:39,345 --> 01:09:43,175
Speaker 13:  power user of this device, kind of a pandemic holdover, but

1038
01:09:43,315 --> 01:09:46,935
Speaker 13:  around the pandemic, I had children and thus was calling

1039
01:09:47,355 --> 01:09:50,855
Speaker 13:  my parents, my kids' grandparents quite often using the

1040
01:09:51,175 --> 01:09:54,975
Speaker 13:  Facebook now meta portal. That device is kind of part of Facebook's push

1041
01:09:55,165 --> 01:09:59,095
Speaker 13:  into hardware and they've since deprecated it. It worked for about a year

1042
01:09:59,095 --> 01:10:02,935
Speaker 13:  after the announcement was made, but has recently started dying. And

1043
01:10:02,935 --> 01:10:06,655
Speaker 13:  the main use case for us is literally just calling my parents

1044
01:10:06,915 --> 01:10:09,975
Speaker 13:  at dinner when we're with our kids. Kind of a nice hand free

1045
01:10:10,735 --> 01:10:14,335
Speaker 13:  FaceTime type experience. And I was wondering If you all have any

1046
01:10:14,335 --> 01:10:18,225
Speaker 13:  recommendations for other dedicated portal

1047
01:10:18,225 --> 01:10:21,665
Speaker 13:  calling type devices I could use for my kids and, and me to call

1048
01:10:22,245 --> 01:10:25,985
Speaker 13:  my parents their grandparents. Yeah, that's pretty much it.

1049
01:10:25,985 --> 01:10:27,425
Speaker 13:  Thanks so much. Appreciate what y'all do.

1050
01:10:28,365 --> 01:10:29,985
Speaker 2:  All right. Jen Tui is here to help me. Hi Jen.

1051
01:10:30,605 --> 01:10:31,065
Speaker 14:  Hi David.

1052
01:10:31,605 --> 01:10:32,505
Speaker 2:  Did you ever have a portal?

1053
01:10:33,865 --> 01:10:37,745
Speaker 14:  I, I tested the portal. Go. I never owned one

1054
01:10:37,745 --> 01:10:41,265
Speaker 14:  myself. I do have several friends who owned one though. 'cause it really

1055
01:10:41,285 --> 01:10:44,665
Speaker 14:  did, I think it appealed to a lot of non-techie people

1056
01:10:44,965 --> 01:10:48,865
Speaker 14:  during the pandemic. Yeah. So I'm sad to hear that they're

1057
01:10:48,865 --> 01:10:52,505
Speaker 14:  pretty much dead and dying now that that's, that's really sad.

1058
01:10:52,845 --> 01:10:56,745
Speaker 2:  It is a real bummer. I bought the portal TV during the pandemic. Oh.

1059
01:10:56,805 --> 01:11:00,705
Speaker 2:  And we used it a ton. It was, I was so shocked at how good that thing

1060
01:11:00,705 --> 01:11:04,585
Speaker 2:  was for like, as a, as a microphone especially like, we would just sit

1061
01:11:04,585 --> 01:11:07,945
Speaker 2:  on the couch and we would like play games with our friends over Zoom, which

1062
01:11:07,965 --> 01:11:11,945
Speaker 2:  is a like insane to remember and think about all of the time that

1063
01:11:11,945 --> 01:11:15,325
Speaker 2:  we spent doing that. Mm. But like the thing kind of worked. Yeah. And I'm

1064
01:11:15,325 --> 01:11:19,285
Speaker 2:  sure bummed to hear that I, I frankly have not plugged mine in in a long

1065
01:11:19,285 --> 01:11:22,725
Speaker 2:  time. But like I'm sad that they're going away and I will say I looked this

1066
01:11:22,725 --> 01:11:26,565
Speaker 2:  up and meta claims that it is continuing to support existing ones.

1067
01:11:26,865 --> 01:11:30,045
Speaker 2:  So Right. The the first thing you can do is, is reach out to Meta there as

1068
01:11:30,045 --> 01:11:33,965
Speaker 2:  a, yeah, I would say small but non-zero chance. They

1069
01:11:33,965 --> 01:11:37,685
Speaker 2:  might do something for you. But I'm curious where, where

1070
01:11:37,685 --> 01:11:41,565
Speaker 2:  your head goes as far as replacement devices. I, I think of a

1071
01:11:41,565 --> 01:11:45,045
Speaker 2:  couple of possibilities that we can get into and I'm curious if there's anything

1072
01:11:45,045 --> 01:11:46,925
Speaker 2:  that immediately comes to mind for you. Yeah,

1073
01:11:46,925 --> 01:11:50,685
Speaker 14:  Well I think the most obvious alternative and

1074
01:11:50,885 --> 01:11:53,205
Speaker 14:  probably the one I would actually have recommended to people rather than

1075
01:11:53,205 --> 01:11:57,005
Speaker 14:  buying this in the first place, except for one reason

1076
01:11:57,345 --> 01:12:00,845
Speaker 14:  is an Echo show. Because Amazon really has kind of

1077
01:12:00,845 --> 01:12:04,365
Speaker 14:  perfected the Alexa calling experience as much as

1078
01:12:04,985 --> 01:12:08,845
Speaker 14:  it, it does still have some rough edges, but it is very universal.

1079
01:12:09,045 --> 01:12:13,005
Speaker 14:  Like the other person doesn't have to have an Echo show for you to use

1080
01:12:13,005 --> 01:12:16,405
Speaker 14:  it as a calling device. They just have to have the Alexa app on their phone.

1081
01:12:17,585 --> 01:12:21,445
Speaker 14:  So they know you don't, you're not limited by hardware and

1082
01:12:21,465 --> 01:12:25,085
Speaker 14:  it works very well. And the new Echo show devices have the kind of

1083
01:12:25,445 --> 01:12:29,325
Speaker 14:  tracking, so If you are sitting having your kids talk to your, to their

1084
01:12:29,325 --> 01:12:32,205
Speaker 14:  grandparents, you know, you don't have to like make sure they're sitting

1085
01:12:32,495 --> 01:12:36,005
Speaker 14:  right in front of the camera. And the portal had a good, had that too. Has

1086
01:12:36,005 --> 01:12:39,485
Speaker 14:  that kind of the, what is it? It's got a technical term.

1087
01:12:40,715 --> 01:12:43,965
Speaker 2:  Yeah. It's like the automatic pan in Zoom that keeps you in in frame.

1088
01:12:44,855 --> 01:12:48,085
Speaker 2:  Which I find sort of unnerving in a lot of cases. It can be. But for this

1089
01:12:48,185 --> 01:12:51,645
Speaker 2:  one use case I think is like Exactly, yes. Like chasing a child around is

1090
01:12:51,645 --> 01:12:54,045
Speaker 2:  the one good use case for this technology?

1091
01:12:54,285 --> 01:12:58,205
Speaker 14:  It is. And the Echo Show eight and Echo Show 10 would be sort

1092
01:12:58,205 --> 01:13:01,725
Speaker 14:  of my go-tos. The Echo Show eight is the less expensive, similar

1093
01:13:01,955 --> 01:13:05,885
Speaker 14:  size to the portal, similar features, you know, you could, if it doesn't

1094
01:13:05,885 --> 01:13:08,845
Speaker 14:  sound like he used any of the other features of the portal, but you can,

1095
01:13:09,025 --> 01:13:12,005
Speaker 14:  you know, it works as a photo frame. There are other things you can do with,

1096
01:13:12,005 --> 01:13:15,845
Speaker 14:  it obviously has the voice assistant built in and

1097
01:13:16,185 --> 01:13:19,945
Speaker 14:  the Echo show, the current one has the

1098
01:13:19,945 --> 01:13:23,865
Speaker 14:  framing, the auto framing and then the Echo Show 10 is actually on a robotic

1099
01:13:24,045 --> 01:13:27,945
Speaker 14:  arm and will follow you around. So like If you are having a conversation

1100
01:13:28,125 --> 01:13:31,585
Speaker 14:  Oh that's handy in the kitchen, it will follow you as you go.

1101
01:13:32,175 --> 01:13:35,225
Speaker 14:  It's an older device now and it's still quite expensive though. It's

1102
01:13:35,225 --> 01:13:36,905
Speaker 14:  $250, so,

1103
01:13:37,255 --> 01:13:39,905
Speaker 2:  Okay. I mean the portals are pretty expensive too, so I think on that front,

1104
01:13:40,045 --> 01:13:43,585
Speaker 2:  yes. That's not so terrible. Yeah, yeah. Like it's definitely like a hundred

1105
01:13:43,585 --> 01:13:45,945
Speaker 2:  dollars more than I'd like it to be. But I feel like that's still in the

1106
01:13:45,945 --> 01:13:49,745
Speaker 2:  realm of like, if it solves this problem, so be it. Okay. I have,

1107
01:13:49,825 --> 01:13:53,505
Speaker 2:  I have two questions about the Echo show though. One is like,

1108
01:13:54,835 --> 01:13:58,555
Speaker 2:  convince me that Alexa calling is actually good because A, I used Alexa calling

1109
01:13:58,555 --> 01:14:01,755
Speaker 2:  when it first came out and it was not good. Like not good to the point that

1110
01:14:01,755 --> 01:14:05,715
Speaker 2:  I kind of stopped trying and B, I do occasionally have to use Chime,

1111
01:14:05,765 --> 01:14:09,515
Speaker 2:  which is Amazon's like, oh, don't do that own video calling

1112
01:14:09,515 --> 01:14:13,325
Speaker 2:  service. And like the people that's bad who make Chime think

1113
01:14:13,325 --> 01:14:17,045
Speaker 2:  Chime sucks. Like, like that is reporting. Like they, they

1114
01:14:17,045 --> 01:14:20,805
Speaker 2:  don't like it, it's bad. Everyone agrees. But you're telling me Alexa calling

1115
01:14:20,865 --> 01:14:22,085
Speaker 2:  now is, is good.

1116
01:14:22,275 --> 01:14:26,165
Speaker 14:  Yeah, I, I I mean it's, is there a really good video calling

1117
01:14:26,165 --> 01:14:29,925
Speaker 14:  service out there? I mean maybe FaceTime, that's fair. But the problem with

1118
01:14:30,165 --> 01:14:33,645
Speaker 14:  FaceTime is everyone has to have an Apple device and you know, and if grandparents

1119
01:14:33,645 --> 01:14:37,445
Speaker 14:  have an Apple device and you know everyone has an Apple device, maybe

1120
01:14:37,465 --> 01:14:40,445
Speaker 14:  use an iPad. If you don't already have one that's, that's a good choice.

1121
01:14:40,905 --> 01:14:44,285
Speaker 14:  We are hearing rumors that there's going to be an iPad on an arm that we'll

1122
01:14:44,285 --> 01:14:47,925
Speaker 14:  move around one day. Right. So you know, If you can wait, wait and see if

1123
01:14:48,085 --> 01:14:50,765
Speaker 14:  that comes out, if you're an Apple household, but you know, you're limited

1124
01:14:51,315 --> 01:14:55,205
Speaker 14:  with iPads to people that can use FaceTime and

1125
01:14:55,215 --> 01:14:58,965
Speaker 14:  Alexa calling with its universal aspect, I feel like

1126
01:14:59,065 --> 01:15:03,005
Speaker 14:  is, is is a good bet and they've been refining it and making it better

1127
01:15:03,005 --> 01:15:06,765
Speaker 14:  over the years. You can also use your Echo show to make phone calls too.

1128
01:15:07,785 --> 01:15:11,325
Speaker 14:  So you can just call someone's landline or cell phone,

1129
01:15:11,705 --> 01:15:15,525
Speaker 14:  not video calling but you know, it's, it's like a phone for your home, which

1130
01:15:15,585 --> 01:15:18,405
Speaker 14:  you know is kind of weird because we don't have those anymore.

1131
01:15:18,835 --> 01:15:22,045
Speaker 2:  It's true. And there is something to the, like the phone that is just in

1132
01:15:22,085 --> 01:15:25,645
Speaker 2:  a place on a table. Right. But you kind of go to when you want, particularly

1133
01:15:25,705 --> 01:15:29,645
Speaker 2:  for kids. Yes. And it's like having them, it's one thing, like I try to

1134
01:15:29,645 --> 01:15:32,365
Speaker 2:  hand my two-year-old, my phone and he just like throws it on the ground and

1135
01:15:32,365 --> 01:15:35,125
Speaker 2:  runs away. But there's something too. It's like this is where the phone is.

1136
01:15:35,145 --> 01:15:37,405
Speaker 2:  Yes. And they go to it like that actually kind of works for

1137
01:15:37,405 --> 01:15:41,005
Speaker 14:  Sure. And when you have young, young, older than you but younger than my

1138
01:15:41,155 --> 01:15:44,925
Speaker 14:  kids who don't have phones but are maybe old

1139
01:15:44,925 --> 01:15:48,805
Speaker 14:  enough to be home alone for 30 minutes. Sure. They don't have a phone.

1140
01:15:49,105 --> 01:15:52,925
Speaker 14:  So if something happened, you know, now you can actually use Alexa to

1141
01:15:52,925 --> 01:15:56,485
Speaker 14:  call like you can, they can say call mom and call you

1142
01:15:56,745 --> 01:16:00,685
Speaker 14:  or call nine one one. You know that it, having not having landlines

1143
01:16:00,685 --> 01:16:04,645
Speaker 14:  in our homes has kind of opened up this kind of weird gray

1144
01:16:04,675 --> 01:16:08,325
Speaker 14:  area. Especially when you have kids at home. So I think, I feel like an

1145
01:16:08,325 --> 01:16:12,285
Speaker 14:  echo show is a good solution here. If you aren't a fan of the

1146
01:16:12,305 --> 01:16:13,405
Speaker 14:  Amazon side of things,

1147
01:16:15,285 --> 01:16:18,725
Speaker 14:  I, you know, I think the I the Apple option, that iPad is probably your

1148
01:16:18,725 --> 01:16:22,645
Speaker 14:  best other choice. Yeah. Video calling as a whole has kind of

1149
01:16:22,645 --> 01:16:25,605
Speaker 14:  dropped off the cliff since the end of the pandemic.

1150
01:16:26,705 --> 01:16:30,405
Speaker 14:  You know, when Port the portal launched, it had like seven different services

1151
01:16:30,505 --> 01:16:34,445
Speaker 14:  you could use. So it had Zoom, you had WhatsApp, Facebook, all of that.

1152
01:16:34,485 --> 01:16:37,685
Speaker 14:  I don't think there is any other way you can use WhatsApp or Facebook

1153
01:16:38,345 --> 01:16:41,245
Speaker 14:  on video calling device today that I can think of.

1154
01:16:41,505 --> 01:16:44,245
Speaker 2:  That's right. I've done a fair amount of research on this now 'cause I assume

1155
01:16:44,865 --> 01:16:48,565
Speaker 2:  the, the people like a, I think there are a lot of people out there

1156
01:16:48,615 --> 01:16:52,565
Speaker 2:  whose main connection to family is through one of those two apps,

1157
01:16:52,565 --> 01:16:55,885
Speaker 2:  messenger or WhatsApp. Yes. And I also think there's a strong chance that

1158
01:16:55,885 --> 01:16:59,725
Speaker 2:  If you are still now a portal user, it's because it

1159
01:16:59,725 --> 01:17:00,405
Speaker 2:  works of those

1160
01:17:00,585 --> 01:17:00,805
Speaker 14:  Yes.

1161
01:17:00,865 --> 01:17:04,565
Speaker 2:  Or because of those two things. Right. So my assumption, Rob, our

1162
01:17:04,565 --> 01:17:08,325
Speaker 2:  caller didn't say, but my assumption is that the reason this is hard to replace

1163
01:17:08,785 --> 01:17:12,605
Speaker 2:  is because of WhatsApp and Messenger and Right on that front

1164
01:17:12,865 --> 01:17:16,365
Speaker 2:  you're just hosed. No, like there's just, there just isn't a good answer.

1165
01:17:16,865 --> 01:17:18,205
Speaker 14:  No a a laptop.

1166
01:17:18,995 --> 01:17:21,245
Speaker 2:  Yeah a laptop works fine. Yeah. An iPad works fine. Like

1167
01:17:21,355 --> 01:17:24,805
Speaker 14:  IPad. Yeah you could do it an iPad for WhatsApp video calling. They're just

1168
01:17:24,805 --> 01:17:26,605
Speaker 2:  Such overkill and I kind of feel like it's

1169
01:17:26,605 --> 01:17:29,485
Speaker 14:  Overkill. Yeah. And movable.

1170
01:17:30,115 --> 01:17:30,925
Speaker 2:  Well yeah, true.

1171
01:17:31,225 --> 01:17:34,165
Speaker 14:  An iPad, If you think it's hard to take, take a cell phone outta your kid's

1172
01:17:34,165 --> 01:17:38,085
Speaker 14:  hand, try taking an iPad. I mean it'll get used for other things.

1173
01:17:38,295 --> 01:17:41,325
Speaker 14:  Again, this is why I'm kind of excited about whatever Apple is gonna come

1174
01:17:41,325 --> 01:17:45,085
Speaker 14:  up with in terms of a home device. Because yes, you could use an iPad

1175
01:17:45,145 --> 01:17:49,125
Speaker 14:  as a WhatsApp calling device if it was fixed somewhere in your

1176
01:17:49,125 --> 01:17:52,925
Speaker 14:  house for children. Obviously you can use it if it moves too. But the

1177
01:17:52,945 --> 01:17:56,845
Speaker 14:  kid aspect is a tablet isn't going to stay fixed. Although

1178
01:17:57,165 --> 01:18:00,325
Speaker 14:  speaking of as, as we've mentioned this, I'm sitting here staring at my

1179
01:18:00,325 --> 01:18:03,865
Speaker 14:  Pixel tablet, which could be another

1180
01:18:04,025 --> 01:18:07,825
Speaker 14:  option and you could do WhatsApp calling through that.

1181
01:18:08,395 --> 01:18:11,505
Speaker 14:  Again, it's not fixed, but you can take it off the speaker.

1182
01:18:12,765 --> 01:18:16,745
Speaker 14:  But that would, that would be another option. I just don't

1183
01:18:16,745 --> 01:18:19,865
Speaker 14:  feel that comfortable recommending Pixel hardware right now.

1184
01:18:20,375 --> 01:18:24,345
Speaker 2:  That is, that is very fair. Well I have another Google question which we

1185
01:18:24,345 --> 01:18:27,545
Speaker 2:  should come to in a second. But I, I will say I think a non, a non

1186
01:18:27,875 --> 01:18:31,865
Speaker 2:  ridiculous answer to sort of solving this problem

1187
01:18:32,045 --> 01:18:35,025
Speaker 2:  is just to find the cheapest Android tablet you possibly can. Yeah. Yeah.

1188
01:18:35,025 --> 01:18:38,585
Speaker 2:  Because like the camera will be fine. Yeah. It will run all these apps on

1189
01:18:38,585 --> 01:18:42,505
Speaker 2:  Android, which is I think the way to solve your, your compatibility problem.

1190
01:18:42,855 --> 01:18:46,585
Speaker 2:  It's not gonna be nearly as like clean and useful and dedicated as something

1191
01:18:46,585 --> 01:18:49,825
Speaker 2:  like the portal was. No, but if you're just like, I just need a thing I can

1192
01:18:49,825 --> 01:18:53,625
Speaker 2:  prop on a coffee mug and put in front of my kid like a, a cheap Android tablet

1193
01:18:53,775 --> 01:18:55,545
Speaker 2:  will do that job fairly successfully.

1194
01:18:55,685 --> 01:18:56,785
Speaker 14:  Yes. Yes, that's

1195
01:18:56,785 --> 01:18:59,865
Speaker 2:  True. So I think that's one, one way to go. But I do think the dedicated

1196
01:19:00,025 --> 01:19:03,545
Speaker 2:  device experience is real. Like there's a reason people gravitated to things

1197
01:19:03,545 --> 01:19:07,385
Speaker 2:  like the portal. Yeah. In the first place. You have not mentioned a

1198
01:19:07,385 --> 01:19:09,785
Speaker 2:  Nest Hub one single time. Oh

1199
01:19:09,845 --> 01:19:10,065
Speaker 14:  No.

1200
01:19:10,645 --> 01:19:12,225
Speaker 2:  Why? Yeah. Okay. Because they don't, that was

1201
01:19:12,225 --> 01:19:15,585
Speaker 14:  What I figured. They don't do that. They don't, they had some kind of calling

1202
01:19:15,585 --> 01:19:19,025
Speaker 14:  feature at some point, but it keeps changing and going away and

1203
01:19:19,525 --> 01:19:22,785
Speaker 14:  is not helpful. I mean the Pixel tablet would be better than a Nest hub

1204
01:19:22,785 --> 01:19:26,585
Speaker 14:  at this stage. Definitely the Pixel tablet with its doc,

1205
01:19:26,585 --> 01:19:30,105
Speaker 14:  speaker doc too is is is a nice little device.

1206
01:19:31,545 --> 01:19:34,225
Speaker 14:  I think it's about ready for an upgrade and there were quite a few rumors

1207
01:19:34,225 --> 01:19:37,505
Speaker 14:  that p that Google wasn't going to upgrade it. So yeah,

1208
01:19:38,195 --> 01:19:41,945
Speaker 14:  again, I just, if you've been burned by one device dying

1209
01:19:42,005 --> 01:19:45,625
Speaker 14:  and losing support, it's so true. I honestly feel like an echo show

1210
01:19:46,285 --> 01:19:49,665
Speaker 14:  is probably or an iPad are gonna be, you know, those aren't going anywhere.

1211
01:19:50,275 --> 01:19:54,025
Speaker 2:  Right. Yeah. With Google it's like, can I interest you in another dead product

1212
01:19:54,055 --> 01:19:56,065
Speaker 2:  that it's company doesn't care about it at all.

1213
01:19:57,055 --> 01:20:00,945
Speaker 14:  Yeah. I mean what, how you talk to the person on the other end is the ultimate

1214
01:20:01,185 --> 01:20:04,665
Speaker 14:  decision here. And he didn't mention that, but as you say, but if they were

1215
01:20:04,665 --> 01:20:05,945
Speaker 14:  using WhatsApp and

1216
01:20:07,965 --> 01:20:11,885
Speaker 14:  Facebook Messenger, you know, Alexa app is gonna work in the same way on

1217
01:20:11,885 --> 01:20:15,845
Speaker 14:  your phone. It'll call, it comes through like a call on their end when

1218
01:20:15,845 --> 01:20:19,365
Speaker 14:  you call them. I think I I do think, yeah, that's the simplest,

1219
01:20:19,915 --> 01:20:23,805
Speaker 14:  most straightforward. Sorry, I

1220
01:20:23,805 --> 01:20:27,685
Speaker 14:  have like seven of them around and I thought I muted most of them, but apparently

1221
01:20:27,705 --> 01:20:27,925
Speaker 14:  not.

1222
01:20:28,715 --> 01:20:29,605
Speaker 2:  What went wrong? So clever.

1223
01:20:30,425 --> 01:20:34,045
Speaker 14:  Oh, it's, it's okay. I know why because you made me get the Echo Show 10

1224
01:20:34,045 --> 01:20:37,445
Speaker 14:  out. So this, we didn't we didn't come up. Yeah, we did not

1225
01:20:37,635 --> 01:20:41,525
Speaker 14:  discuss this. But I should mention in case Zoom was the way you were calling

1226
01:20:41,845 --> 01:20:45,125
Speaker 14:  'cause you could zoom through the portal, you can zoom

1227
01:20:45,435 --> 01:20:48,965
Speaker 14:  through Echo Show devices. So if that was the way that they were

1228
01:20:49,205 --> 01:20:52,725
Speaker 14:  communicating with the grandparents, although only

1229
01:20:53,305 --> 01:20:57,155
Speaker 14:  the Echo Show 10 works with Zoom or the

1230
01:20:57,155 --> 01:21:00,795
Speaker 14:  first or second Gen Echo Show eight, the third Gen

1231
01:21:00,905 --> 01:21:04,675
Speaker 14:  Echo show the most new one, which you would expect to go by if

1232
01:21:04,675 --> 01:21:08,035
Speaker 14:  that's what you were hoping to buy. You know, or by the latest gen

1233
01:21:08,465 --> 01:21:11,275
Speaker 14:  does not support Zoom. So what

1234
01:21:11,315 --> 01:21:14,915
Speaker 2:  A perfect explanation of Amazon's entire product strategy. It's

1235
01:21:14,915 --> 01:21:15,875
Speaker 14:  Just like no idea why

1236
01:21:15,945 --> 01:21:18,995
Speaker 2:  They have a, they have a grab bag of things that it does and they just, somebody

1237
01:21:18,995 --> 01:21:21,795
Speaker 2:  just reaches in and pulls out a bunch and that's what their devices are.

1238
01:21:22,215 --> 01:21:26,035
Speaker 14:  And actually the Zoom experience on the Echo shows is quite good. I tested

1239
01:21:26,095 --> 01:21:29,315
Speaker 14:  it, I did a how to on our site If you wanna check it out. And

1240
01:21:29,895 --> 01:21:33,715
Speaker 14:  it was a good experience. We stopped using Zoom for work calls, but I actually

1241
01:21:33,715 --> 01:21:36,395
Speaker 14:  used it for work a lot because it would just pop up and say, are you ready

1242
01:21:36,395 --> 01:21:38,875
Speaker 14:  for your call? And I could just press it and it would be there. And that

1243
01:21:38,875 --> 01:21:42,715
Speaker 14:  was like what I used the portal for too. It was, it was a, a good integration.

1244
01:21:42,715 --> 01:21:46,435
Speaker 14:  It had, it had a similar experience on the portal as it did on the show.

1245
01:21:46,575 --> 01:21:50,075
Speaker 14:  So if that was the way you were going then the show is definitely

1246
01:21:50,695 --> 01:21:54,115
Speaker 14:  the best option. Just don't get the latest Echo Show eight. 'cause it won't

1247
01:21:54,115 --> 01:21:54,635
Speaker 14:  work with Zoom. Right.

1248
01:21:55,115 --> 01:21:58,795
Speaker 2:  Yeah, I think I I'm increasingly convinced as you talk that the

1249
01:21:58,825 --> 01:22:02,035
Speaker 2:  Echo Show Alexa calling is the way to go because

1250
01:22:03,535 --> 01:22:06,795
Speaker 2:  the, the Echo show microphones are gonna be better. Yes. Especially for like,

1251
01:22:06,795 --> 01:22:10,475
Speaker 2:  people moving around a room Yeah. Than even something like an iPad is gonna

1252
01:22:10,475 --> 01:22:14,315
Speaker 2:  be the, the speakers are very good. The calling stuff is

1253
01:22:14,315 --> 01:22:18,035
Speaker 2:  very, like, the technology for calling is very good inside of those devices.

1254
01:22:19,055 --> 01:22:22,995
Speaker 2:  And I think the pitch to family members of like, all you need is the

1255
01:22:22,995 --> 01:22:26,435
Speaker 2:  Alexa app is probably doable.

1256
01:22:26,695 --> 01:22:28,275
Speaker 14:  Not so bad. Yeah. It's not

1257
01:22:28,275 --> 01:22:31,115
Speaker 2:  Great, but it's, it's doable and it gives you the opportunity of like

1258
01:22:32,275 --> 01:22:35,875
Speaker 2:  Christmas 2025 gift here is your own box

1259
01:22:36,135 --> 01:22:39,875
Speaker 2:  for calling your grandchildren. Yeah. Which is like a, a spectacular victory

1260
01:22:40,055 --> 01:22:43,795
Speaker 2:  of a, of a device. I will put all pictures of your grandchildren and you

1261
01:22:43,795 --> 01:22:46,755
Speaker 2:  can press this button and call them. Yeah. So is a win.

1262
01:22:47,705 --> 01:22:51,355
Speaker 2:  Okay. For sure. I think that's it. So which if, if we're doing calling

1263
01:22:51,495 --> 01:22:54,555
Speaker 2:  it means you can get any, any echo show you want. We're doing this all through

1264
01:22:54,555 --> 01:22:58,035
Speaker 2:  Alexa. Which echo show would you recommend for our caller here?

1265
01:22:59,635 --> 01:23:03,115
Speaker 14:  I think the 10 because of its rotating

1266
01:23:04,215 --> 01:23:07,945
Speaker 14:  arm. I think the Echo Show 10, it, it is

1267
01:23:07,945 --> 01:23:11,585
Speaker 14:  $250 though. And if, and the Echo show eight

1268
01:23:11,605 --> 01:23:14,465
Speaker 14:  Second Gen would be a perfectly acceptable

1269
01:23:14,985 --> 01:23:18,945
Speaker 14:  alternative and about half the price. So it just has

1270
01:23:18,965 --> 01:23:22,385
Speaker 14:  it, I think the camera's not as good. The speakers aren't gonna be quite

1271
01:23:22,385 --> 01:23:26,305
Speaker 14:  as good, but it will work in the same, the software is the same.

1272
01:23:26,525 --> 01:23:30,385
Speaker 14:  So I would, yeah, I I mean the Echo show 10 would be more fun,

1273
01:23:30,385 --> 01:23:34,305
Speaker 14:  especially if your kids are moving around a lot. Right. They can't run away

1274
01:23:34,305 --> 01:23:37,025
Speaker 14:  from grandma as easily. Right. The show 10. True.

1275
01:23:37,245 --> 01:23:40,625
Speaker 2:  But If you can convince your family to download the Alexa app, pick your

1276
01:23:40,705 --> 01:23:41,185
Speaker 2:  favorite gun.

1277
01:23:41,365 --> 01:23:45,025
Speaker 14:  Yes. Yes. Okay. Well I wouldn't, I wouldn't do the five. That's a bit too

1278
01:23:45,025 --> 01:23:48,785
Speaker 14:  small. And then there's new yeah, the five huge ones. There's like the 21

1279
01:23:48,895 --> 01:23:49,705
Speaker 14:  just came out

1280
01:23:50,205 --> 01:23:52,585
Speaker 2:  Now you're talking. Put that on your dining room table, see what happens.

1281
01:23:52,585 --> 01:23:53,705
Speaker 2:  Yes, I'm into that. It's,

1282
01:23:53,705 --> 01:23:54,425
Speaker 14:  It's a bit large.

1283
01:23:55,945 --> 01:23:57,305
Speaker 14:  I think these are better. All right. So

1284
01:23:57,305 --> 01:24:00,505
Speaker 2:  Yeah, I think the, the eight or 10 seems like the right place to live. Alright

1285
01:24:00,805 --> 01:24:02,505
Speaker 2:  Jen, thank you. I hope this

1286
01:24:02,505 --> 01:24:03,465
Speaker 14:  Helps. You're welcome.

1287
01:24:06,415 --> 01:24:09,625
Speaker 2:  Alright, that is it for The Vergecast today. Thank you to everybody who came

1288
01:24:09,625 --> 01:24:13,065
Speaker 2:  on the show and thank you as always for listening. There's lots more on everything

1289
01:24:13,065 --> 01:24:16,985
Speaker 2:  we talked about in this episode from our S 25 reviews to the rest of our

1290
01:24:16,985 --> 01:24:20,825
Speaker 2:  phone coverage, to all the stuff with TikTok and RedNote and DeepSeek and

1291
01:24:20,825 --> 01:24:23,905
Speaker 2:  everything China at The Verge dot com. I'll put lots of links in the show

1292
01:24:23,905 --> 01:24:27,825
Speaker 2:  notes, but as always, read the website, Lord help us. There is a

1293
01:24:27,825 --> 01:24:31,345
Speaker 2:  lot going on right now. As always, If you have thoughts, questions, or feelings,

1294
01:24:31,405 --> 01:24:34,785
Speaker 2:  you can email vergecast at The Verge dot com or call the hotline. It's six

1295
01:24:34,785 --> 01:24:38,625
Speaker 2:  six VERGE one one. I've terrible news for you. The slack room broke,

1296
01:24:39,005 --> 01:24:41,785
Speaker 2:  but it also comes to the email and we're getting the slack room fixed so

1297
01:24:41,785 --> 01:24:45,225
Speaker 2:  the hotlines keep coming. Don't you worry. And we love hearing from you.

1298
01:24:45,655 --> 01:24:49,265
Speaker 2:  This show is produced by Will Poor Eric Gomez and Brandon Kiefer. The Vergecast

1299
01:24:49,265 --> 01:24:52,585
Speaker 2:  is a VERGE production and part of the Vox Media podcast network. Neli and

1300
01:24:52,585 --> 01:24:56,545
Speaker 2:  I'll be back on Friday to talk about all the politics, all the

1301
01:24:56,545 --> 01:25:00,265
Speaker 2:  news, whatever weird stuff is happening at the FCC Mor

1302
01:25:00,335 --> 01:25:04,145
Speaker 2:  gadgets that are still to come and everything else. We'll see you then. Rock

1303
01:25:04,145 --> 01:25:04,425
Speaker 2:  and roll.

