1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 5d2ab537-6801-423c-aa54-32e3549033c2
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-413040593540717371/8061311869007081849/s93290-US-5730s-1731672284.mp3
Description: Nilay and David talk about the future of social, in light of Bluesky's recent surge in growth. Threads is huge, Bluesky is ascendent, Mastodon is... around, but can any of them become the next Twitter? Is that even the goal? After that, Kylie Robison joins the show and the gang discusses Apple's smart home device (which is just an iPad), the AI scaling slowdown, and a new twist in the delivery wars. In the lightning round, it's all about disclosures, wireless carriers, and the sad end of Freevee.

2
00:02:03,615 --> 00:02:07,245
Speaker 2:  Hello and welcome to Vergecast, the flagship podcast of six inch Wall

3
00:02:07,245 --> 00:02:07,645
Speaker 2:  tablets.

4
00:02:09,265 --> 00:02:10,725
Speaker 2:  So what everybody wants, do we have

5
00:02:10,725 --> 00:02:12,925
Speaker 3:  To be, I don't like that one very much

6
00:02:14,825 --> 00:02:18,565
Speaker 2:  Fr from what I gather, this is the product that's gonna set the tech industry

7
00:02:18,585 --> 00:02:19,085
Speaker 2:  on fire.

8
00:02:20,705 --> 00:02:21,515
Speaker 2:  It's gonna happen, David.

9
00:02:22,425 --> 00:02:26,035
Speaker 3:  Sure. Listen, if it'll make you shut up about your garage door, I'll take

10
00:02:26,035 --> 00:02:26,515
Speaker 3:  it. Oh no.

11
00:02:26,515 --> 00:02:29,875
Speaker 2:  Well there's gonna be some, some garage door talk on this show. Hi, I'm your

12
00:02:29,875 --> 00:02:33,315
Speaker 2:  friend Eli. David Pierce is here. Hello. A little later. Kylie Robinson is

13
00:02:33,315 --> 00:02:36,395
Speaker 2:  gonna join us. We're gonna talk about whether or not AI is is real, whether

14
00:02:36,395 --> 00:02:38,885
Speaker 2:  it's just a fake idea. The Vergecast,

15
00:02:40,075 --> 00:02:43,565
Speaker 2:  there's a lot of news talk about this week. It is week negative eight of

16
00:02:43,565 --> 00:02:47,205
Speaker 2:  the Trump administration. So that Is that how they count and that's how George Washington

17
00:02:47,475 --> 00:02:48,725
Speaker 2:  Yeah, that seems right. That's in the

18
00:02:49,005 --> 00:02:51,765
Speaker 3:  Constitution. As he was in a boat, he was like, this is week negative six

19
00:02:51,825 --> 00:02:53,605
Speaker 3:  and then it, yeah, no, that makes sense. Yeah,

20
00:02:55,195 --> 00:02:58,205
Speaker 2:  Elon is already doing stuff. There's a fake department of government efficiency

21
00:02:58,205 --> 00:03:01,805
Speaker 2:  that we should talk about for as much as we need to talk about it. There's

22
00:03:01,805 --> 00:03:04,805
Speaker 2:  a fake wireless carrier called Boost Mobile that we should talk about that

23
00:03:04,805 --> 00:03:05,725
Speaker 2:  I'm excited to talk about.

24
00:03:06,035 --> 00:03:06,885
Speaker 3:  It's a real carrier

25
00:03:07,185 --> 00:03:09,885
Speaker 2:  Dli. There are rumors that Apple's gonna make a wall tablet, so we gotta

26
00:03:09,885 --> 00:03:13,485
Speaker 2:  talk about garage droppers as promised. But let's start with

27
00:03:15,315 --> 00:03:19,295
Speaker 2:  what's happening on social media. We've talked a lot about

28
00:03:19,295 --> 00:03:22,975
Speaker 2:  the Fedi verse on this show, about the idea of the open social web

29
00:03:23,685 --> 00:03:27,455
Speaker 2:  that maybe you weren't gonna be locked into one platform that you can

30
00:03:27,455 --> 00:03:31,215
Speaker 2:  move around. That's Mastodon. There's a protocol called

31
00:03:31,495 --> 00:03:35,335
Speaker 2:  Activity Pub that we've talked about a lot. Threads from Meta is using Activity

32
00:03:35,435 --> 00:03:38,615
Speaker 2:  Pub the very slowly inched their way to support

33
00:03:39,075 --> 00:03:42,015
Speaker 2:  people. Have a lot of issues with threads overall because of its moderation.

34
00:03:42,795 --> 00:03:46,705
Speaker 2:  And then this week after the election, after Elon

35
00:03:46,705 --> 00:03:50,385
Speaker 2:  has basically turned the X algorithm to being a pure

36
00:03:50,635 --> 00:03:54,505
Speaker 2:  flood of propaganda for himself, not, not even I would say conservative ideas

37
00:03:54,505 --> 00:03:58,225
Speaker 2:  just for Elon Musk. People are fleeing X,

38
00:03:58,225 --> 00:04:01,785
Speaker 2:  they're, they're out of there. Huge drop in users and they're not going to

39
00:04:01,785 --> 00:04:05,745
Speaker 2:  Threads or MA on. They're going to Bluesky, which is a different federated

40
00:04:05,745 --> 00:04:09,585
Speaker 2:  social platform that uses a different protocol called At Protocol.

41
00:04:09,585 --> 00:04:13,385
Speaker 2:  At Protocol I, I've talked to Blue Sky's, COJ Grabber on

42
00:04:13,455 --> 00:04:16,865
Speaker 2:  decoder. We can get into the weeds of it, but it seems like that is the winner

43
00:04:17,405 --> 00:04:20,145
Speaker 2:  in social media this week. David, what do you think is going on here?

44
00:04:20,645 --> 00:04:22,505
Speaker 3:  Is it the winner? This is such an interesting question

45
00:04:22,815 --> 00:04:23,225
Speaker 2:  This week.

46
00:04:23,575 --> 00:04:27,465
Speaker 3:  This week, yes it is. It is the vibe's winner in a very real way.

47
00:04:27,465 --> 00:04:31,025
Speaker 3:  And I think the thing that we've discovered over the two years since

48
00:04:31,655 --> 00:04:35,305
Speaker 3:  Elon Musk bought Twitter is that the vibe shift really

49
00:04:35,305 --> 00:04:39,185
Speaker 3:  matters. And I think your, your diagnosis is exactly right,

50
00:04:39,185 --> 00:04:42,705
Speaker 3:  right? Like Threads was the thing. Threads probably still is the thing and

51
00:04:42,705 --> 00:04:45,545
Speaker 3:  we should talk about it, but Threads has

52
00:04:45,545 --> 00:04:49,225
Speaker 3:  275 million users. That's what Mark Zuckerberg announced. They're signing

53
00:04:49,225 --> 00:04:52,905
Speaker 3:  up a million people a day like that. That thing is growing like a weed.

54
00:04:52,905 --> 00:04:56,265
Speaker 3:  There's been some news that Threads is gonna turn on ads next year, which

55
00:04:56,265 --> 00:05:00,065
Speaker 3:  means it's going to be a big scale business. All anyone

56
00:05:00,065 --> 00:05:03,785
Speaker 3:  wants to talk about right now is Bluesky. And I think Bluesky has

57
00:05:04,645 --> 00:05:07,625
Speaker 3:  hit something like mainstream

58
00:05:08,585 --> 00:05:11,785
Speaker 3:  critical mass, which I think is a really exciting

59
00:05:12,585 --> 00:05:16,305
Speaker 3:  B, really annoying in some ways that we should talk about. And C

60
00:05:16,365 --> 00:05:20,145
Speaker 3:  really surprising, I think if I'm being completely honest, I kind of left

61
00:05:20,215 --> 00:05:24,185
Speaker 3:  Bluesky for Dead a while ago. It, it had its first spike. People

62
00:05:24,185 --> 00:05:27,345
Speaker 3:  were really excited. I think Bluesky has done a lot of things really right

63
00:05:27,805 --> 00:05:30,665
Speaker 3:  in how to build this kind of thing. It was very smart about how to think

64
00:05:30,665 --> 00:05:34,505
Speaker 3:  about identity. It was very smart in thinking about discovery. They

65
00:05:34,505 --> 00:05:38,345
Speaker 3:  built products like List and messages and like as a, as a platform.

66
00:05:38,575 --> 00:05:42,105
Speaker 3:  Bluesky is dramatically better than any of the other competitors right now.

67
00:05:42,925 --> 00:05:46,425
Speaker 3:  But it was weird and it was like all the people who went to Bluesky

68
00:05:47,005 --> 00:05:50,945
Speaker 3:  at the beginning went to be weird on purpose and that is like fine and

69
00:05:50,945 --> 00:05:54,625
Speaker 3:  good as far as it goes, right? And so my thinking was

70
00:05:54,625 --> 00:05:57,770
Speaker 3:  there's going to be this subset of people like the the Twitter shit posters

71
00:05:57,825 --> 00:06:00,885
Speaker 3:  who were going to be very happy of Bluesky and we just going to sort of hang

72
00:06:00,885 --> 00:06:04,805
Speaker 3:  out with each other over there. And it got out of that this week.

73
00:06:04,975 --> 00:06:08,565
Speaker 3:  We're now in a moment where people who don't want any part of that

74
00:06:09,385 --> 00:06:13,165
Speaker 3:  are coming onto Bluesky. People are coming back to Bluesky, A OC came back

75
00:06:13,165 --> 00:06:16,525
Speaker 3:  to Bluesky and caused like a mini uproar when she started posting. There

76
00:06:16,525 --> 00:06:19,925
Speaker 3:  again, everybody's trying to make Skitting happen again instead of calling

77
00:06:19,925 --> 00:06:23,685
Speaker 3:  it posting like Bluesky is is I think by

78
00:06:23,825 --> 00:06:27,165
Speaker 3:  far like an order of magnitude out of the

79
00:06:27,465 --> 00:06:31,445
Speaker 3:  actual competitor to Threads World right now. But in

80
00:06:31,445 --> 00:06:34,405
Speaker 3:  terms of like who has the juice, I think Bluesky

81
00:06:34,765 --> 00:06:37,205
Speaker 3:  legitimately has the juice at this point. Yeah,

82
00:06:37,705 --> 00:06:41,325
Speaker 2:  Two things about this that I think are really important. One Threads is an

83
00:06:41,325 --> 00:06:44,085
Speaker 2:  algorithmic platform and so is X now?

84
00:06:44,595 --> 00:06:44,885
Speaker 3:  Yeah,

85
00:06:45,345 --> 00:06:48,965
Speaker 2:  You open XI open my X account and it is just the

86
00:06:48,965 --> 00:06:52,045
Speaker 2:  algorithm feeding me whatever Elon Musk wants me to see,

87
00:06:53,005 --> 00:06:56,875
Speaker 2:  which is mostly himself. Yeah. Weird. And I, I think

88
00:06:56,875 --> 00:07:00,195
Speaker 2:  people are just reacting to that and reacting to that poison. It is a right

89
00:07:00,195 --> 00:07:03,795
Speaker 2:  wing, echo chamber. It is impossible to participate there unless you say

90
00:07:03,795 --> 00:07:07,675
Speaker 2:  exactly what that audience wants to hear. That's bad. Like that's

91
00:07:07,865 --> 00:07:11,595
Speaker 2:  algorithmic collapse is real. I don't think anybody wants to be in an echo

92
00:07:11,595 --> 00:07:13,795
Speaker 2:  chamber that powerful in any way, shape or form.

93
00:07:13,905 --> 00:07:17,715
Speaker 3:  Some people do. I mean to, to be blunt, some people do and that's fine. Right?

94
00:07:17,715 --> 00:07:21,555
Speaker 3:  But it is like the distance between X and like truth social

95
00:07:21,695 --> 00:07:25,635
Speaker 3:  and Rumble is smaller and smaller every day. Yeah. And there is a

96
00:07:25,635 --> 00:07:29,515
Speaker 3:  community of people who is, well-served by that, great. But it is

97
00:07:29,635 --> 00:07:33,195
Speaker 3:  like if that platform has run away from anything like

98
00:07:33,285 --> 00:07:36,555
Speaker 3:  mainstream appeal, like actively running away from it.

99
00:07:36,705 --> 00:07:40,595
Speaker 2:  Yeah. And, and we should talk about the extreme hypocrisy of Elon

100
00:07:40,595 --> 00:07:44,435
Speaker 2:  Musk in general who is like, I'm a free speech warrior and then slowly closed

101
00:07:44,975 --> 00:07:48,515
Speaker 2:  the boundary of speech on X to be exactly what he wants. Yeah.

102
00:07:48,855 --> 00:07:52,755
Speaker 2:  The point I'm making is Threads is also an algorithmic platform. You

103
00:07:52,755 --> 00:07:56,155
Speaker 2:  open it and you just see a fire hose of whatever meta wants you to see, which

104
00:07:56,155 --> 00:07:59,595
Speaker 2:  is the most inane engagement bait that has ever been produced in the entire

105
00:07:59,875 --> 00:08:03,275
Speaker 2:  Yes. Right. Like, and it's so, it's like not a you open it, you're like,

106
00:08:03,275 --> 00:08:06,315
Speaker 2:  what is happening here? What am I seeing? And yes, there's a reverse chron

107
00:08:06,425 --> 00:08:09,275
Speaker 2:  feed that you can like slide over to, but it's not the default. Even If,

108
00:08:09,275 --> 00:08:12,795
Speaker 2:  you do set it, they'll drop you back into the algorithmic feed at a moment's

109
00:08:12,795 --> 00:08:15,675
Speaker 2:  notice. And really you just get to a place where

110
00:08:16,705 --> 00:08:20,675
Speaker 2:  they're not platforms that replace Twitter. Like

111
00:08:20,675 --> 00:08:24,115
Speaker 2:  they, they don't serve the same role. They're not doing the same job threads.

112
00:08:24,155 --> 00:08:27,515
Speaker 2:  I think intentionally they've talked about how they don't want it to be that

113
00:08:28,155 --> 00:08:32,075
Speaker 2:  XI think intentionally in another way, which is he just broke it,

114
00:08:32,175 --> 00:08:35,715
Speaker 2:  you know? He just like took the thing and yeah, used it for his own purposes.

115
00:08:37,055 --> 00:08:40,165
Speaker 3:  Super successfully by the way, like just to, he did, just to briefly give

116
00:08:40,165 --> 00:08:44,125
Speaker 3:  credit where credit is due. Like I, I got a bunch of crap from

117
00:08:44,285 --> 00:08:48,205
Speaker 3:  people after the election. 'cause we've, we've said many times how stupid

118
00:08:48,525 --> 00:08:52,245
Speaker 3:  a purchasing decision Twitter was, which I would also remind you

119
00:08:52,555 --> 00:08:56,085
Speaker 3:  Elon Musk also agrees with that fact. Yeah. He tried very hard to not

120
00:08:56,405 --> 00:09:00,365
Speaker 3:  purchase it, but it, like, in a, in a certain way of thinking about it,

121
00:09:01,225 --> 00:09:04,565
Speaker 3:  boy was buying Twitter a good move for Elon Musk who is now just

122
00:09:05,265 --> 00:09:06,965
Speaker 3:  the shadow president of the United States.

123
00:09:07,445 --> 00:09:10,805
Speaker 2:  I totally think that's debatable. I think he spent a lot of money and he

124
00:09:10,805 --> 00:09:13,645
Speaker 2:  got a bunch of votes and he did a bunch of rallies and he gave away a million

125
00:09:13,645 --> 00:09:16,805
Speaker 2:  dollars to sign people to a petition that may or may not have been in Constitu.

126
00:09:16,825 --> 00:09:20,525
Speaker 2:  Who knows the I'm gonna make the X algorithm

127
00:09:20,555 --> 00:09:24,525
Speaker 2:  just do whatever I want. Debatable, I think, I think, I don't

128
00:09:24,525 --> 00:09:27,885
Speaker 2:  know that the average swing voter got swayed by the amount of garbage on

129
00:09:27,965 --> 00:09:28,645
Speaker 2:  X. No,

130
00:09:28,645 --> 00:09:31,845
Speaker 3:  But he's now the second most powerful person in America.

131
00:09:32,705 --> 00:09:36,655
Speaker 2:  Right. But did X make him that or, or did his money spent

132
00:09:36,655 --> 00:09:40,575
Speaker 2:  like literally handing novelty checks out on saving like, I don't know

133
00:09:40,575 --> 00:09:44,055
Speaker 2:  the answer. It's a reasonable question. Yeah. But the point, the broader

134
00:09:44,055 --> 00:09:47,605
Speaker 2:  point of making the second part is these are now creator

135
00:09:48,045 --> 00:09:51,565
Speaker 2:  platforms. That's what they are. Yes. They're closed in

136
00:09:51,885 --> 00:09:55,765
Speaker 2:  insanely closed X will deran your post If, you put links in

137
00:09:55,765 --> 00:09:59,595
Speaker 2:  them, so Will threads. Yep. Because they're algorithmic, they're

138
00:09:59,755 --> 00:10:03,565
Speaker 2:  designed to promote engagement on the platform themselves. So they are

139
00:10:03,565 --> 00:10:07,485
Speaker 2:  just very closed. They're in they're little walled gardens

140
00:10:07,485 --> 00:10:10,605
Speaker 2:  that you're supposed to be in. And even if Threads finishes its activity

141
00:10:10,625 --> 00:10:14,525
Speaker 2:  pub integration, even if it all works out the way that I, I would

142
00:10:14,525 --> 00:10:18,005
Speaker 2:  very much want it to work out, it's still closed. Like it's de

143
00:10:18,485 --> 00:10:20,485
Speaker 2:  designed to be a closed ecosystem. And I think

144
00:10:20,485 --> 00:10:23,925
Speaker 3:  Crucially that, that that thing has kind of calcified

145
00:10:24,415 --> 00:10:27,405
Speaker 3:  since really the last time we talked about this, right? Like threads has

146
00:10:27,405 --> 00:10:31,365
Speaker 3:  now been telling us what threads is for long enough

147
00:10:31,365 --> 00:10:34,365
Speaker 3:  that the smart thing to do is just believe it, right? Yeah. Everybody is

148
00:10:34,365 --> 00:10:37,765
Speaker 3:  after being like, Adam Moer, please, dear God, let me

149
00:10:38,155 --> 00:10:41,965
Speaker 3:  just see the reverse crown of all the people I follow. If, if Adam

150
00:10:42,155 --> 00:10:45,045
Speaker 3:  Moer and Mark Zuckerberg and the Threads team wanted to do that, they would

151
00:10:45,045 --> 00:10:48,845
Speaker 3:  have, they were like, this is, this is where we are. The thing you're describing

152
00:10:48,845 --> 00:10:52,045
Speaker 3:  is what threads is going to be for the foreseeable future. And I think to

153
00:10:52,045 --> 00:10:55,405
Speaker 3:  me that is what is underlying a lot of this is there is this sense of like,

154
00:10:55,405 --> 00:10:58,485
Speaker 3:  threads was new and it was early and we weren't sure what it was gonna be.

155
00:10:58,485 --> 00:11:01,885
Speaker 3:  And they seem to have these big interesting ambitious goals. None of that

156
00:11:02,625 --> 00:11:06,005
Speaker 3:  counts in its favor anymore. Like Threads is threads now and we, we should

157
00:11:06,005 --> 00:11:07,045
Speaker 3:  take the thing for what it is

158
00:11:07,185 --> 00:11:09,885
Speaker 2:  And, and and, and it's gonna grow however it grows, right? Yeah. It is growing

159
00:11:09,885 --> 00:11:13,845
Speaker 2:  at some rate, but it is very much meant to be a creator platform.

160
00:11:13,905 --> 00:11:17,445
Speaker 2:  And, and I think that's how they're gonna think about it. Bluesky for

161
00:11:17,925 --> 00:11:21,605
Speaker 2:  whatever it will become is way smaller. As you noted David, it's 15 million

162
00:11:21,605 --> 00:11:25,405
Speaker 2:  users just today as we're talking. But it's designed to be an open

163
00:11:25,725 --> 00:11:29,485
Speaker 2:  platform. Links are not suppressed in the algorithm. It is leading you

164
00:11:29,485 --> 00:11:33,445
Speaker 2:  towards revon feeds by default. There are algorithms

165
00:11:33,445 --> 00:11:37,205
Speaker 2:  you can get that sort the fire hose in different ways. That's a part of their

166
00:11:37,205 --> 00:11:40,245
Speaker 2:  monetization strategy is actually to sell you algorithms, which is

167
00:11:41,075 --> 00:11:44,445
Speaker 2:  like fascinating. Yes. The moderation is quote

168
00:11:44,455 --> 00:11:48,085
Speaker 2:  composable, so you can tell it how you want to moderate the feeds.

169
00:11:49,365 --> 00:11:53,335
Speaker 2:  The protocol I think is wonkier, right? Like there

170
00:11:53,335 --> 00:11:57,295
Speaker 2:  isn't another Bluesky server yet, right? So everything is happening on one

171
00:11:57,295 --> 00:11:59,855
Speaker 2:  server. You can kind of set your own domain name so you can like make it

172
00:11:59,855 --> 00:12:02,995
Speaker 2:  feel a little bit different. But eventually when there is one,

173
00:12:03,895 --> 00:12:07,515
Speaker 2:  the idea of following someone from another server is not as political as

174
00:12:07,515 --> 00:12:10,995
Speaker 2:  it is on Mastodon. Like you're not getting at these like server wide block

175
00:12:10,995 --> 00:12:14,515
Speaker 2:  lists. Like it's just not how it works, right? All the federation is at the

176
00:12:14,515 --> 00:12:17,995
Speaker 2:  user level. So if you're like, I don't like this Bluesky server that I'm

177
00:12:17,995 --> 00:12:21,955
Speaker 2:  on, I can take my whole account and take it to another server because

178
00:12:21,955 --> 00:12:25,865
Speaker 2:  that's the, the, the element that is moderated is

179
00:12:25,865 --> 00:12:28,745
Speaker 2:  the user account. Whereas on Activity Pub and MAs that and whatever else,

180
00:12:28,965 --> 00:12:32,665
Speaker 2:  the thing that is federated is the servers, right? So like

181
00:12:32,765 --> 00:12:36,625
Speaker 2:  if The Verge Mastodon existed, that would be the the thing that

182
00:12:36,625 --> 00:12:39,465
Speaker 2:  is federated. And you could be like, I hate uni and like leave and go to

183
00:12:39,465 --> 00:12:43,345
Speaker 2:  mastodon.com or whatever of Bluesky. It's your

184
00:12:43,345 --> 00:12:46,845
Speaker 2:  account is the thing that moves around, right? And you can take that

185
00:12:47,075 --> 00:12:49,405
Speaker 2:  from server to server at will kind of, right?

186
00:12:49,835 --> 00:12:53,165
Speaker 3:  Yeah. And I think that's the thing. It it Bluesky like I said, got a lot

187
00:12:53,165 --> 00:12:56,125
Speaker 3:  right? But I think that is the thing it got most right. And I think is the

188
00:12:56,125 --> 00:12:59,845
Speaker 3:  thing that is proving to be the hardest about the Fedi verse

189
00:13:00,105 --> 00:13:04,085
Speaker 3:  and, and this kind of whole universe is nobody can figure out who you are

190
00:13:04,155 --> 00:13:07,045
Speaker 3:  like in a, in a sort of meaningful way. Like what is my

191
00:13:08,085 --> 00:13:11,445
Speaker 3:  username and identity and profile is actually like a crucially important

192
00:13:11,445 --> 00:13:15,245
Speaker 3:  part of this entire system. And it is the most complicated

193
00:13:15,245 --> 00:13:18,925
Speaker 3:  thing going in Activity Pub and Masson and Bluesky. It is like central

194
00:13:19,185 --> 00:13:22,405
Speaker 3:  and they've done a bunch of really smart stuff and like your, your username

195
00:13:22,405 --> 00:13:25,565
Speaker 3:  is also just a URL. You can just type your username into a bar and it will

196
00:13:25,565 --> 00:13:29,485
Speaker 3:  load up your profile. Like that stuff is powerful and I think is

197
00:13:29,505 --> 00:13:32,805
Speaker 3:  is a big win. Like you said, Bluesky desperately needs

198
00:13:33,405 --> 00:13:37,245
Speaker 3:  a second thing because it is, it is currently it is exactly as

199
00:13:37,245 --> 00:13:41,085
Speaker 3:  open as Facebook. It has a bunch

200
00:13:41,085 --> 00:13:44,365
Speaker 3:  of big ideas about being open and it just isn't right now. And

201
00:13:44,595 --> 00:13:48,295
Speaker 3:  they've gotta build the next thing. But I

202
00:13:48,855 --> 00:13:52,335
Speaker 3:  I, a big part of this honestly is I, I believe Bluesky is telling the truth

203
00:13:52,685 --> 00:13:56,535
Speaker 3:  much more than I believe Threads is telling the truth about where they want

204
00:13:56,535 --> 00:13:57,335
Speaker 3:  to go. Yeah.

205
00:13:57,675 --> 00:14:01,615
Speaker 2:  And Adam er again very direct, we don't wanna do news.

206
00:14:01,685 --> 00:14:05,135
Speaker 2:  It's more trouble than it's worth. Yeah. Okay, well you have

207
00:14:05,475 --> 00:14:08,855
Speaker 2:  an X in this election you had an X platform that was explicitly

208
00:14:09,585 --> 00:14:11,455
Speaker 2:  showcasing one view of America

209
00:14:13,015 --> 00:14:16,455
Speaker 2:  explicitly in the tank for one candidate. Yep. And then the alternative was

210
00:14:16,455 --> 00:14:20,445
Speaker 2:  nothing. Right? The alternative platform and that and that style

211
00:14:20,445 --> 00:14:24,245
Speaker 2:  of social media was we don't want this here. And that's a weird

212
00:14:24,315 --> 00:14:27,165
Speaker 2:  imbalance, right? Because all the people who were leaving X were going to

213
00:14:27,165 --> 00:14:31,085
Speaker 2:  a platform where that stuff was not there the way that it was

214
00:14:31,085 --> 00:14:34,765
Speaker 2:  on the other platform. Certainly not as overt. And I think now what you're

215
00:14:34,765 --> 00:14:37,045
Speaker 2:  getting is, okay, that didn't work either. And I think now what you're getting

216
00:14:37,045 --> 00:14:39,685
Speaker 2:  is a bunch of people saying, well this didn't feel right. Let's go to a platform

217
00:14:39,685 --> 00:14:43,645
Speaker 2:  where we can make it what we want. Right? And Bluesky literally has the tools

218
00:14:43,655 --> 00:14:47,485
Speaker 2:  built into it to make it what you want. They have the APIs

219
00:14:47,485 --> 00:14:51,285
Speaker 2:  are there, the, the availability of just the fire hose of posts is

220
00:14:51,285 --> 00:14:54,125
Speaker 2:  there and people can build tools. There's already

221
00:14:55,315 --> 00:14:59,285
Speaker 2:  like Deck Blue I think it's called is the tweet deck for Bluesky. It like

222
00:14:59,285 --> 00:15:02,405
Speaker 2:  already exists. Yep, there it is. You can just use it. So there's something

223
00:15:02,405 --> 00:15:05,965
Speaker 2:  really interesting happening here. We have kind of like a VHS beta

224
00:15:06,245 --> 00:15:08,565
Speaker 2:  situation inside of federated social media, open social media.

225
00:15:10,095 --> 00:15:12,995
Speaker 2:  But a lot of the smart people that I talk to are like, this isn't gonna matter

226
00:15:13,015 --> 00:15:16,635
Speaker 2:  at the end of the day because there's software that bridges between all of

227
00:15:16,635 --> 00:15:20,595
Speaker 2:  these things. And actually the best outcome is for MAs on

228
00:15:20,595 --> 00:15:23,995
Speaker 2:  and Bluesky and Threads and whatever else part of the Fed verse ghost

229
00:15:24,535 --> 00:15:27,915
Speaker 2:  to all just be able to talk to each other and the protocol shouldn't matter

230
00:15:27,915 --> 00:15:31,035
Speaker 2:  as much. I don't know if we'll get there. I think that's a long way away.

231
00:15:31,115 --> 00:15:34,235
Speaker 2:  I think people are still trying to make their specific protocols work and

232
00:15:34,235 --> 00:15:37,555
Speaker 2:  you gotta make technology bets, right? So you gotta start with something,

233
00:15:38,495 --> 00:15:42,195
Speaker 2:  but I can see a future where yeah, actually everything does work

234
00:15:42,435 --> 00:15:45,395
Speaker 2:  together way better. And If you, what you want to do is pick the creator

235
00:15:45,875 --> 00:15:49,675
Speaker 2:  platform. You can go pick the creator platform, but if what you

236
00:15:49,675 --> 00:15:53,525
Speaker 2:  want is the more open, here's where we share a bunch of links and

237
00:15:53,525 --> 00:15:55,885
Speaker 2:  talk about them platform that is also available to you.

238
00:15:56,475 --> 00:16:00,245
Speaker 3:  Yeah. I think the outcome you're describing I think is pretty

239
00:16:00,245 --> 00:16:03,525
Speaker 3:  clearly the best version of this story. And

240
00:16:04,105 --> 00:16:06,765
Speaker 3:  it was always gonna take a long time, right? Like we've, we've been talking

241
00:16:06,845 --> 00:16:09,605
Speaker 3:  a lot about the Fedi verse and activity pub for the last couple of years

242
00:16:09,745 --> 00:16:13,565
Speaker 3:  and I've reached a point where I'm, I'm sort of itchy that it

243
00:16:13,565 --> 00:16:17,405
Speaker 3:  hasn't happened yet and it's like, okay, maybe this just isn't gonna ha

244
00:16:17,405 --> 00:16:20,365
Speaker 3:  and then it's like, okay, every time I talk to people they're like, everyone

245
00:16:20,365 --> 00:16:23,845
Speaker 3:  who works on this has been working on this longer than you realize and is

246
00:16:23,845 --> 00:16:26,965
Speaker 3:  un is aware of the fact that this is going to take a long time. Right? So

247
00:16:26,965 --> 00:16:30,805
Speaker 3:  it's like none of this gets built in a day. I also

248
00:16:30,805 --> 00:16:34,605
Speaker 3:  think these things are in some ways getting further apart

249
00:16:34,985 --> 00:16:38,605
Speaker 3:  and that's the part that gets problematic, right? Like everyday Threads

250
00:16:38,605 --> 00:16:42,445
Speaker 3:  doesn't build out really strong activity pub integration,

251
00:16:42,585 --> 00:16:46,405
Speaker 3:  it gets harder to build really strong activity. Pub integration and everyday

252
00:16:46,405 --> 00:16:50,285
Speaker 3:  threads gets more successful. Building that stuff well becomes less

253
00:16:50,285 --> 00:16:53,485
Speaker 3:  and less compelling, right? Like Threads as a

254
00:16:54,045 --> 00:16:57,925
Speaker 3:  powerful closed creator platform could be very

255
00:16:57,925 --> 00:17:01,685
Speaker 3:  successful. It is already very successful. It's just like there

256
00:17:01,925 --> 00:17:05,885
Speaker 3:  comes a time when being a good steward of an open ecosystem is not as

257
00:17:06,085 --> 00:17:09,205
Speaker 3:  exciting as it once was when you were teeny tiny and kind of needed that

258
00:17:09,205 --> 00:17:13,165
Speaker 3:  ecosystem. I still believe the people who work there are serious when they

259
00:17:13,165 --> 00:17:14,245
Speaker 3:  say they wanna do that, but

260
00:17:15,875 --> 00:17:17,205
Speaker 3:  that doesn't get you very far.

261
00:17:17,215 --> 00:17:21,005
Speaker 2:  Lemme make the defense of the Threads team not of Meta, but

262
00:17:21,565 --> 00:17:24,805
Speaker 2:  specifically the, the challenge facing the Threads team. Sure. 'cause I I

263
00:17:24,805 --> 00:17:28,565
Speaker 2:  think they've done something here that is smart, interesting at least, but

264
00:17:28,565 --> 00:17:32,205
Speaker 2:  potentially Smart If, you look light Bluesky, they built all their features

265
00:17:32,465 --> 00:17:35,965
Speaker 2:  and they have struggled to scale them to even 15 million users, which is

266
00:17:35,965 --> 00:17:39,005
Speaker 2:  why they had invites at the beginning, which is why they, the thing called

267
00:17:39,005 --> 00:17:42,805
Speaker 2:  the health thread where like all you could see was one insane thread that

268
00:17:42,805 --> 00:17:46,725
Speaker 2:  was going crazy every day, but they built the complete product

269
00:17:46,825 --> 00:17:50,795
Speaker 2:  and they scaled it. And that has, and that's how most

270
00:17:50,795 --> 00:17:54,275
Speaker 2:  people build things. The Threads team is taking a productivity pub

271
00:17:54,725 --> 00:17:58,275
Speaker 2:  where they're adding one piece of federation at scale

272
00:17:58,275 --> 00:18:02,235
Speaker 2:  immediately, right? So they're like, okay, you can now see

273
00:18:02,235 --> 00:18:05,395
Speaker 2:  who follows you in the Fedi verse. All 275 million of you can see this at

274
00:18:05,395 --> 00:18:09,155
Speaker 2:  scale. It works. Okay, now we're gonna let you see who liked it.

275
00:18:09,865 --> 00:18:13,495
Speaker 2:  We're not gonna let you reply yet. Now we're gonna let the next thing happen.

276
00:18:13,715 --> 00:18:17,615
Speaker 2:  And they're adding sort of like one piece of the stack at the scale of

277
00:18:17,615 --> 00:18:21,445
Speaker 2:  the whole platform, which is just a different way of going

278
00:18:21,445 --> 00:18:24,525
Speaker 2:  about it. But the fact that the loops haven't closed yet, I think is what's

279
00:18:24,645 --> 00:18:26,205
Speaker 2:  striving everybody crazy. Right?

280
00:18:26,265 --> 00:18:27,405
Speaker 3:  And and I I I agree

281
00:18:27,525 --> 00:18:29,405
Speaker 2:  With you that right? If someone replies to you from the Fed verse and you

282
00:18:29,405 --> 00:18:31,725
Speaker 2:  can't write back to them, it's like, what is the point of this? Right?

283
00:18:31,725 --> 00:18:35,165
Speaker 3:  That's actually like an actively bad experience. Yeah. If you're, if you're

284
00:18:35,165 --> 00:18:38,965
Speaker 3:  someone who is paying attention to protocol development, that is like exciting.

285
00:18:39,705 --> 00:18:41,645
Speaker 3:  But the thing where somebody replies to me,

286
00:18:41,645 --> 00:18:42,365
Speaker 2:  I'm sorry everybody, sorry, this is

287
00:18:42,365 --> 00:18:45,845
Speaker 3:  What I mean, right? But it's like what it actually looks like is a user is

288
00:18:46,085 --> 00:18:49,925
Speaker 3:  I see a thing that asks me periodically if I want to keep sharing

289
00:18:49,925 --> 00:18:53,525
Speaker 3:  to the Fedi verse that I have to figure out what that means and decide.

290
00:18:53,785 --> 00:18:57,365
Speaker 3:  And then I get a bunch of people who are like concerned trolling me into

291
00:18:57,365 --> 00:19:00,525
Speaker 3:  sharing to the Fedi verse. And then people reply to me, but I can't reply

292
00:19:00,525 --> 00:19:03,365
Speaker 3:  to them. And if I like what they reply to, they don't see it like it's bad

293
00:19:03,365 --> 00:19:07,125
Speaker 3:  product until it works. And I think the longer it goes being bad

294
00:19:07,125 --> 00:19:10,765
Speaker 3:  product, the less compelling it becomes kind of to

295
00:19:10,765 --> 00:19:13,485
Speaker 3:  everybody involved. I'm still very hopeful and I do still think it's the

296
00:19:13,485 --> 00:19:17,445
Speaker 3:  right answer, but I, I worry increasingly, like the reason

297
00:19:17,525 --> 00:19:21,175
Speaker 3:  I think this Bluesky thing has been such good news is I think Threads

298
00:19:22,405 --> 00:19:26,145
Speaker 3:  really didn't seem like it was gonna have meaningful competition there

299
00:19:26,285 --> 00:19:29,545
Speaker 3:  for a while. And I think the idea that Bluesky,

300
00:19:30,015 --> 00:19:33,895
Speaker 3:  even if it doesn't like federate in the way that we want, even

301
00:19:33,895 --> 00:19:36,615
Speaker 3:  if it doesn't become this sort of big beautiful open thing like competition

302
00:19:36,615 --> 00:19:40,575
Speaker 3:  is good. And the idea that Threads was just going to sort of walk away with

303
00:19:40,575 --> 00:19:43,055
Speaker 3:  this because we all wanted some other place to

304
00:23:18,815 --> 00:23:22,725
Speaker 2:  We're back. If I was starting The Verge cold today, you can already see

305
00:23:22,725 --> 00:23:25,885
Speaker 2:  it in our design. What I want it to be. But if I was starting it cold today,

306
00:23:27,615 --> 00:23:31,605
Speaker 2:  the open source licenses of these various platforms aside, 'cause

307
00:23:31,605 --> 00:23:35,485
Speaker 2:  they're complicated. I would be like we're starting a server and

308
00:23:35,485 --> 00:23:39,165
Speaker 2:  you can follow our feeds. Like I'm just gonna post all day on my server and

309
00:23:39,165 --> 00:23:42,445
Speaker 2:  we'll have some ads on it or whatever. Yeah. And If, you wanna follow my

310
00:23:42,455 --> 00:23:46,045
Speaker 2:  posts? You can follow them. But we're gonna own this and we're gonna curate

311
00:23:46,085 --> 00:23:48,765
Speaker 2:  a bunch of stuff from these other places using activity pubs. So If, you

312
00:23:48,765 --> 00:23:51,525
Speaker 2:  wanna see the best of what we're looking at. You can see it here. You can

313
00:23:51,525 --> 00:23:54,765
Speaker 2:  already see what we're doing with Quick Post You, we've talked about federating

314
00:23:54,765 --> 00:23:57,805
Speaker 2:  our site quite a bit. Like you, you can add all these ideas together, right?

315
00:23:58,015 --> 00:24:00,725
Speaker 2:  Right. You're Vergecast listeners, you're smart. You can see what I'm trying

316
00:24:00,725 --> 00:24:04,645
Speaker 2:  to do here. Yeah, it's harder when you have a giant website with 13 years

317
00:24:04,645 --> 00:24:08,125
Speaker 2:  of archives and static site CSS

318
00:24:08,485 --> 00:24:12,325
Speaker 2:  features that animate and blow up your phone when you scroll. To be

319
00:24:12,325 --> 00:24:16,165
Speaker 2:  honest. Yeah. Some of our old ones were were, look, the technology was

320
00:24:16,165 --> 00:24:19,645
Speaker 2:  not ready yet. We, we have a, we have a big archive that we gotta deal with.

321
00:24:19,825 --> 00:24:23,645
Speaker 2:  But if I was starting one today, I would be like, the thing to do

322
00:24:24,265 --> 00:24:28,005
Speaker 2:  is lean into federated distribution and to actually own

323
00:24:28,005 --> 00:24:31,805
Speaker 2:  your own distribution. Not be like, I'm gonna start a website and

324
00:24:31,805 --> 00:24:35,365
Speaker 2:  make SEO content for the Google robot or I'm gonna start a YouTube channel

325
00:24:35,825 --> 00:24:38,885
Speaker 2:  and eventually get buffeted around by this algorithm until I have to make

326
00:24:38,885 --> 00:24:42,865
Speaker 2:  a video about how mad I am at YouTube. Which everyone does.

327
00:24:43,685 --> 00:24:46,905
Speaker 2:  That's when you get your wings. It's actually

328
00:24:47,575 --> 00:24:50,865
Speaker 2:  lean into the next phase of what the internet looks like.

329
00:24:51,485 --> 00:24:54,825
Speaker 2:  And that's why it's like which of these protocols is gonna win? 'cause I

330
00:24:54,825 --> 00:24:57,345
Speaker 2:  don't, I think there's a bunch of businesses that are sort of like waiting

331
00:24:57,345 --> 00:25:00,985
Speaker 2:  to start once it's clear like how to do it

332
00:25:01,925 --> 00:25:05,705
Speaker 2:  but nobody knows yet. Like there's just a bunch of this foundational work

333
00:25:05,705 --> 00:25:08,025
Speaker 2:  that is still just inching towards a finish line.

334
00:25:08,415 --> 00:25:11,505
Speaker 3:  Yeah. Well and it's weird because I think we're at a moment now where

335
00:25:12,245 --> 00:25:15,865
Speaker 3:  at a protocol level activity pub is way ahead, right?

336
00:25:16,225 --> 00:25:19,505
Speaker 3:  Just in terms of sort of adoption and belief.

337
00:25:20,325 --> 00:25:23,545
Speaker 3:  It is the one that everybody who is making bets is betting on at this moment.

338
00:25:25,385 --> 00:25:28,565
Speaker 3:  But in terms of actual places people are,

339
00:25:29,515 --> 00:25:33,365
Speaker 3:  Bluesky is winning. Like I, I think it is

340
00:25:34,105 --> 00:25:37,845
Speaker 3:  it, it is going to keep growing like this because

341
00:25:37,985 --> 00:25:41,965
Speaker 3:  it made the bet that what people want is Twitter minus

342
00:25:42,345 --> 00:25:46,285
Speaker 3:  the mess. And I think truthfully one of the things that I

343
00:25:46,285 --> 00:25:50,085
Speaker 3:  have come to feel over the last couple of years is like Twitter was

344
00:25:50,205 --> 00:25:53,965
Speaker 3:  a disaster of a company run poorly in so many ways and

345
00:25:53,965 --> 00:25:57,925
Speaker 3:  also was kind of like a magical thing that really

346
00:25:57,925 --> 00:26:01,485
Speaker 3:  accomplished a lot of goals that are hard to accomplish in one place.

347
00:26:01,945 --> 00:26:05,885
Speaker 3:  And we're seeing that now, right? Like what, what all of these companies

348
00:26:05,885 --> 00:26:09,605
Speaker 3:  are doing is sort of pulling pieces apart of Twitter and doing

349
00:26:09,985 --> 00:26:13,965
Speaker 3:  one or two of those things. Well no one is

350
00:26:14,345 --> 00:26:18,245
Speaker 3:  trying to do full Twitter and frankly you probably shouldn't. Like was Twitter

351
00:26:18,245 --> 00:26:21,325
Speaker 3:  good for the world? Who knows? But the thing where it was like a place to

352
00:26:21,325 --> 00:26:25,125
Speaker 3:  hang out with your friends and also a place to discover creators

353
00:26:25,305 --> 00:26:29,245
Speaker 3:  but also a place to get like government information at incredible speed

354
00:26:29,345 --> 00:26:33,165
Speaker 3:  is like Twitter was central in our

355
00:26:33,165 --> 00:26:36,765
Speaker 3:  culture in a way that I think we still kind of underrate

356
00:26:37,105 --> 00:26:41,085
Speaker 3:  now and nothing out there is even close to

357
00:26:41,085 --> 00:26:42,125
Speaker 3:  getting to that. But

358
00:26:42,125 --> 00:26:46,085
Speaker 2:  To be clear, this is what, what I'm saying, it would be better if that

359
00:26:46,105 --> 00:26:49,845
Speaker 2:  was reconstructed but actually the government agencies

360
00:26:49,855 --> 00:26:53,685
Speaker 2:  owned their own servers. Yes. So the next time a billionaire shows

361
00:26:53,685 --> 00:26:57,245
Speaker 2:  up and breaks it, we're not like where do I get earthquake information from?

362
00:26:57,765 --> 00:27:01,365
Speaker 2:  Right. Right. Like that's a real thing that has occurred in the past several

363
00:27:01,365 --> 00:27:05,205
Speaker 2:  years. Yeah. Right. The next time someone shows up and breaks it. We're not

364
00:27:05,205 --> 00:27:08,645
Speaker 2:  like where will independent creators post their apologies?

365
00:27:09,295 --> 00:27:12,085
Speaker 2:  Which is a, a real question that was asked this week.

366
00:27:13,355 --> 00:27:15,925
Speaker 2:  It's just a lot of that that's like, oh we should actually just own our own

367
00:27:15,925 --> 00:27:19,085
Speaker 2:  tools like in a, in a meaningful way. We should own our own tools. Yeah.

368
00:27:19,085 --> 00:27:21,725
Speaker 2:  And I know I'm always ranting and raving about this 'cause we have our own

369
00:27:21,725 --> 00:27:23,925
Speaker 2:  website and it's the last website on earth and all, but I'm,

370
00:27:25,475 --> 00:27:29,135
Speaker 2:  you look at the who gets to control speech in America and it's like three

371
00:27:29,135 --> 00:27:33,095
Speaker 2:  guys. Yeah. Like at the end of the day Yeah. It's not the government

372
00:27:33,475 --> 00:27:37,335
Speaker 2:  that's bad. It's like three guys and they can come and go

373
00:27:37,405 --> 00:27:40,575
Speaker 2:  like very clearly they can come and go. I think one of the miracles of Twitter

374
00:27:41,155 --> 00:27:45,095
Speaker 2:  and people can, you are free to disagree with me about this, but by and large

375
00:27:45,165 --> 00:27:48,735
Speaker 2:  they got the balance of moderation. Correct. Yeah, I agree with that.

376
00:27:49,005 --> 00:27:52,935
Speaker 2:  That platform was lively. It it, everybody was mad

377
00:27:53,635 --> 00:27:57,215
Speaker 2:  it like sort of exactly the right volume. Jack Dorsey

378
00:27:57,635 --> 00:28:01,575
Speaker 2:  was bizarrely the sort of right personality to go sit

379
00:28:01,575 --> 00:28:05,215
Speaker 2:  in front of Congress and just accept blame with a beard in his kitchen. Yeah.

380
00:28:05,215 --> 00:28:08,295
Speaker 2:  Right. He was just like, I'll never forget that. He was like, I suck. I want

381
00:28:08,295 --> 00:28:12,215
Speaker 2:  to be clear. I agree with you that I suck. Like I

382
00:28:12,215 --> 00:28:15,535
Speaker 2:  don't, I sad that I did this, that Mark Zuckerberg quote about Twitter is

383
00:28:15,535 --> 00:28:19,475
Speaker 2:  as a clown car that fell into a gold mine and they've dismantled all that

384
00:28:19,475 --> 00:28:23,035
Speaker 2:  and they've turned the knobs on moderation and algorithms and you can just

385
00:28:23,035 --> 00:28:26,475
Speaker 2:  see, okay, this is a thing that can happen right in in America

386
00:28:27,055 --> 00:28:30,675
Speaker 2:  at least for the next eight weeks. We have a First amendment that prevents

387
00:28:30,675 --> 00:28:34,645
Speaker 2:  the government from passing content moderation rules that let

388
00:28:34,865 --> 00:28:37,725
Speaker 2:  the government level set. So you, what you need is competition.

389
00:28:38,915 --> 00:28:42,535
Speaker 2:  I'm actually, we, we should not talk about Trump too much at all, but I'm

390
00:28:42,535 --> 00:28:45,855
Speaker 2:  confident the next chairman of the FCC is gonna be Brendan Carr. Brendan

391
00:28:45,855 --> 00:28:49,695
Speaker 2:  Carr does not think the the First Amendment should keep the FCC out of

392
00:28:49,695 --> 00:28:52,855
Speaker 2:  content moderation. It's like a real thing that he's talked about. Yeah.

393
00:28:53,235 --> 00:28:56,255
Speaker 2:  And if he becomes a chairman we will talk about him a lot. So I'll set that

394
00:28:56,255 --> 00:29:00,055
Speaker 2:  aside. But up in up until now, the

395
00:29:00,435 --> 00:29:03,735
Speaker 2:  who gets to make the rules about what you see is guys.

396
00:29:04,245 --> 00:29:08,015
Speaker 2:  Yeah. Mostly just guys. It's just dudes and Sherry Redstone. Yeah. And I'm

397
00:29:08,015 --> 00:29:10,655
Speaker 2:  hopeful that this moment where people are like, screw it, we'll go to Bluesky.

398
00:29:10,655 --> 00:29:14,645
Speaker 2:  It's fun Here points to a future where future, if

399
00:29:14,705 --> 00:29:18,675
Speaker 2:  not the protocols push people towards a better outcome.

400
00:29:19,055 --> 00:29:22,985
Speaker 2:  The fact that everybody can still vote with their attention

401
00:29:23,165 --> 00:29:26,945
Speaker 2:  points to the better outcome. Yeah, I agree. Like Twitter is not like

402
00:29:26,945 --> 00:29:30,465
Speaker 2:  Elon's mistake with Twitter has always been believing it's a monopoly. And

403
00:29:30,505 --> 00:29:32,225
Speaker 2:  I think right now you can just look at the numbers.

404
00:29:33,765 --> 00:29:37,665
Speaker 2:  People are leaving Twitter to join Bluesky and like that means

405
00:29:37,665 --> 00:29:38,465
Speaker 2:  it's not a monopoly.

406
00:29:40,595 --> 00:29:40,885
Speaker 2:  Yeah.

407
00:29:41,205 --> 00:29:45,135
Speaker 3:  I I tend to think all of this is going to be

408
00:29:45,255 --> 00:29:49,155
Speaker 3:  a blip in the direction of something else.

409
00:29:49,245 --> 00:29:52,555
Speaker 3:  Right. And it's like the, what what we've learned so far is that

410
00:29:53,905 --> 00:29:56,715
Speaker 3:  leaving Twitter is harder for a lot of people than we think.

411
00:29:57,425 --> 00:30:00,915
Speaker 3:  Everybody who goes to a new platform loves to talk about the new platform

412
00:30:01,175 --> 00:30:04,235
Speaker 3:  and then once the novelty of the thing dies down,

413
00:30:05,305 --> 00:30:08,155
Speaker 3:  it's very hard to know what to do. Right. Like I feel like to some extent

414
00:30:08,155 --> 00:30:11,955
Speaker 3:  we had the same feelings about Mastodon in the early

415
00:30:11,955 --> 00:30:15,075
Speaker 3:  days and it was like maybe this is the thing. It's, it has different values.

416
00:30:15,095 --> 00:30:15,555
Speaker 3:  It, I

417
00:30:15,555 --> 00:30:16,635
Speaker 2:  Wanna be clear, I never had that feeling.

418
00:30:17,495 --> 00:30:17,715
Speaker 3:  No

419
00:30:17,975 --> 00:30:20,275
Speaker 2:  1000% ever had that feeling of mask on.

420
00:30:20,575 --> 00:30:21,995
Speaker 3:  Why then why do you have it about Bluesky?

421
00:30:23,905 --> 00:30:27,785
Speaker 2:  I think do you know that Steve Jobs quote

422
00:30:27,955 --> 00:30:31,825
Speaker 2:  about Microsoft and taste? Mm I hope listeners know what I'm talking about.

423
00:30:31,825 --> 00:30:34,945
Speaker 2:  There's this very famous Steve Jobs, he, it's like young Steve Jobs and,

424
00:30:34,945 --> 00:30:37,545
Speaker 2:  and it's in his wilderness period after he got fired from Apple, he was at

425
00:30:37,545 --> 00:30:40,705
Speaker 2:  next and he was a little more bum astic than usual 'cause he was constantly

426
00:30:40,705 --> 00:30:43,425
Speaker 2:  trying to solve the X thing and prove himself whatever. I'm just contextualize

427
00:30:43,425 --> 00:30:47,345
Speaker 2:  the quote. They asked about Microsoft and he said the problem with Microsoft

428
00:30:47,485 --> 00:30:51,425
Speaker 2:  is that they have no taste and he looks very pleased with himself. And he

429
00:30:51,425 --> 00:30:53,905
Speaker 2:  said, I don't mean that in a small way, I mean that in a big way.

430
00:30:55,085 --> 00:30:58,755
Speaker 2:  Right. They just, the company doesn't have taste, it doesn't have a sense

431
00:30:58,755 --> 00:31:02,515
Speaker 2:  of what it is doing or how it should feel. Yeah. And I've always felt that

432
00:31:02,515 --> 00:31:06,195
Speaker 2:  Mastodon lacks that particular kind of taste like it is. Software

433
00:31:07,615 --> 00:31:10,735
Speaker 2:  threads has no taste in a big way.

434
00:31:11,515 --> 00:31:13,915
Speaker 2:  I like the people who are making threads. I've, I've talked to them, they've

435
00:31:13,915 --> 00:31:17,835
Speaker 2:  shown up at VERGE parties. We threw a funeral for Twitter. The team

436
00:31:17,895 --> 00:31:21,835
Speaker 2:  was there, it was great. I they're cool as a company. Meta

437
00:31:21,865 --> 00:31:25,715
Speaker 2:  does not have taste. There's a reason Mark Zuckerberg is like wearing Roman

438
00:31:26,565 --> 00:31:30,475
Speaker 2:  fonts on his shirts. Yeah. And signing deals with RayBan. 'cause they need

439
00:31:30,475 --> 00:31:33,635
Speaker 2:  to buy taste, they need to, they need to demonstrate taste because it does

440
00:31:33,635 --> 00:31:34,995
Speaker 2:  not exist in their products.

441
00:31:35,225 --> 00:31:39,155
Speaker 3:  They've also decided several times that having taste is dangerous. Yep.

442
00:31:39,335 --> 00:31:42,995
Speaker 3:  And the only way to get as big as Meta has gotten is to not have taste

443
00:31:43,185 --> 00:31:45,875
Speaker 3:  like it's, they made a business decision to not have any taste.

444
00:31:46,355 --> 00:31:50,275
Speaker 2:  I challenge anyone to open the Facebook app and be like, I

445
00:31:50,285 --> 00:31:54,235
Speaker 2:  sense taste here. Right. Bluesky largely is a clone

446
00:31:54,395 --> 00:31:58,275
Speaker 2:  of Twitter. So like I'm not, I'm not imputing taste onto that.

447
00:31:58,625 --> 00:32:02,275
Speaker 2:  Twitter had Desi, like Twitter had famous designers, like

448
00:32:02,275 --> 00:32:06,075
Speaker 2:  important parts of Culture came out of the user base of Twitter filtered

449
00:32:06,075 --> 00:32:08,995
Speaker 2:  through Twitter's designers and product people and then out into the world.

450
00:32:08,995 --> 00:32:12,875
Speaker 2:  Right. The at mention the hashtag like all the stuff is stuff

451
00:32:12,875 --> 00:32:16,755
Speaker 2:  Twitter took from its community, productized put design around and

452
00:32:16,755 --> 00:32:20,375
Speaker 2:  then gave to the world. Pull to Refresh was a third party

453
00:32:20,885 --> 00:32:24,575
Speaker 2:  Yeah. Twitter app, Tweety mechanic that Twitter bought and they

454
00:32:24,775 --> 00:32:27,055
Speaker 2:  signed a patent pledge so that anybody could use it. So they have the patent

455
00:32:27,055 --> 00:32:30,495
Speaker 2:  on it but they won't use it. But that is like part of the culture now. Like

456
00:32:30,495 --> 00:32:34,215
Speaker 2:  Pull to Refresh is like an app mechanic. Yeah. That is like actually If you

457
00:32:34,215 --> 00:32:38,055
Speaker 2:  like spend a lot of time thinking about it has led to an entire culture.

458
00:32:40,855 --> 00:32:44,345
Speaker 2:  Blue Sky's design is a lot of copies, but the, you can see it in the people

459
00:32:44,345 --> 00:32:48,305
Speaker 2:  who are making it that they have taste, they have a very clear sense about

460
00:32:48,305 --> 00:32:52,115
Speaker 2:  what the product should be and how it should make people feel. And that is

461
00:32:52,115 --> 00:32:55,035
Speaker 2:  why they talk about composable moderation. That's why Jay's go-to response

462
00:32:55,035 --> 00:32:58,635
Speaker 2:  when you ask for about what does that mean is I have a custom feed that just

463
00:32:58,635 --> 00:33:02,475
Speaker 2:  shows me moss, like kinds of moss that I like, like they're weirdos and

464
00:33:02,475 --> 00:33:05,595
Speaker 2:  they're posters and I think that's why they attracted a bunch of weirdos

465
00:33:05,595 --> 00:33:09,515
Speaker 2:  and posters. I think that's why they've leaned into being weirdos and

466
00:33:09,515 --> 00:33:13,315
Speaker 2:  posters and like having that community there. I think that's why a culture

467
00:33:13,535 --> 00:33:16,675
Speaker 2:  has been built like slowly in the way that cultures on platforms get built.

468
00:33:17,155 --> 00:33:20,795
Speaker 2:  I don't know if any of it will be successful, but when you ask me like what's

469
00:33:20,795 --> 00:33:23,715
Speaker 2:  the difference? It's, I just think about that quote. It's like, oh they're,

470
00:33:23,865 --> 00:33:26,595
Speaker 2:  they they don't have taste and I mean that in a big way.

471
00:33:26,985 --> 00:33:30,875
Speaker 3:  Yeah, no I I I agree with that in large ways. I think

472
00:33:31,255 --> 00:33:35,075
Speaker 3:  the challenge there is like, do you know the 99 1 rule?

473
00:33:36,425 --> 00:33:39,275
Speaker 3:  This is, I don't, I don't know where it came from, but it's now like a truism

474
00:33:39,335 --> 00:33:42,995
Speaker 3:  of all sort of social posting play platforms

475
00:33:43,145 --> 00:33:46,995
Speaker 3:  that 90% of people are the audience. Right? They never post, they

476
00:33:46,995 --> 00:33:49,715
Speaker 3:  never do anything. They're just there to look. 9% of people

477
00:33:50,815 --> 00:33:54,075
Speaker 3:  are kind of light interactors. They might post a little bit, they like things,

478
00:33:54,075 --> 00:33:58,035
Speaker 3:  they reply to things, whatever, but they're, they're sort of around and

479
00:33:58,035 --> 00:34:01,955
Speaker 3:  making their presence known. And then 1% of people do the vast majority of

480
00:34:01,955 --> 00:34:04,315
Speaker 3:  the things that the other 99% of people are there for.

481
00:34:05,775 --> 00:34:09,715
Speaker 3:  The problem I think we have right now is that Bluesky is doing a really good

482
00:34:09,715 --> 00:34:13,115
Speaker 3:  job of appealing to that 1%. Like the the people

483
00:34:13,855 --> 00:34:17,195
Speaker 3:  or maybe it's the 9%, I don't know, the people who like live to post

484
00:34:17,825 --> 00:34:21,595
Speaker 3:  Love Bluesky and Bluesky is built for those people and it is fun

485
00:34:21,895 --> 00:34:25,635
Speaker 3:  and it is exciting and the vibes are good and you wanna participate.

486
00:34:26,595 --> 00:34:30,415
Speaker 3:  But that's, that is a small percentage of the thing. The 90% is who

487
00:34:30,685 --> 00:34:34,495
Speaker 3:  Meta builds for better than any other company on planet Earth. Right.

488
00:34:34,495 --> 00:34:38,175
Speaker 3:  Like that is what has made Instagram successful. It is what has made Facebook

489
00:34:38,175 --> 00:34:41,815
Speaker 3:  successful. The meta builds platforms that you come to and do nothing

490
00:34:42,115 --> 00:34:45,255
Speaker 3:  but you come to them over and over and over and over again. And so you look

491
00:34:45,255 --> 00:34:47,255
Speaker 3:  at ads and so Meta makes a ton of money, but

492
00:34:47,255 --> 00:34:50,735
Speaker 2:  That's why Meta has to go to weird algorithmic feeds where you open Instagram

493
00:34:50,735 --> 00:34:53,295
Speaker 2:  and none of your friends are there anymore and it's just creators

494
00:34:54,165 --> 00:34:57,055
Speaker 2:  bootlegging video clips of eighties movies. Right.

495
00:34:57,075 --> 00:35:00,975
Speaker 3:  But so this is the thing, right? Can you, can you build a place that is both

496
00:35:01,155 --> 00:35:05,055
Speaker 3:  fun to post and full of good stuff every time you open the app?

497
00:35:05,675 --> 00:35:09,175
Speaker 3:  I'm honestly not sure that it is. And I think again, we go back to like the

498
00:35:09,175 --> 00:35:12,935
Speaker 3:  magic of Twitter. Twitter at its peak did both of those things. You,

499
00:35:13,035 --> 00:35:16,855
Speaker 3:  you could have a Twitter experience that felt like lively

500
00:35:16,855 --> 00:35:20,495
Speaker 3:  and real time and interactive and exciting and you could also show up and

501
00:35:20,495 --> 00:35:24,095
Speaker 3:  see what the rock was talking about. Like we, none of these things that we

502
00:35:24,095 --> 00:35:26,615
Speaker 3:  have now do both of those things. None of them.

503
00:35:26,915 --> 00:35:29,335
Speaker 2:  All right. Lemme point a few things out just because I know The, Vergecast

504
00:35:29,405 --> 00:35:32,535
Speaker 2:  listeners are screaming in their cars right now weaving all over the road.

505
00:35:33,195 --> 00:35:37,095
Speaker 2:  One, any criticism of Elon's handling of Twitter is not

506
00:35:37,170 --> 00:35:40,565
Speaker 2:  praise for the previous administration. No. Who by and large did a bad job

507
00:35:40,615 --> 00:35:42,045
Speaker 3:  Clown car goldmine. Right.

508
00:35:42,045 --> 00:35:42,765
Speaker 2:  There's not

509
00:35:42,765 --> 00:35:43,085
Speaker 3:  Agree more.

510
00:35:43,345 --> 00:35:47,205
Speaker 2:  Two, they never made any money even though they had whatever

511
00:35:47,205 --> 00:35:50,805
Speaker 2:  success you're describing and three, the service at its peak was like

512
00:35:50,805 --> 00:35:52,805
Speaker 2:  300 some million users. Yeah.

513
00:35:52,805 --> 00:35:56,605
Speaker 3:  But it was the single most cable news was people reading tweets

514
00:35:56,635 --> 00:36:00,565
Speaker 3:  like yeah. It, it just was like there, there, there was a

515
00:36:01,265 --> 00:36:05,165
Speaker 3:  decade in our culture that was mediated by Twitter in a like very

516
00:36:05,355 --> 00:36:09,005
Speaker 3:  real way that If you wanted to share information with a lot of people

517
00:36:09,505 --> 00:36:13,125
Speaker 3:  no matter who you were a famous person, a government, a company,

518
00:36:13,345 --> 00:36:17,325
Speaker 3:  you went on Twitter, you just did. And that it's still true because

519
00:36:17,625 --> 00:36:20,685
Speaker 3:  the vestiges of that are still so powerful and

520
00:36:21,475 --> 00:36:25,325
Speaker 3:  nothing coming up now looks like it has a chance to replace

521
00:36:25,325 --> 00:36:25,485
Speaker 3:  that.

522
00:36:25,715 --> 00:36:29,165
Speaker 2:  Yeah. And I don't think it should. That's, I I'm just gonna keep coming back

523
00:36:29,165 --> 00:36:32,485
Speaker 2:  to that. I think it would be better if we all owned our own distribution

524
00:36:33,025 --> 00:36:36,125
Speaker 2:  or we built a distribution network that allowed people to come and go more

525
00:36:36,125 --> 00:36:40,045
Speaker 2:  freely. That's what the web is until Google

526
00:36:40,145 --> 00:36:43,525
Speaker 2:  search became this hegemon that sort of made the web look exactly how it's

527
00:36:43,525 --> 00:36:46,805
Speaker 2:  gonna look like. That's the web, that's RSSI think we're on the cusp of doing

528
00:36:46,805 --> 00:36:49,085
Speaker 2:  it. It's podcasts by and large that is,

529
00:36:49,815 --> 00:36:53,205
Speaker 3:  We've made it this far and I haven't brought up Google reader yet and So

530
00:36:53,245 --> 00:36:53,685
Speaker 3:  I won't.

531
00:36:53,865 --> 00:36:55,645
Speaker 2:  All right, we gotta, we gotta get off this now. It's,

532
00:36:55,945 --> 00:36:58,365
Speaker 3:  Can I just read you some user numbers before we go? Yeah. I went and pulled

533
00:36:58,365 --> 00:37:01,725
Speaker 3:  the user numbers for all of these platforms and I just found 'em fascinating

534
00:37:01,725 --> 00:37:05,405
Speaker 3:  and I just want to read them all out loud because it's, it's useful context

535
00:37:05,425 --> 00:37:09,085
Speaker 3:  for everything we've talked about. So Threads, as we mentioned,

536
00:37:09,945 --> 00:37:13,285
Speaker 3:  as of October 30th when meta reported earnings has

537
00:37:13,285 --> 00:37:17,125
Speaker 3:  275 million active users. What

538
00:37:17,125 --> 00:37:21,095
Speaker 3:  that means is always hard to know how companies measure these things

539
00:37:21,095 --> 00:37:24,295
Speaker 3:  as different across the board in all ways. But that's the number they reported

540
00:37:24,655 --> 00:37:27,615
Speaker 3:  and they're getting a million signups a day. Bluesky

541
00:37:28,425 --> 00:37:32,015
Speaker 3:  today, Wednesday as we're recording this passed 15 million total users

542
00:37:32,955 --> 00:37:36,175
Speaker 3:  and I yesterday on Tuesday the 12th had

543
00:37:36,175 --> 00:37:40,135
Speaker 3:  798,142 unique posters, which

544
00:37:40,135 --> 00:37:43,775
Speaker 3:  is people who actually posted a thing, which I love as a metric and I think

545
00:37:43,975 --> 00:37:47,895
Speaker 3:  everyone should do it and 990,464

546
00:37:47,995 --> 00:37:51,855
Speaker 3:  unique Lakers. So that's a decent like balance of

547
00:37:51,985 --> 00:37:55,815
Speaker 3:  who's here and who's doing stuff. Mastodon, this is the one that really

548
00:37:55,815 --> 00:37:57,975
Speaker 3:  surprised me and why I wanted to do this has

549
00:37:57,975 --> 00:38:01,895
Speaker 3:  9,034,753 total users as of

550
00:38:01,945 --> 00:38:02,295
Speaker 3:  today.

551
00:38:03,225 --> 00:38:06,735
Speaker 3:  886,711

552
00:38:06,735 --> 00:38:10,615
Speaker 3:  activities. It's brutal. Like Mastodon and, and you go look

553
00:38:10,615 --> 00:38:14,055
Speaker 3:  at this a a lot of this stuff comes from like open APIs that these things

554
00:38:14,055 --> 00:38:17,655
Speaker 3:  have, they just ping every day. You can see how they go. Mastodon had that

555
00:38:18,075 --> 00:38:21,975
Speaker 3:  big bump real momentum after the Twitter thing

556
00:38:22,175 --> 00:38:25,935
Speaker 3:  happened with Elon Musk and it was it, it had a moment and it just

557
00:38:25,935 --> 00:38:29,415
Speaker 3:  lost all of that momentum and it, it has settled back slightly higher than

558
00:38:29,415 --> 00:38:32,695
Speaker 3:  it was before. It went from like a half a million active users every day

559
00:38:32,695 --> 00:38:36,605
Speaker 3:  to 886,000 active users every day day. Which is not nothing but like

560
00:38:36,705 --> 00:38:40,325
Speaker 3:  that's also not momentum two years later like Mastodon just kind of lost

561
00:38:40,325 --> 00:38:43,365
Speaker 3:  it And I feel like right now we got a ton of people who are asking us like

562
00:38:43,385 --> 00:38:47,205
Speaker 3:  oh where should I go? And I feel like the only two

563
00:38:47,205 --> 00:38:50,565
Speaker 3:  answers I would even think about at this moment are Bluesky and Threads and

564
00:38:50,565 --> 00:38:54,485
Speaker 3:  I would tell you like go to Bluesky is more fun and threads is

565
00:38:54,485 --> 00:38:57,325
Speaker 3:  easier is I guess the place I'd land.

566
00:38:57,525 --> 00:39:00,205
Speaker 2:  I don't even know if it's easier. The Bluesky app is the number one app in

567
00:39:00,205 --> 00:39:03,725
Speaker 2:  the app store today mostly. 'cause speaking of cable news, Chris Hayes

568
00:39:03,875 --> 00:39:07,525
Speaker 2:  brought it up on MSN BBC last night and said I really like Bluesky and they

569
00:39:07,525 --> 00:39:10,725
Speaker 2:  had a bump. The Bluesky devs were pointing out that this made the line go

570
00:39:10,725 --> 00:39:14,085
Speaker 2:  up. So it's the number one app in the store today. People are leaving.

571
00:39:15,105 --> 00:39:17,765
Speaker 2:  The thing of Bluesky is that right now is it's self-contained. There isn't

572
00:39:17,765 --> 00:39:21,725
Speaker 2:  another app protocol server. The everything it's of

573
00:39:21,725 --> 00:39:24,805
Speaker 2:  Bluesky and I feel like the ma cell number is a little bit

574
00:39:25,395 --> 00:39:28,445
Speaker 2:  confusing because all those people on masks it on have the ability to see

575
00:39:28,445 --> 00:39:29,445
Speaker 2:  content from threats.

576
00:39:30,095 --> 00:39:30,925
Speaker 3:  Right. True.

577
00:39:31,485 --> 00:39:34,645
Speaker 2:  'cause that is the promise of federation. So it kind of doesn't matter if

578
00:39:34,645 --> 00:39:37,525
Speaker 2:  that number stagnates as long as the threads number goes up because you are

579
00:39:37,525 --> 00:39:41,245
Speaker 2:  still being able to follow Threads user depending on your mass on server.

580
00:39:41,265 --> 00:39:43,965
Speaker 2:  And this is the complexity, it's all weird, right? But if your mass on server

581
00:39:43,965 --> 00:39:47,805
Speaker 2:  inter operates with threads, as long as threads, numbers keep

582
00:39:47,805 --> 00:39:51,795
Speaker 2:  going up, you have the ability to follow and interact with all those people

583
00:39:51,895 --> 00:39:55,035
Speaker 2:  or you will over time. So there, there's some promise of

584
00:39:56,195 --> 00:39:59,505
Speaker 2:  federation here that I think, excuse these numbers, but the one thing that

585
00:39:59,525 --> 00:40:02,345
Speaker 2:  is clear is that a smaller number of

586
00:40:03,965 --> 00:40:07,185
Speaker 2:  bad people are interacting in higher rates on Twitter. Yes. X

587
00:40:08,255 --> 00:40:11,745
Speaker 2:  It's weird, it's a weird time but I, I think the shakeup is going to be good.

588
00:40:11,865 --> 00:40:15,545
Speaker 2:  I think it is time to think about distribution on the internet in way different

589
00:40:15,545 --> 00:40:18,265
Speaker 2:  ways, particularly as the creator platforms

590
00:40:19,295 --> 00:40:23,065
Speaker 2:  just shove creators and influencers around and like start

591
00:40:23,065 --> 00:40:26,025
Speaker 2:  adding. I opened my Instagram yesterday and it was like, do you wanna make

592
00:40:26,025 --> 00:40:27,865
Speaker 2:  an AI of yourself to talk to your fans

593
00:44:39,905 --> 00:44:42,845
Speaker 2:  All right, we're back. Kylie Robinson's here. Hi Kylie. Hello. Welcome to

594
00:44:42,845 --> 00:44:46,285
Speaker 2:  the V House. Thanks. Have we been on the show together yet? No, I don't think

595
00:44:46,345 --> 00:44:49,945
Speaker 2:  so. Well spooky. There was a reason.

596
00:44:50,625 --> 00:44:52,785
Speaker 2:  I dunno, that's so rude.

597
00:44:54,245 --> 00:44:57,785
Speaker 2:  You're here. We're gonna do a new segment. We're calling show and tell.

598
00:44:58,285 --> 00:44:59,825
Speaker 2:  Are we actually calling it Show and tell David?

599
00:45:00,075 --> 00:45:03,745
Speaker 3:  We're calling it that until someone calls their emails with a better name.

600
00:45:04,435 --> 00:45:07,785
Speaker 3:  We've had very good luck in the past letting smarter people than us name

601
00:45:07,785 --> 00:45:11,585
Speaker 3:  things for us. So please, If, you have a better idea. Call the hotline, send

602
00:45:11,585 --> 00:45:13,825
Speaker 3:  us an email. Name this segment for us.

603
00:45:14,335 --> 00:45:17,295
Speaker 2:  Okay, so here's what we're gonna do during the

604
00:45:17,805 --> 00:45:19,775
Speaker 2:  presumptively named show and tell.

605
00:45:21,445 --> 00:45:24,745
Speaker 2:  All of us are gonna bring one story to the table. We're gonna say what it

606
00:45:24,745 --> 00:45:27,905
Speaker 2:  is and then we're gonna talk about, but it has to be good.

607
00:45:28,645 --> 00:45:32,325
Speaker 2:  Oh God. So we're putting David on the spot first. Okay. David, what's your

608
00:45:32,325 --> 00:45:32,765
Speaker 2:  story this week?

609
00:45:33,325 --> 00:45:36,525
Speaker 3:  I feel like we have to talk about the Square iPad.

610
00:45:37,505 --> 00:45:41,405
Speaker 3:  You mentioned it briefly at the top, but we, we this, this is

611
00:45:41,405 --> 00:45:44,765
Speaker 3:  the only thing I can think about. So we have to talk about this now. So we've

612
00:45:44,765 --> 00:45:48,725
Speaker 3:  been hearing rumors and reporting for a long time that Apple was

613
00:45:48,725 --> 00:45:52,245
Speaker 3:  really interested in getting into the smart home. Mark Erman at Bloomberg,

614
00:45:52,425 --> 00:45:56,215
Speaker 3:  who is better at reporting what Apple is going to do

615
00:45:56,215 --> 00:46:00,175
Speaker 3:  than everybody. Had a big story this week about what

616
00:46:00,175 --> 00:46:04,095
Speaker 3:  this thing is going to be. Apple is is essentially building a smart

617
00:46:04,095 --> 00:46:07,535
Speaker 3:  home controller that is going to live inside of your house.

618
00:46:07,875 --> 00:46:11,295
Speaker 3:  Can I just read you several sentences from this article? And I would like

619
00:46:11,295 --> 00:46:14,055
Speaker 3:  you to tell me what device it sounds like I am describing

620
00:46:15,465 --> 00:46:18,165
Speaker 2:  For a segment called Show and Tell. I feel like this is a little backwards

621
00:46:18,385 --> 00:46:20,925
Speaker 2:  and that you're reading and then I'm describing what I think you've shown

622
00:46:20,925 --> 00:46:22,125
Speaker 2:  me. But let's go ahead. Yeah,

623
00:46:22,155 --> 00:46:25,765
Speaker 3:  It's it's a, it's a telling show. It's fine, don't worry about it.

624
00:46:26,055 --> 00:46:30,045
Speaker 3:  Other people are gonna name this for us. So Mark Iman says it's about the

625
00:46:30,045 --> 00:46:33,165
Speaker 3:  size of two iPhones, side by side with a thick edge around the display. There's

626
00:46:33,165 --> 00:46:36,125
Speaker 3:  also a camera at the top front, a rechargeable built-in battery and internal

627
00:46:36,125 --> 00:46:39,605
Speaker 3:  speakers. Apple plans to offer it in silver and black options. If you're

628
00:46:39,605 --> 00:46:42,165
Speaker 3:  already thinking, gosh, I know what David is describing, I have more for

629
00:46:42,165 --> 00:46:46,085
Speaker 3:  you. The product has a touch interface. The company

630
00:46:46,085 --> 00:46:48,725
Speaker 3:  expects most people to use their voice to interact the device relying on

631
00:46:48,725 --> 00:46:52,565
Speaker 3:  the Siri digital assistant and Apple Intelligence. It. The product

632
00:46:52,565 --> 00:46:55,365
Speaker 3:  will be marketed as a way to control home appliances, chat with Siri and

633
00:46:55,365 --> 00:46:58,405
Speaker 3:  hold intercom sessions with FaceTime. It will also be loaded with Apple apps,

634
00:46:58,405 --> 00:47:01,245
Speaker 3:  including ones for web browsing, listening to news updates and playing music.

635
00:47:01,495 --> 00:47:04,485
Speaker 3:  Users will be able to access their notes and calendar information and the

636
00:47:04,485 --> 00:47:08,125
Speaker 3:  device can turn into a slideshow display for their photos. Do you know what

637
00:47:08,125 --> 00:47:09,045
Speaker 3:  device I'm describing?

638
00:47:09,825 --> 00:47:11,485
Speaker 2:  Is it a $329 iPad?

639
00:47:11,595 --> 00:47:15,565
Speaker 3:  It's an iPad. Apple is going to make an iPad and they're going to

640
00:47:15,565 --> 00:47:19,205
Speaker 3:  sell it to you to use in your house. Let me, let me read you the thing that

641
00:47:19,205 --> 00:47:23,045
Speaker 3:  is actually new and is actually interesting. If, you just imagine an

642
00:47:23,195 --> 00:47:27,085
Speaker 3:  iPad. Mark Kerman writes this in his story. He says, apple has designed different

643
00:47:27,085 --> 00:47:30,000
Speaker 3:  attachments for the device, including ones that affix the screens onto walls

644
00:47:30,000 --> 00:47:33,245
Speaker 3:  like a classic home security panel. There will be bases with additional speakers

645
00:47:33,245 --> 00:47:36,685
Speaker 3:  that can be placed in the kitchen on a nightstand or on a desk. Apple imagines

646
00:47:36,685 --> 00:47:39,525
Speaker 3:  the FaceTime feature being used while cooking or for video conferencing during

647
00:47:39,525 --> 00:47:43,495
Speaker 3:  work meetings. A still just an iPad. It's

648
00:47:43,495 --> 00:47:46,175
Speaker 3:  it, honestly, it sounds very much like the thing Apple is going to make is

649
00:47:46,175 --> 00:47:50,135
Speaker 3:  a bad iPad that it wants to sell you lots of for your

650
00:47:50,135 --> 00:47:53,855
Speaker 3:  house. B, an accessory ecosystem

651
00:47:54,435 --> 00:47:58,415
Speaker 3:  of cool new things that you can add to your iPad just by docking it

652
00:47:58,415 --> 00:48:01,695
Speaker 3:  on these different docs around your house is a kick ass idea that Apple should

653
00:48:01,695 --> 00:48:05,655
Speaker 3:  totally do. Just not with a stupid six inch bad

654
00:48:05,965 --> 00:48:08,455
Speaker 3:  iPad. I'm like losing my mind about this thing.

655
00:48:08,735 --> 00:48:11,895
Speaker 2:  I just wanna say out loud, I've said this many times before, apple is horrible

656
00:48:12,165 --> 00:48:16,155
Speaker 2:  accessory ecosystems actually. It's just a thing. It's just reality.

657
00:48:17,135 --> 00:48:20,195
Speaker 2:  How many smart keyboard covers are there for the iPad today?

658
00:48:20,775 --> 00:48:21,915
Speaker 3:  Oh, agree.

659
00:48:22,225 --> 00:48:22,515
Speaker 2:  Zero.

660
00:48:23,235 --> 00:48:27,035
Speaker 3:  Belkin has become like the official Apple accessory maker because Apple

661
00:48:27,035 --> 00:48:29,475
Speaker 3:  either can't or won't do it itself. Well,

662
00:48:29,475 --> 00:48:32,315
Speaker 2:  Balcony is owned by Foxcon. So you get the idea that every now and again

663
00:48:32,335 --> 00:48:35,075
Speaker 2:  an Apple designer goes in the Foxcon factory and it's like, I have a number

664
00:48:35,075 --> 00:48:35,475
Speaker 2:  of ideas.

665
00:48:38,345 --> 00:48:41,995
Speaker 2:  There's, there's something real there I find, but

666
00:48:43,165 --> 00:48:46,475
Speaker 2:  great and a third party ecosystem of like weird docs and adapters. Everybody

667
00:48:46,475 --> 00:48:48,515
Speaker 2:  wants this to exist for every Apple product and I just don't,

668
00:48:49,865 --> 00:48:53,115
Speaker 3:  Sure, but like I just, I have, I just have to keep reading. The newly designed

669
00:48:53,115 --> 00:48:55,475
Speaker 3:  operating system will also include a customizable home screen.

670
00:48:55,475 --> 00:48:56,195
Speaker 2:  Stop telling me about iPads

671
00:48:56,195 --> 00:48:59,195
Speaker 3:  Where users can run widgets for checking stock, tickers the weather and appointments.

672
00:48:59,195 --> 00:49:02,795
Speaker 3:  That's an iPad. Or they can configure the screen to highlight key home controls

673
00:49:02,865 --> 00:49:05,355
Speaker 3:  iPad. There will also be a doc, hold on for quick, fully launching favorite

674
00:49:05,355 --> 00:49:08,875
Speaker 3:  apps and an screen grid of software icons. It's an iPad.

675
00:49:09,355 --> 00:49:10,795
Speaker 2:  I look in all fairness, they

676
00:49:10,795 --> 00:49:11,515
Speaker 3:  Did iPad again.

677
00:49:11,665 --> 00:49:15,475
Speaker 2:  Mark Bloomberg is a very traditional news organization and Kerman has to

678
00:49:15,475 --> 00:49:15,995
Speaker 2:  hit a word count.

679
00:49:17,425 --> 00:49:20,755
Speaker 3:  Also, none of this, this is all very good reporting from Kerman. The fact

680
00:49:20,755 --> 00:49:23,555
Speaker 3:  that this is all, that's what I'm saying, this is very good reporting. It's

681
00:49:23,555 --> 00:49:27,395
Speaker 3:  just Apple is just going to make an

682
00:49:27,505 --> 00:49:30,355
Speaker 3:  iPad again and they're gonna try to sell it to you as a new thing because

683
00:49:30,355 --> 00:49:34,285
Speaker 3:  it can dock on a speaker. Yeah, that's nothing. Make the

684
00:49:34,355 --> 00:49:34,645
Speaker 3:  iPad

685
00:49:34,645 --> 00:49:36,485
Speaker 2:  Better or they're, they're gonna, they're gonna cut down the, the interface

686
00:49:36,485 --> 00:49:40,445
Speaker 2:  right. To make it more smart, homey, you're gonna let people talk to, you

687
00:49:40,445 --> 00:49:44,405
Speaker 2:  know, the presumably smarter Siri. That's a thing that could happen

688
00:49:44,545 --> 00:49:47,405
Speaker 3:  During development. Apple discussed launching an app store as part of the

689
00:49:47,405 --> 00:49:49,965
Speaker 3:  device, but it recently decided to exclude this feature. At least in the

690
00:49:49,965 --> 00:49:53,565
Speaker 3:  initial version. It's an iPad without the app store. So it's

691
00:49:53,565 --> 00:49:57,485
Speaker 2:  Just worse. I'm just gonna point out that a couple weeks ago we had Joanna

692
00:49:57,485 --> 00:50:01,085
Speaker 2:  Stern on the show and we talked about garage door openers for five hours.

693
00:50:01,915 --> 00:50:05,455
Speaker 2:  And Apple's dreams of making a smart home product are gonna run head first

694
00:50:06,045 --> 00:50:09,415
Speaker 2:  into the reality of smart home products. Yes. That's what's gonna happen.

695
00:50:09,465 --> 00:50:11,895
Speaker 2:  Which is they're, it's impossible.

696
00:50:13,215 --> 00:50:15,175
Speaker 2:  Fascinating. That's the whole answer. That

697
00:50:15,175 --> 00:50:16,055
Speaker 3:  Really is the whole answer.

698
00:50:16,245 --> 00:50:20,095
Speaker 2:  Very smart People get tripped up at whether the smart part of the

699
00:50:20,095 --> 00:50:24,025
Speaker 2:  light bulb should be in the light bulb or the switch. And there are, there

700
00:50:24,045 --> 00:50:27,925
Speaker 2:  are religious arguments for both. There are good reasons

701
00:50:27,985 --> 00:50:31,525
Speaker 2:  to do In my own home, I have both. Yeah. I have smart light bulbs and I have

702
00:50:31,525 --> 00:50:35,285
Speaker 2:  smart switches and no one, no one in my family that literally

703
00:50:35,425 --> 00:50:39,405
Speaker 2:  I'm trying to illuminate knows why or how any of it works. Yeah. And

704
00:50:39,405 --> 00:50:41,445
Speaker 2:  so you put the thing on the wall and you're like, now your house is smart.

705
00:50:41,785 --> 00:50:45,365
Speaker 2:  You end up having to tell a bunch of consumers

706
00:50:46,295 --> 00:50:49,885
Speaker 2:  where a bunch of other computers in their houses have to go. Yeah. And that

707
00:50:49,885 --> 00:50:51,845
Speaker 2:  just falls, it just falls flat immediately.

708
00:50:52,105 --> 00:50:55,245
Speaker 6:  So would you guys not do this though? This is not something, 'cause I all,

709
00:50:55,265 --> 00:50:58,925
Speaker 6:  I'm thinking as you say this is, don't hate the player, hate the game.

710
00:50:58,925 --> 00:51:02,165
Speaker 6:  There's gonna be a dozen people in this office who buy this. It feels like

711
00:51:02,315 --> 00:51:03,845
Speaker 6:  it's, it's just gonna happen.

712
00:51:04,315 --> 00:51:07,805
Speaker 3:  Sure. But if you're Apple, you have this

713
00:51:08,425 --> 00:51:11,685
Speaker 3:  tablet lineup that is very mature and

714
00:51:12,235 --> 00:51:15,965
Speaker 3:  full of identity crises and what if instead you

715
00:51:15,965 --> 00:51:19,765
Speaker 3:  just took the thing and said, now here's a doc that

716
00:51:19,975 --> 00:51:23,945
Speaker 3:  makes it have an always on screen and thus you

717
00:51:23,945 --> 00:51:26,985
Speaker 3:  can control all the things you can still control from your iPad. Like it's

718
00:51:26,985 --> 00:51:30,825
Speaker 3:  just, it's such a tiny leap from an iPad

719
00:51:31,085 --> 00:51:34,305
Speaker 3:  to this. I think the reason you don't do it if your Apple is because you

720
00:51:34,305 --> 00:51:37,985
Speaker 3:  can sell a bad iPad a lot cheaper than you can sell a good iPad. Yeah. And

721
00:51:37,985 --> 00:51:41,785
Speaker 3:  so they're gonna make a bad iPad and stick it to your wall. Fine.

722
00:51:42,015 --> 00:51:45,745
Speaker 3:  That, that, there's also, Gerin has been reporting that the next version

723
00:51:45,745 --> 00:51:49,545
Speaker 3:  of it is gonna have a robotic arm and cost a thousand dollars. Like sure

724
00:51:50,125 --> 00:51:53,745
Speaker 3:  that's all fine and good, but I think there is, there is a really interesting

725
00:51:53,745 --> 00:51:56,945
Speaker 3:  case to be made that you could turn an iPad, which is already, for most people,

726
00:51:57,775 --> 00:52:01,625
Speaker 3:  kind of statistically speaking like a home bound device. It is a thing

727
00:52:01,625 --> 00:52:04,425
Speaker 3:  that lives on your bedside table or on your couch or on your coffee table.

728
00:52:04,455 --> 00:52:08,265
Speaker 3:  Like it's not as portable a thing as it, it

729
00:52:08,265 --> 00:52:12,105
Speaker 3:  maybe is presumed to be in a lot of ways you could

730
00:52:12,135 --> 00:52:15,825
Speaker 3:  just turn that up a little bit and turn it into something really

731
00:52:16,015 --> 00:52:19,785
Speaker 3:  cool and powerful with this accessory ecosystem. But

732
00:52:19,785 --> 00:52:23,585
Speaker 3:  instead Apple is going to reinvent the entire wheel in a way that just

733
00:52:23,585 --> 00:52:24,705
Speaker 3:  feels ridiculous to me.

734
00:52:25,445 --> 00:52:27,745
Speaker 2:  I'm excited for you to buy an iPad that you stick to your wall, David. Yep.

735
00:52:28,385 --> 00:52:31,265
Speaker 2:  I think you're gonna love it. You're gonna love talking to Siri and be like,

736
00:52:31,265 --> 00:52:34,065
Speaker 2:  Siri, do this automation and then Siri's not gonna work. And you're gonna

737
00:52:34,065 --> 00:52:36,425
Speaker 2:  be like, what is the answer? Then you're gonna Google it and the answer for

738
00:52:36,425 --> 00:52:40,065
Speaker 2:  some reason is gonna be restarting your iPhone, which is

739
00:52:40,165 --> 00:52:41,825
Speaker 2:  100% the Apple Home story.

740
00:52:42,345 --> 00:52:46,105
Speaker 3:  A big part of this feels like what you do when you

741
00:52:46,105 --> 00:52:50,065
Speaker 3:  build all of this other AI stuff like the app

742
00:52:50,065 --> 00:52:53,705
Speaker 3:  intent stuff that Apple is working on with Siri, this new Siri, all the Apple

743
00:52:53,705 --> 00:52:57,225
Speaker 3:  intelligence stuff, and you go, Hmm, what does any of this actually useful

744
00:52:57,245 --> 00:53:01,145
Speaker 3:  for? This is the same thing by the way that Google did with Google Assistant

745
00:53:01,145 --> 00:53:04,905
Speaker 3:  and Amazon did with Alexa. And you realize, oh, it's just you can turn off

746
00:53:05,405 --> 00:53:09,065
Speaker 3:  two sets of lights at once instead of one set of lights. And that that

747
00:53:09,155 --> 00:53:12,705
Speaker 3:  Apple is, is running directly towards that and nowhere else.

748
00:53:13,505 --> 00:53:17,305
Speaker 2:  I, I do wanna call it the number of listeners who responded

749
00:53:17,325 --> 00:53:21,105
Speaker 2:  to our Jovanna conversation on garage door openers in which she said cred,

750
00:53:21,485 --> 00:53:24,545
Speaker 2:  FEI uses Siri to open his garage door by pointing out that there is

751
00:53:24,775 --> 00:53:28,485
Speaker 2:  0% chance that Craig Federighi has an Apple home

752
00:53:28,555 --> 00:53:32,405
Speaker 2:  home and instead definitely has a custom Crestron home

753
00:53:32,405 --> 00:53:36,045
Speaker 2:  automation system. Yeah. Oh agreed. The emails we got, they were like,

754
00:53:36,305 --> 00:53:40,085
Speaker 2:  you all understand that there's a custom that this man has a Crestron

755
00:53:40,085 --> 00:53:43,875
Speaker 2:  system. Anyhow, all right. You've shown,

756
00:53:43,875 --> 00:53:47,105
Speaker 2:  you've told, do I do I give you a score

757
00:53:49,155 --> 00:53:49,505
Speaker 2:  seven

758
00:53:51,675 --> 00:53:52,025
Speaker 2:  Kylie,

759
00:53:52,285 --> 00:53:53,425
Speaker 6:  I'm going for 7.7. I'm

760
00:53:53,425 --> 00:53:57,225
Speaker 2:  Leaving now. Some meanest thing you've ever said to me. Jesus. It's a new

761
00:53:57,225 --> 00:53:58,665
Speaker 2:  segment. We're figuring out how it works.

762
00:54:00,385 --> 00:54:01,405
Speaker 2:  All right, Kylie, what do you have?

763
00:54:02,465 --> 00:54:05,125
Speaker 6:  Oh my God. It's gonna be hard to top a bad

764
00:54:05,405 --> 00:54:05,965
Speaker 2:  A seven iPad.

765
00:54:06,465 --> 00:54:09,765
Speaker 6:  No bad iPad. Well now I'm talking about

766
00:54:10,195 --> 00:54:12,765
Speaker 6:  scaling laws, which are really interesting.

767
00:54:14,005 --> 00:54:17,485
Speaker 6:  Everyone's reporting this week that scaling laws are failing.

768
00:54:18,585 --> 00:54:22,445
Speaker 6:  So what that is is just put more compute and

769
00:54:22,445 --> 00:54:26,365
Speaker 6:  more data into an LLM and it will get bigger, better,

770
00:54:26,365 --> 00:54:30,085
Speaker 6:  smarter. And everyone has the same training

771
00:54:30,085 --> 00:54:33,525
Speaker 6:  data, which is the internet, the entire internet and all of our work.

772
00:54:35,345 --> 00:54:38,565
Speaker 6:  So they have all that, they're all building sort of the same thing and they

773
00:54:38,565 --> 00:54:42,365
Speaker 6:  are all finding Google open AI anthropic that it is not

774
00:54:42,365 --> 00:54:46,245
Speaker 6:  working anymore. That they are not getting better than their last generation

775
00:54:46,245 --> 00:54:50,045
Speaker 6:  of models and they're all pissing their pants about it. That's the story

776
00:54:50,045 --> 00:54:53,885
Speaker 6:  this week. Yeah. I think this is, I keep thinking about

777
00:54:53,885 --> 00:54:57,325
Speaker 6:  that tweet, which is like, you know, the haters said I couldn't do it and

778
00:54:57,555 --> 00:55:01,445
Speaker 6:  they were right. Great call from the haters. I think all of the,

779
00:55:03,805 --> 00:55:07,605
Speaker 6:  I think all, all of the AI skeptics are like, yeah, we told you

780
00:55:07,635 --> 00:55:10,765
Speaker 6:  Yeah, we told you that this wasn't something you could scale infinitely.

781
00:55:11,825 --> 00:55:15,765
Speaker 6:  So yeah, I don't think it's like doomsday, like it's over for ai, but still

782
00:55:15,765 --> 00:55:18,805
Speaker 6:  it's, it's interesting that they're all sort of frustrated that they can't

783
00:55:18,805 --> 00:55:22,765
Speaker 6:  make that giant neck leap and it costs so much money. So

784
00:55:23,345 --> 00:55:26,365
Speaker 6:  if people, if they wanna release something that costs so much money for people

785
00:55:26,365 --> 00:55:28,805
Speaker 6:  to use, it's gotta be way better and it's just not.

786
00:55:28,985 --> 00:55:32,725
Speaker 2:  So the idea here is, okay, we made, I know GPT-4 Yeah. But training on the

787
00:55:32,725 --> 00:55:36,045
Speaker 2:  entire internet, we'll get more data, which was always confusing to people

788
00:55:36,045 --> 00:55:37,565
Speaker 2:  where the more data would come from Yes.

789
00:55:38,245 --> 00:55:38,965
Speaker 6:  Synthetic data. So

790
00:55:38,965 --> 00:55:42,525
Speaker 2:  So we'll make some fake AI data. Yes. We'll train an even bigger model and

791
00:55:42,525 --> 00:55:46,005
Speaker 2:  that one will necessarily be smarter. Yes. And that just hasn't worked out

792
00:55:46,145 --> 00:55:49,605
Speaker 6:  And it hasn't worked out. It does not appear that any of them are going to

793
00:55:49,605 --> 00:55:53,325
Speaker 6:  be more capable than the last. So that means, you know, for

794
00:55:53,605 --> 00:55:57,325
Speaker 6:  instance, I believe it was reported that oh one was helping train

795
00:55:58,425 --> 00:56:01,645
Speaker 6:  the next generation of open AI's GBT models.

796
00:56:02,425 --> 00:56:06,365
Speaker 6:  But that has become a problem because then, you know, it just gets

797
00:56:07,245 --> 00:56:10,845
Speaker 6:  confused by synthetic data. It's not high quality data. So yeah,

798
00:56:10,915 --> 00:56:14,125
Speaker 6:  they're all running into that same issue and

799
00:56:14,965 --> 00:56:18,255
Speaker 6:  that means that there's gonna be ha there's gonna have to be some like research

800
00:56:18,255 --> 00:56:21,575
Speaker 6:  breakthrough that gets them to that next step that they don't currently have.

801
00:56:21,915 --> 00:56:25,765
Speaker 6:  And there's just tons of money riding on this for them to figure it out.

802
00:56:25,785 --> 00:56:28,165
Speaker 6:  So, I, think they're all again pissing their pants over it

803
00:56:28,865 --> 00:56:31,125
Speaker 2:  As one of the haters. I definitely feel like I should say I told you

804
00:56:31,125 --> 00:56:34,805
Speaker 3:  So this so exposes to be something Kylie that you've been saying to us

805
00:56:34,985 --> 00:56:38,645
Speaker 3:  and on The Vergecast for forever, which is there has been this

806
00:56:38,995 --> 00:56:42,765
Speaker 3:  ongoing line from all of these AI companies that it's like, we're gonna do

807
00:56:42,765 --> 00:56:45,325
Speaker 3:  a model and then we're gonna do another model and we're gonna do another

808
00:56:45,325 --> 00:56:48,485
Speaker 3:  model and we're gonna do another model and then it's God. And it's like,

809
00:56:48,485 --> 00:56:51,485
Speaker 3:  well what, what's, what is it gonna be on the way? And they're like, don't

810
00:56:51,485 --> 00:56:55,285
Speaker 3:  worry about it. God, none of this shit matters. 'cause God,

811
00:56:55,535 --> 00:56:58,525
Speaker 3:  we're gonna make God and then you're gonna feel dumb for not giving us money.

812
00:56:59,065 --> 00:57:03,005
Speaker 3:  And what happens now is they're gonna get to the point where

813
00:57:03,005 --> 00:57:05,445
Speaker 3:  they're like, okay, you've built this thing. It's actually very cool, it's

814
00:57:05,445 --> 00:57:08,765
Speaker 3:  very capable, it can do lots of things. What's it for? What are people gonna

815
00:57:08,765 --> 00:57:12,265
Speaker 3:  do with it? And all of these companies are like emails.

816
00:57:13,355 --> 00:57:17,305
Speaker 3:  We're gonna write some bomb emails. Yes. And, and we're like, I

817
00:57:17,325 --> 00:57:21,225
Speaker 3:  we are going to be stuck in this. What can you do with

818
00:57:21,225 --> 00:57:24,505
Speaker 3:  this phase for a lot longer than any of these companies

819
00:57:24,875 --> 00:57:25,825
Speaker 3:  would like you to believe?

820
00:57:25,855 --> 00:57:28,745
Speaker 2:  Well there's that, but there's just also this week, right.

821
00:57:29,995 --> 00:57:33,935
Speaker 2:  Dio Modi from Anthropic is telling Lex Friedman that we'll have a GI

822
00:57:33,935 --> 00:57:37,055
Speaker 2:  in like two years. Yes. Sam Altman, I think in the past couple weeks has

823
00:57:37,055 --> 00:57:40,855
Speaker 2:  said on current hardware we can have a GI, which by the way means

824
00:57:40,875 --> 00:57:44,495
Speaker 2:  the tech industry should stop like If. you can make

825
00:57:44,645 --> 00:57:48,415
Speaker 2:  current If, you can make God on NVIDIA's current hardware. We should,

826
00:57:48,515 --> 00:57:49,495
Speaker 2:  we should stop. Yeah.

827
00:57:49,725 --> 00:57:51,735
Speaker 3:  Yeah. We did it. We're we're good. We did it, we're done.

828
00:57:51,915 --> 00:57:55,655
Speaker 2:  Let God build the next version of the GPU. Like it'll be here

829
00:57:55,685 --> 00:57:56,735
Speaker 2:  soon. Totally.

830
00:57:57,155 --> 00:57:58,855
Speaker 3:  The God processing unit, that's

831
00:57:58,855 --> 00:57:59,015
Speaker 2:  The

832
00:58:00,845 --> 00:58:04,215
Speaker 2:  what If, you're like, if I just put enough H one hundreds in a room, I can

833
00:58:04,215 --> 00:58:07,895
Speaker 2:  have God to like, we should, Nvidia should just slow the fuck down.

834
00:58:08,125 --> 00:58:11,935
Speaker 2:  Sure. Right. And it that there's something very incompatible with

835
00:58:12,715 --> 00:58:16,615
Speaker 2:  in two years we'll have a GII can build a GI and current hardware and

836
00:58:17,235 --> 00:58:20,335
Speaker 2:  the bigger models we just trained aren't more capable than the previous models.

837
00:58:20,795 --> 00:58:23,835
Speaker 2:  Yes. Is that what, what's going on?

838
00:58:25,025 --> 00:58:28,995
Speaker 6:  I've been asked on Vergecast, or sorry, I think it was decoder. Should we

839
00:58:28,995 --> 00:58:32,915
Speaker 6:  trust them? And I'm, I, I mean I as a journalist am just

840
00:58:32,915 --> 00:58:36,795
Speaker 6:  very skeptical. So Dario's saying, you know, we're gonna

841
00:58:36,795 --> 00:58:40,675
Speaker 6:  get, AGI i's gonna do all these beautiful things. And I mean they just have

842
00:58:40,675 --> 00:58:44,475
Speaker 6:  to sell products at the end of the day. The Reddit a a

843
00:58:44,595 --> 00:58:48,395
Speaker 6:  MA that Sam Altman did recently where he said, oh, it's really hard to release

844
00:58:48,395 --> 00:58:51,555
Speaker 6:  these things in parallel. We have like such limited compute and it's hard

845
00:58:51,555 --> 00:58:54,955
Speaker 6:  to work on all of these things. But the next big thing I think is gonna be

846
00:58:54,975 --> 00:58:58,955
Speaker 6:  agents. It's just feels like they're pivoting. They're like, don't, don't

847
00:58:58,955 --> 00:59:01,555
Speaker 6:  look at this. Don't look, don't look at this right here. We haven't figured

848
00:59:01,575 --> 00:59:05,195
Speaker 6:  it out. Just don't think about agents on current hardware, current models.

849
00:59:05,745 --> 00:59:09,635
Speaker 6:  Look at that. Please give us money. Don't look at how we are failing to

850
00:59:09,635 --> 00:59:12,875
Speaker 6:  make the next big model. And I don't think we

851
00:59:13,465 --> 00:59:17,315
Speaker 6:  need a next bigger model. I think we really enjoyed these companies, really

852
00:59:17,315 --> 00:59:21,285
Speaker 6:  enjoyed making these huge leaps from model to model. And

853
00:59:21,345 --> 00:59:25,245
Speaker 6:  if they're capable enough now of achieving some good emails,

854
00:59:25,635 --> 00:59:29,565
Speaker 6:  then fine. They think that they can combine,

855
00:59:30,145 --> 00:59:34,005
Speaker 6:  you know, the GBT series with the o reasoning series and perhaps get a

856
00:59:34,045 --> 00:59:37,925
Speaker 6:  GI again, I think all of this is to sell more products and get

857
00:59:37,925 --> 00:59:41,765
Speaker 6:  more money. That is always been my position. So yeah,

858
00:59:41,885 --> 00:59:42,085
Speaker 6:  I mean,

859
00:59:42,365 --> 00:59:45,725
Speaker 2:  I just wanna read you the quote from Daria, please. If, you believe the straight

860
00:59:45,875 --> 00:59:49,605
Speaker 2:  line extrapolation. We'll have artificial general intelligence in

861
00:59:49,605 --> 00:59:51,245
Speaker 2:  2026 or 2027.

862
00:59:52,685 --> 00:59:53,035
Speaker 6:  Right?

863
00:59:53,295 --> 00:59:56,955
Speaker 2:  If line go up forever, I will make God,

864
00:59:57,065 --> 00:59:59,515
Speaker 3:  Have you guys seen the tweet from the guy? I'm sorry, I don't remember who

865
00:59:59,515 --> 01:00:02,235
Speaker 3:  it is. We'll we'll find it and put it in the show notes. Who was like, he

866
01:00:02,235 --> 01:00:05,195
Speaker 3:  has two pictures of him with his newborn baby and then his baby who's now

867
01:00:05,195 --> 01:00:08,755
Speaker 3:  three months old. Yes. And he's like, wild guys, my baby has doubled in weight

868
01:00:08,935 --> 01:00:12,635
Speaker 3:  in three months at this rate by his 10th birthday he'll be

869
01:00:12,635 --> 01:00:16,595
Speaker 3:  7 trillion pounds. I think about that every single time somebody talks

870
01:00:16,595 --> 01:00:19,315
Speaker 3:  about one of these things, like it's, it's really, and people talk about

871
01:00:19,315 --> 01:00:23,155
Speaker 3:  this stuff as if it is guaranteed. Like you look at Moore's law, right? And

872
01:00:23,155 --> 01:00:26,555
Speaker 3:  this, this thing that has like governed technolo technological progress for

873
01:00:26,555 --> 01:00:30,315
Speaker 3:  so long, we now take it as truth that everything that grows

874
01:00:30,365 --> 01:00:34,315
Speaker 3:  grows the same way and forever and it just doesn't like, yeah. There

875
01:00:34,315 --> 01:00:38,035
Speaker 3:  is no guarantee that any of this will work like that just because the way

876
01:00:38,035 --> 01:00:41,715
Speaker 3:  we make semiconductors works like that. It's just not how it works.

877
01:00:42,895 --> 01:00:46,745
Speaker 6:  Okay. To add to this too, you know how Sam Altman was going across the world

878
01:00:46,765 --> 01:00:49,905
Speaker 6:  trying to get these trillion dollar data centers built somewhere. Someone

879
01:00:49,905 --> 01:00:53,705
Speaker 6:  give me the money to build these data centers. So, I can power Digital, digital.

880
01:00:53,885 --> 01:00:57,545
Speaker 6:  God, there was a story in the information today that

881
01:00:57,905 --> 01:01:01,505
Speaker 6:  a competitor flew like a crop plane over X's

882
01:01:02,175 --> 01:01:06,105
Speaker 6:  data center to figure out how he was cooling those chips because they're

883
01:01:06,105 --> 01:01:09,425
Speaker 6:  so scared about liquid cooling and it's so confusing. And I thought that's

884
01:01:09,425 --> 01:01:12,825
Speaker 6:  crazy that we're getting to a point where people are just flying, you know,

885
01:01:13,445 --> 01:01:17,265
Speaker 6:  little planes over Elon's data center to figure out how

886
01:01:17,565 --> 01:01:21,545
Speaker 6:  the fuck they can build digital God in the same way. It's just such a funny

887
01:01:21,545 --> 01:01:21,785
Speaker 6:  thing.

888
01:01:22,085 --> 01:01:25,665
Speaker 3:  The next Mission Impossible movie is just Tom Cruise breaking into a data

889
01:01:25,665 --> 01:01:27,705
Speaker 3:  center to figure out how they power all this stuff.

890
01:01:28,185 --> 01:01:29,545
Speaker 2:  I think that was the last mission impossible

891
01:01:32,095 --> 01:01:33,045
Speaker 6:  David. What what,

892
01:01:33,355 --> 01:01:37,205
Speaker 2:  What Underwater. Exactly. But it was that, oh

893
01:01:37,205 --> 01:01:39,405
Speaker 2:  my God, they did that. All that's a

894
01:01:39,405 --> 01:01:40,205
Speaker 6:  Furious in space man.

895
01:01:41,665 --> 01:01:44,765
Speaker 2:  By the way, If, you look on, on all the streaming services, they've taken

896
01:01:44,995 --> 01:01:48,405
Speaker 2:  part one off of that movie because it ends on such a garbage

897
01:01:48,435 --> 01:01:49,925
Speaker 2:  cliffhanger. People are mad.

898
01:01:50,355 --> 01:01:52,445
Speaker 3:  Yeah. They're like, nevermind, we're just doing a different one now.

899
01:01:52,445 --> 01:01:53,485
Speaker 2:  This is a full movie.

900
01:01:56,605 --> 01:01:59,925
Speaker 2:  I don't know man. All right, Kyle, you've shown, you've told Yes David, you,

901
01:01:59,965 --> 01:02:01,925
Speaker 2:  I think you have to score this one, two and a half. Oh God,

902
01:02:06,945 --> 01:02:07,365
Speaker 2:  that's

903
01:02:07,365 --> 01:02:08,245
Speaker 3:  Outta three. To be clear.

904
01:02:08,575 --> 01:02:09,645
Speaker 6:  Sorry. You're so jealous.

905
01:02:09,825 --> 01:02:10,845
Speaker 3:  We didn't say what our scoring

906
01:02:11,305 --> 01:02:12,845
Speaker 2:  Was. We actually didn't say that we were scoring.

907
01:02:13,235 --> 01:02:16,125
Speaker 3:  Nila gave me a seven outta 10. I'm giving you a two and a half outta three.

908
01:02:16,195 --> 01:02:19,445
Speaker 3:  Perfect. And then we'll see. Actually you get like the Netflix one thumb

909
01:02:19,465 --> 01:02:22,645
Speaker 3:  up but not the two thumbs up. It's like a like it but not a love it kind

910
01:02:22,645 --> 01:02:24,645
Speaker 3:  of thing. You know what I mean? Okay, I'll that, so that's your score.

911
01:02:24,995 --> 01:02:28,925
Speaker 2:  Digital God, David, we can do it on current hardware. I

912
01:02:28,925 --> 01:02:32,125
Speaker 2:  want to say this as directly as I can. If you believe we can build a GI and

913
01:02:32,125 --> 01:02:36,115
Speaker 2:  current hardware, the tech industry should stop. We should just stop

914
01:02:36,115 --> 01:02:40,075
Speaker 2:  doing everything and focus on that one goal so that digital

915
01:02:40,295 --> 01:02:44,115
Speaker 2:  God can design the next iPhone. But I don't think that's true,

916
01:02:44,605 --> 01:02:48,115
Speaker 2:  right? Like that, that claim just implies you should stop working

917
01:02:49,575 --> 01:02:53,315
Speaker 2:  and let you know a GI do it for you. Please. I beg you

918
01:02:53,375 --> 01:02:55,915
Speaker 2:  let a GI write about Donald Trump for the next four years. It'll be, it'll

919
01:02:56,555 --> 01:02:58,235
Speaker 2:  everyone can take a break. All right, here's mine.

920
01:03:00,815 --> 01:03:02,505
Speaker 2:  Just a series of words is so silly.

921
01:03:04,295 --> 01:03:07,025
Speaker 2:  Just eat is selling GrubHub to wonder

922
01:03:07,735 --> 01:03:08,025
Speaker 3:  What

923
01:03:08,575 --> 01:03:12,505
Speaker 2:  None of those words make any sense. So GrubHub is, you know, is is the delivery

924
01:03:12,505 --> 01:03:14,625
Speaker 2:  service, right? It's, it's like probably the one that you are most familiar

925
01:03:14,625 --> 01:03:17,905
Speaker 2:  with it. They bought Seamless a while ago, so all it's all the same app.

926
01:03:18,135 --> 01:03:21,705
Speaker 3:  That was such a New Yorker thing to say by the way. That was seamless.

927
01:03:22,015 --> 01:03:25,745
Speaker 3:  GrubHub is the one is such a New York center isn't Grub say the one, what

928
01:03:25,745 --> 01:03:25,865
Speaker 3:  is

929
01:03:26,815 --> 01:03:28,345
Speaker 6:  None of these words were in the Bible. I

930
01:03:28,435 --> 01:03:31,145
Speaker 3:  Dunno what's going on. Yeah. I dunno what's going on. All right. It's like

931
01:03:31,145 --> 01:03:34,785
Speaker 3:  in LA it's just Postmates, but nowhere else. SF is,

932
01:03:35,065 --> 01:03:38,905
Speaker 3:  I think probably still like a DoorDash town. DoorDash. Yeah. This is

933
01:03:38,905 --> 01:03:42,305
Speaker 3:  like, this is like when you live in New York, it would like, oh, just seamless

934
01:03:42,305 --> 01:03:45,505
Speaker 3:  it. And it's like, what? That's nothing. That doesn't, that's, that's not

935
01:03:45,505 --> 01:03:45,665
Speaker 3:  a word

936
01:03:45,665 --> 01:03:48,185
Speaker 2:  That for Chicago though. When we moved to New York from Chicago. Anyway,

937
01:03:48,185 --> 01:03:51,025
Speaker 2:  it doesn't matter. They, these are all nonsense words and failing businesses

938
01:03:51,025 --> 01:03:53,425
Speaker 2:  that are just selling each other in different configurations. Fair. What

939
01:03:53,425 --> 01:03:56,905
Speaker 2:  I want to get to is they're selling it to a company called Wonder, which

940
01:03:56,905 --> 01:04:00,625
Speaker 2:  is owned by a part owner of the Minnesota Timberwolves and a former Walmart

941
01:04:01,045 --> 01:04:04,985
Speaker 2:  VP and Wonder's business model is bananas. Perfect.

942
01:04:05,415 --> 01:04:08,385
Speaker 2:  They, he licenses recipes from famous chefs.

943
01:04:09,665 --> 01:04:13,445
Speaker 2:  So you're like, yes. What so wonder is like a high end food

944
01:04:13,445 --> 01:04:17,165
Speaker 2:  hall and it's a ghost kitchen with like famous

945
01:04:17,725 --> 01:04:21,615
Speaker 2:  restaurants logos on the front. So you, you go in there and you're

946
01:04:21,615 --> 01:04:25,255
Speaker 2:  like, here's all these like famous local restaurants or like

947
01:04:25,575 --> 01:04:28,415
Speaker 2:  restaurants I've heard of that. Like celebrities go to

948
01:04:29,955 --> 01:04:33,815
Speaker 2:  So Wonder licenses recipes from famous chefs. So you

949
01:04:33,845 --> 01:04:37,655
Speaker 2:  open Wonder and there's Bobby flas steak, there's Street Bird by

950
01:04:37,655 --> 01:04:38,615
Speaker 2:  Marcus Samuelson.

951
01:04:40,625 --> 01:04:43,775
Speaker 2:  There is Detroit Brick Pizza, there's all this stuff

952
01:04:44,995 --> 01:04:48,335
Speaker 2:  De Farro Pizza, which is like a famous New York pizza place in there. But

953
01:04:48,335 --> 01:04:52,295
Speaker 2:  they don't actually make the food. They license the recipes and they have

954
01:04:52,355 --> 01:04:55,935
Speaker 2:  one big commissary kitchen that like pre-make the food

955
01:04:56,755 --> 01:05:00,615
Speaker 2:  so gross. And then it goes to the food hall where they with like

956
01:05:00,665 --> 01:05:04,535
Speaker 2:  steam baths and microwaves, reheat the food and assemble it and then deliver

957
01:05:04,535 --> 01:05:06,935
Speaker 2:  it to you or serve it in the food hall. So they have like

958
01:05:08,125 --> 01:05:11,775
Speaker 2:  commoditize the famous chef's recipe at

959
01:05:11,775 --> 01:05:15,695
Speaker 2:  industrial scale and now they're gonna buy GrubHub and they're

960
01:05:15,695 --> 01:05:19,205
Speaker 2:  gonna bring that model to an even bigger delivery system and it's like, oh

961
01:05:19,205 --> 01:05:22,925
Speaker 2:  this is wild. Wow. Like the reason that the chefs are famous

962
01:05:23,025 --> 01:05:26,165
Speaker 2:  is 'cause you think Jose Andres is gonna make you the food. Yeah. And now

963
01:05:26,165 --> 01:05:29,365
Speaker 2:  he's just licensed a recipes so someone else can steam bath the food to you

964
01:05:29,365 --> 01:05:30,005
Speaker 2:  and send it to you.

965
01:05:30,145 --> 01:05:32,925
Speaker 6:  And we don't know how much they're making off these licenses. Yeah. That

966
01:05:32,925 --> 01:05:33,925
Speaker 6:  hasn't leaked. Wow.

967
01:05:34,185 --> 01:05:38,045
Speaker 2:  And it's all, it also just be clear some, it's very expensive because it's

968
01:05:38,045 --> 01:05:39,045
Speaker 2:  famous chefs. So you're buying,

969
01:05:39,145 --> 01:05:40,565
Speaker 6:  But it's not famous chefs.

970
01:05:41,675 --> 01:05:45,285
Speaker 3:  This is like a knockoff version of eating dinner in a Vegas

971
01:05:45,425 --> 01:05:49,205
Speaker 3:  casino, right. Where it's like a bunch of restaurants

972
01:05:49,595 --> 01:05:53,535
Speaker 3:  that all claim to be, you know, run by famous

973
01:05:53,535 --> 01:05:57,415
Speaker 3:  people, but it just has their name on it. It's like getting, this

974
01:05:57,415 --> 01:06:01,375
Speaker 3:  is the equivalent of getting room service from a Bobby Flay restaurant in

975
01:06:01,375 --> 01:06:02,935
Speaker 3:  a Vegas casino. Well,

976
01:06:02,935 --> 01:06:06,255
Speaker 6:  Gordon Ramsey Burger is delicious. Let's be clear. Look,

977
01:06:06,315 --> 01:06:09,975
Speaker 3:  I'm sure some of this stuff is good. It's just, it also isn't the point of

978
01:06:09,975 --> 01:06:13,935
Speaker 3:  going to Gordon Ramsey Burger

979
01:06:13,995 --> 01:06:17,735
Speaker 3:  places the like vibe like getting take out Gordon

980
01:06:17,875 --> 01:06:18,615
Speaker 3:  Ramsey seems

981
01:06:19,245 --> 01:06:19,855
Speaker 2:  Just wrong.

982
01:06:19,925 --> 01:06:20,895
Speaker 6:  Yeah, no, that's gross.

983
01:06:21,445 --> 01:06:24,535
Speaker 2:  Well, I mean, you want to be screamed at in the Face by Gordon Ramsey. Exactly.

984
01:06:24,835 --> 01:06:28,575
Speaker 2:  To some extent the Vegas version of the chain restaurants like the

985
01:06:28,575 --> 01:06:32,455
Speaker 2:  Vegas carbon some people think is the best carbon. 'cause it

986
01:06:32,455 --> 01:06:36,335
Speaker 2:  just like moves the most business and there's the most dumb money flowing

987
01:06:36,335 --> 01:06:40,215
Speaker 2:  through it. Sure. Fine. This is very much like we're

988
01:06:40,215 --> 01:06:44,135
Speaker 2:  gonna half make the famous pizza, send it to a food hall

989
01:06:44,595 --> 01:06:47,655
Speaker 2:  and then a steam oven. We'll finish the famous pizza. Right. And then we

990
01:06:47,655 --> 01:06:51,095
Speaker 2:  will put that on GrubHub and you know, it's just like, oh, this is the end

991
01:06:51,095 --> 01:06:54,815
Speaker 2:  point of a very particular business model that

992
01:06:54,815 --> 01:06:58,535
Speaker 2:  started with Cloud kitchens, right. Where you like open the delivery

993
01:06:58,635 --> 01:07:02,535
Speaker 2:  app, right. And it's actually Chuck E Cheese. And then people are

994
01:07:02,535 --> 01:07:05,175
Speaker 2:  like, what If, you didn't even have the Chuck E Cheese. And they're like,

995
01:07:05,175 --> 01:07:08,975
Speaker 2:  but then you still, you can't just have like wings.com or

996
01:07:09,175 --> 01:07:12,855
Speaker 2:  whatever was in the, so now you need Bobby Flas name next to it and you're

997
01:07:12,855 --> 01:07:15,095
Speaker 2:  just kinda like, oh this is this, this circle is getting real weird.

998
01:07:15,445 --> 01:07:18,895
Speaker 3:  It's almost like, but it's all of that. But it ends at like a, a Golden Corral

999
01:07:18,895 --> 01:07:21,935
Speaker 3:  Buffet is essentially the end point of this whole system.

1000
01:07:22,075 --> 01:07:24,335
Speaker 2:  Donald Trump's America. Every restaurant is Carbone.

1001
01:07:24,845 --> 01:07:28,055
Speaker 6:  Have you seen people joking about how they don't want DoorDash coming in

1002
01:07:28,055 --> 01:07:31,415
Speaker 6:  like a Nissan Ultima? They want it in an uber black like this Is that same,

1003
01:07:31,645 --> 01:07:33,095
Speaker 6:  that same thing. Are you

1004
01:07:33,095 --> 01:07:33,295
Speaker 3:  Serious?

1005
01:07:33,885 --> 01:07:37,615
Speaker 6:  It's just like, it's like sending an uber black to a, a commissary

1006
01:07:37,675 --> 01:07:40,375
Speaker 6:  to get your food. Like what is the point anymore? Yeah. I feel like we've

1007
01:07:40,375 --> 01:07:44,255
Speaker 6:  just reached a new level of consumerism that is absolutely absurd. And I'm

1008
01:07:44,255 --> 01:07:44,415
Speaker 6:  pure,

1009
01:07:44,415 --> 01:07:45,335
Speaker 2:  That's not absurd enough yet.

1010
01:07:45,655 --> 01:07:49,255
Speaker 3:  I would like every part of this process to feel fancy but actually not be

1011
01:07:49,255 --> 01:07:50,015
Speaker 3:  fancy at all.

1012
01:07:50,265 --> 01:07:51,135
Speaker 6:  Right, exactly.

1013
01:07:51,335 --> 01:07:54,135
Speaker 3:  I wanna think it's expensive even though it's, it sucks.

1014
01:07:56,455 --> 01:08:00,375
Speaker 2:  I just like the idea that you would order any steak from a delivery app has

1015
01:08:00,375 --> 01:08:04,195
Speaker 2:  always seemed odd to me. Like it's just, that's not

1016
01:08:04,195 --> 01:08:07,435
Speaker 2:  right. That's not a great environment for a state to be in. Like in the back

1017
01:08:07,435 --> 01:08:08,755
Speaker 2:  of a Nissan Altima for a while.

1018
01:08:08,755 --> 01:08:12,635
Speaker 3:  They feel the same way about delivery sushi. Like not about it.

1019
01:08:13,005 --> 01:08:13,915
Speaker 6:  Sorry, I can't relate.

1020
01:08:14,055 --> 01:08:17,165
Speaker 2:  Do you know why Meryl Streep was angry in the Devil Wars Prada? 'cause she

1021
01:08:17,165 --> 01:08:20,245
Speaker 2:  was having delivery steak for lunch every day. Such a good point.

1022
01:08:21,105 --> 01:08:23,525
Speaker 2:  All right. That's it. I've, I've shown, I've told what what do you got? Wait,

1023
01:08:23,525 --> 01:08:26,765
Speaker 3:  Can I, can I add one more thing to this? Yeah. So four years ago

1024
01:08:28,195 --> 01:08:31,165
Speaker 3:  when there was some other stuff going on in the world, just Eat,

1025
01:08:32,045 --> 01:08:35,075
Speaker 3:  which was then called Just Eat Takeaway 'cause Sure.

1026
01:08:35,935 --> 01:08:38,835
Speaker 3:  Bought GrubHub for $7.3 billion

1027
01:08:39,775 --> 01:08:43,755
Speaker 3:  and is now selling it to Wonder for $650 million. Wow.

1028
01:08:43,955 --> 01:08:47,755
Speaker 3:  I don't know enough about this world to like really process

1029
01:08:48,095 --> 01:08:51,235
Speaker 3:  why that is, but that is a giant loss in four years.

1030
01:08:51,825 --> 01:08:54,915
Speaker 6:  Yeah. I don't remember the last time I used GrubHub. Maybe 2020.

1031
01:08:56,075 --> 01:08:56,995
Speaker 3:  I mean, it might have been

1032
01:08:57,455 --> 01:08:58,395
Speaker 6:  So makes sense to me.

1033
01:08:59,265 --> 01:09:02,235
Speaker 3:  Well, and just Eat Takeaway was for a minute they were like, it just, it

1034
01:09:02,235 --> 01:09:04,835
Speaker 3:  was called Just Eat Takeaway because that was the combination of two businesses

1035
01:09:04,835 --> 01:09:07,875
Speaker 3:  and it was supposed to be the like giant delivery

1036
01:09:08,035 --> 01:09:11,915
Speaker 3:  conglomerate that was going to eat everything. And that just has not

1037
01:09:12,175 --> 01:09:13,795
Speaker 3:  panned out for anybody.

1038
01:09:13,795 --> 01:09:16,395
Speaker 6:  Yeah. I mean the margins can't be good. Right. I know nothing about this

1039
01:09:16,395 --> 01:09:16,955
Speaker 6:  world, but it's,

1040
01:09:17,175 --> 01:09:21,115
Speaker 2:  I'm I'm guessing the margins on selling microwave Gordon Ramsey

1041
01:09:21,115 --> 01:09:22,315
Speaker 2:  is, I don't think it's true. Well that's,

1042
01:09:22,775 --> 01:09:23,635
Speaker 6:  That's probably better than,

1043
01:09:23,795 --> 01:09:26,915
Speaker 2:  I mean, not say Gordon Ramsey name. I'm sure that margin than selling microwave

1044
01:09:26,915 --> 01:09:28,595
Speaker 2:  Bobby Fla is like very good.

1045
01:09:28,995 --> 01:09:31,235
Speaker 6:  That's probably a better business idea than

1046
01:09:32,975 --> 01:09:36,595
Speaker 6:  people enslaved to McDonald's on motorcycles.

1047
01:09:36,595 --> 01:09:40,395
Speaker 3:  Yeah. Well, and all of these companies have said for years in like Uber

1048
01:09:40,495 --> 01:09:44,395
Speaker 3:  and DoorDash among them that shipping food and stuff is a

1049
01:09:44,395 --> 01:09:47,595
Speaker 3:  much higher margin business around a city than people.

1050
01:09:48,125 --> 01:09:51,915
Speaker 3:  Right? Mm. Giving humans rides is not nearly as good a business

1051
01:09:51,975 --> 01:09:55,875
Speaker 3:  as moving stake around for a huge profit.

1052
01:09:57,215 --> 01:10:00,835
Speaker 3:  So like, you can see it, I, there was just gonna be this time when

1053
01:10:01,015 --> 01:10:04,795
Speaker 3:  all of these companies were competing and whoever won was gonna be a giant

1054
01:10:05,135 --> 01:10:08,555
Speaker 3:  and it was gonna be epic and they were gonna be the biggest company in the

1055
01:10:08,555 --> 01:10:11,035
Speaker 3:  world. And what actually seems to have happened is it's a bunch of like

1056
01:10:12,505 --> 01:10:16,375
Speaker 3:  reasonably successful but fairly low margin businesses. Yeah. That

1057
01:10:16,715 --> 01:10:19,375
Speaker 3:  worked well in some places and not in others.

1058
01:10:19,755 --> 01:10:22,655
Speaker 2:  The VC dollars were not able to buy monopolies and then raise the prices,

1059
01:10:22,825 --> 01:10:26,255
Speaker 2:  which is the business model for in particular Uber for a long time. Yep.

1060
01:10:26,715 --> 01:10:30,295
Speaker 2:  But look, again, this the words I'm using just Eat has sold

1061
01:10:30,365 --> 01:10:33,055
Speaker 2:  GrubHub to wonder is a sentence that you now understand.

1062
01:10:33,815 --> 01:10:35,255
Speaker 6:  I don't wanna understand it. I wanna go back.

1063
01:10:35,405 --> 01:10:36,135
Speaker 2:  Give me a score.

1064
01:10:37,145 --> 01:10:38,695
Speaker 6:  Three Michelin stars. Very

1065
01:10:38,695 --> 01:10:38,895
Speaker 2:  Good.

1066
01:10:40,515 --> 01:10:40,735
Speaker 3:  Wow.

1067
01:10:42,405 --> 01:10:45,015
Speaker 2:  That means I'm now a raging asshole and I can't be stopped.

1068
01:10:46,755 --> 01:10:47,615
Speaker 2:  I'm a made man.

1069
01:10:47,915 --> 01:10:50,535
Speaker 6:  No, I'm gonna put you in the ring with Bobby play and then we'll figure it

1070
01:10:50,535 --> 01:10:51,215
Speaker 6:  out from there. It's all over.

1071
01:10:51,435 --> 01:10:51,895
Speaker 3:  Yes, chef.

1072
01:10:52,715 --> 01:10:52,935
Speaker 6:  Yes.

1073
01:10:53,755 --> 01:10:56,735
Speaker 2:  We gotta stop. That's it. That was show and tell. We have to take a break.

1074
01:10:56,735 --> 01:10:57,935
Speaker 2:  Thank you Kylie. We'll be right back.

1075
01:14:04,775 --> 01:14:08,445
Speaker 2:  We're back with the lightning round. I have news,

1076
01:14:08,755 --> 01:14:11,805
Speaker 2:  it's not today, but I'm told the lightning round is sponsored. It's very

1077
01:14:11,925 --> 01:14:12,445
Speaker 2:  exciting. Big money.

1078
01:14:12,615 --> 01:14:15,325
Speaker 3:  We're gonna be doing this podcast from a yacht starting sometime soon.

1079
01:14:16,345 --> 01:14:20,205
Speaker 2:  It was sponsored by a boat show. If. you run a boat show and

1080
01:14:20,205 --> 01:14:22,365
Speaker 2:  you'd like to sponsor the wedding round, please let me know.

1081
01:14:23,975 --> 01:14:26,905
Speaker 2:  Talk about a sponsor integration, which we are ethically not allowed to do.

1082
01:14:27,025 --> 01:14:27,305
Speaker 2:  I have

1083
01:14:27,305 --> 01:14:30,985
Speaker 3:  Been trying to come up with a reason to go to the

1084
01:14:30,985 --> 01:14:34,825
Speaker 3:  Monaco Yacht Show for journalism for approximately my entire journalism

1085
01:14:34,825 --> 01:14:38,345
Speaker 3:  career. That is my, I've always said that the main thing I wanna do is figure

1086
01:14:38,345 --> 01:14:42,105
Speaker 3:  out a reason to expense drugs, figure out a journalistically

1087
01:14:42,495 --> 01:14:45,425
Speaker 3:  real reason to go to the Monaco Yacht Show is now number one on my list.

1088
01:14:45,425 --> 01:14:45,825
Speaker 3:  You've

1089
01:14:45,825 --> 01:14:46,665
Speaker 2:  Mellowed in your old age.

1090
01:14:48,135 --> 01:14:52,105
Speaker 3:  Yeah, I just wanna be on a boat now. I I'm just sober on a

1091
01:14:52,105 --> 01:14:52,905
Speaker 3:  boat. Seems great.

1092
01:14:53,255 --> 01:14:55,425
Speaker 2:  It's very good. All right. Lightning round.

1093
01:14:57,055 --> 01:14:58,105
Speaker 2:  What do you think? We,

1094
01:14:58,265 --> 01:15:01,465
Speaker 3:  I you, you have selected three things, In the lightning round, which is the

1095
01:15:01,465 --> 01:15:04,545
Speaker 3:  least lightning round thing I could imagine. So why don't you go first, Cindy,

1096
01:15:04,545 --> 01:15:04,745
Speaker 3:  do one.

1097
01:15:05,465 --> 01:15:09,265
Speaker 2:  Okay, so my first one, which I just wanna talk about very quickly is something

1098
01:15:09,305 --> 01:15:13,145
Speaker 2:  a bunch of people have asked me about this week and it's ethics and

1099
01:15:13,145 --> 01:15:16,585
Speaker 2:  disclosure. So talk about this for as much as anybody wants me to talk about

1100
01:15:16,585 --> 01:15:20,185
Speaker 2:  it and we'll move on to more fun lightning round ones. But

1101
01:15:20,415 --> 01:15:23,585
Speaker 2:  this week Mark has, Brownley made a video as a sponsored video. And the video,

1102
01:15:23,605 --> 01:15:26,945
Speaker 2:  he is speeding his car. People got all mad about it. We wrote about it because

1103
01:15:27,015 --> 01:15:30,465
Speaker 2:  Marquez is a huge character in tech. We write about other creators all the

1104
01:15:30,465 --> 01:15:33,545
Speaker 2:  time. We think our audience wants to know and keep up with the things. So

1105
01:15:33,545 --> 01:15:36,185
Speaker 2:  we wrote about it. Here's what's happening, If, you read the story, it's

1106
01:15:36,185 --> 01:15:39,465
Speaker 2:  pretty straight. It's on the website. Here's some stuff that happened. Here's

1107
01:15:39,465 --> 01:15:43,025
Speaker 2:  the coverage of it. Marquez, we wrote about his wallpaper app recently too.

1108
01:15:43,055 --> 01:15:46,425
Speaker 2:  There's whatever controversy, I don't wanna dwell on the video or what happened

1109
01:15:46,425 --> 01:15:50,385
Speaker 2:  in the video or any of that stuff. What people are asking about is that I

1110
01:15:50,385 --> 01:15:53,265
Speaker 2:  think it's, it's waveform, right? Mark's podcast at the end of it, or at

1111
01:15:53,265 --> 01:15:55,225
Speaker 2:  the beginning of it, they say this is part of the V Media podcast network.

1112
01:15:55,445 --> 01:15:59,225
Speaker 2:  And so people are asking, do we need to disclose this? Should

1113
01:15:59,245 --> 01:16:03,185
Speaker 2:  we disclose this in the story? Should we talk about it? Now as I think for

1114
01:16:03,185 --> 01:16:06,345
Speaker 2:  listeners know, I got no problems with disclosures, disclosures all night

1115
01:16:06,345 --> 01:16:09,825
Speaker 2:  and all day. I think we should be as transparent as possible about potential

1116
01:16:09,825 --> 01:16:13,625
Speaker 2:  sources of conflicts. I think we should earn people's trust as just

1117
01:16:13,625 --> 01:16:17,465
Speaker 2:  transparently as we can. We talk about the, the making of journalism

1118
01:16:17,465 --> 01:16:21,265
Speaker 2:  more than any other traditional journalists that I can think of. We

1119
01:16:21,385 --> 01:16:24,785
Speaker 2:  certainly do more disclosures than any traditional media or any influencers

1120
01:16:24,785 --> 01:16:27,705
Speaker 2:  do all the time. I have literally no problem with this. I'm happy to disclose

1121
01:16:27,705 --> 01:16:31,385
Speaker 2:  it. The thing that we're running into right now is like when and why do we

1122
01:16:31,545 --> 01:16:33,665
Speaker 2:  disclose things? And so in this case,

1123
01:16:35,655 --> 01:16:38,395
Speaker 2:  the Vox Media Podcast network is an ad sales network,

1124
01:16:39,345 --> 01:16:42,815
Speaker 2:  right? If, you are If, you start a podcast and you just like go onto YouTube

1125
01:16:42,835 --> 01:16:46,335
Speaker 2:  or you go onto Spotify's platform or whatever. You're kind of, unless you

1126
01:16:46,335 --> 01:16:49,975
Speaker 2:  have big scale, you're kind of stuck with programmatic advertising. Whatever

1127
01:16:49,975 --> 01:16:52,935
Speaker 2:  the platforms will give to you. And If, you want better advertising, you

1128
01:16:52,935 --> 01:16:55,975
Speaker 2:  want more money, you need scale. So you join a podcast network that has a

1129
01:16:55,975 --> 01:16:59,615
Speaker 2:  lot of inventory across a lot of shows, and then our sellers go out and sell

1130
01:16:59,615 --> 01:17:03,295
Speaker 2:  that inventory and then you make more money or whatever. I actually dunno

1131
01:17:03,295 --> 01:17:06,975
Speaker 2:  because that's the other side of the house, right? So the conflict here

1132
01:17:07,125 --> 01:17:10,805
Speaker 2:  doesn't exist. Like our sales team is selling

1133
01:17:10,985 --> 01:17:14,725
Speaker 2:  ads, which they do on our own website that we don't know about, that they

1134
01:17:14,725 --> 01:17:18,605
Speaker 2:  do on the show, right? That we basically dunno about. As many of

1135
01:17:18,605 --> 01:17:22,525
Speaker 2:  you have heard, sometimes we just run the same ad 500 times, right? Like

1136
01:17:22,525 --> 01:17:26,045
Speaker 2:  there's a wall between us and sales and we are very, very, very

1137
01:17:26,045 --> 01:17:29,925
Speaker 2:  protective of that wall. We, our coverage often loses

1138
01:17:29,925 --> 01:17:33,765
Speaker 2:  them money because various companies are mad at our coverage and they

1139
01:17:33,795 --> 01:17:36,765
Speaker 2:  walk away with deals. I've co I've personally cost this company a bunch of

1140
01:17:36,765 --> 01:17:40,725
Speaker 2:  money. But that's the whole point of the wall, right? Is to keep

1141
01:17:40,725 --> 01:17:44,565
Speaker 2:  our newsroom away from any of those considerations so that we

1142
01:17:44,565 --> 01:17:47,325
Speaker 2:  can just write about what's happening and have editorial independence and

1143
01:17:47,325 --> 01:17:50,285
Speaker 2:  freedom and we can If you. It's like the first line of our ethics policy

1144
01:17:50,345 --> 01:17:53,925
Speaker 2:  is like, is the editorial independence that allows us to cover

1145
01:17:54,205 --> 01:17:57,445
Speaker 2:  companies critically without fear of favor or whatever. That's the thing

1146
01:17:57,445 --> 01:18:01,215
Speaker 2:  that's the most important. That's the truly the heart of this whole operation

1147
01:18:01,215 --> 01:18:04,935
Speaker 2:  is the independence. So what we disclose

1148
01:18:05,515 --> 01:18:09,455
Speaker 2:  is where there's a plausible connection to some conflict

1149
01:18:09,675 --> 01:18:13,575
Speaker 2:  in our newsroom. So Comcast, NBC Universal is

1150
01:18:13,575 --> 01:18:17,535
Speaker 2:  an investor in our company. They're on our board of directors. They

1151
01:18:17,555 --> 01:18:21,135
Speaker 2:  can want to fire me, right? They can. They don't like

1152
01:18:21,355 --> 01:18:25,335
Speaker 2:  me a lot. They might. Yeah, they right. Like they can have a board

1153
01:18:25,335 --> 01:18:28,975
Speaker 2:  meeting and say we should fire this guy. That is a plausible in

1154
01:18:28,975 --> 01:18:32,815
Speaker 2:  imposition on our newsroom. It has never happened. You know, we've,

1155
01:18:32,905 --> 01:18:36,775
Speaker 2:  we've been running this thing for 13 years, but that's plausible. I think

1156
01:18:36,775 --> 01:18:40,335
Speaker 2:  you can, you can fairly look at our company and say they're at the top of

1157
01:18:40,335 --> 01:18:44,295
Speaker 2:  it. The Verge is talking about Comcast. Maybe they'll get, get him fired

1158
01:18:44,295 --> 01:18:47,815
Speaker 2:  maybe shit in the coverage. Fine. So we disclose it. I made a Netflix

1159
01:18:48,005 --> 01:18:48,295
Speaker 2:  show.

1160
01:18:50,655 --> 01:18:54,055
Speaker 2:  That's just like an open conflict of interest, right? Like every time I talk

1161
01:18:54,055 --> 01:18:56,855
Speaker 2:  about Netflix, I should point out that I made a Netflix show. I didn't get

1162
01:18:56,855 --> 01:18:58,935
Speaker 2:  paid for it 'cause the company made it, but you know, whatever. I still made

1163
01:18:58,935 --> 01:18:59,175
Speaker 2:  the show

1164
01:19:00,735 --> 01:19:04,565
Speaker 2:  great. Like I I think that's fine. That's a totally rational conflict of

1165
01:19:04,685 --> 01:19:07,245
Speaker 2:  interest. There's a plausible connection to the thing and the the conflict.

1166
01:19:07,315 --> 01:19:10,445
Speaker 2:  There's a million of these. We disclose them all the time.

1167
01:19:11,175 --> 01:19:14,945
Speaker 2:  This one, there isn't a plausible conflict. The actually more plausible

1168
01:19:15,105 --> 01:19:18,105
Speaker 2:  conflict is that David and I know most of the people on Waveform and we like

1169
01:19:18,105 --> 01:19:22,025
Speaker 2:  them. Yeah, So I will disclose to you. I've known Marquez for a long

1170
01:19:22,025 --> 01:19:25,065
Speaker 2:  time. David has known Marquez for a long time. We know a bunch of the folks

1171
01:19:25,095 --> 01:19:28,885
Speaker 2:  over there. We're friendly with them. We generally wish them success when

1172
01:19:28,885 --> 01:19:32,125
Speaker 2:  we cover them. I think we do it as straight as we can, but the actual business

1173
01:19:32,445 --> 01:19:36,365
Speaker 2:  conflict it, it's not there. And if I, and if we open the door to

1174
01:19:36,375 --> 01:19:39,805
Speaker 2:  disclosing what our sales side is doing, I think we actually threaten our

1175
01:19:39,885 --> 01:19:43,805
Speaker 2:  editorial independence because then I have to tell the newsroom every

1176
01:19:43,805 --> 01:19:47,045
Speaker 2:  single thing they have to disclose, right? And I have to make the newsroom

1177
01:19:47,375 --> 01:19:51,165
Speaker 2:  aware of all of the company's commercial and corporate

1178
01:19:51,525 --> 01:19:55,205
Speaker 2:  interactions in a way that I actually don't want them to know. That's the

1179
01:19:55,205 --> 01:19:59,085
Speaker 2:  whole purpose of the wall is that they're just gonna do their jobs. So

1180
01:19:59,085 --> 01:20:01,605
Speaker 2:  there's, there's a line here. And I'm not saying we always get it a hundred

1181
01:20:01,605 --> 01:20:05,045
Speaker 2:  percent right? But in this case that I know what that

1182
01:20:05,195 --> 01:20:08,725
Speaker 2:  arrangement is. Like I know what the Box media podcast network is.

1183
01:20:09,425 --> 01:20:12,685
Speaker 2:  We have a bunch of these deals like all of Scott Galloway's, prof g shows.

1184
01:20:12,865 --> 01:20:15,285
Speaker 2:  We don't own them, we don't make them, but they're in the network. We sell

1185
01:20:15,285 --> 01:20:17,845
Speaker 2:  the ads. There are other ones as well. There's all kinds of arrangements.

1186
01:20:18,135 --> 01:20:21,245
Speaker 2:  We'll disclose the ones where it's our company. But in this case it's, it's

1187
01:20:21,245 --> 01:20:24,925
Speaker 2:  just a little too removed from our newsroom in the same way that we

1188
01:20:25,205 --> 01:20:29,045
Speaker 2:  run a programmatic ad tech stack called concert that is on tons of

1189
01:20:29,045 --> 01:20:32,955
Speaker 2:  publishers. Every time you see a concert logo on a web ad that's, Vox

1190
01:20:32,955 --> 01:20:36,035
Speaker 2:  Media is serving that one. and we, we just cannot disclose

1191
01:20:36,845 --> 01:20:40,075
Speaker 2:  every partner that concert. It would, it would bring our newsroom to a halt.

1192
01:20:40,215 --> 01:20:44,075
Speaker 2:  And and more importantly, it would force me

1193
01:20:44,575 --> 01:20:47,795
Speaker 2:  to make every reporter in the newsroom aware

1194
01:20:48,455 --> 01:20:52,155
Speaker 2:  of the company's business deals. Which is the most important thing, right?

1195
01:20:52,295 --> 01:20:55,995
Speaker 3:  That's the key, right? Like the, the not knowing on that side

1196
01:20:56,135 --> 01:21:00,035
Speaker 3:  is, is important, right? Like there, there is a thing, we talk about

1197
01:21:00,035 --> 01:21:03,315
Speaker 3:  this with creators and stuff all the time, that one of the challenges is

1198
01:21:03,905 --> 01:21:07,795
Speaker 3:  knowing what something you do will do to your

1199
01:21:07,995 --> 01:21:11,795
Speaker 3:  business. And because of who is advertising and who wants to sponsor your

1200
01:21:11,795 --> 01:21:14,755
Speaker 3:  videos and all this stuff, that is a thing you have to reckon with. And a

1201
01:21:14,755 --> 01:21:18,715
Speaker 3:  big part of what we're trying to do is not even give people the

1202
01:21:18,715 --> 01:21:21,595
Speaker 3:  chance to think about that because it just, it just changes things.

1203
01:21:22,095 --> 01:21:25,395
Speaker 2:  And I firmly believe that this is getting confusing and muddled and most

1204
01:21:25,395 --> 01:21:29,315
Speaker 2:  people do not understand this. Yep. And that's on us. We have to constantly

1205
01:21:29,315 --> 01:21:32,635
Speaker 2:  explain it, which is why I'm happy to talk about it whenever anyone asks.

1206
01:21:33,025 --> 01:21:36,395
Speaker 2:  That is not how most of the media that most people consume works anymore.

1207
01:21:37,145 --> 01:21:41,075
Speaker 2:  Most creators, influencers have absolutely blurred the lines between

1208
01:21:41,435 --> 01:21:45,035
Speaker 2:  advertising, between sales. They have investments, their commercial relationships

1209
01:21:45,095 --> 01:21:48,275
Speaker 2:  are in the front of their content. I'm not even calling out any creator.

1210
01:21:48,275 --> 01:21:51,755
Speaker 2:  This is the reality of the business on those platforms. If, you wanna make

1211
01:21:51,755 --> 01:21:55,595
Speaker 2:  enough money to eat, this is how you have to play the game. Yep. But that's

1212
01:21:55,595 --> 01:21:59,475
Speaker 2:  not us, right? Like, it just isn't us. And so I'm happy to disclose everything.

1213
01:21:59,475 --> 01:22:02,355
Speaker 2:  I'm happy to talk about it. I just, there are times when I'm be like, no,

1214
01:22:02,355 --> 01:22:05,275
Speaker 2:  that one doesn't make any sense. And what I'm really talking about is if

1215
01:22:05,355 --> 01:22:09,155
Speaker 2:  I extend the rule that much, we're actually gonna

1216
01:22:09,155 --> 01:22:12,675
Speaker 2:  defeat the purpose of the rule, right? We're gonna defeat the independence

1217
01:22:12,675 --> 01:22:16,395
Speaker 2:  of the newsroom in a way that I, that's, that is the

1218
01:22:16,395 --> 01:22:20,355
Speaker 2:  product we sell here is the independence of the newsroom. Lemme just, I'll

1219
01:22:20,355 --> 01:22:22,795
Speaker 2:  give you this example. Every, we disclose Comcast n BBC all the time. 'cause

1220
01:22:22,795 --> 01:22:26,315
Speaker 2:  everybody knows about it. There are other investors in our company, they're

1221
01:22:26,315 --> 01:22:30,195
Speaker 2:  there. And if I extend the rules so far, like I kind of end up in a

1222
01:22:30,195 --> 01:22:34,125
Speaker 2:  place where every single morning I'm just telling the newsroom

1223
01:22:34,585 --> 01:22:36,365
Speaker 2:  who they should be worried about. Right?

1224
01:22:37,345 --> 01:22:39,085
Speaker 3:  Here's, here's a list of problems.

1225
01:22:39,355 --> 01:22:42,765
Speaker 2:  Yeah. Here's a list of considerations for every story. And it like, I I,

1226
01:22:42,965 --> 01:22:46,565
Speaker 2:  I really think that undercuts the promise of what we do here. So

1227
01:22:47,075 --> 01:22:49,405
Speaker 2:  like I said, we'll take the feedback, I'll talk about it whenever we want.

1228
01:22:49,705 --> 01:22:53,525
Speaker 2:  In this case, I don't, there's not a plausible connection to the

1229
01:22:53,525 --> 01:22:56,965
Speaker 2:  company's commercial activities in our news room there. I I just assure you

1230
01:22:56,965 --> 01:23:00,005
Speaker 2:  that there isn't one to the point where until people mentioned it to us,

1231
01:23:00,125 --> 01:23:04,005
Speaker 2:  I hadn't even thought about it. And so, we'll, we'll keep, we'll we're gonna

1232
01:23:04,005 --> 01:23:07,485
Speaker 2:  keep doing disclosures. My ask of you, If, you want to yell at me about this?

1233
01:23:08,035 --> 01:23:11,565
Speaker 2:  Take 20% of the energy and point it

1234
01:23:11,865 --> 01:23:15,655
Speaker 2:  at other media outlets and other creators and influencers because

1235
01:23:15,895 --> 01:23:19,135
Speaker 2:  I would rather be in a world where the audience is that demanding of everyone.

1236
01:23:19,795 --> 01:23:23,575
Speaker 2:  And I'll do my best to live up to it because that's the thing that's gonna

1237
01:23:23,575 --> 01:23:26,895
Speaker 2:  rebuild trust in whatever kind of journalism exists in that

1238
01:23:27,765 --> 01:23:31,025
Speaker 2:  we do it. So we get it a lot. Right? It's an expectation that we have created

1239
01:23:31,025 --> 01:23:34,385
Speaker 2:  with all of you. And I'm happy about that. We receive the expectation,

1240
01:23:35,045 --> 01:23:38,905
Speaker 2:  but If, you think we're failing? Take just 20% of the energy and

1241
01:23:38,905 --> 01:23:41,785
Speaker 2:  point at everybody else. Like it'll make everything a little bit better.

1242
01:23:43,075 --> 01:23:44,235
Speaker 2:  All right. David, what's your last name? Round item.

1243
01:23:44,975 --> 01:23:48,195
Speaker 3:  Mine's gonna be much quicker because I really don't wanna talk about it.

1244
01:23:48,195 --> 01:23:51,635
Speaker 3:  Like we went from something that we like talking about too. I don't under

1245
01:23:51,855 --> 01:23:55,635
Speaker 3:  any circumstances want to talk about this, but we have to. And it is

1246
01:23:55,635 --> 01:23:59,555
Speaker 3:  that President-elect, Donald Trump has said that Elon

1247
01:23:59,555 --> 01:24:03,395
Speaker 3:  Musk is going to be leading a thing called the Department of Government

1248
01:24:03,395 --> 01:24:07,115
Speaker 3:  Efficiency that is going to do some stuff, cut

1249
01:24:07,115 --> 01:24:10,315
Speaker 3:  wasteful government spending. There's apparently gonna be a leaderboard on

1250
01:24:10,475 --> 01:24:12,755
Speaker 3:  X of all the dumbest ways the government spends money.

1251
01:24:14,415 --> 01:24:18,395
Speaker 3:  The, the only reason I wanna talk about this is because I think if, if I

1252
01:24:18,395 --> 01:24:22,155
Speaker 3:  have a, if I have a bit on this show, it is the question. Is this

1253
01:24:22,395 --> 01:24:25,915
Speaker 3:  anything? It's the meme of a person holding a, like their hand at a butterfly

1254
01:24:25,915 --> 01:24:29,255
Speaker 3:  and going, is this anything? This is nothing. This

1255
01:24:29,255 --> 01:24:32,775
Speaker 2:  Is nothing. Can I just say it's it, it was announced and it's announced that

1256
01:24:32,965 --> 01:24:36,655
Speaker 2:  it's Elon and Vivek Ramaswamy are gonna run it. And it's amazing that the

1257
01:24:36,655 --> 01:24:40,135
Speaker 2:  efficiency department has two leaders, leaders like

1258
01:24:40,235 --> 01:24:44,135
Speaker 2:  you're just coming out the gate with co-CEOs like Blackberry style. Perfect.

1259
01:24:44,135 --> 01:24:44,735
Speaker 2:  Like what are we doing?

1260
01:24:44,765 --> 01:24:45,695
Speaker 3:  What could possibly go wrong?

1261
01:24:45,955 --> 01:24:47,215
Speaker 2:  That's very good. You can't

1262
01:24:47,215 --> 01:24:49,295
Speaker 3:  Just do a department. You can't just do it

1263
01:24:50,275 --> 01:24:51,205
Speaker 2:  Like in life. I

1264
01:24:51,205 --> 01:24:53,485
Speaker 3:  Declare department is not a thing the president can do.

1265
01:24:53,985 --> 01:24:56,205
Speaker 2:  Oh, you mean like in the government? Yeah. You

1266
01:24:56,855 --> 01:25:00,555
Speaker 3:  And I could make a department of I just, the Department

1267
01:25:00,655 --> 01:25:04,435
Speaker 3:  of David's pillows like that exists. I did it. We're here.

1268
01:25:05,195 --> 01:25:06,235
Speaker 2:  I feel like your wife might have

1269
01:25:06,235 --> 01:25:06,835
Speaker 3:  Something to say.

1270
01:25:06,945 --> 01:25:07,235
Speaker 2:  This

1271
01:25:07,235 --> 01:25:09,595
Speaker 3:  Department, I'm the president. I did it.

1272
01:25:10,065 --> 01:25:11,515
Speaker 2:  It's my weird pillow room.

1273
01:25:14,345 --> 01:25:17,525
Speaker 3:  But the the, the government cannot just create a department

1274
01:25:18,145 --> 01:25:21,605
Speaker 3:  out of thin air because someone says, so that's not how this works. Yeah,

1275
01:25:22,865 --> 01:25:25,365
Speaker 2:  I'm gonna say what? Yeah. Do you need an act of Congress? Yeah. Is the thing.

1276
01:25:26,495 --> 01:25:29,395
Speaker 2:  So whatever. The only other thing I'll add to this, because this is gonna

1277
01:25:29,395 --> 01:25:31,595
Speaker 2:  be fake when we're gonna have to talk about it. And this is pure by the way,

1278
01:25:31,595 --> 01:25:34,275
Speaker 2:  decoder debate and we'll definitely talk about under decoder, can you make

1279
01:25:34,275 --> 01:25:37,395
Speaker 2:  a fake department in the government also, by the way, leader leaderboards

1280
01:25:37,395 --> 01:25:39,555
Speaker 2:  of wasteful government spending, they've been doing that shit since the eighties.

1281
01:25:40,405 --> 01:25:40,695
Speaker 2:  Like

1282
01:25:42,405 --> 01:25:45,495
Speaker 2:  some of the, these ideas we're we're just inventing trains again, like the

1283
01:25:45,495 --> 01:25:49,255
Speaker 2:  classic Elon Musk. Yeah. Anyway, all this is to say, there was a New York

1284
01:25:49,275 --> 01:25:52,975
Speaker 2:  Mag article today about the scene at Mar-a-Lago and just like the frenzy

1285
01:25:52,975 --> 01:25:56,135
Speaker 2:  of corruption that is happening there. And every time Elon Musk walks into

1286
01:25:56,135 --> 01:25:59,695
Speaker 2:  dinner, Donald Trump pulls out his iPad and plays Space Oddity by David Bowie.

1287
01:26:00,155 --> 01:26:01,175
Speaker 3:  Oh, I don't like that at all.

1288
01:26:01,855 --> 01:26:04,485
Speaker 2:  I feel like David Bowie very mad, but I also think it's very funny they pick

1289
01:26:04,485 --> 01:26:04,885
Speaker 2:  space side.

1290
01:26:06,235 --> 01:26:09,885
Speaker 3:  Yeah. It's like not exactly the compliment. You might think it is,

1291
01:26:10,675 --> 01:26:11,125
Speaker 2:  It's not.

1292
01:26:11,595 --> 01:26:14,365
Speaker 3:  Yeah. But that's enough. We've talked about that enough. What's your next

1293
01:26:14,365 --> 01:26:14,805
Speaker 3:  episode, NELI.

1294
01:26:14,805 --> 01:26:18,445
Speaker 2:  Welcome. Come back to it around. All right. I want to check in on our nation's

1295
01:26:18,445 --> 01:26:22,315
Speaker 2:  fourth wireless carrier, which you will recall is a product

1296
01:26:22,375 --> 01:26:25,795
Speaker 2:  of Trump won when T-Mobile wanted to buy Sprint.

1297
01:26:26,255 --> 01:26:30,235
Speaker 2:  And instead of saying no, which is the exact process

1298
01:26:30,375 --> 01:26:34,155
Speaker 2:  by which T-Mobile was created, If you recall at t wanted to buy

1299
01:26:34,235 --> 01:26:36,635
Speaker 2:  T-Mobile. The government said no. And then T-Mobile had to go out. They took

1300
01:26:36,635 --> 01:26:38,755
Speaker 2:  a bunch of money and the breakup fee and, but then they became T-Mobile.

1301
01:26:38,755 --> 01:26:41,515
Speaker 2:  Right? They hired a new CEO, they did business. They're like, we're gonna

1302
01:26:41,515 --> 01:26:45,355
Speaker 2:  try hard. Yeah, we didn't do that with Sprint. The court

1303
01:26:45,355 --> 01:26:48,955
Speaker 2:  literally said Sprint sucks so much, no one can fix it. T-Mobile can have

1304
01:26:48,955 --> 01:26:52,915
Speaker 2:  it. And to get around this problem, Macon de was the head of

1305
01:26:52,915 --> 01:26:56,835
Speaker 2:  antitrust at the time, brokered personally a deal by which

1306
01:26:57,115 --> 01:27:00,515
Speaker 2:  T-Mobile would get a bunch of Sprint and a bunch of Sprint Spectrum

1307
01:27:00,845 --> 01:27:04,695
Speaker 2:  would go to Dish Network, America's favorite satellite

1308
01:27:04,695 --> 01:27:07,815
Speaker 2:  TV service. And they would create a fourth wireless network, which

1309
01:27:08,475 --> 01:27:12,215
Speaker 2:  it has been 1 billion years. And which does not meaningfully

1310
01:27:12,215 --> 01:27:15,575
Speaker 2:  exist. There was a pilot network called Project Genis, which offered people

1311
01:27:16,045 --> 01:27:18,935
Speaker 2:  NFTs if they signed up for service on the Motorola Edge.

1312
01:27:20,655 --> 01:27:24,635
Speaker 2:  So that didn't work. Mostly there's been an NVNO, so they resell at

1313
01:27:24,635 --> 01:27:27,875
Speaker 2:  and t and T-Mobile service CL historically

1314
01:27:28,285 --> 01:27:32,075
Speaker 2:  successful plan to compete with at and t and T-Mobile. It's just

1315
01:27:32,075 --> 01:27:35,925
Speaker 2:  buying their service and reselling it for a fee that really hasn't

1316
01:27:36,085 --> 01:27:39,885
Speaker 2:  quaked in their boots. They have lit up some towers in some

1317
01:27:39,885 --> 01:27:43,445
Speaker 2:  cities. They've decided they're gonna let go of all the Gen five system stuff.

1318
01:27:43,445 --> 01:27:46,965
Speaker 2:  They're just gonna call it Boost Mobile, which is a brand that they acquired

1319
01:27:46,965 --> 01:27:50,155
Speaker 2:  in the thing. And now they say, they say

1320
01:27:51,235 --> 01:27:55,125
Speaker 2:  they have earned the title of mobile network operator.

1321
01:27:56,735 --> 01:27:58,035
Speaker 2:  That's their announcement

1322
01:27:58,575 --> 01:27:59,555
Speaker 3:  Con congrats

1323
01:28:00,855 --> 01:28:04,395
Speaker 2:  Rather than MVNO, which is mobile virtual network operator, which is what

1324
01:28:04,395 --> 01:28:06,435
Speaker 2:  you have to call yourself when you're just reselling other people's service.

1325
01:28:06,865 --> 01:28:08,515
Speaker 2:  They have earned the title

1326
01:28:10,305 --> 01:28:12,285
Speaker 2:  of mobile network operator, they're a real network now

1327
01:28:15,215 --> 01:28:18,155
Speaker 2:  by the end of the year needs to reach 80% of the people. They said, we are

1328
01:28:18,155 --> 01:28:21,795
Speaker 2:  well on the way to meeting this goal, they have lit up more than 20,000 of

1329
01:28:21,795 --> 01:28:25,315
Speaker 2:  the 24,000 cell sites. That's plum deployed by June, 2025.

1330
01:28:26,215 --> 01:28:28,635
Speaker 2:  But has anybody seen it?

1331
01:28:29,965 --> 01:28:30,465
Speaker 3:  Has anybody

1332
01:28:30,465 --> 01:28:30,865
Speaker 2:  Running

1333
01:28:30,865 --> 01:28:34,025
Speaker 3:  Ads? Yeah. Like do you have, do you have any friends who are on Boost?

1334
01:28:34,735 --> 01:28:35,345
Speaker 3:  Like has that,

1335
01:28:36,345 --> 01:28:38,465
Speaker 2:  I mean, people have friends who are on Boost, but they're just reusing at

1336
01:28:38,665 --> 01:28:42,385
Speaker 2:  t service. You go on the subreddits of Genesis or

1337
01:28:42,385 --> 01:28:46,345
Speaker 2:  Boost, it's not pretty. And in the meantime, by the

1338
01:28:46,345 --> 01:28:49,705
Speaker 2:  way, all, all the other three carriers, all they've done is raise their prices.

1339
01:28:50,285 --> 01:28:53,075
Speaker 3:  Yep. Yeah. I, all of the stuff that

1340
01:28:53,075 --> 01:28:54,475
Speaker 2:  Not meaningful competition in this market, all the

1341
01:28:54,475 --> 01:28:58,275
Speaker 3:  Stuff that I saw on Project Janis are basically like, if I stand right here,

1342
01:28:59,515 --> 01:29:03,125
Speaker 3:  I get the carrier that I think that I have. And if I'm literally

1343
01:29:03,445 --> 01:29:06,885
Speaker 3:  anywhere else on planet Earth, it's just at t like,

1344
01:29:07,375 --> 01:29:10,685
Speaker 3:  great, you just got like a slightly worse at t phone.

1345
01:29:11,215 --> 01:29:12,195
Speaker 3:  Congratulations.

1346
01:29:12,225 --> 01:29:16,115
Speaker 2:  It's a Motorola edge. You're killing it. We'll see,

1347
01:29:16,295 --> 01:29:20,285
Speaker 2:  you know, as as always, something will

1348
01:29:20,285 --> 01:29:23,405
Speaker 2:  happen. Time will relentlessly go by.

1349
01:29:23,645 --> 01:29:27,485
Speaker 3:  I mean, and you, you mentioned T-Mobile, but it is, it, it is possible to

1350
01:29:27,485 --> 01:29:31,405
Speaker 3:  do interesting things in this space. Like there, there, there was a time

1351
01:29:31,435 --> 01:29:34,845
Speaker 3:  when T-Mobile did the whole un-carrier bit and everything got purple and

1352
01:29:35,075 --> 01:29:38,325
Speaker 3:  John Lager was running around doing crazy stuff. Like there are

1353
01:29:39,365 --> 01:29:42,645
Speaker 3:  interesting moves you can make in this market. And there haven't been any

1354
01:29:42,645 --> 01:29:43,605
Speaker 3:  in a very long time.

1355
01:29:44,355 --> 01:29:44,645
Speaker 2:  Nope.

1356
01:29:45,065 --> 01:29:48,965
Speaker 3:  And I, I think it's, it's like I, I am hopeful for Boost

1357
01:29:49,525 --> 01:29:53,445
Speaker 3:  I would say I have precisely zero actual expectations of this

1358
01:29:53,445 --> 01:29:53,965
Speaker 3:  going anywhere.

1359
01:29:54,705 --> 01:29:58,635
Speaker 2:  And I will just point out that all they had to do was not let

1360
01:29:58,755 --> 01:30:01,595
Speaker 2:  T-Mobile buy Sprint. And so they brokered this complicated deal.

1361
01:30:04,505 --> 01:30:07,105
Speaker 2:  Why is T-Mobile cheaper?

1362
01:30:08,285 --> 01:30:11,295
Speaker 2:  Certainly isn't so, and by the way, T-Mobile promised that it wouldn't cut

1363
01:30:11,295 --> 01:30:15,195
Speaker 2:  any jobs immediately cut thousands of jobs. Yeah. We're just, we're entering

1364
01:30:15,195 --> 01:30:18,835
Speaker 2:  a period now where there, there will be more mergers. The Lena Con era

1365
01:30:18,975 --> 01:30:21,715
Speaker 2:  is, is over. Right. All that's gonna get turned over

1366
01:30:22,955 --> 01:30:26,805
Speaker 2:  already streaming. Like David Avv is like mergers are back. Yeah. Like

1367
01:30:27,225 --> 01:30:29,005
Speaker 2:  the net neutrality is gonna go away.

1368
01:30:30,545 --> 01:30:34,525
Speaker 2:  You can just see the, hey, should Verizon buy Paramount and bundle it

1369
01:30:34,525 --> 01:30:38,205
Speaker 2:  into its service? And throttle Disney is like, there's

1370
01:30:38,205 --> 01:30:42,045
Speaker 2:  accountants that just, just on their boats just staring off into

1371
01:30:42,045 --> 01:30:45,805
Speaker 2:  the sunset, dreaming up ways to raise prices and it's not gonna

1372
01:30:45,805 --> 01:30:49,205
Speaker 2:  result in faster service or more reliable service. No. Almost a guarantee.

1373
01:30:49,705 --> 01:30:51,725
Speaker 2:  You wanna know what the rich cast is gonna be about in the next four years.

1374
01:30:51,835 --> 01:30:54,405
Speaker 2:  It's just me ranting about cell carriers. Oh,

1375
01:30:54,465 --> 01:30:57,525
Speaker 3:  So the same as always. That's good. It's nice to know that some things don't

1376
01:30:57,525 --> 01:30:59,045
Speaker 3:  change. Even do these trying times

1377
01:31:00,495 --> 01:31:01,525
Speaker 2:  Three Michelin stars.

1378
01:31:01,635 --> 01:31:02,645
Speaker 3:  Yeah, exactly. All

1379
01:31:02,645 --> 01:31:03,485
Speaker 2:  Right, one more then we get to go.

1380
01:31:03,905 --> 01:31:07,765
Speaker 3:  All right. I just very briefly wanna pour one out for everyone's 11th

1381
01:31:08,085 --> 01:31:11,885
Speaker 3:  favorite streaming service freebie, which was

1382
01:31:12,085 --> 01:31:15,445
Speaker 3:  I believe once called IMDB free dive

1383
01:31:16,085 --> 01:31:19,485
Speaker 3:  I think. And then it was IMDB TV and then it was

1384
01:31:20,035 --> 01:31:23,645
Speaker 3:  free V and now it is dying and just everything is being

1385
01:31:23,645 --> 01:31:27,405
Speaker 3:  bundled into Prime video. This is not

1386
01:31:27,405 --> 01:31:30,405
Speaker 3:  going to be sad for very many people. I don't think free V was actually like

1387
01:31:30,405 --> 01:31:34,365
Speaker 3:  a sneakily pretty good, pretty light app. So I'm sad to not

1388
01:31:34,445 --> 01:31:35,325
Speaker 3:  be able to use it anymore.

1389
01:31:35,435 --> 01:31:36,965
Speaker 2:  Doesn't they do jury duty? They

1390
01:31:36,965 --> 01:31:40,765
Speaker 3:  Did do jury duty, which was wonderful. And I actually think jury duty

1391
01:31:40,785 --> 01:31:43,605
Speaker 3:  is sort of funny because there's all these, we've talked a lot about the

1392
01:31:43,605 --> 01:31:47,525
Speaker 3:  fast channels and the, the sort of rise of ad supported streaming and

1393
01:31:48,495 --> 01:31:52,265
Speaker 3:  jury duty is kind of the only giant

1394
01:31:52,785 --> 01:31:56,505
Speaker 3:  breakout hit to ever come out of one of these services. Like

1395
01:31:56,605 --> 01:31:59,485
Speaker 3:  you look at the, the Roku channels had a few, they had the, the weird Al

1396
01:31:59,485 --> 01:32:03,325
Speaker 3:  Yankovic movie that was like kind of around Tuby is

1397
01:32:03,325 --> 01:32:06,765
Speaker 3:  doing stuff. Pluto is doing stuff like this. This Fast universe is growing

1398
01:32:06,765 --> 01:32:10,565
Speaker 3:  really quickly, but the huge sort of

1399
01:32:10,575 --> 01:32:14,285
Speaker 3:  mainstream content has not really happened. And I think If, you look at

1400
01:32:14,285 --> 01:32:18,245
Speaker 3:  Amazon, Amazon is all in on ads. And I think this is the thing that

1401
01:32:18,245 --> 01:32:21,805
Speaker 3:  is really starting to happen is the ad business in streaming is

1402
01:32:21,915 --> 01:32:25,845
Speaker 3:  turning really fast now. Netflix is now two years

1403
01:32:25,875 --> 01:32:29,565
Speaker 3:  into it and it's growing pretty quickly. Hulu is doing really well.

1404
01:32:29,745 --> 01:32:33,245
Speaker 3:  And so Disney and ESPN is starting to catch up. Like the ad

1405
01:32:33,315 --> 01:32:37,245
Speaker 3:  supported streaming universe is here

1406
01:32:37,425 --> 01:32:41,325
Speaker 3:  in a big way. And I think Amazon was it earlier this year turned

1407
01:32:41,345 --> 01:32:45,085
Speaker 3:  on the thing where now it's ads by default unless you pay more. And

1408
01:32:45,465 --> 01:32:48,845
Speaker 3:  now it's bringing all this free stuff in to give people more stuff to watch

1409
01:32:48,845 --> 01:32:52,365
Speaker 3:  with those ads inside a prime video. Like this is the future

1410
01:32:52,945 --> 01:32:56,765
Speaker 3:  and we're gonna go back to big giant libraries. Mostly stuff you

1411
01:32:56,765 --> 01:32:59,725
Speaker 3:  don't wanna watch because they're just trying to turn

