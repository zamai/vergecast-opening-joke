1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 5270b00a-6bf3-4604-a17e-091a361d796f
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/5958848496846593825/3189816373527604054/s93290-US-3918s-1712648988.mp3
Description: The Verge’s David Pierce, Nilay Patel, and Alex Cranz answer questions from The Vergecast Hotline all about the TikTok ban debate and the US v Apple case. 

2
00:00:02,675 --> 00:00:06,645
Speaker 2:  Welcome To The Vergecast, the flagship podcast of Super App Regulation. I'm

3
00:00:06,645 --> 00:00:09,925
Speaker 2:  your friend David Pierce and I am what I would call

4
00:00:10,235 --> 00:00:13,925
Speaker 2:  desperately on a hunt for solar eclipse classes. It's Monday morning,

5
00:00:14,075 --> 00:00:17,845
Speaker 2:  it's like three and a half, four hours until the eclipse and like a

6
00:00:17,845 --> 00:00:21,365
Speaker 2:  super genius planner that I am just didn't go get eclipse glasses.

7
00:00:21,805 --> 00:00:25,525
Speaker 2:  I think I sort of thought that sunglasses would work. Turns out that is not

8
00:00:25,525 --> 00:00:29,205
Speaker 2:  correct and terrible science and you should not listen to me about

9
00:00:29,485 --> 00:00:32,485
Speaker 2:  anything to do with the eclipse. So now I'm running around trying desperately

10
00:00:32,485 --> 00:00:36,445
Speaker 2:  to get glasses and so far it's not happening. Target was out. Staples had

11
00:00:36,445 --> 00:00:39,925
Speaker 2:  a sign on the door that clearly somebody had just like hastily printed basically

12
00:00:39,925 --> 00:00:43,685
Speaker 2:  saying like, leave us alone. We don't have any eclipse glasses. I'm now

13
00:00:43,685 --> 00:00:47,125
Speaker 2:  going to every sort I can think of, including some that just obviously won't

14
00:00:47,125 --> 00:00:51,005
Speaker 2:  have Eclipse glasses trying to convince someone to sell me these

15
00:00:51,005 --> 00:00:54,765
Speaker 2:  glasses. I have realized I will pay what amounts to an alarming amount of

16
00:00:54,765 --> 00:00:58,685
Speaker 2:  money for these glasses, but I don't think it's gonna happen. Anyway, we

17
00:00:58,685 --> 00:01:01,525
Speaker 2:  have an awesome show coming up for you today. I was in New York last week

18
00:01:01,625 --> 00:01:05,405
Speaker 2:  and took the opportunity of all being in the same city to drag NELI into

19
00:01:05,405 --> 00:01:09,205
Speaker 2:  the studio and grab Alex and just talk about TikTok

20
00:01:09,505 --> 00:01:12,445
Speaker 2:  and Apple and all of the stuff that's been happening over the last couple

21
00:01:12,445 --> 00:01:16,045
Speaker 2:  of weeks. We've talked a lot about the TikTok Pan and Apple Antitrust and

22
00:01:16,045 --> 00:01:19,525
Speaker 2:  we've heard a ton from you. Questions you have for us, thoughts you have

23
00:01:19,525 --> 00:01:23,005
Speaker 2:  about the things that we think, feelings you have about all of what's going

24
00:01:23,005 --> 00:01:26,005
Speaker 2:  on. And we figured we'd just spend an hour talking about it. We got a bunch

25
00:01:26,005 --> 00:01:28,565
Speaker 2:  of really great emails and a bunch of really great Hotline questions and

26
00:01:28,565 --> 00:01:31,445
Speaker 2:  so that's what this whole show is. It was really fun, I really enjoyed it.

27
00:01:31,665 --> 00:01:35,605
Speaker 2:  It got deep and kind of emotional at times in a

28
00:01:35,605 --> 00:01:39,405
Speaker 2:  really interesting way as all of this Apple Antitrust and TikTok band

29
00:01:39,685 --> 00:01:43,565
Speaker 2:  specifically stuff tends to do. Super fun, really awesome show. All of

30
00:01:43,565 --> 00:01:47,405
Speaker 2:  that is coming up in just a second, but like I said, I have three and a half

31
00:01:47,405 --> 00:01:51,045
Speaker 2:  hours to get some eclipse glasses. It's probably not gonna happen, but wish

32
00:01:51,045 --> 00:01:53,565
Speaker 2:  me luck. Anyway, this is The Vergecast. We'll be right back.

33
00:02:59,005 --> 00:03:01,805
Speaker 2:  two things that we've talked about on the show the last couple of weeks.

34
00:03:01,805 --> 00:03:05,085
Speaker 2:  So we're just gonna dive into a bunch of it. Nilay Patel here. Hi NELI. Hello

35
00:03:05,195 --> 00:03:09,045
Speaker 2:  Alex. Cranz also here. Hey, what's up? Neela and I are in this small studio

36
00:03:09,045 --> 00:03:10,565
Speaker 2:  that I've never been in before. It's very exciting.

37
00:03:10,565 --> 00:03:13,205
Speaker 5:  There's a frame TV in here I wanna point out it's, I'm

38
00:03:13,205 --> 00:03:15,285
Speaker 2:  Not gonna, we're not we a lot. We have a lot to get.

39
00:03:15,505 --> 00:03:17,245
Speaker 5:  I'm just letting you know thoughts. The

40
00:03:17,245 --> 00:03:20,485
Speaker 2:  Two things we're gonna talk mostly about here are the Apple Antitrust stuff,

41
00:03:20,485 --> 00:03:23,525
Speaker 2:  which we talked a lot about and the TikTok ban. We're gonna do Apple first,

42
00:03:23,555 --> 00:03:26,405
Speaker 2:  then we're gonna take a break, then we're gonna talk TikTok and we got a

43
00:03:26,485 --> 00:03:30,005
Speaker 2:  ton of feedback. So what I tried to do was find Hotline voicemails from people

44
00:03:30,005 --> 00:03:33,965
Speaker 2:  that were like roughly representative of the feedback. So some of them

45
00:03:34,155 --> 00:03:37,165
Speaker 2:  have questions that we should ask specifically. Some of them are just kind

46
00:03:37,165 --> 00:03:40,765
Speaker 2:  of points a lot of people made that we should talk about. We have three for

47
00:03:40,765 --> 00:03:43,605
Speaker 2:  Apple and four for TikTok. This is going to take us four hours.

48
00:03:44,495 --> 00:03:46,925
Speaker 2:  Let's go. All right, the first voicemail we got is from Harrison.

49
00:03:48,065 --> 00:03:52,005
Speaker 6:  Hi David and B Crew. My name is Harrison. I have a question

50
00:03:52,005 --> 00:03:55,925
Speaker 6:  about the Apple DOJ case. What I'm trying to

51
00:03:55,925 --> 00:03:59,525
Speaker 6:  understand is why people are going after

52
00:03:59,655 --> 00:04:03,285
Speaker 6:  Apple specifically. Apple has 60% market share in the

53
00:04:03,285 --> 00:04:07,245
Speaker 6:  United States and people like to say that like iMessage is a lock in or that

54
00:04:07,245 --> 00:04:11,125
Speaker 6:  green bubble envy is a thing, which it totally is, but I feel

55
00:04:11,125 --> 00:04:14,885
Speaker 6:  like people are getting upset that Apple like won

56
00:04:14,935 --> 00:04:18,605
Speaker 6:  capitalism. It feels like they made a product that won based off of

57
00:04:18,605 --> 00:04:22,565
Speaker 6:  popularity and not necessity because we all use SMS and then

58
00:04:22,565 --> 00:04:26,525
Speaker 6:  iMessage is built on top of that. It kind of feels like trying to force

59
00:04:26,575 --> 00:04:30,565
Speaker 6:  Apple to be, to open that up or to open other parts of the iOS

60
00:04:30,565 --> 00:04:34,005
Speaker 6:  experience up. It would be kind of like making it so

61
00:04:34,395 --> 00:04:38,205
Speaker 6:  Sony has to put God of war on the Xbox or that like I

62
00:04:38,205 --> 00:04:41,845
Speaker 6:  have to be able to put the brake pads from a Honda Accord onto

63
00:04:42,485 --> 00:04:45,485
Speaker 6:  a Hyundai Tucson or something. It, it feels like we're just trying to like

64
00:04:45,485 --> 00:04:49,205
Speaker 6:  create an argument for the sake of an argument. I would just genuinely like

65
00:04:49,205 --> 00:04:52,845
Speaker 6:  to know what is it about this case with Apple

66
00:04:52,955 --> 00:04:56,725
Speaker 6:  that makes it a bigger deal in Antitrust than something like Amazon Web

67
00:04:56,965 --> 00:05:00,565
Speaker 6:  Services and Amazon storefronts or Google with Gmail

68
00:05:00,985 --> 00:05:04,165
Speaker 6:  or search I guess. Thank you. Have the rest of your day. Bye.

69
00:05:04,715 --> 00:05:07,445
Speaker 2:  Okay, so I wanna reframe this question very slightly before we get into it

70
00:05:07,445 --> 00:05:10,365
Speaker 2:  because there is a part of this premise that I disagree with, which is that

71
00:05:10,365 --> 00:05:13,605
Speaker 2:  we're only going after Apple because there is Antitrust action against all

72
00:05:13,605 --> 00:05:17,565
Speaker 2:  of these companies. But the reason I picked this one is because I would say

73
00:05:17,565 --> 00:05:21,245
Speaker 2:  the most consistent piece of feedback we got was that

74
00:05:21,555 --> 00:05:25,485
Speaker 2:  this is just the DOJ picking on Apple for being too successful and,

75
00:05:25,545 --> 00:05:28,965
Speaker 2:  and that what is this fight if not just trying to turn Apple into Android

76
00:05:28,965 --> 00:05:32,405
Speaker 2:  or make it worse and why are we mad at Apple for being so successful? So

77
00:05:32,405 --> 00:05:35,365
Speaker 2:  I figure that is a thing we should address here that this question is also

78
00:05:35,365 --> 00:05:38,325
Speaker 2:  very much about. So NELI you, you were nodding through this whole question.

79
00:05:38,325 --> 00:05:38,725
Speaker 2:  What do you think?

80
00:05:38,955 --> 00:05:42,805
Speaker 5:  Yeah, I think those are, those are good points. I agree with you David If,

81
00:05:42,805 --> 00:05:46,725
Speaker 5:  you look at the landscape of Antitrust actions, the

82
00:05:46,725 --> 00:05:49,565
Speaker 5:  governments around the world are going after all these companies just all

83
00:05:49,565 --> 00:05:51,805
Speaker 5:  over the place. Yeah. So there's that. They'll just set that aside

84
00:05:51,955 --> 00:05:55,765
Speaker 2:  Including explicitly Amazon storefront and Google search. Yeah. Like this

85
00:05:55,765 --> 00:05:59,245
Speaker 2:  is the, all that stuff is in this in a very real way.

86
00:05:59,395 --> 00:06:02,805
Speaker 5:  Yeah. And then I want to just focus on two words. Winning capitalism.

87
00:06:04,825 --> 00:06:08,725
Speaker 5:  I'm a capitalist. Pretty unrepentant. So I think, I think

88
00:06:08,725 --> 00:06:11,445
Speaker 5:  you should win capitalism. I think you should try really hard. I I think

89
00:06:11,445 --> 00:06:15,405
Speaker 5:  that's a good, I think that works. The problem is you have to have a

90
00:06:15,605 --> 00:06:19,335
Speaker 5:  functional market for other people to try to win. And so that these cases

91
00:06:19,435 --> 00:06:23,375
Speaker 5:  are all premised on, once you've won in one place, you shouldn't

92
00:06:23,375 --> 00:06:26,495
Speaker 5:  be able to take that power and prevent anyone from winning in another place.

93
00:06:26,995 --> 00:06:30,815
Speaker 5:  And I think in particular with the iPhone Apple's

94
00:06:30,995 --> 00:06:34,775
Speaker 5:  desire for control or desire for quality or desire

95
00:06:34,915 --> 00:06:38,215
Speaker 5:  for fees, you pick and choose in what order

96
00:06:38,485 --> 00:06:42,295
Speaker 5:  they're in the equation and how they're weighted desire for services. Revenue

97
00:06:42,795 --> 00:06:46,695
Speaker 5:  has precluded a bunch of other kinds of businesses from existing and

98
00:06:46,695 --> 00:06:50,215
Speaker 5:  competing with Apple. And that's actually the problem, right? It's that you

99
00:06:50,215 --> 00:06:54,015
Speaker 5:  get these companies that have a monopoly in one area and maybe they've

100
00:06:54,015 --> 00:06:57,135
Speaker 5:  earned it. I think iPhones are really good phones. I think their cameras

101
00:06:57,155 --> 00:07:00,055
Speaker 5:  are really good. Like all the stuff, I think they've earned that stuff. And

102
00:07:00,055 --> 00:07:04,015
Speaker 5:  then you take that and you say, and now we will make sure that no

103
00:07:04,015 --> 00:07:07,335
Speaker 5:  one else can compete in another area or we will make sure that we have an

104
00:07:07,335 --> 00:07:11,135
Speaker 5:  advantage in some other area that is unrelated to where we won.

105
00:07:11,555 --> 00:07:14,655
Speaker 5:  And I think that's the part where If, you want a functional

106
00:07:14,935 --> 00:07:18,895
Speaker 5:  capitalistic market. You have to have markets, right? People have to be

107
00:07:18,895 --> 00:07:22,615
Speaker 5:  able to pick and choose freely and vote with their dollars, which I

108
00:07:22,615 --> 00:07:26,135
Speaker 5:  believe is more efficient than like voting for politicians in

109
00:07:26,135 --> 00:07:30,015
Speaker 5:  centralized control structures. Like I, I, I would rather vote with

110
00:07:30,015 --> 00:07:33,535
Speaker 5:  my dollars than vote for politicians. Like that's just a, a thing that I

111
00:07:33,535 --> 00:07:36,775
Speaker 5:  believe. And so you just look at the iPhone and you're like, oh, it's actually

112
00:07:36,775 --> 00:07:39,535
Speaker 5:  pretty hard to vote with your dollars here. Is it pretty hard to vote with

113
00:07:39,535 --> 00:07:43,375
Speaker 5:  your time? And if Apple doesn't want that to exist, it just doesn't. And

114
00:07:43,375 --> 00:07:46,495
Speaker 5:  I think that's the heart of these cases and I think it gets lost. When I

115
00:07:46,495 --> 00:07:50,415
Speaker 5:  interviewed Jonathan Cantor on Decoder, he made

116
00:07:50,455 --> 00:07:54,335
Speaker 5:  a point of saying there is more interest in Antitrust by young people

117
00:07:54,335 --> 00:07:57,895
Speaker 5:  than there ever has been before. Hmm. Because people can feel that their

118
00:07:57,895 --> 00:08:01,255
Speaker 5:  options are being limited by a handful of big companies across the entire

119
00:08:01,765 --> 00:08:04,335
Speaker 5:  like economy. And that's, that's the heart of it.

120
00:08:04,485 --> 00:08:08,295
Speaker 2:  Yeah. It seems to me that thinking about this one compared to Amazon

121
00:08:08,295 --> 00:08:11,935
Speaker 2:  and Google, I actually feel like I can explain that tension very easily

122
00:08:12,085 --> 00:08:15,935
Speaker 2:  with Amazon and Google because there is sort of one specific thing, right?

123
00:08:15,935 --> 00:08:19,015
Speaker 2:  With Google it's, we built a very successful search engine. It is not illegal

124
00:08:19,155 --> 00:08:23,015
Speaker 2:  to win. But then what Google did is use all the money that it made

125
00:08:23,015 --> 00:08:26,975
Speaker 2:  from said successful search engine to basically buy all the real

126
00:08:26,975 --> 00:08:29,335
Speaker 2:  estate on the internet so that no one else could have a successful search

127
00:08:29,335 --> 00:08:32,335
Speaker 2:  engine. At least that is the allegation, right? Whether that will win or

128
00:08:32,335 --> 00:08:34,975
Speaker 2:  not, I don't know. But that is at least sort of a straightforward version

129
00:08:34,975 --> 00:08:37,975
Speaker 2:  of the thing you're talking about the thing that Amazon allegedly did where

130
00:08:38,035 --> 00:08:41,855
Speaker 2:  it would crawl the web to find sellers who were selling stuff cheaper

131
00:08:41,995 --> 00:08:45,855
Speaker 2:  off of Amazon and then ruthlessly penalize those people on Amazon. Same

132
00:08:45,855 --> 00:08:49,095
Speaker 2:  thing, right? That is you created a big market and then you used it to punish

133
00:08:49,095 --> 00:08:52,375
Speaker 2:  everybody who played elsewhere. I don't know that there is one thing that

134
00:08:52,375 --> 00:08:56,245
Speaker 2:  feels as obvious to me in the Apple suit that we've seen so far.

135
00:08:56,345 --> 00:08:58,885
Speaker 2:  Is there one that you can point to that feels kind of, 'cause I think this

136
00:08:58,885 --> 00:09:02,485
Speaker 2:  is part of what people are responding to and Alex, I'm curious how you feel

137
00:09:02,485 --> 00:09:05,685
Speaker 2:  about this too. 'cause it seems like, yeah, the Apple thing is about sort

138
00:09:05,685 --> 00:09:08,925
Speaker 2:  of so many things and I think to some extent, and Alex, we talked about this

139
00:09:08,925 --> 00:09:12,005
Speaker 2:  on the show, the wallet one feels to me like maybe the most straightforward

140
00:09:12,005 --> 00:09:15,165
Speaker 2:  version of this where like Apple built a thing and then didn't allow anybody

141
00:09:15,165 --> 00:09:17,805
Speaker 2:  else to build said thing. That is a version of the thing. I

142
00:09:17,885 --> 00:09:21,645
Speaker 7:  I think it's, it's both about protecting markets and and allowing

143
00:09:21,645 --> 00:09:24,725
Speaker 7:  markets to exist, right? Like, like part of this case is saying Apple has

144
00:09:24,755 --> 00:09:28,525
Speaker 7:  said these markets cannot exist. And the other part of it is that

145
00:09:28,935 --> 00:09:32,885
Speaker 7:  Apple has made the experience for consumers fundamentally

146
00:09:32,885 --> 00:09:36,445
Speaker 7:  worse. And it has such a large market share that that worse is now

147
00:09:36,475 --> 00:09:40,325
Speaker 7:  impacting people in a really real and measurable way. And

148
00:09:40,325 --> 00:09:42,885
Speaker 7:  that's the part I think about the most. 'cause I think, I think NELI is right,

149
00:09:42,885 --> 00:09:45,685
Speaker 7:  right? Like they went in and they said, okay, you can't have these markets

150
00:09:45,835 --> 00:09:48,885
Speaker 7:  like If, you wanna have cloud gaming. It cannot exist on this, which means

151
00:09:48,895 --> 00:09:52,765
Speaker 7:  60% of Americans cannot have this unless they choose

152
00:09:52,765 --> 00:09:56,005
Speaker 7:  to vote with their dollars elsewhere. But all this lock-in is keeping them

153
00:09:56,005 --> 00:09:59,805
Speaker 7:  from doing that. And then the other part of that is If, you wanna send

154
00:09:59,885 --> 00:10:03,765
Speaker 7:  a message to your mom with a photo in it. That photo is now

155
00:10:03,765 --> 00:10:07,205
Speaker 7:  degraded because Apple has willingly chosen to degrade its services

156
00:10:07,745 --> 00:10:11,685
Speaker 7:  to keep people locked in. And those two things are like both existing

157
00:10:11,705 --> 00:10:15,565
Speaker 7:  at once. So it's like Apple won at capitalism and then made everything

158
00:10:15,655 --> 00:10:19,445
Speaker 7:  worse as like a victory lap is kind of part of this

159
00:10:19,445 --> 00:10:23,405
Speaker 7:  case. And that part I'm like, yeah, I mean maybe that

160
00:10:23,405 --> 00:10:26,325
Speaker 7:  should be illegal. Maybe that shouldn't be a thing that's happening. And

161
00:10:26,325 --> 00:10:29,365
Speaker 7:  that's a tension of the case, right? That the tension of the case is like,

162
00:10:29,385 --> 00:10:33,205
Speaker 7:  is that allowed? And I think that's where it becomes almost like a philosophical

163
00:10:33,565 --> 00:10:36,485
Speaker 7:  argument of like, should that be allowed? And I'm on the ca, like I love

164
00:10:36,685 --> 00:10:39,525
Speaker 7:  consumers, I wanna help consumers. That's my job as a consumer technology

165
00:10:39,845 --> 00:10:42,525
Speaker 7:  reporter. I wanna make sure that they're protected. And so I'm like, yeah,

166
00:10:42,545 --> 00:10:46,485
Speaker 7:  we shouldn't make things measurably worse just because we win at capitalism.

167
00:10:46,665 --> 00:10:49,365
Speaker 7:  And a lot of people are like, yeah but you win at capitalism, you get to

168
00:10:49,365 --> 00:10:49,805
Speaker 7:  do what you want.

169
00:10:50,115 --> 00:10:53,485
Speaker 5:  Yeah. By the way, this is like a tension of the American economy dating back

170
00:10:53,685 --> 00:10:57,085
Speaker 5:  a hundred years or or more, right? Right. Like the reason called

171
00:10:57,645 --> 00:10:57,925
Speaker 2:  Railroads.

172
00:10:57,995 --> 00:11:00,765
Speaker 5:  Yeah. Like the reason it's called Antitrust is because there was a form of

173
00:11:01,005 --> 00:11:04,645
Speaker 5:  business that called trusts and we like knocked them all down and built

174
00:11:04,645 --> 00:11:08,205
Speaker 5:  Antitrust law. I highly recommend reading The Curse of Bigness by Tim Wu,

175
00:11:08,215 --> 00:11:11,925
Speaker 5:  which is a little, it's like a booklet. It's not, it is not even long. It's

176
00:11:11,925 --> 00:11:15,365
Speaker 5:  just like a fun readable history of Antitrust. But this is the idea is that

177
00:11:15,365 --> 00:11:19,125
Speaker 5:  you should have competition in our market and If, you don't

178
00:11:19,125 --> 00:11:22,685
Speaker 5:  protect the competition in our market. Then you're gonna end up with a handful

179
00:11:22,685 --> 00:11:25,725
Speaker 5:  of big companies that run everything and they will not be as good for you.

180
00:11:26,105 --> 00:11:30,045
Speaker 5:  And by the way, I think a bunch of big companies in our markets right now

181
00:11:30,055 --> 00:11:34,045
Speaker 5:  would love to be regulated monopolies like just up and down. Yeah, they

182
00:11:34,045 --> 00:11:37,245
Speaker 5:  would love it. Facebook would love to be a regulated monopoly and be in charge

183
00:11:37,245 --> 00:11:39,845
Speaker 5:  of everything and make all the money and not have to compete. That just,

184
00:11:39,885 --> 00:11:43,725
Speaker 5:  I, I don't know. It feels sicky to me. I think with the iPhone in particular,

185
00:11:43,725 --> 00:11:45,965
Speaker 5:  you're right, it's like hard to point at one thing. But I'll give you one

186
00:11:45,965 --> 00:11:49,565
Speaker 5:  example. Sure. There are ads in the setting screen. Mm, that's brutal.

187
00:11:49,585 --> 00:11:53,085
Speaker 5:  That's a good one. That's brutal, right? And it's like that's just the clearest

188
00:11:53,205 --> 00:11:56,965
Speaker 5:  self referencing that anyone can do. And it's like this sucks.

189
00:11:57,035 --> 00:12:01,005
Speaker 5:  Like fine, okay put ads in the setting screen but at least let

190
00:12:01,005 --> 00:12:04,925
Speaker 5:  other competitor apps have as much access to the phone. It should not

191
00:12:04,925 --> 00:12:08,165
Speaker 5:  be that because I picked an operating system one time or I preferred one

192
00:12:08,165 --> 00:12:12,045
Speaker 5:  camera that all of these other choices down the line get

193
00:12:12,045 --> 00:12:15,325
Speaker 5:  made from me by some corporation that wants to extract 30%. I just don't

194
00:12:15,325 --> 00:12:18,765
Speaker 5:  I that feels icky. Like ah, it's my money stay, stay away from it.

195
00:12:19,035 --> 00:12:22,325
Speaker 2:  Okay. What a truly perfect segue. That just was into question number two

196
00:12:22,325 --> 00:12:25,005
Speaker 2:  because there's more we should talk about on that point. But this next question

197
00:12:25,035 --> 00:12:27,765
Speaker 2:  basically asks it directly. It's from Josiah.

198
00:12:28,985 --> 00:12:32,805
Speaker 8:  Hi David. My name is Josiah and I of course have a question about the

199
00:12:32,965 --> 00:12:36,325
Speaker 8:  DOJ versus Apple situation. A lot of the stuff in that

200
00:12:36,765 --> 00:12:40,725
Speaker 8:  complaint is about like Apple forcing companies to do things either the Apple

201
00:12:40,785 --> 00:12:44,485
Speaker 8:  way or just not at all. And I feel like that is an area where

202
00:12:44,615 --> 00:12:48,605
Speaker 8:  Apple being the bully to these other companies does result in a

203
00:12:48,605 --> 00:12:52,405
Speaker 8:  lot of benefits for me as a user. The nightmare scenario is like thinking

204
00:12:52,405 --> 00:12:56,205
Speaker 8:  about the wallet and NFC access and obviously opening that up has

205
00:12:56,205 --> 00:12:59,485
Speaker 8:  the intent of creating a bunch of different competitors that have better

206
00:12:59,885 --> 00:13:03,085
Speaker 8:  features and then that requires Apple to make their thing better. And I would

207
00:13:03,085 --> 00:13:06,765
Speaker 8:  love to live in that world. But far more realistically, I feel like the world

208
00:13:06,845 --> 00:13:10,245
Speaker 8:  we live in is one where the second the court says Apple

209
00:13:10,675 --> 00:13:14,605
Speaker 8:  exclusively can't lock users in, then every other

210
00:13:14,605 --> 00:13:17,605
Speaker 8:  company is just going to say, oh cool. And they're gonna remove their card

211
00:13:17,605 --> 00:13:20,765
Speaker 8:  from the Apple like wallet and they're going to make their own wallet and

212
00:13:20,765 --> 00:13:23,805
Speaker 8:  then they're going to make me use exclusively their wallet to use their thing.

213
00:13:24,265 --> 00:13:28,005
Speaker 8:  And that's hell because then all of a sudden I have my Amazon

214
00:13:28,005 --> 00:13:31,965
Speaker 8:  card is in my Apple wallet and then my Delta tickets and my Sky

215
00:13:31,965 --> 00:13:35,845
Speaker 8:  Miles card are in my Delta exclusive wallet. And how does that not

216
00:13:35,845 --> 00:13:39,805
Speaker 8:  just like result in a worse experience for everybody on the backend? Like

217
00:13:39,805 --> 00:13:43,685
Speaker 8:  how can we force Apple to open up? Is there

218
00:13:43,685 --> 00:13:47,285
Speaker 8:  a way to force Apple to open up that doesn't just allow all these other

219
00:13:47,605 --> 00:13:50,965
Speaker 8:  companies to be like, Ooh, apple can't be the monopoly, so I would like to

220
00:13:51,105 --> 00:13:55,045
Speaker 8:  and then lock everybody else out of their new thing. Is that

221
00:13:55,605 --> 00:13:59,325
Speaker 8:  possible or is by forcing people to open up, we're going to inevitably

222
00:14:00,205 --> 00:14:03,685
Speaker 8:  struggle with interoperability. Thanks. Hopefully it wasn't too long.

223
00:14:04,485 --> 00:14:08,445
Speaker 7:  I got an answer for this one. So I think it is down to the

224
00:14:08,445 --> 00:14:11,445
Speaker 7:  idea of capitalism is that competition would happen. The idea of capitalism

225
00:14:11,465 --> 00:14:15,205
Speaker 7:  is that Apple would say, okay, other people can make their their wallets

226
00:14:15,465 --> 00:14:19,285
Speaker 7:  and they can, they can now do this as well. And then Apple has to make sure

227
00:14:19,285 --> 00:14:22,765
Speaker 7:  their wallet is the best wallet and and force people to, like Netflix

228
00:14:23,105 --> 00:14:25,805
Speaker 7:  was an example of this, right? Hulu were example of this. They were, they

229
00:14:25,805 --> 00:14:28,525
Speaker 7:  were early movers in these fields and they said, okay, we're gonna be the

230
00:14:28,525 --> 00:14:31,485
Speaker 7:  best and everybody else is gonna come work with us. And if they don't work

231
00:14:31,485 --> 00:14:35,405
Speaker 7:  with us then their product is gonna be measurably shittier, IE

232
00:14:35,405 --> 00:14:39,125
Speaker 7:  Paramount plus. And and that's what, that's what's gonna happen. And,

233
00:14:39,305 --> 00:14:43,045
Speaker 7:  and that theoretically is what would happen in this case too, right?

234
00:14:43,045 --> 00:14:46,805
Speaker 7:  Chase may say, okay, we're gonna go make our wallet app and not use Apples

235
00:14:46,805 --> 00:14:50,485
Speaker 7:  anymore. And if their wallet app is worse, then people might be like, well

236
00:14:50,485 --> 00:14:54,245
Speaker 7:  it's not that hard for me to move over to Bank of America or Wells Fargo

237
00:14:54,245 --> 00:14:57,405
Speaker 7:  or whatever. I'm just gonna move my business over there because I need the

238
00:14:57,565 --> 00:14:59,365
Speaker 7:  convenience of this other product that's much better.

239
00:14:59,905 --> 00:15:03,685
Speaker 2:  So having just switched banks, I take unbelievable offense to that

240
00:15:03,685 --> 00:15:07,365
Speaker 2:  premise that switching banks, this is, this is one of the things this

241
00:15:07,845 --> 00:15:10,925
Speaker 2:  question made me think about is like maybe where we're headed is we're about

242
00:15:10,925 --> 00:15:14,245
Speaker 2:  to realize lock-in is more real more places than anybody has reckoned with.

243
00:15:14,505 --> 00:15:17,205
Speaker 2:  And actually what we're doing is we're starting down this like incredible

244
00:15:17,515 --> 00:15:21,325
Speaker 2:  hill of trying to get out of the holes that we've dug ourselves into

245
00:15:21,325 --> 00:15:23,965
Speaker 2:  over the years. but don don't know Neil. What do you, what do you make of

246
00:15:23,965 --> 00:15:24,805
Speaker 2:  this question? So

247
00:15:25,125 --> 00:15:27,245
Speaker 5:  Specifically with wallets, I have an answer. Okay. And then, and then we

248
00:15:27,245 --> 00:15:30,885
Speaker 5:  can abstract it with wallets. Everybody wants your credit card to be everywhere.

249
00:15:31,035 --> 00:15:34,965
Speaker 5:  There's no incentive for anyone to make you use a different wallet app.

250
00:15:35,305 --> 00:15:38,005
Speaker 5:  The incentive is for your credit card to be everywhere, right?

251
00:15:38,005 --> 00:15:38,725
Speaker 2:  Because they want you to

252
00:15:38,725 --> 00:15:40,525
Speaker 5:  Use your credit card, they want you to use your credit card. And you can

253
00:15:40,525 --> 00:15:44,325
Speaker 5:  see this play out on the web already where every storefront has like

254
00:15:44,635 --> 00:15:48,205
Speaker 5:  15 payment service buttons. Like that is true. Do you wanna use shop pay?

255
00:15:48,205 --> 00:15:51,645
Speaker 5:  Do you wanna use Google Pay, Amazon Pay Apple, like whatever. Just pay us,

256
00:15:51,715 --> 00:15:52,445
Speaker 5:  like pay us the money.

257
00:15:52,505 --> 00:15:55,165
Speaker 2:  PayPal and Venmo, which are the same company, they're like, we don't care.

258
00:15:55,165 --> 00:15:56,365
Speaker 2:  Just do any, just do something

259
00:15:56,625 --> 00:15:59,445
Speaker 5:  Any way to get your money. They'll do it. So the incentive at least for that

260
00:15:59,445 --> 00:16:03,285
Speaker 5:  one is for payment services to make it easy for you to spend

261
00:16:03,285 --> 00:16:07,125
Speaker 5:  money. So I think that one will be fine. I think there are other ones

262
00:16:07,655 --> 00:16:11,445
Speaker 5:  where the incentives will be get over here and we'll lock you in in other

263
00:16:11,445 --> 00:16:15,405
Speaker 5:  ways. What I'm hopeful for is that yep, we'll all

264
00:16:15,645 --> 00:16:19,125
Speaker 5:  perceive that and that'll be annoying in some ways. But then over time that

265
00:16:19,125 --> 00:16:22,765
Speaker 5:  annoyance will actually reduce how much people use some of these services

266
00:16:22,825 --> 00:16:26,725
Speaker 5:  or the switching costs will be obvious. Alex brought up Netflix. I think

267
00:16:26,725 --> 00:16:30,685
Speaker 5:  we've all gone through this now in the streaming example where every

268
00:16:30,685 --> 00:16:33,285
Speaker 5:  streamer was like, we have these exclusives music services. We were like,

269
00:16:33,285 --> 00:16:37,005
Speaker 5:  we have these exclusives. And then people are like, but I don't care.

270
00:16:37,115 --> 00:16:40,445
Speaker 5:  Like whatever. And then like most of the streaming companies have gotten

271
00:16:40,445 --> 00:16:44,165
Speaker 5:  90 and put their stuff on Netflix. Like I think the economy should wax and

272
00:16:44,195 --> 00:16:48,125
Speaker 5:  wane in these ways. And I think right now it can't.

273
00:16:48,425 --> 00:16:51,925
Speaker 5:  It can't because you picked an operating system, which is weird. Like I,

274
00:16:52,105 --> 00:16:53,845
Speaker 5:  that's too many decisions to give away.

275
00:16:54,195 --> 00:16:58,005
Speaker 2:  Okay. Yeah. Yeah. I mean I think I buy the premise to some extent that If,

276
00:16:58,005 --> 00:17:01,965
Speaker 2:  you give everybody access to everything. You suddenly

277
00:17:01,995 --> 00:17:05,325
Speaker 2:  will get a thousand ads on your setting screen. And that actually, that's

278
00:17:05,325 --> 00:17:08,085
Speaker 2:  a worse outcome than only Apple being allowed to show me ads on the setting

279
00:17:08,085 --> 00:17:11,525
Speaker 2:  screen. Just from a pure like user experience perspective. And I think then

280
00:17:11,525 --> 00:17:14,565
Speaker 2:  you have to believe that, oh okay, people will ditch their iPhones because

281
00:17:14,565 --> 00:17:16,885
Speaker 2:  there are too many ads on the setting screen. you

282
00:17:16,885 --> 00:17:19,645
Speaker 5:  Know, there's a counter example, it's just like sitting in front of all of

283
00:17:19,645 --> 00:17:23,365
Speaker 5:  us all the time, which is we use the web on our computers every day. The

284
00:17:23,365 --> 00:17:27,325
Speaker 5:  model for computing is not only on phones. Yeah. Think there's,

285
00:17:27,325 --> 00:17:30,845
Speaker 5:  that's there's a whole other one. Like you buy any desktop computer

286
00:17:31,225 --> 00:17:34,845
Speaker 5:  and then you put another application environment on it in terms of a web

287
00:17:34,845 --> 00:17:38,685
Speaker 5:  browser and then you have multiple computing application layers and multiple,

288
00:17:38,685 --> 00:17:42,125
Speaker 5:  like all this stuff is just like pure chaos. And it, that market seems to

289
00:17:42,125 --> 00:17:46,085
Speaker 5:  be fine. Like from what I got, like all this seem to enjoy it. It like people

290
00:17:46,085 --> 00:17:49,790
Speaker 5:  make things, the browser companies seem to be doing fine. Like there's new

291
00:17:49,790 --> 00:17:53,125
Speaker 5:  innovative browser companies. All of a sudden, like the market changes,

292
00:17:53,705 --> 00:17:57,205
Speaker 5:  people are selling laptops from what I understand Alex, they they keep making.

293
00:17:57,205 --> 00:18:00,805
Speaker 5:  Yeah, yeah. They do that every day. You look at this other thing and you're

294
00:18:00,805 --> 00:18:02,325
Speaker 5:  like, well that works fine until

295
00:18:02,325 --> 00:18:05,685
Speaker 2:  Google comes along and ruins it for everybody. But then, but then we get

296
00:18:05,685 --> 00:18:08,845
Speaker 2:  another other stuff that shows up and starts to work. Yeah, I think that's,

297
00:18:08,925 --> 00:18:12,685
Speaker 2:  I think that's largely right. I think what I wonder is how many things

298
00:18:12,685 --> 00:18:16,645
Speaker 2:  we're about to discover don't have the incentive structure of

299
00:18:16,705 --> 00:18:19,685
Speaker 2:  things like credit cards. Yeah. And actually I, as you were talking about

300
00:18:19,685 --> 00:18:23,085
Speaker 2:  the, the Netflix stuff, Alex, I was thinking about all of these companies

301
00:18:23,085 --> 00:18:26,965
Speaker 2:  that have shown up trying to be like the, the search service

302
00:18:27,305 --> 00:18:30,885
Speaker 2:  for streaming and Netflix sometimes

303
00:18:31,055 --> 00:18:34,685
Speaker 2:  works with them and is usually part of the search stuff. And there was a

304
00:18:34,685 --> 00:18:36,765
Speaker 2:  really funny thing recently where a bunch of people discovered you can search

305
00:18:36,865 --> 00:18:40,525
Speaker 2:  on the Apple TV app and get Netflix stuff and everybody got really excited

306
00:18:40,525 --> 00:18:43,045
Speaker 2:  and it was like, no, that's been there for a while. But what it won't do

307
00:18:43,045 --> 00:18:46,525
Speaker 2:  is show up in the continue watching stuff and it won't show up in the

308
00:18:46,525 --> 00:18:49,445
Speaker 2:  recommendations. And it's like Netflix wants to own that experience. They'll

309
00:18:49,445 --> 00:18:53,165
Speaker 2:  take search because you gotta be there. But Netflix still wants to own that

310
00:18:53,165 --> 00:18:55,845
Speaker 2:  experience. Yeah. And is powerful enough that it can get away with not being

311
00:18:55,845 --> 00:18:59,525
Speaker 2:  part of that. And it just makes me wonder there are, there are more things

312
00:18:59,525 --> 00:19:01,845
Speaker 2:  like that that are gonna be out there. I think

313
00:19:02,425 --> 00:19:05,365
Speaker 5:  The foundational premise of this question is also really interesting, which

314
00:19:05,365 --> 00:19:08,885
Speaker 5:  is like Apple makes people do things the right way, which is Apple's rep,

315
00:19:09,255 --> 00:19:12,045
Speaker 5:  right? Right. They're like, we have a user experience and If, you wanna be

316
00:19:12,045 --> 00:19:13,085
Speaker 5:  a part of it, you gotta do it our way.

317
00:19:13,085 --> 00:19:15,445
Speaker 2:  Right? But this is the correct answer in some certain way,

318
00:19:15,465 --> 00:19:18,245
Speaker 5:  But there's a correct answer. And like part of that's true. Like that's Apple's

319
00:19:18,245 --> 00:19:21,605
Speaker 5:  history. Like there're like there is a correct design answer. I think that's

320
00:19:21,725 --> 00:19:25,245
Speaker 5:  being corrupted by Apple's financial interests. And then I think like

321
00:19:25,925 --> 00:19:29,485
Speaker 5:  actually you look around and you're like, eh, we made a bunch of weird decisions.

322
00:19:30,155 --> 00:19:33,845
Speaker 5:  Like we all have to deal with H EICs. Yeah. Right, right. Like that's weird.

323
00:19:33,845 --> 00:19:36,645
Speaker 5:  Like did that, was that the right answer? Yeah. Like I don't know, TikTok

324
00:19:36,645 --> 00:19:40,605
Speaker 5:  started supporting HT R videos and it's just a mess. Like it is just a

325
00:19:40,605 --> 00:19:44,565
Speaker 5:  mess. It looks like shit and like everything is too bright. And then also

326
00:19:44,565 --> 00:19:47,405
Speaker 5:  kind of grainy. Instagram has the same problem with H share videos. Yeah.

327
00:19:47,425 --> 00:19:50,325
Speaker 5:  And it's like, this is just because Apple is like now the videos are HDR

328
00:19:50,705 --> 00:19:54,045
Speaker 5:  and it forced everyone to like deal with it and it's like, ugh,

329
00:19:55,235 --> 00:19:57,845
Speaker 5:  this isn't great. And it's like these are just choices that Apple is sort

330
00:19:57,845 --> 00:20:01,405
Speaker 5:  of like making down the line. I think one piece of evidence that, you know,

331
00:20:01,405 --> 00:20:05,325
Speaker 5:  it's kind of the lumbering monopoly is that the polish on some of that stuff

332
00:20:05,415 --> 00:20:08,445
Speaker 5:  isn't there the way it used to be. Yeah, yeah. And it's still coasting

333
00:20:08,505 --> 00:20:10,805
Speaker 2:  And it doesn't matter. Yeah. It doesn't matter. It it gets, they get away

334
00:20:10,805 --> 00:20:13,725
Speaker 2:  with it. Yeah. I think that's fair. We have one more question from Peter.

335
00:20:14,985 --> 00:20:18,565
Speaker 9:  Hey, this is Peter in Brooklyn. Just heard the episode about the Apple

336
00:20:18,565 --> 00:20:22,285
Speaker 9:  lawsuit with the US government and wanna say one thing people

337
00:20:22,285 --> 00:20:26,125
Speaker 9:  never point out about super apps is that China has one because

338
00:20:26,145 --> 00:20:29,965
Speaker 9:  the Chinese government has banned everything else and they

339
00:20:29,965 --> 00:20:33,125
Speaker 9:  want everyone to be in one app because it's easier to collect all the data

340
00:20:34,305 --> 00:20:37,925
Speaker 9:  and mess with all the information in one place. So

341
00:20:38,455 --> 00:20:42,165
Speaker 9:  maybe that's why China and India have one and no one else wants it. Yeah.

342
00:20:42,275 --> 00:20:44,325
Speaker 9:  Just something to think about. Thanks. Bye.

343
00:20:44,905 --> 00:20:48,005
Speaker 2:  So I just, I want to add one thing to this before we talk about it, which

344
00:20:48,005 --> 00:20:51,965
Speaker 2:  is I think another consistent piece of feedback we got when we

345
00:20:51,965 --> 00:20:55,525
Speaker 2:  talked about the Antitrust stuff was people saying why would you want super

346
00:20:55,525 --> 00:20:59,165
Speaker 2:  apps? Those are just monopolies of their own and they have

347
00:20:59,355 --> 00:21:02,885
Speaker 2:  just as much, if not more lock-in than many of these other systems. Why

348
00:21:03,265 --> 00:21:07,165
Speaker 2:  are we the three Vergecast co-hosts? Yeah. Standing so hard for

349
00:21:07,165 --> 00:21:07,605
Speaker 2:  super apps.

350
00:21:08,145 --> 00:21:11,565
Speaker 5:  All right, so maybe I, I didn't say this as clearly as I could have because

351
00:21:11,685 --> 00:21:15,245
Speaker 5:  I was on a beach drinking, literally drinking a bi enchilada

352
00:21:15,665 --> 00:21:19,445
Speaker 5:  and my audio was coming through AirPods. I think the

353
00:21:19,485 --> 00:21:23,165
Speaker 5:  DOJ is talking about super apps. 'cause that's a sexier idea than web apps.

354
00:21:24,155 --> 00:21:25,885
Speaker 5:  That is my fundamental belief.

355
00:21:25,885 --> 00:21:26,645
Speaker 2:  That's what I think too.

356
00:21:27,005 --> 00:21:30,525
Speaker 5:  I I think they can point to be like, we could turn Facebook

357
00:21:30,995 --> 00:21:34,845
Speaker 5:  into a super app and then you would just like leave your iPhone and buy

358
00:21:34,885 --> 00:21:37,645
Speaker 5:  a cheap Android phone and Facebook would take you there and that would bring

359
00:21:37,645 --> 00:21:41,125
Speaker 5:  down prices of phones in the market. And that's one way it fine. But it's

360
00:21:41,485 --> 00:21:45,125
Speaker 5:  actually web apps could do the same thing. Right? I think of my phone in

361
00:21:45,125 --> 00:21:48,885
Speaker 5:  many ways as a vessel for Google Services, which are also slowly

362
00:21:48,885 --> 00:21:52,325
Speaker 5:  degrading over time. But that was a real problem for Apple about five years

363
00:21:52,325 --> 00:21:55,445
Speaker 5:  ago when people would buy iPhones and then load 'em up with Google apps and

364
00:21:55,445 --> 00:21:58,685
Speaker 5:  Apple realized, oh, we need services that can compete with this across the

365
00:21:58,685 --> 00:22:01,365
Speaker 5:  board. Right. And those services has to be everywhere. That's why Apple Music

366
00:22:01,365 --> 00:22:04,645
Speaker 5:  is on Android. Like they know that some of these services have to be everywhere.

367
00:22:05,305 --> 00:22:08,445
Speaker 5:  So I, I don't know. I don't know that I want super apps either. I I just,

368
00:22:08,505 --> 00:22:12,405
Speaker 5:  my belief is that they, they couldn't pick web app. Like you can't

369
00:22:12,405 --> 00:22:16,205
Speaker 5:  be like, apples are killing the web. Like that is somewhat famously

370
00:22:16,205 --> 00:22:19,725
Speaker 5:  the argument they made about Microsoft in the nineties. Right. So I think

371
00:22:19,725 --> 00:22:23,685
Speaker 5:  they had to pick something new and shiny And. honestly, I think

372
00:22:23,685 --> 00:22:26,605
Speaker 5:  because Elon keeps talking about turning X into a super app, I think they

373
00:22:26,605 --> 00:22:29,365
Speaker 5:  wanted to court that particular political base.

374
00:22:29,785 --> 00:22:33,765
Speaker 2:  You think it also might just be in the lexicon in a way that like If you

375
00:22:33,765 --> 00:22:37,245
Speaker 2:  say progressive web apps, everybody's eyes kind of start to glaze over

376
00:22:37,585 --> 00:22:39,805
Speaker 2:  except for guest listeners, which is why we love you. Yeah,

377
00:22:39,805 --> 00:22:42,765
Speaker 5:  Yeah, yeah. That's what I mean. I, there's, there's an element of politics

378
00:22:42,765 --> 00:22:45,525
Speaker 5:  here. Like the United States government is like doing a thing. I think they're,

379
00:22:45,525 --> 00:22:49,485
Speaker 5:  they are communicating as political actors, you know, they, this is law like

380
00:22:49,485 --> 00:22:52,845
Speaker 5:  the d OJ is law enforcement. The cops are like doing stuff and they need

381
00:22:52,845 --> 00:22:56,685
Speaker 5:  people to believe in their power as cops. Okay. Like I, I just, I'm not

382
00:22:56,885 --> 00:23:00,645
Speaker 5:  out here saying we need a Chinese style super app. I like the point is

383
00:23:01,265 --> 00:23:04,805
Speaker 5:  If, you had one and in the markets where there are one, you see the

384
00:23:04,805 --> 00:23:08,685
Speaker 5:  switching costs between iPhones to other phones are very low and people switch

385
00:23:08,685 --> 00:23:11,405
Speaker 5:  between them all the time. And that is true in Europe, that is true in China,

386
00:23:11,405 --> 00:23:14,405
Speaker 5:  that is true in India. There are other ways to make those switching costs

387
00:23:14,425 --> 00:23:18,125
Speaker 5:  low. They just happen to be the web and it's only us here in our little,

388
00:23:18,125 --> 00:23:21,485
Speaker 5:  little Vergecast club that know that and care about that as much as we do.

389
00:23:21,755 --> 00:23:22,925
Speaker 2:  Yeah. Alex what do you think?

390
00:23:23,445 --> 00:23:27,365
Speaker 7:  I mean, ditto, it's just, just, I, I totally agree with NELI on

391
00:23:27,365 --> 00:23:30,605
Speaker 7:  that. Like, I don't think anybody necessarily wants a super app, but it's

392
00:23:30,605 --> 00:23:34,565
Speaker 7:  a really good example to use in this thing. And it's a really good

393
00:23:34,565 --> 00:23:38,085
Speaker 7:  example to show like we could have cheaper phones. This could be a lot cheaper

394
00:23:38,425 --> 00:23:41,125
Speaker 7:  and we don't necessarily need super apps for that. It could be the Google

395
00:23:41,125 --> 00:23:44,885
Speaker 7:  suite, it could be the Amazon suite, it could be another monopoly like tech

396
00:23:45,245 --> 00:23:49,085
Speaker 7:  companies suite who can say, but, but we should have choices and just

397
00:23:49,085 --> 00:23:51,885
Speaker 7:  choices at all. And, and to have just a whole

398
00:23:52,935 --> 00:23:56,845
Speaker 7:  style of app forbidden from 60% of phones

399
00:23:56,845 --> 00:23:59,845
Speaker 7:  in the United States because Apple doesn't feel like it and is threatened

400
00:23:59,845 --> 00:24:03,765
Speaker 7:  by it is like bad. Yeah. Even if those apps themselves maybe

401
00:24:03,765 --> 00:24:04,285
Speaker 7:  aren't great.

402
00:24:04,825 --> 00:24:08,685
Speaker 5:  And I would point I once again point to desktop computers where you can just

403
00:24:08,685 --> 00:24:12,365
Speaker 5:  Yep. The entire application model is the web and that's fine. Right. And

404
00:24:12,365 --> 00:24:15,925
Speaker 5:  like do people switch between Windows and Mac all the time because you can

405
00:24:15,925 --> 00:24:18,965
Speaker 5:  just use Google search and YouTube. No, they don't. They have, they still

406
00:24:18,965 --> 00:24:22,525
Speaker 5:  have preferences and the computers are still expensive, but

407
00:24:22,845 --> 00:24:26,685
Speaker 5:  a lot of them have gotten way cheaper in a way that, you know, phones have

408
00:24:26,685 --> 00:24:30,485
Speaker 5:  not, and I, we have evidence of this, right? Like Apple talks about not wanting

409
00:24:30,485 --> 00:24:34,445
Speaker 5:  parents to buy their kids cheap Android phones because that worries them

410
00:24:34,445 --> 00:24:37,525
Speaker 5:  that if they people can just access the service on a good enough phone, they

411
00:24:37,525 --> 00:24:39,045
Speaker 5:  won't buy expensive iPhones.

412
00:24:39,275 --> 00:24:42,165
Speaker 2:  Yeah. And I think that's right. Alex, we're about to get to the portion of

413
00:24:42,165 --> 00:24:45,645
Speaker 2:  our show where you and I get repeatedly accused of being China loving

414
00:24:45,775 --> 00:24:49,725
Speaker 2:  communists. Would you like, would you like to briefly explain why you'd like

415
00:24:49,725 --> 00:24:53,005
Speaker 2:  WeChat to come to America and and it'll make everything better and solve

416
00:24:53,105 --> 00:24:53,805
Speaker 2:  all of our problems?

417
00:24:54,465 --> 00:24:55,325
Speaker 7:  No. Okay,

418
00:24:55,325 --> 00:24:55,525
Speaker 2:  Good.

419
00:24:55,675 --> 00:24:59,445
Speaker 7:  Yeah, I don't think it will. I I don't think we need it in this country

420
00:24:59,705 --> 00:25:03,325
Speaker 7:  and I don't think, I think super apps are probably, I I think to, to

421
00:25:03,325 --> 00:25:07,005
Speaker 7:  Peter's point, monopolies themselves and we probably don't need them in this

422
00:25:07,005 --> 00:25:10,885
Speaker 7:  company country, but we also should probably be able to have them if we really

423
00:25:10,885 --> 00:25:13,525
Speaker 7:  want them. Like the choice should be there. The whole idea of capitalism

424
00:25:13,525 --> 00:25:17,205
Speaker 7:  is we have choices and it's like, okay, I would like that choice.

425
00:25:17,635 --> 00:25:17,925
Speaker 7:  Yeah.

426
00:25:17,995 --> 00:25:21,685
Speaker 5:  Also, millions of Americans routinely

427
00:25:21,685 --> 00:25:24,565
Speaker 5:  choose to use meta products like all the time.

428
00:25:25,545 --> 00:25:29,285
Speaker 5:  All the time. Like all the time. Like we are just a like a little

429
00:25:29,505 --> 00:25:32,925
Speaker 5:  bit away from that thing actually being real. Yeah. And it's not like

430
00:25:33,755 --> 00:25:37,165
Speaker 5:  John Gruber keeps pointing this out when you give people the choice of do

431
00:25:37,165 --> 00:25:40,365
Speaker 5:  you want a free service with personalized advertising? They're like, yes.

432
00:25:41,145 --> 00:25:43,605
Speaker 5:  And they're like, but would you, what If, you didn't have that and you could

433
00:25:43,605 --> 00:25:44,845
Speaker 5:  pay for it. And they're like, no.

434
00:25:45,815 --> 00:25:46,685
Speaker 10:  Right. Yeah.

435
00:25:46,945 --> 00:25:47,405
Speaker 5:  No man.

436
00:25:48,675 --> 00:25:51,285
Speaker 2:  Yeah. No, that's right. Alright, well we should get to TikTok stuff, but

437
00:25:51,285 --> 00:25:53,565
Speaker 2:  first we gotta take a brief break. We'll be right

438
00:25:53,565 --> 00:25:53,725
Speaker 10:  There.

439
00:28:46,865 --> 00:28:50,565
Speaker 2:  All right, we're back. Alex and I are card carrying members of the Chinese

440
00:28:50,565 --> 00:28:51,885
Speaker 2:  Communist Party. Oh, I

441
00:28:51,885 --> 00:28:52,605
Speaker 5:  Always want, can

442
00:28:52,605 --> 00:28:56,485
Speaker 2:  I see your card? And NELI NELI is the lone bastion of free

443
00:28:56,485 --> 00:29:00,325
Speaker 2:  speech and goodness here on The Vergecast, but is

444
00:29:00,325 --> 00:29:04,205
Speaker 2:  also occasionally, sometimes a monster who believes

445
00:29:04,305 --> 00:29:07,445
Speaker 2:  in the opposite of capitalism and hates everything. It's really been fun

446
00:29:07,445 --> 00:29:11,205
Speaker 2:  times listening to Yeah, the, the feedback to the TikTok band stuff we

447
00:29:12,185 --> 00:29:15,325
Speaker 2:  so much feedback about the TikTok thing, including somebody who called us

448
00:29:15,445 --> 00:29:19,085
Speaker 2:  I think three times to yell at me specifically in increasingly

449
00:29:19,875 --> 00:29:22,965
Speaker 2:  well-spoken ways. It's like they, they call that's good. They weren't happy

450
00:29:22,965 --> 00:29:25,725
Speaker 2:  with how they did so they called again and then they did it. It was unbelievable.

451
00:29:26,085 --> 00:29:26,845
Speaker 2:  But anyway, he did

452
00:29:26,845 --> 00:29:30,165
Speaker 5:  That person More people should call and yell at David in an increasingly

453
00:29:30,165 --> 00:29:30,685
Speaker 5:  polite ways.

454
00:29:31,185 --> 00:29:34,525
Speaker 2:  No, no, no. They were not increasingly polite, increasingly well argued ways.

455
00:29:34,925 --> 00:29:35,045
Speaker 2:  I

456
00:29:35,045 --> 00:29:36,525
Speaker 5:  See. Okay, I'll take that too.

457
00:29:36,865 --> 00:29:40,765
Speaker 2:  Do that again. Yeah. Alright. But let's get to a few of them starting with

458
00:29:40,765 --> 00:29:41,685
Speaker 2:  a question we got from Brandon.

459
00:29:42,895 --> 00:29:46,605
Speaker 11:  Hello, my name is Brandon, I'm based in Cleveland. I have thoughts about

460
00:29:46,635 --> 00:29:50,045
Speaker 11:  your conversation on The Verge cast about the TikTok ban.

461
00:29:50,545 --> 00:29:54,325
Speaker 11:  Not to be a complete conspiracy theorist, but I feel like there is a bunch

462
00:29:54,325 --> 00:29:57,805
Speaker 11:  of ulterior motives for getting rid of TikTok that have nothing to do with

463
00:29:58,085 --> 00:30:01,285
Speaker 11:  national security. First of which is that most of

464
00:30:01,965 --> 00:30:05,925
Speaker 11:  Congress is funded in part or in some significant way by apac.

465
00:30:05,925 --> 00:30:09,845
Speaker 11:  And APAC is sort of losing a propaganda or on TikTok regarding

466
00:30:09,845 --> 00:30:13,365
Speaker 11:  the Gaza situation. Secondly, it's sort of a source of like

467
00:30:13,455 --> 00:30:17,125
Speaker 11:  unfiltered current events information that kind of gives

468
00:30:17,425 --> 00:30:21,165
Speaker 11:  pumped out to viewers before sort of party officials

469
00:30:21,195 --> 00:30:24,805
Speaker 11:  kind of get the chance to formulate talking points about it. But I think

470
00:30:24,805 --> 00:30:28,045
Speaker 11:  that there's just sort of a best of interest to kind of eliminate the wildcard

471
00:30:28,185 --> 00:30:31,765
Speaker 11:  of like unmediated current events news from the

472
00:30:31,765 --> 00:30:35,645
Speaker 11:  landscape on an election year. But the national security and sort

473
00:30:35,645 --> 00:30:39,525
Speaker 11:  of like China angle of it is sort of like a convenient sort of

474
00:30:39,905 --> 00:30:43,805
Speaker 11:  top level reason to use to get rid of the app. But I feel like

475
00:30:43,805 --> 00:30:47,565
Speaker 11:  it just sort of is, you know, one hand that's washing the other and the

476
00:30:47,565 --> 00:30:51,325
Speaker 11:  other hand is really the true reason why both sides of the aisle want to

477
00:30:51,325 --> 00:30:54,645
Speaker 11:  get rid of the app. But that's just my thoughts. Thanks.

478
00:30:55,475 --> 00:30:59,445
Speaker 2:  Okay. Two things going on here. One, we got a surprising number of voicemails

479
00:30:59,445 --> 00:31:03,165
Speaker 2:  that start with not to be a conspiracy theorist and then dive deep down

480
00:31:03,275 --> 00:31:06,885
Speaker 2:  into it. Yeah. Which is just delightful and is perfectly in line with this

481
00:31:06,885 --> 00:31:10,085
Speaker 2:  entire conversation. But I do think this question of the

482
00:31:10,625 --> 00:31:14,605
Speaker 2:  Israel Hamas war being sort of the catalyzing event for a lot

483
00:31:14,605 --> 00:31:18,565
Speaker 2:  of this came up a lot and we talked about it a smidge in the episode

484
00:31:18,565 --> 00:31:21,605
Speaker 2:  that we did on it, but it's, it's been reported on a lot and there's been

485
00:31:21,605 --> 00:31:25,525
Speaker 2:  this question still ongoing of like, what does the government know and

486
00:31:25,525 --> 00:31:27,005
Speaker 2:  why haven't they told us? Yes. Right. Without,

487
00:31:27,075 --> 00:31:27,965
Speaker 5:  Without question they have

488
00:31:27,965 --> 00:31:31,085
Speaker 2:  Not been clear. Now, a couple of weeks later, I just wanna come back to this

489
00:31:31,085 --> 00:31:34,125
Speaker 2:  thing about like, okay, what, what do we know about what this is actually

490
00:31:34,125 --> 00:31:37,685
Speaker 2:  about and what's going on and what the US

491
00:31:37,685 --> 00:31:39,565
Speaker 2:  government believes it is actually doing here?

492
00:31:39,955 --> 00:31:43,205
Speaker 5:  Okay. I don't want to talk about APAC too much. Like you can, you really

493
00:31:43,225 --> 00:31:47,165
Speaker 5:  can fall down a, a wild ride of conspiracy theories. Yes there. But

494
00:31:47,165 --> 00:31:51,005
Speaker 5:  I will point out that yesterday as we're talking probably last week

495
00:31:51,045 --> 00:31:54,925
Speaker 5:  as people hear this, Joe Biden told Netanyahu on

496
00:31:54,925 --> 00:31:58,805
Speaker 5:  the phone, the situation of Gaza is unacceptable and conditioned further

497
00:31:58,985 --> 00:32:02,845
Speaker 5:  aid for Israel on some lasting solution to that situation.

498
00:32:03,185 --> 00:32:06,965
Speaker 5:  So the pressure has worked Fair enough. I think embedded in

499
00:32:06,965 --> 00:32:10,925
Speaker 5:  this question and much of the feedback that we got is an

500
00:32:10,925 --> 00:32:14,605
Speaker 5:  assumption that the TikTok algorithm is neutral. Mm.

501
00:32:14,785 --> 00:32:18,725
Speaker 5:  And then what's happening on TikTok is a neutral representation of how

502
00:32:19,285 --> 00:32:23,125
Speaker 5:  everyone in America feels. And people are like the kids

503
00:32:23,145 --> 00:32:26,685
Speaker 5:  are speaking and TikTok is show it's like fighting back. Right? And it's

504
00:32:26,685 --> 00:32:30,445
Speaker 5:  like, maybe, maybe that's true. I also believe the situation Gaza us untenable

505
00:32:30,845 --> 00:32:34,125
Speaker 5:  and there should be a ceasefire. But I don't believe that the TikTok algorithm

506
00:32:34,145 --> 00:32:37,565
Speaker 5:  is neutral. There's no evidence that it is right. There's no evidence that

507
00:32:37,635 --> 00:32:40,605
Speaker 5:  bite dance or the Chinese government, it's not like, you know what the fastest

508
00:32:40,785 --> 00:32:44,285
Speaker 5:  way to break lasting Western peace would be would be to break the

509
00:32:44,345 --> 00:32:47,885
Speaker 5:  United States support of Israel. Like that is a true thing. That's a thing

510
00:32:47,885 --> 00:32:50,645
Speaker 5:  that you could do. And the pr putting pressure on that alliance in particular

511
00:32:50,955 --> 00:32:54,405
Speaker 5:  like resets the world order, can you do that through the mechanism of fucking

512
00:32:54,505 --> 00:32:55,325
Speaker 5:  TikTok? I don't know.

513
00:32:57,015 --> 00:33:00,725
Speaker 5:  Right. Like, but I I think like if to

514
00:33:00,725 --> 00:33:04,605
Speaker 5:  accept that premise that it's because of what happened in Gaza and that young

515
00:33:04,605 --> 00:33:08,525
Speaker 5:  people arguing against a war is what is causing

516
00:33:08,625 --> 00:33:11,805
Speaker 5:  the United States government to say TikTok is a pro. Like you have to accept

517
00:33:11,805 --> 00:33:15,405
Speaker 5:  somewhere in there that the algorithm is neutral. That it is a neutral

518
00:33:15,405 --> 00:33:19,125
Speaker 5:  representation. And I think that's a huge assumption that you should not

519
00:33:19,125 --> 00:33:23,045
Speaker 5:  just make lightly. I also think my formative experience as a young

520
00:33:23,045 --> 00:33:26,965
Speaker 5:  person was the war in Iraq and I, no one listened to

521
00:33:26,965 --> 00:33:27,285
Speaker 5:  me either.

522
00:33:29,395 --> 00:33:32,405
Speaker 5:  Like my friends got arrested, marching down Lake Shore Drive protesting that

523
00:33:32,405 --> 00:33:36,245
Speaker 5:  war and that straight up like no one, like we were

524
00:33:36,245 --> 00:33:38,925
Speaker 5:  loud. I wish I'd had a TikTok then I would've made a lot of videos. Yeah.

525
00:33:39,325 --> 00:33:42,245
Speaker 5:  And so I, I hear that frustration. I feel it very keenly. I feel the same

526
00:33:42,245 --> 00:33:45,965
Speaker 5:  way about this war in all Wars, but I, I think the presumption that the

527
00:33:45,965 --> 00:33:49,645
Speaker 5:  algorithm is neutral is one that If, you wanna make that claim. I would just

528
00:33:49,645 --> 00:33:53,565
Speaker 5:  encourage you to challenge that presumption and, and think about how much

529
00:33:54,105 --> 00:33:57,765
Speaker 5:  you're relying on it. But like at least yester at least you know,

530
00:33:58,145 --> 00:33:59,965
Speaker 5:  the pressure has worked in some minor way.

531
00:34:00,475 --> 00:34:04,445
Speaker 7:  Well and this is also a trend we see with social media every time

532
00:34:04,445 --> 00:34:08,365
Speaker 7:  like a, a social media that is used by younger people tends to have

533
00:34:08,365 --> 00:34:10,805
Speaker 7:  this moment where everybody's like, why is nobody else talking about this?

534
00:34:11,105 --> 00:34:14,645
Speaker 7:  And it's like, well because you're just on this particular, you're just on

535
00:34:14,765 --> 00:34:18,325
Speaker 7:  Tumblr in 2016. That's why nobody else is talking about it because you haven't

536
00:34:18,325 --> 00:34:22,125
Speaker 7:  left Tumblr, you're just on TikTok in 2024. That's why nobody else

537
00:34:22,145 --> 00:34:25,245
Speaker 7:  is talking about it because you haven't left this app and If, you go and

538
00:34:25,245 --> 00:34:28,405
Speaker 7:  you look and elsewhere, elsewhere If, you look at other media, you will see

539
00:34:28,405 --> 00:34:31,405
Speaker 7:  that this stuff is being covered. And I think that's a trend we see a lot.

540
00:34:31,625 --> 00:34:35,285
Speaker 7:  And on TikTok in particular because of the algorithm, because of the way

541
00:34:35,585 --> 00:34:38,605
Speaker 7:  it is really, really good at disseminating information really, really quickly.

542
00:34:39,295 --> 00:34:41,885
Speaker 7:  We've seen that accelerate. We've seen that be a lot louder and a lot faster

543
00:34:41,885 --> 00:34:45,085
Speaker 7:  than it was in those other cases. And which we have seen, like, to be clear,

544
00:34:45,085 --> 00:34:48,845
Speaker 7:  we've seen it, we saw it with live journal back in, in 2004

545
00:34:48,965 --> 00:34:52,885
Speaker 7:  with with the, the war in Iraq 2003, 2004. You see it again and again

546
00:34:52,945 --> 00:34:56,285
Speaker 7:  and again and it's a behavior where younger people who are starting to really

547
00:34:56,505 --> 00:34:59,245
Speaker 7:  get into media literacy and starting to really think about these things,

548
00:34:59,555 --> 00:35:03,245
Speaker 7:  they go, they get on an app, they find other people just like them and they're

549
00:35:03,245 --> 00:35:06,685
Speaker 7:  like, why is nobody else talking about this? Why is this being held for me

550
00:35:06,685 --> 00:35:10,525
Speaker 7:  and these other areas? And the truth is, it's not, it's just being

551
00:35:10,525 --> 00:35:13,325
Speaker 7:  discussed in a different way. It's being discussed maybe with a little less

552
00:35:13,785 --> 00:35:17,525
Speaker 7:  heated rhetoric or whatever. But also I do wanna, I do kind of agree with

553
00:35:17,525 --> 00:35:20,445
Speaker 7:  him not about that part, but I agree with him certainly about like there

554
00:35:20,445 --> 00:35:24,405
Speaker 7:  are other reasons why the TikTok ban is being pushed. And it is, I would

555
00:35:24,405 --> 00:35:27,245
Speaker 7:  certainly agree it is not just national security reasons. I think there's

556
00:35:27,245 --> 00:35:31,125
Speaker 7:  a massive financial incentive for both the United States and for

557
00:35:31,545 --> 00:35:35,405
Speaker 7:  the many, many companies based in the United States that are direct competitors

558
00:35:35,405 --> 00:35:39,245
Speaker 7:  to TikTok. And those are the people that, like they do, they Meadow,

559
00:35:39,515 --> 00:35:43,485
Speaker 7:  mark Zuckerberg would be delighted if TikTok got shut down

560
00:35:43,725 --> 00:35:46,805
Speaker 7:  tomorrow. you know? Yeah. Like Elon Musk would be delighted if it got shut

561
00:35:46,805 --> 00:35:50,525
Speaker 7:  down tomorrow because that means more users back on their platforms. So I

562
00:35:50,525 --> 00:35:53,445
Speaker 7:  think like we can't ignore the fact that there are certainly other incentives

563
00:35:53,515 --> 00:35:57,045
Speaker 7:  here that are, that are encouraging this. But we also have to like

564
00:35:57,435 --> 00:36:00,925
Speaker 7:  deal with the facts as we are given them. And like when we start to think

565
00:36:00,925 --> 00:36:03,885
Speaker 7:  about, well what if it, you know, why is nobody reporting on this stuff?

566
00:36:03,885 --> 00:36:06,325
Speaker 7:  People are reporting on it, people are looking into this stuff, people are

567
00:36:06,485 --> 00:36:09,525
Speaker 7:  examining it. But if we don't have proof, if we don't have like real

568
00:36:10,165 --> 00:36:14,045
Speaker 7:  quantifiable facts, we are just like pissing in the wind

569
00:36:14,085 --> 00:36:16,445
Speaker 7:  being like maybe something's happening over there. Yeah.

570
00:36:16,715 --> 00:36:20,405
Speaker 5:  Also, I, you know, most of Congress believes that what they're going to accomplish

571
00:36:20,405 --> 00:36:24,365
Speaker 5:  is a sale of TikTok and that I don't like If you believe

572
00:36:24,365 --> 00:36:27,685
Speaker 5:  they're gonna sell it. Like then you also have to believe that someone's

573
00:36:27,685 --> 00:36:31,245
Speaker 5:  gonna find the big algorithm dial and turn it like towards Israel

574
00:36:31,545 --> 00:36:34,725
Speaker 5:  and that implies that that dial exists and it is currently pointed towards

575
00:36:34,725 --> 00:36:38,445
Speaker 5:  God and like it can be turned and then now you're right back at the problem

576
00:36:38,465 --> 00:36:41,685
Speaker 5:  of who controls that dial. And so I would just like, it's that assumption

577
00:36:41,685 --> 00:36:44,805
Speaker 5:  that is like, do you believe that the Instagram reels algorithm is neutral?

578
00:36:45,165 --> 00:36:48,725
Speaker 5:  I do not. It mostly shows me babes. Like it just fully

579
00:36:48,805 --> 00:36:52,445
Speaker 5:  believes that that is what I want from that. And like I can't type

580
00:36:52,545 --> 00:36:56,485
Speaker 5:  trucks exploding into Instagram like more loudly. Like

581
00:36:56,485 --> 00:36:59,685
Speaker 5:  that's the thing I actually want. Yeah. And the TikTok algorithm is like,

582
00:36:59,685 --> 00:37:02,645
Speaker 5:  you definitely want trucks exploding and then here are some of the weirdest

583
00:37:02,645 --> 00:37:04,365
Speaker 5:  gadgets ever made. You should buy them.

584
00:37:04,465 --> 00:37:05,645
Speaker 2:  So TikTok gets you TikTok

585
00:37:05,705 --> 00:37:09,605
Speaker 5:  Is what I was like, you are gonna buy so many vacuum cleaners, here's some

586
00:37:09,785 --> 00:37:12,725
Speaker 5:  cut rate anchor batteries, we're doing it this week. That's what's happening.

587
00:37:13,145 --> 00:37:16,325
Speaker 5:  And it's like these algorithm of, we all know that the algorithms have preferences

588
00:37:16,345 --> 00:37:20,085
Speaker 5:  and biases and can be shaped by the people who control them. The

589
00:37:20,365 --> 00:37:24,125
Speaker 5:  question for for this is who should do that? Should it, should it exist in

590
00:37:24,125 --> 00:37:27,645
Speaker 5:  our country? Should it exist? If Rupert and Murdoch bought TikTok, would

591
00:37:27,645 --> 00:37:31,405
Speaker 5:  you be pleased about that? Why or why not? Right? And then the question is,

592
00:37:31,405 --> 00:37:33,605
Speaker 5:  would you be pleased that the Chinese government has that same power?

593
00:37:34,075 --> 00:37:37,365
Speaker 2:  Yeah. I think that, I think that's fair. And then the, you know, tangential

594
00:37:37,365 --> 00:37:41,005
Speaker 2:  to the question of is the algorithm neutral is like on what

595
00:37:41,035 --> 00:37:44,925
Speaker 2:  vectors can you move the knobs? Right? And it's like that comes back to

596
00:37:44,925 --> 00:37:47,565
Speaker 2:  what do these companies want and who is really in charge? And it's like,

597
00:37:47,565 --> 00:37:51,045
Speaker 2:  that's where all of this gets so messy for me, right. Because it's like I

598
00:37:51,055 --> 00:37:54,605
Speaker 2:  doubt sincerely that it would be good for tiktoks business

599
00:37:55,225 --> 00:37:59,165
Speaker 2:  to move the Gaza knob one way or another. I do

600
00:37:59,165 --> 00:38:03,045
Speaker 2:  think it moves the shop knob to move the business.

601
00:38:03,115 --> 00:38:06,925
Speaker 2:  Yeah. That's just obviously true. Like it feels true being on TikTok. But

602
00:38:06,925 --> 00:38:10,605
Speaker 2:  then there's all of those questions next to the fact like you're talking

603
00:38:10,605 --> 00:38:13,725
Speaker 2:  about Alex, that the three of us sitting in this room have completely different

604
00:38:13,725 --> 00:38:17,685
Speaker 2:  experiences of TikTok. So to be, to sit here and talk about TikTok as

605
00:38:17,725 --> 00:38:21,445
Speaker 2:  a single thing is essentially impossible. And this is where like I just start

606
00:38:21,445 --> 00:38:24,565
Speaker 2:  running in circles on all of this, right? Like we're essentially using different

607
00:38:24,565 --> 00:38:28,485
Speaker 2:  apps. Yeah. I would bet 95% of what the three of us see on

608
00:38:28,505 --> 00:38:32,045
Speaker 2:  TikTok does not overlap. Yeah. And what do you do with that? Yeah,

609
00:38:32,315 --> 00:38:36,085
Speaker 2:  it's so weird. Well, you, you explain Jojo Siwa

610
00:38:36,185 --> 00:38:36,405
Speaker 2:  to

611
00:38:36,585 --> 00:38:39,725
Speaker 5:  To NELI right before the show starts. No, I refuse to know any of this information.

612
00:38:39,995 --> 00:38:40,285
Speaker 5:  Yeah,

613
00:38:40,285 --> 00:38:43,245
Speaker 2:  NELI got to, I'm sorry. I know there is a, there is an entity called Jojo

614
00:38:43,275 --> 00:38:44,845
Speaker 2:  Siwa and that's all the informationi.

615
00:38:44,845 --> 00:38:47,045
Speaker 5:  I've refused to even acknowledge that it is an entity. I know that there

616
00:38:47,045 --> 00:38:49,205
Speaker 5:  are words that people say that sound like that.

617
00:38:49,365 --> 00:38:50,085
Speaker 2:  I see. Okay. Yeah.

618
00:38:50,345 --> 00:38:53,205
Speaker 5:  By the way, my belief is that the Instagram algorithm only shows me babes

619
00:38:53,285 --> 00:38:56,645
Speaker 5:  'cause I refuse to engage with it. And its default is like, huh,

620
00:38:58,275 --> 00:38:59,005
Speaker 5:  will this work today?

621
00:38:59,685 --> 00:39:00,525
Speaker 2:  I know you want babes.

622
00:39:00,955 --> 00:39:03,925
Speaker 5:  It's like we don't know anything about you babe.

623
00:39:04,835 --> 00:39:07,645
Speaker 2:  Fair enough. Alright, let's get to the next one, which in the name of fairness

624
00:39:07,825 --> 00:39:11,005
Speaker 2:  is very mad at me specifically. But we got a lot of these that are very mad

625
00:39:11,005 --> 00:39:14,325
Speaker 2:  at me specifically. And as a good journalist, I feel obligated to air one

626
00:39:14,475 --> 00:39:17,765
Speaker 2:  this person, they said their name in a way that I couldn't identify. So we're

627
00:39:17,765 --> 00:39:19,645
Speaker 2:  just gonna call them St. Louis. So this is from St. Louis.

628
00:39:21,795 --> 00:39:25,485
Speaker 12:  From St. Louis and listening to the latest episode of the Birge Cast

629
00:39:25,625 --> 00:39:29,285
Speaker 12:  and taking my fist at the clouds and yelling into the

630
00:39:29,335 --> 00:39:33,045
Speaker 12:  ether because David and Alex are just,

631
00:39:33,365 --> 00:39:36,365
Speaker 12:  I don't know, I guess they've been brainwashed by TikTok or something to

632
00:39:36,365 --> 00:39:40,245
Speaker 12:  start from first principles, right? The most compelling reasons

633
00:39:40,305 --> 00:39:43,845
Speaker 12:  for banning TikTok and then just work your way down to the least compelling.

634
00:39:44,055 --> 00:39:47,685
Speaker 12:  First and foremost when Nila mentioned the 1932 was

635
00:39:48,005 --> 00:39:51,925
Speaker 12:  Communications act, known corner ownership of media. Boom right there.

636
00:39:51,945 --> 00:39:55,445
Speaker 12:  You don't need to go any further. That right there is justification for

637
00:39:55,565 --> 00:39:57,885
Speaker 12:  banning TikTok. It should have been done a long time ago. We don't need

638
00:39:57,885 --> 00:40:01,485
Speaker 12:  to have any debate. We're done, period. Next China

639
00:40:01,885 --> 00:40:04,485
Speaker 12:  bans us social media. Why would that be? Why would they think they should

640
00:40:04,485 --> 00:40:08,405
Speaker 12:  do that? Maybe because if they think it's being done to them, it's

641
00:40:08,405 --> 00:40:12,365
Speaker 12:  because they're doing it to you, right? I mean, it's kind of a tit for SAT

642
00:40:12,365 --> 00:40:15,525
Speaker 12:  thing. But again, you can find that with the other one. And again, I don't

643
00:40:15,525 --> 00:40:19,165
Speaker 12:  think we need to debate it any further. Second, you guys are talking about,

644
00:40:19,555 --> 00:40:22,885
Speaker 12:  well what are they doing? This is all hearsay, blah blah, blah. I don't

645
00:40:22,885 --> 00:40:26,765
Speaker 12:  know. You guys have a have a, you know, a whole website and you seem

646
00:40:26,765 --> 00:40:30,365
Speaker 12:  to like to investigate, you know, shit related to technology and whatever.

647
00:40:30,365 --> 00:40:33,685
Speaker 12:  How about looking into the differences in content between, you know, the

648
00:40:33,685 --> 00:40:37,605
Speaker 12:  different platforms? I would hazard a guess, and I take a big

649
00:40:37,705 --> 00:40:41,325
Speaker 12:  bet that the types of content on TikTok

650
00:40:41,345 --> 00:40:44,965
Speaker 12:  versus reels versus YouTube shorts is

651
00:40:45,205 --> 00:40:48,885
Speaker 12:  quite different. Meaning pick a controversial subject, be it,

652
00:40:49,105 --> 00:40:52,685
Speaker 12:  you know, the Israel, Hamas for Taiwan, et cetera,

653
00:40:52,835 --> 00:40:56,685
Speaker 12:  that there's a dramatic difference in the number of pros

654
00:40:56,685 --> 00:41:00,565
Speaker 12:  and cons posts that are presented on these different platforms.

655
00:41:01,025 --> 00:41:01,245
Speaker 12:  Hi.

656
00:41:02,145 --> 00:41:06,045
Speaker 2:  So the two things in here, one, he brings up a bunch of stuff we've been

657
00:41:06,045 --> 00:41:10,005
Speaker 2:  talking about and, and I think the question of content differences is very

658
00:41:10,205 --> 00:41:14,045
Speaker 2:  interesting, but I specifically wanna talk about this one because a lot of

659
00:41:14,045 --> 00:41:17,445
Speaker 2:  people responded to our talk about the TikTok ban by saying, well, China

660
00:41:17,445 --> 00:41:21,405
Speaker 2:  does it to us, the end problem solved, we should, we can do

661
00:41:21,565 --> 00:41:25,245
Speaker 2:  it back. And I don't find that argument credible at all,

662
00:41:25,385 --> 00:41:29,365
Speaker 2:  but I am open to discussion on that. And NELI in particular, I wanna

663
00:41:29,365 --> 00:41:32,965
Speaker 2:  know what you think because you are the most pro band of us,

664
00:41:33,365 --> 00:41:33,725
Speaker 2:  I would say.

665
00:41:34,195 --> 00:41:37,365
Speaker 5:  Yeah, I don't, I I've heard that argument a lot. It makes sense in like,

666
00:41:37,425 --> 00:41:41,165
Speaker 5:  its way like straight tit for tat like, but China

667
00:41:41,235 --> 00:41:45,205
Speaker 5:  also directly controls its information economy and it is

668
00:41:45,205 --> 00:41:48,285
Speaker 5:  an authoritarian government and I don't think we should do that.

669
00:41:49,035 --> 00:41:50,885
Speaker 2:  Well. So this is kind of where, where I lateral to,

670
00:41:51,285 --> 00:41:55,165
Speaker 5:  I just wanna be clear. Like I I I, I believe in the First Amendment in

671
00:41:55,165 --> 00:41:58,285
Speaker 5:  a very real and meaningful way. What I'm saying is

672
00:41:58,875 --> 00:42:02,445
Speaker 5:  there's a reason in the United States we don't allow a ton of foreign

673
00:42:02,445 --> 00:42:06,085
Speaker 5:  ownership of media. There's a reason that historically if we have not allowed

674
00:42:06,445 --> 00:42:10,125
Speaker 5:  concentration of media ownership, because we know that's dangerous to

675
00:42:10,325 --> 00:42:13,885
Speaker 5:  like the plurality that makes the democracy strong and all this stuff. And

676
00:42:13,885 --> 00:42:17,405
Speaker 5:  so like that, that's its own argument. That is not, they do it so we can

677
00:42:17,405 --> 00:42:17,725
Speaker 5:  do it too,

678
00:42:18,095 --> 00:42:21,285
Speaker 2:  Right? Yeah. I think to me there are sort of two

679
00:42:21,755 --> 00:42:25,685
Speaker 2:  inclusive questions inside of that. One is like, is China

680
00:42:25,685 --> 00:42:29,445
Speaker 2:  does something we can do it back a good argument. And I I think

681
00:42:29,585 --> 00:42:32,365
Speaker 2:  no, for the reasons you just said, I don't want to be like,

682
00:42:32,525 --> 00:42:34,845
Speaker 5:  I think that argument feels, I I wanna be clear. I think that argument feels

683
00:42:34,845 --> 00:42:35,365
Speaker 5:  good. Sure.

684
00:42:35,365 --> 00:42:35,565
Speaker 2:  But I

685
00:42:35,565 --> 00:42:38,085
Speaker 5:  Also, but when you, when when you like run around being like, what we want

686
00:42:38,085 --> 00:42:41,565
Speaker 5:  to preserve is a plurality of media, like no one gives a shit when you're

687
00:42:41,565 --> 00:42:44,285
Speaker 5:  like, they do it to us. Like, everyone's like, yeah, like that feels good.

688
00:42:44,445 --> 00:42:47,285
Speaker 5:  I I understand why the argument is made and I understand why it feels

689
00:42:47,285 --> 00:42:51,125
Speaker 2:  Good. Right? And I think the, it it ladders up to an argument that

690
00:42:51,165 --> 00:42:54,605
Speaker 2:  I think a lot of the Antitrust conversation also ladders up to, which is

691
00:42:54,605 --> 00:42:58,525
Speaker 2:  what do we think our government's job is to do here? And I think in, in a

692
00:42:58,525 --> 00:43:02,365
Speaker 2:  lot of ways there is this belief in America that

693
00:43:02,365 --> 00:43:04,765
Speaker 2:  like the, the market regulates itself and this is how we talk about this

694
00:43:04,765 --> 00:43:07,805
Speaker 2:  stuff in capitalism and all this stuff. But then the question of what is

695
00:43:07,805 --> 00:43:11,725
Speaker 2:  the government's role in that is like, it, it has, it has occurred to me

696
00:43:11,725 --> 00:43:14,125
Speaker 2:  a number of times that this is a thing we should spend a lot of this year

697
00:43:14,125 --> 00:43:17,805
Speaker 2:  talking about is what the government's job is and

698
00:43:17,805 --> 00:43:21,285
Speaker 2:  should be and what that actually looks like in practice. Because I think

699
00:43:21,285 --> 00:43:24,445
Speaker 2:  a lot of people in America feel like what the EU is doing to tech companies

700
00:43:24,465 --> 00:43:28,445
Speaker 2:  is like way overreaching and heavy handed and ridiculous. But it

701
00:43:28,445 --> 00:43:32,365
Speaker 2:  is like culturally, I think in a lot of places in Europe, it is less out

702
00:43:32,365 --> 00:43:36,005
Speaker 2:  of bounds with how things normally work. But to me, all of this

703
00:43:36,375 --> 00:43:40,045
Speaker 2:  stuff sort of circles around this question of like, is the government's job

704
00:43:40,105 --> 00:43:44,045
Speaker 2:  to govern what I look at on my phone? I don't

705
00:43:44,045 --> 00:43:47,925
Speaker 5:  Know. No, I just wanna be very clear about that. No, like

706
00:43:47,965 --> 00:43:48,845
Speaker 5:  I really don't believe, but

707
00:43:48,845 --> 00:43:49,725
Speaker 2:  You want them to ban on TikTok.

708
00:43:49,995 --> 00:43:53,525
Speaker 5:  Yeah. I, again, I think the, your question about like what can the government

709
00:43:53,525 --> 00:43:56,805
Speaker 5:  do and can the market regulate itself? The pendulum has swung pretty wildly

710
00:43:57,075 --> 00:44:00,925
Speaker 5:  over the last 40 years towards no regulation, right? And

711
00:44:00,925 --> 00:44:04,725
Speaker 5:  now it might just slowly be swinging back, right? Like

712
00:44:04,725 --> 00:44:08,525
Speaker 5:  there's 1980 Ronald Reagan, Robert Bork, we've done that Dakota

713
00:44:08,555 --> 00:44:12,165
Speaker 5:  episode. There's like a total deregulation of the market. You can see it.

714
00:44:12,525 --> 00:44:15,725
Speaker 5:  Jonathan Cantor mentioned it to me, same thing. He's like, 1980 this happened

715
00:44:16,025 --> 00:44:19,365
Speaker 5:  and now it pendulum might just be swinging back like just a little bit and

716
00:44:19,365 --> 00:44:23,285
Speaker 5:  people are like, Ooh, that's weird and that's fine. Like that is inside

717
00:44:23,285 --> 00:44:26,765
Speaker 5:  of our market. The thing that I'm saying about TikTok in particular

718
00:44:27,545 --> 00:44:31,405
Speaker 5:  is If, you find out they're doing the bad thing. We can't

719
00:44:31,405 --> 00:44:35,125
Speaker 5:  go arrest the Chinese government. Right? You, you can't do it. You cannot

720
00:44:35,195 --> 00:44:38,845
Speaker 5:  hold them accountable in, in specific ways. I mentioned this on the last

721
00:44:38,845 --> 00:44:42,285
Speaker 5:  show, and I'll say it again. Their kids aren't here. The people who run by

722
00:44:42,285 --> 00:44:45,045
Speaker 5:  dance, you know, their, their kids are there, they're in China, they're in

723
00:44:45,125 --> 00:44:48,845
Speaker 5:  Singapore. So I, there's just a thing that's different, like our experiences

724
00:44:48,845 --> 00:44:52,445
Speaker 5:  here in this country are valuable to us and our

725
00:44:52,695 --> 00:44:56,005
Speaker 5:  media ownership is just a part of that. Like it really is a big part of that.

726
00:44:56,005 --> 00:44:59,365
Speaker 5:  Like I said this as a joke at the end of the last episode, I think we should

727
00:44:59,365 --> 00:45:03,125
Speaker 5:  also break up Sinclair Broadcasting and Clear Channel. Sure. Right? Like

728
00:45:03,235 --> 00:45:07,165
Speaker 5:  massive concentration of media ownership across the country is not good.

729
00:45:07,545 --> 00:45:10,885
Speaker 5:  It only gives you like a singular point of view and puts too many people

730
00:45:10,945 --> 00:45:14,445
Speaker 5:  in charge of what too many people see and feel. There's that really famous

731
00:45:14,445 --> 00:45:18,245
Speaker 5:  video that I think Deadspin made ages ago that was just Sinclair News

732
00:45:18,245 --> 00:45:21,925
Speaker 5:  anchors all saying, all reading the same speech about the fake news. Yeah.

733
00:45:21,925 --> 00:45:25,445
Speaker 5:  And that is horrifying, right? That's horrifying. And the reason you have

734
00:45:25,445 --> 00:45:29,365
Speaker 5:  media ownership rules is to make sure that doesn't happen. And so like I

735
00:45:29,565 --> 00:45:33,405
Speaker 5:  I landing all of my, like we should ban TikTok

736
00:45:33,435 --> 00:45:37,165
Speaker 5:  criticism in that idea, right?

737
00:45:37,165 --> 00:45:40,605
Speaker 5:  Which is the people who make the media in the United States who shape opinion

738
00:45:40,605 --> 00:45:44,045
Speaker 5:  in the United States who have control over what people see and experience.

739
00:45:44,755 --> 00:45:47,605
Speaker 5:  This has skin in the game here. Fair enough. Alex. And there should be, and

740
00:45:47,605 --> 00:45:49,085
Speaker 5:  there should be more competition in that. Any

741
00:45:49,085 --> 00:45:52,685
Speaker 7:  Thoughts? Yeah, to NE's earlier point, I think, I think he's right that like

742
00:45:52,985 --> 00:45:56,125
Speaker 7:  we took our eye off the ball for a very long ki time in this country. We,

743
00:45:56,125 --> 00:45:59,685
Speaker 7:  we stopped paying content and we stopped caring to regulate companies.

744
00:45:59,905 --> 00:46:03,885
Speaker 7:  And historically we did that a lot. And some of our biggest and most like

745
00:46:03,885 --> 00:46:07,605
Speaker 7:  vibrant economic moments in this country were when we were heavily

746
00:46:08,335 --> 00:46:12,125
Speaker 7:  regulating companies. And so a lot of this is just like culture

747
00:46:12,215 --> 00:46:15,205
Speaker 7:  shock. If, you haven't done something for 40 years and you start doing it

748
00:46:15,205 --> 00:46:17,885
Speaker 7:  even a little bit. Everybody's gonna be like, the hell are you doing over

749
00:46:17,885 --> 00:46:21,085
Speaker 7:  there? But at the same time, like I see the TikTok stuff and I'm like, well

750
00:46:21,085 --> 00:46:24,725
Speaker 7:  that feels kind of hypocritical of us to be like, well, we have to shut down

751
00:46:24,825 --> 00:46:28,645
Speaker 7:  TikTok because it has this really large control

752
00:46:28,715 --> 00:46:32,365
Speaker 7:  over our, our media and, and it has this really

753
00:46:32,395 --> 00:46:35,845
Speaker 7:  important impact on our media when Disney has what, like

754
00:46:35,845 --> 00:46:39,765
Speaker 7:  80% of American box office and, and has this enormous

755
00:46:39,765 --> 00:46:43,085
Speaker 7:  control. And so the only difference between those two is one is in China,

756
00:46:43,665 --> 00:46:46,285
Speaker 7:  and one is Bob Iker. That's

757
00:46:46,285 --> 00:46:50,245
Speaker 5:  A huge difference. Like Disney's here, and, and, and Ron DeSantis is like,

758
00:46:50,725 --> 00:46:54,045
Speaker 5:  here's a weird law about not saying that anyone can ever be gay, which is

759
00:46:54,045 --> 00:46:57,565
Speaker 5:  going like super well for Ron DeSantis, right? Like then Disney got into

760
00:46:57,605 --> 00:47:01,485
Speaker 5:  a political fight and they lost a tax district and

761
00:47:01,485 --> 00:47:04,765
Speaker 5:  they gotta get it back. There was an investor fight that Disney just had

762
00:47:04,765 --> 00:47:08,525
Speaker 5:  to win. Like the consequences of Disney's speech in

763
00:47:08,525 --> 00:47:12,485
Speaker 5:  America are real. Right? And yes, it is true. They have

764
00:47:12,485 --> 00:47:15,605
Speaker 5:  mostly succeeded in all of their fights, but they had to fight.

765
00:47:16,195 --> 00:47:19,965
Speaker 5:  Yeah, right. There were, there were actual, they were held accountable for

766
00:47:19,965 --> 00:47:23,885
Speaker 5:  their positions. And I agree with most of their posi, not all of

767
00:47:23,885 --> 00:47:27,805
Speaker 5:  Disney's positions, I would hasten to say, but some of their

768
00:47:28,045 --> 00:47:31,685
Speaker 5:  positions here about being inclusive, like all that stuff, like a

769
00:47:31,975 --> 00:47:35,765
Speaker 5:  meaningful political element in the United States tried to punish Disney

770
00:47:35,905 --> 00:47:39,765
Speaker 5:  for that stuff and Disney fought back and largely has won or not

771
00:47:39,765 --> 00:47:43,405
Speaker 5:  won, or come to some set of accommodations with the Florida

772
00:47:43,405 --> 00:47:47,365
Speaker 5:  government. Like whatever happened there is different than whatever.

773
00:47:47,545 --> 00:47:51,365
Speaker 5:  If we find out TikTok is doing the bad thing. Yeah. Right. And that's, I

774
00:47:51,365 --> 00:47:55,005
Speaker 5:  think that is just a massively important, like, I don't know, like Disney

775
00:47:55,105 --> 00:47:58,685
Speaker 5:  has employees in the United States, like if Disney has 80% of the box office.

776
00:47:59,025 --> 00:48:03,005
Speaker 7:  I'm sorry, I was reading my, I was reading my little red book that

777
00:48:03,005 --> 00:48:04,925
Speaker 7:  I, I received, I didn't hear anything

778
00:48:04,925 --> 00:48:06,245
Speaker 5:  That I was just saying like, yeah,

779
00:48:06,245 --> 00:48:09,085
Speaker 7:  No, I, I think there is a, there is a fundamental difference, right? Like

780
00:48:09,305 --> 00:48:12,725
Speaker 7:  the, the argument here, the, the core argument of this TikTok thing is

781
00:48:13,185 --> 00:48:16,725
Speaker 7:  who is allowed to dominate conversations in America?

782
00:48:17,425 --> 00:48:19,925
Speaker 7:  And I think that argument shouldn't happen at all. Who should be allowed

783
00:48:19,925 --> 00:48:23,725
Speaker 7:  to dominate conversations in America? No one shouldn't have that. Like

784
00:48:23,725 --> 00:48:27,325
Speaker 7:  Disney shouldn't be as used as it is. TikTok certainly

785
00:48:27,325 --> 00:48:31,045
Speaker 7:  shouldn't be able to just have everybody believe a conspiracy theory or know

786
00:48:31,045 --> 00:48:34,805
Speaker 7:  who the what's up brother guy is with just like a little twist

787
00:48:34,905 --> 00:48:38,765
Speaker 7:  of the algorithm. That's bananas. No one should have that kind of

788
00:48:39,285 --> 00:48:43,245
Speaker 7:  monopoly on our culture and on our media. But at

789
00:48:43,405 --> 00:48:46,885
Speaker 7:  the same time, I kind of agree with the fact that like, we probably don't

790
00:48:46,885 --> 00:48:50,285
Speaker 7:  want foreign actors in, in, in the United States controlling

791
00:48:50,895 --> 00:48:54,605
Speaker 7:  stuff, right? Like we, we, we don't necessarily want that because we've seen

792
00:48:54,675 --> 00:48:58,605
Speaker 7:  time and time again. But banning TikTok doesn't solve that. Russia has found

793
00:48:58,605 --> 00:49:02,565
Speaker 7:  many ways to get into our country and, and influence

794
00:49:02,585 --> 00:49:06,445
Speaker 7:  us at a mass scale using American tools. Like the tools themselves

795
00:49:06,465 --> 00:49:10,085
Speaker 7:  are the problem. It's not who owns them because the tools are the thing that

796
00:49:10,085 --> 00:49:13,765
Speaker 7:  is disseminating the information. We, we saw that in 2016 with

797
00:49:13,865 --> 00:49:17,205
Speaker 7:  how Russia manipulated Facebook and other social media platforms and there's,

798
00:49:17,205 --> 00:49:19,685
Speaker 7:  that's just proof like that, that happened.

799
00:49:19,975 --> 00:49:23,565
Speaker 5:  There was a bunch of reporting about how there was a Russian disinformation

800
00:49:23,925 --> 00:49:27,285
Speaker 5:  campaign around Kate Middleton. Yeah. And it's like, oh, they just keep doing

801
00:49:27,285 --> 00:49:29,245
Speaker 5:  it. They, oh, they, they're still at it. They're,

802
00:49:29,245 --> 00:49:30,005
Speaker 7:  They're still doing it.

803
00:49:30,265 --> 00:49:33,325
Speaker 2:  I'm realizing as we talked that I think I would be more compelled by your

804
00:49:33,565 --> 00:49:37,205
Speaker 2:  argument NELI if I felt like the US was regulating anything

805
00:49:38,125 --> 00:49:38,565
Speaker 2:  that like

806
00:49:39,405 --> 00:49:40,565
Speaker 5:  We have like a functional government. Yeah.

807
00:49:40,625 --> 00:49:44,525
Speaker 2:  If we were preventing the American owned services from doing

808
00:49:44,525 --> 00:49:48,445
Speaker 2:  the things we're accusing TikTok of, I would be more compelled by the argument

809
00:49:48,445 --> 00:49:51,845
Speaker 2:  that since we can't prevent TikTok from doing it, the responsible thing to

810
00:49:51,845 --> 00:49:55,005
Speaker 2:  do is kick them out. I think if If you draw that line,

811
00:49:55,675 --> 00:49:59,605
Speaker 2:  that sort of makes sense to me. But that assumes that we are

812
00:49:59,605 --> 00:50:02,885
Speaker 2:  capable of doing it to anybody and there's really no evidence that we're

813
00:50:02,885 --> 00:50:03,965
Speaker 2:  capable of doing that to anybody. Well,

814
00:50:03,965 --> 00:50:07,805
Speaker 5:  There's one huge prohibition, which is the first amendment. It really,

815
00:50:07,985 --> 00:50:11,965
Speaker 5:  really gets in your way. Right? It's like a real problem. It's, it's

816
00:50:11,965 --> 00:50:14,125
Speaker 5:  good problem. A problem that I, I think we should continue to have.

817
00:50:14,885 --> 00:50:17,485
Speaker 2:  I swear there will come a time on the show where I make you earnestly argue

818
00:50:17,485 --> 00:50:19,885
Speaker 2:  against the first time. Exactly. I'm so excited about it. It's

819
00:50:19,885 --> 00:50:23,445
Speaker 5:  Very challenging. You have to believe, and I think this is why a lot of the

820
00:50:23,445 --> 00:50:27,440
Speaker 5:  people who don't think TikTok should be banned or sold, sold who,

821
00:50:27,465 --> 00:50:30,885
Speaker 5:  who think this is all crazy. You have to believe that American companies

822
00:50:31,115 --> 00:50:34,965
Speaker 5:  have in some way the best interest of Americans at heart or America at

823
00:50:34,965 --> 00:50:38,285
Speaker 5:  heart. And I don't think that's easy to believe. I think it, if I walked

824
00:50:38,285 --> 00:50:41,645
Speaker 5:  up to most people and I was like, Disney isn't a champion of American values

825
00:50:41,705 --> 00:50:45,085
Speaker 5:  to pick, what are you talking? Right? If I said that about Facebook or Apple

826
00:50:45,365 --> 00:50:49,125
Speaker 5:  or Google or Pfizer, whatever, like most people do not

827
00:50:49,125 --> 00:50:52,405
Speaker 5:  believe that that is the case. Right? I don't know that I believe that that

828
00:50:52,405 --> 00:50:55,965
Speaker 5:  is the case, but it is, when I talk about challenging assumptions,

829
00:50:56,195 --> 00:50:59,845
Speaker 5:  that is one assumption at the heart of the idea that big companies in America

830
00:51:00,305 --> 00:51:02,845
Speaker 5:  should have all kinds of freedoms and

831
00:53:19,395 --> 00:53:22,915
Speaker 15:  prohibition laws fail, so this will probably go that way. Love the pod.

832
00:53:23,065 --> 00:53:23,715
Speaker 15:  Have a good one.

833
00:53:24,205 --> 00:53:27,935
Speaker 2:  Ditto. Nilay. Patel. TikTok is Digital Crack. That's, that's the

834
00:53:28,095 --> 00:53:28,455
Speaker 2:  headline here.

835
00:53:28,995 --> 00:53:29,735
Speaker 5:  I'm not sure that's the,

836
00:53:30,895 --> 00:53:33,975
Speaker 2:  I wanna pose this as as a question because I think this is kind of where

837
00:53:33,975 --> 00:53:37,575
Speaker 2:  we ended the last time we talked about this and I, I I want to end here too.

838
00:53:38,035 --> 00:53:41,335
Speaker 2:  Is there a version of this that accomplishes anything? A

839
00:53:41,335 --> 00:53:41,815
Speaker 5:  Version of what

840
00:53:42,175 --> 00:53:45,815
Speaker 2:  TikTok ban? Like can you, a, can you ban TikTok

841
00:53:46,075 --> 00:53:49,575
Speaker 2:  in a, in an actually practically enforceable way and B

842
00:53:50,065 --> 00:53:53,215
Speaker 2:  would it do anything? Because I think there's, there's a real nihilism setting

843
00:53:53,235 --> 00:53:56,375
Speaker 2:  in in a lot of this conversation that's like, whatever, it's, it's,

844
00:53:57,285 --> 00:54:01,175
Speaker 5:  Yeah. First of all, just to be, I think as of today, TikTok is

845
00:54:01,175 --> 00:54:04,375
Speaker 5:  not banned Correct. And there is no movement on a bill in the Senate.

846
00:54:04,525 --> 00:54:06,255
Speaker 2:  Alex and I are winning that bet so far. Yeah.

847
00:54:06,255 --> 00:54:09,735
Speaker 5:  Yeah. There's no movement on a bill in the Senate to actually ban TikTok,

848
00:54:10,075 --> 00:54:13,975
Speaker 5:  so whatever. Yeah. Right, right. Then

849
00:54:14,045 --> 00:54:17,975
Speaker 5:  there's the other reality, which is the bill would potentially force a

850
00:54:17,975 --> 00:54:21,935
Speaker 5:  sale and there's a lot of people who might want, want to

851
00:54:21,995 --> 00:54:25,935
Speaker 5:  buy it and you might just end up in that situation. Yep. So there's a lot

852
00:54:25,935 --> 00:54:29,255
Speaker 5:  of things that have to happen first, and many of them don't end up in the

853
00:54:29,255 --> 00:54:33,015
Speaker 5:  thing as banned. But I think If, you do ban it like it, I don't think people

854
00:54:33,015 --> 00:54:36,375
Speaker 5:  are just gonna be staring at like a blank screen on their phone. Like, just

855
00:54:36,375 --> 00:54:40,135
Speaker 5:  like Wistfully thinking about when Charlie Delio started dancing again.

856
00:54:40,235 --> 00:54:44,055
Speaker 5:  you know, like I, they, they're gonna just like move on. Okay,

857
00:54:44,055 --> 00:54:47,415
Speaker 2:  But let me pause at this. So the, the, what this does is prevent app stores

858
00:54:47,415 --> 00:54:49,975
Speaker 2:  from carrying it, right? Yeah, that is, that is essentially what this man

859
00:54:49,975 --> 00:54:52,615
Speaker 2:  looks like. There are what, a couple hundred million people in the United States

860
00:54:52,615 --> 00:54:55,735
Speaker 2:  who already have TikTok on their phones. I don't think there's any real precedent

861
00:54:55,735 --> 00:54:59,695
Speaker 2:  for Apple and Google reaching out and proactively deleting apps from

862
00:54:59,695 --> 00:55:03,495
Speaker 2:  your phone. Yeah. So that's just a lot of people who have TikTok still

863
00:55:03,565 --> 00:55:07,375
Speaker 2:  already. It also VPNs exist. People

864
00:55:07,375 --> 00:55:08,135
Speaker 2:  have done

865
00:55:08,135 --> 00:55:11,495
Speaker 5:  A lot of work. I love the idea of work to like some small country like becoming

866
00:55:11,575 --> 00:55:15,495
Speaker 5:  a honeypot VPN station for TikTok, like Monaco. you know, it's like

867
00:55:15,735 --> 00:55:19,575
Speaker 5:  everyone is just like VPNing through Monaco and Monaco's TikTok becomes

868
00:55:20,235 --> 00:55:20,935
Speaker 5:  us TikTok.

869
00:55:21,285 --> 00:55:23,935
Speaker 2:  It's like the, I forget which country it is, but the country that owns the

870
00:55:24,315 --> 00:55:27,575
Speaker 2:  AI domain is suddenly that's like a meaningful part of the GVP as all these

871
00:55:27,775 --> 00:55:28,135
Speaker 2:  companies. It's

872
00:55:28,135 --> 00:55:31,455
Speaker 5:  Great. Yeah. Great. All of these things could happen and I agree many,

873
00:55:31,845 --> 00:55:35,775
Speaker 5:  look, the Chinese great firewall works, but it, it's not perfect. Right?

874
00:55:35,995 --> 00:55:38,775
Speaker 5:  And the idea that we would put one up and it would work perfectly is like

875
00:55:38,775 --> 00:55:42,295
Speaker 5:  nonsensical. Like, yes, some people are still gonna use TikTok, but the app

876
00:55:42,295 --> 00:55:46,215
Speaker 5:  won't be able to get updated and people won't be uploading content

877
00:55:46,235 --> 00:55:49,335
Speaker 5:  to a thing that looks like, it's not like it will result in some kind of

878
00:55:49,335 --> 00:55:53,175
Speaker 5:  weird decline over time and fine. But there's just so many

879
00:55:53,415 --> 00:55:56,655
Speaker 5:  steps from here to there. Like so, so many steps from here to there.

880
00:55:56,655 --> 00:55:59,655
Speaker 2:  Yeah. Yeah. Alex, you and I have been on on the same page about this and

881
00:55:59,655 --> 00:56:02,655
Speaker 2:  I'm curious where I've landed after, you know, two more weeks of this is

882
00:56:02,735 --> 00:56:06,575
Speaker 2:  I think most likely outcome by a pretty wide margin. Nothing happens.

883
00:56:06,805 --> 00:56:10,055
Speaker 2:  Yeah. Second most likely outcome, it gets sold

884
00:56:10,755 --> 00:56:14,655
Speaker 2:  in some way, shape, or form. Not to Steven Mnuchin, but to somebody else.

885
00:56:15,795 --> 00:56:19,615
Speaker 2:  Big, giant planet sized gap down to option

886
00:56:19,615 --> 00:56:22,415
Speaker 2:  number three, which is that TikTok actually gets banned in a meaningful way.

887
00:56:22,675 --> 00:56:24,085
Speaker 2:  Do you disagree or disagree?

888
00:56:24,515 --> 00:56:28,285
Speaker 7:  It's not gonna get banned. It, it, it, it won't get banned. And, and I think

889
00:56:28,285 --> 00:56:31,685
Speaker 7:  even a sale is gonna be super unlikely because who's gonna buy it? Who's

890
00:56:31,685 --> 00:56:35,525
Speaker 7:  gonna have the money and not have a monopoly as soon as they

891
00:56:35,545 --> 00:56:38,845
Speaker 7:  own it. Right. And also then I think we just come back to that conversation

892
00:56:38,845 --> 00:56:41,805
Speaker 7:  of wait, wait, wait, wait, wait. It's not okay for the Chinese government

893
00:56:41,805 --> 00:56:45,045
Speaker 7:  to manipulate us through TikTok, but it is totally okay for

894
00:56:45,545 --> 00:56:49,325
Speaker 7:  Disney or Larry Ellison or whoever

895
00:56:49,945 --> 00:56:53,805
Speaker 7:  to manipulate us through TikTok. Well, that's not good. Like I,

896
00:56:53,845 --> 00:56:57,525
Speaker 7:  I think it's just such a stupid, stupid ban. And

897
00:56:57,705 --> 00:57:01,085
Speaker 7:  for, for those reasons, I understand like the rationale behind it and the

898
00:57:01,085 --> 00:57:04,285
Speaker 7:  legal theory behind it and, and all of that. I, I get that, but at the same

899
00:57:04,285 --> 00:57:08,245
Speaker 7:  time I'm like, the hypocrisy of it is so outrageous and I'm like, don't be

900
00:57:08,245 --> 00:57:08,605
Speaker 7:  so dumb.

901
00:57:09,195 --> 00:57:12,525
Speaker 2:  I've decided that the funniest possible outcome is that one branch of the

902
00:57:12,525 --> 00:57:16,125
Speaker 2:  government forces it to be sold to YouTube and then

903
00:57:16,315 --> 00:57:19,805
Speaker 2:  four minutes later, Lena Khan files a lawsuit against two

904
00:57:20,265 --> 00:57:21,405
Speaker 2:  for, for Antitrust.

905
00:57:21,425 --> 00:57:22,085
Speaker 7:  That'd be good.

906
00:57:22,345 --> 00:57:24,685
Speaker 2:  You gotta keep the government wheels turning. Yeah. Yeah. We're just gonna

907
00:57:24,685 --> 00:57:25,725
Speaker 2:  keep a lot of lawyers employed.

908
00:57:25,955 --> 00:57:29,765
Speaker 5:  Well, when I think of what the founding fathers really wanted, it was a self-perpetuating

909
00:57:29,855 --> 00:57:31,445
Speaker 5:  cycle of government actions.

910
00:57:31,795 --> 00:57:34,365
Speaker 2:  It's beautiful. All right, we got one more and then I'm gonna let you guys

911
00:57:34,365 --> 00:57:37,205
Speaker 2:  get outta here. This has nothing to do with TikTok or Apple, but it is Apple.

912
00:57:37,205 --> 00:57:40,165
Speaker 2:  It is a perfectly Verge casty question and so I'm obligated to play it. This

913
00:57:40,165 --> 00:57:40,565
Speaker 2:  is from Michael.

914
00:57:41,615 --> 00:57:45,525
Speaker 16:  Hello, this is Michael from San Francisco. So I've been

915
00:57:45,525 --> 00:57:49,325
Speaker 16:  loving you guys' coverage on The future of the web and I love how obsessed

916
00:57:49,325 --> 00:57:53,245
Speaker 16:  with the web you are. And I too am obsessed with it and

917
00:57:53,245 --> 00:57:56,805
Speaker 16:  I'm trying to find more and more web apps to replace the apps on my phone.

918
00:57:57,505 --> 00:58:01,405
Speaker 16:  So I'm wondering what web apps, not native apps, but like,

919
00:58:01,405 --> 00:58:05,325
Speaker 16:  whether they be PWAs or just web pages, like what

920
00:58:05,325 --> 00:58:08,205
Speaker 16:  are the web apps you guys use day to day? What are some of your favorite

921
00:58:08,305 --> 00:58:10,045
Speaker 16:  web apps? Thanks. Goodbye.

922
00:58:10,675 --> 00:58:14,405
Speaker 2:  Okay. I just, I want to just, we're, we're gonna do two each. Okay.

923
00:58:14,485 --> 00:58:17,885
Speaker 2:  This is, these are the rules and neither none of us can say The Verge because

924
00:58:17,885 --> 00:58:20,965
Speaker 2:  The Verge is the best web app that exists. You should download it to your

925
00:58:20,965 --> 00:58:23,405
Speaker 2:  home screen. It's actually very good on your home screen. Highly recommend

926
00:58:23,555 --> 00:58:26,325
Speaker 2:  everybody's furiously scrolling through their phones right now. Yeah, so

927
00:58:26,325 --> 00:58:30,245
Speaker 2:  I'll go first. The two web apps that I use the most, I would say at this

928
00:58:30,245 --> 00:58:33,965
Speaker 2:  moment are, I use an app called Feed Bin as an RSS reader

929
00:58:34,235 --> 00:58:37,885
Speaker 2:  that is fantastic on the web. It's super late and super fast. It's where

930
00:58:37,885 --> 00:58:41,005
Speaker 2:  all of my stuff comes into. I started piping my YouTube subscriptions into

931
00:58:41,005 --> 00:58:44,965
Speaker 2:  there so that I get new things from the channels I subscribe to without

932
00:58:44,965 --> 00:58:48,485
Speaker 2:  the rest of the YouTube interface. Love it. Feed bin.com. It's amazing. I

933
00:58:48,485 --> 00:58:51,685
Speaker 2:  think it's like five bucks a month, cannot recommend it highly enough. And

934
00:58:51,685 --> 00:58:55,245
Speaker 2:  the other one, there's two I could choose from here, but the other one I'll

935
00:58:55,245 --> 00:58:58,885
Speaker 2:  pick is a to-Do list app that I have started using and

936
00:58:58,885 --> 00:59:01,925
Speaker 2:  stopped using and come back to because this is the, the Sickness with which

937
00:59:01,925 --> 00:59:05,645
Speaker 2:  I live that way. It's called twos, TWOS. And it is like

938
00:59:05,995 --> 00:59:09,965
Speaker 2:  just a perfectly made, very simple list

939
00:59:10,085 --> 00:59:13,325
Speaker 2:  making app with reminders and integrates with your calendar. And it is just

940
00:59:13,515 --> 00:59:17,245
Speaker 2:  fast as hell. And a lot of the app works offline even in your browser. It,

941
00:59:17,305 --> 00:59:20,845
Speaker 2:  it, it rules. Cannot recommend it enough. I love a good simple, fast

942
00:59:20,945 --> 00:59:21,885
Speaker 5:  Choose.com.

943
00:59:22,205 --> 00:59:24,005
Speaker 2:  I think it's twos app.com.

944
00:59:24,105 --> 00:59:25,325
Speaker 5:  Ah, that explains a lot of thing.

945
00:59:25,465 --> 00:59:26,165
Speaker 7:  That's very cool.

946
00:59:26,395 --> 00:59:28,605
Speaker 2:  Yeah, so those are my two Alex. What do you got?

947
00:59:28,895 --> 00:59:32,685
Speaker 7:  Story Graph is is probably my big one. It's a good read replacement. That's

948
00:59:32,685 --> 00:59:36,405
Speaker 7:  kind and it is, it just slaps. It is fantastic. I don't use

949
00:59:36,465 --> 00:59:39,725
Speaker 7:  any of the social parts of it, I just use it to track what I'm reading and

950
00:59:39,725 --> 00:59:42,925
Speaker 7:  anytime somebody says which book should I read, I immediately open that and,

951
00:59:42,925 --> 00:59:46,205
Speaker 7:  and start flipping through it. 'cause I just adore it. And then my other

952
00:59:46,205 --> 00:59:50,005
Speaker 7:  one is probably like a console I use on to to, to

953
00:59:50,245 --> 00:59:53,805
Speaker 7:  interact with my Raspberry Pie. That it, it's just like amazing. Like it's

954
00:59:53,805 --> 00:59:56,885
Speaker 7:  the pie hole console and you can just like, there's like a web app version

955
00:59:56,885 --> 01:00:00,805
Speaker 7:  of it and, and I adore that. Like a lot of smart home stuff has

956
01:00:00,805 --> 01:00:04,685
Speaker 7:  web apps and I'm just like, yeah, this is great. And I, so I was looking

957
01:00:04,685 --> 01:00:07,285
Speaker 7:  through it and I was like, oh, I guess most of my web apps are like smart

958
01:00:07,285 --> 01:00:08,445
Speaker 7:  Home, quick access.

959
01:00:09,075 --> 01:00:11,885
Speaker 2:  It's perfect. I love it. And that's like, it, it connects to all your stuff.

960
01:00:12,265 --> 01:00:12,605
Speaker 2:  It does all

961
01:00:12,605 --> 01:00:15,445
Speaker 7:  This stuff and it does it. Yeah. And they work. Yeah. And it's great.

962
01:00:15,705 --> 01:00:18,525
Speaker 2:  That's good. Yeah. Pie Hole is a good app. All right. Neela, what's yours?

963
01:00:18,915 --> 01:00:21,965
Speaker 5:  Well, I wish I'd gotten this question knowing that I wasn't allowed to say

964
01:00:21,965 --> 01:00:22,725
Speaker 5:  The Verge dot com.

965
01:00:23,275 --> 01:00:25,805
Speaker 2:  Yeah, it's just cheating. It's like, it's a website. It's,

966
01:00:25,805 --> 01:00:29,445
Speaker 5:  It is very good on the, on the thing. I want to issue one correction last

967
01:00:29,445 --> 01:00:32,445
Speaker 5:  week or two weeks ago, I said Notion Calendar on the Mac was native. Mm.

968
01:00:32,445 --> 01:00:36,165
Speaker 5:  That's an electron app. It just happens to be very good. And the person who

969
01:00:36,165 --> 01:00:38,005
Speaker 5:  wrote it was tweeting about how happy he was.

970
01:00:38,105 --> 01:00:41,365
Speaker 2:  He was very proud. Yeah. That you, you confuse it for being a native app.

971
01:00:41,365 --> 01:00:44,565
Speaker 2:  That's good. Which means all the people who build bad electron apps, shame

972
01:00:44,565 --> 01:00:45,525
Speaker 2:  on you. Yeah. Do better.

973
01:00:46,025 --> 01:00:50,005
Speaker 5:  You got nowhere to hide. So yeah, I, I have a home

974
01:00:50,005 --> 01:00:53,565
Speaker 5:  bridge and I use the Home Bridge web app on my phone all the time,

975
01:00:54,325 --> 01:00:58,085
Speaker 5:  mostly to update the plugins, but that's like a thing that I use all the

976
01:00:58,085 --> 01:01:01,045
Speaker 5:  time. I go to that web and then it's actually interesting that I don't think

977
01:01:01,045 --> 01:01:04,245
Speaker 5:  of these as web apps. They're just little web servers in my house. So Homer

978
01:01:04,245 --> 01:01:08,045
Speaker 5:  just runs in my house. That counts. Yeah. And then my Sony receiver has a

979
01:01:08,045 --> 01:01:10,645
Speaker 5:  little web server in it to change all the settings and of course it does.

980
01:01:10,805 --> 01:01:14,245
Speaker 5:  I spends so much time just like monkeying with the little settings on the

981
01:01:14,245 --> 01:01:17,125
Speaker 5:  center of the receiver. That's amazing. you know the, this question, like

982
01:01:17,145 --> 01:01:20,685
Speaker 5:  it gets at the heart of something I was looking@twostwosapp.com

983
01:01:21,265 --> 01:01:24,245
Speaker 5:  and you open it and the banner is like, download our app Yep. At the top

984
01:01:24,245 --> 01:01:24,805
Speaker 5:  of the screen. Yep.

985
01:01:25,315 --> 01:01:27,685
Speaker 2:  It's actually better on the web than any other platform and it's still wants

986
01:01:27,685 --> 01:01:29,645
Speaker 2:  you to download an app, which I think is fascinating.

987
01:01:29,845 --> 01:01:32,845
Speaker 5:  A lot of this question is just like Apple does not want that thing to happen.

988
01:01:32,875 --> 01:01:34,285
Speaker 5:  That happened to its laptops,

989
01:01:34,285 --> 01:01:37,605
Speaker 2:  Right? Yeah. And, and yeah, there, there's gonna come a time when

990
01:01:38,265 --> 01:01:41,325
Speaker 2:  I'm gonna write 40,000 words about how annoying it is when you open up like

991
01:01:41,585 --> 01:01:44,405
Speaker 2:  Reddit or any other site and it's like, isn't this better in the app? And

992
01:01:44,405 --> 01:01:47,965
Speaker 2:  I'm like, no, I on our website have a good website. Yep. If it's better in

993
01:01:47,965 --> 01:01:51,805
Speaker 2:  the app, it's your fault. Yeah. But yeah, anyway, the web is great. We love

994
01:01:51,805 --> 01:01:55,205
Speaker 2:  the web. Please ask us questions about the web. Alright, we gotta get outta

995
01:01:55,205 --> 01:01:58,845
Speaker 2:  here. NELI. Alex, thank you as always for doing this and I suspect we'll

996
01:01:58,845 --> 01:02:02,645
Speaker 2:  have more of this to do in the very near future. Peace. That's it for The

997
01:02:02,725 --> 01:02:05,445
Speaker 2:  Vergecast today. Thanks to NELI and Alex for doing this with me. And thank

998
01:02:05,445 --> 01:02:09,365
Speaker 2:  you as always for listening and for sending in all of those Hotline questions

999
01:02:09,365 --> 01:02:13,125
Speaker 2:  and emails. We love getting all of your feedback. There's lots more on everything

1000
01:02:13,125 --> 01:02:16,325
Speaker 2:  we talked about, by the way, at The Verge dot com. I'll put some links in

1001
01:02:16,325 --> 01:02:19,725
Speaker 2:  the show notes. But also the TikTok ban and the Apple stuff is all happening

1002
01:02:19,995 --> 01:02:23,805
Speaker 2:  sort of constantly all the time. Even just recently, there's a

1003
01:02:23,805 --> 01:02:27,445
Speaker 2:  huge lawsuit about the Apple Watch that is very much a regulatory question

1004
01:02:27,445 --> 01:02:31,125
Speaker 2:  about Apple. Even separately from the Antitrust stuff. There's just a lot

1005
01:02:31,125 --> 01:02:35,085
Speaker 2:  going on. Before we go, two quick housekeeping things. One, this

1006
01:02:35,085 --> 01:02:38,965
Speaker 2:  coming weekend, April 13th on Saturday, I'm gonna be

1007
01:02:38,965 --> 01:02:42,885
Speaker 2:  in Chicago at the Chicago Humanities Festival along with a couple of my colleagues

1008
01:02:42,975 --> 01:02:46,805
Speaker 2:  doing a series of panels, all about AI and creativity.

1009
01:02:46,825 --> 01:02:50,725
Speaker 2:  Trying to figure out what does AI mean for people who wanna

1010
01:02:50,725 --> 01:02:54,125
Speaker 2:  make things and what does it give them in terms of tools? What does it take

1011
01:02:54,125 --> 01:02:58,045
Speaker 2:  away? How do we as consumers understand what this stuff

1012
01:02:58,105 --> 01:03:01,205
Speaker 2:  is when some of it is made by humans and some of it's made by ai and that

1013
01:03:01,205 --> 01:03:04,965
Speaker 2:  line starts to get really blurry. We're gonna spend a whole Saturday afternoon

1014
01:03:05,155 --> 01:03:08,245
Speaker 2:  sorting through all of that with some really interesting people. I'm gonna

1015
01:03:08,245 --> 01:03:10,965
Speaker 2:  put the link in the show notes, we'll put it in the description. If, you

1016
01:03:10,965 --> 01:03:13,565
Speaker 2:  want to get tickets. If you're in Chicago, you want to come hang out and

1017
01:03:13,565 --> 01:03:17,445
Speaker 2:  talk about ai? Please do. We would love to have you. It's gonna be incredibly

1018
01:03:17,505 --> 01:03:21,205
Speaker 2:  fun. Thing number two, we have been nominated for a Webby Award

1019
01:03:21,385 --> 01:03:25,205
Speaker 2:  for best technology podcast. It's very important, A, that you

1020
01:03:25,205 --> 01:03:29,125
Speaker 2:  vote for us because we wanna win this award very badly. And B, that we

1021
01:03:29,125 --> 01:03:33,045
Speaker 2:  beat NELI and decoder. It's so, so important. NELI

1022
01:03:33,265 --> 01:03:37,005
Speaker 2:  is nominated for decoder as best business podcast and he can totally

1023
01:03:37,065 --> 01:03:41,045
Speaker 2:  win that. Sounds great. Love that for Eli. Enjoy that. I wanna beat

1024
01:03:41,045 --> 01:03:44,885
Speaker 2:  him for Best Technology podcast so bad. Plus he wins. Anyway, great news

1025
01:03:44,885 --> 01:03:47,565
Speaker 2:  all around. Go to the Webbys. We'll put the link in the show notes, put the

1026
01:03:47,565 --> 01:03:51,445
Speaker 2:  link in the description, please vote for The. Vergecast. We love, particularly

1027
01:03:51,555 --> 01:03:55,085
Speaker 2:  when we win the People's Choice Award, because it comes from you all the

1028
01:03:55,085 --> 01:03:57,845
Speaker 2:  listeners who say you like this show, we want all your feedback, we want

1029
01:03:57,845 --> 01:04:00,685
Speaker 2:  all your thoughts. But the Webby Award is really cool looking and I want

1030
01:04:00,685 --> 01:04:04,005
Speaker 2:  one really bad. That's enough for now. Please go vote for us. Come see us

1031
01:04:04,005 --> 01:04:07,645
Speaker 2:  in Chicago. Can't wait to hang out. As always, If, you have thoughts, questions,

1032
01:04:07,685 --> 01:04:11,645
Speaker 2:  feelings, or more you wanna say about TikTok in China. You can

1033
01:04:11,645 --> 01:04:15,165
Speaker 2:  always email us at Vergecast at The Verge dot com or call the Hotline eight six six

1034
01:04:15,365 --> 01:04:18,805
Speaker 2:  Verge one one. Truly the Hotline is my favorite thing about The Vergecast.

1035
01:04:18,955 --> 01:04:22,565
Speaker 2:  It's so fun hearing all of the things you have to say, some of which is super

1036
01:04:22,565 --> 01:04:24,965
Speaker 2:  mean and doesn't make it on the show, some of which is really nice and doesn't

1037
01:04:24,965 --> 01:04:28,805
Speaker 2:  make it on the show, some of which is somewhere in between. It's great. We

1038
01:04:28,845 --> 01:04:32,365
Speaker 2:  do a Hotline question on the show at least once a week, so please keep 'em

1039
01:04:32,365 --> 01:04:35,365
Speaker 2:  all coming. This show is produced by Andrew Marino, Liam James, and Will

1040
01:04:35,365 --> 01:04:38,085
Speaker 2:  four The Vergecast is The Verge production and part of the Vox Media podcast

1041
01:04:38,085 --> 01:04:42,045
Speaker 2:  network. NELI, Alex and I will be back on Friday to talk about some fun gadget

1042
01:04:42,045 --> 01:04:45,125
Speaker 2:  reviews we got coming this week and everything else happening in tech. We'll

1043
01:04:45,125 --> 01:04:46,205
Speaker 2:  see you then. Rock and roll

1044
01:04:56,795 --> 01:05:00,405
Speaker 3:  Support for this podcast comes from Smart Water. Want to get a little more

1045
01:05:00,405 --> 01:05:04,365
Speaker 3:  from every sip. Smart water alkaline doesn't just taste crisp and pure. It's

1046
01:05:04,365 --> 01:05:07,645
Speaker 3:  loaded with everything you need to perform at your best. Whether you're running

1047
01:05:07,965 --> 01:05:11,365
Speaker 3:  marathons or boardroom meetings, elevate how you hydrate and pick up a smart

1048
01:05:11,365 --> 01:05:15,045
Speaker 3:  water alkaline today. To learn more, visit drink smart water.com.

