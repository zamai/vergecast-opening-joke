1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 10c8f666-9ed0-426b-9471-4258bc958080
Status: Done
Stage: Done
Title: Apple OS betas, how to talk about AI, and our video game picks
Audio URL: https://jfe93e.s3.amazonaws.com/4734174120816489870/6040172684135670124/s93290-US-5582s-1689149695.mp3
Description: Today on the flagship podcast of transformers (both the movie and the AI thing): 
03:46 - The Verge’s Victoria Song, Chris Welch, Allison Johnson, and David Pierce discuss using the new features and tools in beta versions of Apple’s watchOS 10, tvOS 17, iOS 17, and iPadOS 17. 
28:36 - The Verge’s James Vincent joins the show to discuss how we should think about using the popular vocabulary terms in AI like GPT, LLM, transformers, hallucinations, etc. Are we using them the right way? Does it matter how we use them? 
54:20 - David is joined by The Verge’s Ash Parrish and Polygon’s Chris Plante to share the video games they are most excited about after a string of announcements from Nintendo, Sony, Microsoft, Ubisoft, Summer Game Fest, and others. 
1:25:46 - We answer a question from the Vergecast Hotline
Email us at vergecast@theverge.com, or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Disabled

2
00:00:02,630 --> 00:00:06,160
Speaker 2:  Welcome to The Vergecast, the flagship podcast of Transformers,

3
00:00:06,350 --> 00:00:10,240
Speaker 2:  both the movie and the AI thing. I'm your friend, David Pierce. And

4
00:00:10,240 --> 00:00:13,640
Speaker 2:  I am sitting here catching up on Wimbledon, the best tennis tournament of

5
00:00:13,640 --> 00:00:14,200
Speaker 2:  the year. Whoa,

6
00:00:15,100 --> 00:00:17,240
Speaker 3:  Surely pointed the tournament so far. That one,

7
00:00:17,420 --> 00:00:19,120
Speaker 4:  You have got to be kidding me.

8
00:00:19,780 --> 00:00:23,480
Speaker 2:  Wow. It's been a busy few days for me so I'm a bit behind. But luckily

9
00:00:23,480 --> 00:00:27,400
Speaker 2:  wimbledon.com has a pretty good set of highlights so I can catch up

10
00:00:27,400 --> 00:00:30,800
Speaker 2:  on all the matches I missed in just a few minutes at a time. And I, don't

11
00:00:30,800 --> 00:00:34,160
Speaker 2:  know if you know this, but Wimbledon is doing a thing with AI commentary

12
00:00:34,260 --> 00:00:37,960
Speaker 2:  in these highlights. It's part of some collaboration with IBM's Watson.

13
00:00:38,700 --> 00:00:42,400
Speaker 2:  And. I can See how it's an interesting and cool idea, but oh boy,

14
00:00:42,510 --> 00:00:46,480
Speaker 2:  it's so, so, so bad. Like, okay, listen

15
00:00:46,480 --> 00:00:50,320
Speaker 2:  to this one. A recap of Monday's match between Christopher Eubanks and

16
00:00:50,400 --> 00:00:51,400
Speaker 2:  Stefanos Cepa.

17
00:00:52,040 --> 00:00:54,480
Speaker 5:  Eubanks plays Tootsie Pass for the first time in the car.

18
00:00:55,370 --> 00:00:58,880
Speaker 2:  First of all it gets one of the two names just

19
00:00:59,050 --> 00:01:02,840
Speaker 2:  wrong. And then that's all it says for like 30 seconds.

20
00:01:03,190 --> 00:01:07,080
Speaker 2:  This is not commentary. Actually wait, this will be fun. Here

21
00:01:07,080 --> 00:01:11,000
Speaker 2:  is every single thing the AI says throughout the rest of this.

22
00:01:11,000 --> 00:01:12,480
Speaker 2:  Three and a half minute highlight clip.

23
00:01:12,870 --> 00:01:16,640
Speaker 5:  Tootsie Pass wins the first set after Eubanks unforced backhand error

24
00:01:16,740 --> 00:01:20,640
Speaker 5:  set. Number two, Tootsie Pass is forced into a backhand era, loses the second

25
00:01:20,780 --> 00:01:24,600
Speaker 5:  set. Set number three, unable to return the forehand from Tittie Pass.

26
00:01:25,040 --> 00:01:28,920
Speaker 5:  Eubanks loses the set break point opportunity for Eubanks. Eubanks

27
00:01:28,920 --> 00:01:32,400
Speaker 5:  wins the set after Tootsie Pass. Cannot deal with his serve. Tittie pass

28
00:01:32,400 --> 00:01:36,080
Speaker 5:  facing Breakpoint wins the Matchpoint defeating

29
00:01:36,080 --> 00:01:38,480
Speaker 5:  Tootsie passed six games to four in the last set.

30
00:01:39,380 --> 00:01:43,160
Speaker 2:  Did you get anything from that I mean? What is the point of this? It's not

31
00:01:43,370 --> 00:01:47,120
Speaker 2:  commentary. I'm not really sure what it is. I am

32
00:01:47,190 --> 00:01:51,000
Speaker 2:  very intrigued in general by the idea of AI commentary, which could have

33
00:01:51,000 --> 00:01:54,720
Speaker 2:  access to data and insights and real time knowledge

34
00:01:54,750 --> 00:01:58,680
Speaker 2:  that even the best humans can't see. But this ain't it

35
00:01:58,690 --> 00:02:02,080
Speaker 2:  folks. Oh wait, one more thing on this and then we will actually get to the

36
00:02:02,080 --> 00:02:05,880
Speaker 2:  show. Today's Vergecast is not about Wimbledon I promise, but the

37
00:02:05,910 --> 00:02:09,720
Speaker 2:  most actually commentary ish thing the AI has done

38
00:02:09,720 --> 00:02:13,560
Speaker 2:  for me, at least in the highlights I've seen so far was in a match with Andy

39
00:02:13,560 --> 00:02:17,240
Speaker 2:  Murray from a few days ago where it completely spoiled the play that was

40
00:02:17,240 --> 00:02:18,960
Speaker 2:  coming like three shots before it happened.

41
00:02:19,540 --> 00:02:21,720
Speaker 5:  Penton hits a backhand winner on Game point.

42
00:02:26,070 --> 00:02:30,040
Speaker 2:  It's really ridiculous, right? AI has lots of potential in

43
00:02:30,070 --> 00:02:33,680
Speaker 2:  lots of areas. We're gonna talk about some of it today, but it is definitely

44
00:02:33,700 --> 00:02:37,600
Speaker 2:  not stealing any commentary jobs just yet. Anyway, let's get to

45
00:02:37,600 --> 00:02:40,920
Speaker 2:  the show because it's a good one. We're gonna talk about all the new stuff

46
00:02:40,940 --> 00:02:44,800
Speaker 2:  in Apple's new betas because we're probably getting public betas soon, which

47
00:02:44,800 --> 00:02:48,200
Speaker 2:  means you'll be able to download the new software if you want to and there's

48
00:02:48,270 --> 00:02:51,800
Speaker 2:  lots of interesting stuff coming to phones and tablets and watchOS and TVs

49
00:02:51,800 --> 00:02:55,360
Speaker 2:  and all of Apple's devices. We're also gonna talk about how we talk about

50
00:02:55,660 --> 00:02:58,840
Speaker 2:  ai, LLMs chatbots and all this other

51
00:02:59,190 --> 00:03:02,900
Speaker 2:  vocabulary we've had to learn these last few months. And we're gonna talk

52
00:03:02,900 --> 00:03:05,740
Speaker 2:  about the video games we're most excited about this summer because there

53
00:03:05,760 --> 00:03:09,660
Speaker 2:  are a lot of them. All that is coming in just a sec. But first I

54
00:03:09,660 --> 00:03:13,100
Speaker 2:  just heard that a tennis player named Andre Rublev did like the coolest shot

55
00:03:13,100 --> 00:03:15,260
Speaker 2:  anyone has ever seen. Let me watch this real fast.

56
00:03:21,850 --> 00:03:25,230
Speaker 1:  He can't believe it and we can't either. The crowd up.

57
00:03:26,160 --> 00:03:30,100
Speaker 2:  See now that is commentary. Oh, and in case you were wondering, I

58
00:03:30,100 --> 00:03:33,180
Speaker 2:  went back and just watched the AI highlight and it had literally nothing

59
00:03:33,240 --> 00:03:36,980
Speaker 2:  to say about that point. Great job Watson. Cool future we're living in.

60
00:03:37,210 --> 00:03:38,900
Speaker 2:  This is The Vergecast. We'll be right back.

61
00:03:39,410 --> 00:03:43,380
Speaker 7:  That is one of the great shots we've seen here in years to get

62
00:03:43,380 --> 00:03:44,220
Speaker 7:  him to match point.

63
00:03:51,580 --> 00:03:53,520
Speaker 8:  I'm Lisa Ling, a journalist and host and

64
00:03:53,580 --> 00:03:57,440
Speaker 9:  I'm Ho Lee But. you may know me as chow on the Max original series Warrior

65
00:03:57,690 --> 00:03:59,200
Speaker 9:  based on the writings of Bruce Lee

66
00:03:59,450 --> 00:04:03,280
Speaker 8:  After. every new episode, join us here. Ho and I and a

67
00:04:03,280 --> 00:04:07,040
Speaker 8:  series of special guests are going to discuss how the show is made.

68
00:04:07,420 --> 00:04:11,280
Speaker 9:  So, Stream, Warrior, season three starting June 29th only on Max

69
00:04:11,460 --> 00:04:13,840
Speaker 9:  And. join us here or wherever you listen to podcasts

70
00:04:17,920 --> 00:04:21,780
Speaker 10:  On criminal, we bring you true crime stories told by

71
00:04:21,780 --> 00:04:23,220
Speaker 10:  people who know them best.

72
00:04:24,160 --> 00:04:27,380
Speaker 11:  We didn't believe in setting fires cause that was too dangerous. We were,

73
00:04:27,380 --> 00:04:31,020
Speaker 11:  you know, a kind, a gentler kind of crooks so to speak.

74
00:04:31,600 --> 00:04:33,860
Speaker 10:  So the best plan you had was that you'd LaSow it?

75
00:04:34,680 --> 00:04:36,860
Speaker 12:  Yes. Never imagined I'd use it for a camel.

76
00:04:39,280 --> 00:04:43,220
Speaker 10:  I'm Phoebe Judge and this is criminal. Did you have to say what

77
00:04:43,220 --> 00:04:44,020
Speaker 10:  was in the box

78
00:04:44,840 --> 00:04:45,980
Speaker 1:  Phoebe? We told lies.

79
00:04:46,880 --> 00:04:50,500
Speaker 10:  Listen to criminal every week, wherever you get your podcasts.

80
00:04:59,660 --> 00:05:03,430
Speaker 2:  Welcome back First up. Today we're gonna dive into all of the new

81
00:05:03,430 --> 00:05:06,950
Speaker 2:  Apple software coming to your devices this fall. The developer betas have

82
00:05:06,950 --> 00:05:10,070
Speaker 2:  been out for a while, so people who make apps can learn how to use the new

83
00:05:10,270 --> 00:05:14,190
Speaker 2:  features and tools and we're pretty sure the public beta is coming soon as

84
00:05:14,270 --> 00:05:17,470
Speaker 2:  well. So we figured we'd go through the stuff that matters, the stuff that's

85
00:05:17,470 --> 00:05:21,150
Speaker 2:  unexpectedly good and bad and somewhere in between and what you can

86
00:05:21,150 --> 00:05:24,550
Speaker 2:  expect either on the beta or this fall when you get the updates.

87
00:05:24,930 --> 00:05:26,990
Speaker 2:  We got a bunch to do. So let's get to it.

88
00:05:29,760 --> 00:05:33,150
Speaker 2:  First up, let's do watch OS with V Song. Hi V.

89
00:05:33,530 --> 00:05:33,750
Speaker 13:  Hi.

90
00:05:34,120 --> 00:05:35,750
Speaker 2:  We're gonna talk about watch OS 10.

91
00:05:36,290 --> 00:05:38,750
Speaker 13:  Yes, the the great old watch OS 10.

92
00:05:39,280 --> 00:05:43,230
Speaker 2:  Which Apple build as, what was it the biggest change to watch OS

93
00:05:43,240 --> 00:05:44,510
Speaker 2:  since watch OS?

94
00:05:44,890 --> 00:05:48,830
Speaker 13:  It was billed as a milestone and having used it for

95
00:05:48,990 --> 00:05:52,910
Speaker 13:  a couple weeks, I get why, but just on the surface it kind

96
00:05:52,910 --> 00:05:56,150
Speaker 13:  of feels like a mm, I think we should redefine what

97
00:05:56,590 --> 00:06:00,380
Speaker 13:  milestone is like at ww d c I was like, what

98
00:06:00,820 --> 00:06:04,500
Speaker 13:  milestone? It's just widgets. But having used it, it's, oh,

99
00:06:04,650 --> 00:06:06,820
Speaker 13:  it's widgets. It's widgets all the way down.

100
00:06:07,000 --> 00:06:10,940
Speaker 2:  Oh, interesting. Tell me more. What like what does it actually change about

101
00:06:10,940 --> 00:06:12,420
Speaker 2:  how you use the thing? A little

102
00:06:12,420 --> 00:06:16,220
Speaker 13:  Bit of everything. It's one of those significant but subtle

103
00:06:16,220 --> 00:06:20,060
Speaker 13:  changes like I can now use watch faces that don't have

104
00:06:20,060 --> 00:06:23,940
Speaker 13:  complications on it and not feel like I'm missing out, which for me is

105
00:06:23,940 --> 00:06:27,860
Speaker 13:  huge because I aesthetically don't love the look of

106
00:06:27,930 --> 00:06:31,740
Speaker 13:  modular duo or like modular, which is my go-to watch face.

107
00:06:31,960 --> 00:06:35,500
Speaker 13:  Yep. But you know, I have them because I'm a data

108
00:06:35,630 --> 00:06:38,940
Speaker 13:  girly, I need to see everything. I need to access my complications, I need

109
00:06:38,940 --> 00:06:42,740
Speaker 13:  things now, I need it yesterday and widgets allows me to use something

110
00:06:42,740 --> 00:06:46,700
Speaker 13:  like this little Snoopy guy, which by the way, Snoopy watch face,

111
00:06:46,850 --> 00:06:50,700
Speaker 13:  they undersold that. But basically the widgets allow

112
00:06:50,700 --> 00:06:54,420
Speaker 13:  me to use all these watch faces that I felt were not

113
00:06:54,650 --> 00:06:58,500
Speaker 13:  available to someone like me before. So you basically get a lot

114
00:06:58,500 --> 00:07:02,380
Speaker 13:  more personalization because of the widgets. And I actually liken it

115
00:07:02,480 --> 00:07:06,420
Speaker 13:  to kind of reading Chinese and Japanese versus English because you can

116
00:07:06,480 --> 00:07:10,220
Speaker 13:  absorb so much more, more quickly with a

117
00:07:10,220 --> 00:07:13,980
Speaker 13:  widget than you can with a tiny little complication or even just a little

118
00:07:14,230 --> 00:07:17,340
Speaker 13:  thing on your watch face. You can see it and go like, oh I now know the

119
00:07:17,340 --> 00:07:21,260
Speaker 13:  weather conditions for the next six hours in an instant. Which you

120
00:07:21,260 --> 00:07:25,220
Speaker 13:  know, it's wild. you know, widgets are not a revolutionary concept on

121
00:07:25,220 --> 00:07:28,940
Speaker 13:  smart watchOS where OS has them, their tiles, whatever they wanna call

122
00:07:28,950 --> 00:07:32,740
Speaker 13:  their particular brand of widgets. It makes a lot of sense

123
00:07:32,760 --> 00:07:36,500
Speaker 13:  to have. But watch OS has kind of been fumbling

124
00:07:36,500 --> 00:07:40,420
Speaker 13:  along without it since watch OS three I believe. So it's, it's kind of

125
00:07:40,520 --> 00:07:44,380
Speaker 13:  odd to see it come back and it's like dominoes because you've added

126
00:07:44,410 --> 00:07:48,260
Speaker 13:  widgets. Everything else needs to change in small subtle ways. So it's,

127
00:07:48,500 --> 00:07:52,260
Speaker 13:  it's really kind of been blowing my mind at how natural yet

128
00:07:52,330 --> 00:07:55,260
Speaker 13:  different everything feels compared to watch at West Nine. So

129
00:07:55,260 --> 00:07:58,100
Speaker 2:  The idea of the watch now, right, is that you have your watch face and then

130
00:07:58,280 --> 00:08:02,140
Speaker 2:  the stack of widgets kind of lives underneath it in sort of the the like

131
00:08:02,140 --> 00:08:06,060
Speaker 2:  mental model of the software, right? And so you do, you swipe up, do you

132
00:08:06,060 --> 00:08:07,700
Speaker 2:  scroll the, like how do you get to the widgets?

133
00:08:08,220 --> 00:08:12,100
Speaker 13:  You can either swipe or scroll up. So what you would use to do to get to

134
00:08:12,100 --> 00:08:15,380
Speaker 13:  control center now will bring you the smart stack of widgets

135
00:08:15,610 --> 00:08:19,060
Speaker 2:  Much better use of the space underneath than control center.

136
00:08:19,370 --> 00:08:22,740
Speaker 13:  Yeah, well control center you still have it. You just basically have to

137
00:08:22,960 --> 00:08:26,740
Speaker 13:  hit the slide button, which makes more sense when you think about it.

138
00:08:26,840 --> 00:08:30,660
Speaker 13:  But my muscle memory is completely effed up because

139
00:08:30,800 --> 00:08:34,740
Speaker 13:  I'm so used to doing things a certain way that now I'm always like, oh no

140
00:08:34,740 --> 00:08:38,500
Speaker 13:  wait, if I wanna find my phone because I used the find iPhone button like

141
00:08:38,560 --> 00:08:42,500
Speaker 13:  20 times in a day, I never know where my iPhone is. Like if I wanna

142
00:08:42,500 --> 00:08:45,900
Speaker 13:  use that I have to hit the side button. But now I'm bringing up widgets

143
00:08:45,900 --> 00:08:48,740
Speaker 13:  and just, oh like oh I appreciate the widgets but that's not what I wanted.

144
00:08:49,480 --> 00:08:53,180
Speaker 13:  So it's that type of small change that is

145
00:08:53,400 --> 00:08:57,260
Speaker 13:  really big when you think about it. But like that's just cuz I've been

146
00:08:57,260 --> 00:09:01,020
Speaker 13:  using Apple watchOS for forever. If you're new to it, you'll get used to

147
00:09:01,020 --> 00:09:02,260
Speaker 13:  it a lot faster than I am.

148
00:09:02,320 --> 00:09:05,980
Speaker 2:  That's fair. So the big thing I've been wondering about watch OS 10 is

149
00:09:06,280 --> 00:09:09,980
Speaker 2:  the thing I do probably more than any other activity on my watch

150
00:09:10,160 --> 00:09:14,100
Speaker 2:  is just like play and pause stuff that's like the

151
00:09:14,290 --> 00:09:17,900
Speaker 2:  most I touch my watchOS is if I'm like walking And I want to like change

152
00:09:17,900 --> 00:09:21,460
Speaker 2:  the song or go back in a podcast, part of the reason I like the watch is

153
00:09:21,460 --> 00:09:23,940
Speaker 2:  I don't have to dig into my pocket. I can just, you know, hit the thing.

154
00:09:24,360 --> 00:09:28,340
Speaker 2:  Are the widgets interactive? Do they work that way in that you

155
00:09:28,340 --> 00:09:32,060
Speaker 2:  can like I can just scroll up and hit pause in the pocket cast widget and

156
00:09:32,060 --> 00:09:33,340
Speaker 2:  this'll solve all my problems.

157
00:09:33,730 --> 00:09:37,580
Speaker 13:  Well right now I can't answer that fully because all the widgets are

158
00:09:37,630 --> 00:09:40,580
Speaker 13:  apple widgets. Yeah, it's all for the Apple native apps.

159
00:09:41,540 --> 00:09:45,260
Speaker 13:  We'll have to see what third parties do with it. But there is one

160
00:09:45,260 --> 00:09:49,100
Speaker 13:  widget that's basically three complications in one little widget

161
00:09:49,100 --> 00:09:52,500
Speaker 13:  stack. So Oh that's neat. you know that's, that one's kind of neat. It took

162
00:09:52,500 --> 00:09:55,820
Speaker 13:  me a while to figure out how I wanted to use it but I actually think that's

163
00:09:55,820 --> 00:09:59,540
Speaker 13:  pretty cool. But widgets are both like instantaneous

164
00:09:59,570 --> 00:10:03,540
Speaker 13:  information and an Appalachia in one. Okay. Which is interesting.

165
00:10:03,600 --> 00:10:07,460
Speaker 13:  So it's like complications magnified and then at the same

166
00:10:07,460 --> 00:10:11,380
Speaker 13:  time all the apps have been redesigned so the way you use apps

167
00:10:11,400 --> 00:10:15,020
Speaker 13:  on the watch is going to change. So you can still do all of that pretty

168
00:10:15,020 --> 00:10:18,780
Speaker 13:  quickly. It's just, I think the way you perceive and process information

169
00:10:18,780 --> 00:10:22,700
Speaker 13:  in watch OS 10 is much different. It feels like an actual

170
00:10:22,730 --> 00:10:26,620
Speaker 13:  mini phone app as opposed to like, let's just draw this phone

171
00:10:26,640 --> 00:10:30,380
Speaker 13:  app from memory and make it small. It's a very, it's a

172
00:10:30,380 --> 00:10:33,820
Speaker 13:  very subtle but significant change. Yeah. And I think that's kind of the

173
00:10:33,820 --> 00:10:37,500
Speaker 13:  theme with watch OS 10 where you're really not going to notice

174
00:10:38,120 --> 00:10:41,940
Speaker 13:  how different it is until you sit and think about it. Which is what

175
00:10:41,940 --> 00:10:43,260
Speaker 13:  I've been doing while writing my preview.

176
00:10:43,570 --> 00:10:45,260
Speaker 2:  Yeah, as as one does. Yeah

177
00:10:45,260 --> 00:10:49,140
Speaker 13:  It was like, oh there's not much different. Actually wait this app is completely

178
00:10:49,140 --> 00:10:52,380
Speaker 13:  changed. Like the weather app completely different. I love it. It's so,

179
00:10:52,380 --> 00:10:56,020
Speaker 13:  it's so much better than it. It was because you know the weather app used

180
00:10:56,020 --> 00:10:59,340
Speaker 13:  to just be like this giant screen that you scroll down and you're just like

181
00:10:59,340 --> 00:11:03,260
Speaker 13:  endlessly scrolling cuz you wanna know the chance of precipitation now you

182
00:11:03,260 --> 00:11:07,180
Speaker 13:  just like tap a thing and you switch to like, I guess I would

183
00:11:07,180 --> 00:11:11,100
Speaker 13:  call it the precipitation tab and there it is and you can see for the next

184
00:11:11,100 --> 00:11:15,060
Speaker 13:  12 hours like what your chance of rain is. It's, it very much feels like

185
00:11:15,100 --> 00:11:18,780
Speaker 13:  a better adaptation of a phone app than it's ever felt like before.

186
00:11:19,210 --> 00:11:19,500
Speaker 13:  Yeah,

187
00:11:19,510 --> 00:11:23,300
Speaker 2:  Thank God we're getting rid of the everything you need. Just scroll forever

188
00:11:23,480 --> 00:11:26,860
Speaker 2:  and ever on your wrist. That was not good App design, this is better.

189
00:11:27,010 --> 00:11:30,860
Speaker 13:  There's so much less scrolling and yet I use the Digital Crown a lot

190
00:11:30,860 --> 00:11:33,300
Speaker 13:  more. It's very weird. I don't understand why

191
00:11:33,490 --> 00:11:36,460
Speaker 2:  This is how they get you v it's a revolutionary input device. It's,

192
00:11:36,460 --> 00:11:40,180
Speaker 13:  It's the mouse of the Apple watch. I'm still

193
00:11:40,180 --> 00:11:44,100
Speaker 13:  scarred by that from the Apple Ultra podcaster did. But it's,

194
00:11:44,160 --> 00:11:47,980
Speaker 13:  it actually is more useful and more intuitive to use than it

195
00:11:47,980 --> 00:11:51,500
Speaker 13:  has been because then previously I would just be like scrolling

196
00:11:51,880 --> 00:11:55,740
Speaker 13:  and now it's just, it makes more sense to use it as I scroll between

197
00:11:55,740 --> 00:11:59,700
Speaker 13:  the different screens of, of the different watch OS apps.

198
00:11:59,970 --> 00:12:03,260
Speaker 13:  It's, I just can't wait to see what third party developers are gonna do

199
00:12:03,260 --> 00:12:06,900
Speaker 13:  with it because whether or not watch OS 10 does well

200
00:12:06,900 --> 00:12:10,660
Speaker 13:  overall I think it'll depend a lot on that because the app will

201
00:12:10,660 --> 00:12:14,580
Speaker 13:  watch apps are fine. Like the workout app is basically

202
00:12:14,580 --> 00:12:18,460
Speaker 13:  the same thing. It's just slightly easier to read but you know

203
00:12:18,460 --> 00:12:21,660
Speaker 13:  it, you can just be a lot more creative with how you design the watch. Like

204
00:12:21,660 --> 00:12:24,700
Speaker 13:  the activity app is completely different. The weather app is completely

205
00:12:24,700 --> 00:12:28,460
Speaker 13:  different and the way I interact with those apps is much more

206
00:12:28,740 --> 00:12:32,340
Speaker 13:  creative and free flowing than it would have been in the past.

207
00:12:32,600 --> 00:12:36,260
Speaker 13:  So you know, you know me, I love my focus modes. I'm gonna go ham, I'm gonna

208
00:12:36,260 --> 00:12:39,780
Speaker 13:  go ham on them. Love it. So that's, yeah but

209
00:12:39,920 --> 00:12:42,420
Speaker 13:  Snoopy watch face totally underrated. Okay,

210
00:12:42,420 --> 00:12:46,260
Speaker 2:  Well hard disagree but we'll, we'll save that for another time. This mostly

211
00:12:46,260 --> 00:12:49,780
Speaker 2:  seems like good news. Is there anything that sucks about watchOS 10? Anything

212
00:12:49,780 --> 00:12:50,540
Speaker 2:  you hate so far?

213
00:12:51,970 --> 00:12:55,860
Speaker 13:  Nothing I hate so far. Just like I haven't

214
00:12:55,920 --> 00:12:59,740
Speaker 13:  had as much time as I would like to get into the

215
00:12:59,740 --> 00:13:03,340
Speaker 13:  fitness stuff just because it's mostly cycling. I am a public hazard on

216
00:13:03,340 --> 00:13:07,140
Speaker 13:  a bike. I should not ride a bike so I'm gonna rope somebody in to give a

217
00:13:07,140 --> 00:13:11,060
Speaker 13:  more informed opinion on that And. I haven't had a chance to go hiking with

218
00:13:11,060 --> 00:13:14,900
Speaker 13:  it yet, so I can't tell you how good the maps are just yet. But

219
00:13:15,220 --> 00:13:19,060
Speaker 13:  I guess if I were to hate something, I actually don't love

220
00:13:19,060 --> 00:13:22,900
Speaker 13:  the way that they've changed your activity app in the sense

221
00:13:23,010 --> 00:13:26,860
Speaker 13:  that they've grouped your trophies and badges in a slightly different

222
00:13:26,860 --> 00:13:30,820
Speaker 13:  way. And it's kind of obnoxious to me. I don't, I don't love it.

223
00:13:30,890 --> 00:13:31,460
Speaker 13:  It's weird.

224
00:13:31,600 --> 00:13:34,380
Speaker 2:  That's one place where I like all the scrolling. I'm like, look at all this

225
00:13:34,380 --> 00:13:35,100
Speaker 2:  cool stuff I did.

226
00:13:35,360 --> 00:13:38,940
Speaker 13:  Oh it's, it's not like it's gone. It's just, you just, it's like switching

227
00:13:38,940 --> 00:13:42,420
Speaker 13:  between tabs and a mobile app. You just hit something and there it is and

228
00:13:42,420 --> 00:13:46,140
Speaker 13:  you can scroll a little bit to get more, more data. But it's just everything

229
00:13:46,160 --> 00:13:50,020
Speaker 13:  is much faster with less scrolling. Like it just makes

230
00:13:50,020 --> 00:13:53,540
Speaker 13:  sense when you use it. You just have to use it and you'll get what I mean.

231
00:13:53,720 --> 00:13:57,420
Speaker 13:  But it's, it's very hard to describe is what I'm learning right now.

232
00:13:58,570 --> 00:14:01,460
Speaker 2:  Fair enough. All right, well this is good news. This is better than I was

233
00:14:01,460 --> 00:14:05,380
Speaker 2:  hoping for. I was kind of expecting when we came out of WWDC being like,

234
00:14:05,580 --> 00:14:08,180
Speaker 2:  this doesn't seem like all that much but it sounds like it's, it all adds

235
00:14:08,180 --> 00:14:09,220
Speaker 2:  up to something that's exciting.

236
00:14:09,650 --> 00:14:12,860
Speaker 13:  Yeah and I'm telling you, you're wrong about the Snoopy one. It adjusts

237
00:14:12,860 --> 00:14:16,660
Speaker 13:  to your day. It's very cool in ways that I did not expect. I

238
00:14:16,660 --> 00:14:19,860
Speaker 13:  don't even like peanuts. I'm not a peanut head. I don't like Snoopy but

239
00:14:19,860 --> 00:14:21,860
Speaker 13:  I like the, the watch face. It's very strange.

240
00:14:22,200 --> 00:14:25,340
Speaker 2:  You're, you're a data girly but not a peanut head. This is what we're learning.

241
00:14:25,450 --> 00:14:25,740
Speaker 2:  Yeah.

242
00:14:25,740 --> 00:14:27,980
Speaker 13:  Data girly not a peanut head. That's me. I like it.

243
00:14:28,160 --> 00:14:29,100
Speaker 2:  All right v thank you.

244
00:14:29,520 --> 00:14:29,820
Speaker 13:  All right,

245
00:14:31,970 --> 00:14:35,940
Speaker 2:  Next up. TV v OS, the Apple tv. Chris watchOS is here. Hi Chris.

246
00:14:36,110 --> 00:14:39,620
Speaker 2:  Hello. Good to be back. I feel like TV v OS is

247
00:14:39,890 --> 00:14:43,580
Speaker 2:  more exciting than it was advertised at wwdc. It turns out there's actually

248
00:14:43,580 --> 00:14:46,780
Speaker 2:  like some stuff going on, right? What have you found so far? Yeah,

249
00:14:46,820 --> 00:14:49,940
Speaker 14:  I agree. This seems to be one of the bigger years for T V O S in quite a

250
00:14:49,940 --> 00:14:53,660
Speaker 14:  while. There's FaceTime obviously, which is one of those things that I kind

251
00:14:53,660 --> 00:14:57,620
Speaker 14:  of feel like would've been nice during the pandemic but I guess better late

252
00:14:57,620 --> 00:15:00,860
Speaker 14:  than never. Fair. So that's gonna be on there. And, I, guess Zoom and also

253
00:15:00,860 --> 00:15:04,140
Speaker 14:  WebEx are gonna have their apps on Apple TV as well. So that's one of the

254
00:15:04,140 --> 00:15:07,780
Speaker 14:  big ones. They redid the control center so it's a lot more dense with

255
00:15:07,780 --> 00:15:10,860
Speaker 14:  information now and shows the stuff you actually want there. There's like

256
00:15:10,860 --> 00:15:13,500
Speaker 14:  a sleep timer for your tv. If you're one of those people just, you know,

257
00:15:13,570 --> 00:15:17,540
Speaker 14:  nods off during Netflix There you go, you can have six icons per row now

258
00:15:17,540 --> 00:15:20,420
Speaker 14:  instead of five. And of course the most important thing is they have a lot

259
00:15:20,420 --> 00:15:23,580
Speaker 14:  more screen savers. Those dazzling four K screen savers. How

260
00:15:23,640 --> 00:15:27,060
Speaker 2:  Are the screen savers? Like you, I, I don't know if you're joking or not

261
00:15:27,060 --> 00:15:29,540
Speaker 2:  when you say that's the most important thing but I genuinely believe that

262
00:15:29,540 --> 00:15:32,940
Speaker 2:  is like the most important I, I don't know what it is about those screensavers

263
00:15:32,960 --> 00:15:36,500
Speaker 2:  but there's something, it's those screensavers and it's Roku City on the

264
00:15:36,580 --> 00:15:39,300
Speaker 2:  Roku. Yeah. That have like really solved the thing where I will just sit

265
00:15:39,300 --> 00:15:43,020
Speaker 2:  and look at my TV and not watch it for long periods of time as a result.

266
00:15:43,250 --> 00:15:47,220
Speaker 2:  Same are the new ones up to par with the old ones on, on Apple

267
00:15:47,240 --> 00:15:47,460
Speaker 2:  tv.

268
00:15:47,980 --> 00:15:50,460
Speaker 14:  So the new ones weren't in the first couple betas so I think there's gonna

269
00:15:50,460 --> 00:15:53,420
Speaker 14:  be like a later edition. I see. But I can't wait and I'm very excited like

270
00:15:53,420 --> 00:15:56,900
Speaker 14:  you, I don't know who does those, who's responsible for them but that should

271
00:15:56,900 --> 00:15:57,380
Speaker 14:  be a story.

272
00:15:57,530 --> 00:16:00,940
Speaker 2:  Yeah, whoever you are, you are please come on The Vergecast and tell us everything.

273
00:16:01,410 --> 00:16:05,300
Speaker 2:  What have you been using that surprised you either in good and bad ways so

274
00:16:05,300 --> 00:16:05,460
Speaker 2:  far?

275
00:16:06,180 --> 00:16:09,860
Speaker 14:  I mean the control center is nice. It feels more like the iPhones now that's

276
00:16:09,860 --> 00:16:13,060
Speaker 14:  easier to get around or get to your, your home scenes and your cameras and

277
00:16:13,060 --> 00:16:16,580
Speaker 14:  whatnot or change profiles. So just a lot of like just very small quality

278
00:16:16,580 --> 00:16:20,180
Speaker 14:  of life stuff. I mean Apple tv, just like the overall UX and like interface.

279
00:16:20,360 --> 00:16:23,380
Speaker 14:  I'm still a guy who like likes the home screen of apps cause I know where

280
00:16:23,380 --> 00:16:27,300
Speaker 14:  my shows are. Usually And, I can search if not or go to the TV app and up

281
00:16:27,300 --> 00:16:30,220
Speaker 14:  next and all those things. But yeah, they didn't have to add a lot I feel

282
00:16:30,220 --> 00:16:34,140
Speaker 14:  like. But they kind of did FaceTime. You can do like karaoke and see yourself

283
00:16:34,140 --> 00:16:37,620
Speaker 14:  on the screen now with Apple Sing and all. Oh wow kinda stuff and even add

284
00:16:37,620 --> 00:16:38,580
Speaker 14:  effects to it. How

285
00:16:38,580 --> 00:16:41,820
Speaker 2:  Does the continuity camera stuff work? Have you been able to test it?

286
00:16:42,250 --> 00:16:45,460
Speaker 14:  Yeah so you just start a FaceTime session on the TV and then you get like

287
00:16:45,460 --> 00:16:48,860
Speaker 14:  a prompt on your phone right away that asks like can I use this phone for

288
00:16:48,860 --> 00:16:52,620
Speaker 14:  continuity camera? Just like your Mac basically. And you say yes and

289
00:16:52,810 --> 00:16:53,460
Speaker 14:  away you go.

290
00:16:53,800 --> 00:16:57,340
Speaker 2:  What's the go-to strategy there? Do you sit on the couch and kind of hold

291
00:16:57,370 --> 00:17:00,860
Speaker 2:  your camera, like hold your phone up to be the camera? Do you prop it up

292
00:17:00,860 --> 00:17:02,940
Speaker 2:  somewhere? Like what's, what's the move here? Yeah I

293
00:17:02,940 --> 00:17:05,500
Speaker 14:  Think you had to prop it on a table maybe. Okay. I mean maybe they'll sell

294
00:17:05,860 --> 00:17:08,660
Speaker 14:  mounts cause they have like all the same stuff, you know like center stage

295
00:17:08,680 --> 00:17:11,540
Speaker 14:  on those like auto zoom and pan things right. That kind of just focus on

296
00:17:11,540 --> 00:17:14,100
Speaker 14:  you. You can put it pretty much wherever it should be able to do a decent

297
00:17:14,160 --> 00:17:18,060
Speaker 14:  job just finding you and putting your people on the big screen, which is

298
00:17:18,060 --> 00:17:19,060
Speaker 14:  pretty cool. And I must say.

299
00:17:19,330 --> 00:17:23,220
Speaker 2:  Yeah, one of my theories this year is that the iPad

300
00:17:23,480 --> 00:17:27,140
Speaker 2:  is turning into a sneaky great video conferencing

301
00:17:27,140 --> 00:17:31,060
Speaker 2:  device in part because like you're talking about, you can use it

302
00:17:31,120 --> 00:17:34,940
Speaker 2:  as a continuity camera thing for your tv. You can just set

303
00:17:35,080 --> 00:17:38,580
Speaker 2:  it down in landscape mode on your coffee table

304
00:17:38,920 --> 00:17:41,780
Speaker 2:  and it'll use center stage to follow you around And. I generally think center

305
00:17:41,780 --> 00:17:45,420
Speaker 2:  stage is ridiculous and stupid and bad because no one wants their

306
00:17:45,840 --> 00:17:49,780
Speaker 2:  webcam moving around as they talk on a video call. It's just distracting

307
00:17:49,780 --> 00:17:53,140
Speaker 2:  and awful. But in a case like this it actually makes sense why it would exist

308
00:17:53,140 --> 00:17:56,780
Speaker 2:  because it can kind of solve for some problems that exist. Yeah, for sure.

309
00:17:56,960 --> 00:18:00,660
Speaker 2:  I'm very happy about that. Any new apps? You mentioned the Zoom and stuff

310
00:18:00,660 --> 00:18:03,380
Speaker 2:  like are there, have you, have we heard anything from developers doing stuff

311
00:18:03,440 --> 00:18:05,420
Speaker 2:  for TV OS yet? Any ideas?

312
00:18:05,720 --> 00:18:09,540
Speaker 14:  Not a ton yet. There's more small stuff like there's VPN support now you

313
00:18:09,540 --> 00:18:12,740
Speaker 14:  can use those right on the Apple tv. So if you care about security and privacy

314
00:18:13,500 --> 00:18:16,540
Speaker 14:  like a lot of folks do, that's nice to have and a lot of small things. You

315
00:18:16,540 --> 00:18:19,860
Speaker 14:  can actually find your remote now. Oh yeah. With your iPhone, which is another

316
00:18:20,300 --> 00:18:22,820
Speaker 14:  blessing. There's no U one chip so it's not quite as precise as like a air

317
00:18:23,080 --> 00:18:26,420
Speaker 14:  tag or whatever, but you can you know, find it easily enough, which is better

318
00:18:26,420 --> 00:18:29,900
Speaker 14:  than before where you just had to say your prayers and go hunt for it.

319
00:18:30,320 --> 00:18:31,820
Speaker 14:  But yeah, so far so good.

320
00:18:31,970 --> 00:18:35,340
Speaker 2:  Yeah I'll take it. Is there anything, anything you don't like so far, anything

321
00:18:35,590 --> 00:18:39,140
Speaker 2:  still missing or not working properly that it, the beta, at least from what

322
00:18:39,140 --> 00:18:41,740
Speaker 2:  I've heard seems to be pretty solid for folks so far. Yeah, it's

323
00:18:41,740 --> 00:18:44,540
Speaker 14:  Pretty good. It's a low stakes. Beta I mean it's not the same thing as like

324
00:18:44,540 --> 00:18:47,700
Speaker 14:  putting like iOS 17 on your phone on your main iPhone or whatever. So if

325
00:18:47,700 --> 00:18:50,460
Speaker 14:  you're gonna play around the tv it's a pretty safe environment to do it.

326
00:18:50,460 --> 00:18:53,020
Speaker 14:  But yeah, so far so good. I'm looking forward to those screen savers and

327
00:18:53,020 --> 00:18:55,460
Speaker 14:  seeing what else comes up over the beta cycle.

328
00:18:55,820 --> 00:18:59,380
Speaker 2:  I like it. Yeah, the control center to me is like a sneaky big deal. I'm

329
00:18:59,380 --> 00:19:02,300
Speaker 2:  excited that that one has turned out because Apple is desperate to figure

330
00:19:02,320 --> 00:19:06,140
Speaker 2:  out how to make it like the hub of your home in all these interesting

331
00:19:06,140 --> 00:19:10,020
Speaker 2:  ways and this is a good way to do it that isn't just put more

332
00:19:10,020 --> 00:19:13,900
Speaker 2:  app icons onto your TV screen. Right. And, I think that that seems to

333
00:19:13,900 --> 00:19:15,300
Speaker 2:  be they get getting that right. Right.

334
00:19:15,300 --> 00:19:17,540
Speaker 14:  Yeah it's there if you want it. If you're a power user it's right there

335
00:19:17,540 --> 00:19:20,340
Speaker 14:  and easy to get to If you just wanna ignore it, you can do that too and

336
00:19:20,340 --> 00:19:21,220
Speaker 14:  just do whatever. Yeah,

337
00:19:21,260 --> 00:19:24,660
Speaker 2:  I used an Apple TV for the longest time without realizing control center

338
00:19:24,680 --> 00:19:27,940
Speaker 2:  was there at all. And. I actually have come around to thinking that's a big

339
00:19:27,960 --> 00:19:29,580
Speaker 2:  win. Like that's actually how that should work.

340
00:19:30,050 --> 00:19:31,580
Speaker 14:  Exactly. Yeah, same.

341
00:19:31,740 --> 00:19:35,460
Speaker 2:  I like it. All right Chris, thank you as always. We'll talk to you again

342
00:19:35,460 --> 00:19:35,660
Speaker 2:  soon.

343
00:19:35,960 --> 00:19:36,820
Speaker 14:  Yes sir. Cheers.

344
00:19:39,280 --> 00:19:42,940
Speaker 2:  Now let's do iOS 17 Allison Johnson's here. Hi

345
00:19:42,940 --> 00:19:46,460
Speaker 2:  Allison. Hello. You have the hardest job in this particular segment,

346
00:19:47,100 --> 00:19:50,900
Speaker 2:  which is just that you have by far the most to talk about because

347
00:19:51,120 --> 00:19:54,220
Speaker 2:  iOS 17, I was just going through the list. There's actually a lot of new

348
00:19:54,220 --> 00:19:58,100
Speaker 2:  stuff. Let's not get into everything. We have lots of time to

349
00:19:58,100 --> 00:20:01,500
Speaker 2:  get into everything, but you've been using it so far and the question I'm

350
00:20:01,500 --> 00:20:05,180
Speaker 2:  most curious about is in using the betas, what

351
00:20:05,290 --> 00:20:09,220
Speaker 2:  have you found yourself using that's new most often? Like what has

352
00:20:09,460 --> 00:20:11,660
Speaker 2:  actually sort of crept into your daily life of the new stuff?

353
00:20:11,970 --> 00:20:15,540
Speaker 16:  It's a lot of little things. And, I. Think that's, yeah there's just a

354
00:20:15,770 --> 00:20:19,380
Speaker 16:  huge laundry list of stuff that's updated like across

355
00:20:19,430 --> 00:20:23,220
Speaker 16:  everything you can imagine. But some things that stick out to me

356
00:20:23,360 --> 00:20:27,260
Speaker 16:  and they're not like glamorous or exciting but like the updates

357
00:20:27,320 --> 00:20:31,300
Speaker 16:  to the keyboard, you can write a swear word now and

358
00:20:31,360 --> 00:20:34,700
Speaker 16:  it doesn't just swoop in there and correct it for you.

359
00:20:35,060 --> 00:20:38,860
Speaker 2:  I have found auto autocorrect is wrong much less often. Yeah. Than it

360
00:20:38,860 --> 00:20:42,140
Speaker 2:  used to be. Yeah. And it might just be anecdotal, I might be paying more

361
00:20:42,140 --> 00:20:45,860
Speaker 2:  attention than normal but the number of texts that I have sent with

362
00:20:45,860 --> 00:20:48,100
Speaker 2:  autocorrect mistakes has gone way down.

363
00:20:48,310 --> 00:20:52,100
Speaker 16:  Right. I feel like I'm fighting it less. Yeah. Where you're constantly having

364
00:20:52,100 --> 00:20:55,020
Speaker 16:  to go back and be like, ah no that's not what I wanted to write. There's

365
00:20:55,020 --> 00:20:58,340
Speaker 16:  like extra little tools in there where it underlines something that it changed

366
00:20:58,640 --> 00:21:02,580
Speaker 16:  so you're less likely to like send the text and be like, oh my god I that's

367
00:21:02,720 --> 00:21:06,220
Speaker 16:  not what I meant to say. Just like little, little pleasant things

368
00:21:06,220 --> 00:21:10,140
Speaker 16:  throughout the keyboard that will be hard for anybody to really

369
00:21:10,330 --> 00:21:14,180
Speaker 16:  like identify even or be like wow this is a

370
00:21:14,180 --> 00:21:17,900
Speaker 16:  great new experience but it's just nicer. One that I know

371
00:21:17,910 --> 00:21:21,340
Speaker 16:  we're both fans of is standby. Yes. Which is a

372
00:21:21,430 --> 00:21:25,260
Speaker 16:  delightful little feature where you start charging your

373
00:21:25,260 --> 00:21:28,660
Speaker 16:  phone, turn it sideways and it turns

374
00:21:29,200 --> 00:21:32,780
Speaker 16:  the display into like a little clock or there's a couple options

375
00:21:32,970 --> 00:21:36,820
Speaker 16:  like a calendar with some widgets and the idea is you

376
00:21:36,820 --> 00:21:40,700
Speaker 16:  put it on kind of your nightstand and it's there for you when you

377
00:21:40,700 --> 00:21:43,340
Speaker 16:  wanna check the time in the middle of the night. It's so

378
00:21:43,340 --> 00:21:47,180
Speaker 2:  Nice. I really like it. There's a version of standby that you can basically

379
00:21:47,180 --> 00:21:51,140
Speaker 2:  just use as a photo viewer and the aspect ratio is not amazing.

380
00:21:51,140 --> 00:21:54,980
Speaker 2:  Right. Cuz you're basically on a like long short screen. But

381
00:21:54,980 --> 00:21:58,060
Speaker 2:  it's great. I just set it up to show my photos, And I, just have a photo

382
00:21:58,060 --> 00:22:00,740
Speaker 2:  viewer that sits there while my phone charges. Yeah, it's awesome. It's

383
00:22:00,740 --> 00:22:04,580
Speaker 16:  So nice. I love that. Works with any charger, you can use wired charging,

384
00:22:04,720 --> 00:22:07,860
Speaker 16:  you can use MagSafe, you can use whatever wireless charger you have lying

385
00:22:07,860 --> 00:22:11,540
Speaker 16:  around that's just like kind of un apple and lovely.

386
00:22:11,980 --> 00:22:15,820
Speaker 16:  I know, right? Yeah. So thanks guys. One that surprised me I was not

387
00:22:15,820 --> 00:22:19,780
Speaker 16:  expecting the like as much as I do is the new kind of

388
00:22:19,780 --> 00:22:23,300
Speaker 16:  interface for stickers. Okay. Gotta admit I don't use

389
00:22:23,380 --> 00:22:27,180
Speaker 16:  stickers a lot, but in IO 17 you can,

390
00:22:27,520 --> 00:22:31,420
Speaker 16:  you know how in IO 16 you could do those like image cutouts of someone

391
00:22:31,650 --> 00:22:32,860
Speaker 16:  from a photo or

392
00:22:33,210 --> 00:22:36,460
Speaker 2:  Yeah. You just long press and it like pulls out. Yeah, whatever the thing

393
00:22:36,460 --> 00:22:37,500
Speaker 2:  you're talking about is. Yeah,

394
00:22:37,570 --> 00:22:41,020
Speaker 16:  Yeah. Takes it outta the background. Everyone was like, this is cool, what

395
00:22:41,020 --> 00:22:44,820
Speaker 16:  do I do with this now you go, there's just an option right there

396
00:22:44,820 --> 00:22:48,780
Speaker 16:  to turn it into a sticker and you can go into your iMessage chat and

397
00:22:48,780 --> 00:22:52,420
Speaker 16:  you can put that sticker all over the chat like just on

398
00:22:52,560 --> 00:22:56,340
Speaker 16:  any message and it'll show up for everybody where you put it

399
00:22:57,120 --> 00:23:00,500
Speaker 16:  and you can turn a live photo into a sticker now too.

400
00:23:00,720 --> 00:23:03,700
Speaker 2:  That's awesome. I didn't know that actually is genuinely useful.

401
00:23:04,090 --> 00:23:07,820
Speaker 16:  It's fun. It's like a great new way to annoy your

402
00:23:07,820 --> 00:23:10,780
Speaker 16:  partner, which is I'm using it, I'm

403
00:23:10,780 --> 00:23:14,660
Speaker 2:  A big believer in anything that makes it so I can respond to a

404
00:23:14,780 --> 00:23:18,660
Speaker 2:  text message in like two taps. Yeah. Like the tap back

405
00:23:18,660 --> 00:23:22,060
Speaker 2:  stuff is so good for that reason and having a bunch of stickers where I can

406
00:23:22,060 --> 00:23:24,580
Speaker 2:  just like anytime we're talking about the dog, I can just like press the

407
00:23:24,580 --> 00:23:28,420
Speaker 2:  dog sticker and just boom, there it goes. Love that. Yep. Into that. What

408
00:23:28,420 --> 00:23:31,340
Speaker 2:  have you seen with the phone call stuff so far? Obviously this'll be easier

409
00:23:31,360 --> 00:23:35,140
Speaker 2:  to see once more people have iOS 17, but there's the contact

410
00:23:35,290 --> 00:23:39,220
Speaker 2:  posters, there's the live voicemail stuff. Any, anything jump out to

411
00:23:39,220 --> 00:23:40,180
Speaker 2:  you in that space so far?

412
00:23:40,690 --> 00:23:44,220
Speaker 16:  Yeah, I played with contact posters a little bit. It's very much like the

413
00:23:44,220 --> 00:23:46,860
Speaker 16:  lock screen on Iowa 16. Same kind of deal.

414
00:23:47,240 --> 00:23:49,780
Speaker 2:  Did you pick a photo or AMO for your contact poster?

415
00:23:50,040 --> 00:23:53,820
Speaker 16:  Oh I did a photo. I can't do an emoji. I don't know, I think I'm too old

416
00:23:54,080 --> 00:23:57,940
Speaker 16:  or not old enough or like I'm in a middle ground where like I

417
00:23:57,940 --> 00:24:01,380
Speaker 16:  missed emojis. But yeah, it's a lot of pressure. It

418
00:24:01,380 --> 00:24:04,340
Speaker 2:  Really is a lot of pressure. I spent a long time setting mine up.

419
00:24:04,570 --> 00:24:08,020
Speaker 16:  Yeah. I have like three different ones that I'm like, maybe I'll be on a

420
00:24:08,020 --> 00:24:11,340
Speaker 16:  different mood and I'll pick a different one. So those will be fun. It'll

421
00:24:11,340 --> 00:24:15,180
Speaker 16:  be really interesting to see like who adopts it and what the uptake rate

422
00:24:15,180 --> 00:24:18,660
Speaker 16:  is is like everyone gonna have a contact poster all at once so that that

423
00:24:18,660 --> 00:24:22,580
Speaker 16:  one will get, I think more interesting as the beta rolls out and the full

424
00:24:22,580 --> 00:24:26,300
Speaker 16:  release comes. But the live transcription on

425
00:24:26,570 --> 00:24:30,340
Speaker 16:  voicemail a hundred percent love it. I'm never picking it by phone

426
00:24:30,340 --> 00:24:34,220
Speaker 16:  again. Like this is, this is what I need and it, it's

427
00:24:34,440 --> 00:24:38,380
Speaker 16:  should mention that Google Pixel phones do a similar thing where the

428
00:24:38,380 --> 00:24:42,260
Speaker 16:  assistant will kind of be like, this person is using a screening

429
00:24:42,260 --> 00:24:45,460
Speaker 16:  service, what are you calling about? But I kind of love the Apple. It's

430
00:24:45,460 --> 00:24:49,220
Speaker 16:  just like you're just leaving a voicemail and then you can just

431
00:24:49,220 --> 00:24:52,340
Speaker 16:  like spy on what they're saying as they say it.

432
00:24:52,480 --> 00:24:56,380
Speaker 2:  It is really good. It works surprisingly seamlessly too. I've had a couple

433
00:24:56,750 --> 00:24:59,500
Speaker 2:  where I'm just straight up screening calls. It's like being in the nineties

434
00:24:59,500 --> 00:25:00,700
Speaker 2:  again. It's the best. Yeah.

435
00:25:00,800 --> 00:25:04,460
Speaker 16:  Oh it's so good. I had some robot call me about

436
00:25:04,460 --> 00:25:08,020
Speaker 16:  Comcast offers And I was like, see ya. Nope.

437
00:25:09,130 --> 00:25:12,500
Speaker 2:  Love that. Anything you haven't liked so far in, in the beta, I've had some

438
00:25:12,500 --> 00:25:15,940
Speaker 2:  pretty real performance and battery issues, which is like

439
00:25:16,160 --> 00:25:19,740
Speaker 2:  normal for a beta and so I'm not super worried about it. But have you had

440
00:25:19,760 --> 00:25:23,300
Speaker 2:  any, anything that's jumped out to you in IO 17 You Don't like so far

441
00:25:23,960 --> 00:25:27,860
Speaker 16:  Not terrible. I am running it, I've used it a little bit on a 14 pro,

442
00:25:27,880 --> 00:25:31,860
Speaker 16:  but I have it on my own 13 mini. So when the battery life

443
00:25:31,860 --> 00:25:35,700
Speaker 16:  is kind of crummy, I'm like, this could be because the battery life is

444
00:25:35,700 --> 00:25:39,220
Speaker 16:  sort of crummy on my phone. But yeah. Yeah, just a couple of like

445
00:25:39,650 --> 00:25:43,020
Speaker 16:  bugs and things, you know as we've observed getting onto

446
00:25:43,250 --> 00:25:46,980
Speaker 16:  threads, like there's some weird bug where you couldn't post a photo but

447
00:25:47,120 --> 00:25:50,740
Speaker 2:  The app would instantly crash every time you tried to post a photo on threads.

448
00:25:50,930 --> 00:25:51,420
Speaker 2:  It's great.

449
00:25:51,420 --> 00:25:53,980
Speaker 16:  Yeah, it was, it was fun. This is the first thing you do is get in there

450
00:25:53,980 --> 00:25:57,540
Speaker 16:  like, I'm gonna post a photo. Nope. Yep. Try it again.

451
00:25:58,090 --> 00:26:02,060
Speaker 16:  Yeah, no, overall it's been a really positive experience and

452
00:26:02,240 --> 00:26:06,020
Speaker 16:  I'm, I'm excited. Like I'm excited for people to download it

453
00:26:06,320 --> 00:26:09,180
Speaker 16:  and then they can see what I'm talking about. Cuz right now I'm just telling

454
00:26:09,240 --> 00:26:11,980
Speaker 16:  my friends like stickers and they're like, what?

455
00:26:12,650 --> 00:26:15,700
Speaker 2:  Yeah, this is that awkward time of year where you're sending people like

456
00:26:15,760 --> 00:26:19,300
Speaker 2:  broken things that they can barely see. You're like, look at this sticker.

457
00:26:19,300 --> 00:26:21,460
Speaker 2:  And they're like, what is this tiny image that you just sent me?

458
00:26:21,940 --> 00:26:25,380
Speaker 16:  I kept trying to put them in Slack and they just look like the grossest

459
00:26:25,640 --> 00:26:28,820
Speaker 16:  little PNGs where I was like, you guys have to trust me.

460
00:26:29,600 --> 00:26:30,300
Speaker 16:  It looks cool.

461
00:26:30,880 --> 00:26:33,660
Speaker 2:  All right, awesome. Well yeah, there's, there's lots more to talk about in

462
00:26:33,720 --> 00:26:36,580
Speaker 2:  iOS 17, so we'll we'll have to come back to lots of this, but good luck with

463
00:26:36,830 --> 00:26:38,540
Speaker 2:  betas and Godspeed as always.

464
00:26:38,750 --> 00:26:39,220
Speaker 16:  Thank you.

465
00:26:41,120 --> 00:26:41,780
Speaker 17:  The iPad,

466
00:26:42,320 --> 00:26:46,020
Speaker 2:  The last one we should talk about quickly is iPadOS 17, which is the one

467
00:26:46,020 --> 00:26:48,740
Speaker 2:  I've been goofing around with. I have it installed on an iPad Mini and an

468
00:26:48,740 --> 00:26:52,500
Speaker 2:  iPad Pro. There are lots of little new things here. Most of them borrowed

469
00:26:52,570 --> 00:26:56,420
Speaker 2:  from iOS 16 and 17. So if you use an iPhone, most of the stuff on the

470
00:26:56,420 --> 00:27:00,180
Speaker 2:  iPad will not be surprising. But there are two things on the iPad that I

471
00:27:00,180 --> 00:27:03,900
Speaker 2:  wanna mention. The first is the lock screen. iPadOS 17

472
00:27:03,970 --> 00:27:07,420
Speaker 2:  lets you customize your lock screen mostly like you can on the iPhone with

473
00:27:07,420 --> 00:27:11,260
Speaker 2:  different fonts and colors and stuff. But you also get a rail of lock screen

474
00:27:11,260 --> 00:27:14,620
Speaker 2:  widgets on the left side, which is super useful and you can actually fit

475
00:27:14,700 --> 00:27:18,140
Speaker 2:  a lot of widgets there because you just have more screen space. I would much

476
00:27:18,140 --> 00:27:21,940
Speaker 2:  rather have more of them though since there's so much screen space here.

477
00:27:22,170 --> 00:27:25,700
Speaker 2:  It's just kind of being unused, putting just the tiny widgets on the left.

478
00:27:26,170 --> 00:27:30,060
Speaker 2:  Give me full sized widgets, give me the new interactive widgets on iOS

479
00:27:30,060 --> 00:27:33,820
Speaker 2:  and iPadOS. Let me like really do stuff from my lock screen.

480
00:27:34,040 --> 00:27:38,020
Speaker 2:  But hey, some widgets is better than no widgets, so I'll take it. The

481
00:27:38,020 --> 00:27:41,660
Speaker 2:  other thing is stage manager. If you're a longtime Vergecast listener, you

482
00:27:41,660 --> 00:27:45,260
Speaker 2:  know that last year when Stage Manager came out, I hated it. Like

483
00:27:45,430 --> 00:27:49,380
Speaker 2:  hated it. Stage Manager is the multitasking feature that lets you switch

484
00:27:49,380 --> 00:27:52,420
Speaker 2:  between collections of apps. So you can have a few things on the screen at

485
00:27:52,420 --> 00:27:56,380
Speaker 2:  a time, but mostly it's buggy and bad and pointless. I don't know, I

486
00:27:56,380 --> 00:28:00,140
Speaker 2:  don't get it. But this year Apple did make some big improvements. And I

487
00:28:00,140 --> 00:28:04,020
Speaker 2:  still don't think it's great, but I at least see the potential. The big

488
00:28:04,020 --> 00:28:07,900
Speaker 2:  change is that you can now move apps more or less freely around the screen.

489
00:28:07,930 --> 00:28:11,860
Speaker 2:  They can be almost any size and go almost anywhere on your iPad instead of

490
00:28:11,860 --> 00:28:15,220
Speaker 2:  just having to fit into these predetermined slots like before.

491
00:28:15,850 --> 00:28:19,820
Speaker 2:  That alone makes it feel much more like actual multitasking and makes

492
00:28:19,940 --> 00:28:23,460
Speaker 2:  Sage Manager way more useful. If you're the kind of person who uses their

493
00:28:23,490 --> 00:28:27,180
Speaker 2:  iPad with a mouse and keyboard and external monitor, Sage Manager really

494
00:28:27,200 --> 00:28:30,780
Speaker 2:  is for you. It's a decent system for managing multiple apps on multi multiple

495
00:28:30,810 --> 00:28:34,660
Speaker 2:  screens and it's a lot better now than it was, but it's still

496
00:28:34,660 --> 00:28:38,620
Speaker 2:  just awkwardly implemented on the iPad. You can't command tab

497
00:28:38,620 --> 00:28:42,180
Speaker 2:  between stages, you can only have four apps in a stage. You can only have

498
00:28:42,440 --> 00:28:46,420
Speaker 2:  one app in a single stage and you can't save stages as

499
00:28:46,420 --> 00:28:50,220
Speaker 2:  they are. So everything just kind of ends up awkward and strewn about unless

500
00:28:50,320 --> 00:28:54,300
Speaker 2:  you set up your stages and then never ever change them or download new apps

501
00:28:54,560 --> 00:28:58,500
Speaker 2:  or anything. It's just still too much work for not that much gain. I

502
00:28:58,500 --> 00:29:02,340
Speaker 2:  think I still don't plan to keep using Stage Manager, but I do at

503
00:29:02,340 --> 00:29:05,780
Speaker 2:  least think there's maybe a future in the idea as Apple figures out ways

504
00:29:05,840 --> 00:29:09,500
Speaker 2:  to integrate it more and more with the rest of the iPad. I still don't plan

505
00:29:09,500 --> 00:29:13,340
Speaker 2:  to keep using Stage Manager, but I at least think there's maybe a

506
00:29:13,340 --> 00:29:16,900
Speaker 2:  future in the concept as Apple keeps working to integrate it better and better

507
00:29:16,900 --> 00:29:20,660
Speaker 2:  with the rest of the iPad. Otherwise, on the iPad there's a health app now,

508
00:29:20,660 --> 00:29:24,620
Speaker 2:  which is nice. and iPadOS 17 actually does make the iPad maybe

509
00:29:24,640 --> 00:29:28,260
Speaker 2:  the best PDF editing device I've ever used. It actually automatically

510
00:29:28,370 --> 00:29:32,300
Speaker 2:  detects all the fields you can fill in and you can either just type or scribble

511
00:29:32,300 --> 00:29:36,220
Speaker 2:  to fill it out. It's awesome. But mostly, you know, the iPad is

512
00:29:36,220 --> 00:29:40,180
Speaker 2:  the iPad is the iPad. Alright, we gotta take a break and then

513
00:29:40,180 --> 00:29:43,580
Speaker 2:  we're gonna come back and talk about how we talk about ai. We'll be right

514
00:29:43,580 --> 00:29:43,740
Speaker 2:  back.

515
00:29:48,130 --> 00:29:52,040
Speaker 18:  Hello, I'm Esther Perel. I'm a psychotherapist and host of the

516
00:29:52,040 --> 00:29:55,600
Speaker 18:  podcast. Where should we begin? Relationships, expectations

517
00:29:55,820 --> 00:29:59,720
Speaker 18:  are at an all time high and yet the norms

518
00:29:59,900 --> 00:30:03,760
Speaker 18:  are less and less clear and we are literally making up the new

519
00:30:03,770 --> 00:30:07,720
Speaker 18:  norms as we go. Whether it's your work relationships,

520
00:30:07,990 --> 00:30:11,920
Speaker 18:  friendships or romantic relationships. I invite you

521
00:30:12,140 --> 00:30:15,680
Speaker 18:  to enter into my office and listen in on my

522
00:30:15,680 --> 00:30:19,440
Speaker 18:  sessions where I help people explore the challenges

523
00:30:19,660 --> 00:30:23,640
Speaker 18:  and choices in their relationships. You will listen

524
00:30:24,270 --> 00:30:27,800
Speaker 18:  intensely to them, but you will actually see

525
00:30:27,800 --> 00:30:31,320
Speaker 18:  yourselves and in the process you become unstuck

526
00:30:31,740 --> 00:30:34,160
Speaker 18:  and empowered in your own relationships.

527
00:30:35,550 --> 00:30:39,400
Speaker 18:  Join me in my office every Monday morning for a new

528
00:30:39,430 --> 00:30:43,360
Speaker 18:  episode. Listen and follow. Where should we begin

529
00:30:43,500 --> 00:30:45,240
Speaker 18:  on your favorite podcast app?

530
00:30:51,160 --> 00:30:54,810
Speaker 2:  Welcome back. One of the weird things that has happened over the last,

531
00:30:55,300 --> 00:30:59,050
Speaker 2:  let's say nine months, is that all kinds of AI terms have

532
00:30:59,050 --> 00:31:03,010
Speaker 2:  found their way into our vocabulary. GPT, LLM,

533
00:31:03,490 --> 00:31:07,090
Speaker 2:  transformers, hallucinations, all these things that no reasonable

534
00:31:07,140 --> 00:31:11,090
Speaker 2:  human knew about before are just words we use now, but Are,

535
00:31:11,090 --> 00:31:14,770
Speaker 2:  we using them the right way and Does it matter how we use them.

536
00:31:14,870 --> 00:31:18,690
Speaker 2:  As we talk about AI and as AI changes so fast, I

537
00:31:18,690 --> 00:31:21,850
Speaker 2:  can't stop thinking about this. So I called up the verges James Vincent to

538
00:31:21,850 --> 00:31:23,210
Speaker 2:  help me sort it out. Hi James.

539
00:31:23,670 --> 00:31:24,730
Speaker 19:  Hi David. How are you doing?

540
00:31:25,310 --> 00:31:28,410
Speaker 2:  I'm good. You're now three days into book leave on a very mysterious book

541
00:31:28,410 --> 00:31:31,730
Speaker 2:  that you're not willing to tell anyone about. How's it going to you? Miss

542
00:31:31,730 --> 00:31:32,450
Speaker 2:  is terribly already.

543
00:31:33,130 --> 00:31:37,010
Speaker 19:  I miss you terribly. I wake up every day. I see things in

544
00:31:37,510 --> 00:31:41,410
Speaker 19:  my feeds in my Twitter follows. I genuinely have been lurking on

545
00:31:41,410 --> 00:31:45,130
Speaker 19:  Slack. I've had, this is so terrible. I've had Slack open. I'm already regretting

546
00:31:45,370 --> 00:31:48,610
Speaker 19:  somewhat my decision to take leave, but I'm, I'm trying to make predictions,

547
00:31:49,340 --> 00:31:52,170
Speaker 19:  write some stuff down now what I think is gonna happen the rest of the year

548
00:31:52,270 --> 00:31:56,210
Speaker 19:  and then six months time I'll check in and be like, oh, did was

549
00:31:56,210 --> 00:31:57,170
Speaker 19:  that right? Was that wrong?

550
00:31:57,560 --> 00:32:00,970
Speaker 2:  Once you finished that list, come back on the show. I, we, we should do that

551
00:32:00,970 --> 00:32:04,610
Speaker 2:  in public so we can shame you for this. But the reason I've dragged you here

552
00:32:04,610 --> 00:32:08,410
Speaker 2:  today is because I want to talk about how we

553
00:32:08,440 --> 00:32:11,970
Speaker 2:  talk about AI And, I've been thinking about this for a while, but this has

554
00:32:11,970 --> 00:32:15,810
Speaker 2:  really sparked for me listening to a podcast a couple of weeks ago where

555
00:32:16,000 --> 00:32:19,810
Speaker 2:  they had this otherwise very interesting conversation about ai, but

556
00:32:19,960 --> 00:32:23,610
Speaker 2:  kept talking about it in just the worst ways. And it was talking about like

557
00:32:23,610 --> 00:32:27,570
Speaker 2:  when you do something with the ai and it just, it makes me cringe every time

558
00:32:27,570 --> 00:32:31,290
Speaker 2:  that happens. And then I've been reading all this stuff and we're using all

559
00:32:31,290 --> 00:32:35,170
Speaker 2:  these terms like AI and machine learning and LLMs

560
00:32:35,170 --> 00:32:38,970
Speaker 2:  and chat GPT and chat bots and all this stuff just becomes

561
00:32:39,080 --> 00:32:42,860
Speaker 2:  so sort of interchanged to the point of being meaningless.

562
00:32:43,200 --> 00:32:47,180
Speaker 2:  So what I wanna do here with you, my, my British pedantic

563
00:32:47,180 --> 00:32:51,060
Speaker 2:  friend is try and sort this out a little bit because I actually think it's

564
00:32:51,060 --> 00:32:53,780
Speaker 2:  really important we're in this moment where this stuff is moving really fast

565
00:32:53,780 --> 00:32:56,980
Speaker 2:  and it's so transformative that I actually think the way we talk about it

566
00:32:57,180 --> 00:33:00,860
Speaker 2:  matters. And so I want to just not exactly like

567
00:33:00,960 --> 00:33:04,660
Speaker 2:  define terms, but I want to just sort of think through how we talk about

568
00:33:04,660 --> 00:33:06,500
Speaker 2:  this stuff. Does that sound good? Is that a good plan?

569
00:33:06,730 --> 00:33:08,380
Speaker 19:  Yeah, perfect. Loved it. Love to be

570
00:33:08,380 --> 00:33:12,180
Speaker 2:  Pedantic. I love it. So let's just literally start with the term ai, which

571
00:33:12,180 --> 00:33:16,020
Speaker 2:  is a thing we force ourselves to use and have to use all the

572
00:33:16,020 --> 00:33:19,660
Speaker 2:  time. It gets used for everything. It is, it is like so

573
00:33:19,770 --> 00:33:23,540
Speaker 2:  broadly defined as to be almost sort of meaningless now. Mm.

574
00:33:23,980 --> 00:33:27,740
Speaker 2:  I it's not quite a technical term because it's like

575
00:33:27,850 --> 00:33:31,540
Speaker 2:  just to call something the AI is to refer to like the code, which is just

576
00:33:31,540 --> 00:33:35,020
Speaker 2:  not how we talk about things. But I am curious, like as you think about

577
00:33:35,370 --> 00:33:39,180
Speaker 2:  what you mean when you say AI at this point, both for you as a reporter

578
00:33:39,180 --> 00:33:42,580
Speaker 2:  reporting on this stuff, and for you as just a person in the world living

579
00:33:42,580 --> 00:33:46,380
Speaker 2:  with this stuff, where does it fit into kind of your vocabulary

580
00:33:46,380 --> 00:33:46,980
Speaker 2:  correctly?

581
00:33:47,360 --> 00:33:50,900
Speaker 19:  You are completely right in that the definition of AI is so diffuse as to

582
00:33:50,900 --> 00:33:54,620
Speaker 19:  be sort of useless. It is such a broad term. It applies to so many

583
00:33:54,620 --> 00:33:57,940
Speaker 19:  different specific applications, technological methods,

584
00:33:58,350 --> 00:34:02,140
Speaker 19:  ideas, concepts, that it's very difficult to say

585
00:34:02,140 --> 00:34:06,020
Speaker 19:  what it is. What I like to do is not think about necessarily

586
00:34:06,020 --> 00:34:09,180
Speaker 19:  what the strict definition is, but think about how

587
00:34:10,120 --> 00:34:14,100
Speaker 19:  we use it in terms of how it fits into other frameworks

588
00:34:14,100 --> 00:34:17,900
Speaker 19:  and how we think about it conceptually. So you mentioned just now one of

589
00:34:17,900 --> 00:34:21,020
Speaker 19:  the things you dislike is talking about the ai, like the AI did this, the

590
00:34:21,080 --> 00:34:24,900
Speaker 19:  AI did that. I hate that too. you know, I, I've spoken to Verge staff

591
00:34:24,900 --> 00:34:28,460
Speaker 19:  people about this And I. I, I try to sort of give a Verge

592
00:34:28,460 --> 00:34:31,940
Speaker 19:  framework on it and there's no Official policy, but one of my

593
00:34:32,320 --> 00:34:36,140
Speaker 19:  big no-nos for covering AI is anthropomorphizing the ai. And

594
00:34:36,140 --> 00:34:39,700
Speaker 19:  that involves turning it into this discreet entity that happens when you

595
00:34:39,800 --> 00:34:43,540
Speaker 19:  use the grammatical form. The AI and ai, AI did this.

596
00:34:44,080 --> 00:34:48,020
Speaker 19:  So I, I don't really mind the term. I know some people,

597
00:34:48,570 --> 00:34:52,380
Speaker 19:  some researchers are really critical of it and they're like,

598
00:34:52,380 --> 00:34:56,300
Speaker 19:  you know, they put artificial in and intelligence in, in inverted commerce

599
00:34:56,440 --> 00:34:59,540
Speaker 19:  and they, you know, they really hate seeing it used And I. I respect that

600
00:34:59,600 --> 00:35:03,260
Speaker 19:  as a viewpoint, but it is not the one I think is the right approach

601
00:35:03,260 --> 00:35:06,740
Speaker 19:  because I think that has to be a language for people who are

602
00:35:06,740 --> 00:35:09,860
Speaker 19:  non-experts to talk about this stuff. And AI has become the phrase we use.

603
00:35:10,250 --> 00:35:13,740
Speaker 19:  Fine, let's just go with it. If we've accepted it is the phrase we use,

604
00:35:13,810 --> 00:35:17,780
Speaker 19:  then what becomes important is yes, as I say, how we conceptualize it. So

605
00:35:17,780 --> 00:35:21,740
Speaker 19:  we don't want to anthropomorphize it, we don't want to give it agency

606
00:35:21,740 --> 00:35:25,580
Speaker 19:  when it has none. So we can, I think we can talk about AI as much as we

607
00:35:25,580 --> 00:35:28,700
Speaker 19:  like and we can talk about what people are doing with it. But that is the

608
00:35:28,700 --> 00:35:32,340
Speaker 19:  thing. Yeah, we need to remember how it is being used and who is ultimately

609
00:35:32,490 --> 00:35:36,100
Speaker 19:  responsible for it. you know, there's that great, been a bit of a

610
00:35:36,410 --> 00:35:40,300
Speaker 19:  meme on Twitter for a while, a presentation card from an IBM

611
00:35:40,650 --> 00:35:43,820
Speaker 19:  sort of slideshow given to management in the 1970s. This is a great old

612
00:35:43,820 --> 00:35:47,540
Speaker 19:  looking presentation card, old sort of courier type font being used. And

613
00:35:47,540 --> 00:35:50,940
Speaker 19:  it says, machines must never make a management decision because

614
00:35:51,020 --> 00:35:54,100
Speaker 19:  machines can't be held responsible for management decisions. Something like

615
00:35:54,100 --> 00:35:57,460
Speaker 19:  that. Mm. I think something similar applies to AI

616
00:35:57,880 --> 00:36:01,740
Speaker 19:  in that we may say casually AI is doing that or AI is

617
00:36:01,740 --> 00:36:05,100
Speaker 19:  doing this, but we need to remember who put those systems in place, who

618
00:36:05,110 --> 00:36:08,940
Speaker 19:  bears responsibility. you know, we live in a society where

619
00:36:08,940 --> 00:36:12,820
Speaker 19:  machines cannot be responsible, humans can be responsible. And

620
00:36:12,820 --> 00:36:16,540
Speaker 19:  if there is to be justice, if there is to be, you know, a, a sort of

621
00:36:16,730 --> 00:36:20,500
Speaker 19:  fair, a fair society to live in, then we need to remember the humans at

622
00:36:20,500 --> 00:36:23,980
Speaker 19:  the heart of it, not ai. So that's, that's a terribly

623
00:36:24,110 --> 00:36:27,780
Speaker 19:  conceptual over the top approach to that question. But in short, I don't

624
00:36:27,780 --> 00:36:31,340
Speaker 19:  think definitions matter so much as the context sheet that you put those

625
00:36:31,340 --> 00:36:32,540
Speaker 19:  terms in. Yeah,

626
00:36:32,560 --> 00:36:35,540
Speaker 2:  No, I think, I think that makes a lot of sense. And, I think as we talk about

627
00:36:35,600 --> 00:36:39,300
Speaker 2:  the ai, I've come to think of it as sort of synonymous with like the technology

628
00:36:39,610 --> 00:36:43,500
Speaker 2:  that it's, it's a thing that you use if you don't sort of immediately further

629
00:36:43,500 --> 00:36:46,020
Speaker 2:  define it, you're just telling on yourself as somebody who doesn't understand

630
00:36:46,020 --> 00:36:49,140
Speaker 2:  what the hell you're talking about. Because what it is is like technology

631
00:36:49,200 --> 00:36:52,460
Speaker 2:  is not a thing, it's an umbrella term for lots of things, right? And, I think

632
00:36:52,680 --> 00:36:56,580
Speaker 2:  AI is the same way. Like AI is not a thing, but it is, it is

633
00:36:56,580 --> 00:36:59,180
Speaker 2:  a category of things. But if you're gonna talk about it, you have to then

634
00:36:59,180 --> 00:37:03,060
Speaker 2:  talk about the more specific things right away or else I'm just gonna

635
00:37:03,060 --> 00:37:04,580
Speaker 2:  assume you have no idea what you're talking about.

636
00:37:05,010 --> 00:37:08,740
Speaker 19:  Yeah, I agree with you. You, you, you, it's fine. You can use the term and

637
00:37:08,740 --> 00:37:09,780
Speaker 19:  maybe you're against using the term.

638
00:37:09,920 --> 00:37:13,700
Speaker 2:  No, I, I'm actually with you in the sense that I think there are lots of

639
00:37:13,860 --> 00:37:17,780
Speaker 2:  interesting arguments to have been made a very long time ago about whether

640
00:37:18,140 --> 00:37:21,300
Speaker 2:  artificial and intelligence are the right words at this point. I think it's

641
00:37:21,300 --> 00:37:23,780
Speaker 2:  like the, the toothpaste is outta the tube. It almost doesn't matter. Yeah.

642
00:37:23,780 --> 00:37:27,100
Speaker 2:  That just is the term And I think. My hope would be that we kind of get to

643
00:37:27,100 --> 00:37:30,900
Speaker 2:  the point where AI is like, it's like s a t or MTV

644
00:37:30,960 --> 00:37:34,620
Speaker 2:  in that kind of the original definition gets lost and then AI just means

645
00:37:34,840 --> 00:37:38,420
Speaker 2:  AI and we all kind of know what it means. But artificial and intelligence

646
00:37:38,420 --> 00:37:41,900
Speaker 2:  doesn't really matter anymore. But again, I think I'm with you in the sense

647
00:37:41,900 --> 00:37:45,620
Speaker 2:  that like the time to have had that debate was a long time ago and it's over

648
00:37:45,640 --> 00:37:47,140
Speaker 2:  and it really doesn't matter anymore.

649
00:37:47,490 --> 00:37:51,260
Speaker 19:  Yeah. And, I I mean that I think there is one argument to make perhaps that

650
00:37:51,400 --> 00:37:55,300
Speaker 19:  AI is in many ways a fitting term in that it is as diffuse

651
00:37:55,840 --> 00:37:59,660
Speaker 19:  as the entity it describes in the world. And it also

652
00:37:59,660 --> 00:38:03,140
Speaker 19:  reflects and embodies grammatically the problems we have

653
00:38:03,410 --> 00:38:07,380
Speaker 19:  talking about ai. you know, AI is a difficult thing to describe

654
00:38:07,630 --> 00:38:11,300
Speaker 19:  cause it is so multi formed. It has so many different variations

655
00:38:11,960 --> 00:38:15,660
Speaker 19:  and in a way just doing what we're doing now, I'm gonna give both of us

656
00:38:15,700 --> 00:38:18,580
Speaker 19:  a big pat on the back right now. There we go. you know, talking about this

657
00:38:18,580 --> 00:38:22,500
Speaker 19:  stuff is useful. It puts it in context. People think about it in you, obviously

658
00:38:22,720 --> 00:38:26,460
Speaker 19:  the, you know, the, the worst, not the worst sin, but the sin with using

659
00:38:26,460 --> 00:38:28,860
Speaker 19:  words every time you use them, no matter what you're talking about them,

660
00:38:28,920 --> 00:38:31,980
Speaker 19:  is using them thoughtlessly and not thinking about the words you're using.

661
00:38:32,620 --> 00:38:35,700
Speaker 19:  And I think if we think about them, we're okay. AI can be okay.

662
00:38:36,300 --> 00:38:40,180
Speaker 2:  I like it On the AI front. The, the other one that I have come across a bunch

663
00:38:40,240 --> 00:38:43,700
Speaker 2:  in trying to report about this is AI versus machine learning. And, I think,

664
00:38:43,770 --> 00:38:47,660
Speaker 2:  yeah, they get used interchangeably in part because I think machine learning

665
00:38:47,680 --> 00:38:51,620
Speaker 2:  is perceived to be the less kind of magical sounding version of it.

666
00:38:51,620 --> 00:38:54,580
Speaker 2:  It's like, if you wanna make AI seem real, you just call it machine learning.

667
00:38:54,920 --> 00:38:58,780
Speaker 2:  But that's not quite the right distinction, I don't think. Where

668
00:38:58,780 --> 00:39:01,860
Speaker 2:  do you draw the line between those things? Are they synonymous with one another?

669
00:39:02,570 --> 00:39:02,860
Speaker 2:  Yeah,

670
00:39:03,020 --> 00:39:06,780
Speaker 19:  I mean, the thing is that like there are distinctions to be made. So you

671
00:39:06,780 --> 00:39:10,420
Speaker 19:  could distinguish between machine learning methods and stuff like

672
00:39:10,420 --> 00:39:13,980
Speaker 19:  expert systems methods, which, you know, were based

673
00:39:14,680 --> 00:39:18,660
Speaker 19:  on creating ai, both of them fall under the AI category, but were more

674
00:39:18,660 --> 00:39:22,420
Speaker 19:  about structuring and sort of hard coding. The rules that were being used

675
00:39:22,420 --> 00:39:26,020
Speaker 19:  in these systems and expert systems had a vogue decades ago. And you know

676
00:39:26,020 --> 00:39:28,700
Speaker 19:  what, they're still, they're still used now in many places. It's not, it's

677
00:39:28,700 --> 00:39:32,140
Speaker 19:  not fair to say they've gone out of use, but it's been

678
00:39:32,140 --> 00:39:35,580
Speaker 19:  overtaken by the learning quote unquote learning methods, the deep learning

679
00:39:35,580 --> 00:39:39,420
Speaker 19:  methods, the machine learning methods which are more reliant on letting,

680
00:39:39,770 --> 00:39:43,380
Speaker 19:  letting systems, you know, learn on their own, not on their own, but you

681
00:39:43,380 --> 00:39:46,660
Speaker 19:  know, look at data and find rules in there under the guidance of humans.

682
00:39:47,300 --> 00:39:50,620
Speaker 19:  I think machine learning is, it's used generally now, it's just like being

683
00:39:50,660 --> 00:39:54,260
Speaker 19:  a little bit more fussy, a little bit more, as you say, a little no and

684
00:39:54,260 --> 00:39:56,820
Speaker 19:  a little bit more correct as well to be like, well let's just take some

685
00:39:56,820 --> 00:39:59,420
Speaker 19:  of the, let's just take some of the energy out the room. Let's take some

686
00:39:59,420 --> 00:40:01,900
Speaker 19:  of the hype out of the room and call it machine learning instead.

687
00:40:02,050 --> 00:40:05,700
Speaker 2:  Yeah. It's funny, you wanna remind people that this isn't some fake thing

688
00:40:05,700 --> 00:40:08,900
Speaker 2:  that's happening. Yeah. It's just, it's just you're, you're just letting

689
00:40:08,900 --> 00:40:12,060
Speaker 2:  machines do things for you. It's a reminder that like, this is just a thing

690
00:40:12,060 --> 00:40:13,580
Speaker 2:  that happens on a computer, it's fine.

691
00:40:13,890 --> 00:40:17,740
Speaker 19:  Yeah, a bit arguably it's also sort of inflationary in terms of what

692
00:40:17,740 --> 00:40:20,940
Speaker 19:  it, what it draws our expectations from. you know, you talk about machines,

693
00:40:20,940 --> 00:40:23,340
Speaker 19:  you think about physical machines, You don't often think about software.

694
00:40:23,480 --> 00:40:26,780
Speaker 19:  That's one mistake and that plays into AI myths. You talk about learning

695
00:40:27,000 --> 00:40:30,740
Speaker 19:  and then you imagine an autonomous system that is able to read

696
00:40:30,840 --> 00:40:34,340
Speaker 19:  and engage with and analyze information in the same way as a human does.

697
00:40:34,360 --> 00:40:37,780
Speaker 19:  But that's a poor illusion of terms as well because conceptually these things

698
00:40:37,850 --> 00:40:41,580
Speaker 19:  work very, very differently. you know, and then you have the

699
00:40:41,580 --> 00:40:45,540
Speaker 19:  sort of self-directed aspect of learning. And then we've had this

700
00:40:45,540 --> 00:40:49,300
Speaker 19:  wonderful piece up on the site last week, Josh jeer this

701
00:40:49,300 --> 00:40:53,220
Speaker 19:  fantastic piece looking at the huge amount of human labor that goes

702
00:40:53,250 --> 00:40:57,180
Speaker 19:  into it. Yep. Is that machine learning, if you need to employ thousands,

703
00:40:57,210 --> 00:40:59,980
Speaker 19:  tens of thousands of people around the world to click on pictures of fire

704
00:41:00,060 --> 00:41:03,740
Speaker 19:  hydrants in captures day after day, you know, is that machine learning was

705
00:41:03,740 --> 00:41:07,500
Speaker 19:  that human rule making turned into machine decision

706
00:41:07,500 --> 00:41:11,220
Speaker 19:  making? So yeah, machine learning is to all intents and

707
00:41:11,220 --> 00:41:14,860
Speaker 19:  purposes the less hyped way of saying ai.

708
00:41:15,360 --> 00:41:19,300
Speaker 19:  But again, I think defining the term is perhaps less important than

709
00:41:19,320 --> 00:41:23,260
Speaker 19:  the context within which you use them and talking about these other parts

710
00:41:23,480 --> 00:41:24,500
Speaker 19:  of, of the systems.

711
00:41:24,870 --> 00:41:28,780
Speaker 2:  Right? Yeah. I found myself trying to use machine learning less

712
00:41:29,000 --> 00:41:32,900
Speaker 2:  unless I am specifically referring to a type of system

713
00:41:33,210 --> 00:41:37,140
Speaker 2:  that is machine learning. Yeah. Because it is a thing that has a sort of

714
00:41:37,140 --> 00:41:40,940
Speaker 2:  strict simple definition in how it is used in some of these systems.

715
00:41:41,320 --> 00:41:45,180
Speaker 2:  And, I think I've definitely fallen under the trap of using machine

716
00:41:45,340 --> 00:41:48,900
Speaker 2:  learning as, as the less sexy term for AI And. I'm trying not to do that

717
00:41:48,900 --> 00:41:51,540
Speaker 2:  because I think it's unhelpful sometimes. What

718
00:41:51,540 --> 00:41:53,460
Speaker 19:  Would you give as the definition for machine learning?

719
00:41:53,820 --> 00:41:56,220
Speaker 2:  I, I think it's, it's what you said at the beginning, right? It is, it is

720
00:41:56,280 --> 00:42:00,260
Speaker 2:  the, these automated systems by which a huge amount of training data is fed

721
00:42:00,280 --> 00:42:04,260
Speaker 2:  in and algorithms run and they learn what fire hydrants look like. Right.

722
00:42:04,320 --> 00:42:08,220
Speaker 2:  And, I think in frankly in my world, mostly covering products, I

723
00:42:08,220 --> 00:42:12,140
Speaker 2:  have very little actual reason to use machine learning as a term. So

724
00:42:12,140 --> 00:42:15,500
Speaker 2:  I'm just trying to use it less and less. Right. It's, it's, I think you're

725
00:42:15,500 --> 00:42:19,300
Speaker 2:  right to say it is more useful as a way of talking about how these

726
00:42:19,300 --> 00:42:22,900
Speaker 2:  systems are built than the actual output of these systems. Yeah.

727
00:42:23,070 --> 00:42:26,020
Speaker 2:  Which brings me to my next question, and this is the one that I have struggled

728
00:42:26,020 --> 00:42:29,740
Speaker 2:  with the most as a reporter, which is terms

729
00:42:30,210 --> 00:42:34,180
Speaker 2:  like LLM, large language model and GPT, which is generative

730
00:42:34,180 --> 00:42:37,340
Speaker 2:  pre-trained transformers. These are things that if you had asked me a year

731
00:42:37,360 --> 00:42:40,180
Speaker 2:  ago, would I ever use these terms in a story, I would've said, no, you're,

732
00:42:40,180 --> 00:42:44,020
Speaker 2:  you're insane. Absolutely not, never and all at once. These feel like they

733
00:42:44,020 --> 00:42:47,940
Speaker 2:  have become like mainstream terms. I don't think anybody knows what

734
00:42:48,000 --> 00:42:51,780
Speaker 2:  GPT stands for, but I think everyone has heard the phrase chat GPT

735
00:42:51,840 --> 00:42:55,740
Speaker 2:  now and it's just kind of in the lexicon now And I find myself wondering

736
00:42:55,740 --> 00:42:58,900
Speaker 2:  like, are we good with this? Like, like are we just going to, are we gonna

737
00:42:59,000 --> 00:43:02,740
Speaker 2:  get to a point where I can just say LLM and assume most of our

738
00:43:02,980 --> 00:43:05,660
Speaker 2:  audience and most of the people in the world know what I'm talking about

739
00:43:06,220 --> 00:43:06,540
Speaker 19:  I mean?

740
00:43:06,810 --> 00:43:07,100
Speaker 2:  Yeah.

741
00:43:07,100 --> 00:43:09,980
Speaker 19:  The these, you know, oh God, this is a lovely conversation about language.

742
00:43:10,060 --> 00:43:13,060
Speaker 19:  I love the, I love these sort of discussions. I'm sorry to be heard discursive

743
00:43:13,060 --> 00:43:16,180
Speaker 19:  at them, but you know, I am very much a descriptiveness when it comes to

744
00:43:16,340 --> 00:43:19,460
Speaker 19:  language word I, words are what we say they are and they are the context

745
00:43:19,460 --> 00:43:23,420
Speaker 19:  they're used within GPT you are right. Has become this completely

746
00:43:24,250 --> 00:43:28,140
Speaker 19:  denatured term. you know, I I made a joke when I had

747
00:43:28,140 --> 00:43:31,660
Speaker 19:  my last day that you were guys were gonna train a language on model on all

748
00:43:31,660 --> 00:43:35,260
Speaker 19:  my articles and you'd obviously replace me in my absence. And I. Oh yeah.

749
00:43:35,260 --> 00:43:38,980
Speaker 19:  It'll be called James GPT. And GPT is a sort of suffix

750
00:43:39,040 --> 00:43:42,460
Speaker 19:  now just means a program you talk to. Totally. It just means like a, a a

751
00:43:42,460 --> 00:43:46,340
Speaker 19:  chatty program, which is very unusual and LLM is another one

752
00:43:46,520 --> 00:43:50,300
Speaker 19:  in that, you know, the large in it is completely subjective as a value

753
00:43:50,600 --> 00:43:54,540
Speaker 19:  in that the importance of having a large language model as opposed to

754
00:43:54,540 --> 00:43:57,620
Speaker 19:  a small one. No, you know, no one you can speak to in AI will give you a

755
00:43:57,620 --> 00:44:01,020
Speaker 19:  clear cutoff about what makes the difference between a large and a small

756
00:44:01,020 --> 00:44:04,540
Speaker 19:  one. Especially as, you know, scales go up and down

757
00:44:05,000 --> 00:44:08,100
Speaker 19:  and size itself, which is, you know, we measure a number of parameters.

758
00:44:08,400 --> 00:44:12,180
Speaker 19:  The connections within the model has sort of become more and less

759
00:44:12,180 --> 00:44:15,100
Speaker 19:  important. you know, there was this, obviously there was this push where

760
00:44:15,100 --> 00:44:18,620
Speaker 19:  you would scale it up and we just got larger and larger models and now it's

761
00:44:18,620 --> 00:44:21,140
Speaker 19:  sort of going the other way. And there are different methods of training

762
00:44:21,140 --> 00:44:25,100
Speaker 19:  them using fewer parameters. So maybe the large isn't important at all.

763
00:44:25,100 --> 00:44:28,260
Speaker 19:  And actually I think there's probably a good argument there to get rid of

764
00:44:28,260 --> 00:44:31,620
Speaker 19:  large and just call them language models. And that is, to me,

765
00:44:32,140 --> 00:44:35,700
Speaker 19:  usefully generalized as an approach. The underlying methodologies

766
00:44:36,090 --> 00:44:39,460
Speaker 19:  advancing and mutating so rapidly

767
00:44:40,050 --> 00:44:43,780
Speaker 19:  that any turn, any descriptive term, GPT or otherwise

768
00:44:43,840 --> 00:44:47,540
Speaker 19:  is bound to become obsolete in a matter of months. But I

769
00:44:47,630 --> 00:44:51,380
Speaker 19:  think GPT will hang on cause it's become a marketing term

770
00:44:51,920 --> 00:44:55,060
Speaker 19:  and like ai, the point at which something becomes a marketing term, you

771
00:44:55,060 --> 00:44:57,580
Speaker 19:  know, you may as well give up on a technical definition and then it just

772
00:44:57,580 --> 00:45:00,340
Speaker 19:  becomes about, well, what type of story are you trying to tell? What information

773
00:45:00,340 --> 00:45:03,580
Speaker 19:  do you need to give to your reader, whoever they may be. Yeah. you know,

774
00:45:03,580 --> 00:45:07,380
Speaker 19:  I, I feel like chat GPT Neli has said this in the past. He just thinks it's

775
00:45:07,460 --> 00:45:09,140
Speaker 19:  a awful name. Oh, it's

776
00:45:09,330 --> 00:45:13,220
Speaker 2:  Objectively a horrendous product name. One of the things you're

777
00:45:13,220 --> 00:45:16,740
Speaker 2:  making me realize with all of this is that we kind of don't have

778
00:45:17,460 --> 00:45:21,060
Speaker 2:  middle-sized terms in AI right now. We either have these like

779
00:45:21,060 --> 00:45:24,860
Speaker 2:  incredibly small descriptive things like large language model and machine

780
00:45:25,140 --> 00:45:28,940
Speaker 2:  learning or GPT or we just call it ai. Mm Right. And there's like nothing

781
00:45:29,000 --> 00:45:31,540
Speaker 2:  in between. And, I wonder if the thing in between is like, we'll end up just

782
00:45:31,540 --> 00:45:35,260
Speaker 2:  calling it software because fundamentally it's just software created in a

783
00:45:35,260 --> 00:45:38,020
Speaker 2:  different way. And like, we're pretty comfortable just calling things software

784
00:45:38,020 --> 00:45:40,820
Speaker 2:  at this point. But it does occur to me that even as I'm describing this stuff,

785
00:45:40,820 --> 00:45:44,660
Speaker 2:  like I don't have an answer to, if I'm not just going to refer

786
00:45:44,660 --> 00:45:48,260
Speaker 2:  to it as a large language model powered chatbot, which is

787
00:45:48,390 --> 00:45:51,340
Speaker 2:  messy, And I, think not how we should talk about this stuff forever. All

788
00:45:51,340 --> 00:45:54,900
Speaker 2:  I call it is AI and that's too much And I. So I wonder like we're, we're

789
00:45:54,900 --> 00:45:58,100
Speaker 2:  sort of stuck between these two polls for now, and And I wonder if our our

790
00:45:58,100 --> 00:46:00,180
Speaker 2:  vocabulary needs some stuff in the middle. I think

791
00:46:00,180 --> 00:46:04,060
Speaker 19:  That's a really good point. I I, I think something about the dilemma you

792
00:46:04,060 --> 00:46:07,980
Speaker 19:  are describing is due to where we are in the product cycle. you know, I've,

793
00:46:07,980 --> 00:46:11,660
Speaker 19:  I've been covering AI for not too long,

794
00:46:11,730 --> 00:46:15,460
Speaker 19:  five, six years or something like that now. And before this last

795
00:46:15,490 --> 00:46:19,380
Speaker 19:  year, the amount of products I talked about was fairly small. And I, you

796
00:46:19,380 --> 00:46:23,100
Speaker 19:  know, I, it used to be a thing where I would, some archive paper

797
00:46:23,190 --> 00:46:26,700
Speaker 19:  would be going around with some new sort of GaN technique involved with

798
00:46:26,700 --> 00:46:29,380
Speaker 19:  image synthesis generation, whatever it was. And we'd write, we'd write

799
00:46:29,380 --> 00:46:33,260
Speaker 19:  that up and we'd talk about whatever the specific name for that neural

800
00:46:33,260 --> 00:46:37,100
Speaker 19:  network architecture was. But we would never really be important again.

801
00:46:37,100 --> 00:46:40,820
Speaker 19:  And the realize was, was there was no continuity to those stories that term,

802
00:46:41,240 --> 00:46:45,020
Speaker 19:  you know, unless it became a very successful model or approach like GaN

803
00:46:45,020 --> 00:46:48,580
Speaker 19:  itself, which started off as this, you know, obscure,

804
00:46:49,130 --> 00:46:52,980
Speaker 19:  well not obscure, you know, it became very popular very quickly. But

805
00:46:53,240 --> 00:46:56,860
Speaker 19:  in terms of public knowledge, obscure term. And then, you know, I think

806
00:46:57,100 --> 00:47:00,700
Speaker 19:  a few, many of our listeners would recognize the term GaN and know it has

807
00:47:00,700 --> 00:47:04,140
Speaker 19:  something to do with image generation. But my story, my point is that when

808
00:47:04,560 --> 00:47:07,940
Speaker 19:  we cross over from the research stage to the product stage

809
00:47:08,820 --> 00:47:12,620
Speaker 19:  A, the idea of marketing gets involved and how you sell it. But B, you have

810
00:47:12,620 --> 00:47:15,900
Speaker 19:  these known narratives about these technologies and that takes on a life

811
00:47:16,720 --> 00:47:20,620
Speaker 19:  far apart from the research itself. And some

812
00:47:20,620 --> 00:47:23,860
Speaker 19:  terminology sticks around. I think a really interesting example is

813
00:47:24,140 --> 00:47:28,060
Speaker 19:  hallucinations. Yeah. So hallucinations for listen, listeners who are not

814
00:47:28,060 --> 00:47:32,020
Speaker 19:  aware is a sort of name given to essentially the mistakes made by

815
00:47:32,180 --> 00:47:34,860
Speaker 19:  language models. you know, you give them a question and they come up with

816
00:47:34,860 --> 00:47:38,140
Speaker 19:  an answer that is, you know, not derived from anything directly in their

817
00:47:38,260 --> 00:47:41,060
Speaker 19:  training data derived from the patterns within it. But it's wrong in some

818
00:47:41,060 --> 00:47:44,380
Speaker 19:  way factually incorrect. And a lot of scientists, a lot of researchers

819
00:47:44,770 --> 00:47:48,220
Speaker 19:  dislike the term hallucination because they think it

820
00:47:48,530 --> 00:47:52,300
Speaker 19:  implies a mental model that is akin to a human mind.

821
00:47:52,300 --> 00:47:56,220
Speaker 19:  Humans hallucinate, conscious beings, hallucinate machines do

822
00:47:56,220 --> 00:47:59,620
Speaker 19:  not hallucinate, they just make mistakes. But I think that's a really interesting

823
00:47:59,620 --> 00:48:03,340
Speaker 19:  example of how a term that starts off as something within the research world

824
00:48:03,930 --> 00:48:07,580
Speaker 19:  then takes on this greater meaning. Cause it happens to

825
00:48:07,820 --> 00:48:11,100
Speaker 19:  describe something that is very common to people using these products.

826
00:48:11,780 --> 00:48:15,700
Speaker 19:  I love your suggestion that we need more middle terms, but I think,

827
00:48:15,790 --> 00:48:18,340
Speaker 19:  again, another reason for this, apart from the fact that we're in the sort

828
00:48:18,340 --> 00:48:22,260
Speaker 19:  of productization stage of this development cycle is

829
00:48:22,260 --> 00:48:25,500
Speaker 19:  that actually a lot of attention is being focused on a relatively small

830
00:48:26,240 --> 00:48:30,020
Speaker 19:  zoo of different technical animals as it were. you know, a lot of it comes

831
00:48:30,020 --> 00:48:33,940
Speaker 19:  down to language models, the differences between them. If we wanna talk

832
00:48:33,950 --> 00:48:37,820
Speaker 19:  about, you know, specific structures with how they're trained, it's really

833
00:48:37,820 --> 00:48:41,500
Speaker 19:  just not relevant to the general population. you know, if we're talking

834
00:48:41,500 --> 00:48:44,700
Speaker 19:  about the difference between how GPT three, 3.5, and four were trained,

835
00:48:44,700 --> 00:48:47,140
Speaker 19:  we're talking about transformer heads and all this sort of stuff, tension

836
00:48:47,140 --> 00:48:50,420
Speaker 19:  heads. I've definitely got one of those terminologies wrong. I apologize,

837
00:48:50,760 --> 00:48:53,340
Speaker 19:  you know, this is what I mean. Like, but a lot of that stuff is really not

838
00:48:53,540 --> 00:48:56,900
Speaker 19:  relevant unless you are, you know, you're sitting in a data center somewhere

839
00:48:56,900 --> 00:48:59,420
Speaker 19:  or not sitting in a data center. You're just trying to train this stuff

840
00:48:59,660 --> 00:48:59,820
Speaker 19:  yourself.

841
00:49:00,030 --> 00:49:00,380
Speaker 2:  Right.

842
00:49:00,720 --> 00:49:04,340
Speaker 19:  Are there particular areas of AI that you think we are deficient

843
00:49:04,560 --> 00:49:07,100
Speaker 19:  in language to describe that we're missing terminology?

844
00:49:08,100 --> 00:49:12,020
Speaker 2:  I think you're right that right now we're doing an okay job just because

845
00:49:12,020 --> 00:49:15,020
Speaker 2:  there aren't that many things to do. But the thing that catches me the most,

846
00:49:15,240 --> 00:49:18,620
Speaker 2:  the two things everybody thinks about with AI are sort of generative image

847
00:49:18,940 --> 00:49:22,380
Speaker 2:  platforms. Yeah. And, I think that's a slightly messy term, but is at least

848
00:49:22,380 --> 00:49:25,820
Speaker 2:  kind of understandable, right? It's like, use AI to make new art out of nothing.

849
00:49:26,180 --> 00:49:28,860
Speaker 2:  I can sort of understand what that is. I suspect we'll have pretty good vocabulary

850
00:49:28,860 --> 00:49:32,660
Speaker 2:  for that pretty fast. And then the other one is the chatbots. And I. Actually

851
00:49:32,660 --> 00:49:35,860
Speaker 2:  think chatbots is like a fine term for that. It's, it, it may not be perfect,

852
00:49:36,080 --> 00:49:39,340
Speaker 2:  but it works and everybody kind of understands what it is. And that's the

853
00:49:39,340 --> 00:49:42,300
Speaker 2:  other side of things. The one where I get tripped up is like, I feel like

854
00:49:42,300 --> 00:49:45,300
Speaker 2:  I read a hundred press releases every day that a company is like, we put

855
00:49:45,520 --> 00:49:49,420
Speaker 2:  AI into our product. And I'm just like, what does that mean? Yeah.

856
00:49:49,810 --> 00:49:53,460
Speaker 2:  Yeah. And and to me it's like, I just read that now. It's like we put technology

857
00:49:53,570 --> 00:49:54,540
Speaker 2:  into our products.

858
00:49:55,330 --> 00:49:55,620
Speaker 19:  It's

859
00:49:55,620 --> 00:49:59,060
Speaker 2:  Like, well congratulations. Like, I don't know, did we, is that anything?

860
00:49:59,400 --> 00:50:01,900
Speaker 2:  And so I think, and that's where I get to the point where it's like, okay,

861
00:50:01,940 --> 00:50:05,900
Speaker 2:  I think we, we might just need more words for this. Mm. And maybe

862
00:50:05,900 --> 00:50:08,860
Speaker 2:  what'll happen is we'll get to the point where this stuff is just sort of

863
00:50:09,160 --> 00:50:12,620
Speaker 2:  unsexy enough that we don't talk about it. It's like, it's like talking about

864
00:50:12,620 --> 00:50:16,380
Speaker 2:  like you added a new file to your code base. Like it's, that's nothing

865
00:50:16,450 --> 00:50:19,540
Speaker 2:  true. Right? And this was back when everybody was saying like, we're all

866
00:50:19,540 --> 00:50:21,460
Speaker 2:  in on web three. And I was like, well what does that mean? Yeah. And they're

867
00:50:21,460 --> 00:50:24,100
Speaker 2:  like, we don't know either. And so maybe this is just kind of how the hype

868
00:50:24,100 --> 00:50:27,700
Speaker 2:  cycle works, but it does feel to me like we just need a

869
00:50:27,700 --> 00:50:31,500
Speaker 2:  larger set of ways to talk about what it means to put

870
00:50:31,500 --> 00:50:34,540
Speaker 2:  some of these tools into your product. Yeah. Because what you're not doing

871
00:50:34,540 --> 00:50:38,020
Speaker 2:  is putting chat GPT or an image generator into your product. And if you're

872
00:50:38,020 --> 00:50:40,780
Speaker 2:  not doing either of those things, we need a third thing to call it

873
00:50:42,000 --> 00:50:45,140
Speaker 2:  And I. Just don't know what that is yet. But, okay. I have, I have two more

874
00:50:45,140 --> 00:50:47,260
Speaker 2:  things. I have two more terms I'm gonna throw at you and then I'm gonna let

875
00:50:47,260 --> 00:50:51,140
Speaker 2:  you go here. Sure. One is, where are we on Spicy Auto Complete

876
00:50:51,200 --> 00:50:54,100
Speaker 2:  as a descriptor for some of this AI stuff? Oh, I've been seeing this for

877
00:50:54,100 --> 00:50:57,660
Speaker 2:  months. I loved it at first. I like it less and less over time, but I wanna

878
00:50:57,660 --> 00:50:58,140
Speaker 2:  know what you think.

879
00:50:58,690 --> 00:51:02,500
Speaker 19:  Okay. So I mean, I think this is a, a, again, a fascinating example

880
00:51:02,720 --> 00:51:06,260
Speaker 19:  of the limits, the benefits, the drawbacks of certain terms.

881
00:51:06,760 --> 00:51:10,060
Speaker 19:  So auto complete as a way of

882
00:51:10,630 --> 00:51:14,540
Speaker 19:  describing language models and their abilities. I actually, I

883
00:51:14,540 --> 00:51:17,860
Speaker 19:  tweeted about this a few, a few months ago. Cause I was trying to, I was

884
00:51:17,860 --> 00:51:21,660
Speaker 19:  trying to work out where the term Fast first started getting

885
00:51:21,690 --> 00:51:25,140
Speaker 19:  applied to these And I, actually I think it was Robin Sloan, I don't know

886
00:51:25,140 --> 00:51:29,100
Speaker 19:  if you know him at all. He is an author. He wrote Sourdough

887
00:51:29,120 --> 00:51:32,620
Speaker 19:  Mr. Penumbra's 24 hour bookstore, but he also has a fantastic

888
00:51:32,710 --> 00:51:36,580
Speaker 19:  newsletter. He does. And he's very like involved in technology. He's done

889
00:51:36,580 --> 00:51:39,900
Speaker 19:  like a, he's got a side music project that uses ai, you know, he's been

890
00:51:39,900 --> 00:51:43,220
Speaker 19:  experimenting with these tools for ages. His was the first instant I could

891
00:51:43,220 --> 00:51:47,100
Speaker 19:  find of it being applied to language models, And I, think it was like 20 16, 20 17,

892
00:51:47,100 --> 00:51:50,580
Speaker 19:  something like that a while ago. Then of course it became

893
00:51:50,980 --> 00:51:54,500
Speaker 19:  attached to essentially criticisms of these models. I mean, and particularly

894
00:51:54,500 --> 00:51:58,100
Speaker 19:  the, the, the, the Stochastic Parrots paper I think did a lot about

895
00:51:58,310 --> 00:52:01,780
Speaker 19:  connecting these things. And because it got attached to

896
00:52:01,910 --> 00:52:05,420
Speaker 19:  criticisms of these models, it's then become somewhat politicized term

897
00:52:05,680 --> 00:52:09,620
Speaker 19:  within AI communities. And if you use

898
00:52:09,620 --> 00:52:13,540
Speaker 19:  it, it can put you in camps, in people's mind, camps of

899
00:52:13,540 --> 00:52:16,980
Speaker 19:  political or ideological belief or thought. So it's a very, it's a very

900
00:52:17,260 --> 00:52:20,940
Speaker 19:  interesting term. And you know, if you, if you someone who derives language

901
00:52:20,940 --> 00:52:24,860
Speaker 19:  models as just fancy auto complete or whatever it is, some people

902
00:52:24,860 --> 00:52:28,500
Speaker 19:  in the AI community who let's just say, you know, are, are more likely

903
00:52:28,640 --> 00:52:32,540
Speaker 19:  to believe in existential risk problems, for example, will be quite dismissive.

904
00:52:32,540 --> 00:52:35,420
Speaker 19:  Or they can be quite dismissive cuz they'll think You don't fully understand

905
00:52:35,560 --> 00:52:39,540
Speaker 19:  the qualities that these systems have. And the thing is, I think it

906
00:52:39,540 --> 00:52:43,220
Speaker 19:  was a really useful term for a long time, it was a really useful way

907
00:52:43,320 --> 00:52:46,980
Speaker 19:  of quickly explaining, I'm communicating, sorry, the

908
00:52:47,050 --> 00:52:49,820
Speaker 19:  abilities of these systems and also something about the way they're trained.

909
00:52:50,080 --> 00:52:53,580
Speaker 19:  you know, it, it is a statistical predictor that is definitely true. That

910
00:52:53,580 --> 00:52:56,980
Speaker 19:  the problem with the term, and I'm still, I don't have a decision, I haven't,

911
00:52:56,980 --> 00:53:00,300
Speaker 19:  you know, made a decision in my head about this, is that it doesn't quite

912
00:53:00,480 --> 00:53:04,260
Speaker 19:  convey to people now the full capabilities of these

913
00:53:04,260 --> 00:53:08,100
Speaker 19:  systems. Which, you know, you get something like the

914
00:53:08,100 --> 00:53:11,660
Speaker 19:  famous Sparks of AGI paper, the one that came out from the Microsoft research,

915
00:53:11,800 --> 00:53:15,100
Speaker 19:  And I say famous, also very controversial. A lot of people

916
00:53:15,820 --> 00:53:18,700
Speaker 19:  disagree with the contents, the conclusions of that paper, which was basically

917
00:53:18,700 --> 00:53:22,060
Speaker 19:  saying that GPT four had abilities in it, which were not

918
00:53:22,580 --> 00:53:25,700
Speaker 19:  adequately described by our current mental models of language models. And

919
00:53:25,700 --> 00:53:29,580
Speaker 19:  it was something perhaps closer to, as the title suggests, sparks of

920
00:53:29,740 --> 00:53:33,300
Speaker 19:  artificial general intelligence. And I haven't come down at a sign on that.

921
00:53:33,340 --> 00:53:37,060
Speaker 19:  I still think auto complete is a useful term in many contexts when talking

922
00:53:37,060 --> 00:53:40,580
Speaker 19:  about language models. But it's also sort of lacking now because it does

923
00:53:40,770 --> 00:53:44,620
Speaker 19:  underplay the fantastic breadth of

924
00:53:44,620 --> 00:53:48,460
Speaker 19:  capabilities that these systems have and the fact that there may be,

925
00:53:48,520 --> 00:53:52,260
Speaker 19:  you know, aptitudes within them that just don't

926
00:53:52,260 --> 00:53:55,620
Speaker 19:  apply to our model of what auto complete software does. So I think it's

927
00:53:55,620 --> 00:53:58,220
Speaker 19:  a term that we're gonna see phased out in the years to come because it's

928
00:53:58,220 --> 00:54:01,500
Speaker 19:  been slightly lacking or perhaps it's a term that's gonna become increasingly

929
00:54:01,500 --> 00:54:05,380
Speaker 19:  politicized and that using it will align you with one

930
00:54:05,380 --> 00:54:09,300
Speaker 19:  or other political camp of beliefs or research camps and belief. But a really

931
00:54:09,540 --> 00:54:11,820
Speaker 19:  fascinating term. Do you, do you like it still spicy auto to complete?

932
00:54:11,980 --> 00:54:15,860
Speaker 2:  I liked it at first because I think it's a really helpful

933
00:54:16,250 --> 00:54:19,740
Speaker 2:  kind of kindergarten level understanding of what's actually going on, right?

934
00:54:19,740 --> 00:54:22,980
Speaker 2:  Yeah. Like, it's because everyone, everyone has had that experience and you

935
00:54:22,980 --> 00:54:25,660
Speaker 2:  type something and it throws up the three options and sometimes they're insane

936
00:54:25,680 --> 00:54:29,020
Speaker 2:  and sometimes they're great. And it's like, that is not a terrible metaphor

937
00:54:29,020 --> 00:54:32,700
Speaker 2:  for what's happening in a lot of these systems. I think it's becoming an

938
00:54:32,700 --> 00:54:36,100
Speaker 2:  incomplete enough metaphor is to not be useful very, very, very quickly.

939
00:54:36,240 --> 00:54:40,180
Speaker 2:  So I I kind of like it less over time. And I agree. I think the way

940
00:54:40,180 --> 00:54:44,100
Speaker 2:  that people use it has gotten, people are either very dismissive

941
00:54:44,100 --> 00:54:46,900
Speaker 2:  when they use it, or very dismissive of people who use it. And I. Think both

942
00:54:46,900 --> 00:54:50,620
Speaker 2:  of those are kind of annoying. And for that reason alone, I'm, I'm

943
00:54:50,670 --> 00:54:54,620
Speaker 2:  ready to move on to something else. But as a, as a first run at making

944
00:54:55,170 --> 00:54:58,500
Speaker 2:  this stuff really understandable to people, I think it kind of worked. It,

945
00:54:58,500 --> 00:55:02,260
Speaker 2:  it, it got us, yeah, it got us six months of decent metaphors. So I I'm not

946
00:55:02,260 --> 00:55:02,740
Speaker 2:  mad at it.

947
00:55:03,280 --> 00:55:06,500
Speaker 19:  No, absolutely. I'm, I'm glad to hear we're staking out the radical centrist

948
00:55:06,500 --> 00:55:09,780
Speaker 19:  ground here, David. Absolutely. We are annoyed by both people on both sides

949
00:55:09,780 --> 00:55:10,380
Speaker 19:  of this argument.

950
00:55:10,640 --> 00:55:13,700
Speaker 2:  I'm really the The Verge cast's Official position is, everybody should just

951
00:55:13,700 --> 00:55:14,940
Speaker 2:  calm down for five minutes, I think.

952
00:55:16,680 --> 00:55:20,300
Speaker 2:  But here's, here's one I suspect you And I will aggressively agree, agree

953
00:55:20,300 --> 00:55:24,220
Speaker 2:  on, and then we can go, okay, which is the, the term magic to describe AI

954
00:55:24,370 --> 00:55:28,020
Speaker 2:  like in magic eraser and magic editor and magic, whatever,

955
00:55:28,130 --> 00:55:31,860
Speaker 2:  that needs to die in a fire as quickly as possible, right? Like,

956
00:55:31,860 --> 00:55:35,260
Speaker 2:  yeah, we gotta stop with the magic. There's no magic here. I'm done with

957
00:55:35,260 --> 00:55:36,460
Speaker 19:  This. There's no magic. We're good on

958
00:55:36,460 --> 00:55:36,740
Speaker 2:  This. Right?

959
00:55:36,770 --> 00:55:40,620
Speaker 19:  Well, but you know, when you deliver a product, David, David, listen to

960
00:55:40,620 --> 00:55:44,340
Speaker 19:  me, listen to me for a second, Dave. When you deliver a product that uplifts

961
00:55:44,370 --> 00:55:48,260
Speaker 19:  your customer's heart, that brings light to them, when they get rid of

962
00:55:48,260 --> 00:55:52,020
Speaker 19:  that obnoxious pug dog that was learing at them in that family photo in

963
00:55:52,020 --> 00:55:55,900
Speaker 19:  the background, is that not magic? Is that not a type of wizardry of

964
00:55:55,930 --> 00:55:57,660
Speaker 19:  sorcery? No, you, sorry,

965
00:55:57,800 --> 00:56:01,460
Speaker 2:  Did Johnny, I've just come into your room weird. How did that that was amazing.

966
00:56:02,420 --> 00:56:05,860
Speaker 19:  Terrible. Yeah, but but the context, you've just described it within a purely

967
00:56:05,860 --> 00:56:09,700
Speaker 19:  marketing context. So I think people already know that magic is

968
00:56:10,340 --> 00:56:12,180
Speaker 19:  bullshit for want of a more polite term.

969
00:56:12,650 --> 00:56:15,780
Speaker 2:  Yeah. Yeah, that's fair. Hopefully it stays that way. All right, James, you

970
00:56:15,780 --> 00:56:18,900
Speaker 2:  got a book to write? We need to take a break, but thank you as always. Thanks

971
00:56:18,900 --> 00:56:19,900
Speaker 19:  Guys. Bye.

972
00:56:21,040 --> 00:56:23,460
Speaker 2:  All right, we gotta take one more break and then we're gonna come back and

973
00:56:23,460 --> 00:56:27,100
Speaker 2:  talk about all the video games. We cannot wait to play. We'll be right back.

974
00:56:33,710 --> 00:56:37,620
Speaker 2:  We're back. So usually the gaming world has a couple of

975
00:56:37,800 --> 00:56:41,460
Speaker 2:  big moments a year with the E three conference usually in June

976
00:56:41,470 --> 00:56:45,140
Speaker 2:  being the biggest by far. But E three is no longer. So

977
00:56:45,140 --> 00:56:48,860
Speaker 2:  instead we've had a string of announcements from Nintendo Sony,

978
00:56:49,140 --> 00:56:52,900
Speaker 2:  Microsoft Ubisoft, there was the Summer, Game Fest and a bunch of others.

979
00:56:53,560 --> 00:56:57,500
Speaker 2:  All detailing what's coming to a console and computer near you. This year

980
00:56:57,500 --> 00:57:00,780
Speaker 2:  is actually a big year for games, it turns out. And it's a lot to keep up

981
00:57:00,780 --> 00:57:04,540
Speaker 2:  with. So I asked the verges, Ash, Parrish and Polygons Chris Plant

982
00:57:04,600 --> 00:57:07,780
Speaker 2:  to come on the show and tell me all the new stuff that they're most excited

983
00:57:07,780 --> 00:57:09,220
Speaker 2:  about. Ash. Hi.

984
00:57:09,800 --> 00:57:11,180
Speaker 20:  Hi. Great to be back.

985
00:57:11,530 --> 00:57:14,940
Speaker 2:  It's good to have you back. And speaking of coming back, Chris Plant, welcome

986
00:57:14,940 --> 00:57:16,500
Speaker 2:  back to The Vergecast. It's been a while. Hi.

987
00:57:16,510 --> 00:57:20,300
Speaker 21:  Thank you. It's been six years, seven years. Obviously you missed me

988
00:57:21,000 --> 00:57:22,180
Speaker 21:  and you're just so happy to have

989
00:57:22,180 --> 00:57:25,380
Speaker 2:  Me listen, you were just here. I don't know, I, I opened up the link and

990
00:57:25,380 --> 00:57:27,820
Speaker 2:  you were just here and, and we're scrolling with it. It's fine.

991
00:57:29,330 --> 00:57:33,020
Speaker 2:  Okay. So the way we wanted to do this is basically there's been a lot of

992
00:57:33,020 --> 00:57:36,140
Speaker 2:  video game announcements. There was no E three, so there was no one like

993
00:57:36,140 --> 00:57:39,420
Speaker 2:  moment for video games and said, it's been the summer of video games, And

994
00:57:39,780 --> 00:57:43,220
Speaker 2:  I. Just want to like rattle through some of the coolest stuff that people

995
00:57:43,220 --> 00:57:47,180
Speaker 2:  have been talking about. So the way we set this up is the, the

996
00:57:47,380 --> 00:57:51,300
Speaker 2:  homework we each had is we each had to come with two games that we

997
00:57:51,300 --> 00:57:54,820
Speaker 2:  are excited to play this summer. Ideally brand new games. But if you wanna

998
00:57:54,820 --> 00:57:58,580
Speaker 2:  cheat on that one, I'll allow it. And then two games you're excited

999
00:57:58,590 --> 00:58:02,460
Speaker 2:  about coming this fall. So games you can't play yet, but will

1000
00:58:02,520 --> 00:58:05,540
Speaker 2:  before the end of the year. Are you guys prepared? Are you ready? Does this

1001
00:58:05,540 --> 00:58:06,180
Speaker 2:  sound like a plan?

1002
00:58:06,370 --> 00:58:08,300
Speaker 20:  This sounds like a tentative plan. I

1003
00:58:08,300 --> 00:58:09,900
Speaker 21:  Think we're gonna maybe be okay,

1004
00:58:09,930 --> 00:58:12,980
Speaker 2:  This is The Vergecast, maybe be Okay. Is the best we're ever gonna do. Great.

1005
00:58:13,190 --> 00:58:16,500
Speaker 2:  Let's start with this summer and we'll just, we'll just go around in circles

1006
00:58:16,500 --> 00:58:19,220
Speaker 2:  here. So Ash, you go first. What's the first game you're excited about this

1007
00:58:19,220 --> 00:58:19,380
Speaker 2:  summer?

1008
00:58:19,640 --> 00:58:21,940
Speaker 20:  So my first pick is Boulder's Gate three.

1009
00:58:28,940 --> 00:58:32,900
Speaker 20:  I am really excited about this game. It has been an early access for about

1010
00:58:32,900 --> 00:58:36,820
Speaker 20:  forever. I remember the first time it went to like early access, And

1011
00:58:36,820 --> 00:58:39,820
Speaker 20:  I got to play like an early build of it. And I've never played the Boulders

1012
00:58:39,820 --> 00:58:43,460
Speaker 20:  Gate games before. I kind of really haven't dabbled with like the, the

1013
00:58:43,460 --> 00:58:46,460
Speaker 20:  Dungeons and Dragons games that have been, you know, made into video games.

1014
00:58:46,640 --> 00:58:49,300
Speaker 20:  But Boulders Gate was like the first time I had a, an experience with a

1015
00:58:49,300 --> 00:58:53,140
Speaker 20:  game like that. And I loved it. It was really fun. I got

1016
00:58:53,290 --> 00:58:57,220
Speaker 20:  such a kick out of not like doing anything for like my class. I think

1017
00:58:57,220 --> 00:58:59,940
Speaker 20:  I played like a Paladin or something like that. I don't remember if that's

1018
00:58:59,940 --> 00:59:03,500
Speaker 20:  not one of the classes. Don't, don't at me on that. But I got more

1019
00:59:03,960 --> 00:59:07,780
Speaker 20:  fun out of like pushing people off of things and lighting

1020
00:59:07,780 --> 00:59:11,740
Speaker 20:  them on fire than I did doing anything else that was like

1021
00:59:11,770 --> 00:59:15,540
Speaker 20:  class-based because they just do so much damage and it's so much fun being

1022
00:59:15,540 --> 00:59:19,180
Speaker 20:  a little chaos gremlin that like pushes people off buildings and stuff like

1023
00:59:19,180 --> 00:59:23,020
Speaker 20:  that. So I'm really excited to see what a full version of that game looks

1024
00:59:23,020 --> 00:59:25,860
Speaker 20:  like, especially because there's romances, And, I haven't had a good game

1025
00:59:25,860 --> 00:59:29,540
Speaker 20:  with romance in it since Mass effect three. So I'm really

1026
00:59:29,690 --> 00:59:33,100
Speaker 20:  excited to get back into that like real crunchy

1027
00:59:33,660 --> 00:59:36,900
Speaker 20:  C R P G type experience that has like

1028
00:59:37,510 --> 00:59:41,020
Speaker 20:  50 million lines of voice dialogue and 20 million different things that

1029
00:59:41,020 --> 00:59:43,580
Speaker 20:  you can do. I am jazzed about that.

1030
00:59:44,100 --> 00:59:46,580
Speaker 2:  I love that. Chris, any feelings about boulders? Skate?

1031
00:59:46,900 --> 00:59:50,460
Speaker 21:  I mean, I'm just intimidated, you know, intimidated by what it could do

1032
00:59:50,460 --> 00:59:53,900
Speaker 21:  to me if I allow myself to enjoy a game like that. Because it's definitely

1033
00:59:53,900 --> 00:59:57,140
Speaker 21:  one of those games that you start playing I mean like, you know, I'll put

1034
00:59:57,140 --> 01:00:00,380
Speaker 21:  20 hours into it, that's a reasonable amount of time to play a video game

1035
01:00:00,560 --> 01:00:04,420
Speaker 21:  and then 300 hours later you're like, what did I do? Yeah,

1036
01:00:04,420 --> 01:00:07,740
Speaker 21:  yeah. you know, and, and that's not to say that's a bad use of time.

1037
01:00:08,200 --> 01:00:11,900
Speaker 21:  It just, it slips away. I, I, I played a little bit of

1038
01:00:12,020 --> 01:00:15,260
Speaker 21:  divinity, original sin too, same kind of game. And

1039
01:00:15,930 --> 01:00:19,900
Speaker 21:  yeah, it was definitely that thing where I

1040
01:00:19,900 --> 01:00:23,140
Speaker 21:  thought I had only played for 10 hours and it had been about 40 or 50.

1041
01:00:23,490 --> 01:00:27,420
Speaker 2:  Yeah. That feeling of, oh God, I cannot afford to lose my life

1042
01:00:27,420 --> 01:00:30,700
Speaker 2:  to this game is a running theme through all of my picks, which you will see.

1043
01:00:30,700 --> 01:00:33,860
Speaker 2:  Yes. Very shortly. But Chris, what's your first one? What are you excited

1044
01:00:33,860 --> 01:00:34,260
Speaker 2:  about this summer?

1045
01:00:34,680 --> 01:00:38,540
Speaker 21:  So I'm, I'm cheating and I'm using California summertime, which means

1046
01:00:38,540 --> 01:00:39,700
Speaker 21:  it goes to the end of October

1047
01:00:40,000 --> 01:00:41,060
Speaker 2:  And hasn't started yet.

1048
01:00:41,530 --> 01:00:45,340
Speaker 21:  Exactly. I mean definitely correct. So there is a

1049
01:00:45,340 --> 01:00:49,100
Speaker 21:  week in October that has like three huge releases. And I'll be picking two

1050
01:00:49,100 --> 01:00:53,020
Speaker 21:  from them. One of them is just a very old video game, which

1051
01:00:53,080 --> 01:00:56,460
Speaker 21:  is the metal gear solid master collection. Yes. Coming out on

1052
01:00:56,460 --> 01:00:57,500
Speaker 21:  October 24th.

1053
01:01:01,330 --> 01:01:05,260
Speaker 2:  Okay. Are we giving you that first? That feels like a October 24th is a

1054
01:01:05,260 --> 01:01:05,500
Speaker 2:  stretch.

1055
01:01:05,940 --> 01:01:09,740
Speaker 21:  I said the end of October. I, I created the rules and then I used the rules.

1056
01:01:10,000 --> 01:01:11,340
Speaker 21:  That's how this game works.

1057
01:01:11,440 --> 01:01:14,260
Speaker 2:  You were just here when I clicked the link, man. That's all, that's all I

1058
01:01:14,260 --> 01:01:14,420
Speaker 2:  know.

1059
01:01:14,920 --> 01:01:18,540
Speaker 21:  Here's why it matters. There are a bunch of like flashier games coming out.

1060
01:01:18,920 --> 01:01:22,900
Speaker 21:  Middle gear solid is one of the most important video game franchises in

1061
01:01:22,900 --> 01:01:26,220
Speaker 21:  the history of the medium. And you effectively cannot play it right now

1062
01:01:26,330 --> 01:01:30,180
Speaker 21:  legally. Hmm. And that is absolutely absurd. There

1063
01:01:30,180 --> 01:01:33,620
Speaker 21:  was a documentary at Tribeca Film Festival about he

1064
01:01:33,920 --> 01:01:37,740
Speaker 21:  kajima, he has new games coming up with death stranding too. And yet if

1065
01:01:37,740 --> 01:01:41,700
Speaker 21:  you wanted to go play Metal gear solid or metal gear solid two or

1066
01:01:41,700 --> 01:01:45,460
Speaker 21:  three or any of the original games, good luck. You will need to go get

1067
01:01:45,520 --> 01:01:48,820
Speaker 21:  an original system because they're no longer available on Windows

1068
01:01:49,400 --> 01:01:52,860
Speaker 21:  pc. They used to be on good old games and they're not on modern

1069
01:01:52,980 --> 01:01:56,780
Speaker 21:  consoles. It doesn't make sense how hard it is to

1070
01:01:56,780 --> 01:02:00,260
Speaker 21:  play these games. And this, this isn't exclusive to metal gear,

1071
01:02:00,940 --> 01:02:04,260
Speaker 21:  but I think it is kind of the shining example of video games.

1072
01:02:05,380 --> 01:02:09,140
Speaker 21:  Terrible habits of erasing or legally blocking out its

1073
01:02:09,140 --> 01:02:12,460
Speaker 21:  past And I am very glad that this is going to become available and then

1074
01:02:12,460 --> 01:02:15,100
Speaker 21:  everybody can play it and realize, you know what, dust ending's actually

1075
01:02:15,100 --> 01:02:16,420
Speaker 21:  a better game than all of them. So.

1076
01:02:16,880 --> 01:02:18,220
Speaker 20:  Oh, that's, that's big.

1077
01:02:18,330 --> 01:02:22,220
Speaker 2:  Yeah. And this is, is it the whole collection coming to basically all

1078
01:02:22,220 --> 01:02:23,300
Speaker 2:  of the major platforms?

1079
01:02:23,720 --> 01:02:27,500
Speaker 21:  So this is Metal gear solids one, two, and three. Okay. And

1080
01:02:27,530 --> 01:02:29,620
Speaker 21:  some I believe like the Ns or

1081
01:02:29,950 --> 01:02:32,260
Speaker 20:  Metal gear, not the solid just metal gear.

1082
01:02:32,260 --> 01:02:35,980
Speaker 21:  Yes. Thank you. Thank you. But sadly, I do not think metal gear solid for

1083
01:02:35,980 --> 01:02:39,820
Speaker 21:  the Game. Boy color is part of this, despite being a delightful game

1084
01:02:40,320 --> 01:02:44,100
Speaker 21:  and metal gear solid four and five are not on this though. I think it's

1085
01:02:44,100 --> 01:02:47,780
Speaker 21:  pretty safe to assume that there will be a sequel collection in the next

1086
01:02:47,780 --> 01:02:50,100
Speaker 21:  year or two to make sure that people can buy those too.

1087
01:02:50,640 --> 01:02:53,700
Speaker 2:  And then he's and, and Kojima's very busy getting all his stuff to work on

1088
01:02:53,700 --> 01:02:56,620
Speaker 2:  a Mac. So it's gonna, it's it's all gonna be very exciting. It's all coming

1089
01:02:56,620 --> 01:03:00,580
Speaker 2:  up Metal gear. All right. My first pick is comparatively very small.

1090
01:03:00,810 --> 01:03:04,780
Speaker 2:  It's the new Mario Kart d l c for the Nintendo Switch Wave

1091
01:03:04,890 --> 01:03:05,180
Speaker 2:  five.

1092
01:03:10,990 --> 01:03:14,980
Speaker 2:  Mario Kart is the only game I can play for any amount

1093
01:03:14,980 --> 01:03:18,780
Speaker 2:  of time, whenever, for any reason and be very happy about it.

1094
01:03:18,970 --> 01:03:20,420
Speaker 20:  It's a very good appointment game.

1095
01:03:20,720 --> 01:03:22,220
Speaker 2:  Yes, that's exactly right. Yeah,

1096
01:03:22,220 --> 01:03:25,540
Speaker 20:  You can just sit down, pop in, have like a bespoke 20 minute experience,

1097
01:03:25,680 --> 01:03:29,300
Speaker 20:  get everything, like experience an entire gameplay loop and stop and

1098
01:03:29,480 --> 01:03:32,500
Speaker 20:  You don't have to worry about falling behind or anything like that. Mario

1099
01:03:32,740 --> 01:03:33,940
Speaker 20:  Kart is a perfect game for that.

1100
01:03:34,200 --> 01:03:37,380
Speaker 2:  And the thing that they've done really well is I feel like every Mario Kart

1101
01:03:37,380 --> 01:03:41,300
Speaker 2:  game before I've, I feel like I've sort of played through and then

1102
01:03:41,300 --> 01:03:44,180
Speaker 2:  it gets a little bit repetitive. And, I have to kind of take a break and

1103
01:03:44,180 --> 01:03:46,540
Speaker 2:  go, but they're, they're doing these waves at just the right cadence where

1104
01:03:46,540 --> 01:03:48,820
Speaker 2:  it's like, oh, I have a new character that kind of makes everything feel

1105
01:03:48,820 --> 01:03:51,620
Speaker 2:  new. And then, oh, there's a new course that makes everything feel kind of

1106
01:03:51,620 --> 01:03:55,380
Speaker 2:  new. And this one, there's a a handful of new characters and it's

1107
01:03:55,430 --> 01:03:58,260
Speaker 2:  going to give me endless reasons to play this game a lot

1108
01:03:58,260 --> 01:04:01,900
Speaker 21:  More. You buried the lead comic Yes. Is one of the new Cam

1109
01:04:01,900 --> 01:04:05,700
Speaker 21:  characters. And this is huge in the plant house because my five year old

1110
01:04:05,700 --> 01:04:09,380
Speaker 21:  thinks comic is the star of Mario. He's very misguided.

1111
01:04:09,520 --> 01:04:13,380
Speaker 20:  You know what? I would believe that, yeah, if I had not ever played

1112
01:04:13,380 --> 01:04:17,100
Speaker 20:  Mario, if I didn't know what Mario was, I would 100% believe that

1113
01:04:17,100 --> 01:04:20,940
Speaker 20:  because this is the guy that comes in on like the cloud, right? He's Bower's

1114
01:04:20,940 --> 01:04:24,900
Speaker 20:  Herald. Right. This is the first person who shows up and is like given

1115
01:04:24,900 --> 01:04:28,860
Speaker 20:  this like outsized importance. He he is, he's talking to you. I would 100%

1116
01:04:28,900 --> 01:04:31,820
Speaker 20:  believe that your, your kid is 100% right and you can tell him I said that.

1117
01:04:32,160 --> 01:04:32,380
Speaker 20:  Wow.

1118
01:04:33,360 --> 01:04:36,980
Speaker 2:  That's kind of deep, honestly. Like I was about to come out firing about

1119
01:04:36,980 --> 01:04:39,620
Speaker 2:  how wrong that opinion is, but I think you might be right. I take it back.

1120
01:04:40,040 --> 01:04:42,300
Speaker 2:  All right. Ash, what's your next one for the summer

1121
01:04:42,630 --> 01:04:43,740
Speaker 20:  Ghost Trick? Oh,

1122
01:04:48,030 --> 01:04:51,940
Speaker 20:  ghost Trick is a switch game. It's kind of like, like a, like a

1123
01:04:51,940 --> 01:04:55,380
Speaker 20:  phoenix right kind of game where you go through and you have to like solve

1124
01:04:55,380 --> 01:04:58,380
Speaker 20:  mysteries and things like that. And this has this weird mechanic where like

1125
01:04:58,380 --> 01:05:01,500
Speaker 20:  you're a ghost and you have to stop people's untimely deaths and you have

1126
01:05:01,500 --> 01:05:05,380
Speaker 20:  like these weird Rube Goldberg like device way of going about

1127
01:05:05,380 --> 01:05:07,660
Speaker 20:  that. And I'm looking forward to getting into that cause that looks like

1128
01:05:07,660 --> 01:05:11,300
Speaker 20:  a fun, nifty little game that'll scratch that Ace Attorney itch.

1129
01:05:11,780 --> 01:05:14,540
Speaker 2:  I had not seen this before. And, I'm looking at it now and also has this

1130
01:05:14,540 --> 01:05:18,220
Speaker 2:  amazing kind of retro animation style that I'm very into.

1131
01:05:18,410 --> 01:05:22,260
Speaker 21:  Yeah, yeah. For people who wanna try it right now it's on iOS

1132
01:05:22,440 --> 01:05:24,220
Speaker 21:  and yeah, it is a delight. All

1133
01:05:24,220 --> 01:05:27,060
Speaker 2:  Right, well I'm gonna have there, there goes my summer. Chris, what's your

1134
01:05:27,060 --> 01:05:27,380
Speaker 2:  second one?

1135
01:05:27,600 --> 01:05:31,300
Speaker 21:  I'm gonna follow the rules this time. My pick is my house

1136
01:05:32,000 --> 01:05:35,500
Speaker 21:  dot wa or my house dot wad

1137
01:05:38,920 --> 01:05:42,620
Speaker 21:  and it is a mod for Doom. Oh, And I am just targeting The

1138
01:05:42,780 --> 01:05:43,300
Speaker 21:  Verge audience.

1139
01:05:43,690 --> 01:05:45,980
Speaker 2:  Wait, tell me everything about this. I don't know about this.

1140
01:05:46,360 --> 01:05:49,780
Speaker 21:  It is an absolutely bonkers mod that in the

1141
01:05:50,040 --> 01:05:53,740
Speaker 21:  cannon of the Forum post where it was published, two friends

1142
01:05:53,930 --> 01:05:57,740
Speaker 21:  were making it in 1999 and then they grew

1143
01:05:57,790 --> 01:06:01,100
Speaker 21:  apart. And more recently one of those friends passed away.

1144
01:06:01,640 --> 01:06:05,220
Speaker 21:  So the friend who is still alive found this mod that they were working on

1145
01:06:05,220 --> 01:06:08,340
Speaker 21:  and decided to like touched up and just released it out onto the world.

1146
01:06:08,560 --> 01:06:12,500
Speaker 21:  And it is just their house. It is, it is the,

1147
01:06:12,500 --> 01:06:16,340
Speaker 21:  the pass away friend's home that is not the mod at all. And

1148
01:06:16,340 --> 01:06:20,100
Speaker 21:  you should keep playing it. It is a very different

1149
01:06:20,100 --> 01:06:23,900
Speaker 21:  thing and it is, it is the kind of like prize,

1150
01:06:24,200 --> 01:06:27,020
Speaker 21:  you know, nesting doll toy. Is it Inscription?

1151
01:06:27,040 --> 01:06:28,100
Speaker 20:  Is it like inscription?

1152
01:06:28,460 --> 01:06:32,380
Speaker 21:  I mean as somebody who like inscription after the first act, I would say

1153
01:06:32,380 --> 01:06:36,060
Speaker 21:  it's better than Inscription. Oh you know what, that's okay. I admire Inscription

1154
01:06:36,100 --> 01:06:39,900
Speaker 21:  a lot. I think the, the first third of that game is, is fantastic. But I

1155
01:06:39,900 --> 01:06:43,780
Speaker 21:  think what this is doing is I hate doing

1156
01:06:43,780 --> 01:06:47,660
Speaker 21:  a Lynchian thing because that is such a meaningless comparison, but

1157
01:06:47,660 --> 01:06:51,300
Speaker 21:  it is not trying to ascribe a meaning to every

1158
01:06:51,580 --> 01:06:55,100
Speaker 21:  decision that it makes. It is I think a lot looser and more playful

1159
01:06:55,450 --> 01:06:58,660
Speaker 21:  than that, which is why it's a mod not a retail game because it probably

1160
01:06:58,660 --> 01:06:59,900
Speaker 21:  would make a total of $5,

1161
01:07:01,240 --> 01:07:05,180
Speaker 2:  But instead just show up for random insanity and see what happens. Yeah,

1162
01:07:05,540 --> 01:07:09,180
Speaker 2:  I love that. I do really appreciate it. I'm just reading about this now and

1163
01:07:09,180 --> 01:07:12,700
Speaker 2:  one of the things that says is are you expecting to battle demons? Yes, this

1164
01:07:12,700 --> 01:07:15,740
Speaker 2:  will happen, but first you must uncover the secrets of what seems to just

1165
01:07:15,740 --> 01:07:16,780
Speaker 2:  be a suburban house.

1166
01:07:17,120 --> 01:07:17,340
Speaker 21:  Yes.

1167
01:07:18,360 --> 01:07:19,260
Speaker 2:  Sounds amazing.

1168
01:07:19,490 --> 01:07:20,140
Speaker 21:  That does sound

1169
01:07:20,140 --> 01:07:21,740
Speaker 20:  Amazing, especially because this is in Doom

1170
01:07:21,930 --> 01:07:23,340
Speaker 2:  Sold. I'm in, I will play this.

1171
01:07:23,560 --> 01:07:27,140
Speaker 21:  Can I give you like one little spoilery thing? Sure. This is like no story

1172
01:07:27,140 --> 01:07:30,420
Speaker 21:  or anything. There is a point in the game where you come across two dogs

1173
01:07:31,000 --> 01:07:34,860
Speaker 21:  and one of the dogs is like a three-headed hell beast with

1174
01:07:34,860 --> 01:07:38,780
Speaker 21:  like borderline infinite health and the other dog is like

1175
01:07:38,900 --> 01:07:42,820
Speaker 21:  a cute puppy with like two health and whichever one

1176
01:07:42,840 --> 01:07:46,700
Speaker 21:  you kill, it kills the other and that's the only way to move on.

1177
01:07:46,840 --> 01:07:50,620
Speaker 21:  Oh no. Which really puts a like choice on your

1178
01:07:50,620 --> 01:07:54,580
Speaker 21:  platter. Wow. Yeah, it's like I, it's not even a Charlie problem, it's just

1179
01:07:54,580 --> 01:07:57,860
Speaker 21:  an awful problem. I swear the game is not that dark

1180
01:07:58,360 --> 01:08:02,100
Speaker 21:  in general, but that that certainly Yeah.

1181
01:08:02,280 --> 01:08:05,500
Speaker 21:  It leaves a, a funky taste in the in the palette.

1182
01:08:05,650 --> 01:08:09,420
Speaker 2:  Yeah. Real, real summer vibes coming outta that one my pick

1183
01:08:09,420 --> 01:08:13,260
Speaker 2:  because unlike the two of you I followed the rules is out now and it

1184
01:08:13,260 --> 01:08:15,820
Speaker 2:  is F 1 23 the racing game.

1185
01:08:16,120 --> 01:08:16,620
Speaker 21:  Oh wow.

1186
01:08:19,340 --> 01:08:23,140
Speaker 2:  Specifically because, well a, I love racing games, as you can tell

1187
01:08:23,170 --> 01:08:26,580
Speaker 2:  from my two picks so far, And I like them because I can just like

1188
01:08:26,960 --> 01:08:30,340
Speaker 2:  sit down for 10 minutes and do it like in between things or go somewhere

1189
01:08:30,340 --> 01:08:34,180
Speaker 2:  else. Like the main thrust of my life right now is I have a six month old

1190
01:08:34,200 --> 01:08:37,380
Speaker 2:  kid, so I get like 15 free minutes at various times. And, I'm like, I'm gonna

1191
01:08:37,400 --> 01:08:40,220
Speaker 2:  sit. I had a friend who bought me a steering wheel for these games. And I

1192
01:08:40,220 --> 01:08:44,180
Speaker 2:  love them. But F1 23 has this new mode called F1 World,

1193
01:08:44,430 --> 01:08:48,260
Speaker 2:  which is basically for anyone who's ever played like two K or

1194
01:08:48,290 --> 01:08:51,700
Speaker 2:  like FIFA ultimate team, it's one of those where you get to just like build

1195
01:08:51,860 --> 01:08:55,300
Speaker 2:  up your team and you play over time and instead of just like beating the

1196
01:08:55,300 --> 01:08:58,300
Speaker 2:  game over and over and over again, which most of these games just make you

1197
01:08:58,300 --> 01:09:02,060
Speaker 2:  do in career mode, this one you can just like hang out in the world and keep

1198
01:09:02,060 --> 01:09:05,620
Speaker 2:  racing and getting better and doing new things. Which again for me will keep

1199
01:09:05,620 --> 01:09:09,300
Speaker 2:  me interested much longer than just like trying to kind of

1200
01:09:09,300 --> 01:09:12,420
Speaker 2:  achieve the same goals over and over again. And people seem to really like

1201
01:09:12,560 --> 01:09:14,580
Speaker 2:  F1 world so I'm very excited about it.

1202
01:09:14,850 --> 01:09:18,820
Speaker 21:  Have you, you gotten into many of these th this always just seems so

1203
01:09:18,820 --> 01:09:22,700
Speaker 21:  intimidating. Intimidating not in the, I'll get sucked in forever. It

1204
01:09:22,700 --> 01:09:25,340
Speaker 21:  more intimidating in the like where do I even start? Yeah.

1205
01:09:25,400 --> 01:09:29,340
Speaker 2:  The challenge I have with these games is that if I don't get in

1206
01:09:29,390 --> 01:09:33,300
Speaker 2:  early, I'm so far behind everybody else. Like I've been playing

1207
01:09:33,300 --> 01:09:36,020
Speaker 2:  sports video games for a very long time. I'm like pretty good at most sports

1208
01:09:36,020 --> 01:09:39,780
Speaker 2:  video games, but I just don't grind. Like the people who

1209
01:09:39,780 --> 01:09:43,260
Speaker 2:  grind And I think this is true of sort of any competitive like Playto Pay

1210
01:09:43,260 --> 01:09:46,500
Speaker 2:  to win games to some extent. There's just like people with credit cards who

1211
01:09:46,500 --> 01:09:49,340
Speaker 2:  are just like buying their way to the top of all of these things. So I've

1212
01:09:49,340 --> 01:09:52,300
Speaker 2:  had to learn to just have a very zen approach. And I lose most of the time

1213
01:09:52,300 --> 01:09:55,700
Speaker 2:  and it's basically fine. Yeah. And I just like tell myself stories about

1214
01:09:55,700 --> 01:09:58,180
Speaker 2:  these all being teenagers with their parents' credit cards who are beating

1215
01:09:58,200 --> 01:10:00,420
Speaker 2:  me and I'm morally superior to them.

1216
01:10:00,780 --> 01:10:04,580
Speaker 21:  I had lunch at a friend's house last night and he is the person who is always

1217
01:10:04,580 --> 01:10:08,540
Speaker 21:  beating you in this game. Yeah. And I had no idea. These friends, they build

1218
01:10:08,670 --> 01:10:11,420
Speaker 21:  decks, And I didn't even know that they liked video games cuz they never

1219
01:10:11,420 --> 01:10:14,620
Speaker 21:  have talked about video games. And then he showed me his garage and he is

1220
01:10:14,620 --> 01:10:18,500
Speaker 21:  like, oh by the way, I do play one video game. I play

1221
01:10:18,840 --> 01:10:22,340
Speaker 21:  F1 and here's like a steel rig I built. Oh boy.

1222
01:10:22,570 --> 01:10:26,100
Speaker 21:  Like a like full, like it's like half their garage

1223
01:10:26,520 --> 01:10:30,300
Speaker 21:  and it's like, oh this is who this is. Who plays these games? Yeah.

1224
01:10:30,300 --> 01:10:32,780
Speaker 21:  It's like fighting game fans. They're like that hardcore.

1225
01:10:33,220 --> 01:10:37,140
Speaker 2:  I bought a steering wheel and like anchored it to my desk. And I thought

1226
01:10:37,140 --> 01:10:39,540
Speaker 2:  that was like very impressive. And then, and then I had the same experience.

1227
01:10:39,540 --> 01:10:43,180
Speaker 2:  People are like, here's the $10,000 rig with three giant

1228
01:10:43,270 --> 01:10:46,500
Speaker 2:  wraparound screens that I got. And I was like, oh you're gonna, you're gonna

1229
01:10:46,500 --> 01:10:47,940
Speaker 2:  beat me in all of our races, aren't

1230
01:10:47,940 --> 01:10:51,380
Speaker 20:  You? One of the things that I remember most about attending summer games

1231
01:10:51,620 --> 01:10:55,140
Speaker 20:  Fest last year was they had this like rig set up, I don't even remember

1232
01:10:55,140 --> 01:10:59,060
Speaker 20:  what game it is now. And I feel bad where you kind of like, it mimics sitting

1233
01:10:59,060 --> 01:11:02,940
Speaker 20:  in an F1 car so it's really low to the ground on the floor. Like

1234
01:11:02,940 --> 01:11:06,420
Speaker 20:  you're fully like recumbent and you use like your feet to press the pedals

1235
01:11:06,420 --> 01:11:09,980
Speaker 20:  and everything. And it like the, it had a line like really long for people

1236
01:11:09,980 --> 01:11:13,780
Speaker 20:  to try it out. And I just was so intimidated for trying it out because

1237
01:11:13,880 --> 01:11:17,340
Speaker 20:  Summer Games Fest, or at least what it was last year was like, it's this

1238
01:11:17,530 --> 01:11:21,260
Speaker 20:  open space where all these game demos are so people are like walking around

1239
01:11:21,320 --> 01:11:24,980
Speaker 20:  and you've got like Twitch influencers on those like little standing

1240
01:11:25,330 --> 01:11:29,220
Speaker 20:  like oh yeah Roomba things where they have like a Roomba attached to like

1241
01:11:29,260 --> 01:11:33,180
Speaker 20:  a screen. so like influencers who are not there can walk around the

1242
01:11:33,180 --> 01:11:36,140
Speaker 20:  floor and like look and like, oh this is cool. you know, that kind of stuff.

1243
01:11:36,360 --> 01:11:38,580
Speaker 20:  And there were so many people there with like cameras and stuff. And I was

1244
01:11:38,580 --> 01:11:41,260
Speaker 20:  just so super intimidated of getting in that thing and looking like an idiot.

1245
01:11:41,320 --> 01:11:45,180
Speaker 20:  That's so I never tried it even though I was deathly curious about it. And

1246
01:11:45,240 --> 01:11:46,540
Speaker 20:  that's one of my bigger regrets.

1247
01:11:46,910 --> 01:11:50,700
Speaker 2:  Those games are tough. They do a better job now of making

1248
01:11:50,760 --> 01:11:54,740
Speaker 2:  the racing simulators a little more sort of approachable to get into. But

1249
01:11:54,740 --> 01:11:58,700
Speaker 2:  like they're so accurate at this point that every time I

1250
01:11:58,700 --> 01:12:01,580
Speaker 2:  play one of these games I sit down and the very first thing I do is crash

1251
01:12:01,600 --> 01:12:03,140
Speaker 2:  my cart like 30 to 60 times.

1252
01:12:03,480 --> 01:12:07,340
Speaker 21:  So you're saying they don't send 30 streamers to your house with

1253
01:12:07,340 --> 01:12:11,220
Speaker 21:  video cameras to Shane, that's no. Great, great,

1254
01:12:11,220 --> 01:12:12,420
Speaker 21:  great thing. I'm on board now.

1255
01:12:12,760 --> 01:12:16,500
Speaker 2:  All right, let's shift and go to this fall, which I guess for

1256
01:12:16,500 --> 01:12:19,940
Speaker 2:  Chris Plant means the months of November and December. Yeah. But any, any

1257
01:12:19,940 --> 01:12:23,340
Speaker 2:  game that's not out yet or won't be out until the end of the summer, we'll

1258
01:12:23,340 --> 01:12:25,780
Speaker 2:  we'll say is fair game here Ash, what's your first one?

1259
01:12:26,160 --> 01:12:30,060
Speaker 20:  So this is what I was holding onto from the previous segment thing

1260
01:12:30,060 --> 01:12:33,820
Speaker 20:  that I'm looking forward to the most that is supposed to come out by

1261
01:12:34,080 --> 01:12:37,140
Speaker 20:  the end of 2023 is Sonic Superstars.

1262
01:12:43,320 --> 01:12:47,220
Speaker 20:  Big huge Sonic fan. I was jazzed as hell to see

1263
01:12:47,220 --> 01:12:50,460
Speaker 20:  that they're making another 2D Sonic

1264
01:12:50,860 --> 01:12:54,820
Speaker 20:  Platformer. I'm not really a big fan of the 3D Sonic platforms.

1265
01:12:55,190 --> 01:12:59,100
Speaker 20:  Sonic Frontiers broke my heart famously because it was like, I was so

1266
01:12:59,100 --> 01:13:02,740
Speaker 20:  excited for this game and then I played it and it was just like such a mess

1267
01:13:02,880 --> 01:13:06,220
Speaker 20:  in terms of how they implemented systems that it, it literally broke my

1268
01:13:06,220 --> 01:13:09,100
Speaker 20:  heart. Like, cause I wanted to like this game so bad. So I'm really excited

1269
01:13:09,160 --> 01:13:12,780
Speaker 20:  to see that, you know, even though Sega won't give me Sonic Mania two,

1270
01:13:12,780 --> 01:13:15,860
Speaker 20:  they'll give me Sonic Superstars, which you know, I consider that a fair

1271
01:13:15,860 --> 01:13:19,100
Speaker 20:  trade. So I'm really excited to get back into like these

1272
01:13:19,480 --> 01:13:23,100
Speaker 20:  2.5 2D side scrolling Sonic Platformers

1273
01:13:23,180 --> 01:13:26,940
Speaker 20:  because those are just fantastic perfect games in every way. And I

1274
01:13:27,030 --> 01:13:27,980
Speaker 20:  can't get enough of them.

1275
01:13:28,620 --> 01:13:31,500
Speaker 2:  I almost picked this one too. I'm very excited about this. And I was trying

1276
01:13:31,500 --> 01:13:35,340
Speaker 2:  to think when was the last really great sonic

1277
01:13:35,340 --> 01:13:39,300
Speaker 2:  game? I feel like it's been a really long time since True Sonic fans have

1278
01:13:39,300 --> 01:13:39,900
Speaker 2:  had a real winner.

1279
01:13:40,190 --> 01:13:42,620
Speaker 20:  Sonic Mania was 2017. Okay,

1280
01:13:42,730 --> 01:13:46,300
Speaker 21:  Yeah. Okay. This is, this is the controversial thing amongst like Sonic

1281
01:13:46,300 --> 01:13:50,140
Speaker 21:  fans. We're a, we're a sonic house out here. And the

1282
01:13:50,140 --> 01:13:53,940
Speaker 21:  truth is, you could both say that there have never been good ones because

1283
01:13:53,940 --> 01:13:56,740
Speaker 21:  going back and playing Sonic One and Sonic Two and Sonic Three, they're

1284
01:13:56,860 --> 01:14:00,500
Speaker 21:  designed to be headaches. The pleasure of the game is to like get

1285
01:14:00,820 --> 01:14:04,700
Speaker 21:  a your speed going right and getting a flow and the game does everything

1286
01:14:04,700 --> 01:14:08,660
Speaker 21:  it can to prevent that And I feel like my, I was a diehard sonic

1287
01:14:08,660 --> 01:14:12,380
Speaker 21:  kid as a kid then literally fell off it. And now like with my kid

1288
01:14:12,520 --> 01:14:15,420
Speaker 21:  now I'm like really falling in love with it, kind of meeting it on its own

1289
01:14:15,420 --> 01:14:18,940
Speaker 21:  terms. I'm like, oh it's actually just a traditional platformer

1290
01:14:19,320 --> 01:14:21,780
Speaker 21:  And I. Think once you start thinking about it like that, a lot of these

1291
01:14:21,780 --> 01:14:24,980
Speaker 21:  recent Sonic games have been pretty okay. Sonic Colors.

1292
01:14:25,560 --> 01:14:29,260
Speaker 21:  It happens. I think that there's kind of like weird, some weird

1293
01:14:29,290 --> 01:14:32,740
Speaker 21:  rose colored glasses for what people think Sonic was in the past for us,

1294
01:14:32,740 --> 01:14:36,260
Speaker 21:  what it actually was. But also the short answer like actually that is just

1295
01:14:36,260 --> 01:14:37,100
Speaker 21:  Sonic Mania. Yeah

1296
01:14:37,140 --> 01:14:40,180
Speaker 2:  I guess that's true. I was thinking mania was longer ago than it actually

1297
01:14:40,200 --> 01:14:43,660
Speaker 2:  was. And I Guess Mania did what I hope Superstars does, which is just be

1298
01:14:43,660 --> 01:14:46,300
Speaker 2:  a sonic game. Yes. Like, like you're saying, Ashley don't, don't try to do

1299
01:14:46,300 --> 01:14:48,620
Speaker 2:  other things. Just could be more Sonic. Yeah.

1300
01:14:48,690 --> 01:14:52,540
Speaker 20:  Give me more Sonic and Knuckles three and we're good. Yeah, you can keep

1301
01:14:52,540 --> 01:14:56,260
Speaker 20:  making that game forever and ever with new stuff. And I will always buy

1302
01:14:56,260 --> 01:14:57,220
Speaker 20:  it. And I will always be happy.

1303
01:14:57,440 --> 01:14:59,940
Speaker 2:  And you barely even have to update the graphics. No. Like it's fine.

1304
01:14:59,940 --> 01:15:01,100
Speaker 20:  Not at all. Exactly. Yeah.

1305
01:15:02,180 --> 01:15:03,180
Speaker 2:  All right Chris, what's your first one?

1306
01:15:03,550 --> 01:15:05,580
Speaker 21:  Super Mario Brothers Wonder Nice

1307
01:15:05,720 --> 01:15:05,940
Speaker 2:  Ice,

1308
01:15:09,940 --> 01:15:13,900
Speaker 21:  Which actually comes out before Metal Gear. So I am seeing the flaw in

1309
01:15:13,900 --> 01:15:14,340
Speaker 21:  my plan.

1310
01:15:16,080 --> 01:15:20,020
Speaker 21:  It comes out on October 20th. And I. Just love that this is the most

1311
01:15:20,020 --> 01:15:23,660
Speaker 21:  Nintendo thing to do on the planet that Nintendo spins

1312
01:15:23,660 --> 01:15:27,500
Speaker 21:  decades making a, and like refining an image of Super Mario

1313
01:15:28,080 --> 01:15:31,900
Speaker 21:  to the point where they finally make a movie and they're like, cool, great,

1314
01:15:31,920 --> 01:15:35,140
Speaker 21:  we nailed it. Now we're gonna change the entire aesthetic. And they're like,

1315
01:15:35,140 --> 01:15:38,020
Speaker 21:  no, are you sure You don't wanna make a game that looks like, you know Mario?

1316
01:15:38,170 --> 01:15:41,220
Speaker 21:  Like that movie that just made a gajillion dollars And. I'm like, no, no,

1317
01:15:41,220 --> 01:15:44,460
Speaker 21:  no. We're gonna make it look like a Dreamworks movie now instead. And they're

1318
01:15:44,460 --> 01:15:48,340
Speaker 21:  like, God dammit, I am so excited. I am so glad that

1319
01:15:48,340 --> 01:15:51,620
Speaker 21:  Mari was going to turn into an elephant. It's gonna be a delight.

1320
01:15:52,120 --> 01:15:56,020
Speaker 21:  And I kind of don't wanna see another image or trailer or anything

1321
01:15:56,020 --> 01:15:59,980
Speaker 21:  from this game. Because as the wonder in this subtitle suggests like

1322
01:16:00,340 --> 01:16:03,740
Speaker 21:  I think the surprise of it all and the hint that it could be a little bit

1323
01:16:03,740 --> 01:16:07,540
Speaker 21:  like Super Mario Brothers two in the us, that's enough to get me to play

1324
01:16:07,540 --> 01:16:07,660
Speaker 21:  it.

1325
01:16:08,260 --> 01:16:11,860
Speaker 20:  I wanted to ask like, how do you feel about people saying like, this just

1326
01:16:11,860 --> 01:16:15,780
Speaker 20:  looks like a updated version of New Super Mario Brothers. Which, you

1327
01:16:15,780 --> 01:16:19,380
Speaker 20:  know, as I was a sonic household, I was not a Mario household. So looking

1328
01:16:19,380 --> 01:16:22,980
Speaker 20:  at this from the outside, like this just looks like a new version of

1329
01:16:23,400 --> 01:16:27,300
Speaker 20:  New Super Mario Brothers. But instead of, I don't know, being

1330
01:16:27,460 --> 01:16:30,620
Speaker 20:  a cat, I know that's not new Super Mario's brothers don't like don't at

1331
01:16:30,620 --> 01:16:33,260
Speaker 20:  me. I know that's not it. Instead of being a cat, Mario just gets high,

1332
01:16:33,310 --> 01:16:37,140
Speaker 20:  right? Like it just seems like, okay, Mario drops acid. That's what

1333
01:16:37,140 --> 01:16:41,100
Speaker 20:  the thesis of this game is. Versus something like Super Mario Galaxy

1334
01:16:41,160 --> 01:16:44,700
Speaker 20:  or Super Mario Odyssey or you know, where they definitely

1335
01:16:44,850 --> 01:16:48,660
Speaker 20:  innovated on that formula. This just looks like, you know, a newer game

1336
01:16:48,720 --> 01:16:52,540
Speaker 20:  was not that new of a game, rather with like slightly updated graphics and

1337
01:16:52,540 --> 01:16:56,020
Speaker 20:  maybe one twist that doesn't really feel as

1338
01:16:56,610 --> 01:17:00,500
Speaker 20:  different as it should, which though sounds

1339
01:17:00,570 --> 01:17:04,460
Speaker 20:  exactly what tears of the Kingdom was. And then you played it.

1340
01:17:04,460 --> 01:17:08,340
Speaker 20:  Yeah. And it was a completely different experience on the level that

1341
01:17:08,340 --> 01:17:12,060
Speaker 20:  is like media shifting, like earth shattering. So I hope

1342
01:17:12,060 --> 01:17:14,620
Speaker 20:  you're right in that we don't get to see anything else about it and they

1343
01:17:14,620 --> 01:17:17,700
Speaker 20:  just release it, which is kind of what Nintendo kind of does is like, okay,

1344
01:17:17,700 --> 01:17:20,140
Speaker 20:  yeah, wait till they see this shit. I'm gonna knock the fucking socks off

1345
01:17:20,140 --> 01:17:21,500
Speaker 20:  of them. So yeah,

1346
01:17:21,820 --> 01:17:25,620
Speaker 21:  I think also to your point that like loving video games is a lot

1347
01:17:25,620 --> 01:17:29,340
Speaker 21:  like being a wine connoisseur no matter like what your franchise is.

1348
01:17:29,920 --> 01:17:33,340
Speaker 21:  So if you're inside of it, you're like, oh, I love Sora, I love Mario.

1349
01:17:34,200 --> 01:17:37,780
Speaker 21:  And you'd taste the the difference. And it feels more

1350
01:17:37,780 --> 01:17:41,660
Speaker 21:  substantial than it probably is. Like if every Mario game is

1351
01:17:41,660 --> 01:17:45,540
Speaker 21:  red wine, this is like Lambrusco or like something sugary and like

1352
01:17:45,660 --> 01:17:48,900
Speaker 21:  bubbly and it's like, oh, I didn't know that a wine should do that. I don't

1353
01:17:48,900 --> 01:17:51,620
Speaker 21:  know that much about wine so I'm kind of flying by the scene of my pants

1354
01:17:51,620 --> 01:17:55,340
Speaker 21:  here. But I, yeah, I think, I think we searched for those, those

1355
01:17:55,340 --> 01:17:59,180
Speaker 21:  like slight variations because we both want the thing that we're familiar

1356
01:17:59,180 --> 01:18:01,820
Speaker 21:  with but also want just a little hint of something new.

1357
01:18:02,820 --> 01:18:06,060
Speaker 2:  I mean. It also feels like we're, I don't know if this is a bigger trend

1358
01:18:06,160 --> 01:18:09,580
Speaker 2:  or not, but there is definitely in a lot of these franchises a sort of

1359
01:18:09,660 --> 01:18:13,340
Speaker 2:  pullback to like, let's do the thing that works. I think everybody,

1360
01:18:13,340 --> 01:18:17,020
Speaker 2:  everybody has been brought in by the, the lure of the battle

1361
01:18:17,080 --> 01:18:19,620
Speaker 2:  royale and the open world everything. And now everybody's just like, what

1362
01:18:19,620 --> 01:18:21,700
Speaker 2:  if we just like made a cool game that's fun to play? Hmm.

1363
01:18:21,700 --> 01:18:25,180
Speaker 21:  Which is why you're gonna tell us about Mortal Kom one. Is that a AlleyOOP?

1364
01:18:25,280 --> 01:18:27,540
Speaker 2:  No, it's why I'm gonna tell you about Assassin's Creed Mirage.

1365
01:18:28,520 --> 01:18:29,940
Speaker 21:  You're right. The other one doing it.

1366
01:18:32,240 --> 01:18:36,020
Speaker 2:  The two series I have played most completely in the course of my life are

1367
01:18:36,020 --> 01:18:39,500
Speaker 2:  the the AUM games of Batman, which I absolutely love to pieces

1368
01:18:40,220 --> 01:18:43,620
Speaker 2:  and I'm very excited that they're coming to Switch and the Assassins Creed

1369
01:18:43,620 --> 01:18:46,740
Speaker 2:  games. And the thing that happened with the last two, with the last few really

1370
01:18:46,940 --> 01:18:49,940
Speaker 2:  Assassins Creed games was they just got too big. Everything got too open

1371
01:18:49,940 --> 01:18:52,420
Speaker 2:  world. And it was just like, do you just wanna be on a ship for the next

1372
01:18:52,420 --> 01:18:55,740
Speaker 2:  five days? And I was like, no, I don't like, give me something to do. Give

1373
01:18:55,740 --> 01:18:59,500
Speaker 2:  me a task. Let me go and actually play this game.

1374
01:18:59,500 --> 01:19:03,380
Speaker 2:  Instead of just sort of aimlessly wandering yet another ancient town

1375
01:19:03,490 --> 01:19:06,820
Speaker 2:  like, I don't know, I that got old for me. And the story about Mirage so

1376
01:19:06,820 --> 01:19:10,180
Speaker 2:  far is that it is a return to form in the sense that it is

1377
01:19:10,630 --> 01:19:14,340
Speaker 2:  still big and interesting, but more sort of straightforward. And it's like

1378
01:19:14,380 --> 01:19:18,260
Speaker 2:  a game you play rather than a world you explore. And I've just

1379
01:19:18,260 --> 01:19:21,860
Speaker 2:  never been the like wander the world video gamer. I like

1380
01:19:21,860 --> 01:19:24,700
Speaker 2:  appreciate those games, And I understand why people like them. It's just

1381
01:19:24,700 --> 01:19:28,260
Speaker 2:  never been for me. And Assassin's Creed is, is like a puzzle solving game

1382
01:19:28,280 --> 01:19:32,220
Speaker 2:  at its best and I'm very excited for that to happen again. I'm very hopeful

1383
01:19:32,220 --> 01:19:34,660
Speaker 2:  for Mirage. The last two have been very disappointing, but I have high hopes

1384
01:19:34,660 --> 01:19:35,060
Speaker 2:  for Mirage.

1385
01:19:35,680 --> 01:19:35,900
Speaker 21:  Eh,

1386
01:19:36,840 --> 01:19:38,220
Speaker 2:  No you're out on Mirage.

1387
01:19:39,220 --> 01:19:42,420
Speaker 21:  I mean it's a UB soft game in the year of far, Lord

1388
01:19:42,420 --> 01:19:46,380
Speaker 21:  2023. I, I hate to do that because a lot of talented people work at this

1389
01:19:46,450 --> 01:19:49,940
Speaker 21:  publisher and everybody's trying their absolute best, but

1390
01:19:49,940 --> 01:19:53,900
Speaker 21:  everything coming outta Yousoft right now just feels so completely

1391
01:19:53,990 --> 01:19:57,940
Speaker 21:  mismanaged. I would love for it to work. I really, really would. And

1392
01:19:57,940 --> 01:20:01,340
Speaker 21:  it might be like my surprise there because everything you're saying is like

1393
01:20:01,340 --> 01:20:05,300
Speaker 21:  spot on. That is what I want. I just, I just feel like

1394
01:20:05,300 --> 01:20:07,060
Speaker 21:  I keep getting burned every time I let

1395
01:20:07,220 --> 01:20:08,360
Speaker 20:  Myself get excited for one

1396
01:20:08,360 --> 01:20:11,460
Speaker 2:  Of their games. It's fair. And the worry would be that this is basically

1397
01:20:11,460 --> 01:20:14,940
Speaker 2:  just, they just release, you know, a a 10 year old game

1398
01:20:15,220 --> 01:20:17,580
Speaker 2:  with slightly better graphics because they're like, well we couldn't forget

1399
01:20:17,580 --> 01:20:20,220
Speaker 2:  a news story. People like the old one, we'll just do that again and you're

1400
01:20:20,220 --> 01:20:23,660
Speaker 2:  not wrong that that would be potentially the most obvious thing for Ubisoft

1401
01:20:23,660 --> 01:20:27,180
Speaker 2:  to do here. So we'll see. All right, let's keep going through last round

1402
01:20:27,180 --> 01:20:28,140
Speaker 2:  here. Ash, what do you got?

1403
01:20:28,560 --> 01:20:32,340
Speaker 20:  So I have a couple things that I, I want to mention. So the one thing was

1404
01:20:32,340 --> 01:20:35,580
Speaker 20:  the Prince of Persia got side scroller that was announced at the Ubisoft

1405
01:20:35,580 --> 01:20:37,620
Speaker 20:  Direct. That looks really, really cool.

1406
01:20:39,520 --> 01:20:39,740
Speaker 25:  The

1407
01:20:39,740 --> 01:20:43,660
Speaker 26:  Prince has been kidnapped and taken to a forbidden land.

1408
01:20:45,140 --> 01:20:48,380
Speaker 20:  I don't really jive with the Prince of Persia games like the newer ones.

1409
01:20:48,700 --> 01:20:52,580
Speaker 20:  I kind of really like the Xbox One where the girl like shoots flowers out

1410
01:20:52,580 --> 01:20:55,620
Speaker 20:  of her butt when you know you unlock a thing. That was fun. That was a fun

1411
01:20:55,620 --> 01:20:58,700
Speaker 20:  game. But beyond that, like the Prince of Persia, like that original trilogy

1412
01:20:58,700 --> 01:21:01,620
Speaker 20:  and all that, that really didn't jive with me. But seeing like the side

1413
01:21:01,620 --> 01:21:05,460
Speaker 20:  scroller, I guess there's something about like side scroller platform puzzle

1414
01:21:05,460 --> 01:21:09,180
Speaker 20:  solving action that just really gets me and seeing that game

1415
01:21:09,240 --> 01:21:12,500
Speaker 20:  was like, oh okay, yeah I, I think I would like that a lot. So I'm really

1416
01:21:12,500 --> 01:21:15,860
Speaker 20:  excited about that. There was another game that was kind of like that but

1417
01:21:15,860 --> 01:21:19,740
Speaker 20:  gives me more Hades vibes. It was shown during summer

1418
01:21:19,740 --> 01:21:23,700
Speaker 20:  games, Fest, it's from this, I don't know actually where it's from.

1419
01:21:23,730 --> 01:21:27,660
Speaker 20:  It's just like this, it had this like one-off thing, it's called lga,

1420
01:21:27,800 --> 01:21:28,860
Speaker 20:  the Time shift. Warrior

1421
01:21:29,450 --> 01:21:31,340
Speaker 25:  Have another me I look good.

1422
01:21:34,200 --> 01:21:37,460
Speaker 20:  It has this like Prince of Persia like aesthetic. But this woman can like

1423
01:21:37,470 --> 01:21:41,220
Speaker 20:  split herself into different copies of herself to like solve puzzles and

1424
01:21:41,220 --> 01:21:44,100
Speaker 20:  stuff like that and fight enemies. It looked really cool. It was one of

1425
01:21:44,100 --> 01:21:46,860
Speaker 20:  the coolest things that were shown off during summer games. Fest and like

1426
01:21:46,860 --> 01:21:49,740
Speaker 20:  one of the only games I like featured a woman, sorry, I had to get that

1427
01:21:49,740 --> 01:21:53,420
Speaker 20:  in there. And then finally this, this one really does not fit within

1428
01:21:53,520 --> 01:21:56,860
Speaker 20:  the purview that you set out for us, but it is a thick game that is always

1429
01:21:56,920 --> 01:22:00,700
Speaker 20:  on my, I cannot wait for this list. And that is Dragon Age

1430
01:22:00,990 --> 01:22:01,620
Speaker 20:  Dread Wolf.

1431
01:22:03,040 --> 01:22:06,740
Speaker 25:  But now he wanted to tear down that veil

1432
01:22:07,200 --> 01:22:10,900
Speaker 25:  and destroy the world and we're the only

1433
01:22:11,050 --> 01:22:13,740
Speaker 25:  ones who can stop him.

1434
01:22:14,760 --> 01:22:18,460
Speaker 20:  We have been waiting for this game forever. Every so often

1435
01:22:18,770 --> 01:22:22,100
Speaker 20:  BioWare will pop up and be like, Hey, we're still working on this game.

1436
01:22:22,250 --> 01:22:25,420
Speaker 20:  It's still coming. Development is fine, we promise,

1437
01:22:25,880 --> 01:22:29,260
Speaker 20:  here's a little tidbit. And then they go back into their hole for like another

1438
01:22:29,260 --> 01:22:33,220
Speaker 20:  three years and we're about that time where it's time to pop out of

1439
01:22:33,220 --> 01:22:36,220
Speaker 20:  their hole and say, Hey, this game is still in development and it's still

1440
01:22:36,220 --> 01:22:39,900
Speaker 20:  coming. Here's, I don't know, here's crumbs for you, dragon age freaks and

1441
01:22:39,900 --> 01:22:43,260
Speaker 20:  then go back into their hole. So I'm really excited to see what that next

1442
01:22:43,260 --> 01:22:47,100
Speaker 20:  little tidbit is, but I, I'm excited. Dragon Age is a series

1443
01:22:47,330 --> 01:22:51,180
Speaker 20:  that saved my life in so many ways, so I'm really excited to

1444
01:22:51,240 --> 01:22:53,060
Speaker 20:  get a chance to play another one. All

1445
01:22:53,060 --> 01:22:56,420
Speaker 2:  Right, I like that that one isn't like a game you're excited about so much

1446
01:22:56,420 --> 01:22:59,380
Speaker 2:  as it is like a YouTube video that will happen at some point that you're

1447
01:22:59,380 --> 01:23:00,220
Speaker 20:  Excited about eventually.

1448
01:23:03,250 --> 01:23:06,160
Speaker 2:  Okay. All right. Well yeah, none of those, those count technically under

1449
01:23:06,160 --> 01:23:09,420
Speaker 2:  the rules. Sorry but I'll allow it. It's okay. Chris Plant last one. What

1450
01:23:09,420 --> 01:23:09,700
Speaker 2:  do you got?

1451
01:23:09,900 --> 01:23:13,220
Speaker 21:  I have one that's in the rules and one that transcends the rules. It

1452
01:23:13,500 --> 01:23:16,260
Speaker 2:  Transcends, it doesn't break the rules. It transcends the rules. Yeah.

1453
01:23:16,370 --> 01:23:19,380
Speaker 21:  Okay. The, the one that follows the rules is Alan Wake two. Yep.

1454
01:23:19,760 --> 01:23:20,460
Speaker 27:  I'm trapped here

1455
01:23:22,080 --> 01:23:24,100
Speaker 27:  in this nightmare.

1456
01:23:25,940 --> 01:23:26,980
Speaker 27:  I write to escape

1457
01:23:27,930 --> 01:23:31,900
Speaker 21:  Because Remedy makes interesting games. They made

1458
01:23:32,380 --> 01:23:35,580
Speaker 21:  control a couple years ago, which I think was one of the top five games

1459
01:23:35,640 --> 01:23:39,260
Speaker 21:  for polygons into the year list. And Allen Wake continues

1460
01:23:40,180 --> 01:23:44,020
Speaker 21:  creator of the Allen Wake games. Sam Lakes fascination with

1461
01:23:44,020 --> 01:23:47,900
Speaker 21:  Stephen King and by fascination I mean borderline

1462
01:23:48,100 --> 01:23:51,900
Speaker 21:  stalking obsession. I just think the games are a delight. And I think

1463
01:23:51,900 --> 01:23:55,820
Speaker 21:  that they understand the limitations of video games storytelling

1464
01:23:56,270 --> 01:24:00,020
Speaker 21:  while actively wanting to push them. I think video games stories

1465
01:24:00,050 --> 01:24:03,540
Speaker 21:  tend to have a bad reputation pretty understandably. And that's because

1466
01:24:03,540 --> 01:24:07,500
Speaker 21:  they have a really tough task of both giving the player some sense of

1467
01:24:07,500 --> 01:24:11,300
Speaker 21:  freedom and choice while then also having authorial

1468
01:24:11,300 --> 01:24:15,180
Speaker 21:  intent, which those things seem to conflict. And I think that

1469
01:24:15,730 --> 01:24:19,580
Speaker 21:  they enjoy toying with that, knowing

1470
01:24:19,610 --> 01:24:23,540
Speaker 21:  that like almost thinking of story as an experiment. Unless it's like,

1471
01:24:23,540 --> 01:24:27,100
Speaker 21:  oh I need to make the greatest thing ever because they kind of know from

1472
01:24:27,100 --> 01:24:29,540
Speaker 21:  the beginning that that's not entirely possible within the strictures of

1473
01:24:29,540 --> 01:24:30,100
Speaker 21:  a video game.

1474
01:24:30,570 --> 01:24:33,780
Speaker 2:  Wait, just real quick, how do you feel about the fact that Alan Wake looks

1475
01:24:34,140 --> 01:24:36,460
Speaker 2:  absolutely exactly like Bradley Cooper? What are your thoughts?

1476
01:24:36,940 --> 01:24:40,540
Speaker 21:  I like that, but I like Max Payne better because Max Payne

1477
01:24:40,940 --> 01:24:44,740
Speaker 21:  actually has the face of the creator of Alan Wake Has

1478
01:24:44,840 --> 01:24:48,540
Speaker 21:  his face and he looks Like. he is p like the world's biggest dump.

1479
01:24:48,760 --> 01:24:52,380
Speaker 21:  Oh my God. Oh that's it is such a good, good thing.

1480
01:24:52,840 --> 01:24:56,540
Speaker 21:  And then my, my like transcending the rules is I am ready for the game of

1481
01:24:56,550 --> 01:25:00,300
Speaker 21:  capitalism to come to an end and for this Microsoft Ft.

1482
01:25:00,410 --> 01:25:04,060
Speaker 21:  Cade Oh good glory, yes. To just be absolutely over with cuz I'm just

1483
01:25:04,200 --> 01:25:07,780
Speaker 21:  so done with it. Do you care at all? I care because living

1484
01:25:08,080 --> 01:25:11,500
Speaker 21:  in Irvine there are so many Blizzard and

1485
01:25:11,500 --> 01:25:15,340
Speaker 21:  Activision people in this area and my personal

1486
01:25:15,620 --> 01:25:19,060
Speaker 21:  stance on this is I, I think it's like a parody

1487
01:25:19,560 --> 01:25:23,460
Speaker 21:  of government action where things were not done when they

1488
01:25:23,460 --> 01:25:26,500
Speaker 21:  mattered. So now it's going to be done over the people who make Call of

1489
01:25:26,500 --> 01:25:30,300
Speaker 21:  Duty and Diablo And I think it's gonna blow up in the FTCs face,

1490
01:25:31,110 --> 01:25:35,060
Speaker 21:  which is bad and embarrassing for them. The good

1491
01:25:35,060 --> 01:25:38,420
Speaker 21:  news is I think a lot of people who already work at a place that is

1492
01:25:38,610 --> 01:25:42,580
Speaker 21:  notorious for being a difficult place to work can like get

1493
01:25:42,580 --> 01:25:45,940
Speaker 21:  out of this like purgatory period and start moving on with their lives,

1494
01:25:46,030 --> 01:25:49,940
Speaker 21:  which I think is like a better thing than whatever the past six

1495
01:25:49,940 --> 01:25:51,100
Speaker 21:  months has been for all these people.

1496
01:25:51,970 --> 01:25:54,820
Speaker 2:  Fair enough. That does in fact transcend the rules. I will g I will grant

1497
01:25:54,820 --> 01:25:58,060
Speaker 2:  that one. My last one is Spider-Man two because

1498
01:25:58,700 --> 01:25:59,980
Speaker 2:  I loved Spider-Man. One

1499
01:26:03,220 --> 01:26:06,780
Speaker 2:  Venom is the villain you can play as multiple characters. It's just one of

1500
01:26:06,780 --> 01:26:08,900
Speaker 2:  those things where they're like, we took a game that you love and we made

1501
01:26:08,900 --> 01:26:11,660
Speaker 2:  it slightly better. Would you like to play it again? And my answer to that

1502
01:26:11,660 --> 01:26:13,220
Speaker 2:  is yes. Always. Every single time.

1503
01:26:13,330 --> 01:26:13,620
Speaker 20:  Yeah.

1504
01:26:14,760 --> 01:26:18,660
Speaker 2:  And they're gonna be like, we made swinging through buildings 6% more

1505
01:26:18,660 --> 01:26:21,940
Speaker 2:  fun. And I'm like, yes, I will play it 500% more often now

1506
01:26:22,120 --> 01:26:25,300
Speaker 21:  He just flies. Right? Like I, I feel like on that trailer of this like,

1507
01:26:25,300 --> 01:26:27,700
Speaker 21:  but what if he just flies? Yeah. And I was Like.

1508
01:26:28,240 --> 01:26:31,860
Speaker 2:  He has like flying squirrel wings now. It's like, I don't think that's

1509
01:26:32,070 --> 01:26:33,460
Speaker 2:  Canon, but I'm cool with it

1510
01:26:34,280 --> 01:26:38,100
Speaker 20:  As a, across the Spider verse per Enjoyer person I who

1511
01:26:38,120 --> 01:26:42,060
Speaker 20:  did not play Spider-Man one or the Miles Morales dlc. I,

1512
01:26:42,290 --> 01:26:46,100
Speaker 20:  well I can't say I'm excited for Spider-Man two, I'm excited to, I

1513
01:26:46,100 --> 01:26:50,020
Speaker 20:  guess try it to see if it can sell me on what it is because it seems

1514
01:26:50,020 --> 01:26:53,980
Speaker 20:  like a good experience. But beyond that, like, I don't

1515
01:26:53,980 --> 01:26:56,180
Speaker 20:  know man those I get it but I just don't get it.

1516
01:26:56,730 --> 01:27:00,660
Speaker 21:  It's a certain type of, of game, right? Like I mean we were talking about

1517
01:27:00,660 --> 01:27:04,500
Speaker 21:  the Ubisoft thing earlier, but I feel like it, it demands a certain

1518
01:27:04,950 --> 01:27:08,780
Speaker 21:  thing of the player both in terms of like, well the politics

1519
01:27:08,930 --> 01:27:12,660
Speaker 21:  yeah, but also the like the open world of the game and the, and the kind

1520
01:27:12,660 --> 01:27:16,380
Speaker 21:  of to-do list. But that said, I get it is somebody

1521
01:27:16,480 --> 01:27:19,940
Speaker 21:  who I feel like I could really use a good to-do list game. I cannot, I should

1522
01:27:19,940 --> 01:27:22,900
Speaker 21:  have said this earlier, I'm so excited to get deeper into Final Fantasy

1523
01:27:22,970 --> 01:27:26,900
Speaker 21:  16 because after Zelda I am so happy to have a game that's

1524
01:27:26,900 --> 01:27:27,460
Speaker 21:  like you

1525
01:27:27,460 --> 01:27:29,820
Speaker 20:  Are on rails. You cannot go anywhere except

1526
01:27:29,820 --> 01:27:30,820
Speaker 2:  Where we tell you to

1527
01:27:30,820 --> 01:27:34,100
Speaker 21:  Go. You'll do this and it will be pretty and You don like it and it will

1528
01:27:34,170 --> 01:27:34,780
Speaker 21:  confuse you

1529
01:27:36,160 --> 01:27:36,740
Speaker 20:  And Yeah,

1530
01:27:38,290 --> 01:27:39,300
Speaker 20:  exactly. Totally

1531
01:27:39,360 --> 01:27:43,140
Speaker 2:  Get it. Yeah. I'm, I'm glad to have a game that doesn't feel like a

1532
01:27:43,420 --> 01:27:47,340
Speaker 2:  creative exercise all the time. Sometimes yes. All right, well

1533
01:27:47,340 --> 01:27:50,020
Speaker 2:  we need to take a break, but thank you both for doing this. This was, this

1534
01:27:50,020 --> 01:27:52,700
Speaker 2:  was really fun and we're, we're gonna have to do this periodically cuz God

1535
01:27:52,700 --> 01:27:54,540
Speaker 2:  knows the games don't keep coming. But thank you both.

1536
01:27:54,750 --> 01:27:55,260
Speaker 21:  Thank you.

1537
01:27:55,470 --> 01:27:56,500
Speaker 20:  Thank you for having us.

1538
01:28:01,560 --> 01:28:04,700
Speaker 2:  All right, before we go, let's get to The Vergecast hotline. As a reminder,

1539
01:28:04,720 --> 01:28:08,300
Speaker 2:  the hotline number is eight six six Verge 11. Call and ask us

1540
01:28:08,520 --> 01:28:12,020
Speaker 2:  all of your deepest, most personal, most chaotic

1541
01:28:12,250 --> 01:28:16,060
Speaker 2:  tech questions. We love it. Here's one that seemed fitting for today's episode

1542
01:28:16,210 --> 01:28:16,860
Speaker 2:  from aj.

1543
01:28:18,000 --> 01:28:21,620
Speaker 28:  Hi Vergecast, this is AJ from Minneapolis. I'm curious to know, what

1544
01:28:21,620 --> 01:28:25,220
Speaker 28:  advice do you have to keep an iPhone feeling fresh and performing well

1545
01:28:25,640 --> 01:28:29,580
Speaker 28:  as it gets closer to its third year and beyond? A little background, I've

1546
01:28:29,580 --> 01:28:33,540
Speaker 28:  been a mostly happy owner of an iPhone 13 pro since that device

1547
01:28:33,860 --> 01:28:37,220
Speaker 28:  launched about a year and a half ago, but the battery quality has gotten

1548
01:28:37,250 --> 01:28:41,020
Speaker 28:  significantly worse recently. Some days I'm charging it twice

1549
01:28:41,110 --> 01:28:44,740
Speaker 28:  fully just to make it through one day. I've made all my past smartphones

1550
01:28:44,740 --> 01:28:47,780
Speaker 28:  last at least three years, but I am not looking forward to another year

1551
01:28:47,780 --> 01:28:51,140
Speaker 28:  and a half of this phone. I'll probably be tempted to buy their latest device

1552
01:28:51,140 --> 01:28:54,980
Speaker 28:  in the fall. Any advice to keep my battery in tip top shape and

1553
01:28:54,980 --> 01:28:57,820
Speaker 28:  keep this iPhone 13 pro going strong. Thanks

1554
01:28:58,840 --> 01:29:02,740
Speaker 2:  Aj. I asked around did some research, And I have goodish news? I

1555
01:29:02,740 --> 01:29:06,300
Speaker 2:  would say the first thing that I tell everyone to do and is just generally

1556
01:29:06,300 --> 01:29:10,140
Speaker 2:  good advice is reboot your phone more often than you think every few

1557
01:29:10,140 --> 01:29:13,500
Speaker 2:  days. Just turn it off and turn it back on again. It's good advice frankly

1558
01:29:13,560 --> 01:29:16,500
Speaker 2:  for any gadget that you own, but you'll be amazed at the number of things

1559
01:29:16,570 --> 01:29:19,780
Speaker 2:  that stop running in the background, that stop trying to access your location

1560
01:29:19,780 --> 01:29:23,140
Speaker 2:  that stopped trying to access your microphone. These things just drain battery

1561
01:29:23,160 --> 01:29:26,220
Speaker 2:  and they really add up. So reboot your phone every once in a while. A clean

1562
01:29:26,220 --> 01:29:30,180
Speaker 2:  start always helps also to the same end. Delete some apps, apps you don't

1563
01:29:30,240 --> 01:29:33,660
Speaker 2:  use might be running in the background. Might be refreshing every now and

1564
01:29:33,660 --> 01:29:37,420
Speaker 2:  then. Apps that you genuinely don't use or care about, just get rid of

1565
01:29:37,580 --> 01:29:40,820
Speaker 2:  them. The Ticketmaster app on your phone that you use two times, you're better

1566
01:29:40,820 --> 01:29:43,620
Speaker 2:  off just downloading that and relogging in every once in a while than letting

1567
01:29:43,620 --> 01:29:47,460
Speaker 2:  it linger on your phone. If you ask Apple how to help your battery, the first

1568
01:29:47,460 --> 01:29:51,300
Speaker 2:  two things it will tell you are use wifi whenever possible and turn down

1569
01:29:51,300 --> 01:29:55,020
Speaker 2:  the brightness on your screen. Those are only really doable

1570
01:29:55,020 --> 01:29:58,540
Speaker 2:  things in certain situations, but take that for what it's worth. As little

1571
01:29:58,540 --> 01:30:02,460
Speaker 2:  brightness as you can wifi whenever possible. The thing I do to save battery

1572
01:30:02,490 --> 01:30:05,700
Speaker 2:  life that I've had really good luck with is turning on low power mode on

1573
01:30:05,700 --> 01:30:09,620
Speaker 2:  the iPhone. In theory it turns some stuff off. Mostly background refreshing

1574
01:30:09,620 --> 01:30:13,260
Speaker 2:  and push email and that kind of thing. The place I notice it is, it turns

1575
01:30:13,280 --> 01:30:17,220
Speaker 2:  off background iCloud syncing. So if you use apps that sync

1576
01:30:17,220 --> 01:30:20,740
Speaker 2:  through iCloud to other devices, you might notice it not syncing quite as

1577
01:30:20,740 --> 01:30:24,420
Speaker 2:  often or successfully, but otherwise I can have low power mode on all day

1578
01:30:24,640 --> 01:30:28,260
Speaker 2:  and frankly barely notice the difference but actually get significantly better

1579
01:30:28,260 --> 01:30:31,980
Speaker 2:  battery life. One thing you should do for sure is make sure that on your

1580
01:30:31,980 --> 01:30:35,780
Speaker 2:  iPhone you have optimized battery charging on, it's a setting I think under

1581
01:30:35,780 --> 01:30:39,660
Speaker 2:  battery health, in the battery settings, in the settings app. And basically

1582
01:30:39,660 --> 01:30:43,500
Speaker 2:  what that does is not fully charge your iPhone until you're gonna need it.

1583
01:30:43,520 --> 01:30:46,820
Speaker 2:  And there are a lot of people who will tell you that leaving your phone at

1584
01:30:46,860 --> 01:30:50,340
Speaker 2:  a hundred percent for a long time, especially plugged in, can be bad for

1585
01:30:50,340 --> 01:30:54,260
Speaker 2:  your battery health. So turn that on. I'm generally not of the mind that

1586
01:30:54,260 --> 01:30:58,100
Speaker 2:  you need to like really babysit the way that you charge your

1587
01:30:58,100 --> 01:31:01,140
Speaker 2:  phone. I just think that's too much work. But you can at least turn that

1588
01:31:01,140 --> 01:31:04,700
Speaker 2:  setting on and have the device do it for you at some point. But ultimately

1589
01:31:05,120 --> 01:31:07,900
Speaker 2:  the honest truth is you're just gonna have to get a new battery at some point.

1590
01:31:08,300 --> 01:31:12,180
Speaker 2:  I think we keep our phones longer and longer and the idea that you

1591
01:31:12,180 --> 01:31:15,580
Speaker 2:  can keep your phone for several years but replace the battery somewhere in

1592
01:31:15,580 --> 01:31:19,100
Speaker 2:  the middle of that range is not a terrible trade off. I checked Apple's thing

1593
01:31:19,360 --> 01:31:23,260
Speaker 2:  and it said that it'll be about $89 to put a new battery in the

1594
01:31:23,420 --> 01:31:26,620
Speaker 2:  13 pro, which to me is totally worth it and certainly a lot cheaper than

1595
01:31:26,620 --> 01:31:30,140
Speaker 2:  buying a new phone. If you're otherwise happy with your phone, I think it's

1596
01:31:30,140 --> 01:31:34,100
Speaker 2:  a bummer that you're already experiencing battery troubles with a 13 pro,

1597
01:31:34,100 --> 01:31:37,900
Speaker 2:  which is not an old phone. But if that is the case, you can check the battery

1598
01:31:37,900 --> 01:31:41,820
Speaker 2:  health also in the battery settings, in the settings app. And if it's below

1599
01:31:41,820 --> 01:31:45,660
Speaker 2:  80% of its original capacity, that's when Apple recommends

1600
01:31:45,760 --> 01:31:49,660
Speaker 2:  and will actually work with you to replace it. So get a new

1601
01:31:49,660 --> 01:31:53,300
Speaker 2:  battery, low power mode, reboot your phone every once in a while and

1602
01:31:53,300 --> 01:31:57,060
Speaker 2:  otherwise good luck. You can be one of those people who obsessively charges

1603
01:31:57,060 --> 01:32:00,080
Speaker 2:  your phone between 40 and 80%, which is is what a lot of people will tell

1604
01:32:00,080 --> 01:32:03,020
Speaker 2:  you to do. I think that's too much work do without you will.

1605
01:32:04,800 --> 01:32:08,020
Speaker 2:  All right, that is it for The Vergecast today. Thanks to everyone who is

1606
01:32:08,020 --> 01:32:11,420
Speaker 2:  on the show, and thank you as always so much for listening. There's lots

1607
01:32:11,420 --> 01:32:15,300
Speaker 2:  more from everything we talked about ai, apple stuff on The Verge

1608
01:32:15,320 --> 01:32:18,860
Speaker 2:  dot com, lots of Apple things coming in the next few days. I think we'll

1609
01:32:18,860 --> 01:32:21,060
Speaker 2:  put some links in the show notes, but also, you know, read The Verge dot

1610
01:32:21,060 --> 01:32:24,100
Speaker 2:  com. It's a website. We like it. If you have thoughts, questions, feelings,

1611
01:32:24,160 --> 01:32:27,500
Speaker 2:  or other tips on how to make your battery work better, you can always email

1612
01:32:27,500 --> 01:32:31,460
Speaker 2:  us at Vergecast The Verge dot com or keep calling the hotline. Its six six

1613
01:32:31,660 --> 01:32:35,500
Speaker 2:  Verge one 11. We are already building a bunch of episodes based on your hotline

1614
01:32:35,700 --> 01:32:38,780
Speaker 2:  questions, so thank you so much for that. This show is produced by Andrew

1615
01:32:38,780 --> 01:32:42,060
Speaker 2:  Marino and Liam James. Brooke Minters is our editorial director of Audio

1616
01:32:42,360 --> 01:32:45,420
Speaker 2:  The. Vergecast is Verge production and part of the Vox Media podcast network.

1617
01:32:45,970 --> 01:32:49,900
Speaker 2:  Nili Alex now will be back on Friday to talk about threads, Reddit, apple,

1618
01:32:50,120 --> 01:32:52,580
Speaker 2:  and lots more. We'll see you then. Rock and roll.

