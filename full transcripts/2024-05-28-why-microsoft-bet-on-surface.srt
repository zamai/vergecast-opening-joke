1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: bf88ccfb-6130-49d5-81af-4570ccf5768b
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-5737265934328429244/-4662017448900315629/s93290-US-5318s-1716880788.mp3
Description: Today on the flagship podcast of open smart home standards: 

03:25 - Microsoft’s Pavan Davuluri, leader for Windows and Devices, joins the show to discuss the future of the AI PC and what’s next for Microsoft’s hardware

Microsoft’s new Windows chief on the future of the OS, Surface, and those annoying ads

Microsoft’s big bet on building a new type of AI computer 

Microsoft Build 2024: everything announced


30:25 - The Verge’s Jen Tuohy and David Pierce discuss the latest updates in the smart home world in a segment called “Does Matter matter yet?”

The Dyson WashG1 is the company’s first dedicated mop

Amazon’s Matter Casting is shaping up so nicely, I want to use it everywhere

Matter 1.3 arrives with new device type and features

Smart lighting company Brilliant is looking for a buyer

Google launches new Home APIs and turns Google TVs into smart home hubs 


01:13:20 - David answers a question from the Vergecast Hotline about AI-powered search engines. 


Google is redesigning its search engine — and it's AI all the way down 

Google CEO Sundar Pichai on AI-powered search and the future of the web


Email us at vergecast@theverge.com or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Enabled (37 ads detected)

2
00:00:02,595 --> 00:00:03,085
Speaker 2:  Welcome

3
00:00:03,085 --> 00:00:06,805
Speaker 3:  To The Vergecast, the flagship podcast of Open Smart Home Standards.

4
00:00:07,105 --> 00:00:10,965
Speaker 3:  I'm your friend David Pierce, and I am cooped up inside. It's a

5
00:00:10,965 --> 00:00:14,885
Speaker 3:  holiday weekend, but it's like hot and rainy all at the same

6
00:00:14,885 --> 00:00:18,805
Speaker 3:  time, and it's just like a nasty time to be outside. But the upside of that

7
00:00:18,825 --> 00:00:22,765
Speaker 3:  is it means I have an incredible built-in excuse to just spend

8
00:00:22,765 --> 00:00:26,605
Speaker 3:  three days playing video games. And that is essentially what has happened.

9
00:00:27,285 --> 00:00:30,885
Speaker 3:  I don't know if I've mentioned this on the show before, but the game over

10
00:00:31,325 --> 00:00:35,125
Speaker 3:  probably the last decade that has eaten up the most of my time is fifa. The

11
00:00:35,125 --> 00:00:38,965
Speaker 3:  soccer game, it's not even called FIFA anymore, it's EA Sports FC now,

12
00:00:39,185 --> 00:00:42,845
Speaker 3:  but who cares? It's FIFA and I play arguably too much

13
00:00:42,995 --> 00:00:46,605
Speaker 3:  fifa. I'm like pretty good at it in a way that I'm not good at a lot of the

14
00:00:46,705 --> 00:00:50,565
Speaker 3:  Battle Royale games. I just get crushed at Fortnite and War Zone and all

15
00:00:50,565 --> 00:00:54,325
Speaker 3:  of those. But I'm pretty good at FIFA and I have become alarmingly

16
00:00:54,325 --> 00:00:58,245
Speaker 3:  into it, especially over the course of this year, and now it's

17
00:00:58,345 --> 00:01:01,125
Speaker 3:  May, it's almost June, which means it's the end of the soccer season, which

18
00:01:01,125 --> 00:01:04,645
Speaker 3:  means it's almost the end of the FIFA season and I'm, I'm too deep in it

19
00:01:04,645 --> 00:01:08,445
Speaker 3:  at this point. I am in the subreddits, I'm in the Trading Discords.

20
00:01:08,645 --> 00:01:12,365
Speaker 3:  I spent 20 bucks on a guide to trading players inside of

21
00:01:12,395 --> 00:01:16,365
Speaker 3:  FIFA to get more coins, to buy more players. It's a lot. I'm deep in it.

22
00:01:16,675 --> 00:01:19,685
Speaker 3:  It's a whole thing. I can tell you who all the leakers are. If you ever want

23
00:01:19,685 --> 00:01:23,605
Speaker 3:  to talk about FIFA and compare ultimate teams, get at me. It's the only

24
00:01:23,605 --> 00:01:27,285
Speaker 3:  thing I ever want to talk about. Luckily, for most of you, that is not what

25
00:01:27,285 --> 00:01:30,445
Speaker 3:  we are here to talk about on this show today, we're gonna do two things.

26
00:01:30,785 --> 00:01:34,565
Speaker 3:  One, we're gonna talk more about what has gone on with Microsoft.

27
00:01:34,585 --> 00:01:38,285
Speaker 3:  The last couple of weeks. It was Build, it was the Surface launch,

28
00:01:38,545 --> 00:01:42,125
Speaker 3:  and we have the person who runs Windows and Surface at

29
00:01:42,365 --> 00:01:46,325
Speaker 3:  Microsoft Pavan Dava Lure on the show to talk about both the beginning

30
00:01:46,465 --> 00:01:50,325
Speaker 3:  and end of this project that Microsoft has been on for a long time

31
00:01:50,785 --> 00:01:54,405
Speaker 3:  and what he sees coming for the next decade too. Super fun, really

32
00:01:54,645 --> 00:01:57,965
Speaker 3:  interesting. Then Gen two is gonna come on and we're gonna do a bit of a

33
00:01:57,965 --> 00:02:01,885
Speaker 3:  round robin of Smart Home News because a bunch of stuff has happened, some

34
00:02:01,885 --> 00:02:05,405
Speaker 3:  of which I think is actually bigger than I realized, and we're just gonna

35
00:02:05,405 --> 00:02:08,085
Speaker 3:  dig into all of it and see what's really going on. Then we're gonna get to

36
00:02:08,085 --> 00:02:11,805
Speaker 3:  the hotline. We're gonna talk about search engines, search engines on everybody's

37
00:02:11,805 --> 00:02:15,165
Speaker 3:  mind right now. All that is coming up in just a minute. But first,

38
00:02:15,995 --> 00:02:19,805
Speaker 3:  fifa, it's Champions. If you know what that means, you know

39
00:02:19,805 --> 00:02:23,285
Speaker 3:  that's a big deal. If you don't know what that means, stay that way. It's

40
00:02:23,285 --> 00:02:26,205
Speaker 3:  for the best But anyway. I gotta go play a bunch of fifa for some reason

41
00:02:26,435 --> 00:02:29,925
Speaker 3:  that feels very important to me right now. This is The Vergecast. We'll be

42
00:02:29,925 --> 00:02:30,205
Speaker 3:  right back.

43
00:03:45,355 --> 00:03:47,715
Speaker 3:  few episodes, but it's because I think this is

44
00:04:27,895 --> 00:04:29,235
Speaker 5:  leader for Windows and Devices.

45
00:04:29,965 --> 00:04:33,795
Speaker 3:  Pavin currently runs all things Windows and Surface inside of Microsoft.

46
00:04:34,105 --> 00:04:37,035
Speaker 3:  He's been in that job for a few months, but he's actually been at the company

47
00:04:37,135 --> 00:04:40,915
Speaker 3:  for more than two decades and as a result has seen just about everything

48
00:04:41,215 --> 00:04:45,195
Speaker 3:  in the Windows and Surface world in that time. So we started our

49
00:04:45,195 --> 00:04:49,075
Speaker 3:  conversation by going back in time all the way to 2012 to the first ever

50
00:04:49,635 --> 00:04:53,195
Speaker 3:  Microsoft Surface and Surface rt. Back then, we weren't talking

51
00:04:53,285 --> 00:04:56,595
Speaker 3:  about ai, we weren't even really talking about laptops. That was the time

52
00:04:56,595 --> 00:05:00,275
Speaker 3:  when everybody kind of thought PCs were dead and phones were going to be

53
00:05:00,275 --> 00:05:03,315
Speaker 3:  the only thing you remember that like this was supposed to be the end of

54
00:05:03,515 --> 00:05:06,795
Speaker 3:  computers, not the beginning of some grand project for Microsoft. But you

55
00:05:06,795 --> 00:05:10,675
Speaker 3:  can draw a line from that moment in 2012 with the

56
00:05:10,675 --> 00:05:14,235
Speaker 3:  Surface rt, which was bad all the way to this one

57
00:05:14,265 --> 00:05:18,195
Speaker 3:  without trying very hard. So 2012, let's go back, what was

58
00:05:18,195 --> 00:05:21,835
Speaker 3:  the big bet behind the Surface, particularly the Surface rt?

59
00:05:22,645 --> 00:05:26,505
Speaker 5:  So our core thesis, you know, at that point in time, you're right, we

60
00:05:26,505 --> 00:05:30,265
Speaker 5:  made an arm bet. The ARM bet was around modernizing

61
00:05:30,365 --> 00:05:34,025
Speaker 5:  the platform at the end of the day and bringing modern architectures to Windows

62
00:05:34,765 --> 00:05:38,545
Speaker 5:  arm was a part of it for sure. You know, instruction sets matter obviously

63
00:05:38,545 --> 00:05:41,665
Speaker 5:  for the core operating system and the app experiences, but really the theory

64
00:05:41,665 --> 00:05:45,625
Speaker 5:  of the case for Arm was a modern system, you know, in

65
00:05:45,625 --> 00:05:48,865
Speaker 5:  its in its entirety. And so what we wanted was

66
00:05:49,525 --> 00:05:52,665
Speaker 5:  yes, great, you know, performance. We wanted great battery life, we wanted,

67
00:05:52,665 --> 00:05:55,785
Speaker 5:  you know, security, all the other aspects of modern platforms at the in in

68
00:05:55,785 --> 00:05:59,525
Speaker 5:  that window of time. And so arm Arm was a big bet. And as you

69
00:05:59,585 --> 00:06:03,365
Speaker 5:  recall for sure, Surface RD did bring a new user experience sort of,

70
00:06:03,505 --> 00:06:06,565
Speaker 5:  you know, paradigm to the table for sure. And you know, in that window of

71
00:06:06,565 --> 00:06:10,005
Speaker 5:  time we were seeing Confluence certainly across what was happening in the

72
00:06:10,145 --> 00:06:13,765
Speaker 5:  PC space and the tablet space. And in mobile it was early days of, you know,

73
00:06:13,765 --> 00:06:17,685
Speaker 5:  tablet iteration back then. Yeah. So a lot of those constructs

74
00:06:17,725 --> 00:06:21,325
Speaker 5:  I think, you know, are still true today for sure. And the way I think about

75
00:06:21,335 --> 00:06:24,445
Speaker 5:  kinda this kinda where your thought was going to bridge that from back then

76
00:06:24,465 --> 00:06:28,245
Speaker 5:  to today is the arm journey as an example, has been a

77
00:06:28,385 --> 00:06:32,165
Speaker 5:  multi-generation exercise for us for sure. And we

78
00:06:32,165 --> 00:06:35,445
Speaker 5:  certainly learned many lessons, especially on the Surface team, between the

79
00:06:35,445 --> 00:06:38,805
Speaker 5:  work we did in Surface Pro X and Surface Pro nine 5G for instance.

80
00:06:39,345 --> 00:06:43,165
Speaker 5:  And now I think we're in a place where we brought the totality of what was

81
00:06:43,165 --> 00:06:46,365
Speaker 5:  needed to be just building great product for customers at the end of the

82
00:06:46,365 --> 00:06:50,325
Speaker 5:  day to the table. And so, so I feel much more confident now in terms

83
00:06:50,325 --> 00:06:52,205
Speaker 5:  of the work that we have done. Did

84
00:06:52,205 --> 00:06:56,005
Speaker 3:  You know, 12 years ago, how long that list

85
00:06:56,025 --> 00:06:59,005
Speaker 3:  of things you just described was, 'cause I think part of the reason I ask

86
00:06:59,005 --> 00:07:02,765
Speaker 3:  is it feels like, you know, the, the running joke is next year has been the

87
00:07:02,765 --> 00:07:06,685
Speaker 3:  year of Windows on Arm for a decade now. And, and it seems like at the

88
00:07:06,685 --> 00:07:10,565
Speaker 3:  very least, you and Microsoft are substantially more confident that

89
00:07:10,715 --> 00:07:14,445
Speaker 3:  that is the case now than ever. But if you rewind

90
00:07:14,445 --> 00:07:18,165
Speaker 3:  12 years, do you think your sense of the project was

91
00:07:19,045 --> 00:07:20,765
Speaker 3:  actually as big as the project turned out to be?

92
00:07:20,955 --> 00:07:24,645
Speaker 5:  Yeah, there, you know, this is a great example of the breadth and

93
00:07:24,645 --> 00:07:27,845
Speaker 5:  diversity of the Windows ecosystem. I think our superpower is the diversity

94
00:07:27,845 --> 00:07:28,685
Speaker 5:  of the ecosystem,

95
00:07:28,855 --> 00:07:32,725
Speaker 3:  Which is such a great euphemism in such like a good and bad way. Like it

96
00:07:32,725 --> 00:07:35,645
Speaker 3:  makes everything wonderful and massively complicated all at the same time.

97
00:07:35,675 --> 00:07:36,165
Speaker 3:  Massive.

98
00:07:36,165 --> 00:07:39,965
Speaker 5:  Exactly. So you kind of have to get your arms around enough of the massive

99
00:07:39,965 --> 00:07:43,485
Speaker 5:  components, I think, to be meaningful at the end of the day. And that has

100
00:07:43,485 --> 00:07:46,925
Speaker 5:  been, in fact, the reason why we took for this iteration of it,

101
00:07:47,595 --> 00:07:50,805
Speaker 5:  frankly David, I think we could have done individual bits and pieces sooner

102
00:07:50,985 --> 00:07:54,165
Speaker 5:  and then kind of done them on an asynchronous basis. We could have done some

103
00:07:54,165 --> 00:07:57,245
Speaker 5:  of the dev pla stuff kind of out of band and, and kind of got, got those

104
00:07:57,245 --> 00:08:00,125
Speaker 5:  pieces out. We could have done parts of the CoreOS and then released them

105
00:08:00,145 --> 00:08:03,725
Speaker 5:  as, you know, incremental updates in Windows. But we chose to go ahead, take

106
00:08:03,725 --> 00:08:07,525
Speaker 5:  the time needed to go do the entire thing. You know, one good example of

107
00:08:07,525 --> 00:08:11,405
Speaker 5:  that is our partnership on the Silicon platform. To me, the Silicon platform

108
00:08:11,405 --> 00:08:15,125
Speaker 5:  is a foundation for what, you know, the OSS and app experiences are and what

109
00:08:15,125 --> 00:08:18,885
Speaker 5:  they can, you know, take advantage of. And it takes time to go rebuild the

110
00:08:18,885 --> 00:08:22,285
Speaker 5:  entire silicon. In this case, our partnership with Qualcomm took us to a

111
00:08:22,285 --> 00:08:24,725
Speaker 5:  place and quite frankly, with Arm Holdings to a place where we had to go

112
00:08:24,725 --> 00:08:28,205
Speaker 5:  back and address some fundamentals. And you know, silicon design lifecycle

113
00:08:28,535 --> 00:08:32,165
Speaker 5:  takes time when you are rebuilding an entire ship for the exercise. So, so

114
00:08:32,205 --> 00:08:35,045
Speaker 5:  I think we, we certainly appreciated the magnitude of it in the more recent

115
00:08:35,045 --> 00:08:38,965
Speaker 5:  years and I think we decided to take the time to address the, the completion

116
00:08:38,965 --> 00:08:42,365
Speaker 5:  of it perhaps, versus doing another sort of incremental take on it. Is

117
00:08:42,365 --> 00:08:46,325
Speaker 3:  It easy then in that process to sort

118
00:08:46,325 --> 00:08:49,525
Speaker 3:  of find the moment where you're, or like identify the moment where you're

119
00:08:49,525 --> 00:08:52,845
Speaker 3:  like, okay, we're we're there, we've done the thing and instead of, 'cause

120
00:08:52,845 --> 00:08:55,820
Speaker 3:  my sense was something like this is you could tinker with app compatibility

121
00:08:55,820 --> 00:08:59,805
Speaker 3:  until the heat death of the universe and never actually solve every

122
00:08:59,805 --> 00:09:03,285
Speaker 3:  problem in every edge case. How do you pick the moment where you're like,

123
00:09:03,285 --> 00:09:07,125
Speaker 3:  okay, we have kind of over promise and under-delivered a couple of times,

124
00:09:07,185 --> 00:09:10,765
Speaker 3:  we know we have to get this right and we have like what, how do you put that

125
00:09:10,875 --> 00:09:11,605
Speaker 3:  flag in the ground?

126
00:09:11,915 --> 00:09:15,285
Speaker 5:  Yeah, it's a great question. You know, I think to me there isn't a single

127
00:09:15,505 --> 00:09:19,365
Speaker 5:  one answer thing here. You, I typically as a team, we collectively

128
00:09:19,365 --> 00:09:22,885
Speaker 5:  look for a set of signals. I would say in this instance,

129
00:09:23,135 --> 00:09:26,845
Speaker 5:  there were some things that we clearly learned by way of customer feedback.

130
00:09:26,845 --> 00:09:29,365
Speaker 5:  In fact, you know, feedback from folks like you for sure who are looking

131
00:09:29,365 --> 00:09:33,005
Speaker 5:  at our products. And so that to me, there's some front and center things

132
00:09:33,005 --> 00:09:36,805
Speaker 5:  that, you know, we just had to make sure we were, we were delivering on emulator

133
00:09:36,805 --> 00:09:40,165
Speaker 5:  performance was one, in such example, it was, you know, kind of, sort of

134
00:09:40,325 --> 00:09:44,165
Speaker 5:  apparent to us what the, the benchmark industry competition, et cetera. So

135
00:09:44,165 --> 00:09:47,485
Speaker 5:  we had some clear benchmarks that we had to go hit that were kind of markers

136
00:09:47,485 --> 00:09:51,405
Speaker 5:  that we set for ourselves. The second part of it I think was we had some

137
00:09:51,405 --> 00:09:54,565
Speaker 5:  expectations of, you know, when we take another iteration doing this, we

138
00:09:54,565 --> 00:09:58,445
Speaker 5:  do have to be kind of meaningful and world class in this context. And so

139
00:09:58,675 --> 00:10:01,845
Speaker 5:  that was kind of a moving target for us and we had to go as you know, it's

140
00:10:01,845 --> 00:10:04,845
Speaker 5:  a function of time obviously, and time to market and so on. So, so some of

141
00:10:04,845 --> 00:10:08,325
Speaker 5:  those we just decided we're gonna take a quantum leap kind of in that sense.

142
00:10:08,345 --> 00:10:11,685
Speaker 5:  And then you will have to kind of wait and watch and decide and see if, if

143
00:10:11,685 --> 00:10:15,445
Speaker 5:  that's a meaningful exercise or not. The other big component is we do, you

144
00:10:15,445 --> 00:10:18,285
Speaker 5:  know, get a chance to talk to customers. We, we do that for consumers for

145
00:10:18,285 --> 00:10:21,645
Speaker 5:  sure. We talk to commercial customers, we get a chance to do, you know, iterations

146
00:10:21,745 --> 00:10:25,485
Speaker 5:  and you know, trials and deployments with them. And so we learn through actual

147
00:10:25,925 --> 00:10:29,645
Speaker 5:  dialogue and data and telemetry from our commercial customers to see if we've

148
00:10:29,645 --> 00:10:32,925
Speaker 5:  addressed the core issues. Like, you know, a great example of that is, you

149
00:10:32,925 --> 00:10:36,245
Speaker 5:  know, on the emulator itself, as much as we did tremendous work on the emulator

150
00:10:36,245 --> 00:10:39,805
Speaker 5:  on this iteration, there are some things that you can't emulate. And so,

151
00:10:39,945 --> 00:10:43,525
Speaker 5:  you know, kernel com mode components and windows and you know, malware type

152
00:10:43,525 --> 00:10:47,485
Speaker 5:  stuff that, and VPN applications that commercial customers do rely on,

153
00:10:47,665 --> 00:10:50,805
Speaker 5:  you have to get them native. So some of those things we do, we took time

154
00:10:50,825 --> 00:10:54,565
Speaker 5:  to go get the data, get customer feedback, and you know, do the trials, do

155
00:10:54,565 --> 00:10:57,885
Speaker 5:  some deployments, get their feedback, and then, then I think you look at

156
00:10:57,885 --> 00:11:01,205
Speaker 5:  the, the culmination of 'em all and then see if you've done enough of the

157
00:11:01,365 --> 00:11:04,365
Speaker 5:  critical mass to decide that you've, you know, kind of met that expectation.

158
00:11:04,745 --> 00:11:08,685
Speaker 5:  The one thing that is kind of a gift for us in this context is the AI

159
00:11:08,685 --> 00:11:12,645
Speaker 5:  stuff that happened. I think the, the one real inflection point for us,

160
00:11:12,645 --> 00:11:16,565
Speaker 5:  David, was knowing that we could use this opportunity in a more general

161
00:11:16,655 --> 00:11:20,085
Speaker 5:  sense. Certainly ARM is a big piece of it for us and, and the first wave

162
00:11:20,085 --> 00:11:23,845
Speaker 5:  of copilot plus PCs are on Qualcomm series X

163
00:11:23,845 --> 00:11:27,485
Speaker 5:  components. But really using the AI point in time as an inflection

164
00:11:27,665 --> 00:11:31,405
Speaker 5:  for us to kind of go after a, a bigger vector for

165
00:11:31,475 --> 00:11:35,165
Speaker 5:  what, you know, value we could serve at the end of the day was another thing

166
00:11:35,165 --> 00:11:38,965
Speaker 5:  where, you know, timing figured into our decision making for both value and

167
00:11:38,965 --> 00:11:40,365
Speaker 5:  and timing for the exercise.

168
00:11:40,665 --> 00:11:42,965
Speaker 3:  So it makes sense. That's actually a good segue into the next thing I wanted

169
00:11:42,965 --> 00:11:46,245
Speaker 3:  to talk about, which is that it feels like to some extent in 2012,

170
00:11:46,785 --> 00:11:50,725
Speaker 3:  the Surface's job in particular was to sort of remind people that

171
00:11:51,465 --> 00:11:55,445
Speaker 3:  PCs matter. Like we were in the, the era when, you know, smartphones were

172
00:11:55,445 --> 00:11:58,685
Speaker 3:  gonna kill everything, laptops are dead, who needs any of this stuff anymore?

173
00:11:58,715 --> 00:12:02,285
Speaker 3:  Like the, that's the old way. And that was, I think obviously never the case,

174
00:12:02,465 --> 00:12:06,405
Speaker 3:  but that was, I think part of what Surface existed to do was

175
00:12:06,805 --> 00:12:10,605
Speaker 3:  continue to, you know, push that along. It feels like the

176
00:12:10,625 --> 00:12:14,245
Speaker 3:  job now seems to have shifted a bit where you're, you're trying to, and I

177
00:12:14,245 --> 00:12:17,205
Speaker 3:  even noticed this sort of as you're on stage talking about this stuff, like

178
00:12:17,205 --> 00:12:21,165
Speaker 3:  you have to make the case for these devices in a new way. And it's not just

179
00:12:21,415 --> 00:12:25,405
Speaker 3:  these things still matter because typing is annoying on your phone. You have

180
00:12:25,405 --> 00:12:29,085
Speaker 3:  to like describe a different way to think about my

181
00:12:29,325 --> 00:12:32,565
Speaker 3:  computer than it has. So I'm curious, give me sort of the big

182
00:12:32,595 --> 00:12:36,445
Speaker 3:  philosophical vision of like the job to be done of a PC

183
00:12:36,945 --> 00:12:40,005
Speaker 3:  in this era that we're just starting right now. Has it changed at all?

184
00:12:40,385 --> 00:12:44,165
Speaker 5:  It has and I think to be tr honest with you on that exercise of

185
00:12:44,265 --> 00:12:47,885
Speaker 5:  my own learning and journey, I would say the last four years I've been

186
00:12:47,885 --> 00:12:50,485
Speaker 5:  particularly instrumental. 'cause to your point, I think people go through

187
00:12:50,485 --> 00:12:52,765
Speaker 5:  that thought process periodically. They're like, you know, what is the job

188
00:12:52,765 --> 00:12:56,445
Speaker 5:  of the pc? And one thing we learned through the pandemic and coming outta

189
00:12:56,445 --> 00:13:00,245
Speaker 5:  the pandemic on the other side was how Vital PCs were yeah.

190
00:13:00,305 --> 00:13:03,725
Speaker 5:  For people and just how fundamental Windows is in that context of serving

191
00:13:03,785 --> 00:13:07,285
Speaker 5:  the breadth of education customers through commercial

192
00:13:07,605 --> 00:13:10,845
Speaker 5:  customers, through frontline workers, through, you know, consumers at large.

193
00:13:10,865 --> 00:13:14,485
Speaker 5:  And so I think it, it reinforced for people in a way that obviously

194
00:13:14,745 --> 00:13:18,565
Speaker 5:  it took a pandemic, but I think in a way it also forced us

195
00:13:18,585 --> 00:13:21,765
Speaker 5:  to kind of go through the introspection of how are we making sure we are

196
00:13:21,765 --> 00:13:25,685
Speaker 5:  thinking deeply about the promise of the platform, the ecosystem that

197
00:13:25,765 --> 00:13:29,045
Speaker 5:  Windows is on the role for Surface in that context

198
00:13:29,605 --> 00:13:33,445
Speaker 5:  as we go forward. I think for me there's two constructs. One, to your point

199
00:13:33,445 --> 00:13:36,885
Speaker 5:  earlier, I think the deep rooted value proposition of Windows, I think just,

200
00:13:36,905 --> 00:13:40,765
Speaker 5:  it is a, it is a great reminder. It is kind of a humbling thing and an inspiring

201
00:13:40,765 --> 00:13:44,725
Speaker 5:  experience at the same time for how important and foundational and, and key

202
00:13:44,725 --> 00:13:48,445
Speaker 5:  windows is across all of kind of work and play for people in, in life. As

203
00:13:48,445 --> 00:13:51,965
Speaker 5:  we think about the world going forward, I think for me, my sense of

204
00:13:51,965 --> 00:13:55,805
Speaker 5:  orientation in this space is this AI journey that the world is going through

205
00:13:55,825 --> 00:13:59,765
Speaker 5:  our industry, at least for sure is, is a tremendous gift for us.

206
00:14:00,105 --> 00:14:03,965
Speaker 5:  And you know, I think it gives us a sense of agency for what is

207
00:14:04,205 --> 00:14:07,685
Speaker 5:  possible on a PC and to kinda reimagine what was possible from, you know,

208
00:14:07,685 --> 00:14:11,165
Speaker 5:  10 years ago, you know, 2012 for sure. We were not thinking about this

209
00:14:11,665 --> 00:14:15,565
Speaker 5:  in a way that I think is somewhat of a title, you know,

210
00:14:15,565 --> 00:14:19,365
Speaker 5:  shift for us. To me, what I love about this is especially

211
00:14:19,435 --> 00:14:23,085
Speaker 5:  with, with the ability to build an entire system stack, you know, kind of

212
00:14:23,085 --> 00:14:26,525
Speaker 5:  be thoughtful. And this is also in part why this project took, you know,

213
00:14:26,525 --> 00:14:29,725
Speaker 5:  kinda longer perhaps than others would've expected, is it needed us to kind

214
00:14:29,725 --> 00:14:33,285
Speaker 5:  of go through the deep thinking on how do we deliver this proposition in

215
00:14:33,285 --> 00:14:36,405
Speaker 5:  a way that is somewhat durable. And I think we're the infancy of this journey,

216
00:14:36,405 --> 00:14:39,485
Speaker 5:  David. I think there's gonna be, you know, iteration and refinement and learning

217
00:14:39,785 --> 00:14:43,525
Speaker 5:  and evolution in that sense. And so, so it required us to go think deeply

218
00:14:43,525 --> 00:14:47,325
Speaker 5:  about how do we go integrate AI into our products across the board. It took

219
00:14:47,325 --> 00:14:50,885
Speaker 5:  us down the path of, of making sure we were building the hardware platform

220
00:14:51,045 --> 00:14:54,485
Speaker 5:  and capability and that's a statement across the entire Windows ecosystem.

221
00:14:54,505 --> 00:14:58,205
Speaker 5:  We have a whole modern generation of SOCs that I'm actually very

222
00:14:58,205 --> 00:15:00,925
Speaker 5:  excited about that are gonna start showing up for Windows. It's gonna be

223
00:15:00,925 --> 00:15:04,605
Speaker 5:  great across our partners because I think that modern platform is what then

224
00:15:04,625 --> 00:15:08,085
Speaker 5:  we can build on top of both from an operating system standpoint and as

225
00:15:08,525 --> 00:15:10,045
Speaker 5:  a device maker in Surface.

226
00:15:10,545 --> 00:15:13,605
Speaker 3:  But I think, I mean, just to that point actually, one of the things I think

227
00:15:13,625 --> 00:15:16,965
Speaker 3:  you could have done, and you should tell me if you did do this and 'cause

228
00:15:16,965 --> 00:15:20,925
Speaker 3:  I think it's very interesting is say, you know, Microsoft's kind of

229
00:15:20,925 --> 00:15:24,605
Speaker 3:  lost in, in mobile the AI thing is happening, this is our moment.

230
00:15:24,695 --> 00:15:28,565
Speaker 3:  We're gonna relaunch the Surface Duo as an AI device and take over the

231
00:15:28,725 --> 00:15:32,565
Speaker 3:  universe. That is one like perfectly rational version of that thing.

232
00:15:32,565 --> 00:15:36,365
Speaker 3:  But you, you went another way and you went, you went all in on on PCs. Like

233
00:15:36,515 --> 00:15:40,445
Speaker 3:  even the fact that the Surface pro itself is the same size as the last one,

234
00:15:40,705 --> 00:15:44,525
Speaker 3:  but is in such a meaningful way, like a fundamentally different device, I

235
00:15:44,525 --> 00:15:48,005
Speaker 3:  think is so interesting. And it's like there, there's something about what

236
00:15:48,005 --> 00:15:51,325
Speaker 3:  happens when you put AI inside of a PC that I feel like

237
00:15:52,045 --> 00:15:55,245
Speaker 3:  consumers just have not seen yet. This stuff is so new. Correct. But you've,

238
00:15:55,245 --> 00:15:58,765
Speaker 3:  you've had to like think ahead about what that will look like and how we'll

239
00:15:58,765 --> 00:16:01,405
Speaker 3:  use it. And I'm sure you've just used these devices longer than the rest

240
00:16:01,405 --> 00:16:05,125
Speaker 3:  of us. So like what, what is it about the size and shape

241
00:16:05,205 --> 00:16:08,805
Speaker 3:  and form factor of a PC that you can add AI to and it changes it

242
00:16:08,805 --> 00:16:09,765
Speaker 3:  meaningfully? That's

243
00:16:09,765 --> 00:16:12,365
Speaker 5:  A really good question. As somebody who worked on Duo, you know, we definitely

244
00:16:12,365 --> 00:16:15,125
Speaker 5:  did think deeply about that. You know, in terms of vectors and options.

245
00:16:15,445 --> 00:16:18,525
Speaker 3:  I love Duo by the way. I have a duo right over there and I I love it to pieces,

246
00:16:19,175 --> 00:16:21,125
Speaker 5:  Warms my heart, love hearing that

247
00:16:22,845 --> 00:16:26,685
Speaker 5:  I, you know, my sense on that topic first, I think AI is gonna

248
00:16:26,685 --> 00:16:30,325
Speaker 5:  show up in, in a variety of different forms for us. You know, you know, Microsoft

249
00:16:30,325 --> 00:16:33,685
Speaker 5:  sort of our, we, we are the copilot company and we're going to, you know,

250
00:16:33,685 --> 00:16:36,805
Speaker 5:  deliver copilot as a set of services and experiences

251
00:16:37,465 --> 00:16:40,525
Speaker 5:  on a variety of different devices, a variety of different form factors, you

252
00:16:40,525 --> 00:16:43,245
Speaker 5:  know, different platforms. So you, you're seeing that from us. We talked

253
00:16:43,245 --> 00:16:46,965
Speaker 5:  about it on Monday as well. So that I think is a, is a certainly a thrust

254
00:16:46,985 --> 00:16:50,445
Speaker 5:  for the company, you know, across the board I think it is, we're seeing tremendous

255
00:16:50,645 --> 00:16:54,005
Speaker 5:  momentum with things like the M 365 copilot for example, in terms of

256
00:16:54,115 --> 00:16:57,605
Speaker 5:  embedding agent capabilities, copilot capabilities and productivity suite

257
00:16:57,605 --> 00:17:01,445
Speaker 5:  and applications and services. In terms of the device form factor, the thing

258
00:17:01,445 --> 00:17:05,405
Speaker 5:  that I, I'm particularly excited about with the PC orientation around it,

259
00:17:06,065 --> 00:17:09,765
Speaker 5:  by the way, one thing we should to mention mobile, you the one reason why,

260
00:17:10,145 --> 00:17:13,725
Speaker 5:  you know, the value of the neural engine and efficiency and just matrix math

261
00:17:13,725 --> 00:17:17,445
Speaker 5:  computation and performance per watt and all this stuff. We do inherit a

262
00:17:17,445 --> 00:17:20,925
Speaker 5:  lot of those capabilities of mobile platforms into these next generation

263
00:17:20,925 --> 00:17:24,885
Speaker 5:  mobile SSCs. Obviously we have the sensibilities because anyway, so I

264
00:17:24,885 --> 00:17:27,805
Speaker 5:  think that, I think you know this of course, and you're seeing this, it's

265
00:17:27,805 --> 00:17:31,285
Speaker 5:  happening in industry, you know, broadly, and we are a pole position when

266
00:17:31,285 --> 00:17:34,725
Speaker 5:  it comes to taking advantage of those ips, those capabilities and then bringing,

267
00:17:34,825 --> 00:17:38,525
Speaker 5:  you know, the largest possible neural engines at scale in, into Windows

268
00:17:38,705 --> 00:17:42,645
Speaker 5:  on, on the, on the, on the devices themselves. The thing

269
00:17:42,865 --> 00:17:46,805
Speaker 5:  for us when it comes to large screen form factors, you know, pro devices,

270
00:17:47,275 --> 00:17:51,005
Speaker 5:  laptops, and by the way, I think Surface is one great embodiment of it, but

271
00:17:51,035 --> 00:17:54,405
Speaker 5:  what was kind of magical for us with this copilot PC moment is it was not

272
00:17:54,475 --> 00:17:58,005
Speaker 5:  just Surface. We had the, our, you know, lean in from our entire ecosystem

273
00:17:58,005 --> 00:18:01,765
Speaker 5:  partners and the signals we got from, from all of our OEM partners

274
00:18:01,765 --> 00:18:05,325
Speaker 5:  here was super strong. So it kind of gave us conviction on thinking about

275
00:18:05,325 --> 00:18:08,605
Speaker 5:  this, you know, broad and holistic and making sure we're, we think of it

276
00:18:08,605 --> 00:18:12,285
Speaker 5:  as a transition for a class of devices versus, you know, one particular form

277
00:18:12,285 --> 00:18:16,045
Speaker 5:  factor. The couple of things that make AI kind of meaningful for me in

278
00:18:16,465 --> 00:18:19,965
Speaker 5:  PCs, one of them is by definition Windows

279
00:18:20,265 --> 00:18:24,165
Speaker 5:  is a multi-platform, multi app operating system. And one of the things that

280
00:18:24,165 --> 00:18:27,885
Speaker 5:  I think that makes these AI experiences powerful is the fact that these

281
00:18:27,885 --> 00:18:31,605
Speaker 5:  models can reason across things happening, you know, on your, across your

282
00:18:31,605 --> 00:18:35,485
Speaker 5:  screen, across multiple applications, across workflows. And I think in

283
00:18:35,485 --> 00:18:39,365
Speaker 5:  a world where a lot of what we do is task flow across applications and

284
00:18:39,365 --> 00:18:43,245
Speaker 5:  so on, having the ability for having AI help you both in your own

285
00:18:43,345 --> 00:18:47,205
Speaker 5:  app but also be able to help with workflows across apps is

286
00:18:47,275 --> 00:18:50,845
Speaker 5:  huge I think. And totally for us with the idea of recall the

287
00:18:50,865 --> 00:18:54,805
Speaker 5:  notion of search and search becoming semantic. I think that, you

288
00:18:54,805 --> 00:18:58,045
Speaker 5:  know, today most people don't interact with their devices in a natural language

289
00:18:58,045 --> 00:19:01,325
Speaker 5:  sense. Like I think intuitively we are able to do or would like to go do.

290
00:19:01,345 --> 00:19:05,285
Speaker 5:  And so for, but for search to be semantic, you know, you do need to

291
00:19:05,285 --> 00:19:08,365
Speaker 5:  flatten what that information architecture and data schema looks like. 'cause

292
00:19:08,365 --> 00:19:11,605
Speaker 5:  you know, if you, again, you don't wanna be app specific, you want to search

293
00:19:11,605 --> 00:19:14,245
Speaker 5:  the way you know your memories would work for instance and how you recall

294
00:19:14,245 --> 00:19:18,165
Speaker 5:  things. And so, so that way for us pc, that was one powerful thing, the

295
00:19:18,165 --> 00:19:22,085
Speaker 5:  ability for us to be able to bring AI across applications. The second big

296
00:19:22,085 --> 00:19:25,765
Speaker 5:  thing is multimodality on a pc you are looking at content,

297
00:19:25,825 --> 00:19:28,965
Speaker 5:  you're typing on a screen, you have the opportunity for voice interactions,

298
00:19:28,985 --> 00:19:32,805
Speaker 5:  you have touch, you have ink. And so these AI models are

299
00:19:32,805 --> 00:19:36,325
Speaker 5:  increasingly going to become multimodal for us. And so the fact that we are

300
00:19:36,405 --> 00:19:40,325
Speaker 5:  a, you know, multimodal operating system, we are multitasking operating system,

301
00:19:40,465 --> 00:19:44,445
Speaker 5:  it gives us a fertile ground to go, you know, bring these capabilities.

302
00:19:44,465 --> 00:19:47,925
Speaker 5:  And quite frankly, I think my sentiment is we have a point of view on where

303
00:19:47,925 --> 00:19:51,725
Speaker 5:  that value starts. The fact is people are going to do things with them that

304
00:19:51,725 --> 00:19:53,965
Speaker 5:  we start with as a point of view and then they are gonna bring their own

305
00:19:53,965 --> 00:19:56,685
Speaker 5:  ideas and I think that's gonna be powerful. The last thing I'll say, David,

306
00:19:56,745 --> 00:20:00,685
Speaker 5:  is you know, the power of the Windows ecosystem is our app catalog and

307
00:20:00,685 --> 00:20:04,485
Speaker 5:  what developers do on top of it. And the beautiful thing with AI now

308
00:20:04,625 --> 00:20:08,565
Speaker 5:  is we are finding a strong pull from traditional, you know, windows

309
00:20:08,565 --> 00:20:11,645
Speaker 5:  applications as well as a set of folks who are traditionally sort of web

310
00:20:11,645 --> 00:20:14,605
Speaker 5:  apps if you will, and build websites and stuff who are very interested in

311
00:20:14,605 --> 00:20:18,405
Speaker 5:  knowing what they can do with the AI capabilities local on

312
00:20:18,405 --> 00:20:22,285
Speaker 5:  device. And so the pull from them of reimagining what apps can

313
00:20:22,285 --> 00:20:26,205
Speaker 5:  be and that's full spectrum quite frankly from I wanna change the UI 'cause

314
00:20:26,205 --> 00:20:29,565
Speaker 5:  I don't need, you know, as many radial buttons, dials and so on. 'cause the

315
00:20:29,565 --> 00:20:32,885
Speaker 5:  agents can start understanding what's happening all the way through. I want

316
00:20:32,885 --> 00:20:36,565
Speaker 5:  to do net new things where I need local models and I want those local models

317
00:20:36,625 --> 00:20:40,085
Speaker 5:  to have a set of attributes that we can, you know, kind of from Windows platform

318
00:20:40,085 --> 00:20:43,565
Speaker 5:  standpoint, build platform capabilities to serve them. That's another strong

319
00:20:43,565 --> 00:20:46,285
Speaker 5:  signal, which is why I think, you know, windows devices are a great place

320
00:20:46,445 --> 00:20:50,405
Speaker 5:  'cause we have a rich catalog that exists at scale today and they have

321
00:20:50,645 --> 00:20:52,885
Speaker 5:  a very broad Surface area for taking advantage of ai.

322
00:20:53,195 --> 00:20:56,725
Speaker 3:  Yeah, you just brought up my favorite user experience

323
00:20:57,015 --> 00:21:00,085
Speaker 3:  thing to think about right now and I can't stop thinking about it and I'm

324
00:21:00,085 --> 00:21:03,365
Speaker 3:  curious how you're thinking about it, which is this sort of UI of AI also

325
00:21:03,365 --> 00:21:06,725
Speaker 3:  feels very uncertain. 'cause a lot of what you just described is what I would

326
00:21:06,725 --> 00:21:10,485
Speaker 3:  call like infrastructural ai, it's sort of underlying technology

327
00:21:10,625 --> 00:21:14,045
Speaker 3:  in service of something that shouldn't really feel like AI as you do it,

328
00:21:14,045 --> 00:21:17,485
Speaker 3:  right? It just makes it faster or smarter or whatever else. When we talk

329
00:21:17,485 --> 00:21:20,765
Speaker 3:  about AI a lot, we talk about chatbots, right? Like that is, that is I think

330
00:21:20,785 --> 00:21:24,645
Speaker 3:  the, the sort of accidental synonym of AI in a way that I really hate and

331
00:21:24,645 --> 00:21:28,485
Speaker 3:  hope we get past. But I am curious, I mean I think ai it sounds

332
00:21:28,485 --> 00:21:31,245
Speaker 3:  like for you sort of runs that whole spectrum, but as you're thinking about

333
00:21:31,245 --> 00:21:35,085
Speaker 3:  like what this stuff should look like and where people should see

334
00:21:35,345 --> 00:21:38,525
Speaker 3:  AI and sort of how loudly it should scream AI at them when they see it.

335
00:21:39,225 --> 00:21:40,725
Speaker 3:  How are you thinking about that right now?

336
00:21:41,225 --> 00:21:44,725
Speaker 5:  You know that as a company, David, we are, there's a

337
00:21:45,195 --> 00:21:48,725
Speaker 5:  variety of teams who are looking broadly and deeply at that topic.

338
00:21:48,915 --> 00:21:49,205
Speaker 5:  Yeah.

339
00:21:49,325 --> 00:21:51,925
Speaker 3:  'cause nobody knows anything. It's so fun. It's all so new.

340
00:21:52,365 --> 00:21:56,005
Speaker 5:  I think honestly that's kind of the beauty of it right now. It's a place

341
00:21:56,005 --> 00:21:59,525
Speaker 5:  for innovation. We are early in the life cycle, like you said. I think my

342
00:21:59,525 --> 00:22:03,485
Speaker 5:  sense is people are looking for a paradigm and for a period of time at least,

343
00:22:03,565 --> 00:22:06,565
Speaker 5:  I think there's gonna be iteration evolution, there's gonna be different

344
00:22:06,565 --> 00:22:09,885
Speaker 5:  people with different points of view. It, the value's gonna Surface itself

345
00:22:09,885 --> 00:22:13,165
Speaker 5:  in different ways. And then I think perhaps there'll be some patterns that

346
00:22:13,165 --> 00:22:15,485
Speaker 5:  are more stickier in a certain set of use cases than others.

347
00:22:15,905 --> 00:22:19,485
Speaker 3:  Can you get away with that on Windows though? Like Windows is not,

348
00:22:19,805 --> 00:22:23,165
Speaker 3:  I would say famously a place where you can do a lot of

349
00:22:23,165 --> 00:22:26,525
Speaker 3:  experimentation without immediately infuriating millions of people around

350
00:22:26,525 --> 00:22:30,325
Speaker 3:  the world. Can you play like that in something as big and important

351
00:22:30,585 --> 00:22:31,045
Speaker 3:  as Windows?

352
00:22:31,675 --> 00:22:34,325
Speaker 5:  Yeah, let me actually, let me try to complete response for you in the previous

353
00:22:34,325 --> 00:22:36,725
Speaker 5:  thing and I'll come back to your iteration question. Okay, the question,

354
00:22:36,735 --> 00:22:39,765
Speaker 5:  where does it Surface itself? You know, we shared a little bit, we shared

355
00:22:39,845 --> 00:22:43,725
Speaker 5:  a glimpse of this at the bill conference. You know, I, one of our big

356
00:22:43,925 --> 00:22:47,685
Speaker 5:  learnings, at least in the canvas of windows, is using AI for

357
00:22:47,685 --> 00:22:51,645
Speaker 5:  serving kind of customers where they're at in their workflows. And so we

358
00:22:51,645 --> 00:22:55,165
Speaker 5:  have a lot of very highly used surfaces, very high traffic

359
00:22:55,165 --> 00:22:58,285
Speaker 5:  surfaces and windows right now. And one of the things we're thinking about

360
00:22:58,465 --> 00:23:02,365
Speaker 5:  is how do we have these agentic experiences just help people get to their

361
00:23:02,425 --> 00:23:06,205
Speaker 5:  intent faster, easier, quicker. And so that's one

362
00:23:06,395 --> 00:23:10,045
Speaker 5:  sort of thought process where I think in, in terms of UI evolution, you'll

363
00:23:10,045 --> 00:23:14,005
Speaker 5:  see the UI evolve itself to a place where you'll see copilot showing up in

364
00:23:14,005 --> 00:23:17,725
Speaker 5:  more diffuse but infuse manner across the operating system. It's not

365
00:23:17,815 --> 00:23:21,205
Speaker 5:  gonna be screaming at you, but I think it's the subtle ways of being able

366
00:23:21,205 --> 00:23:24,165
Speaker 5:  to do things that you perhaps do today, but it'll just get you through 'em

367
00:23:24,165 --> 00:23:27,925
Speaker 5:  faster and more efficient, kinda more intentful way. There's another big

368
00:23:27,925 --> 00:23:31,285
Speaker 5:  thought process, which is around the idea of recall that we just introduced

369
00:23:32,085 --> 00:23:35,645
Speaker 5:  features and preview the notion that you can bring net new capabilities,

370
00:23:35,765 --> 00:23:39,045
Speaker 5:  I think is gonna create new shell surfaces is gonna create new experiences

371
00:23:39,045 --> 00:23:42,205
Speaker 5:  and they'll become a place where we'll refine and iterate and add new value

372
00:23:42,425 --> 00:23:46,245
Speaker 5:  as well. Once you have a semantic index to your point, that's sort of a

373
00:23:46,485 --> 00:23:49,685
Speaker 5:  structural notion that is gonna Surface itself in, in a variety of different

374
00:23:49,685 --> 00:23:52,085
Speaker 5:  ways. And so I think that, you know, that's a, that's another way to think

375
00:23:52,085 --> 00:23:54,805
Speaker 5:  about it. And of course then there's the app experiences and how do those

376
00:23:54,805 --> 00:23:58,485
Speaker 5:  app experiences in themselves take advantage of copilot capabilities. We

377
00:23:58,485 --> 00:24:01,725
Speaker 5:  introduced the, the new copilot, you know, thinking yes on Monday as well.

378
00:24:02,265 --> 00:24:06,005
Speaker 5:  And so, and then I think you'll see a, we think of a hybrid ai,

379
00:24:06,005 --> 00:24:09,485
Speaker 5:  there's gonna be a pattern I think where you'll see these large models in

380
00:24:09,485 --> 00:24:12,885
Speaker 5:  the cloud working with models on the edge, the model on the edge will bring

381
00:24:12,885 --> 00:24:16,565
Speaker 5:  context and understanding and these large models will do reasoning, you know,

382
00:24:16,705 --> 00:24:20,205
Speaker 5:  at a scale that's not possible. And I think that concert is gonna open up

383
00:24:20,205 --> 00:24:23,725
Speaker 5:  some new experiences about the OS and app layer anyway. So I think that's

384
00:24:23,725 --> 00:24:26,685
Speaker 5:  kinda our three vectors of, of thought process right now in terms of where,

385
00:24:26,945 --> 00:24:30,285
Speaker 5:  you know, ui you know, affordances and constructs will, will take themselves

386
00:24:30,785 --> 00:24:33,565
Speaker 5:  and then we'll see, you know, a year from now. I'm sure if we talk you, you'll

387
00:24:33,565 --> 00:24:37,405
Speaker 5:  see you can be smarter across the board. I think the, the point on these

388
00:24:37,415 --> 00:24:41,325
Speaker 5:  interfaces can be minimalist over time because of the reasoning capabilities

389
00:24:41,385 --> 00:24:44,205
Speaker 5:  is certainly a, a deep call. I know you've, you've talked about it in a couple

390
00:24:44,205 --> 00:24:47,725
Speaker 5:  of different places. I think that's kind of on on our minds. Your

391
00:24:47,725 --> 00:24:51,165
Speaker 5:  experimentation iteration point is a great one. And I think that is a thing.

392
00:24:51,165 --> 00:24:54,445
Speaker 5:  We are on a learning journey ourselves, quite frankly. And how do we go do

393
00:24:54,445 --> 00:24:57,525
Speaker 5:  that? We'll continue to use the Windows Insider program. It's been powerful

394
00:24:57,525 --> 00:25:01,485
Speaker 5:  for us to learn in kinda what works and what doesn't. What I love with the

395
00:25:01,485 --> 00:25:05,085
Speaker 5:  insider community is we're able to do a bunch of different experiments. We're

396
00:25:05,085 --> 00:25:08,965
Speaker 5:  able to do them asynchronously, you know, and get individual signals at at,

397
00:25:08,965 --> 00:25:12,725
Speaker 5:  at the level that matters for individual features in themselves. But we also

398
00:25:12,725 --> 00:25:16,245
Speaker 5:  have a variety of other learning tools and experimentation methods. We are

399
00:25:16,245 --> 00:25:19,725
Speaker 5:  able to talk to customers. We certainly, you know, get the chance to go experiment

400
00:25:19,725 --> 00:25:23,365
Speaker 5:  with commercial customers. And then I think from a window standpoint,

401
00:25:23,705 --> 00:25:27,285
Speaker 5:  you know, we get to learn at the rate of the entire company. And so

402
00:25:27,705 --> 00:25:31,445
Speaker 5:  for me, the fact when it comes to the, the idea of responsible ai, for example,

403
00:25:31,725 --> 00:25:34,725
Speaker 5:  Microsoft is leading responsible AI in the cloud. We are learning a bunch

404
00:25:34,725 --> 00:25:37,485
Speaker 5:  there. And certainly we take those lessons and we apply them to customers

405
00:25:37,665 --> 00:25:40,365
Speaker 5:  in Windows context. 'cause at end the day they're, you know, the same person,

406
00:25:40,365 --> 00:25:44,045
Speaker 5:  they're the same corporation, same set of customers. And so, so I find in

407
00:25:44,045 --> 00:25:47,845
Speaker 5:  fact in this AI world, I have more learning tools because the way

408
00:25:48,385 --> 00:25:51,085
Speaker 5:  AI capabilities and services and even, you know, social experiments and how

409
00:25:51,085 --> 00:25:54,405
Speaker 5:  people are experiencing them is actually pretty broad brushed across the

410
00:25:54,565 --> 00:25:57,725
Speaker 5:  company than than features and windows in the past by themselves.

411
00:25:58,115 --> 00:26:01,845
Speaker 3:  Yeah, I've always enjoyed the, the sort of pros and cons of being Microsoft

412
00:26:01,865 --> 00:26:05,805
Speaker 3:  in this ecosystem. On the one hand you have this incredibly long

413
00:26:05,805 --> 00:26:08,685
Speaker 3:  history and a lot of people who are very accustomed to certain workflows

414
00:26:08,865 --> 00:26:12,485
Speaker 3:  and the sort of cost of change is very high, but on the

415
00:26:12,505 --> 00:26:16,125
Speaker 3:  upside you can put that kind of stuff in front of huge numbers of

416
00:26:16,125 --> 00:26:19,805
Speaker 3:  different kinds of people pretty quickly. Yeah. And I just, that that tension

417
00:26:20,005 --> 00:26:23,245
Speaker 3:  I feel like I see everywhere across Microsoft and it is always really interesting

418
00:26:23,245 --> 00:26:23,565
Speaker 3:  to watch.

419
00:26:23,985 --> 00:26:27,445
Speaker 5:  It is a great balance. Yeah. I don't know if I have a recipe for sort of

420
00:26:27,445 --> 00:26:30,125
Speaker 5:  an an answer that as a result of this to, to success. Like you said, it's

421
00:26:30,125 --> 00:26:33,245
Speaker 5:  a, it's a tension and we have to kinda work, you know, work the balance there

422
00:26:33,245 --> 00:26:33,565
Speaker 5:  for sure.

423
00:26:33,755 --> 00:26:36,765
Speaker 3:  Totally. So I know I have to let you go here in a minute. So one last question.

424
00:26:37,065 --> 00:26:40,965
Speaker 3:  We started 12 years ago. Fast forward 12 more years for me. Is

425
00:26:40,985 --> 00:26:44,845
Speaker 3:  the bet now the same one you feel like you were making

426
00:26:44,845 --> 00:26:48,605
Speaker 3:  with Surface 12 years ago? Or is it, has it shifted?

427
00:26:48,635 --> 00:26:52,445
Speaker 3:  Like is this a sort of inflection point in the life of what you think these

428
00:26:52,445 --> 00:26:55,245
Speaker 3:  devices are and what you're pushing towards with them?

429
00:26:55,945 --> 00:26:59,405
Speaker 5:  Our, okay, it's a great question. Let me, I, let me try to do this in two.

430
00:26:59,545 --> 00:27:03,365
Speaker 5:  The, the philosophy and our strategy and mission

431
00:27:03,365 --> 00:27:07,045
Speaker 5:  with Surface has been around, you know, driving, leading

432
00:27:07,045 --> 00:27:10,565
Speaker 5:  innovation in the Windows ecosystem in a way that we think

433
00:27:11,065 --> 00:27:14,925
Speaker 5:  allows Windows itself to move the needle for what is possible, but to

434
00:27:14,925 --> 00:27:18,645
Speaker 5:  do it in a way that is actually responsible for

435
00:27:18,745 --> 00:27:22,725
Speaker 5:  end customers. And as a business within Microsoft. I think that aspect

436
00:27:22,785 --> 00:27:26,725
Speaker 5:  of Surface is going to be instrumental for us to continue to move the

437
00:27:26,725 --> 00:27:30,605
Speaker 5:  needle of what is possible, both in a technology sense, in a product

438
00:27:30,605 --> 00:27:34,205
Speaker 5:  making sense, in a sense of how do we deliver these capabilities to customers

439
00:27:34,205 --> 00:27:36,765
Speaker 5:  and to businesses in a way that, you know, actually is credible for them

440
00:27:36,765 --> 00:27:40,405
Speaker 5:  at the end of the day. I think that aspect of Surface will continue. It is,

441
00:27:40,405 --> 00:27:44,165
Speaker 5:  it has been powerful for us quite frankly. I think the copilot wave copilot

442
00:27:44,165 --> 00:27:48,005
Speaker 5:  plus wave of PCs was only possible with the deep work that happened in Surface

443
00:27:48,115 --> 00:27:50,805
Speaker 5:  over the last, you know, four or five years. And so that will continue to

444
00:27:50,805 --> 00:27:54,285
Speaker 5:  be instrumental for us. And I, and I expect and believe that will continue

445
00:27:54,285 --> 00:27:57,965
Speaker 5:  to be great for us going forward in terms of the devices themselves.

446
00:27:58,465 --> 00:28:01,525
Speaker 5:  You know, time will tell, I think, you know, we've grown our portfolio, we've,

447
00:28:01,525 --> 00:28:04,485
Speaker 5:  we've played, we've added, we've tried, we've learned, I think that that

448
00:28:04,485 --> 00:28:06,965
Speaker 5:  spirit will continue with the team. We will continue to drive innovation.

449
00:28:07,765 --> 00:28:10,645
Speaker 5:  We will learn through those experiments. I'm excited many of them are gonna

450
00:28:10,645 --> 00:28:13,045
Speaker 5:  be successful, but I'm also, you know, clear-eyed. Some of those experiments

451
00:28:13,045 --> 00:28:16,805
Speaker 5:  and learnings may or may not result in, you know, in products in themselves.

452
00:28:17,225 --> 00:28:20,405
Speaker 5:  But I, in either case, I think they serve the, the outcome and the mission

453
00:28:20,465 --> 00:28:23,285
Speaker 5:  for what, what's critical for Surface and quite frankly Microsoft I think

454
00:28:23,285 --> 00:28:23,765
Speaker 5:  at the end of the

455
00:28:23,765 --> 00:28:26,805
Speaker 3:  Day. Fair enough. All right, well I've made you late for a meeting so I'll

456
00:28:26,805 --> 00:28:29,965
Speaker 3:  let you go but someday we're just gonna talk about like hinges and stuff

457
00:28:29,985 --> 00:28:32,725
Speaker 3:  for several hours and I'm very much looking forward to that. It's gonna be

458
00:28:32,725 --> 00:28:32,885
Speaker 3:  better.

459
00:28:33,065 --> 00:28:34,325
Speaker 5:  Sounds lovely. Thank you.

460
00:28:34,995 --> 00:28:38,285
Speaker 3:  Alright, we have to take a break and then we're gonna do a big smart home

461
00:28:38,285 --> 00:28:39,845
Speaker 3:  catch up. 'cause there's a lot to get to.

462
00:31:54,965 --> 00:31:55,185
Speaker 3:  It

463
00:31:55,205 --> 00:31:57,265
Speaker 7:  Has David, it's always a pleasure to be back though.

464
00:31:57,705 --> 00:32:01,505
Speaker 3:  I feel like we haven't had enough time to yell about Matter on this show

465
00:32:01,945 --> 00:32:03,065
Speaker 3:  recently. It feels like it's time.

466
00:32:03,625 --> 00:32:06,945
Speaker 7:  I know. Well I got to yell about Matter with with Neli on the other show

467
00:32:07,165 --> 00:32:08,185
Speaker 7:  so we

468
00:32:08,185 --> 00:32:11,985
Speaker 3:  We don't talk about the other show. How, how dare you. Okay, so

469
00:32:12,065 --> 00:32:15,505
Speaker 3:  I, I have come up with a little game for us and I didn't tell you about it

470
00:32:15,505 --> 00:32:18,385
Speaker 3:  because I'm a very cruel and unhelpful podcast host. I

471
00:32:18,385 --> 00:32:19,905
Speaker 7:  Have no idea what's about to happen.

472
00:32:20,605 --> 00:32:24,465
Speaker 3:  So I have five topics for you. They're all based on

473
00:32:24,465 --> 00:32:28,425
Speaker 3:  stories you've written recently and I'm gonna throw them at you one

474
00:32:28,425 --> 00:32:31,945
Speaker 3:  by one and you're gonna have to tell me whether this thing is a big deal,

475
00:32:32,145 --> 00:32:35,985
Speaker 3:  a medium deal or a small deal. And then we're gonna talk about it. Okay,

476
00:32:36,385 --> 00:32:39,645
Speaker 3:  I have these, but I wanna know what you think about all of these. Does that

477
00:32:39,645 --> 00:32:41,485
Speaker 3:  sound good? We're just gonna dive in. It's gonna be great.

478
00:32:41,705 --> 00:32:42,365
Speaker 7:  Sounds good.

479
00:32:42,785 --> 00:32:46,605
Speaker 3:  The first one, big deal, medium deal, small deal. The

480
00:32:46,695 --> 00:32:50,525
Speaker 3:  Dyson Wash G one Dyson's first mop. People are

481
00:32:50,555 --> 00:32:54,365
Speaker 3:  very excited about this thing. Jen, big deal, medium deal, small deal. What

482
00:32:54,365 --> 00:32:55,405
Speaker 3:  do we think from

483
00:32:55,485 --> 00:32:58,445
Speaker 7:  A smart home perspective? Jeanie? Tiny deal.

484
00:32:59,205 --> 00:33:02,925
Speaker 7:  Okay. Because it's not a smart thing, it's, well

485
00:33:03,145 --> 00:33:06,565
Speaker 7:  it depends on your definition. It's not smart, but it's not internet connected

486
00:33:06,565 --> 00:33:10,405
Speaker 7:  in any way. It is not an iot device from the world of floor

487
00:33:10,405 --> 00:33:13,565
Speaker 7:  washing. However, I would say it's kind of a big deal

488
00:33:14,475 --> 00:33:18,125
Speaker 7:  because you know, it's very expensive. But

489
00:33:18,535 --> 00:33:22,405
Speaker 7:  Dyson love them or hate them. They are innovative. They do

490
00:33:22,405 --> 00:33:26,325
Speaker 7:  come up with some interesting solutions for common problems in

491
00:33:26,325 --> 00:33:30,045
Speaker 7:  our home. And whilst there are lots of great ways to mop your floor, this

492
00:33:30,045 --> 00:33:33,845
Speaker 7:  does actually seem like it has an interesting construct

493
00:33:33,845 --> 00:33:37,645
Speaker 7:  that's going to take a lot of the hard work outta mopping. I mean frankly

494
00:33:37,845 --> 00:33:41,485
Speaker 7:  I, I have never mopped my floors in years because I use robot mops,

495
00:33:42,025 --> 00:33:45,325
Speaker 7:  but that's part of my job. But when I used to have to pull the mop out with

496
00:33:45,325 --> 00:33:46,085
Speaker 7:  the bucket, oh

497
00:33:46,085 --> 00:33:46,605
Speaker 3:  It's the worst.

498
00:33:46,915 --> 00:33:50,205
Speaker 7:  It's the worst. And this does actually seem like a good solution and I have

499
00:33:50,205 --> 00:33:53,645
Speaker 7:  used some of the automated versions of there. So it's a

500
00:33:54,045 --> 00:33:57,805
Speaker 7:  mop that does not have any kind of motor in it or any kind of

501
00:33:57,825 --> 00:34:01,405
Speaker 7:  fan. So it's very different from any of the products that Dyson's brought

502
00:34:01,405 --> 00:34:04,925
Speaker 7:  out prior. You know, it's known for its fans, it's known for its hair dryers,

503
00:34:05,035 --> 00:34:08,885
Speaker 7:  it's known for its vacuum cleaners. This does not suck or blow. Oh, interesting.

504
00:34:10,565 --> 00:34:12,285
Speaker 7:  Although it sucks in a different way.

505
00:34:14,425 --> 00:34:18,205
Speaker 7:  And that's the kind of neat engineering trick here, which I think is, I think

506
00:34:18,205 --> 00:34:22,045
Speaker 7:  is interesting in terms of cleaning your floors. But people love Dyson

507
00:34:22,045 --> 00:34:25,405
Speaker 7:  products and people are prepared to pay a lot of money for them. I do think

508
00:34:25,405 --> 00:34:29,005
Speaker 7:  it's ridiculously over-engineered and ridiculously overpriced. But

509
00:34:29,345 --> 00:34:33,165
Speaker 7:  I'm quite confident that it will work well. So that makes it a big deal I

510
00:34:33,165 --> 00:34:35,245
Speaker 7:  suppose. Okay. What do you think about this?

511
00:34:35,725 --> 00:34:39,525
Speaker 3:  I feel exactly the same way. Every Dyson thing I've ever tried or

512
00:34:39,535 --> 00:34:43,445
Speaker 3:  owned I think is wonderful and preposterous at the same time.

513
00:34:43,725 --> 00:34:47,405
Speaker 3:  Like I bought my wife an air wrap for Christmas a couple of years ago.

514
00:34:47,505 --> 00:34:47,925
Speaker 3:  Oh you

515
00:34:47,925 --> 00:34:48,805
Speaker 7:  Wonderful husband?

516
00:34:49,545 --> 00:34:53,005
Speaker 3:  Oh it is hands down the most successful gift I have ever bought. My wife,

517
00:34:53,105 --> 00:34:56,765
Speaker 3:  she loves it and it's an awesome thing, but it is also like

518
00:34:56,765 --> 00:35:00,045
Speaker 3:  ludicrously expensive and it involves a lot of like, let's be clear, you're

519
00:35:00,045 --> 00:35:03,045
Speaker 3:  not getting any more gifts for several years after this. Like this is, it

520
00:35:03,045 --> 00:35:05,645
Speaker 3:  was like your engagement ring and this like, these are the two big gifts

521
00:35:05,645 --> 00:35:08,885
Speaker 3:  you're ever getting from me. But the stuff they make tends to be great. And

522
00:35:08,885 --> 00:35:12,445
Speaker 3:  I think part of the reason I'm fascinated by the mop thing is I think as

523
00:35:12,445 --> 00:35:16,285
Speaker 3:  someone who has had a robot vacuum running around for a long

524
00:35:16,285 --> 00:35:20,205
Speaker 3:  time, the robot mop thing seems like it ought to

525
00:35:20,205 --> 00:35:23,685
Speaker 3:  be the next thing. But at least from the, the little bit of experience I

526
00:35:23,685 --> 00:35:27,645
Speaker 3:  have with them, they're not nearly as good as the robot vacuums.

527
00:35:27,645 --> 00:35:30,045
Speaker 3:  And you're, you're shaking your head like, like you agree with me

528
00:35:30,045 --> 00:35:33,765
Speaker 7:  On that. I agree. Yes. They're not, they've, they've got better but you have

529
00:35:33,765 --> 00:35:37,565
Speaker 7:  to pay an awful lot for the really good ones. And yeah, it's just nowhere

530
00:35:37,795 --> 00:35:41,325
Speaker 7:  near the same as actually mopping your floor and this thing will

531
00:35:41,885 --> 00:35:45,805
Speaker 7:  actually mop your floor because it uses water. Like the water is

532
00:35:45,805 --> 00:35:49,685
Speaker 7:  constantly flowing onto the mop and to a big mop. Most

533
00:35:49,685 --> 00:35:53,565
Speaker 7:  of the mops on robot mops are small and maybe, you know,

534
00:35:53,565 --> 00:35:57,485
Speaker 7:  have a very small Surface area so you're not really getting a lot of clean

535
00:35:57,585 --> 00:36:01,125
Speaker 7:  for your, for your motion. Whereas this uses like a

536
00:36:01,585 --> 00:36:05,325
Speaker 7:  two large roller mops that constantly spray

537
00:36:05,495 --> 00:36:08,645
Speaker 7:  clean water onto them and then sucks up with

538
00:36:09,155 --> 00:36:13,085
Speaker 7:  agitation the dirt. So it doesn't, like I said, it doesn't have a mo so it's

539
00:36:13,085 --> 00:36:16,845
Speaker 7:  not a vacuum but it uses agitation to kind of get up the dirt. So yeah,

540
00:36:16,905 --> 00:36:19,885
Speaker 7:  it, you know, the pictures they sent and the demo they showed me, I mean

541
00:36:19,885 --> 00:36:22,205
Speaker 7:  they're very excited about this. This was big enough that they even rolled

542
00:36:22,225 --> 00:36:24,685
Speaker 7:  out, you know, sir James Dyson himself to the press.

543
00:36:24,705 --> 00:36:26,645
Speaker 3:  Oh yeah. Which is pretty rare these days. Yeah.

544
00:36:26,865 --> 00:36:30,765
Speaker 7:  So they were very excited by it. But 700 I know up,

545
00:36:32,005 --> 00:36:35,485
Speaker 3:  I just, I'm sort of in the position of like when in the early days of the

546
00:36:35,485 --> 00:36:38,725
Speaker 3:  Roomba it was like, yes, this is a good idea, I hope everybody decides to

547
00:36:38,725 --> 00:36:41,565
Speaker 3:  work on this. And they kind of did. And robot vacuums got to be pretty good.

548
00:36:42,305 --> 00:36:45,805
Speaker 3:  I'm hoping that's where we are with MOPS now because it feels like if I could

549
00:36:45,805 --> 00:36:49,685
Speaker 3:  solve that problem robotically, it would be amazing. Even if

550
00:36:49,685 --> 00:36:52,765
Speaker 3:  I bought this Dyson one, I would use it like twice and then be like, mopping

551
00:36:52,765 --> 00:36:54,845
Speaker 3:  is a lot of work. I don't, I don't care. It's a lot of, but I'm hoping this

552
00:36:54,845 --> 00:36:57,325
Speaker 3:  is the like a spark for people to work on this stuff.

553
00:36:57,705 --> 00:37:01,365
Speaker 7:  Yes, I think that's true. I'm just surprised they haven't come out with a

554
00:37:01,415 --> 00:37:04,925
Speaker 7:  robot mop. You know, they came out with their robot vacuum but they've yet

555
00:37:04,925 --> 00:37:08,405
Speaker 7:  to come up with a robot mop, which seems like a natural progression for them.

556
00:37:08,725 --> 00:37:12,205
Speaker 7:  I don't know, maybe this was their sort of shock to say actually we don't

557
00:37:12,205 --> 00:37:15,725
Speaker 7:  think the robot version is ever gonna work. You know, you still need to do

558
00:37:15,725 --> 00:37:19,645
Speaker 7:  the manual part. But we've taken a lot of the hard work out. I mean

559
00:37:19,645 --> 00:37:23,285
Speaker 7:  the main, the good thing about this compared to, so there are other options

560
00:37:23,285 --> 00:37:26,485
Speaker 7:  out there from, from companies like Robo Rock that make robot vacuums that

561
00:37:26,505 --> 00:37:30,325
Speaker 7:  are handheld wet dry vacuums so they can

562
00:37:30,485 --> 00:37:34,365
Speaker 7:  mop and vacuum as you go, but they're huge and bulky and you know, it's like

563
00:37:34,405 --> 00:37:38,365
Speaker 7:  a workout pushing them around the floor. Totally. Whereas this is

564
00:37:38,365 --> 00:37:42,245
Speaker 7:  much more lightweight and apparently kind of you, you know, has the motion,

565
00:37:42,715 --> 00:37:46,405
Speaker 7:  it's doing the hard work, you are just guiding it eventually, you know,

566
00:37:46,645 --> 00:37:50,365
Speaker 7:  we'll have the full size Android in the house Android

567
00:37:50,415 --> 00:37:53,845
Speaker 7:  robot that can come around and push it for you. Maybe that's their plan

568
00:37:54,755 --> 00:37:58,485
Speaker 3:  Sold that will upgrade to big deal. But for now we'll leave it at small deal.

569
00:37:58,565 --> 00:37:59,605
Speaker 3:  I think that's fair. Small deal.

570
00:37:59,925 --> 00:38:00,325
Speaker 7:  Alright,

571
00:38:00,555 --> 00:38:04,525
Speaker 3:  Next thing on the list, you tested out Amazon's matter casting

572
00:38:05,085 --> 00:38:08,645
Speaker 3:  a, I wanna know about your experience and B matter casting in general,

573
00:38:09,345 --> 00:38:11,125
Speaker 3:  big deal, medium, small deal. What do you think?

574
00:38:11,685 --> 00:38:15,605
Speaker 7:  I think it's a big deal. Okay. I do, but it's, it's stymied at the

575
00:38:15,605 --> 00:38:19,525
Speaker 7:  moment because I just don't see that Apple or Google are going to

576
00:38:19,555 --> 00:38:23,085
Speaker 7:  embrace it because they already have their own proprietary

577
00:38:23,435 --> 00:38:25,965
Speaker 7:  solutions for casting content to your TV

578
00:38:26,385 --> 00:38:30,285
Speaker 3:  And matter casting is is like we, it's like Amazon's working on it

579
00:38:30,585 --> 00:38:33,405
Speaker 3:  the most right now it seems like. But in theory it's like an open standard

580
00:38:33,505 --> 00:38:36,725
Speaker 3:  for sending content around between devices basically, right?

581
00:38:36,985 --> 00:38:40,525
Speaker 7:  Yes. So it is, it's part of the matter standard. It actually came out with

582
00:38:40,525 --> 00:38:44,245
Speaker 7:  the first iteration of Matter so 1.0. But it's been very

583
00:38:44,595 --> 00:38:47,965
Speaker 7:  sort of under the radar. I have written about it, but it's not, not many,

584
00:38:47,965 --> 00:38:51,645
Speaker 7:  there's not much adoption. It has been driven by Amazon. So the way

585
00:38:51,645 --> 00:38:55,525
Speaker 7:  matter works there's working groups and you have sort of a lead of each

586
00:38:55,525 --> 00:38:58,725
Speaker 7:  ahead of each working group and the head of that working group is an Amazon

587
00:38:59,765 --> 00:39:03,565
Speaker 7:  engineer and he's pushing this and he's working with from,

588
00:39:03,715 --> 00:39:06,525
Speaker 7:  they're, they're not allowed to tell me exactly who's in the group, but he

589
00:39:06,525 --> 00:39:10,285
Speaker 7:  implied it's mainly TV manufacturers and app makers. So like

590
00:39:10,995 --> 00:39:14,805
Speaker 7:  Hulu or, and I'm, I don't know that Hulu's there but that kind of,

591
00:39:14,915 --> 00:39:18,565
Speaker 7:  sure those kind of people are working on developing it. So, but yes, just

592
00:39:18,565 --> 00:39:22,365
Speaker 7:  to clarify, so matter casting is a way of casting content from

593
00:39:22,745 --> 00:39:26,605
Speaker 7:  one device to another at its core. But what it's been

594
00:39:26,605 --> 00:39:30,085
Speaker 7:  used for here is casting content from your phone

595
00:39:30,425 --> 00:39:34,405
Speaker 7:  or tablet to a screen IE or tv, but

596
00:39:34,405 --> 00:39:38,365
Speaker 7:  it could be to any screen in your home. So Amazon's using it as

597
00:39:38,365 --> 00:39:42,125
Speaker 7:  a way to cast prime video content to the fire TV stick

598
00:39:42,145 --> 00:39:45,925
Speaker 7:  or an echo show. 15 matter casting has to be enabled on both

599
00:39:46,155 --> 00:39:49,645
Speaker 7:  ends. And if you are familiar with Fire TVs and

600
00:39:49,855 --> 00:39:53,765
Speaker 7:  right now they do not have a native way of casting content. So

601
00:39:53,835 --> 00:39:57,365
Speaker 7:  this is a, this is really the first time Amazon's had something like this

602
00:39:57,745 --> 00:40:00,845
Speaker 7:  and it's been kind of a frustrating experience for people that use Fire TVs

603
00:40:00,845 --> 00:40:04,685
Speaker 7:  not to have, you can mirror but mirroring is never great. But right now it

604
00:40:04,685 --> 00:40:07,525
Speaker 7:  only works on Prime video though they say they have a number of app makers

605
00:40:07,725 --> 00:40:11,525
Speaker 7:  who are, who are going to enable it, including Plex and Sling. So

606
00:40:11,525 --> 00:40:15,085
Speaker 7:  they're really pushing it hard. The thing that's different about it

607
00:40:15,305 --> 00:40:19,125
Speaker 7:  versus Google cast or Apple Airplay is, and

608
00:40:19,125 --> 00:40:23,045
Speaker 7:  this is where the app makers come in, is you actually, it's an app to

609
00:40:23,045 --> 00:40:26,845
Speaker 7:  app communication. So you are replicating the app on your phone

610
00:40:27,225 --> 00:40:31,085
Speaker 7:  and on your TV. So you can control everything you can do in the Prime

611
00:40:31,085 --> 00:40:35,005
Speaker 7:  video app or the Hulu app or which other Netflix app mirrors exactly

612
00:40:35,025 --> 00:40:38,245
Speaker 7:  on your tv. So you're not kind of like, when I use Apple Airplay I'm like,

613
00:40:38,285 --> 00:40:42,205
Speaker 7:  I wanna fast forward but I can't, like the controls aren't intuitive

614
00:40:42,825 --> 00:40:46,805
Speaker 7:  and app makers are like, we've made these great experiences for you on our

615
00:40:46,895 --> 00:40:50,445
Speaker 7:  phone apps, let's just make that what you use on the tv. So it's

616
00:40:50,645 --> 00:40:54,445
Speaker 7:  simplifying the process basically. And I think it works really well. My

617
00:40:54,445 --> 00:40:56,725
Speaker 7:  experience was just limited to prime video 'cause that's the only one that

618
00:40:56,725 --> 00:41:00,565
Speaker 7:  works. But it worked great. It was much easier for me than other forms of

619
00:41:00,565 --> 00:41:04,405
Speaker 7:  casting. So I think it's gonna be a big deal for Fire

620
00:41:04,505 --> 00:41:08,405
Speaker 7:  TV at the moment. But in the smart

621
00:41:08,405 --> 00:41:12,245
Speaker 7:  home in general matter casting means any device can

622
00:41:12,245 --> 00:41:15,845
Speaker 7:  cast to any device so your washing machine

623
00:41:16,025 --> 00:41:19,765
Speaker 7:  can cast to your tv. I know that's the stuff of nightmares for some people,

624
00:41:19,825 --> 00:41:23,645
Speaker 7:  but I like getting an alert on my TV when my washing's done.

625
00:41:23,755 --> 00:41:27,685
Speaker 7:  Yeah, it, you could also, once matter brings cameras

626
00:41:28,025 --> 00:41:31,885
Speaker 7:  in theory to the standard, you know, you could have an a

627
00:41:31,885 --> 00:41:35,445
Speaker 7:  non-proprietary way of viewing your video doorbell on your tv

628
00:41:35,745 --> 00:41:38,245
Speaker 7:  so you wouldn't have to have a certain tv, you wouldn't have to have a certain

629
00:41:38,245 --> 00:41:41,565
Speaker 7:  video doorbell for that to work, which is the way it is today. And it's a

630
00:41:41,565 --> 00:41:45,365
Speaker 7:  universal, you know, standard open protocol. Anyone

631
00:41:45,365 --> 00:41:48,125
Speaker 7:  can use it. You know, that's a good thing In the smart home we like these

632
00:41:48,275 --> 00:41:52,205
Speaker 7:  open standards as opposed to the closed infrastructure of, you

633
00:41:52,205 --> 00:41:56,085
Speaker 7:  know, airplay or Google cast. You know, there's, there's a lot of

634
00:41:56,675 --> 00:42:00,645
Speaker 7:  potential here. Yeah. Right now though it's, yeah,

635
00:42:00,645 --> 00:42:04,485
Speaker 7:  it's all Amazon and no one else. I've spoken to Apple and I've spoken

636
00:42:04,485 --> 00:42:07,805
Speaker 7:  to Google about it and they're all like, nope, not saying anything,

637
00:42:08,415 --> 00:42:12,005
Speaker 7:  we're not using this yet. And this is one of the problems with Matter.

638
00:42:12,865 --> 00:42:16,525
Speaker 7:  Not all platforms are required to use or implement every

639
00:42:16,635 --> 00:42:20,445
Speaker 7:  part of the matter standard. And for example, one of the problems

640
00:42:20,445 --> 00:42:24,165
Speaker 7:  right now, I love the idea of being able to cast to my TV from any matter

641
00:42:24,185 --> 00:42:27,965
Speaker 7:  device, but Samsung, one of the major TV

642
00:42:27,965 --> 00:42:31,925
Speaker 7:  manufacturers, even though they're fully on board with Matter, they have

643
00:42:32,025 --> 00:42:36,005
Speaker 7:  not committed to their TVs or any of their appliances being matter

644
00:42:36,155 --> 00:42:39,885
Speaker 7:  enabled. Hmm. So with, we're going back to this issue of,

645
00:42:40,145 --> 00:42:43,445
Speaker 7:  you know, there's these great open standards and open protocols that you

646
00:42:43,445 --> 00:42:47,365
Speaker 7:  can use, but not everyone's adopting them. So that kind of, you know,

647
00:42:47,525 --> 00:42:49,925
Speaker 7:  kneecaps the whole initiative from day one.

648
00:42:50,415 --> 00:42:54,285
Speaker 3:  Right. Well and with matter casting in particular, it seems like if I'm Google

649
00:42:54,425 --> 00:42:58,245
Speaker 3:  or Apple, I'm looking at it saying, okay, at least matter in general

650
00:42:59,065 --> 00:43:02,725
Speaker 3:  solves problems, right? Like you can understand why eventually you're going

651
00:43:02,725 --> 00:43:06,605
Speaker 3:  to want to be part of this broader ecosystem that

652
00:43:06,785 --> 00:43:10,245
Speaker 3:  you don't have to control all of by yourself. Yeah. Whether they want to

653
00:43:10,305 --> 00:43:14,205
Speaker 3:  now or not. Spoiler alert we're gonna get to in a minute. But the question

654
00:43:14,205 --> 00:43:17,965
Speaker 3:  of like is it a long-term good idea sort of makes sense. My sense is

655
00:43:17,985 --> 00:43:21,685
Speaker 3:  for casting, if I'm running Airplay or Google Cast,

656
00:43:21,785 --> 00:43:25,605
Speaker 3:  I'm like eh, we've kind of solved this problem. And like sure, it might be

657
00:43:25,605 --> 00:43:29,445
Speaker 3:  nice to have a bigger, broader thing to do, but what most people

658
00:43:29,475 --> 00:43:32,525
Speaker 3:  want to do is they want to tap a thing on their phone and have it play on

659
00:43:32,525 --> 00:43:36,005
Speaker 3:  their television and we've done that. Yeah. So to me it's like, I'm curious

660
00:43:36,025 --> 00:43:39,725
Speaker 3:  to see if anybody can sort of build a use case that is so

661
00:43:39,795 --> 00:43:42,885
Speaker 3:  much more useful for matter casting than that.

662
00:43:43,665 --> 00:43:46,565
Speaker 3:  And then I think you might start to see everybody get on board, but until

663
00:43:46,565 --> 00:43:49,845
Speaker 3:  then, my sense is Apple looks at airplane and is like, yeah we, we did that.

664
00:43:49,875 --> 00:43:53,525
Speaker 3:  Like we're, we're good. Yeah we want to get it on more screens like in hotels

665
00:43:53,525 --> 00:43:56,605
Speaker 3:  and whatever, but like airplane works, it's fine. We we're not gonna invest

666
00:43:56,605 --> 00:43:57,125
Speaker 3:  more resources.

667
00:43:57,625 --> 00:44:01,325
Speaker 7:  But there, the advantage there that hotel TV screens is a great example.

668
00:44:01,855 --> 00:44:05,685
Speaker 7:  Hotel TVs would not need all new hardware to work with apps. That

669
00:44:05,705 --> 00:44:08,165
Speaker 7:  is true with matter casting. That is true. Yeah. All they need is an update

670
00:44:08,165 --> 00:44:12,045
Speaker 7:  to an app. So, you know, instead of waiting till what, 2050 when we can

671
00:44:12,045 --> 00:44:16,005
Speaker 7:  go into a Hilton and an airplay to our LG TV

672
00:44:16,025 --> 00:44:20,005
Speaker 7:  or whichever, I forget who it is that made the deal with, but you'd be

673
00:44:20,205 --> 00:44:23,405
Speaker 7:  able to do it tomorrow. It, it would just, all you need to do is update the

674
00:44:23,605 --> 00:44:27,565
Speaker 7:  software on the app, on the TV and the software on the app on your phone.

675
00:44:28,005 --> 00:44:31,765
Speaker 7:  I mean you can have it built into the TV itself, but it, you

676
00:44:31,765 --> 00:44:35,725
Speaker 7:  don't have to have a matter enabled TV for this to work necessarily.

677
00:44:36,505 --> 00:44:40,125
Speaker 7:  So it's, it would be an easier solution. And I think where the momentum

678
00:44:40,215 --> 00:44:43,565
Speaker 7:  might shift is if Amazon is successful in getting the app

679
00:44:43,565 --> 00:44:47,245
Speaker 7:  manufacturers on board here and the TV manufacturers, because

680
00:44:47,785 --> 00:44:51,685
Speaker 7:  yes the TV can have airplay and Google cast, but if it also has matter casting

681
00:44:51,865 --> 00:44:55,845
Speaker 7:  it sh it would be a, a more seamless experience for the user because

682
00:44:55,875 --> 00:44:59,645
Speaker 7:  it's very, you know, you don't have to figure out if it supports this or

683
00:44:59,645 --> 00:45:03,525
Speaker 7:  that. It will just work, which is the whole promise of matter. It

684
00:45:03,525 --> 00:45:05,965
Speaker 7:  will just work. Big air quotes.

685
00:45:06,555 --> 00:45:10,125
Speaker 3:  Yeah, exactly. Alright, so while, while we're on the subject of matter matter

686
00:45:10,125 --> 00:45:13,925
Speaker 3:  casting, big deal. I I agree. I think long term big deal,

687
00:45:13,935 --> 00:45:14,445
Speaker 3:  short term,

688
00:45:14,945 --> 00:45:15,725
Speaker 7:  Not so much. Yeah.

689
00:45:15,905 --> 00:45:19,165
Speaker 3:  Big deal for Prime video, fire TV owning customers. Sure. Yes.

690
00:45:20,185 --> 00:45:24,165
Speaker 3:  Matter 1.3 came out a couple of weeks ago, you wrote a story about

691
00:45:24,165 --> 00:45:27,445
Speaker 3:  it matter 1.3, big deal, medium deal, small deal,

692
00:45:27,785 --> 00:45:28,205
Speaker 7:  Big deal.

693
00:45:28,955 --> 00:45:29,245
Speaker 3:  Okay.

694
00:45:30,065 --> 00:45:33,885
Speaker 7:  Big deal. A lot of momentum. I was very not

695
00:45:33,885 --> 00:45:37,725
Speaker 7:  excited by matter. 1.1 matter 1.2 was a little bit

696
00:45:37,725 --> 00:45:40,965
Speaker 7:  more interesting 'cause there was a lot more device types added but Matter

697
00:45:40,985 --> 00:45:44,085
Speaker 7:  1.3 just brought a whole load of more

698
00:45:44,475 --> 00:45:48,445
Speaker 7:  potential with it because more device types, not the device types

699
00:45:48,445 --> 00:45:51,285
Speaker 7:  weren't that exciting. It was kind of what we expected. Like we got washing

700
00:45:51,285 --> 00:45:54,805
Speaker 7:  machines last time, so now we had tumble dryers like woo. Sure

701
00:45:56,445 --> 00:46:00,205
Speaker 7:  there were a few, a few interesting additions there. But I think the big,

702
00:46:00,705 --> 00:46:04,685
Speaker 7:  big deal here, well matter casting came updates to matter casting came with

703
00:46:04,685 --> 00:46:08,405
Speaker 7:  1.3, which I was excited about. That was the ability to cast from device

704
00:46:08,465 --> 00:46:12,445
Speaker 7:  to device, not just the app to app. But the

705
00:46:12,445 --> 00:46:16,165
Speaker 7:  big deal I think is the energy reporting, energy management features, which

706
00:46:16,175 --> 00:46:19,605
Speaker 7:  we've been waiting for. We knew it was coming, but we've been waiting for

707
00:46:19,605 --> 00:46:23,525
Speaker 7:  this. And this is, you know, to me energy management in the smart home

708
00:46:23,705 --> 00:46:27,525
Speaker 7:  really takes the smart home from sort of niche to

709
00:46:28,105 --> 00:46:31,525
Speaker 7:  almost necessary. Because today, you know,

710
00:46:31,525 --> 00:46:35,485
Speaker 7:  conserving resources, using less energy in our homes, saving

711
00:46:35,495 --> 00:46:39,325
Speaker 7:  money are all things that, you know, many people are worried about,

712
00:46:39,325 --> 00:46:43,045
Speaker 7:  concerned about trying to do. And the smart home makes can make it

713
00:46:43,145 --> 00:46:46,925
Speaker 7:  so much easier to do all of this stuff automatically to

714
00:46:47,465 --> 00:46:51,125
Speaker 7:  one of the main sort of showcase pieces that came out with Matter

715
00:46:51,145 --> 00:46:54,725
Speaker 7:  1.3 that exemplifies this is electric vehicle management, so

716
00:46:54,985 --> 00:46:58,525
Speaker 7:  Oh sure. EVSE chargers. So electrical vehicle

717
00:46:58,585 --> 00:47:02,485
Speaker 7:  supply equipment is now a device type in matter

718
00:47:03,065 --> 00:47:06,405
Speaker 7:  as is the ability to control and

719
00:47:06,825 --> 00:47:10,725
Speaker 7:  create management of the way it charges. So for

720
00:47:10,725 --> 00:47:14,365
Speaker 7:  example, you could use your matter app or matter enabled app to

721
00:47:14,955 --> 00:47:18,725
Speaker 7:  tell your ev I want to have 80 miles

722
00:47:19,185 --> 00:47:22,965
Speaker 7:  of range by 2:00 PM this evening or this afternoon and

723
00:47:23,445 --> 00:47:27,405
Speaker 7:  I want you to use the least expensive energy to get there between now and

724
00:47:27,405 --> 00:47:30,605
Speaker 7:  then and you just, you know, hit button and it will do that for you as opposed

725
00:47:30,605 --> 00:47:34,165
Speaker 7:  to you having to go in and like check, you know, is there clean energy now

726
00:47:34,225 --> 00:47:38,085
Speaker 7:  or, and some electrical vehicle supply equipment can do

727
00:47:38,085 --> 00:47:41,725
Speaker 7:  this today, but it's proprietary so it you have to have, you know,

728
00:47:41,865 --> 00:47:45,605
Speaker 7:  the Tesla charger and the Tesla app or the Kia charger and the Kia app. Whereas

729
00:47:46,035 --> 00:47:49,965
Speaker 7:  this will open this ability to any smart home app that uses

730
00:47:49,965 --> 00:47:53,445
Speaker 7:  matter. So if in theory your Apple Home app or your

731
00:47:53,555 --> 00:47:57,445
Speaker 7:  Samsung Smart Things app could do this kind of management for your

732
00:47:57,905 --> 00:48:01,525
Speaker 7:  ev for you. In fact Samsung already does have some electric vehicle

733
00:48:01,525 --> 00:48:05,245
Speaker 7:  management, but again it's specific brands and specific cars and

734
00:48:05,465 --> 00:48:09,005
Speaker 7:  so you have to have the right equipment whereas bringing this type of

735
00:48:09,135 --> 00:48:13,045
Speaker 7:  management to matter will open it up so that it should work

736
00:48:13,045 --> 00:48:16,325
Speaker 7:  with anything that can work with matter. and it works locally obviously,

737
00:48:16,325 --> 00:48:19,485
Speaker 7:  which is, which isn't a bonus but it, we will need to use the cloud obviously

738
00:48:19,485 --> 00:48:23,445
Speaker 7:  to get things like energy prices. But beyond EVs, you know,

739
00:48:23,505 --> 00:48:27,285
Speaker 7:  you could see this applying to using your tumble dryer, your,

740
00:48:27,285 --> 00:48:31,085
Speaker 7:  your washing machine, making sure your fridge and freezer uses Defrost,

741
00:48:31,275 --> 00:48:34,685
Speaker 7:  does a defrost cycle at a, you know, at a time when energy's low, like if

742
00:48:34,685 --> 00:48:38,605
Speaker 7:  you connected everything in your home and appliances, almost all appliances

743
00:48:38,605 --> 00:48:42,565
Speaker 7:  are now part of matter, which is what came with 1.3. We are mainly just waiting

744
00:48:42,985 --> 00:48:46,925
Speaker 7:  on heat pumps, which they say are coming next and that's obviously a

745
00:48:46,925 --> 00:48:50,685
Speaker 7:  big part. And there was one other appliance, I can't remember off the top

746
00:48:50,685 --> 00:48:50,925
Speaker 7:  of my head.

747
00:48:50,985 --> 00:48:52,445
Speaker 3:  It was water heaters, right? Water

748
00:48:52,445 --> 00:48:56,165
Speaker 7:  Heaters. So both of those obviously are big energy consumers, although

749
00:48:56,275 --> 00:48:59,925
Speaker 7:  heat pumps less than traditional HVAC. So, but still

750
00:49:00,135 --> 00:49:03,845
Speaker 7:  being able to manage the energy use, energy reporting,

751
00:49:04,185 --> 00:49:07,245
Speaker 7:  and this is where I think it's gonna get interesting with the platforms like

752
00:49:07,245 --> 00:49:10,685
Speaker 7:  Apple Home, Google Home, because this gives them

753
00:49:11,185 --> 00:49:15,125
Speaker 7:  the opportunity to start differentiating, right? So to date a

754
00:49:15,125 --> 00:49:18,685
Speaker 7:  lot of people have said well matter just commodifies everything, everything

755
00:49:18,685 --> 00:49:22,565
Speaker 7:  works with everything. So why is there a benefit for Right for

756
00:49:22,565 --> 00:49:26,205
Speaker 7:  these platforms and for anyone that wants to create something in the smart

757
00:49:26,205 --> 00:49:30,085
Speaker 7:  home and how you manage the energy, what kind of service you

758
00:49:30,085 --> 00:49:33,885
Speaker 7:  can provide on top of this type of reporting that the

759
00:49:33,885 --> 00:49:37,325
Speaker 7:  system is now providing is going to help

760
00:49:37,325 --> 00:49:40,645
Speaker 7:  differentiate. So if Apple Home comes up with a great way of

761
00:49:41,485 --> 00:49:44,485
Speaker 7:  managing energy throughout your home with your connected appliances, you

762
00:49:44,485 --> 00:49:48,165
Speaker 7:  might be more inclined to use their app. Samsung already has a pretty good

763
00:49:48,235 --> 00:49:52,125
Speaker 7:  Samsung energy system in place, so I think it's got the headstart there

764
00:49:52,425 --> 00:49:56,045
Speaker 7:  and Google Home will see, Alexa

765
00:49:56,045 --> 00:50:00,005
Speaker 7:  already has some energy management built in if your device supports it.

766
00:50:00,145 --> 00:50:04,005
Speaker 7:  So I think in the next few months, and I've already seen a few come

767
00:50:04,005 --> 00:50:07,805
Speaker 7:  out, we're gonna see a lot more devices adopting matter in order

768
00:50:07,905 --> 00:50:11,885
Speaker 7:  to, because this is a reason to put matter in your device, having

769
00:50:11,885 --> 00:50:15,485
Speaker 7:  energy management is, is a huge sort of push for the smart home.

770
00:50:15,955 --> 00:50:19,605
Speaker 7:  It's not the sexy fun stuff, but it's really important. Well

771
00:50:19,725 --> 00:50:23,645
Speaker 3:  I I think back to like the days of the Nest thermostat and,

772
00:50:23,705 --> 00:50:27,670
Speaker 3:  and to some extent that thing that it was just like we will will help you

773
00:50:28,135 --> 00:50:31,965
Speaker 3:  lower your heating and cooling bill for your house is maybe still

774
00:50:32,025 --> 00:50:35,885
Speaker 3:  to this day the single like simplest, most compelling smart home use case

775
00:50:36,265 --> 00:50:40,205
Speaker 3:  for most people. And I think this, this just adds to that in really interesting

776
00:50:40,205 --> 00:50:43,565
Speaker 3:  ways but also seems like it's sets up this cool

777
00:50:44,365 --> 00:50:48,285
Speaker 3:  flywheel potentially where it's like okay and not only are you able to

778
00:50:48,755 --> 00:50:51,805
Speaker 3:  control more and more of your stuff, but the stuff that you're controlling

779
00:50:51,865 --> 00:50:55,165
Speaker 3:  can feed more data back to the system. Which means like you're saying the

780
00:50:55,165 --> 00:50:58,645
Speaker 3:  system can start to do better and the people building these systems can do

781
00:50:58,645 --> 00:51:02,085
Speaker 3:  more stuff with that information and you can actually start to like improve

782
00:51:02,355 --> 00:51:05,445
Speaker 3:  upon itself over time as opposed to just

783
00:51:06,405 --> 00:51:09,485
Speaker 3:  a lot of what we've had so far is just sort of increasingly elaborate

784
00:51:10,165 --> 00:51:13,725
Speaker 3:  controllers and that's fine as far as it goes, but like the job of the smart

785
00:51:13,725 --> 00:51:17,485
Speaker 3:  home should be to do most of this on its own right. And we're like,

786
00:51:17,535 --> 00:51:21,285
Speaker 3:  we're slowly getting to the point of it feels like the puzzle pieces for

787
00:51:21,285 --> 00:51:23,365
Speaker 3:  that are starting to get into place, which is very exciting.

788
00:51:23,945 --> 00:51:26,965
Speaker 7:  It is. And this is something I've been talking to companies about for years

789
00:51:27,145 --> 00:51:30,605
Speaker 7:  and it takes the, has taken them years to, you know, get the

790
00:51:30,605 --> 00:51:33,965
Speaker 7:  partnerships, get the electric companies on board, you know, get it. It's,

791
00:51:33,965 --> 00:51:37,885
Speaker 7:  it's, it's a huge project whereas this should make it a lot easier

792
00:51:38,305 --> 00:51:42,205
Speaker 7:  to push us forward. And the really exciting part I think, and this is also

793
00:51:42,205 --> 00:51:46,005
Speaker 7:  something I wrote about last in the last couple weeks, is that it

794
00:51:46,005 --> 00:51:49,925
Speaker 7:  could help shift not just your home but

795
00:51:50,145 --> 00:51:53,925
Speaker 7:  energy use in the entire country or world

796
00:51:54,345 --> 00:51:58,245
Speaker 7:  by promoting and helping push forward the idea of virtual power plants.

797
00:51:58,505 --> 00:52:02,365
Speaker 7:  And this is something, so Nest Renew you mentioned Nest. So Nest Renew

798
00:52:02,365 --> 00:52:05,965
Speaker 7:  has turned into a new program now called Renew Home,

799
00:52:06,265 --> 00:52:10,045
Speaker 7:  but Google's still involved but Google kind of shifted its Nest Renew, which

800
00:52:10,045 --> 00:52:13,045
Speaker 7:  is the service that helps you save energy when you use your Nest thermostat

801
00:52:13,345 --> 00:52:17,045
Speaker 7:  to a new sort of platform that merged with a company that had already been

802
00:52:17,045 --> 00:52:20,885
Speaker 7:  doing demand response programs in select states

803
00:52:20,885 --> 00:52:24,765
Speaker 7:  in the country. But now it's working towards sort of creating virtual power

804
00:52:24,765 --> 00:52:28,565
Speaker 7:  plants using every smart house and every house that has

805
00:52:28,575 --> 00:52:32,525
Speaker 7:  smart appliances as virtual power plants. And that's

806
00:52:32,525 --> 00:52:35,525
Speaker 7:  something that could really help reduce the strain on the grid, you know,

807
00:52:35,525 --> 00:52:38,885
Speaker 7:  and create a better experience for everyone. So

808
00:52:39,235 --> 00:52:40,565
Speaker 7:  it's for the greater good.

809
00:52:41,435 --> 00:52:44,525
Speaker 3:  Totally. I think that's really exciting. What you, you mentioned

810
00:52:45,155 --> 00:52:48,845
Speaker 3:  heat pumps and water heaters. Are there other like huge categories still

811
00:52:48,845 --> 00:52:52,765
Speaker 3:  missing in matter? What, what's kind of still on the, on the to-do list there

812
00:52:52,875 --> 00:52:53,365
Speaker 3:  cameras

813
00:52:53,825 --> 00:52:57,765
Speaker 7:  Is is a big one they said said that's definitely coming. Although it

814
00:52:57,765 --> 00:53:01,445
Speaker 7:  will come from what I understand in a very limited fashion, it will really,

815
00:53:01,495 --> 00:53:05,085
Speaker 7:  it'll just be that you can view your stream and control your stream in any

816
00:53:05,765 --> 00:53:09,445
Speaker 7:  platform. But if you want recorded video, you want the added things like

817
00:53:10,105 --> 00:53:13,765
Speaker 7:  ai, identification of people, animals, that's all gonna

818
00:53:13,965 --> 00:53:17,845
Speaker 7:  be from your, from the manufacturer still. So it'll just be though that you'll

819
00:53:17,845 --> 00:53:21,685
Speaker 7:  be able to in theory, view your video anywhere or use it

820
00:53:21,705 --> 00:53:25,685
Speaker 7:  for hopefully for triggering automations like motion detection or if you

821
00:53:25,715 --> 00:53:29,645
Speaker 7:  spot an animal, turn the siren on. This is for my chicken coop.

822
00:53:31,345 --> 00:53:35,005
Speaker 7:  So the, I think, I think people want cameras there because you want one app

823
00:53:35,145 --> 00:53:39,045
Speaker 7:  to see everything but you're still going and this is a theme with matter,

824
00:53:39,045 --> 00:53:42,965
Speaker 7:  you're still going to need to use manufacturer apps if you

825
00:53:42,965 --> 00:53:46,565
Speaker 7:  want the added benefits, if you want the added features. But if you just

826
00:53:46,565 --> 00:53:50,245
Speaker 7:  want the basic use case of smart home, that's one one that's really

827
00:53:50,515 --> 00:53:53,685
Speaker 7:  requested. People really want cameras. And then the other, which I don't

828
00:53:53,685 --> 00:53:55,965
Speaker 7:  think we're ever going to get is security systems.

829
00:53:56,385 --> 00:53:56,925
Speaker 3:  Oh sure.

830
00:53:57,185 --> 00:54:01,045
Speaker 7:  So you know, your smart home security system, I think those may

831
00:54:01,045 --> 00:54:04,725
Speaker 7:  bridge into matter because most of them are Z-Wave based,

832
00:54:05,145 --> 00:54:09,085
Speaker 7:  but there's just too much around the ul. So all,

833
00:54:09,225 --> 00:54:13,085
Speaker 7:  all security systems most, you know, if you have a certificate, most of them

834
00:54:13,225 --> 00:54:16,645
Speaker 7:  are UL certified and that requires a lot of

835
00:54:17,325 --> 00:54:21,085
Speaker 7:  certification. It's a tough certification to get. It is an important

836
00:54:21,105 --> 00:54:25,085
Speaker 7:  one. Yeah. It ensures your security system is gonna work and the way you

837
00:54:25,085 --> 00:54:28,845
Speaker 7:  expect it to and I just don't see much, I think the

838
00:54:28,845 --> 00:54:32,725
Speaker 7:  meshing between security systems and matter is just not likely to happen

839
00:54:32,725 --> 00:54:35,525
Speaker 7:  anytime soon. But I think we may get to the point where you can bridge it

840
00:54:35,525 --> 00:54:39,365
Speaker 7:  so you can still control everything in one app. But those are the

841
00:54:39,605 --> 00:54:40,645
Speaker 7:  main things that we're at now

842
00:54:41,035 --> 00:54:44,045
Speaker 3:  That feels like an okay outcome to me with both of those actually to say,

843
00:54:44,105 --> 00:54:48,085
Speaker 3:  you know, you can sort of take what's happening inside of those systems

844
00:54:48,625 --> 00:54:52,165
Speaker 3:  and use it in the broader system. Yeah. But the idea that like in theory

845
00:54:52,335 --> 00:54:55,845
Speaker 3:  everything in my matter home should have perfect

846
00:54:55,985 --> 00:54:59,885
Speaker 3:  access to everything I've ever recorded on my security camera actually feels

847
00:54:59,885 --> 00:55:03,725
Speaker 3:  kinda weird. So like right, it maybe, maybe at least at the

848
00:55:03,725 --> 00:55:07,685
Speaker 3:  very least taking that one slightly slowly makes some sense to

849
00:55:07,685 --> 00:55:11,245
Speaker 3:  me. Yeah, so I'm, I'm, I'm actually for once I will give the matter folks

850
00:55:11,245 --> 00:55:14,885
Speaker 3:  some credit for going slowly here that that feels, that feels good. And

851
00:55:14,885 --> 00:55:18,445
Speaker 7:  Then there is one more though. Sorry. Adaptive lighting. We're still waiting

852
00:55:18,745 --> 00:55:22,405
Speaker 7:  for better control of lighting. Mm. They say that's coming soon,

853
00:55:22,825 --> 00:55:25,885
Speaker 7:  but again this is gonna be one of the things you need to use your apps for,

854
00:55:26,225 --> 00:55:29,885
Speaker 7:  but I still, I want to be able to use, I want every light in my house no

855
00:55:29,885 --> 00:55:33,085
Speaker 7:  matter which manufacturer it's from to be able to sink to the scene that

856
00:55:33,085 --> 00:55:37,005
Speaker 7:  I've chosen and they say that's coming. So hopefully in the

857
00:55:37,005 --> 00:55:39,205
Speaker 7:  next update, but sorry. Yes, I could keep going.

858
00:55:39,865 --> 00:55:43,365
Speaker 3:  Got it. Alright, two more. So one, I think I know

859
00:55:43,575 --> 00:55:46,685
Speaker 3:  where both of these will fall, so we'll do the, we'll do the less exciting

860
00:55:46,705 --> 00:55:50,605
Speaker 3:  one First you wrote about brilliant, this smart home company that was, I

861
00:55:50,605 --> 00:55:54,565
Speaker 3:  would say once sort of high flying and now seems to

862
00:55:54,565 --> 00:55:58,285
Speaker 3:  be in, in very rough shape. Brilliant kind of collapsing

863
00:55:58,345 --> 00:56:01,605
Speaker 3:  for lack of a better term, big deal, medium deal or small deal.

864
00:56:03,045 --> 00:56:05,285
Speaker 3:  I can sense you wanting to be nice to brilliant here.

865
00:56:07,035 --> 00:56:10,805
Speaker 7:  It's not surprising. I kind of saw it coming. It

866
00:56:10,825 --> 00:56:14,605
Speaker 7:  was a great idea. I have written a lot about wanting better controllers in

867
00:56:14,605 --> 00:56:18,525
Speaker 7:  my home and it worked very well as that type of controller I had

868
00:56:18,525 --> 00:56:22,365
Speaker 7:  been looking for, but only with certain products and that

869
00:56:22,365 --> 00:56:26,005
Speaker 7:  was, you know, it, it was almost, it's almost like a symbol of the

870
00:56:26,005 --> 00:56:29,805
Speaker 7:  problems the smart home have had to date. It's, they've been around a long

871
00:56:29,805 --> 00:56:33,445
Speaker 7:  time. They launched, you know, almost 10 years ago. I think they've, they've

872
00:56:33,445 --> 00:56:37,365
Speaker 7:  been around a long time. It's a good product, good hardware, but

873
00:56:37,775 --> 00:56:40,925
Speaker 7:  unfor so they, they've basically gone outta business. I mean they're still

874
00:56:40,925 --> 00:56:44,885
Speaker 7:  keeping the lights on so the system still works. I have one in my

875
00:56:44,885 --> 00:56:48,165
Speaker 7:  house and it's not stopped working. They're looking for a buyer.

876
00:56:49,085 --> 00:56:52,925
Speaker 7:  I did actually check in with the CEO just last, just a few days ago and

877
00:56:52,925 --> 00:56:56,765
Speaker 7:  he said no news yet, but it's looking promising and he's hoping that users

878
00:56:56,825 --> 00:57:00,525
Speaker 7:  of the system, which is a smart light switch that's installed

879
00:57:00,795 --> 00:57:04,285
Speaker 7:  wire to your house but can also be used as a smart home controller to control

880
00:57:04,285 --> 00:57:08,165
Speaker 7:  your, like your sono system, view your video doorbell control your

881
00:57:08,165 --> 00:57:11,605
Speaker 7:  lights, your thermostat. It's sort of an all-in-one smart home controller,

882
00:57:11,605 --> 00:57:15,485
Speaker 7:  but it had very limited integrations. And the company

883
00:57:15,675 --> 00:57:18,445
Speaker 7:  said to me over the years when I'd asked 'em about this, it's like, it's

884
00:57:18,645 --> 00:57:22,085
Speaker 7:  not that we don't want these integrations, it's that companies won't work

885
00:57:22,085 --> 00:57:25,925
Speaker 7:  with us. And this is one of the reasons that Matter came about because of

886
00:57:25,925 --> 00:57:29,685
Speaker 7:  this issue with interoperability and having to make individual integrations

887
00:57:29,685 --> 00:57:33,645
Speaker 7:  with every device out there. And they, they've been trying to

888
00:57:33,645 --> 00:57:37,005
Speaker 7:  do this for years, but they'd hardly added any new integrations in the last

889
00:57:37,245 --> 00:57:41,045
Speaker 7:  few years and they weren't adopting matter. And I had asked them, they said

890
00:57:41,045 --> 00:57:44,605
Speaker 7:  they were, they said they were, but they hadn't done it yet and Right.

891
00:57:44,905 --> 00:57:48,485
Speaker 7:  Didn't really feel like it was, it was coming down the pipeline. Aaron, the

892
00:57:48,565 --> 00:57:52,525
Speaker 7:  CEO told me that they did have a new generation

893
00:57:52,775 --> 00:57:56,085
Speaker 7:  ready to roll better hardware, better

894
00:57:56,315 --> 00:58:00,045
Speaker 7:  integration not, not better integrations yet, but they had sort of more there

895
00:58:00,045 --> 00:58:03,965
Speaker 7:  that it was gonna make on-device processing ai, it was gonna be

896
00:58:03,965 --> 00:58:07,885
Speaker 7:  a much improved device and less expensive because oh my gosh, I forgot

897
00:58:07,885 --> 00:58:11,685
Speaker 7:  to mention how expensive these devices were starting at $400 for a light

898
00:58:11,685 --> 00:58:15,645
Speaker 7:  switch was just too much and that was always their problem too

899
00:58:15,645 --> 00:58:19,165
Speaker 7:  expensive. But when I asked they, it doesn't sound like they'd added thread

900
00:58:19,225 --> 00:58:22,845
Speaker 7:  or matter yet even to this next generation. And I think there's some

901
00:58:22,845 --> 00:58:26,365
Speaker 7:  potential for a buyer who does, if someone does come and take this

902
00:58:26,475 --> 00:58:30,325
Speaker 7:  product and sort of keep it as it is but improve upon it,

903
00:58:30,845 --> 00:58:34,765
Speaker 7:  that's really where I think it has a lot of potential to be a decent

904
00:58:34,775 --> 00:58:38,325
Speaker 7:  smart home controller if it can work with everything. But yeah, it's, I mean

905
00:58:38,325 --> 00:58:42,005
Speaker 7:  it's kind of a medium deal. It's, it is a symbol I think of with, of the

906
00:58:42,005 --> 00:58:45,605
Speaker 7:  churn of the smart home. Like we're a decade or so

907
00:58:45,875 --> 00:58:49,805
Speaker 7:  into this sort of DIY smart home now and we are seeing,

908
00:58:50,025 --> 00:58:53,645
Speaker 7:  you know, some of the early pioneers kind of drop off.

909
00:58:53,715 --> 00:58:57,285
Speaker 7:  They've either been bought or they've sort of become

910
00:58:57,765 --> 00:59:01,165
Speaker 7:  somewhat boring, like Ring Fair, they're not really innovating anymore but

911
00:59:01,165 --> 00:59:04,805
Speaker 7:  they're, you know, they have a core customer group that they have a great

912
00:59:05,045 --> 00:59:08,965
Speaker 7:  business but it's not exciting anymore. Brilliant is an example. I

913
00:59:08,965 --> 00:59:11,845
Speaker 7:  think they were an independent company and they kept independent until the

914
00:59:11,845 --> 00:59:15,725
Speaker 7:  very end. But it's hard now for these startups. And I'm guessing, I don't

915
00:59:15,725 --> 00:59:18,645
Speaker 7:  know if this next question is gonna be about a startup 'cause I think it

916
00:59:18,645 --> 00:59:21,805
Speaker 7:  might be it's not actually. Oh, okay. Well I was

917
00:59:22,525 --> 00:59:26,125
Speaker 7:  Quilt was the startup there. Oh yeah, the other one that I wrote about, which

918
00:59:26,125 --> 00:59:29,965
Speaker 7:  is a heat pump company. But yeah, it's, it's not an easy space right now

919
00:59:30,025 --> 00:59:33,965
Speaker 7:  for, for startups and it hasn't been for, for the last few years and,

920
00:59:34,105 --> 00:59:37,245
Speaker 7:  and Brilliant was kind of sadly a, a victim of that. Yeah,

921
00:59:37,485 --> 00:59:41,085
Speaker 3:  Brilliant Is is always going to have a sort of special place in my heart.

922
00:59:41,165 --> 00:59:44,885
Speaker 3:  I tried a very early version of it that just sucked. I mean it was so

923
00:59:45,505 --> 00:59:49,365
Speaker 3:  broken and bad I put it in my wall and then the light

924
00:59:49,505 --> 00:59:52,885
Speaker 3:  on the balcony of my apartment wouldn't turn off

925
00:59:53,295 --> 00:59:56,605
Speaker 3:  until I took it out of the wall. But eventually they fixed it and I got a

926
00:59:56,605 --> 00:59:59,245
Speaker 3:  working version of it that was like an early prototype that I just thought

927
00:59:59,245 --> 01:00:02,285
Speaker 3:  was hilarious. But eventually I got a thing that worked. It was really great,

928
01:00:02,435 --> 01:00:06,165
Speaker 3:  they got a lot of things right but it always felt like, like a touchscreen

929
01:00:06,185 --> 01:00:10,005
Speaker 3:  on your wall can't possibly be the correct answer to this problem. Yeah and

930
01:00:10,005 --> 01:00:13,605
Speaker 3:  and it does seem like the thing that Brilliant was was always going to be

931
01:00:13,605 --> 01:00:17,165
Speaker 3:  sort of a transition into how this smart home is actually supposed to work.

932
01:00:17,315 --> 01:00:21,125
Speaker 3:  Yeah. and it feels like good for us but bad for brilliant. That is the

933
01:00:21,125 --> 01:00:23,205
Speaker 3:  transition that's happening right now. Yeah,

934
01:00:23,555 --> 01:00:26,285
Speaker 7:  Yeah. No I think you're right. The smart home needs to be smarter.

935
01:00:27,115 --> 01:00:31,045
Speaker 3:  Yeah, agreed. Alright, last one. Google launched a bunch of new

936
01:00:31,235 --> 01:00:35,005
Speaker 3:  home APIs at Google io and I

937
01:00:35,205 --> 01:00:38,965
Speaker 3:  confess I'm torn between either this is a huge deal that might actually change

938
01:00:39,045 --> 01:00:42,845
Speaker 3:  a lot of things and this is nothing and no one will adopt these APIs and

939
01:00:42,845 --> 01:00:46,725
Speaker 3:  no one cares. So where are you? Big deal, medium deal, small deal.

940
01:00:47,065 --> 01:00:50,565
Speaker 7:  Oh I think it's a huge deal. Okay, good. I think it's huge. I think it's

941
01:00:50,565 --> 01:00:54,285
Speaker 7:  huge. Huge. I hope it's not, I hope it's not Google

942
01:00:54,315 --> 01:00:56,965
Speaker 7:  just saying we have had enough of this someone else deal with it.

943
01:00:58,595 --> 01:01:02,285
Speaker 3:  Yeah. So wait, what is sort of the idea behind the APIs that they're launching

944
01:01:02,285 --> 01:01:02,485
Speaker 3:  here?

945
01:01:03,025 --> 01:01:06,965
Speaker 7:  So they have launched Home a their home APIs, which is giving

946
01:01:07,185 --> 01:01:10,645
Speaker 7:  access to developers, device makers at Makers to

947
01:01:11,465 --> 01:01:15,445
Speaker 7:  any device connected to Google Home including Google's devices.

948
01:01:15,705 --> 01:01:19,325
Speaker 7:  So thermostats presumably smoke alarms, cameras

949
01:01:19,435 --> 01:01:23,125
Speaker 7:  they've said not necessarily initially, but that may be coming.

950
01:01:23,665 --> 01:01:27,205
Speaker 7:  But one of the key parts is it's also giving access to the automation engine.

951
01:01:27,545 --> 01:01:31,325
Speaker 7:  So now essentially, so with these APIs

952
01:01:31,845 --> 01:01:35,805
Speaker 7:  a device maker can create an app from scratch

953
01:01:36,345 --> 01:01:40,045
Speaker 7:  for their device or for any device that connects to Google Home

954
01:01:40,225 --> 01:01:43,605
Speaker 7:  and create a smart home experience for you. So you wouldn't have to use Google

955
01:01:43,635 --> 01:01:47,365
Speaker 7:  Home but you would that the Google Home app. But you could use

956
01:01:48,065 --> 01:01:51,605
Speaker 7:  any automation system that the Google Home app

957
01:01:51,645 --> 01:01:55,605
Speaker 7:  provides and any devices that connect to it and with Matter, there are

958
01:01:55,605 --> 01:01:59,325
Speaker 7:  many devices to connect to it. So both works with Google and Matter

959
01:01:59,325 --> 01:02:03,045
Speaker 7:  devices will be accessible through these APIs and it

960
01:02:03,045 --> 01:02:06,765
Speaker 7:  basically is similar in some ways to how Apple Homes Home

961
01:02:07,085 --> 01:02:10,965
Speaker 7:  Original Home Kit worked. If you've ever used like an Eve app or nano Leaf

962
01:02:10,985 --> 01:02:14,805
Speaker 7:  app, you could access every device that was connected to Apple Home Kit

963
01:02:15,105 --> 01:02:18,805
Speaker 7:  in the Eve app or the Nano Leaf app on iOS. This Google

964
01:02:19,035 --> 01:02:22,725
Speaker 7:  Home API will work on both iOS or Android and

965
01:02:22,735 --> 01:02:26,365
Speaker 7:  could basically mean people can create an entire smart home platform

966
01:02:26,715 --> 01:02:30,565
Speaker 7:  from scratch on an app that you could use that isn't

967
01:02:30,565 --> 01:02:34,525
Speaker 7:  Google Home but uses Google's smarts in the

968
01:02:34,525 --> 01:02:38,485
Speaker 7:  background, which are good. They just have been

969
01:02:39,165 --> 01:02:42,405
Speaker 7:  stymied because I feel like perhaps not enough

970
01:02:43,125 --> 01:02:46,885
Speaker 7:  resources are going into developing Google Home at Google.

971
01:02:47,165 --> 01:02:50,845
Speaker 7:  I mean Google's got its fingers in many pies and it's always felt like Google

972
01:02:50,845 --> 01:02:54,245
Speaker 7:  Home is a bit of an afterthought. I think it's really only still here because

973
01:02:54,245 --> 01:02:58,085
Speaker 7:  of the hardware. So I think this is big. I think it's

974
01:02:58,115 --> 01:03:02,085
Speaker 7:  also really big because open APIs are really the

975
01:03:02,085 --> 01:03:05,605
Speaker 7:  sort of lifeblood of the smart home when things are closed and locked down,

976
01:03:06,315 --> 01:03:10,285
Speaker 7:  like brilliant, you know, when it shuts down it no longer works.

977
01:03:10,665 --> 01:03:14,445
Speaker 7:  But if Brilliant had a local API like, you know, if

978
01:03:14,565 --> 01:03:18,205
Speaker 7:  like Google Homes opening its APIs, then even if they

979
01:03:18,585 --> 01:03:22,325
Speaker 7:  go outta business, the device is still gonna work in your home. That it's

980
01:03:22,325 --> 01:03:26,245
Speaker 7:  like the lifeblood of the smart home APIs and opening this to anyone

981
01:03:26,245 --> 01:03:30,165
Speaker 7:  to be able to use I think is, is really exciting. But you are right,

982
01:03:30,165 --> 01:03:33,925
Speaker 7:  it does depend on people actually picking up and using

983
01:03:33,945 --> 01:03:37,845
Speaker 7:  it. So far though, there are a number of big companies that, that

984
01:03:37,845 --> 01:03:41,605
Speaker 7:  are using it. A DT is using the facial recognition on Google Nest

985
01:03:41,605 --> 01:03:45,365
Speaker 7:  cameras. The facial recognition is going to let your system

986
01:03:46,065 --> 01:03:50,005
Speaker 7:  disarm when it recognizes someone that you've authorized to come into your

987
01:03:50,005 --> 01:03:53,565
Speaker 7:  home. It's called Trusted Neighbor. It's a new service that they're rolling

988
01:03:53,625 --> 01:03:57,565
Speaker 7:  out later this year and that's all using Google Home APIs. So, and

989
01:03:57,565 --> 01:04:01,525
Speaker 7:  it, it's again, going back to what I mentioned before, what this gives is

990
01:04:01,545 --> 01:04:05,165
Speaker 7:  the potential for companies to build better experiences

991
01:04:05,755 --> 01:04:09,725
Speaker 7:  than say Google Home has been doing today, but using the tools that are

992
01:04:09,725 --> 01:04:13,285
Speaker 7:  already there, rather than having to reinvent the wheel or develop

993
01:04:13,285 --> 01:04:16,885
Speaker 7:  individual partnerships with all of these companies to have access to their

994
01:04:16,885 --> 01:04:20,485
Speaker 7:  devices. But Google is like Alexa in that it works with

995
01:04:20,585 --> 01:04:24,525
Speaker 7:  pretty much everything but just in a limited way. And now you're

996
01:04:24,525 --> 01:04:27,565
Speaker 7:  gonna have, I think much you're gonna see more innovation from

997
01:04:27,965 --> 01:04:31,805
Speaker 7:  manufacturers and device makers and that is exciting if if

998
01:04:31,805 --> 01:04:32,165
Speaker 7:  it happens.

999
01:04:33,355 --> 01:04:36,845
Speaker 3:  Yeah, well part of what I wonder about the home API thing is if it means

1000
01:04:37,425 --> 01:04:41,325
Speaker 3:  we can get a bunch of new kinds of devices with

1001
01:04:41,425 --> 01:04:43,925
Speaker 3:  new capabilities, like the a DT thing you're talking about is is a really

1002
01:04:43,925 --> 01:04:47,445
Speaker 3:  good example of that. And again, it goes back to this idea of sort of making

1003
01:04:47,745 --> 01:04:51,325
Speaker 3:  the system work with itself in really cool ways, which I think is super exciting.

1004
01:04:51,325 --> 01:04:54,045
Speaker 3:  Yeah. But then I just keep thinking about one of the examples that they gave

1005
01:04:54,045 --> 01:04:57,885
Speaker 3:  where they're like, DoorDash can make it so that

1006
01:04:58,035 --> 01:05:01,685
Speaker 3:  when the delivery person comes to your house it like automatically

1007
01:05:01,995 --> 01:05:05,925
Speaker 3:  unlocks for them and turns the front light on or whatever. And I, on the

1008
01:05:06,125 --> 01:05:09,845
Speaker 3:  one hand I think there are probably really cool, exciting versions of that

1009
01:05:09,845 --> 01:05:13,645
Speaker 3:  that exist in the world. On the other hand, I think that might be the most

1010
01:05:13,755 --> 01:05:17,250
Speaker 3:  like solution in search of a problem thing I've ever heard in my entire life.

1011
01:05:17,645 --> 01:05:21,245
Speaker 3:  So do you think, do you think there's anything to that idea that like maybe

1012
01:05:21,245 --> 01:05:24,605
Speaker 3:  this is how the smart home sort of invades the rest of the online ecosystem?

1013
01:05:24,705 --> 01:05:26,085
Speaker 3:  Or is this just a smart home thing?

1014
01:05:26,635 --> 01:05:30,485
Speaker 7:  Yeah, so that was the way they were selling it. In fact, it was very not

1015
01:05:30,485 --> 01:05:34,285
Speaker 7:  smart home. They were like now any developer can from with any

1016
01:05:34,305 --> 01:05:38,085
Speaker 7:  app can, can use smart home devices and and I get where they were coming

1017
01:05:38,115 --> 01:05:41,965
Speaker 7:  from there. I do think that this to date the smart home has kind of

1018
01:05:41,965 --> 01:05:45,845
Speaker 7:  felt niche enclosed and like you need all of these devices to

1019
01:05:45,845 --> 01:05:49,285
Speaker 7:  get any benefit out of it. And this, whilst it is a,

1020
01:05:49,665 --> 01:05:53,245
Speaker 7:  it does seem like a, a solution in such a problem. The DoorDash

1021
01:05:53,995 --> 01:05:57,885
Speaker 7:  idea is, you know, you don't have to be a smart home device maker to

1022
01:05:57,885 --> 01:06:01,645
Speaker 7:  take advantage of what we can, what what you can do with these APIs.

1023
01:06:01,905 --> 01:06:05,085
Speaker 7:  And I think that was an important message to get out there just to show,

1024
01:06:05,545 --> 01:06:09,525
Speaker 7:  to maybe get people thinking about what they could do with this type of technology

1025
01:06:09,675 --> 01:06:13,445
Speaker 7:  because it isn't, it shouldn't just be limited to, you know, goodnight

1026
01:06:13,445 --> 01:06:17,365
Speaker 7:  routines or welcome home routines. There, there is so much more that we could

1027
01:06:17,365 --> 01:06:21,045
Speaker 7:  be doing with our homes. I think that was a slightly uninspired

1028
01:06:21,075 --> 01:06:24,965
Speaker 7:  example, but I, I think that people that are gonna be taking

1029
01:06:24,965 --> 01:06:28,805
Speaker 7:  advantage of this really it will be the smart home device makers. I'd be

1030
01:06:28,805 --> 01:06:32,445
Speaker 7:  interested to see if you know Uber or Airbnb

1031
01:06:32,725 --> 01:06:36,445
Speaker 7:  I could see potentially taking some real advantage of this

1032
01:06:36,825 --> 01:06:40,765
Speaker 7:  and companies that are sort of home related if not necessarily

1033
01:06:40,775 --> 01:06:44,725
Speaker 7:  smart home related. So I think, I think there's a lot of potential but

1034
01:06:44,725 --> 01:06:47,245
Speaker 7:  like all of these developer conferences, it, you know, these announcements

1035
01:06:47,245 --> 01:06:50,605
Speaker 7:  we get, it really is gonna depend on how much this has inspired

1036
01:06:50,895 --> 01:06:54,885
Speaker 7:  developers to go out and and do something. So we will, we'll have

1037
01:06:54,885 --> 01:06:55,485
Speaker 7:  to wait and see.

1038
01:06:55,945 --> 01:06:59,925
Speaker 3:  It feels like a fun moment in that sense that there's actually a lot

1039
01:06:59,945 --> 01:07:03,925
Speaker 3:  of sort of new fun toys for anyone working in the smart home

1040
01:07:03,985 --> 01:07:07,605
Speaker 3:  to play with between all the new stuff coming in matter and what

1041
01:07:07,605 --> 01:07:11,205
Speaker 3:  Google's up to and obviously Amazon is continuing to invest in Alexa and

1042
01:07:11,205 --> 01:07:14,885
Speaker 3:  it's like it, there's just sort of more stuff to work with

1043
01:07:15,035 --> 01:07:19,005
Speaker 3:  than there has been. Yeah. Which I guess means we're probably due for some

1044
01:07:19,005 --> 01:07:22,965
Speaker 3:  more chaos in the near term but also maybe means a lot

1045
01:07:22,965 --> 01:07:26,805
Speaker 3:  of this stuff that has just been sort of theory waiting for

1046
01:07:26,805 --> 01:07:30,725
Speaker 3:  infrastructure is like starting to become real, which I think is really cool.

1047
01:07:31,195 --> 01:07:34,205
Speaker 7:  Yeah, I think you're right and it is, it is an exciting time and you know,

1048
01:07:34,205 --> 01:07:37,565
Speaker 7:  we mentioned that this was sort of the end of a cycle for one load lot of

1049
01:07:37,565 --> 01:07:40,645
Speaker 7:  startups in the smart home, but it is the potential beginning of a cycle.

1050
01:07:40,765 --> 01:07:43,325
Speaker 7:  I mean there's a couple smart, smart home startups I've been talking with

1051
01:07:43,325 --> 01:07:46,885
Speaker 7:  over the last few months who have some great products that they're ready

1052
01:07:46,885 --> 01:07:50,285
Speaker 7:  to launch, but they're still just been waiting on this type of infrastructure

1053
01:07:50,905 --> 01:07:54,765
Speaker 7:  to come along to make it possible. And whilst the

1054
01:07:54,855 --> 01:07:58,765
Speaker 7:  signs are there, and this is one thing that I was quite disappointed about

1055
01:07:58,765 --> 01:08:02,445
Speaker 7:  with Matter 1.3, is that we still don't have the support

1056
01:08:02,595 --> 01:08:06,485
Speaker 7:  from platforms. I mean Google's opening up its APIs was a, was a nice

1057
01:08:06,485 --> 01:08:10,325
Speaker 7:  step in the right direction, but they still don't support half of the

1058
01:08:10,325 --> 01:08:14,245
Speaker 7:  new device types that are in matter 1.3. Apple hasn't, hasn't gone

1059
01:08:14,245 --> 01:08:17,965
Speaker 7:  beyond matter 1.0. I mean if we are lucky, we may get 1.2

1060
01:08:17,965 --> 01:08:20,925
Speaker 7:  devices, which are robot vacuums, washing machines,

1061
01:08:21,675 --> 01:08:25,525
Speaker 7:  fridges in Apple home with iOS 18 if we're lucky.

1062
01:08:25,745 --> 01:08:29,485
Speaker 7:  But that means another whole year until we get tumble dryers, right.

1063
01:08:29,625 --> 01:08:33,605
Speaker 7:  So I just, I really hope that the platforms and Amazon's been very

1064
01:08:33,605 --> 01:08:37,565
Speaker 7:  slow here. Samsung's been a little faster and I get why they're being

1065
01:08:37,565 --> 01:08:41,445
Speaker 7:  slow to some extent they don't wanna break people's homes, but if we

1066
01:08:41,445 --> 01:08:45,245
Speaker 7:  don't start getting this out there and the consumers get to use it

1067
01:08:45,265 --> 01:08:48,845
Speaker 7:  and get excited about it, then we are not gonna get the developers coming

1068
01:08:48,865 --> 01:08:52,765
Speaker 7:  on board and making these good experiences. You know, we need, we

1069
01:08:52,765 --> 01:08:56,565
Speaker 7:  need both sides of, of the solution here to, to get people

1070
01:08:56,565 --> 01:09:00,245
Speaker 7:  excited. So I really wanna see Apple, Google, Amazon,

1071
01:09:00,355 --> 01:09:04,245
Speaker 7:  Samsung, just go all in on what this, this platform,

1072
01:09:04,245 --> 01:09:08,125
Speaker 7:  this protocol, this smart home standard that they've developed to

1073
01:09:08,125 --> 01:09:12,085
Speaker 7:  solve this problem. They can't just leave it there now that

1074
01:09:12,085 --> 01:09:15,565
Speaker 7:  they've, yeah, now they brought it to life. They've really got to put the

1075
01:09:15,565 --> 01:09:19,285
Speaker 7:  work in and see this through and so far

1076
01:09:19,315 --> 01:09:22,645
Speaker 7:  it's been pretty limited and that's been quite disappointing. So I'm hoping

1077
01:09:22,645 --> 01:09:26,365
Speaker 7:  that we'll hear something exciting at WWC next month. I'm not

1078
01:09:26,365 --> 01:09:29,925
Speaker 7:  holding my breath, I think it's just gonna be all about ai but

1079
01:09:30,325 --> 01:09:31,925
Speaker 7:  yeah, I may be wrong. I

1080
01:09:31,925 --> 01:09:33,205
Speaker 3:  Suspect, I suspect you're right.

1081
01:09:33,295 --> 01:09:35,165
Speaker 7:  Prove me wrong, apple. Yeah,

1082
01:09:35,555 --> 01:09:38,965
Speaker 3:  Fingers crossed. All right, before we go, you've been playing with tons of

1083
01:09:39,105 --> 01:09:43,045
Speaker 3:  new smart home gadgets. What give me, give me your favorite coolest thing

1084
01:09:43,045 --> 01:09:44,685
Speaker 3:  you've been playing with recently. Oh,

1085
01:09:44,955 --> 01:09:48,005
Speaker 7:  Well actually I have, I have to go with my smart chicken coop.

1086
01:09:48,155 --> 01:09:49,045
Speaker 3:  Okay. Do tell.

1087
01:09:49,385 --> 01:09:53,325
Speaker 7:  Yes, I am been testing a new smart chicken coop, it's

1088
01:09:53,325 --> 01:09:57,285
Speaker 7:  called Coop and it is a startup based out

1089
01:09:57,285 --> 01:10:00,965
Speaker 7:  in California and it has, it is very well designed chicken

1090
01:10:01,035 --> 01:10:05,005
Speaker 7:  coop, but the main kind of smart features, it has two cameras in with

1091
01:10:05,265 --> 01:10:09,005
Speaker 7:  really impressive AI capabilities. So it can tell me

1092
01:10:09,185 --> 01:10:13,085
Speaker 7:  if the door of the coop is open, it can tell me if there's an egg laid,

1093
01:10:13,705 --> 01:10:17,685
Speaker 7:  it can count how many chickens are in my coop. So in case one's gone

1094
01:10:17,685 --> 01:10:21,405
Speaker 7:  missing. and it will also tell me if it's spots like a fox or coyote or if

1095
01:10:21,405 --> 01:10:25,045
Speaker 7:  it's spots a, a cat or a bobcat. Like different

1096
01:10:25,285 --> 01:10:29,085
Speaker 7:  predators, different nuisance animals. Like it has some really interesting

1097
01:10:29,345 --> 01:10:33,325
Speaker 7:  AI capabilities as well as the automatic door that will

1098
01:10:33,325 --> 01:10:37,285
Speaker 7:  open and close at the right time based on sunrise or sunset

1099
01:10:37,425 --> 01:10:41,045
Speaker 7:  so that the chicks go in and out. I have baby chicks right now. I got new

1100
01:10:41,045 --> 01:10:44,685
Speaker 7:  ones to test out this coop 'cause my, my ladies were too big to fit in this

1101
01:10:44,755 --> 01:10:48,685
Speaker 7:  coop. It's quite small, but it's been a lot of fun. It's just, I

1102
01:10:48,685 --> 01:10:51,085
Speaker 7:  mean, baby chicks, I mean it's, that's fun.

1103
01:10:51,385 --> 01:10:52,445
Speaker 3:  You can't, you can't beat it,

1104
01:10:52,545 --> 01:10:55,405
Speaker 7:  You can't beat that. It's very expensive. I think. I wanna say it's like

1105
01:10:55,405 --> 01:10:59,205
Speaker 7:  $2,500, but having built my own chicken coop with

1106
01:10:59,205 --> 01:11:03,085
Speaker 7:  wood, well having watched my husband build our own

1107
01:11:03,085 --> 01:11:06,605
Speaker 7:  chicken coop and helped buy the stuff at Lowe's,

1108
01:11:06,605 --> 01:11:10,245
Speaker 7:  they're not cheap. You know, it's an expensive product

1109
01:11:10,355 --> 01:11:13,815
Speaker 7:  whether you buy one or build one. So it's interesting to see this kind of

1110
01:11:13,815 --> 01:11:17,775
Speaker 7:  innovation, smart home innovation, sort of moving outside of the

1111
01:11:17,775 --> 01:11:21,535
Speaker 7:  home and into the garden and you know, homesteading with

1112
01:11:21,695 --> 01:11:22,095
Speaker 7:  McChickens.

1113
01:15:00,355 --> 01:15:04,135
Speaker 11:  ARC browser is AI generating whole kind of webpages every time you search

1114
01:15:04,135 --> 01:15:07,695
Speaker 11:  something on your phone. And then I'm one of the 12 people that uses

1115
01:15:08,005 --> 01:15:11,415
Speaker 11:  Edge at Work and I actually use BIN to search because then it will

1116
01:15:11,725 --> 01:15:15,615
Speaker 11:  auto generate a response with copilot first and then kind give me all

1117
01:15:15,615 --> 01:15:19,575
Speaker 11:  the web results. So when you know Google was telling Eli that that's actually

1118
01:15:19,575 --> 01:15:21,695
Speaker 11:  something they're experiencing, that the people have higher click through

1119
01:15:21,695 --> 01:15:24,815
Speaker 11:  rates from those generated responses. I mean I can really back that up because

1120
01:15:24,835 --> 01:15:28,775
Speaker 11:  that's exactly what I do and, and so I'm wondering is the problem just that

1121
01:15:28,775 --> 01:15:32,615
Speaker 11:  Google's doing it, is the problem that they're so large that if they're

1122
01:15:32,615 --> 01:15:36,415
Speaker 11:  doing this, this impacts the way that the search world works?

1123
01:15:36,555 --> 01:15:40,335
Speaker 11:  You know, because obviously they're top dog and that when the Edge browser

1124
01:15:40,515 --> 01:15:43,175
Speaker 11:  and when the ARC browser are doing this, that doesn't really matter because

1125
01:15:43,175 --> 01:15:47,015
Speaker 11:  they're just not the dominant search. I feel like that's maybe the argument

1126
01:15:47,015 --> 01:15:50,215
Speaker 11:  here. So I was just wondering what your guys' thoughts were on that. If

1127
01:15:50,215 --> 01:15:53,695
Speaker 11:  it's just a matter of scale, not a matter of what they're doing or if there's

1128
01:15:53,695 --> 01:15:54,975
Speaker 11:  more to this. Thanks guys.

1129
01:15:55,685 --> 01:15:59,335
Speaker 3:  Okay. I think the answer to this question is mostly yes,

1130
01:15:59,755 --> 01:16:03,695
Speaker 3:  but kind of yes and no. I think on the one hand, the scale

1131
01:16:03,875 --> 01:16:07,775
Speaker 3:  of Google is the thing you just can't overstate the

1132
01:16:07,795 --> 01:16:11,775
Speaker 3:  extent to which Google is the center of the internet. For anyone who makes

1133
01:16:11,775 --> 01:16:15,655
Speaker 3:  a website, whether it's a cooking blog or a news site or just a

1134
01:16:15,655 --> 01:16:19,455
Speaker 3:  place to show off your photography, Google is the internet. It is

1135
01:16:19,455 --> 01:16:23,415
Speaker 3:  the main discovery tool of the internet. So what you've seen

1136
01:16:23,875 --> 01:16:27,855
Speaker 3:  is everything over the last, I don't know, 15 years really

1137
01:16:28,315 --> 01:16:32,295
Speaker 3:  has reshaped in order to work the way that Google has asked it to work.

1138
01:16:32,475 --> 01:16:36,375
Speaker 3:  You see cooking blogs just to keep harping on that, they

1139
01:16:36,375 --> 01:16:40,175
Speaker 3:  have changed the way that they make their pages in order to suit Google.

1140
01:16:40,475 --> 01:16:43,895
Speaker 3:  The thing where at the bottom you have the recipe, but at the top you have,

1141
01:16:43,915 --> 01:16:47,215
Speaker 3:  you know, 2000 words of stories about the person and there's a bunch of photos

1142
01:16:47,215 --> 01:16:50,935
Speaker 3:  and there's a bunch of sub headlines that are all kind of questions that

1143
01:16:50,945 --> 01:16:54,895
Speaker 3:  don't really fit but are questions people might be Googling. All of that

1144
01:16:55,315 --> 01:16:58,415
Speaker 3:  is designed for Google. The SEO search engine optimization

1145
01:16:59,155 --> 01:17:02,335
Speaker 3:  has completely reshaped the web. This is a thing we've talked a lot about

1146
01:17:02,795 --> 01:17:05,735
Speaker 3:  on the show. This is a thing we've written a lot about on the site. I'll

1147
01:17:05,735 --> 01:17:09,445
Speaker 3:  put some links in the show notes, but Google has fundamentally reshaped the

1148
01:17:09,445 --> 01:17:13,285
Speaker 3:  web because it is so important because when people want to find

1149
01:17:13,285 --> 01:17:17,165
Speaker 3:  things on the internet, they don't go other places. And I think the Arc

1150
01:17:17,165 --> 01:17:20,725
Speaker 3:  search and Bing are instructive examples here actually because

1151
01:17:21,195 --> 01:17:24,805
Speaker 3:  it's true that Bing has been doing this longer than Google. You could

1152
01:17:24,805 --> 01:17:28,525
Speaker 3:  already AI your way through the internet with Bing. And

1153
01:17:28,835 --> 01:17:32,005
Speaker 3:  it's not that no one noticed, but no one really cared because Bing is not

1154
01:17:32,335 --> 01:17:35,925
Speaker 3:  meaningful to the traffic and revenue and

1155
01:17:35,925 --> 01:17:39,485
Speaker 3:  existence of websites in the way that Google is. It just

1156
01:17:39,795 --> 01:17:43,165
Speaker 3:  does not matter what everybody else does cumulative

1157
01:17:43,625 --> 01:17:47,365
Speaker 3:  in the same way that it does what Google does. Google has something like

1158
01:17:47,545 --> 01:17:51,485
Speaker 3:  90% of the search on the internet. That's

1159
01:17:51,485 --> 01:17:54,645
Speaker 3:  a crazy number. That is one of the things that has brought Google into the

1160
01:17:54,675 --> 01:17:58,565
Speaker 3:  antitrust scrutiny that it has because it is so powerful because it

1161
01:17:58,585 --> 01:18:02,485
Speaker 3:  has no real meaningful competitor. The flip side of that is

1162
01:18:02,515 --> 01:18:06,365
Speaker 3:  that I think the things that we're talking about apply just as much

1163
01:18:06,625 --> 01:18:09,485
Speaker 3:  to these other things you're talking about. When Arc, for instance, rolled

1164
01:18:09,505 --> 01:18:13,485
Speaker 3:  out the browse for me feature where you type in a search query, you hit

1165
01:18:13,485 --> 01:18:17,285
Speaker 3:  browse for me and instead of giving you a bunch of search results, it sort

1166
01:18:17,285 --> 01:18:20,525
Speaker 3:  of compiles a webpage for you, which is a lot like what the AI overviews

1167
01:18:20,525 --> 01:18:23,645
Speaker 3:  on Google are doing. It gives you the summary and then some links and some

1168
01:18:23,645 --> 01:18:27,165
Speaker 3:  multimedia stuff. People had the same kind of visceral

1169
01:18:27,565 --> 01:18:31,285
Speaker 3:  reaction, which is that it felt like this exchange of value

1170
01:18:31,395 --> 01:18:35,005
Speaker 3:  that people who make websites have with Discovery tools

1171
01:18:35,625 --> 01:18:39,325
Speaker 3:  was gone. Right? The idea for two decades has been that

1172
01:18:39,565 --> 01:18:42,765
Speaker 3:  I am going to make something and I'm going to let Google

1173
01:18:43,385 --> 01:18:47,365
Speaker 3:  access it and index it and cache it on its servers and make ads when people

1174
01:18:47,385 --> 01:18:51,045
Speaker 3:  try to find it in exchange for sending traffic to my

1175
01:18:51,045 --> 01:18:55,005
Speaker 3:  website and the idea that I could monetize or in other

1176
01:18:55,005 --> 01:18:58,845
Speaker 3:  ways benefit from the traffic to my website. That was the trade Google

1177
01:18:58,955 --> 01:19:02,645
Speaker 3:  gets to have and have access to. And in some ways sort of

1178
01:19:02,645 --> 01:19:06,365
Speaker 3:  intermediate how people find my website because it sends people to my

1179
01:19:06,365 --> 01:19:09,765
Speaker 3:  website. That is the trade, that is the trade people have made on the internet

1180
01:19:10,105 --> 01:19:14,045
Speaker 3:  for 20 years. That feels different when it's ai.

1181
01:19:14,185 --> 01:19:17,765
Speaker 3:  And I think the way people reacted to Arc, there have been people who said

1182
01:19:17,765 --> 01:19:21,005
Speaker 3:  this with Bing, there have been people who worried about this with perplexity.

1183
01:19:21,385 --> 01:19:25,205
Speaker 3:  All of these tools run into the same thing, which is they shortcut that

1184
01:19:25,315 --> 01:19:29,165
Speaker 3:  they, they completely end around that exchange of value and just say,

1185
01:19:29,455 --> 01:19:33,245
Speaker 3:  don't worry, I went and visited all those webpages for you and brought back

1186
01:19:33,245 --> 01:19:37,125
Speaker 3:  the information that you need. Nevermind that the crawler on that

1187
01:19:37,195 --> 01:19:41,165
Speaker 3:  webpage doesn't accrue me any advertising money. It's not going to click

1188
01:19:41,165 --> 01:19:45,085
Speaker 3:  my affiliate links, it's not going to be impressed with my stuff

1189
01:19:45,145 --> 01:19:48,965
Speaker 3:  and read more articles. It's not going to make the cookies

1190
01:19:49,035 --> 01:19:52,765
Speaker 3:  that I suggested and then save it and tell friends about it and bring more

1191
01:19:52,765 --> 01:19:56,645
Speaker 3:  traffic. It doesn't do any of that. It just pulled it into a

1192
01:19:56,845 --> 01:20:00,685
Speaker 3:  database and spat out the information with essentially no link

1193
01:20:00,685 --> 01:20:04,565
Speaker 3:  back to the original source of the information and certainly no reason

1194
01:20:04,825 --> 01:20:07,805
Speaker 3:  to go find the source of that information because I've already given you

1195
01:20:07,805 --> 01:20:11,485
Speaker 3:  everything you need right here in the summary. On the one hand, cool user

1196
01:20:11,485 --> 01:20:14,925
Speaker 3:  experience for lots of things, on the other hand totally breaks the value

1197
01:20:15,125 --> 01:20:18,685
Speaker 3:  exchange of the internet, right? So I think the thesis is not that different

1198
01:20:18,755 --> 01:20:22,725
Speaker 3:  between what you're seeing from all of these AI companies and what you're

1199
01:20:22,725 --> 01:20:26,165
Speaker 3:  seeing from Google. The difference is just the scale. And

1200
01:20:26,385 --> 01:20:30,165
Speaker 3:  Google has been existentially important to

1201
01:20:30,525 --> 01:20:34,205
Speaker 3:  websites for two decades in a way that I think has been problematic for a

1202
01:20:34,205 --> 01:20:38,005
Speaker 3:  really long time. There is this sense that Google won in

1203
01:20:38,005 --> 01:20:41,685
Speaker 3:  some way that Google became the arbiter of the internet and that the only

1204
01:20:41,685 --> 01:20:45,325
Speaker 3:  thing to do as a media company or as a cooking

1205
01:20:45,435 --> 01:20:49,205
Speaker 3:  blog or as a person with a website of any kind was to

1206
01:20:49,395 --> 01:20:53,085
Speaker 3:  play Google's game or try to find a way to get money from Google

1207
01:20:53,805 --> 01:20:57,285
Speaker 3:  directly. And so you've seen a lot of these fights over the years of companies

1208
01:20:57,355 --> 01:21:01,205
Speaker 3:  like News Corp picking fights with Google and saying, you have to

1209
01:21:01,425 --> 01:21:04,805
Speaker 3:  pay us for our content or we're going to

1210
01:21:04,995 --> 01:21:08,685
Speaker 3:  disappear. And I think what has been true forever is that these websites

1211
01:21:08,685 --> 01:21:12,045
Speaker 3:  have needed Google more than Google has needed these websites. And that has

1212
01:21:12,045 --> 01:21:15,445
Speaker 3:  been a challenge. And one thing you've heard us talk about, and Neli in particular

1213
01:21:15,445 --> 01:21:19,325
Speaker 3:  talks about this is that Google doesn't actually owe these

1214
01:21:19,365 --> 01:21:23,285
Speaker 3:  websites anything. And I think Google would tell you that it

1215
01:21:23,335 --> 01:21:26,445
Speaker 3:  cares about them and believes in the web and wants to preserve the open web.

1216
01:21:26,745 --> 01:21:30,565
Speaker 3:  That's all really easy to say out loud. And it's also

1217
01:21:31,105 --> 01:21:34,965
Speaker 3:  not particularly meaningful when Google is able to do the

1218
01:21:34,965 --> 01:21:38,405
Speaker 3:  things that it's doing now, which is say, well, our responsibility is actually

1219
01:21:38,405 --> 01:21:42,165
Speaker 3:  to get users to the information that they want as quickly as possible. And

1220
01:21:42,165 --> 01:21:45,925
Speaker 3:  again, that's actually an interesting product argument. It subverts a huge

1221
01:21:45,925 --> 01:21:49,085
Speaker 3:  amount of the way that the internet has worked in part because all of these

1222
01:21:49,085 --> 01:21:52,765
Speaker 3:  websites are so reliant on Google and what Google has meant to them for so

1223
01:21:52,765 --> 01:21:56,365
Speaker 3:  long. This is what we went through with Facebook when Facebook made everybody

1224
01:21:56,365 --> 01:22:00,125
Speaker 3:  pivot to video with the promises of huge amounts of traffic and tons of money

1225
01:22:00,145 --> 01:22:03,925
Speaker 3:  and then that all sort of dried up and everybody kind of got used to Facebook's

1226
01:22:04,175 --> 01:22:08,045
Speaker 3:  wishy washiness and back and forth on supporting websites and caring

1227
01:22:08,045 --> 01:22:11,965
Speaker 3:  about traffic outside and eventually just realized, well, okay, we're gonna

1228
01:22:11,965 --> 01:22:15,645
Speaker 3:  treat Facebook as kind of a a value add, right? If we get traffic from Facebook,

1229
01:22:16,005 --> 01:22:19,885
Speaker 3:  terrific, but I'm not going to bend over backwards in order to get traffic

1230
01:22:19,885 --> 01:22:23,605
Speaker 3:  from Facebook. And that hurt a lot of websites traffic. There are a lot of

1231
01:22:23,605 --> 01:22:27,485
Speaker 3:  websites that went away when Facebook stopped sending them traffic. And

1232
01:22:27,945 --> 01:22:31,445
Speaker 3:  the same has never really happened with Google in part because Google

1233
01:22:31,955 --> 01:22:35,765
Speaker 3:  more or less remained a good citizen of that value

1234
01:22:36,085 --> 01:22:39,925
Speaker 3:  exchange we're talking about until now. And there's a lot left

1235
01:22:40,025 --> 01:22:43,805
Speaker 3:  to be seen. I think it's possible, as Nathan says, that really great

1236
01:22:43,805 --> 01:22:47,725
Speaker 3:  content is going to be more prioritized. And the

1237
01:22:47,885 --> 01:22:51,805
Speaker 3:  question will be what happens to the folks who write this

1238
01:22:51,805 --> 01:22:55,605
Speaker 3:  sort of commodity stuff? Like I think a lot about the articles years ago

1239
01:22:55,605 --> 01:22:59,005
Speaker 3:  that every time John Oliver would post anything, every website on the internet

1240
01:22:59,005 --> 01:23:02,725
Speaker 3:  would be like John Oliver roasts the whoever, right? Like he gets mad about

1241
01:23:02,745 --> 01:23:06,405
Speaker 3:  hotdog and lots of people cared about what John Oliver did, so they would

1242
01:23:06,405 --> 01:23:10,045
Speaker 3:  google John Oliver on a Monday morning after the Sunday night show and whoever

1243
01:23:10,045 --> 01:23:13,965
Speaker 3:  was at the top of search results made a ton of money and got a lot of traffic.

1244
01:23:14,275 --> 01:23:18,085
Speaker 3:  That was always kind of a weird game. And I think you could reasonably argue

1245
01:23:18,085 --> 01:23:20,885
Speaker 3:  that the best outcome is actually just that you get to John Oliver much more

1246
01:23:20,885 --> 01:23:24,645
Speaker 3:  quickly instead of a website talking about John Oliver. But

1247
01:23:24,915 --> 01:23:28,805
Speaker 3:  what if there's really great unique context added or lots

1248
01:23:28,805 --> 01:23:32,765
Speaker 3:  of interesting new information or somebody did good reporting on top

1249
01:23:32,765 --> 01:23:36,205
Speaker 3:  of the reporting that John Oliver did. This question of that sort of sliding

1250
01:23:36,205 --> 01:23:39,725
Speaker 3:  scale between what is commodity information that

1251
01:23:40,125 --> 01:23:43,685
Speaker 3:  everyone should know and no one has particular claim to. Like when was Abraham

1252
01:23:43,685 --> 01:23:46,805
Speaker 3:  Lincoln born? That is just a question. It doesn't matter who has the answer.

1253
01:23:47,215 --> 01:23:51,165
Speaker 3:  There are not particularly interesting reasons to go to one place or another

1254
01:23:51,165 --> 01:23:54,725
Speaker 3:  for the answer. I just want to know when Abraham Lincoln was born all the

1255
01:23:54,725 --> 01:23:58,605
Speaker 3:  way down to like truly great original stuff, whether

1256
01:23:58,605 --> 01:24:02,285
Speaker 3:  it's a new recipe or new art that somebody made or

1257
01:24:02,685 --> 01:24:06,365
Speaker 3:  a new essay from somebody smart that you like or original

1258
01:24:06,365 --> 01:24:09,485
Speaker 3:  reporting in the news business, Google is now in a position of having to

1259
01:24:09,545 --> 01:24:13,365
Speaker 3:  decide where one of those things ends and the other begins and

1260
01:24:13,585 --> 01:24:17,565
Speaker 3:  is also just making this bet, or at least this promise to publishers that,

1261
01:24:17,865 --> 01:24:21,485
Speaker 3:  oh, we're going to get so much better at giving people information that they're

1262
01:24:21,605 --> 01:24:24,245
Speaker 3:  actually going to be more curious and they're gonna wanna know more stuff.

1263
01:24:24,585 --> 01:24:28,445
Speaker 3:  I'm very suspicious of that argument to be totally honest. Google is like,

1264
01:24:28,445 --> 01:24:32,125
Speaker 3:  if we just Surface better stuff to more people, more people will click on

1265
01:24:32,125 --> 01:24:36,005
Speaker 3:  it. As somebody who makes their living making things on the internet, I sure

1266
01:24:36,005 --> 01:24:39,925
Speaker 3:  hope that's true. I'm not confident that that's true, but it does put

1267
01:24:39,925 --> 01:24:43,765
Speaker 3:  Google back in this position of once again being the arbiter

1268
01:24:43,785 --> 01:24:47,765
Speaker 3:  of all of this stuff. And I think you'll see us talk a lot more in the

1269
01:24:47,765 --> 01:24:51,285
Speaker 3:  near future about different kinds of search engines because I think search

1270
01:24:51,285 --> 01:24:54,925
Speaker 3:  engines are great, right? Like what Google was for a really long time

1271
01:24:55,425 --> 01:24:59,085
Speaker 3:  was really valuable to a lot of people and I think Google has shifted away

1272
01:24:59,085 --> 01:25:02,845
Speaker 3:  from that to something else. That new thing might be great, it might be

1273
01:25:02,845 --> 01:25:06,485
Speaker 3:  different, it might be terrible, who knows? But I think there's going to

1274
01:25:06,485 --> 01:25:09,765
Speaker 3:  be interesting competition in this space for a long time because Google is

1275
01:25:09,765 --> 01:25:13,525
Speaker 3:  kind of running away from the thing that people loved about it. And

1276
01:25:13,915 --> 01:25:17,805
Speaker 3:  that is weird to me to be totally honest, that there are a lot

1277
01:25:17,805 --> 01:25:20,885
Speaker 3:  of companies that you can understand why they pivot. Google is taking this

1278
01:25:21,275 --> 01:25:25,245
Speaker 3:  beloved, wildly successful business and kind of pivoting

1279
01:25:25,275 --> 01:25:28,645
Speaker 3:  away from it. And I think you're gonna see a lot of folks come in and say,

1280
01:25:29,075 --> 01:25:32,925
Speaker 3:  well actually search was both a good product and a good business and maybe

1281
01:25:33,155 --> 01:25:37,045
Speaker 3:  what we need to do is be part of that because Google is going to just leave

1282
01:25:37,045 --> 01:25:40,485
Speaker 3:  that gap open in the market again. So I think all of this is gonna get

1283
01:25:40,755 --> 01:25:44,445
Speaker 3:  more interesting and more competitive, but also the immediate threat to

1284
01:25:44,575 --> 01:25:48,565
Speaker 3:  publishers and bloggers and anyone who makes a website on the internet is

1285
01:25:48,565 --> 01:25:52,525
Speaker 3:  that all of a sudden it could just dry up traffic. Google

1286
01:25:52,625 --> 01:25:56,365
Speaker 3:  has made changes before that. People have turned around and said, oh, Google

1287
01:25:56,435 --> 01:26:00,325
Speaker 3:  made a small algorithm change and my website essentially disappeared

1288
01:26:00,325 --> 01:26:03,485
Speaker 3:  from the internet. That's a real thing that happens. and it happens to bad

1289
01:26:03,485 --> 01:26:06,885
Speaker 3:  websites that probably should have their spammy stuff removed from Google

1290
01:26:06,905 --> 01:26:10,885
Speaker 3:  search. and it applies to really great websites that don't deserve

1291
01:26:10,885 --> 01:26:14,045
Speaker 3:  that and just get caught up in Google's changes for whatever reason. And

1292
01:26:14,295 --> 01:26:18,085
Speaker 3:  we're already seeing with these AI overviews, lots of unintended

1293
01:26:18,395 --> 01:26:21,725
Speaker 3:  weirdness. There's, there's always people out there posting stuff about,

1294
01:26:22,085 --> 01:26:25,725
Speaker 3:  I think there was one that it was like add glue to your pizza sauce to make

1295
01:26:25,725 --> 01:26:29,645
Speaker 3:  it stickier. Like don't do that. But that's the stuff that's out

1296
01:26:29,645 --> 01:26:33,445
Speaker 3:  there now. So we're at the beginning of a thing that Google has just

1297
01:26:33,465 --> 01:26:35,085
Speaker 3:  turned on and is making a

1298
01:27:45,085 --> 01:27:48,725
Speaker 3:  our best. As always, if you have thoughts, questions, feelings, Surface

1299
01:28:13,865 --> 01:28:16,805
Speaker 3:  and Wil Poor The. Vergecast is a VERGE production and part of the Vox Media

1300
01:28:16,805 --> 01:28:20,605
Speaker 3:  podcast network. Neli, Alex, and I'll be back on Friday to talk

1301
01:28:20,605 --> 01:28:24,445
Speaker 3:  about presumably more open AI shenanigans, all the stuff

1302
01:28:24,445 --> 01:28:28,285
Speaker 3:  that's to come at WWDC and lots more. See you then. Rock and roll.

