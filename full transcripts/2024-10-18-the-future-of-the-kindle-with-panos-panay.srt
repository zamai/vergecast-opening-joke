1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: bcb60977-d8c1-487b-810b-ccfc202f30e4
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-4867592338036987258/-5935121345743156612/s93290-US-6948s-1729248121.mp3
Description: Nilay and David talk about the week in gadget news, after scoring their predictions on last week's Tesla event. (Spoiler alert: nobody did very well.) They talk about the new iPad Mini, the new Sonos Ace Ultra soundbar, and the new Analogue N64 emulator. Then Amazon's Panos Panay joins the show to discuss this week's big Kindle news, and where he thinks the future of e-readers is headed. Finally, Nilay and David do a lightning round, with a lot of Google org chart news and just a little bit of Trump news.

2
00:00:45,735 --> 00:00:49,565
Speaker 3:  Hello and welcome to Vergecast, the flagship podcast of knowing that you

3
00:00:49,565 --> 00:00:52,325
Speaker 3:  should just always take the over on Tesla ship dates.

4
00:00:53,945 --> 00:00:57,205
Speaker 3:  I'm not a betting person. That's not a thing that I do. I spend my money

5
00:00:57,205 --> 00:01:00,205
Speaker 3:  in Vegas in limousines. Famous, famous personality trait of mine.

6
00:01:02,185 --> 00:01:05,325
Speaker 3:  But if FanDuel ever offers bet on Tesla ship dates, I might get into it.

7
00:01:05,345 --> 00:01:06,645
Speaker 3:  I'm the, I'm just putting it out there.

8
00:01:07,025 --> 00:01:09,525
Speaker 4:  Listen, if I've learned one thing about the internet, it's that you can bet

9
00:01:09,525 --> 00:01:13,405
Speaker 4:  on anything somewhere on poly market. You can bet on Elon Musk and the

10
00:01:13,405 --> 00:01:14,805
Speaker 4:  cyber cab. I'm confident.

11
00:01:15,025 --> 00:01:17,565
Speaker 3:  Do you think he's just taking the other side of that bet that that's his

12
00:01:17,595 --> 00:01:18,765
Speaker 3:  plan to fund Twitter?

13
00:01:19,385 --> 00:01:20,885
Speaker 4:  He just gets it coming and going, man.

14
00:01:21,025 --> 00:01:24,205
Speaker 3:  Hi, I'm your friend Eli. That's David Pierce. Hey David. Hello. We've got

15
00:01:24,245 --> 00:01:27,765
Speaker 3:  a good episode. We're gonna go over our bets from last week on the

16
00:01:28,275 --> 00:01:31,605
Speaker 3:  Robo Taxii announcement. Apple announce New iPad

17
00:01:31,935 --> 00:01:35,685
Speaker 3:  minis. There's some weird intel news to talk about.

18
00:01:36,685 --> 00:01:40,295
Speaker 3:  There's a really cute Nintendo 64 emulator that I want to get into.

19
00:01:40,445 --> 00:01:44,415
Speaker 3:  Yeah. But also Amazon's Panos pane is on the show this week. There was

20
00:01:44,415 --> 00:01:48,295
Speaker 3:  a Kindle event. David went to it, Panos came to the studio. We hung

21
00:01:48,295 --> 00:01:50,975
Speaker 3:  out with him for a while. We tried to get him to say, what's going on for

22
00:01:50,975 --> 00:01:54,935
Speaker 3:  Alexa? He declined and then we got a lightning round. It's gonna

23
00:01:54,935 --> 00:01:58,335
Speaker 3:  be amazing. It's the, it's The Vergecast. It's a, it's a good one. Let's

24
00:01:58,335 --> 00:02:02,165
Speaker 3:  start, David, with our bets. So we

25
00:02:02,165 --> 00:02:06,125
Speaker 3:  ran the gimmick last week where we were recording the show before Tesla's

26
00:02:06,125 --> 00:02:09,445
Speaker 3:  robot taxi event and you and I made a bunch of predictions

27
00:02:10,705 --> 00:02:13,045
Speaker 3:  and now we can see if we were correct.

28
00:02:13,545 --> 00:02:16,445
Speaker 4:  You know what's weird is going back through and we'll, we'll, we'll go through

29
00:02:16,445 --> 00:02:20,365
Speaker 4:  it, but I have two regrets that I would like to share. Yeah. Before

30
00:02:20,365 --> 00:02:24,285
Speaker 4:  we get into it, one of my regrets is that I didn't push

31
00:02:24,285 --> 00:02:27,965
Speaker 4:  harder on the, I think this is a thing you're gonna be able to buy. We talked

32
00:02:27,965 --> 00:02:31,125
Speaker 4:  about it briefly and I asked like, wait, do you think that this roboto taxi,

33
00:02:31,125 --> 00:02:33,485
Speaker 4:  they're about to launch is gonna be a thing you can buy? And you were just

34
00:02:33,485 --> 00:02:37,245
Speaker 4:  like, absolutely not. That would be insane. Whoops, here we are.

35
00:02:37,725 --> 00:02:41,125
Speaker 4:  That was not one of your predictions. Carefully, not one of your predictions.

36
00:02:41,125 --> 00:02:43,245
Speaker 4:  Yeah. But it should have been one of mine that it was gonna be something

37
00:02:43,245 --> 00:02:43,645
Speaker 4:  you can buy.

38
00:02:44,725 --> 00:02:46,125
Speaker 3:  I actually still stand by my prediction.

39
00:02:47,165 --> 00:02:47,285
Speaker 4:  I,

40
00:02:47,405 --> 00:02:48,405
Speaker 3:  I want be clear.

41
00:02:49,125 --> 00:02:52,845
Speaker 4:  I mean fair. The problem is we're gonna have to redo who

42
00:02:52,905 --> 00:02:56,725
Speaker 4:  won these predictions like every three months for the next 10 years until

43
00:02:56,725 --> 00:03:00,085
Speaker 4:  these things actually launch and then we'll see who wins. So let me, let

44
00:03:00,085 --> 00:03:03,605
Speaker 4:  me just quickly like run through the news and then we can run through our

45
00:03:03,605 --> 00:03:07,405
Speaker 4:  predictions. And the news I would say was basically two

46
00:03:07,405 --> 00:03:11,365
Speaker 4:  things right there is there was the, the cyber cab and the robo van.

47
00:03:11,885 --> 00:03:13,125
Speaker 4:  There was a bunch of other like, I'm

48
00:03:13,125 --> 00:03:16,685
Speaker 3:  Sorry David, it's pronounced Ovn. You think I'm

49
00:03:16,845 --> 00:03:20,725
Speaker 3:  joking? Wait, listen to Elon pronounce it. No, he

50
00:03:20,725 --> 00:03:21,485
Speaker 3:  says Ovn.

51
00:03:21,595 --> 00:03:22,565
Speaker 4:  It's the Ovn.

52
00:03:23,105 --> 00:03:26,845
Speaker 3:  Yes. And I'm pretty sure that is yet another horrible westward

53
00:03:27,205 --> 00:03:31,005
Speaker 3:  reference that sounds like at the event you could take the robo taxii

54
00:03:31,005 --> 00:03:34,925
Speaker 3:  between two different spots on the map at Warner

55
00:03:34,925 --> 00:03:38,205
Speaker 3:  Brothers on the lot. And one of them was like New York City and one of them

56
00:03:38,205 --> 00:03:41,845
Speaker 3:  was Westworld and If. you stuck it out long enough

57
00:03:41,845 --> 00:03:45,765
Speaker 3:  through Westworld. One of the villains is whatever, it doesn't

58
00:03:45,765 --> 00:03:46,965
Speaker 3:  matter. He said Ovn

59
00:03:47,425 --> 00:03:51,125
Speaker 4:  Ovn is just like the last name of a Midwestern door to door salesman who

60
00:03:51,125 --> 00:03:52,885
Speaker 4:  is just like Thomas Ovn. How you doing?

61
00:03:53,675 --> 00:03:55,685
Speaker 3:  Yeah. Or or it's the all seeing AI in

62
00:03:55,685 --> 00:03:59,645
Speaker 4:  Westworld. Yeah. Or it's that. Well, no, it is not

63
00:03:59,985 --> 00:04:03,005
Speaker 4:  Ovn. I will not acknowledge that it is the robo van.

64
00:04:03,915 --> 00:04:07,165
Speaker 4:  It's fine. It's like when, when Apple was like, no, it's not the iPhone X,

65
00:04:07,165 --> 00:04:10,365
Speaker 4:  it's the iPhone 10. They were wrong. It's the iPhone X and it is the robo

66
00:04:10,365 --> 00:04:11,005
Speaker 4:  van. Wow.

67
00:04:11,835 --> 00:04:12,125
Speaker 3:  Bold.

68
00:04:12,225 --> 00:04:16,045
Speaker 4:  So there was the robo van, the, the robo van named

69
00:04:16,235 --> 00:04:16,525
Speaker 4:  Robo

70
00:04:18,385 --> 00:04:19,485
Speaker 4:  Rob, Rob Boon,

71
00:04:20,305 --> 00:04:22,285
Speaker 3:  Rob ovo. That's great. I'll take that

72
00:04:22,465 --> 00:04:23,645
Speaker 4:  In Europe. It's the Rob of

73
00:04:23,725 --> 00:04:27,165
Speaker 3:  VI just want, again, and I just wanna underline this. All of these things

74
00:04:27,165 --> 00:04:27,565
Speaker 3:  are fake.

75
00:04:28,265 --> 00:04:29,405
Speaker 4:  Yes. They

76
00:04:30,785 --> 00:04:34,645
Speaker 3:  Van, most of all yes. Is not a thing that

77
00:04:34,645 --> 00:04:35,205
Speaker 3:  will occur.

78
00:04:35,395 --> 00:04:38,845
Speaker 4:  Yeah. And one of the things that you said was there, there might be a whiff

79
00:04:38,945 --> 00:04:39,165
Speaker 4:  of,

80
00:04:40,825 --> 00:04:44,605
Speaker 4:  you know, the, the, the supposedly autonomous truck that's actually just

81
00:04:44,605 --> 00:04:45,405
Speaker 4:  rolling downhill.

82
00:04:46,965 --> 00:04:50,725
Speaker 4:  I would not say I'm absolved of all of the, maybe this is not real vibes

83
00:04:50,725 --> 00:04:53,125
Speaker 4:  from this event. But anyway, so those were basically the two things right

84
00:04:53,125 --> 00:04:56,725
Speaker 4:  there was the, the cyber cab was the thing. It has bat

85
00:04:56,775 --> 00:05:00,475
Speaker 4:  wings. It's a two seater car. Looks neat.

86
00:05:00,585 --> 00:05:04,515
Speaker 4:  It's fine. It is supposedly going to be available in 2027.

87
00:05:04,545 --> 00:05:08,315
Speaker 4:  It's supposedly gonna cost less than $30,000. It's just a

88
00:05:08,315 --> 00:05:11,955
Speaker 4:  bunch of words that he said out loud and a

89
00:05:11,955 --> 00:05:12,515
Speaker 4:  prototype.

90
00:05:12,945 --> 00:05:13,235
Speaker 3:  Yeah.

91
00:05:13,545 --> 00:05:16,795
Speaker 4:  It's not nothing like, I wanna be clear, I'm not being dismissive. It's not

92
00:05:16,795 --> 00:05:19,035
Speaker 4:  nothing, but it's not something either.

93
00:05:19,535 --> 00:05:22,475
Speaker 3:  So I just wanna acknowledge this from the start. Our conversation about this

94
00:05:22,695 --> 00:05:26,635
Speaker 3:  is happening in the context of SpaceX catching

95
00:05:27,495 --> 00:05:29,275
Speaker 3:  the Starship booster on

96
00:05:29,275 --> 00:05:30,595
Speaker 4:  The launch tower, which is sick as hell.

97
00:05:30,965 --> 00:05:34,715
Speaker 3:  Which is awesome. Yeah, it is true that sometimes the things

98
00:05:34,715 --> 00:05:38,595
Speaker 3:  happen. Yeah. That is a, a true thing you can say about Elon Musk companies,

99
00:05:39,335 --> 00:05:43,095
Speaker 3:  but mostly about one of them, the one that he doesn't

100
00:05:43,195 --> 00:05:47,175
Speaker 3:  run. Elon Musk companies usually accomplish their goals

101
00:05:47,635 --> 00:05:51,455
Speaker 3:  is a thing you can mostly say about the company that Gwen Shotwell

102
00:05:51,455 --> 00:05:55,265
Speaker 3:  runs. That's it. That's that one. Yes. Tesla

103
00:05:55,565 --> 00:05:59,285
Speaker 3:  on the other hand, has been promising a lot of things for a long time and

104
00:05:59,285 --> 00:06:02,925
Speaker 3:  most of those things don't arrive. And I think it's possible to split them

105
00:06:02,925 --> 00:06:06,805
Speaker 3:  up. I don't think you can say, well, he landed the rocket or caught the

106
00:06:06,805 --> 00:06:10,525
Speaker 3:  rocket in this case. So he will ship the cyber cab in full

107
00:06:10,525 --> 00:06:14,385
Speaker 3:  self-driving. I tho I those things are fundamen like

108
00:06:14,645 --> 00:06:16,865
Speaker 3:  the most deeply unrelated things I can think

109
00:06:16,865 --> 00:06:17,465
Speaker 4:  Of. Totally.

110
00:06:18,005 --> 00:06:20,785
Speaker 3:  For example, Tesla has furious competition.

111
00:06:21,825 --> 00:06:25,705
Speaker 3:  SpaceX does not. In fact, SpaceX's competition is so

112
00:06:25,775 --> 00:06:28,905
Speaker 3:  shit that there are astronauts in space right now. Yeah. The

113
00:06:28,905 --> 00:06:32,785
Speaker 4:  Moment. Yeah. And and including like the government has largely

114
00:06:32,855 --> 00:06:36,505
Speaker 4:  just given SpaceX, everything like that is that is

115
00:06:36,925 --> 00:06:38,265
Speaker 4:  that's a whole different thing. I'm

116
00:06:38,265 --> 00:06:42,185
Speaker 3:  Just saying I just wanted, that's contextually I the people I know and

117
00:06:42,455 --> 00:06:45,865
Speaker 3:  like to read and people I think highly of have

118
00:06:45,865 --> 00:06:49,585
Speaker 3:  conflated these two accomplishments and I I'm just pulling them

119
00:06:49,585 --> 00:06:49,865
Speaker 3:  apart

120
00:06:50,265 --> 00:06:53,945
Speaker 4:  A hundred percent. And I think that's it's useful in another way, which is

121
00:06:53,945 --> 00:06:57,705
Speaker 4:  like we, we always overrate for better and for worse

122
00:06:57,725 --> 00:07:01,225
Speaker 4:  the extent to which A CEO is a company. Right? Like

123
00:07:01,885 --> 00:07:05,865
Speaker 4:  the, the, he doesn't deserve all the blame for the mess of Tesla stuff

124
00:07:05,865 --> 00:07:08,545
Speaker 4:  over the years and he doesn't deserve all of the credit for what SpaceX is

125
00:07:08,545 --> 00:07:12,105
Speaker 4:  doing. Neither of those things is true. I think, I think he probably deserves

126
00:07:12,105 --> 00:07:16,025
Speaker 4:  more blame than credit generally speaking. But like all this is

127
00:07:16,125 --> 00:07:19,065
Speaker 4:  to say, like I actually, I I have found it very useful over the years to

128
00:07:19,065 --> 00:07:22,985
Speaker 4:  think of each of his companies as completely separate things run by separate

129
00:07:22,985 --> 00:07:24,225
Speaker 4:  people. Like

130
00:07:25,905 --> 00:07:29,705
Speaker 4:  X and Tesla increasingly are aligned in ways that are

131
00:07:29,705 --> 00:07:30,825
Speaker 4:  strange and odd

132
00:07:30,925 --> 00:07:34,665
Speaker 3:  And XAI it's the ones he runs and Gwen Shotwell, I, that's it.

133
00:07:34,905 --> 00:07:36,225
Speaker 3:  I mean that's fair. Those are the companies

134
00:07:36,225 --> 00:07:36,985
Speaker 4:  That is, that is fair.

135
00:07:36,985 --> 00:07:40,305
Speaker 3:  They're the companies that Elon runs and then there's Gwen Shotwell who runs

136
00:07:40,305 --> 00:07:44,025
Speaker 3:  Face X and she is by all accounts trusted and visionary and great.

137
00:07:44,255 --> 00:07:47,945
Speaker 3:  Yeah. Okay. But I just wanna separate because the two achievements,

138
00:07:48,225 --> 00:07:51,825
Speaker 3:  it well achievements, the one achievement and the one launch

139
00:07:52,145 --> 00:07:54,905
Speaker 3:  happened in the same timeframe. Right. So everyone thinks one is evidence

140
00:07:54,905 --> 00:07:58,225
Speaker 3:  to the other and, and they're not. And so the cyber cab, which

141
00:07:59,085 --> 00:08:02,505
Speaker 3:  is fine, like people watch this event and in real time

142
00:08:02,695 --> 00:08:06,225
Speaker 3:  they're like, this is fake. Yeah's a guy controlling the car.

143
00:08:07,025 --> 00:08:10,945
Speaker 3:  I dunno if that's true or not. I do know that a a prototype

144
00:08:11,005 --> 00:08:14,065
Speaker 3:  car running around the back lot of a movie set

145
00:08:14,805 --> 00:08:18,745
Speaker 3:  is a thing that we've had for a long time. Yes. Like you can

146
00:08:18,745 --> 00:08:22,595
Speaker 3:  go to Universal Studios today and drive around

147
00:08:22,735 --> 00:08:24,635
Speaker 3:  in a car that appears to be driving itself.

148
00:08:25,025 --> 00:08:28,915
Speaker 4:  Yeah. A hundred and like a a a humanoid seeming robot

149
00:08:28,915 --> 00:08:31,995
Speaker 4:  that's being controlled by somebody else far away. Also a thing we've had

150
00:08:31,995 --> 00:08:35,275
Speaker 4:  for a long time. Yeah. Also a thing that they try to get people very excited

151
00:08:35,275 --> 00:08:38,795
Speaker 4:  about at this event. This is the thing I'm so torn between

152
00:08:40,345 --> 00:08:44,275
Speaker 4:  like where on the spectrum of nothing to something this actually is.

153
00:08:44,435 --> 00:08:48,195
Speaker 4:  Because on the one hand, the whole idea of the cyber

154
00:08:48,335 --> 00:08:51,515
Speaker 4:  cab strikes me as completely ridiculous. Like a, a a

155
00:08:51,725 --> 00:08:54,715
Speaker 4:  two-seater car already

156
00:08:55,865 --> 00:08:58,445
Speaker 4:  vastly decreases the number of people who can use it.

157
00:08:59,765 --> 00:09:03,245
Speaker 4:  I saw somebody point out that like, oh great, you made a cab whose doors

158
00:09:03,255 --> 00:09:07,165
Speaker 4:  can't open in city traffic, which is a really excellent point.

159
00:09:07,605 --> 00:09:11,245
Speaker 4:  Like, this thing just doesn't make any real world sense, but neither does

160
00:09:11,245 --> 00:09:14,205
Speaker 4:  the cyber truck and like that eventually shipped. So who knows.

161
00:09:14,305 --> 00:09:18,165
Speaker 3:  Oh, I mean they also announced inductive charging, which doesn't exist for

162
00:09:18,165 --> 00:09:21,725
Speaker 3:  a car of this size yet. Right. That's cool. I would love to have that. It's

163
00:09:21,725 --> 00:09:25,325
Speaker 3:  just not real. And then the math, they didn't announce any of the

164
00:09:25,325 --> 00:09:29,125
Speaker 3:  mathematics, right? Like how will this work? I buy one of these things for

165
00:09:29,125 --> 00:09:32,685
Speaker 3:  $30,000, I put it on the Robax

166
00:09:32,685 --> 00:09:35,245
Speaker 3:  network or the robot network.

167
00:09:36,435 --> 00:09:40,405
Speaker 3:  That one doesn't work nearly as well. And then Tesla just takes

168
00:09:40,405 --> 00:09:43,045
Speaker 3:  some money while this thing drives around picking up customer. Am I liable

169
00:09:43,045 --> 00:09:46,925
Speaker 3:  if it crashes? Do I have to clean it up? If someone pucks in it is

170
00:09:46,925 --> 00:09:50,525
Speaker 3:  that Tesla's responsibility? Who, what are the splits?

171
00:09:50,955 --> 00:09:54,565
Speaker 3:  Like if I buy a cyber cap for $30,000 and put it on the

172
00:09:54,655 --> 00:09:58,565
Speaker 3:  Robax network, how long in a moderately busy city

173
00:09:59,455 --> 00:10:02,525
Speaker 3:  until that investment is paid off and I'm making a profit on it?

174
00:10:03,265 --> 00:10:05,685
Speaker 3:  If, you don't have that chart. You actually haven't announced anything in

175
00:10:05,685 --> 00:10:07,125
Speaker 3:  the context of this service. Totally.

176
00:10:07,715 --> 00:10:08,005
Speaker 4:  Yeah.

177
00:10:08,435 --> 00:10:09,655
Speaker 3:  At least a projection of that chart.

178
00:10:09,725 --> 00:10:13,495
Speaker 4:  Well, and that's all the stuff that is the

179
00:10:13,495 --> 00:10:17,415
Speaker 4:  stuff of self-driving, right? Like, like you said, a a a

180
00:10:17,475 --> 00:10:21,455
Speaker 4:  car that can drive you around a movie lot without appearing to have a

181
00:10:21,455 --> 00:10:25,335
Speaker 4:  driver. It's actually like, it, it's a huge technical achievement that we

182
00:10:25,335 --> 00:10:29,175
Speaker 4:  are actually not near in the real world, but it, that is only

183
00:10:29,595 --> 00:10:33,295
Speaker 4:  one tiny slice of what is going on here. And Andy Hawkins wrote a great thing,

184
00:10:33,295 --> 00:10:36,655
Speaker 4:  just basically like writing the list of things left to solve

185
00:10:37,005 --> 00:10:40,615
Speaker 4:  both by this whole industry and by Tesla in particular. And I think

186
00:10:41,195 --> 00:10:44,655
Speaker 4:  the belief from Elon Musk and Tesla has been

187
00:10:45,205 --> 00:10:48,335
Speaker 4:  that they can just like brute force their way through it and it'll work and

188
00:10:48,335 --> 00:10:52,135
Speaker 4:  it just hasn't and it won't. And So I think again, even if

189
00:10:52,135 --> 00:10:55,575
Speaker 4:  you've solved the can this thing drive safely by itself on the road problem,

190
00:10:55,665 --> 00:10:59,375
Speaker 4:  which we, we haven't, no one has. Even if you've solved that, you've only

191
00:10:59,375 --> 00:11:02,135
Speaker 4:  solved one tiny slice of the what does it take to actually roll this out

192
00:11:02,135 --> 00:11:05,975
Speaker 4:  in the world problem. And the cyber cab to me is just like

193
00:11:07,195 --> 00:11:11,045
Speaker 4:  one sort of bad idea about what that car might

194
00:11:11,045 --> 00:11:13,845
Speaker 4:  look like. Yeah. That's as far as I am, like willing to grant it.

195
00:11:14,145 --> 00:11:17,765
Speaker 3:  So two things about that. The, the promise for a lot of model

196
00:11:17,815 --> 00:11:21,725
Speaker 3:  three and model Y buyers over the years has been you'll pay the extra money

197
00:11:21,725 --> 00:11:25,085
Speaker 3:  for a full self-driving hardware and then one day overnight these things

198
00:11:25,085 --> 00:11:28,605
Speaker 3:  will turn into robo taxis and they will start making you money while you

199
00:11:28,605 --> 00:11:32,525
Speaker 3:  sleep. This is an explicit promise that Elon Musk and

200
00:11:32,525 --> 00:11:36,005
Speaker 3:  Tesla have made to these buyers, prospective buyers. This is something that

201
00:11:36,005 --> 00:11:39,485
Speaker 3:  people have bought these cars as an investment spending money they maybe

202
00:11:39,485 --> 00:11:42,685
Speaker 3:  didn't have waiting to pay off. It's not here yet.

203
00:11:43,475 --> 00:11:46,605
Speaker 3:  What version of the car will actually get support for this

204
00:11:47,505 --> 00:11:51,405
Speaker 3:  is contested. And when I say contested, I mean

205
00:11:51,735 --> 00:11:55,405
Speaker 3:  while Elon was speaking, speaking, someone was screaming hardware three

206
00:11:55,405 --> 00:11:59,325
Speaker 3:  support at him and his response was, let's not get too nuanced.

207
00:11:59,495 --> 00:12:03,085
Speaker 3:  Right? And then later, I think it was Franz von

208
00:12:03,275 --> 00:12:06,405
Speaker 3:  Hoen, the head of design at Tesla who's giving an interview who said Te Hardware

209
00:12:06,405 --> 00:12:09,765
Speaker 3:  three would be supported. Hmm. What what's the answer? Like, it's

210
00:12:09,995 --> 00:12:13,605
Speaker 3:  unclear. But if you're buying a cyber cab

211
00:12:14,515 --> 00:12:18,115
Speaker 3:  and you're immediately competing with thousands if not

212
00:12:18,115 --> 00:12:21,475
Speaker 3:  millions of existing model threes, you're in a weird spot.

213
00:12:22,425 --> 00:12:25,115
Speaker 3:  Like why would you make that investment? Because then you're buying a less

214
00:12:25,115 --> 00:12:28,865
Speaker 3:  practical car also, presumably Tesla's gonna run its own. Right.

215
00:12:29,285 --> 00:12:33,185
Speaker 3:  So again, I just think the math doesn't add up and then

216
00:12:33,185 --> 00:12:36,425
Speaker 3:  the, the basics of like what Tesla has promised people for a long time

217
00:12:36,835 --> 00:12:37,625
Speaker 3:  still isn't there.

218
00:12:38,175 --> 00:12:42,025
Speaker 4:  Well and there's this sense at all of those events that

219
00:12:42,025 --> 00:12:45,825
Speaker 4:  Tesla is still the company that has infinite demand,

220
00:12:45,825 --> 00:12:49,505
Speaker 4:  right? That anything they do, people will buy because it's Tesla because

221
00:12:49,505 --> 00:12:53,185
Speaker 4:  it's exciting and because it's cool. And to me the reaction

222
00:12:53,645 --> 00:12:57,585
Speaker 4:  to the event was very telling in the sense that I think

223
00:12:57,585 --> 00:13:01,505
Speaker 4:  Tesla has lost a lot of that shine, partly because there's a lot

224
00:13:01,505 --> 00:13:05,025
Speaker 4:  of competition and partly for like Elon Musk reasons, but also

225
00:13:06,325 --> 00:13:10,265
Speaker 4:  people just don't believe Tesla anymore. Yeah. There was a

226
00:13:10,265 --> 00:13:14,145
Speaker 4:  sense for so long that it was like, okay, don't believe the price, don't

227
00:13:14,145 --> 00:13:16,705
Speaker 4:  believe the ship date, but like this thing is going to happen and it's going

228
00:13:16,705 --> 00:13:20,425
Speaker 4:  to be awesome. And that is just not how people react to this anymore.

229
00:13:20,425 --> 00:13:24,185
Speaker 4:  There is no benefit of the doubt that this is a good idea. I just don't see

230
00:13:24,185 --> 00:13:27,865
Speaker 4:  it yet anymore. And Tesla had that going for it for so long

231
00:13:28,645 --> 00:13:32,465
Speaker 4:  and it just feels gone. But anyway, the the taxi thing is a good segue to

232
00:13:32,465 --> 00:13:35,545
Speaker 4:  our predictions. So yeah, let's just, let's just do the scoreboard here very

233
00:13:35,545 --> 00:13:38,825
Speaker 4:  quickly. I think unfortunately it's gonna look very bad for me very quickly.

234
00:13:38,885 --> 00:13:41,345
Speaker 4:  So let's just run through this very fast and then never speak of it again.

235
00:13:41,495 --> 00:13:44,985
Speaker 4:  Your three predictions were won't arrive until 2027. Ding.

236
00:13:45,415 --> 00:13:49,325
Speaker 4:  Yeah. Nailed that one again. We'll see. But he said

237
00:13:49,325 --> 00:13:51,885
Speaker 4:  20, 27 many times I should

238
00:13:51,885 --> 00:13:53,885
Speaker 3:  Take only in certain, I should have said 2029

239
00:13:55,315 --> 00:13:59,005
Speaker 4:  Only in certain cities. What what's our ruling on that? That it,

240
00:13:59,105 --> 00:14:02,265
Speaker 4:  it, like again, this is one we'll we will see someday,

241
00:14:02,965 --> 00:14:06,425
Speaker 4:  but the pitch was like you can buy one and just have it and everything will

242
00:14:06,425 --> 00:14:10,065
Speaker 4:  be like, I kind of wanna give you a push on that because he didn't say it

243
00:14:10,065 --> 00:14:11,265
Speaker 4:  is that he didn't say it won't be that.

244
00:14:11,265 --> 00:14:14,625
Speaker 3:  Yeah, that's, that's, that's a nothing. Okay. I feel very confident that

245
00:14:14,625 --> 00:14:17,225
Speaker 3:  that will be true. Okay. That you can only like the seven in one city at

246
00:14:17,225 --> 00:14:17,425
Speaker 3:  a time.

247
00:14:17,975 --> 00:14:20,545
Speaker 4:  Yeah, no, I I suspect you're right about that.

248
00:14:20,765 --> 00:14:24,345
Speaker 3:  For example, you have to build your vaporware inductive chargers first.

249
00:14:25,115 --> 00:14:25,465
Speaker 4:  Right?

250
00:14:26,205 --> 00:14:29,865
Speaker 3:  So you, you have to invent them, which is an important step one you have

251
00:14:29,865 --> 00:14:33,145
Speaker 3:  to make sure they work at scale, a very important step two. And then you

252
00:14:33,145 --> 00:14:34,265
Speaker 3:  have to put them in in cities.

253
00:14:34,575 --> 00:14:37,985
Speaker 4:  Yeah. Wait, can you explain that one to me actually? 'cause the didn't Tesla

254
00:14:38,175 --> 00:14:42,105
Speaker 4:  like do this once successfully already and now everyone is adopting the

255
00:14:42,225 --> 00:14:44,465
Speaker 4:  standard that Tesla did and we're actually like headed towards a good place

256
00:14:44,465 --> 00:14:47,265
Speaker 4:  where all of this might work successfully. Why

257
00:14:48,435 --> 00:14:50,725
Speaker 4:  blow this up with a new way of charging things?

258
00:14:50,725 --> 00:14:52,965
Speaker 3:  Oh, I thought you meant that they invented an inductive charging standard.

259
00:14:53,045 --> 00:14:55,485
Speaker 3:  I was like that would be amazing. No, no, I meant

260
00:14:55,485 --> 00:14:58,485
Speaker 4:  They did charging charge. Yeah. Like we have the max charger got that's like,

261
00:14:58,485 --> 00:15:01,045
Speaker 4:  that is, that is the thing that is going to enable these charging systems

262
00:15:01,065 --> 00:15:05,005
Speaker 4:  to work around the world on a, in a standard way. And then Tesla is just

263
00:15:05,005 --> 00:15:06,925
Speaker 4:  like, nevermind, we're gonna try this other thing that definitely won't work.

264
00:15:07,035 --> 00:15:08,285
Speaker 4:  Like why? Yeah.

265
00:15:08,555 --> 00:15:12,365
Speaker 3:  Well I mean it makes sense in the, in the way that catching the

266
00:15:12,365 --> 00:15:16,325
Speaker 3:  rocket makes sense. Like, you know what I mean? Like it's, it's an

267
00:15:16,325 --> 00:15:19,285
Speaker 3:  absurd If you idea be sick idea. Like if I can pull up this off, it will

268
00:15:19,285 --> 00:15:19,605
Speaker 3:  be sick.

269
00:15:19,915 --> 00:15:20,805
Speaker 4:  Okay. Right.

270
00:15:20,905 --> 00:15:24,765
Speaker 3:  So you've got taxis, you don't want too many moving parts around

271
00:15:24,765 --> 00:15:25,565
Speaker 3:  the taxis,

272
00:15:27,455 --> 00:15:31,235
Speaker 3:  so to charge them, you don't wanna roll up to a bay where a robot arm opens

273
00:15:31,235 --> 00:15:34,515
Speaker 3:  the door and sticks the charger into it. You just want it to roll up and

274
00:15:34,515 --> 00:15:37,795
Speaker 3:  start charging. Sure. So If, you make it work that there's inductive charging,

275
00:15:38,045 --> 00:15:41,915
Speaker 3:  which has been demoed by a handful of companies and a handful

276
00:15:41,975 --> 00:15:45,355
Speaker 3:  of controlled settings. Tesla I think at one point demoed like

277
00:15:45,745 --> 00:15:49,475
Speaker 3:  motorized battery changing from the underside of the car. But

278
00:15:49,475 --> 00:15:53,395
Speaker 3:  there's lots of ideas on how to make like battery charging

279
00:15:53,495 --> 00:15:57,155
Speaker 3:  faster. Sure. Or simpler or smoother require less moving parts.

280
00:15:57,455 --> 00:16:00,995
Speaker 3:  The problem is that Elon was also showing off mocks of like, what if we got

281
00:16:00,995 --> 00:16:04,115
Speaker 3:  rid of all the parking lots around the stadiums and they were just parked

282
00:16:04,445 --> 00:16:07,595
Speaker 3:  Right? And it's like, well all the robotaxis are gonna drop off the a hundred

283
00:16:07,835 --> 00:16:11,555
Speaker 3:  thousand people at the stadium. Where are they gonna go to charge

284
00:16:11,615 --> 00:16:15,075
Speaker 3:  on these? So you just want fields of

285
00:16:15,075 --> 00:16:18,235
Speaker 3:  inductive charging pads. That seems like

286
00:16:18,725 --> 00:16:21,595
Speaker 3:  weird, that's a weird thing to wanna put somewhere. Every

287
00:16:21,595 --> 00:16:25,355
Speaker 4:  Time somebody shows one of those. I just think of the traffic

288
00:16:25,385 --> 00:16:28,035
Speaker 4:  data from New York where Uber and Lyft were like, we'll get everybody off

289
00:16:28,035 --> 00:16:31,915
Speaker 4:  the roads. And actually what it is now is there are just like 50%

290
00:16:32,105 --> 00:16:35,315
Speaker 4:  more cars because it's just Uber and Lyft driving around waiting for somebody

291
00:16:35,315 --> 00:16:38,395
Speaker 4:  to get in the car. Yeah. Like we, we actually made it worse.

292
00:16:39,215 --> 00:16:43,115
Speaker 4:  And, and yeah. If we have a bunch of robot taxis, they gotta go somewhere.

293
00:16:44,475 --> 00:16:48,275
Speaker 3:  I once tried to explain the concept of induced

294
00:16:48,295 --> 00:16:52,115
Speaker 3:  demand to my family, which is, that's the concept

295
00:16:52,115 --> 00:16:54,835
Speaker 3:  that If you make the highway wider, more people will take the highway.

296
00:16:54,895 --> 00:16:56,915
Speaker 4:  You're so fun at parties. I bet. Well

297
00:16:56,995 --> 00:16:58,635
Speaker 3:  'cause they were like, we should make the highway bigger. And I was like,

298
00:16:58,775 --> 00:17:02,755
Speaker 3:  no. The thing called induced demand, like, boy did that not make sense

299
00:17:02,935 --> 00:17:06,915
Speaker 3:  to anyone. And I feel like this trade off

300
00:17:06,935 --> 00:17:10,475
Speaker 3:  of, we'll put a park near soldier field instead of a parking lot

301
00:17:11,055 --> 00:17:14,475
Speaker 3:  and then we're gonna need to build a field of

302
00:17:15,065 --> 00:17:19,035
Speaker 3:  like inductive charging pads for all the cyber cabs

303
00:17:19,035 --> 00:17:22,155
Speaker 3:  to go to, to charge while everyone's That's I'm just saying

304
00:17:22,935 --> 00:17:23,835
Speaker 3:  one city at a time.

305
00:17:24,385 --> 00:17:24,675
Speaker 4:  Yeah.

306
00:17:25,135 --> 00:17:26,635
Speaker 3:  That's, that's your problem. Yeah.

307
00:17:26,855 --> 00:17:29,035
Speaker 4:  No, I think, I think that's right. So we'll, we'll give you a push on that,

308
00:17:29,095 --> 00:17:32,955
Speaker 4:  but again, we're gonna have to rescore this so many times. And then

309
00:17:32,955 --> 00:17:36,715
Speaker 4:  your third one was existing Teslas will not be able to

310
00:17:36,745 --> 00:17:40,355
Speaker 4:  turn into Robotaxis and I think you're taking a loss on that one.

311
00:17:40,515 --> 00:17:42,595
Speaker 3:  I think this one's also a pushed, 'cause we don't know about hardware three.

312
00:17:42,695 --> 00:17:46,395
Speaker 3:  We don't know if it's only the very newest ones or if the hardware three,

313
00:17:46,395 --> 00:17:49,805
Speaker 3:  which has the, I mean they all, they all have like low resolution cameras,

314
00:17:50,025 --> 00:17:53,685
Speaker 3:  but we don't know which ones. So this is also just up in the air.

315
00:17:54,225 --> 00:17:57,925
Speaker 4:  Mm. I'm gonna give you like a, like a light loss on that one. It's like I'm

316
00:17:58,025 --> 00:18:02,005
Speaker 4:  I'm taking some of your money, but not all. Yeah. Like I'm not taking

317
00:18:02,065 --> 00:18:04,565
Speaker 4:  all your money, but I'm, I'm not happy with you. Yeah.

318
00:18:04,565 --> 00:18:06,445
Speaker 3:  Usually want me to be a little bit embarrassed. I got Yeah.

319
00:18:07,755 --> 00:18:08,045
Speaker 4:  Mine.

320
00:18:08,055 --> 00:18:09,405
Speaker 3:  Lemme do yours. Yours are worse.

321
00:18:09,405 --> 00:18:10,525
Speaker 4:  Yeah, please hit me. Mine are worse.

322
00:18:11,105 --> 00:18:14,365
Speaker 3:  You predicted that the cars would be driven by optimist Robots.

323
00:18:15,035 --> 00:18:16,245
Speaker 4:  It's a push If. you

324
00:18:16,245 --> 00:18:16,565
Speaker 3:  Don't know

325
00:18:16,915 --> 00:18:18,125
Speaker 4:  There's two seats in the car.

326
00:18:18,125 --> 00:18:21,485
Speaker 3:  Well, you were not what you were, what you should have predicted is the optimist,

327
00:18:21,485 --> 00:18:22,925
Speaker 3:  robots would be driven by people.

328
00:18:23,475 --> 00:18:26,485
Speaker 4:  Well, so this is where my second one really hits,

329
00:18:27,215 --> 00:18:30,965
Speaker 4:  which is they, they were gonna do a demo that didn't work and Yep. They,

330
00:18:30,965 --> 00:18:31,245
Speaker 4:  they,

331
00:18:31,445 --> 00:18:35,405
Speaker 3:  Well the demo worked in that the people controlling the

332
00:18:35,405 --> 00:18:38,045
Speaker 3:  Optimus robots fooled some other people. That's

333
00:18:38,045 --> 00:18:38,165
Speaker 4:  Fair.

334
00:18:39,025 --> 00:18:41,645
Speaker 3:  And like a lot of people were like, Optimus is the future. And once again,

335
00:18:41,715 --> 00:18:45,485
Speaker 3:  I'll point out that Honda had those robots like a decade ago

336
00:18:45,485 --> 00:18:49,445
Speaker 3:  that could like jump and flip. Yeah. Boston Robotics. I

337
00:18:49,445 --> 00:18:53,365
Speaker 3:  mean they will sell you a lethally armed robot dog today and they are

338
00:18:53,365 --> 00:18:55,645
Speaker 3:  desperate for customers. They've been trying to sell themselves for a long

339
00:18:55,645 --> 00:18:59,045
Speaker 3:  time. Yeah. I mean if you're in the market for a robot dog with a gun on

340
00:18:59,045 --> 00:19:02,455
Speaker 3:  its tail, make the call, you know, you never know what's gonna, the least

341
00:19:02,455 --> 00:19:05,655
Speaker 3:  deals are out of control and then,

342
00:19:06,435 --> 00:19:07,895
Speaker 3:  you know, Chuck E. Cheese exists.

343
00:19:08,365 --> 00:19:11,735
Speaker 4:  Yeah. I mean truly one of the funniest things about this whole event to me

344
00:19:11,755 --> 00:19:15,455
Speaker 4:  was all the people like taking the videos and stuff of the robots being like,

345
00:19:15,455 --> 00:19:18,895
Speaker 4:  whoa, this is so cool. And my reaction to all of these videos, which are

346
00:19:18,925 --> 00:19:22,655
Speaker 4:  very impressive, like these robots are holding conversations, they're doing

347
00:19:22,655 --> 00:19:26,415
Speaker 4:  really complicated gestures and motions, like all kinds of really

348
00:19:26,415 --> 00:19:29,015
Speaker 4:  impressive stuff. One's like, I think running around doing card tricks or

349
00:19:29,015 --> 00:19:32,855
Speaker 4:  something. If the robots were that good, there would be no

350
00:19:32,855 --> 00:19:36,775
Speaker 4:  other story. Yeah. Like it would, that would've been the event. They

351
00:19:36,775 --> 00:19:40,455
Speaker 4:  would've been like, oh my God, we fixed robots. Like we, we did it.

352
00:19:40,645 --> 00:19:44,575
Speaker 3:  Wait, I need to correct myself. Boston Dynamics was purchased, they did complete

353
00:19:44,575 --> 00:19:48,335
Speaker 3:  the purchase in 2021. Hyundai Motor Group bought Boston

354
00:19:48,415 --> 00:19:52,095
Speaker 3:  Dynamics. So that means Hyundai and Kia have a more

355
00:19:52,335 --> 00:19:55,975
Speaker 3:  advanced optimist than, than Tesla.

356
00:19:56,285 --> 00:19:59,535
Speaker 4:  That also makes me, there's a Hyundai dealership literally down the street

357
00:19:59,535 --> 00:20:03,455
Speaker 4:  from me that I would say four years ago was like

358
00:20:03,455 --> 00:20:07,095
Speaker 4:  kind of dingy and gross. And they have now expanded to its two full blocks

359
00:20:07,205 --> 00:20:11,055
Speaker 4:  long in our town and I now assume one of those is for

360
00:20:11,105 --> 00:20:14,535
Speaker 4:  robot talk with guns. And Yeah. I fear for my life in this neighborhood now

361
00:20:14,795 --> 00:20:18,695
Speaker 3:  The headline and I triple E Spectrum, which is a great magazine. Hyundai

362
00:20:18,805 --> 00:20:22,655
Speaker 3:  buys Boston Dynamics for nearly $1 billion Now what, which is very

363
00:20:22,655 --> 00:20:22,895
Speaker 3:  good.

364
00:20:23,235 --> 00:20:24,055
Speaker 4:  Sounds about right.

365
00:20:25,715 --> 00:20:29,535
Speaker 4:  But yeah, the, the robots was just like, if it had been even remotely

366
00:20:29,625 --> 00:20:32,855
Speaker 4:  close to as good as those robots appeared and they were actually automated

367
00:20:32,875 --> 00:20:36,575
Speaker 4:  and ai, that would've been the most incredible tech demo in

368
00:20:37,645 --> 00:20:37,935
Speaker 4:  ever.

369
00:20:38,835 --> 00:20:39,135
Speaker 3:  So I

370
00:20:39,135 --> 00:20:42,855
Speaker 4:  Was like, no, of course there are people on the other side of this. Like

371
00:20:42,935 --> 00:20:46,815
Speaker 4:  I think where it netted out was they were walking automatically. Yeah. And

372
00:20:46,815 --> 00:20:49,365
Speaker 4:  everything else was, was human assisted, which

373
00:20:49,365 --> 00:20:53,325
Speaker 3:  Again, Honda pulled off a decade ago. Right. And also you can just roll

374
00:20:53,325 --> 00:20:57,245
Speaker 3:  up to a Boston Dynamics robot and kick it and it's like, that's fine. I

375
00:20:57,365 --> 00:21:01,315
Speaker 3:  I won't fall down. And no one was touching the Yeah, I I get

376
00:21:01,315 --> 00:21:04,035
Speaker 3:  it. You you want optimists to exist. You want to prove that it's great. And

377
00:21:04,935 --> 00:21:08,395
Speaker 3:  the videos I saw, I think Marque posted one, I saw a few others

378
00:21:08,645 --> 00:21:12,535
Speaker 3:  where they were just talking to the optimist robots and they were just

379
00:21:12,535 --> 00:21:15,925
Speaker 3:  talking back. They're like, are you an ai? And he is like, yo dude, I don't

380
00:21:15,925 --> 00:21:19,765
Speaker 3:  know. It's like, that's a guy. Yeah. You ever

381
00:21:19,765 --> 00:21:23,645
Speaker 3:  talked to Chad? Me? That's just a guy.

382
00:21:25,825 --> 00:21:29,435
Speaker 3:  All right. And then your last prediction. So that's two L's.

383
00:21:29,825 --> 00:21:30,115
Speaker 4:  Yeah.

384
00:21:30,335 --> 00:21:31,875
Speaker 3:  Off drivers. That won't

385
00:21:31,875 --> 00:21:35,395
Speaker 4:  Work. I'll take it. I should've, I should have gone with It's a thing you

386
00:21:35,395 --> 00:21:38,915
Speaker 4:  can buy. I really should. I was, I was sitting there being like, this is

387
00:21:38,915 --> 00:21:41,515
Speaker 4:  a thing you can buy. But then I was like, that doesn't make any sense that

388
00:21:41,515 --> 00:21:43,075
Speaker 4:  it would be, and I should have stuck to my guns.

389
00:21:43,415 --> 00:21:46,635
Speaker 3:  All right. And then you, you, you existing Teslas are taxis.

390
00:21:47,795 --> 00:21:51,255
Speaker 3:  We basically, we took the opposite side of the bet. Yeah. And I think it's

391
00:21:51,255 --> 00:21:52,815
Speaker 3:  a, it's a light l for both of us.

392
00:21:53,635 --> 00:21:56,735
Speaker 4:  No, it's a light dub for me. It's a light L for you. Let's be, let's be honest

393
00:21:56,735 --> 00:21:57,495
Speaker 4:  here. So it's

394
00:21:57,525 --> 00:22:00,735
Speaker 3:  Some existing Teslas, but maybe not most of it. It's

395
00:22:00,735 --> 00:22:03,535
Speaker 4:  Like, you know, we're like going into halftime and the score is tied, but

396
00:22:03,535 --> 00:22:05,775
Speaker 4:  like, I'm playing much better than you. You know what I mean? Like that's

397
00:22:05,775 --> 00:22:08,775
Speaker 4:  where we are. I have all the momentum, but the score is tied. That's what's

398
00:22:08,775 --> 00:22:09,375
Speaker 4:  going on right now.

399
00:22:09,875 --> 00:22:13,455
Speaker 3:  You're an optimist robot just shuffling your way towards the bar.

400
00:22:13,775 --> 00:22:14,215
Speaker 4:  Exactly.

401
00:22:15,445 --> 00:22:19,295
Speaker 3:  Fair. I'll, I'll, I'll I'll give it to you just because you know,

402
00:22:19,455 --> 00:22:22,615
Speaker 3:  I want you to hit the heights. So the crash is that much sweeter for me

403
00:22:23,805 --> 00:22:24,895
Speaker 3:  playing the long game here.

404
00:22:24,895 --> 00:22:25,495
Speaker 4:  It's kind of you.

405
00:22:26,255 --> 00:22:29,655
Speaker 3:  So that's the, that's the Robo Taxii event. Oh by the way, I need to, I just

406
00:22:29,655 --> 00:22:31,295
Speaker 3:  need to say this about the robo van one more time.

407
00:22:31,385 --> 00:22:33,175
Speaker 4:  Sorry, what? The the what? The robo

408
00:22:33,195 --> 00:22:37,095
Speaker 3:  Van, he showed a picture of it. They showed some mocks of the

409
00:22:37,295 --> 00:22:41,275
Speaker 3:  interior. Of all of the things. This

410
00:22:41,275 --> 00:22:45,075
Speaker 3:  is the one that will not arrive. Which totally agree. The, the way

411
00:22:45,075 --> 00:22:48,835
Speaker 3:  that it looks and operates and works, it's just not gonna

412
00:22:48,835 --> 00:22:49,555
Speaker 3:  happen that way.

413
00:22:49,875 --> 00:22:53,395
Speaker 4:  I mean we, we've seen basically this

414
00:22:53,625 --> 00:22:57,355
Speaker 4:  idea in roughly this design a

415
00:22:57,355 --> 00:23:00,795
Speaker 4:  billion times over the years. Yep. Like in, in so many ways. Nothing about

416
00:23:00,795 --> 00:23:02,875
Speaker 4:  this concept is new at all.

417
00:23:03,055 --> 00:23:04,435
Speaker 3:  That's where my confidence comes from.

418
00:23:04,465 --> 00:23:04,755
Speaker 4:  Yeah.

419
00:23:05,225 --> 00:23:09,115
Speaker 3:  When they do, when, when, when Tesla or another Elon company does the

420
00:23:09,425 --> 00:23:12,475
Speaker 3:  bonkers thing that no one else has tried. 'cause it's too hard. Alright,

421
00:23:12,885 --> 00:23:16,115
Speaker 3:  let's give it catch the rocket. You know what I mean? Yeah. When you're like,

422
00:23:16,115 --> 00:23:17,395
Speaker 3:  oh, well here it is again.

423
00:23:18,225 --> 00:23:22,115
Speaker 4:  Yeah. It's like that stuff in every city of the Future thing. This is

424
00:23:22,115 --> 00:23:25,995
Speaker 4:  what buses look like. Yep. Ev every single one of them for 50 years, this

425
00:23:25,995 --> 00:23:28,355
Speaker 4:  is what they look like and it just,

426
00:23:28,895 --> 00:23:31,555
Speaker 3:  Oh, I figured it out. You know what the difference between SpaceX and Tesla

427
00:23:31,695 --> 00:23:34,915
Speaker 3:  is? What's that? The fucking cyber truck wiper.

428
00:23:37,175 --> 00:23:40,745
Speaker 3:  Like you have a grand plan to reinvent space flight.

429
00:23:41,335 --> 00:23:44,665
Speaker 3:  Gwen Shotwell will get it done. You're like wipers

430
00:23:45,485 --> 00:23:46,555
Speaker 3:  start at the drawing board.

431
00:23:48,175 --> 00:23:49,235
Speaker 3:  No idea what to do.

432
00:23:51,065 --> 00:23:54,035
Speaker 4:  Yeah. Are there wipers on the rockets? I feel like they probably work.

433
00:23:54,985 --> 00:23:58,235
Speaker 3:  Yeah. The, you know, the gimbals on the thrusters, a lot of things on the

434
00:23:58,235 --> 00:23:58,755
Speaker 3:  Rockets work

435
00:24:00,535 --> 00:24:04,435
Speaker 3:  that's all doing it. And then over here we're like, what if one big

436
00:24:04,605 --> 00:24:08,575
Speaker 3:  wiper, let's do it. And it's like that thing does not work at

437
00:24:08,575 --> 00:24:09,655
Speaker 4:  All. No, it's so floppy.

438
00:24:10,485 --> 00:24:14,415
Speaker 3:  It's, but it's a bad wiper. I'm saying taking the

439
00:24:14,415 --> 00:24:18,095
Speaker 3:  solved problem and trying to resol it is very much the Tesla

440
00:24:18,245 --> 00:24:22,095
Speaker 3:  mode right now. Yes. And that it's like

441
00:24:22,095 --> 00:24:26,015
Speaker 3:  this van is the most solved problem. How do you move six people

442
00:24:26,015 --> 00:24:29,925
Speaker 3:  around a city? It's called an Escalade. Just do it. Just

443
00:24:29,925 --> 00:24:32,795
Speaker 3:  Yeah. Make an Escalade. It's gonna be fucked.

444
00:24:32,955 --> 00:24:35,715
Speaker 4:  I mean we, we make fun of Waymo for just getting a bunch of like Chrysler

445
00:24:35,715 --> 00:24:38,795
Speaker 4:  Pacificas. That's actually like It does, it does work. Yeah,

446
00:24:38,795 --> 00:24:41,995
Speaker 3:  It does do job. Actually a very funny thing, I was looking at a chart of

447
00:24:42,445 --> 00:24:46,395
Speaker 3:  percentage of EV sales by car maker and Jaguar has

448
00:24:46,395 --> 00:24:49,195
Speaker 3:  this like shockingly high percentage of EV

449
00:24:49,195 --> 00:24:50,435
Speaker 4:  Sales because of Waymo.

450
00:24:50,435 --> 00:24:51,235
Speaker 3:  Because of Waymo.

451
00:24:51,255 --> 00:24:51,995
Speaker 4:  That's so funny

452
00:24:52,545 --> 00:24:56,435
Speaker 3:  Because Waymo buys so many EVs. Yeah. So like they're,

453
00:24:56,435 --> 00:24:59,355
Speaker 3:  they're taking platforms that work and making them

454
00:25:00,285 --> 00:25:03,795
Speaker 3:  autonomous. And it is, it's like they're just moving along.

455
00:25:04,315 --> 00:25:07,675
Speaker 3:  There are Waymo testing on the streets of New York right now and they're,

456
00:25:07,675 --> 00:25:10,675
Speaker 3:  you know, they're just adding cities and moving along and making the progress

457
00:25:10,675 --> 00:25:12,715
Speaker 3:  and then there's whatever this is in 2027.

458
00:25:13,005 --> 00:25:16,955
Speaker 4:  Right. And Tesla's whole thing is like launch the

459
00:25:16,955 --> 00:25:20,875
Speaker 4:  giant thing and then work backwards from it. And that worked enough

460
00:25:20,875 --> 00:25:24,755
Speaker 4:  times that it gave them a lot of confidence. And I think there's very

461
00:25:24,755 --> 00:25:27,595
Speaker 4:  little evidence it's gonna work this time or has worked the last couple,

462
00:25:27,815 --> 00:25:29,715
Speaker 4:  but we should move on. We have other stuff to talk about

463
00:25:30,455 --> 00:25:32,515
Speaker 3:  By the way. I think we were both one for three.

464
00:25:34,095 --> 00:25:34,905
Speaker 4:  Yeah, no,

465
00:25:34,905 --> 00:25:36,625
Speaker 3:  Well yeah, it's a push for me and I'm

466
00:25:36,625 --> 00:25:38,545
Speaker 4:  One Yeah, you you, you won.

467
00:25:40,205 --> 00:25:43,025
Speaker 3:  Congratulations. Well, we'll, we'll, we'll it's, it's a

468
00:25:43,025 --> 00:25:44,665
Speaker 4:  Provisional, I'll buy you, I'll buy you a cyber cab.

469
00:25:44,735 --> 00:25:48,345
Speaker 3:  There's an asterisk by this one. I'll take the 30 grand.

470
00:25:49,285 --> 00:25:52,985
Speaker 4:  No, I'll, I'll buy you a cyber cab. Damn it. I'll buy you a ovn when it comes

471
00:25:52,985 --> 00:25:53,185
Speaker 4:  out.

472
00:25:54,825 --> 00:25:58,045
Speaker 3:  All right. There's other news actually quite a lot of other news. Yeah, we

473
00:25:58,045 --> 00:26:01,525
Speaker 3:  should start it. There's been a lot of rumors about Apple doing an October

474
00:26:01,535 --> 00:26:05,525
Speaker 3:  event. We're obviously running out of October. A lot of rumors about M four

475
00:26:05,945 --> 00:26:09,925
Speaker 3:  Max. Who knows what's gonna happen. We're waiting on Apple Intelligence

476
00:26:09,925 --> 00:26:13,445
Speaker 3:  to hit that Feels very likely it will happen this month. But again, we're

477
00:26:13,445 --> 00:26:17,245
Speaker 3:  running out of October. Yeah. And I think they just needed to announce the

478
00:26:17,245 --> 00:26:21,185
Speaker 3:  new iPad mini with a new chip in it and then they just did

479
00:26:21,185 --> 00:26:24,225
Speaker 3:  it. They just put out a press release and now there's a new iPad mini.

480
00:26:24,615 --> 00:26:27,505
Speaker 4:  Yeah. At some point I have just given up

481
00:26:28,175 --> 00:26:31,545
Speaker 4:  waiting for Apple to like really care about the iPad Mini

482
00:26:32,925 --> 00:26:36,505
Speaker 4:  and it's not that it's not a good device. I think it's a very good device

483
00:26:36,505 --> 00:26:40,145
Speaker 4:  and I think the new one is probably also very good, but it is so

484
00:26:40,145 --> 00:26:44,045
Speaker 4:  clearly not interesting to Apple for, for whatever reason.

485
00:26:44,045 --> 00:26:48,005
Speaker 4:  Right. Like there's a subset of people who really like it. The new one even

486
00:26:48,585 --> 00:26:52,525
Speaker 4:  is clearly not impressive. Like it's fine, it's gonna

487
00:26:52,525 --> 00:26:56,365
Speaker 4:  be a very good iPad mini, but it has, it has this, it has last year's chip.

488
00:26:56,475 --> 00:26:59,965
Speaker 3:  There's a pilot somewhere that just banked the plane super hard angrily while

489
00:26:59,965 --> 00:27:00,685
Speaker 3:  they're listening to this.

490
00:27:01,065 --> 00:27:04,565
Speaker 4:  Listen, I got a lot of posts, I

491
00:27:04,775 --> 00:27:08,645
Speaker 4:  wrote the story and I put every pilot's favorite tablet in the deck

492
00:27:08,645 --> 00:27:12,205
Speaker 4:  of our story. Like you can't own me harder than I own myself people,

493
00:27:14,505 --> 00:27:18,445
Speaker 4:  but the like it's, it's just a spec upgrade. Right. Which is fine.

494
00:27:18,445 --> 00:27:21,845
Speaker 4:  Yeah. The the last one of these was three years ago and

495
00:27:22,295 --> 00:27:25,485
Speaker 4:  total redesign, they did a bunch of cool stuff. They, they squared off the

496
00:27:25,485 --> 00:27:29,445
Speaker 4:  edges. It got touch ID in the, in the power button. Like

497
00:27:29,585 --> 00:27:33,485
Speaker 4:  all good stuff. It's a really good device. This one is just purely a spec

498
00:27:33,485 --> 00:27:37,365
Speaker 4:  upgrade. Faster everything. Faster connections, faster processors.

499
00:27:37,545 --> 00:27:40,885
Speaker 4:  But to me the thing that's the most telling is in a year where Apple upgraded

500
00:27:41,065 --> 00:27:44,925
Speaker 4:  the iPad air to the M two and the iPad Pro to the M four and

501
00:27:44,945 --> 00:27:48,605
Speaker 4:  and actually launched the M four with an iPad like that, that is a,

502
00:27:48,655 --> 00:27:52,405
Speaker 4:  apple does not do that stuff by accident. That is like a statement of

503
00:27:52,405 --> 00:27:56,325
Speaker 4:  this is what this device means in our lineup. This

504
00:27:56,325 --> 00:28:00,085
Speaker 4:  thing got the A 17 Pro, which was in iPhones last year.

505
00:28:00,865 --> 00:28:04,525
Speaker 3:  Do you think They just were like, well we got all these iPhone 15 pro parts.

506
00:28:05,375 --> 00:28:09,285
Speaker 4:  Jason Snell wrote a really good thing at six Colors, basically positing that

507
00:28:09,795 --> 00:28:13,725
Speaker 4:  that it's like this is a good chip. It's the least you need to

508
00:28:13,995 --> 00:28:17,925
Speaker 4:  work on Apple intelligence. So Apple is, is just trying to pull people along

509
00:28:19,315 --> 00:28:23,245
Speaker 4:  with not quite like garbage bin parts, but like stuff

510
00:28:23,245 --> 00:28:26,765
Speaker 4:  it already had. Right. Yeah. This is the upgrade you can do without trying

511
00:28:26,795 --> 00:28:30,725
Speaker 4:  very hard and, and it'll work like the the, I'm sure this mini will be very

512
00:28:30,725 --> 00:28:34,365
Speaker 4:  good. No one I know had performance issues with the last mini.

513
00:28:34,595 --> 00:28:38,565
Speaker 4:  This one will do fine, it's all gonna be fine. But I, every single

514
00:28:38,565 --> 00:28:42,125
Speaker 4:  time one of these comes out, I hold out hope that Apple is going to do something

515
00:28:42,345 --> 00:28:45,925
Speaker 4:  new for it. Like give me a keyboard case, come up with a new idea about how

516
00:28:45,925 --> 00:28:49,205
Speaker 4:  people are gonna use this thing. We got Pencil Pro support, which is nice.

517
00:28:50,225 --> 00:28:53,845
Speaker 4:  But the story of this is just, it is

518
00:28:54,285 --> 00:28:55,405
Speaker 4:  slightly worse and smaller,

519
00:28:56,165 --> 00:28:57,205
Speaker 3:  Slightly worse. Yeah.

520
00:28:57,205 --> 00:29:00,445
Speaker 4:  It's not the M two. It's not the M four. Oh, I see. Not than before this

521
00:29:00,445 --> 00:29:04,365
Speaker 4:  thing, this thing will feel old much sooner

522
00:29:04,595 --> 00:29:06,285
Speaker 4:  than the other iPads that came out this year.

523
00:29:06,725 --> 00:29:09,285
Speaker 3:  I thought you meant slightly worse in comparison to the old one. Like it's

524
00:29:09,285 --> 00:29:11,725
Speaker 3:  an iPad mini but this one will hurt you in some way. Oh

525
00:29:11,745 --> 00:29:11,965
Speaker 4:  No,

526
00:29:12,145 --> 00:29:13,445
Speaker 3:  No. This like the glass is jagged.

527
00:29:13,555 --> 00:29:17,365
Speaker 4:  This one it's an iPad mini but it pokes you once every eight

528
00:29:17,365 --> 00:29:18,725
Speaker 4:  minutes and you never know when.

529
00:29:18,865 --> 00:29:20,765
Speaker 3:  No, you mean in comparison to the rest of the iPad

530
00:29:20,905 --> 00:29:23,085
Speaker 4:  In comparison to the rest of the iPad. Got it. Right. Okay. And like the

531
00:29:23,085 --> 00:29:26,925
Speaker 4:  story, what you would want really is basically to have this one

532
00:29:26,945 --> 00:29:29,445
Speaker 4:  be just as good and slightly smaller, right? Like this is what people want

533
00:29:29,445 --> 00:29:32,405
Speaker 4:  from the iPhone mini. Like give me one that is just as good but slightly

534
00:29:32,405 --> 00:29:36,285
Speaker 4:  smaller. And Apple is resolutely not doing that with any

535
00:29:36,285 --> 00:29:36,925
Speaker 4:  of its products.

536
00:29:37,525 --> 00:29:40,125
Speaker 3:  I wonder, I mean I wonder if there's thermal issues with sticking an N series

537
00:29:40,125 --> 00:29:43,325
Speaker 3:  chip in a platform. It's possible small who, who knows the thing that gets

538
00:29:43,325 --> 00:29:46,845
Speaker 3:  me, I believe it was Christopher Mims, your old colleague from the journal

539
00:29:47,425 --> 00:29:50,725
Speaker 3:  who I think his post was just make it a phone.

540
00:29:51,395 --> 00:29:55,325
Speaker 3:  Like If, you just called this the iPhone Ultra plus max people would buy

541
00:29:55,325 --> 00:29:59,125
Speaker 3:  it because people love big phones. Yes. And it's so funny because even

542
00:29:59,325 --> 00:30:02,605
Speaker 3:  If, you wanted to use an iPad mini as your phone. You could not

543
00:30:02,995 --> 00:30:05,085
Speaker 3:  because it doesn't run iPhone apps.

544
00:30:05,415 --> 00:30:06,485
Speaker 4:  Right? Well there is a,

545
00:30:06,705 --> 00:30:10,485
Speaker 3:  The iPad OS is like in this weird tweener zone.

546
00:30:11,405 --> 00:30:15,275
Speaker 4:  There is a real like what if I had an iPad and an

547
00:30:15,275 --> 00:30:18,995
Speaker 4:  Apple watch And that was my computing setup that I think could

548
00:30:19,095 --> 00:30:22,755
Speaker 4:  in theory be very compelling in, in the way that you're describing. But

549
00:30:23,005 --> 00:30:26,875
Speaker 4:  Apple just won't do that. You're right. If this was a giant iPhone, I think

550
00:30:26,875 --> 00:30:30,835
Speaker 4:  it would actually be more interesting as a device than as a tiny iPad.

551
00:30:31,065 --> 00:30:33,915
Speaker 3:  Yeah. But it's like, you know what, it doesn't run Instagram. Right?

552
00:30:35,155 --> 00:30:39,075
Speaker 3:  Indefensibly So Yeah, it just doesn't run Instagram. Yeah. And it's,

553
00:30:39,465 --> 00:30:43,355
Speaker 3:  it's not so much bigger than my iPhone 16 max like.

554
00:30:43,585 --> 00:30:47,275
Speaker 4:  Yeah, well, which is I think the strange thing, it's at this point, especially

555
00:30:47,275 --> 00:30:50,835
Speaker 4:  as the phones have just continued to get bigger, I mean the, the 16 Pro Max

556
00:30:50,835 --> 00:30:54,795
Speaker 4:  is 6.9 inches right now. The iPad

557
00:30:54,955 --> 00:30:58,515
Speaker 4:  mini is 8.3 inches, which is a difference,

558
00:30:59,825 --> 00:31:02,525
Speaker 4:  but it's not that huge a difference. Like

559
00:31:04,465 --> 00:31:08,445
Speaker 4:  the only main user interface thing is A,

560
00:31:08,445 --> 00:31:12,085
Speaker 4:  you can't run iPhone apps and B, you don't get the pencil

561
00:31:12,085 --> 00:31:14,725
Speaker 4:  support on the iPhone. Right. So that's No I'm saying's

562
00:31:14,725 --> 00:31:17,805
Speaker 3:  The trade. No, I'm saying the picture Apple's own press picture of the mini

563
00:31:18,425 --> 00:31:22,405
Speaker 3:  is a hand holding it like a phone like this. Yeah. And like the

564
00:31:22,405 --> 00:31:26,365
Speaker 3:  only difference is the fingers are out. Like that's a huge hand. I

565
00:31:26,365 --> 00:31:29,685
Speaker 3:  have a big hand. It's a and like that is a big hand. We're gonna get there,

566
00:31:29,685 --> 00:31:33,205
Speaker 3:  it's gonna happen one day and then the ghost of Steve Jobs is gonna be very

567
00:31:33,205 --> 00:31:37,005
Speaker 3:  upset with everyone. It was, I was like being my old old

568
00:31:37,005 --> 00:31:40,925
Speaker 3:  iPhone five, which was like the biggest, he would let it get and he was

569
00:31:40,925 --> 00:31:44,805
Speaker 3:  like, your thumb has to hit the opposite iPad mini as a phone. Those were

570
00:31:44,805 --> 00:31:46,845
Speaker 3:  the days. That's the future. Those were the days. Alright, can you explain

571
00:31:46,875 --> 00:31:50,645
Speaker 3:  this next one to me because I don't understand

572
00:31:50,645 --> 00:31:51,085
Speaker 3:  what's going on.

573
00:31:51,245 --> 00:31:51,965
Speaker 4:  I was really hoping you

574
00:31:52,365 --> 00:31:55,885
Speaker 3:  A MD Intel and a bunch of tech companies formed an alliance.

575
00:31:58,395 --> 00:32:00,725
Speaker 3:  It's called the X 86 advisory group.

576
00:32:02,215 --> 00:32:05,775
Speaker 3:  Microsoft, Google Meta Lenovo, and then truly

577
00:32:06,425 --> 00:32:10,415
Speaker 3:  Intel and A MD which are ferocious rivals. Yeah. They formed the X

578
00:32:10,535 --> 00:32:14,455
Speaker 3:  86 ecosystem advisory group. Pat Gelsinger announced

579
00:32:14,475 --> 00:32:18,385
Speaker 3:  it on stage at Lenovo's Tech World

580
00:32:18,385 --> 00:32:21,945
Speaker 3:  2024 conference, the hottest conference of the year. And

581
00:32:22,385 --> 00:32:26,105
Speaker 3:  Gelsinger said X 86 said it's, we are alive and well.

582
00:32:26,415 --> 00:32:29,945
Speaker 4:  Yeah. My, my we are alive and well. T-shirt is answering a lot of questions

583
00:32:29,965 --> 00:32:31,745
Speaker 4:  raised by my world. Well

584
00:32:34,525 --> 00:32:37,985
Speaker 4:  the only thing I can read into this is just

585
00:32:38,855 --> 00:32:42,645
Speaker 4:  pure existential fear from these companies. Right? Like of

586
00:32:42,705 --> 00:32:46,445
Speaker 4:  arm of arm. Yeah. And, and I think frankly with good

587
00:32:46,445 --> 00:32:49,245
Speaker 4:  reason, apple has been

588
00:32:50,355 --> 00:32:54,005
Speaker 4:  sort of, has completed its transition to its own ARM-based silicon

589
00:32:54,015 --> 00:32:57,685
Speaker 4:  stuff and is just lapping everybody else

590
00:32:57,945 --> 00:33:01,085
Speaker 4:  in, in like raw sort of everyday device performance. It is just

591
00:33:01,525 --> 00:33:05,405
Speaker 4:  crushing the competition. Qualcomm I think for

592
00:33:05,405 --> 00:33:08,885
Speaker 4:  like a decade made promises that it couldn't keep about

593
00:33:09,625 --> 00:33:13,085
Speaker 4:  its arm performance and how it was gonna bring like all the efficiency of

594
00:33:13,085 --> 00:33:16,085
Speaker 4:  mobile and all the power of desktops and put that together and it was gonna

595
00:33:16,085 --> 00:33:19,485
Speaker 4:  be magic. And I think Intel and a MD and others

596
00:33:20,435 --> 00:33:24,205
Speaker 4:  watched Qualcomm sort of try and fail to do that. And we were like, okay,

597
00:33:24,205 --> 00:33:27,125
Speaker 4:  well they'll never get there. It's not gonna happen. And I think you could

598
00:33:27,125 --> 00:33:31,065
Speaker 4:  argue with relative success that Qualcomm is there

599
00:33:31,165 --> 00:33:34,785
Speaker 4:  now and I think it's very clear that Qualcomm is going to get there. Right?

600
00:33:34,785 --> 00:33:38,265
Speaker 4:  Whether or not you believe it's a real X 86 competitor now

601
00:33:38,655 --> 00:33:41,705
Speaker 4:  with the, the Snapdragon elite and all that stuff in the new copilot plus

602
00:33:41,925 --> 00:33:45,905
Speaker 4:  PCs and all that stuff, it's either there or it's close. And

603
00:33:45,945 --> 00:33:49,625
Speaker 4:  I think that leap was so big that all of these other companies

604
00:33:50,815 --> 00:33:54,625
Speaker 4:  just panicked. I mean, and Intel is obviously like sort of

605
00:33:54,625 --> 00:33:58,585
Speaker 4:  collapsing in on itself, like a dying star in, in

606
00:33:58,585 --> 00:34:01,905
Speaker 4:  so many ways right now. And a MD is a, I think in a slightly

607
00:34:02,615 --> 00:34:03,225
Speaker 3:  Less AMD is in

608
00:34:03,225 --> 00:34:07,065
Speaker 4:  A better spot precarious position. Yeah. But it also would very

609
00:34:07,065 --> 00:34:10,785
Speaker 4:  much like to not have Qualcomm become a dominant player and

610
00:34:11,045 --> 00:34:13,945
Speaker 4:  the whole chip industry has just turned right. Like you have, you have what

611
00:34:13,945 --> 00:34:16,105
Speaker 4:  Apple's doing, you have what Nvidia is doing and you have what Qualcomm is

612
00:34:16,105 --> 00:34:18,985
Speaker 4:  doing and all these other chip makers are just out there being like, oh my

613
00:34:18,985 --> 00:34:22,665
Speaker 4:  God, this happened so much faster than we expected. Yeah.

614
00:34:23,305 --> 00:34:25,025
Speaker 4:  I just, I don't know how to read it other than that

615
00:34:25,365 --> 00:34:29,025
Speaker 3:  On the AI side of things, I So I actually I read this as a like a

616
00:34:29,095 --> 00:34:32,745
Speaker 3:  data center announcement of all of the things that like interesting, even

617
00:34:32,745 --> 00:34:36,705
Speaker 3:  though it's a Lenovo conference, X 86 is still doing well in

618
00:34:36,705 --> 00:34:40,625
Speaker 3:  data centers. Sure. And then, you know, Nvidia I think gets a lot of the

619
00:34:40,625 --> 00:34:44,505
Speaker 3:  shine for AI because it's selling so many of its GPUs to AI companies.

620
00:34:44,965 --> 00:34:48,825
Speaker 3:  But like, you know, X 86 processors outperform the N series in

621
00:34:48,865 --> 00:34:52,505
Speaker 3:  a bunch of AI tasks. Yeah. A MD has a pretty healthy business selling

622
00:34:52,695 --> 00:34:55,835
Speaker 3:  GPUs there. There's just a whole thing there,

623
00:34:56,405 --> 00:35:00,155
Speaker 3:  right? Where like you, if that is the big market,

624
00:35:00,255 --> 00:35:03,875
Speaker 3:  you might as well put together the big competitor to 10

625
00:35:03,875 --> 00:35:07,835
Speaker 3:  Nvidia and say like here's your other path because all these, all the big

626
00:35:08,035 --> 00:35:11,595
Speaker 3:  companies would like not to be locked into Nvidia. I don't know about consumer

627
00:35:11,855 --> 00:35:15,595
Speaker 3:  PCs at all. Like I, I truly don't. I guess they were on stage at the Lenovo

628
00:35:15,595 --> 00:35:19,395
Speaker 3:  event, but they weren't like waving laptops around. That's true. And So.

629
00:35:19,515 --> 00:35:22,675
Speaker 3:  I. Yeah. I just, it's weird and it's weird that Microsoft is like copilot

630
00:35:22,675 --> 00:35:26,475
Speaker 3:  plus PCs and mostly arm ships and then also over here

631
00:35:26,475 --> 00:35:28,835
Speaker 3:  on this other platform that we are tied to forever.

632
00:35:29,595 --> 00:35:32,355
Speaker 4:  Right. Well and I think with a lot of that stuff

633
00:35:33,395 --> 00:35:37,285
Speaker 4:  there is the, the arm advancement has

634
00:35:37,285 --> 00:35:40,965
Speaker 4:  just happened so fast while I think X 86, particularly

635
00:35:41,555 --> 00:35:45,165
Speaker 4:  with Intel, has just been like stuck in the mud for a long time

636
00:35:45,595 --> 00:35:49,165
Speaker 4:  that Intel has kind of gone version after version of its chips without

637
00:35:49,835 --> 00:35:53,685
Speaker 4:  sort of meaningful progress on some of the stuff that people really

638
00:35:53,685 --> 00:35:57,365
Speaker 4:  care about. And I, I think in theory the idea of

639
00:35:57,365 --> 00:36:00,685
Speaker 4:  banding together on this is like, okay, we can sort of rising tide lifts

640
00:36:00,685 --> 00:36:04,565
Speaker 4:  all boats here by meshing together some of

641
00:36:04,565 --> 00:36:06,765
Speaker 4:  the work these companies are doing and saying, okay, we're all gonna build

642
00:36:06,765 --> 00:36:09,845
Speaker 4:  better chips, which is actually going to benefit all of us instead of

643
00:36:10,915 --> 00:36:13,885
Speaker 4:  just, you know, sort of running in parallel and all trying to reinvent the

644
00:36:14,125 --> 00:36:17,685
Speaker 4:  wheel on our own. Which I think is a good strategy. I just think they are

645
00:36:17,905 --> 00:36:21,645
Speaker 4:  way too late in starting this move. Yeah.

646
00:36:21,665 --> 00:36:25,405
Speaker 3:  Let me just read you the list here to support my data

647
00:36:25,405 --> 00:36:28,485
Speaker 3:  center claim. Broadcom, Dell, Google,

648
00:36:29,155 --> 00:36:32,285
Speaker 3:  Hewlett Packard Enterprise as well as HP,

649
00:36:33,265 --> 00:36:37,125
Speaker 3:  the Sure. The other one, Lenovo Meta, Microsoft,

650
00:36:37,125 --> 00:36:40,805
Speaker 3:  Oracle and Red Hat. And then just for fun,

651
00:36:42,005 --> 00:36:45,125
Speaker 3:  Linus Tova and Tim Sweeney. Sure.

652
00:36:46,385 --> 00:36:50,325
Speaker 3:  You know guys, those are all people that run giant service.

653
00:36:50,525 --> 00:36:53,525
Speaker 4:  I mean the picture at the top of the press release is a data center. Like

654
00:36:53,795 --> 00:36:56,965
Speaker 4:  it's not, it's not unclear what they're doing here,

655
00:36:58,105 --> 00:37:01,005
Speaker 4:  but No, I I think you're right and I think it, it's, that's all fine, right?

656
00:37:01,005 --> 00:37:04,005
Speaker 4:  Like there, many of these companies have big businesses like did you mention

657
00:37:04,005 --> 00:37:06,525
Speaker 4:  Google is in this? Yeah. And it's, it is because of Google Cloud, right.

658
00:37:06,525 --> 00:37:10,365
Speaker 4:  Like we run data centers, we kind of need this to work

659
00:37:10,365 --> 00:37:14,245
Speaker 4:  because otherwise we're hosed paying Nvidia every penny we have for

660
00:37:14,265 --> 00:37:14,645
Speaker 4:  the rest of this.

661
00:37:14,645 --> 00:37:16,765
Speaker 3:  But it's funny because all those companies are also building their own chips

662
00:37:16,765 --> 00:37:17,205
Speaker 3:  on the side.

663
00:37:18,215 --> 00:37:18,505
Speaker 4:  Yeah,

664
00:37:18,515 --> 00:37:21,985
Speaker 3:  Right. Microsoft is building its own chips. They have a lot to say.

665
00:37:22,645 --> 00:37:25,865
Speaker 3:  If you're Microsoft and you want Arm on Windows to work, you get to walk

666
00:37:25,865 --> 00:37:29,185
Speaker 3:  in the Qualcomm's office and be like, do what we want. You're it.

667
00:37:29,615 --> 00:37:33,265
Speaker 3:  Yeah. Right. Or we're going back to Intel, which someone has to tell 'em

668
00:37:33,265 --> 00:37:34,825
Speaker 3:  what to do. Yeah. So you just see it's, it's

669
00:37:34,825 --> 00:37:38,105
Speaker 4:  Google's building TPUs like this is this. Yeah. Everybody is on this.

670
00:37:39,215 --> 00:37:43,025
Speaker 3:  Well, we'll see. I just think something is happening in the world of X 86

671
00:37:43,025 --> 00:37:46,665
Speaker 3:  trips and this is one of those things. That's what I got for you

672
00:37:46,865 --> 00:37:50,145
Speaker 3:  right now. And I will say that If, you are, if you're ever in a position

673
00:37:50,145 --> 00:37:53,425
Speaker 3:  to give a keynote and you're like, make the slide say we are alive and well

674
00:37:54,375 --> 00:37:58,365
Speaker 3:  just take a beat. Just really, just really think about what

675
00:37:58,365 --> 00:37:59,845
Speaker 3:  that means to everyone. Yeah.

676
00:37:59,915 --> 00:38:03,325
Speaker 4:  Yeah. I mean again, like it's it's them trying to

677
00:38:03,885 --> 00:38:07,285
Speaker 4:  convince the world. Allison Johnson who wrote the story

678
00:38:07,955 --> 00:38:11,805
Speaker 4:  made the point that this whole thing might have just been to convince

679
00:38:11,805 --> 00:38:14,765
Speaker 4:  investors that like, yes, we are taking Arm seriously.

680
00:38:16,845 --> 00:38:19,685
Speaker 4:  Might've been true. Really would've been a super good idea to do this in

681
00:38:19,685 --> 00:38:20,325
Speaker 4:  like 2017.

682
00:38:21,005 --> 00:38:24,325
Speaker 3:  Hmm. What If you face down the ferocious competitive

683
00:38:25,325 --> 00:38:29,245
Speaker 3:  monster of Nvidia with a committee that works as well as the USB and

684
00:38:29,245 --> 00:38:32,005
Speaker 3:  Influencers forum. Yeah. It's gonna be awesome.

685
00:38:32,235 --> 00:38:35,005
Speaker 4:  Give leather jackets to everyone on the committee. It's game over

686
00:38:35,685 --> 00:38:39,535
Speaker 3:  A couple more bits of Gadget News. Sonos announced a

687
00:38:39,535 --> 00:38:43,255
Speaker 3:  new Arc Ultra soundbar and Sub four, two pieces

688
00:38:43,285 --> 00:38:46,935
Speaker 3:  here. I would say one, I think they've decided the app is good enough again,

689
00:38:47,645 --> 00:38:51,495
Speaker 3:  like they had paused new releases because the app was so broken.

690
00:38:52,315 --> 00:38:55,895
Speaker 3:  But they, you know, they, we've talked about this, they've like released

691
00:38:55,895 --> 00:38:59,615
Speaker 3:  their plan to fix it. They've mostly fixed it. They're doing the

692
00:38:59,615 --> 00:39:03,055
Speaker 3:  public Trello board with the feature updates to come, which is incredible.

693
00:39:04,275 --> 00:39:08,135
Speaker 3:  You know, their Eddie Lazarus in their c-suite is, he has

694
00:39:08,135 --> 00:39:11,815
Speaker 3:  given his media tour about what he found and his report,

695
00:39:11,815 --> 00:39:15,425
Speaker 3:  which was we shouldn't have released a shitty app. Shocking

696
00:39:15,825 --> 00:39:18,985
Speaker 3:  Revolution. But I think they think they're fine. They've, they've gotten

697
00:39:18,985 --> 00:39:21,265
Speaker 3:  to where they need to be and it's time to start releasing products again.

698
00:39:21,445 --> 00:39:25,425
Speaker 3:  So it's a thousand dollars Arc Ultra. It's more powerful than the

699
00:39:25,425 --> 00:39:28,985
Speaker 3:  regular arc. And it's got new trans issues from a company called

700
00:39:29,295 --> 00:39:32,345
Speaker 3:  Mate Mate, M-A-Y-H-T-I

701
00:39:32,345 --> 00:39:33,065
Speaker 4:  Think it's mate Yeah.

702
00:39:33,605 --> 00:39:37,305
Speaker 3:  Sun Product. This company in 2022. They're like specialized

703
00:39:37,665 --> 00:39:41,585
Speaker 3:  speakers basically they call it sound motion. And the quote is

704
00:39:41,605 --> 00:39:44,025
Speaker 3:  one of the most significant breakthroughs in audio engineering's in nearly

705
00:39:44,045 --> 00:39:47,785
Speaker 3:  100 years that unlocks greater clarity, depth and

706
00:39:47,785 --> 00:39:51,545
Speaker 3:  balance than ever before possible in a soundbar. The sleek

707
00:39:52,315 --> 00:39:55,425
Speaker 3:  seven tweeters six mid wolfers a built-in

708
00:39:55,965 --> 00:39:59,625
Speaker 3:  Wolfer and you get 9 1 4 from all from the one soundbar.

709
00:39:59,855 --> 00:40:03,785
Speaker 4:  What do we know about sound motion? Like I I do feel like Sonos is not

710
00:40:04,175 --> 00:40:08,145
Speaker 4:  typically prone to grandiose lies about its own sound

711
00:40:08,145 --> 00:40:12,105
Speaker 4:  quality. So I'm, I'm more inclined than a lot of companies to believe them

712
00:40:12,105 --> 00:40:16,065
Speaker 4:  when they say this is a big deal. But I also, it just seems like

713
00:40:16,145 --> 00:40:16,985
Speaker 4:  a lot of words.

714
00:40:18,175 --> 00:40:21,545
Speaker 3:  It's a, it's a, it's definitely a lot of audio processing.

715
00:40:21,895 --> 00:40:22,185
Speaker 4:  Okay.

716
00:40:22,865 --> 00:40:26,645
Speaker 3:  But like So I I food audio process, the original arc long time

717
00:40:26,725 --> 00:40:30,365
Speaker 3:  ago and I tested it against my own 5 1 4 at with

718
00:40:30,705 --> 00:40:34,085
Speaker 3:  actual speakers in the ceiling. And I thought the Arc did a great job actually,

719
00:40:35,105 --> 00:40:36,805
Speaker 3:  but it was obviously more processed.

720
00:40:37,115 --> 00:40:37,405
Speaker 4:  Yeah.

721
00:40:37,595 --> 00:40:40,725
Speaker 3:  Like that was the trade off. Like very clearly the trade off was,

722
00:40:41,505 --> 00:40:45,165
Speaker 3:  boy there's not as much stuff happening around me when I used my

723
00:40:45,165 --> 00:40:49,125
Speaker 3:  actual system versus the arc. And the arc is like, boy there's a lot of stuff

724
00:40:49,125 --> 00:40:52,725
Speaker 3:  happening around you and boy, it just sounds like more

725
00:40:53,255 --> 00:40:57,165
Speaker 3:  audio processing is occurring to make it seem like a bunch of stuff is happening

726
00:40:57,165 --> 00:41:00,445
Speaker 3:  all around you. I, yeah, I've never been happy with how these things sound

727
00:41:00,445 --> 00:41:04,115
Speaker 3:  for music. I just think music and movies are two different things. Yeah.

728
00:41:04,135 --> 00:41:07,755
Speaker 3:  So I haven't heard this yet. I'm excited to hear it. I know Chris Welch is

729
00:41:07,755 --> 00:41:11,275
Speaker 3:  excited to review it. But you know, the notable thing is

730
00:41:12,185 --> 00:41:14,755
Speaker 3:  we're getting to the place where

731
00:41:15,385 --> 00:41:19,235
Speaker 3:  9 1 4 out of a soundbar is possible. Yeah. For a thousand

732
00:41:19,235 --> 00:41:22,395
Speaker 3:  dollars, which is, if all that works, that is incredible.

733
00:41:23,335 --> 00:41:27,305
Speaker 3:  That is a system that would, you know, even If, you buy cheap speakers, a

734
00:41:27,545 --> 00:41:31,265
Speaker 3:  receiver that can support 9 1 4, like you're, you're out for

735
00:41:31,825 --> 00:41:35,405
Speaker 3:  thousands of dollars and then you gotta put 'em on the ceiling. So to do

736
00:41:35,405 --> 00:41:37,205
Speaker 3:  it in a soundbar for a thousand bucks is pretty cool.

737
00:41:37,315 --> 00:41:41,085
Speaker 4:  Well and that's, I I think that's been Sonos thing with Soundbars for

738
00:41:41,205 --> 00:41:44,005
Speaker 4:  a minute now. Even what you're describing about the ace right. Is like, it's,

739
00:41:44,355 --> 00:41:48,225
Speaker 4:  it's almost as good or like very

740
00:41:48,225 --> 00:41:51,425
Speaker 4:  good if not as good with

741
00:41:51,615 --> 00:41:55,585
Speaker 4:  essentially none of the effort. Right? Like it's, and and that's I

742
00:41:55,585 --> 00:41:58,705
Speaker 4:  think the whole pitch of Soundbars in general. I have become a big believer

743
00:41:58,805 --> 00:42:02,145
Speaker 4:  in Soundbars as somebody who is like, just not going to

744
00:42:03,405 --> 00:42:06,865
Speaker 4:  put nine speakers in my house. It's just not gonna happen. I'd love to but

745
00:42:06,865 --> 00:42:10,625
Speaker 4:  it's not gonna happen. But I think the idea that If, you If you

746
00:42:10,705 --> 00:42:14,385
Speaker 4:  can use this processing to get even most of the way there

747
00:42:14,695 --> 00:42:18,465
Speaker 4:  with just a thing I plant in front of my television. That's pretty powerful.

748
00:42:18,495 --> 00:42:21,465
Speaker 4:  Like I, I think that's, that goes a really long way for an awful lot of people.

749
00:42:21,705 --> 00:42:24,385
Speaker 3:  I just wanna be clear, 9 1 4 is not nine speakers, it's 13.

750
00:42:24,725 --> 00:42:25,785
Speaker 4:  You're right. I apologize

751
00:42:25,925 --> 00:42:28,585
Speaker 3:  That's that and that's bonkers. Like I have a, I'll

752
00:42:28,585 --> 00:42:30,225
Speaker 4:  Put in nine, I'm not putting in 13 right?

753
00:42:30,985 --> 00:42:34,585
Speaker 3:  I have a 5 1 4 system which is nine and that's a lot of speakers.

754
00:42:35,135 --> 00:42:37,145
Speaker 3:  Like arguably too many

755
00:42:38,545 --> 00:42:42,475
Speaker 3:  9 1 4 out of a soundbar is legitimately kind of cool if

756
00:42:42,475 --> 00:42:46,195
Speaker 3:  it works. So I'm excited for that. By the way, the quote from CO Patrick Spence

757
00:42:46,655 --> 00:42:49,755
Speaker 3:  is we have reached a level of quality in the app that gives us the confidence

758
00:42:49,755 --> 00:42:51,595
Speaker 3:  to launch our extraordinary new products.

759
00:42:53,505 --> 00:42:57,315
Speaker 3:  They have 90% of the previous apps features with the

760
00:42:57,315 --> 00:42:58,915
Speaker 3:  forthcoming update and more on the way.

761
00:42:59,395 --> 00:43:02,755
Speaker 4:  I think that's all fine. I also think at some point if you're Sonos, you

762
00:43:02,755 --> 00:43:06,595
Speaker 4:  just have to start shipping stuff. Like you can, you, you can only sort of

763
00:43:06,595 --> 00:43:10,355
Speaker 4:  sit there and apologize so many times and eventually you have to ship new

764
00:43:10,355 --> 00:43:13,955
Speaker 4:  things and it's about to be the holidays. And I think like we just got to

765
00:43:13,955 --> 00:43:17,595
Speaker 4:  the point where they're like, well it is what it's Yeah,

766
00:43:17,755 --> 00:43:19,955
Speaker 4:  we're just gonna ship the thing, which I think is fine. Right? Like you,

767
00:43:20,135 --> 00:43:22,955
Speaker 4:  how, I don't know how much longer they're supposed to sit and sort of beat

768
00:43:22,955 --> 00:43:25,195
Speaker 4:  themselves up about the very bad app that they shipped.

769
00:43:25,825 --> 00:43:28,795
Speaker 3:  Yeah, I well I'm dying to listen to this thing. I'm dying to review it. I

770
00:43:28,795 --> 00:43:31,995
Speaker 3:  will say one of the If, you have a regular sort of

771
00:43:32,065 --> 00:43:35,795
Speaker 3:  5.1 system. The, the biggest, most noticeable

772
00:43:35,795 --> 00:43:37,595
Speaker 3:  upgrade is front height.

773
00:43:38,255 --> 00:43:38,875
Speaker 4:  Oh, interesting. So

774
00:43:38,875 --> 00:43:42,315
Speaker 3:  You have your three speakers in front of you. The, the most immediate upgrade

775
00:43:42,375 --> 00:43:46,195
Speaker 3:  is not over your head. It's in front of you and up.

776
00:43:46,675 --> 00:43:50,665
Speaker 3:  Hmm. 'cause your ears are pointed to the front, some basic

777
00:43:50,665 --> 00:43:54,465
Speaker 3:  biology. So you put the two speakers above your other speakers and they,

778
00:43:54,525 --> 00:43:58,185
Speaker 3:  things are coming at you from above there. That's just a huge upgrade. If,

779
00:43:58,185 --> 00:44:01,665
Speaker 3:  you can figure out how to get that upgrade today, you should do it. But a

780
00:44:01,665 --> 00:44:04,865
Speaker 3:  sound bar or even the speakers you put on top of your speakers are sort of

781
00:44:04,865 --> 00:44:07,505
Speaker 3:  necessarily reflecting from the middle.

782
00:44:09,035 --> 00:44:12,435
Speaker 3:  'cause they can't make the sound come from straight up. So that's always

783
00:44:12,435 --> 00:44:15,995
Speaker 3:  the thing I'm curious about. We'll see. Interesting. Revolutionary new transducers.

784
00:44:15,995 --> 00:44:16,195
Speaker 3:  David,

785
00:44:16,735 --> 00:44:20,555
Speaker 4:  Listen, I still listen to the audio out of my crappy TCL

786
00:44:20,675 --> 00:44:24,315
Speaker 4:  Roku tv. I'm coming to your house, So I am I am looking forward to the day

787
00:44:24,705 --> 00:44:26,835
Speaker 4:  that one of these feels worth buying.

788
00:44:27,515 --> 00:44:30,675
Speaker 3:  I have my old five one system from college, like sitting in storage. I'm

789
00:44:30,675 --> 00:44:33,125
Speaker 3:  just gonna drive to your house. It's not great.

790
00:44:33,345 --> 00:44:36,925
Speaker 4:  Listen, every time I leave for work, I come home and Anna has like

791
00:44:37,125 --> 00:44:40,365
Speaker 4:  rearranged one room in our house. I think next time she leaves you should

792
00:44:40,365 --> 00:44:43,605
Speaker 4:  come over and we'll just set up speakers everywhere. It'll be awesome.

793
00:44:44,505 --> 00:44:48,205
Speaker 3:  All right, last one. It's this four KN 64 from Analogue. I'm so

794
00:44:48,205 --> 00:44:48,565
Speaker 3:  excited

795
00:44:48,565 --> 00:44:52,285
Speaker 4:  About this thing. So this thing has been a year in the making maybe.

796
00:44:53,325 --> 00:44:56,965
Speaker 4:  I think like we, we've been getting teases about this for an incredibly long

797
00:44:56,965 --> 00:45:00,885
Speaker 4:  time. It's called the Analogue 3D. It just looks like a Nintendo

798
00:45:00,885 --> 00:45:04,685
Speaker 4:  64. Actually the thing kinda looks like a Sega Genesis, but

799
00:45:04,785 --> 00:45:07,685
Speaker 4:  it, it'll play 64 cartridges. It has a controller.

800
00:45:08,585 --> 00:45:12,485
Speaker 4:  As somebody who grew up with the N 64, like the, the way I would date

801
00:45:12,485 --> 00:45:14,485
Speaker 4:  my childhood is the Nintendo 64.

802
00:45:16,305 --> 00:45:19,805
Speaker 4:  I'm so excited about this thing. And Analogue does a really great job of

803
00:45:20,205 --> 00:45:22,605
Speaker 4:  emulating stuff and, and letting you play old cartridges with these things.

804
00:45:23,365 --> 00:45:27,245
Speaker 4:  I have, I have every confidence that this thing is actually gonna

805
00:45:27,245 --> 00:45:30,845
Speaker 4:  work really well. The N 64 is notoriously hard to emulator and

806
00:45:31,325 --> 00:45:34,445
Speaker 4:  Analogue seems to feel very good about having pulled it off, which I'm excited

807
00:45:34,445 --> 00:45:34,685
Speaker 4:  about.

808
00:45:35,195 --> 00:45:38,085
Speaker 3:  They changed the controller to now have the weird third thing in the middle,

809
00:45:38,095 --> 00:45:38,685
Speaker 3:  which I think

810
00:45:38,685 --> 00:45:42,125
Speaker 4:  Is, which is a bummer to be honest. Like I I love the stupid controller.

811
00:45:42,345 --> 00:45:45,925
Speaker 4:  It never made any sense because you only ever held the middle one and the

812
00:45:45,925 --> 00:45:46,285
Speaker 4:  right one.

813
00:45:46,555 --> 00:45:46,845
Speaker 3:  Yeah.

814
00:45:47,115 --> 00:45:51,045
Speaker 4:  Because you're not, you don't have three hands. But it does still

815
00:45:51,155 --> 00:45:55,125
Speaker 4:  have the, the ports on the front for plugging in

816
00:45:55,125 --> 00:45:59,085
Speaker 4:  an N 64 controller, which I love. I don't know if it actually even

817
00:45:59,085 --> 00:46:01,325
Speaker 4:  works, but as it just as the way it looks, I'm into it.

818
00:46:02,105 --> 00:46:05,405
Speaker 3:  Let me ask you a really dumb question. This only takes cartridges or you

819
00:46:05,405 --> 00:46:09,205
Speaker 3:  can play off cards like SD cards.

820
00:46:09,365 --> 00:46:10,525
Speaker 3:  I think it only takes cartridges.

821
00:46:10,745 --> 00:46:14,645
Speaker 4:  So No, it, it takes, it has two USB ports and an SD card slot. So

822
00:46:14,645 --> 00:46:16,845
Speaker 4:  you'll you'll in theory be able to, you'll be able to put other stuff onto

823
00:46:16,845 --> 00:46:20,805
Speaker 4:  it. But the, the thing is, and I wonder how true this is, I think there

824
00:46:20,825 --> 00:46:24,365
Speaker 4:  are probably a lot of people out there who still have a box full of n 64

825
00:46:24,365 --> 00:46:28,245
Speaker 3:  Cartridges. I mean, I intend to only play on my legally acquired n 64 cartridges.

826
00:46:28,405 --> 00:46:28,685
Speaker 3:  I don't

827
00:46:28,685 --> 00:46:30,925
Speaker 4:  Know what you're talking about. Yeah, I'm gonna, I'm gonna dump them as I

828
00:46:30,925 --> 00:46:33,885
Speaker 4:  always do and always have, which is how I play goldeneye now.

829
00:46:35,955 --> 00:46:37,485
Speaker 4:  It's it's totally fine. I bought

830
00:46:37,485 --> 00:46:40,365
Speaker 3:  One of those Amber Nick game boys.

831
00:46:41,345 --> 00:46:41,565
Speaker 3:  And

832
00:46:41,565 --> 00:46:44,685
Speaker 4:  So the one that just ships with like 6,000 games on it from Amazon. Yeah,

833
00:46:44,685 --> 00:46:44,965
Speaker 4:  great.

834
00:46:45,945 --> 00:46:49,045
Speaker 3:  And we had friends over and someone was like, what's this and the other,

835
00:46:49,155 --> 00:46:49,965
Speaker 3:  just without missing

836
00:48:20,545 --> 00:48:24,485
Speaker 3:  All right, we're back. So Amazon introduced new Kindles this week. David,

837
00:48:24,545 --> 00:48:28,325
Speaker 3:  you were at the event. I was, which very notably

838
00:48:28,505 --> 00:48:32,285
Speaker 3:  was the first event at Amazon for Panos Penne who first house

839
00:48:32,285 --> 00:48:34,845
Speaker 3:  listeners almost certainly remember from his time at Microsoft when he ran

840
00:48:34,845 --> 00:48:37,485
Speaker 3:  Windows and Surface. How was that event?

841
00:48:37,905 --> 00:48:41,525
Speaker 4:  Really interesting. So I think they, they did it in a very unusual way. It

842
00:48:41,525 --> 00:48:45,405
Speaker 4:  was like a, it was an embargoed event. So the whole existence of

843
00:48:45,405 --> 00:48:49,045
Speaker 4:  the thing was not public. It was basically just like a media

844
00:48:49,365 --> 00:48:51,765
Speaker 4:  briefing. But they framed it in his event upon us, like got up on stage and

845
00:48:51,765 --> 00:48:55,085
Speaker 4:  gave a whole speech very clearly what's going on is

846
00:48:56,845 --> 00:49:00,125
Speaker 4:  whenever they do a big public thing, it is going to have to be the future

847
00:49:00,125 --> 00:49:04,005
Speaker 4:  of Alexa. But they wanted to like give the Kindle its moment,

848
00:49:04,015 --> 00:49:07,565
Speaker 4:  right? And they launched four Kindles at once, which I think has never happened

849
00:49:07,565 --> 00:49:11,445
Speaker 4:  in the history of the Kindle. That it was like, it's a full line reset. And

850
00:49:12,105 --> 00:49:15,965
Speaker 4:  it was fun. Like the, the, this team loves Kindles. I always forget how

851
00:49:15,965 --> 00:49:19,925
Speaker 4:  many people love Kindles. Like the, the traffic to our website on the

852
00:49:19,925 --> 00:49:23,005
Speaker 4:  day. It suggests that a lot of people really care about Kindles

853
00:49:23,745 --> 00:49:27,125
Speaker 4:  and the, the team has been making stuff. Ponos has been there for like almost

854
00:49:27,125 --> 00:49:30,405
Speaker 4:  exactly a year and has done a lot of stuff with the Kindle team since he's

855
00:49:30,405 --> 00:49:34,325
Speaker 4:  been there. So it was cool to actually just get to like live

856
00:49:34,545 --> 00:49:37,805
Speaker 4:  in Kindle universe for a minute. Normally they just like update the website

857
00:49:37,805 --> 00:49:40,485
Speaker 4:  and it's like, here's some new Kindles. And this was like, this was much

858
00:49:40,485 --> 00:49:41,085
Speaker 4:  bigger than that.

859
00:49:41,465 --> 00:49:42,885
Speaker 3:  So what are the new ones? So

860
00:49:42,885 --> 00:49:46,445
Speaker 4:  There's four and I, I'll go from cheapest to most expensive. So the

861
00:49:46,445 --> 00:49:50,365
Speaker 4:  cheapest is just the regular Kindle, which has some, you know,

862
00:49:50,495 --> 00:49:53,645
Speaker 4:  speck improvements. It's a little brighter. It comes in a really cool new

863
00:49:53,665 --> 00:49:57,445
Speaker 4:  matcha color that I like a lot. But it's still just the base

864
00:49:57,465 --> 00:50:00,645
Speaker 4:  Kindle. The new Paperweight has a bigger screen,

865
00:50:01,605 --> 00:50:04,485
Speaker 4:  brighter screen, faster processing. They like redesigned it a little bit.

866
00:50:04,485 --> 00:50:08,005
Speaker 4:  It has some really nice, like vibrant colors. One thing I heard a bunch from

867
00:50:08,005 --> 00:50:11,765
Speaker 4:  folks at Amazon was the whole sort of book talk movement and the thing where

868
00:50:11,765 --> 00:50:14,645
Speaker 4:  people are like bedazzling their Kindles has really changed the way they

869
00:50:14,645 --> 00:50:17,565
Speaker 4:  think about the device. So they're leaning into sort of making it more fun.

870
00:50:19,065 --> 00:50:23,045
Speaker 4:  The Paperweight is the Kindle right in like a very real way. It is, it is

871
00:50:23,045 --> 00:50:26,965
Speaker 4:  the biggest, most important Kindle in the lineup. New one seems to be

872
00:50:27,005 --> 00:50:30,805
Speaker 4:  very good. There's the Kindle scribe, which is the, the biggest

873
00:50:30,945 --> 00:50:34,885
Speaker 4:  one that you can take notes on. They made lots of changes to that, including

874
00:50:34,915 --> 00:50:38,525
Speaker 4:  some gen AI stuff where you can write your notes and then have

875
00:50:38,745 --> 00:50:42,205
Speaker 4:  the scribe either summarize them or just like neatly format them and fix

876
00:50:42,205 --> 00:50:45,125
Speaker 4:  your handwriting so you can share them and find them more easily.

877
00:50:46,185 --> 00:50:49,685
Speaker 4:  But that's still described. And then the big announcement was the, the Kindle

878
00:50:49,685 --> 00:50:53,405
Speaker 4:  Color Soft, which is the first color Kindle. And basically it's a paper white

879
00:50:53,835 --> 00:50:57,485
Speaker 4:  with a color display. And they've done some really interesting like

880
00:50:57,485 --> 00:51:01,445
Speaker 4:  display stack work to make that work. It's very expensive, but

881
00:51:01,445 --> 00:51:05,365
Speaker 4:  it is like the one that they were like, this is sort of

882
00:51:05,385 --> 00:51:09,245
Speaker 4:  the moment for a new Kindle looks really

883
00:51:09,245 --> 00:51:12,085
Speaker 4:  great. I like you look at color and it's like, what do I need from color

884
00:51:12,345 --> 00:51:15,005
Speaker 4:  in a reading device? But then just looking at it on a table,

885
00:51:15,985 --> 00:51:19,765
Speaker 4:  seeing the book cover and now it's in color. It's just instantly like, oh,

886
00:51:19,765 --> 00:51:20,765
Speaker 4:  this is great. Yeah,

887
00:51:21,245 --> 00:51:24,565
Speaker 3:  I was, I played with the new paper, right, you had in the office and it's

888
00:51:24,565 --> 00:51:25,525
Speaker 3:  very fast. That's

889
00:51:25,525 --> 00:51:27,765
Speaker 4:  Awesome. Super fast. Yeah, that's a good advice.

890
00:51:28,645 --> 00:51:31,285
Speaker 3:  I, the only other thing I'll say is I asked back if she wanted to call her

891
00:51:31,285 --> 00:51:33,805
Speaker 3:  Kindle and she just looked at me and said, stop trying to buy me Kindles.

892
00:51:34,955 --> 00:51:37,085
Speaker 3:  This is the problem. You're in here. We're gonna talk about it right now

893
00:51:37,115 --> 00:51:40,325
Speaker 3:  with Panus Penne. And once we're done with that, we're gonna go to an ad.

894
00:51:40,325 --> 00:51:43,245
Speaker 3:  We'll be back with the lightning round. Here's Kindles with Panos Pane.

895
00:51:43,535 --> 00:51:45,205
Speaker 4:  Panos Pane, Welcome, To, The Vergecast. What's

896
00:51:45,205 --> 00:51:45,925
Speaker 6:  Going on guys? Have

897
00:51:45,925 --> 00:51:49,645
Speaker 4:  You been on The Vergecast before? Yeah. Okay. Yeah. But not in your current

898
00:51:49,915 --> 00:51:51,605
Speaker 4:  iteration, new Anos.

899
00:51:54,385 --> 00:51:56,205
Speaker 3:  Do you feel like a different person? No.

900
00:51:58,365 --> 00:52:01,845
Speaker 7:  I mean, you guys come right out swinging it. Yeah.

901
00:52:02,765 --> 00:52:04,845
Speaker 7:  Unbelievable. We gotta do this for

902
00:52:04,845 --> 00:52:05,845
Speaker 6:  30 minutes. Yeah. Yeah.

903
00:52:06,055 --> 00:52:06,765
Speaker 4:  We're just getting started.

904
00:52:07,185 --> 00:52:08,645
Speaker 7:  We got lot to do. So

905
00:52:09,205 --> 00:52:09,405
Speaker 4:  I. Feel

906
00:52:09,405 --> 00:52:10,965
Speaker 6:  Like good to see you guys. It's good to see you guys.

907
00:52:11,295 --> 00:52:14,885
Speaker 4:  We've got a lot of news to talk about. You launched several thousand new

908
00:52:14,885 --> 00:52:16,165
Speaker 4:  Kindles that we have to talk about.

909
00:52:16,985 --> 00:52:20,245
Speaker 6:  It is the most, it is the most Kindle's been launched, I think, in history

910
00:52:20,245 --> 00:52:20,645
Speaker 6:  of Kindle,

911
00:52:20,645 --> 00:52:22,565
Speaker 4:  Which is kind of fascinating and it's part of what we should talk about.

912
00:52:22,625 --> 00:52:26,165
Speaker 4:  But the, let's just start with you. I think our audience

913
00:52:26,295 --> 00:52:29,645
Speaker 4:  knows you well over the years. You've, you've launched a lot of things. You've

914
00:52:29,645 --> 00:52:33,405
Speaker 4:  been a product guy for a really long time. Why? Why'd you go to Amazon?

915
00:52:33,635 --> 00:52:35,165
Speaker 4:  Tell us the, the p transition,

916
00:52:35,165 --> 00:52:37,845
Speaker 3:  The audience does know, but you were Microsoft for the longest time. You

917
00:52:37,845 --> 00:52:41,125
Speaker 3:  did all the surface stuff there, and then it was kind of a surprise, right?

918
00:52:41,305 --> 00:52:44,685
Speaker 3:  You left Microsoft to go to Amazon.

919
00:52:45,155 --> 00:52:48,405
Speaker 3:  That was a surprise. I think people are very curious why, why the move? I

920
00:52:48,405 --> 00:52:51,765
Speaker 3:  feel like you had a ring camera and you were maybe had a bug and you're like,

921
00:52:51,945 --> 00:52:53,085
Speaker 3:  I'm going to Amazon. There

922
00:52:53,085 --> 00:52:55,005
Speaker 6:  Were a few details I wanted to get. I wanted to

923
00:52:55,005 --> 00:52:56,285
Speaker 7:  Get, is

924
00:52:56,285 --> 00:52:57,445
Speaker 6:  Enough of this enough?

925
00:52:58,385 --> 00:53:02,325
Speaker 7:  Fix this right now. You know what? I'm just gonna go somewhere

926
00:53:02,345 --> 00:53:04,085
Speaker 7:  new to fix it. Yeah. Yeah. I

927
00:53:04,085 --> 00:53:06,685
Speaker 6:  Don't think it was exactly that, but there is a, there's a, there's a little

928
00:53:06,685 --> 00:53:09,605
Speaker 6:  bit, there's a little bit to that. You know, when you think about the array

929
00:53:09,605 --> 00:53:13,205
Speaker 6:  of products between Ring, blink, arrow, fire, tv, fire

930
00:53:13,555 --> 00:53:17,125
Speaker 6:  tablets, Alexa, echo, Kindle,

931
00:53:18,365 --> 00:53:21,685
Speaker 6:  satellites, zoos. Like, you just look at that and you go, what, what could

932
00:53:21,685 --> 00:53:25,085
Speaker 6:  you do? And when this technological pipe,

933
00:53:25,865 --> 00:53:29,245
Speaker 6:  you know, of AI that's coming, which eventually ends up being a red thread

934
00:53:29,245 --> 00:53:32,405
Speaker 6:  between all these things, how they all connect and you can change people's

935
00:53:32,405 --> 00:53:36,245
Speaker 6:  lives. Like yeah, it's not a bug. It's just

936
00:53:36,285 --> 00:53:40,085
Speaker 6:  a, it's just awesome. Like awesome. And so, you know, it

937
00:53:40,085 --> 00:53:42,125
Speaker 6:  energized me. Plus, you know,

938
00:53:44,685 --> 00:53:48,665
Speaker 6:  it, it's, it's like a, another chapters is a great thing. It's a

939
00:53:48,665 --> 00:53:49,505
Speaker 6:  cool thing. Yeah.

940
00:53:49,885 --> 00:53:53,555
Speaker 4:  Is there a, is there an underlying AI bet

941
00:53:53,555 --> 00:53:57,435
Speaker 4:  underneath all of that? Like when you came in, 'cause I think you, you

942
00:53:57,435 --> 00:54:01,115
Speaker 4:  were making this move, right? Kind of at the

943
00:54:01,115 --> 00:54:05,035
Speaker 4:  beginning of the Holy crap. AI is going to change everything.

944
00:54:05,225 --> 00:54:07,995
Speaker 4:  Yeah. Moment. And we've been talking to people now for, you know, two years

945
00:54:08,375 --> 00:54:11,795
Speaker 4:  who are like, everything that you can see or touch or imagine,

946
00:54:12,145 --> 00:54:14,675
Speaker 4:  it's a platform shift. AI is right. It's a platform shift. Like, is that,

947
00:54:15,015 --> 00:54:15,435
Speaker 4:  is that your

948
00:54:15,585 --> 00:54:19,395
Speaker 6:  It's a real one too. Like it's very real. Yeah, it's a hundred percent that.

949
00:54:20,265 --> 00:54:24,125
Speaker 6:  And so when you ask the question like, why did you go to Amazon? Like

950
00:54:24,125 --> 00:54:25,405
Speaker 6:  first it's an amazing company.

951
00:54:27,385 --> 00:54:30,805
Speaker 6:  Second, the values are crazy cool, you know,

952
00:54:31,625 --> 00:54:32,125
Speaker 6:  but third,

953
00:54:36,305 --> 00:54:40,035
Speaker 6:  wow. Like that shift is real.

954
00:54:40,375 --> 00:54:44,235
Speaker 6:  And I think what you can do, especially in the consumer space,

955
00:54:44,385 --> 00:54:47,915
Speaker 6:  what you can do for people in their everyday lives is off the charts. So

956
00:54:47,915 --> 00:54:51,835
Speaker 6:  If, you combine it, you know, it gets a pretty easy answer.

957
00:54:52,775 --> 00:54:56,435
Speaker 6:  Not simple, you know, challenging as a human, you know,

958
00:54:56,435 --> 00:54:59,155
Speaker 6:  emotional and on every way. No question.

959
00:54:59,375 --> 00:55:01,995
Speaker 3:  Let me just ask you this. You, you said there, you, you named all the things.

960
00:55:02,385 --> 00:55:05,755
Speaker 3:  Zoox is the autonomous taxis, KU

961
00:55:06,005 --> 00:55:06,355
Speaker 6:  Robax.

962
00:55:06,545 --> 00:55:07,515
Speaker 3:  Robotaxis. Yeah. Think

963
00:55:07,515 --> 00:55:07,915
Speaker 6:  About it that way.

964
00:55:09,175 --> 00:55:13,015
Speaker 3:  Kuper is the satellites. What is the connection between Kindle and the

965
00:55:13,255 --> 00:55:13,615
Speaker 3:  satellites?

966
00:55:13,675 --> 00:55:16,295
Speaker 6:  You don't, you don't need to stretch. Okay. You don't need to stretch everything

967
00:55:16,295 --> 00:55:19,015
Speaker 6:  and pull 'em together. That's not the goal. Okay. It's just the, you know,

968
00:55:19,195 --> 00:55:22,135
Speaker 6:  how you impact people's lives is different in those things. Okay.

969
00:55:22,415 --> 00:55:22,895
Speaker 3:  I was just wondering

970
00:55:22,935 --> 00:55:26,655
Speaker 6:  'cause you getting broadband to everybody versus, and let's just think about

971
00:55:26,655 --> 00:55:30,495
Speaker 6:  the impact that has on people. Like, and for, for me, like, it's like a dream.

972
00:55:32,125 --> 00:55:35,605
Speaker 6:  You have, you know, helping people read, learn, create.

973
00:55:35,945 --> 00:55:39,645
Speaker 6:  That's one side on a Kindle. And so game

974
00:55:39,925 --> 00:55:43,685
Speaker 6:  changing for life to make sure, you know, you're reading, learning, getting

975
00:55:43,685 --> 00:55:46,805
Speaker 6:  into a book, disappearing into it. And that's one, that's one way to think

976
00:55:46,805 --> 00:55:50,725
Speaker 6:  about like, it's just positive everywhere. And then

977
00:55:50,965 --> 00:55:53,245
Speaker 6:  satellites are distributing broadband to the world where everybody needs

978
00:55:53,245 --> 00:55:57,205
Speaker 6:  it. Like same like impact. Both are massive, but very different ways.

979
00:55:57,205 --> 00:55:58,005
Speaker 6:  Yeah, very different ways.

980
00:55:58,225 --> 00:56:01,205
Speaker 3:  One of the things that could connect a bunch of these products is Alexa,

981
00:56:01,355 --> 00:56:05,125
Speaker 3:  obviously you're talking about ai. Yeah. The opportunity for Alexa

982
00:56:05,265 --> 00:56:09,245
Speaker 3:  to be a smarter kind of AI product. I think a lot of people can see it. Yeah.

983
00:56:09,545 --> 00:56:10,805
Speaker 3:  Is that happening? You, you working

984
00:56:10,805 --> 00:56:11,365
Speaker 6:  On that? Yeah,

985
00:56:13,145 --> 00:56:16,405
Speaker 6:  we are working on it. You know, I'm not necessarily here to talk about it.

986
00:56:16,525 --> 00:56:20,445
Speaker 6:  I think I'll be back soon to talk about it. So another way to say it. I mean,

987
00:56:20,445 --> 00:56:24,045
Speaker 6:  if you'll have me back. Yeah, we'll see. 'cause so far I'm frustrated with

988
00:56:24,045 --> 00:56:26,245
Speaker 6:  both of you, so we'll see how this goes. Like how it ends.

989
00:56:26,425 --> 00:56:29,085
Speaker 4:  No, that's right. It'll stay like that. Yeah, that's what we keep doing here.

990
00:56:29,175 --> 00:56:30,405
Speaker 3:  We're gonna keep this carefully

991
00:56:30,605 --> 00:56:31,805
Speaker 4:  Calibrated. Yeah, it goes fine. Like

992
00:56:31,975 --> 00:56:33,085
Speaker 3:  Right at, should I leave?

993
00:56:33,195 --> 00:56:36,325
Speaker 6:  Yeah, like, just start right away. I'm sorry. Why did you go to off? Like

994
00:56:36,325 --> 00:56:37,725
Speaker 6:  what? Come on man. You

995
00:56:38,545 --> 00:56:42,445
Speaker 3:  People, I mean, you were the face of products people love for a long time.

996
00:56:43,485 --> 00:56:46,405
Speaker 3:  I mean, you just had an event. You, David, I think you were at the Kindle

997
00:56:46,405 --> 00:56:50,245
Speaker 3:  launch event and I got an immediate text from David that's like, I missed

998
00:56:50,325 --> 00:56:52,565
Speaker 3:  a Panos pane presentation. Like did

999
00:56:52,565 --> 00:56:55,125
Speaker 4:  You I did. I really did that text. I sent him that text. You did? Yeah.

1000
00:56:55,125 --> 00:56:58,485
Speaker 6:  Yeah. Yeah. It was a little, it was, it was a less of a tech presentation

1001
00:56:58,485 --> 00:57:00,885
Speaker 6:  yesterday. Yeah. Little bit, little bit different. Yeah.

1002
00:57:01,145 --> 00:57:04,645
Speaker 3:  And I just, that was, Microsoft also has a big platform and has a lot of

1003
00:57:04,645 --> 00:57:07,165
Speaker 3:  products that you can connect in different kinds of narratives. Sure. You

1004
00:57:07,165 --> 00:57:11,045
Speaker 3:  were great at that. I I was just curious like the, the jump from one

1005
00:57:11,065 --> 00:57:15,045
Speaker 3:  big company's ecosystem to another big company's ecosystem, trying to

1006
00:57:15,155 --> 00:57:18,045
Speaker 3:  pull them together. It seems like the same challenge, but it sounds very

1007
00:57:18,245 --> 00:57:21,725
Speaker 3:  much like you think of the opportunities as as different. They're

1008
00:57:21,725 --> 00:57:24,925
Speaker 6:  Very different. You know, they're very different. And, and the way I look

1009
00:57:24,925 --> 00:57:28,565
Speaker 6:  at it at Amazon, like the amount of consumers you connect around the world

1010
00:57:30,525 --> 00:57:33,695
Speaker 6:  with the technology shift, you know, it seems like buzzword at this point

1011
00:57:33,715 --> 00:57:37,615
Speaker 6:  to say ai, I can't, it's so hard for me to, and with ai,

1012
00:57:39,805 --> 00:57:43,615
Speaker 6:  What we're gonna be able to do with Alexa just to connect people. I,

1013
00:57:43,795 --> 00:57:46,855
Speaker 6:  I'm not talking about it in detail today, but man, this is gonna be transformative

1014
00:57:47,615 --> 00:57:51,275
Speaker 6:  and how it connects throughout your life with all the devices that we just

1015
00:57:51,275 --> 00:57:54,995
Speaker 6:  talked about, all the brands that are coming together, both in the home and

1016
00:57:54,995 --> 00:57:57,995
Speaker 6:  outside of the home. It's just, it's off the, it's so, it's,

1017
00:57:58,745 --> 00:58:02,315
Speaker 6:  it's so energizing. There's another side to it too, though. You, you, like,

1018
00:58:02,855 --> 00:58:06,635
Speaker 6:  the leadership principles at Amazon are surreal. They're fully

1019
00:58:06,635 --> 00:58:08,515
Speaker 6:  aligned with the way I love running teams.

1020
00:58:10,535 --> 00:58:13,635
Speaker 6:  You know, connecting people and what it means to focus on a customer.

1021
00:58:14,295 --> 00:58:17,155
Speaker 4:  All right. Well before this becomes a full decoder episode that you're, you're

1022
00:58:17,155 --> 00:58:19,395
Speaker 4:  gonna do at some point, I have lots of questions about leadership principles

1023
00:58:19,395 --> 00:58:22,515
Speaker 4:  that you guys will get to some other time. Let's talk about gadgets. Yeah,

1024
00:58:22,575 --> 00:58:24,875
Speaker 6:  I'd love that. We can talk about leadership principles all day. Those are,

1025
00:58:24,875 --> 00:58:27,115
Speaker 6:  they're just, they're awesome. But if you're not gonna let me, that's

1026
00:58:27,115 --> 00:58:27,755
Speaker 3:  The other show. I think that's,

1027
00:58:27,755 --> 00:58:30,115
Speaker 4:  That's the other show. There's time for that. We'll do that, we'll do that

1028
00:58:30,115 --> 00:58:33,915
Speaker 4:  somewhere else but Kindles. So yeah, the, I'm, I'm fascinated

1029
00:58:33,915 --> 00:58:37,555
Speaker 4:  by just the scope of this launch. Like you said, it was four Kindles at once,

1030
00:58:37,645 --> 00:58:40,835
Speaker 4:  which I think Amazon has never, ever done. And I feel like

1031
00:58:41,775 --> 00:58:45,635
Speaker 4:  that's either like an accident of technological development or

1032
00:58:45,635 --> 00:58:49,315
Speaker 4:  like a very much on purpose. Kindles were

1033
00:58:49,415 --> 00:58:53,395
Speaker 4:  so back kind of moment. Which one of those

1034
00:58:53,395 --> 00:58:53,835
Speaker 4:  things is it?

1035
00:58:54,115 --> 00:58:57,315
Speaker 6:  I mean, seriously, come on. It is not gonna be an accident as, you know,

1036
00:58:57,355 --> 00:59:00,595
Speaker 6:  Kindle's one of these products that kind of transcended other products in

1037
00:59:00,635 --> 00:59:04,555
Speaker 6:  a sense of, it's a brand and it's a thing and it's identified as

1038
00:59:04,555 --> 00:59:08,435
Speaker 6:  e-readers. And it's all about reading all this connection to it

1039
00:59:08,535 --> 00:59:12,475
Speaker 6:  is so powerful. But it all all reflects back on the people making it.

1040
00:59:13,195 --> 00:59:17,155
Speaker 6:  I joined Amazon about a year ago. One of the first couple of meetings I had

1041
00:59:17,155 --> 00:59:20,155
Speaker 6:  was on Kindle. And I was inspired to see like, where are we at?

1042
00:59:21,625 --> 00:59:25,485
Speaker 6:  And you had a team with a bunch of stuff in the vault, basically. Like,

1043
00:59:25,485 --> 00:59:27,565
Speaker 6:  we're, we're close. We're thinking, what do you think? What do you think?

1044
00:59:27,565 --> 00:59:30,285
Speaker 6:  and we, you know, we sat down, we looked at it all true story, you know,

1045
00:59:30,385 --> 00:59:33,955
Speaker 6:  in on the Color Soft. We looked at it and I said,

1046
00:59:34,875 --> 00:59:38,525
Speaker 6:  if the color's great, won't, let's not compromise any

1047
00:59:38,525 --> 00:59:41,365
Speaker 6:  experience. You know, there is some limitations with e 'cause it's challenging,

1048
00:59:41,365 --> 00:59:44,685
Speaker 6:  you know, there's flashing and other small challenges and how bright it'll

1049
00:59:44,685 --> 00:59:47,565
Speaker 6:  be. And you always compare it to an ole and what that means. And you have

1050
00:59:47,565 --> 00:59:50,565
Speaker 6:  this team that's just obsessed about the detail in which of course, near

1051
00:59:50,565 --> 00:59:53,725
Speaker 6:  and dear to my heart. And so about a year ago, you know, we looked at the

1052
00:59:53,725 --> 00:59:57,685
Speaker 6:  full lineup and we made, we made the investment that said, let's get

1053
00:59:57,685 --> 01:00:01,605
Speaker 6:  after these products. Let's launch 'em All breeding has

1054
01:00:01,965 --> 01:00:02,165
Speaker 6:  momentum.

1055
01:00:03,785 --> 01:00:07,435
Speaker 6:  Literally. I mean, the Kindle brand product

1056
01:00:07,865 --> 01:00:08,755
Speaker 6:  line is growing

1057
01:00:11,085 --> 01:00:12,865
Speaker 6:  and there's a whole new generation of readers.

1058
01:00:13,735 --> 01:00:16,935
Speaker 4:  I think, what was the stat that 60% of people who bought a Kindle last year

1059
01:00:16,935 --> 01:00:19,855
Speaker 4:  were first time Kindle buyers? First time buyers. I find that, that was so

1060
01:00:19,855 --> 01:00:20,415
Speaker 4:  surprising to me.

1061
01:00:20,595 --> 01:00:23,975
Speaker 6:  So awesome. Because you also have this up into the right reading trend.

1062
01:00:25,115 --> 01:00:25,575
Speaker 6:  And so

1063
01:00:27,835 --> 01:00:31,495
Speaker 6:  you're, when you put those two things together, it basically says,

1064
01:00:32,115 --> 01:00:35,215
Speaker 6:  people who have always read are still reading. And there's a whole new cohort

1065
01:00:35,235 --> 01:00:39,015
Speaker 6:  coming in reading and it's

1066
01:00:39,015 --> 01:00:42,855
Speaker 6:  happening right now. I love it because you have Gen Z and millennials who

1067
01:00:42,855 --> 01:00:46,775
Speaker 6:  are, are diving into the power of like disappearing into a book

1068
01:00:47,715 --> 01:00:50,855
Speaker 6:  and If you on, you know, TikTok, you'll find book talk and there's a lot

1069
01:00:50,855 --> 01:00:53,695
Speaker 6:  of energy. People are bedazzling. There are Kindles right now. That's, that's

1070
01:00:53,695 --> 01:00:57,415
Speaker 6:  always a signal or a sign. That's cool. But a year ago when we sat in a room,

1071
01:00:58,435 --> 01:01:01,055
Speaker 6:  you mean these are can be very personal, passionate. That's what I should

1072
01:01:01,055 --> 01:01:04,215
Speaker 6:  close that. But a year ago when we sat in that room, yeah, it was very, let

1073
01:01:04,215 --> 01:01:08,095
Speaker 6:  me answer the question. Super conscious like next year Kindle

1074
01:01:08,095 --> 01:01:12,075
Speaker 6:  will be the year of Kindle. Let's go. We'll bring color, we'll bring it where

1075
01:01:12,075 --> 01:01:15,995
Speaker 6:  it belongs. We'll bring a new level of ink, it's a writing,

1076
01:01:16,695 --> 01:01:20,395
Speaker 6:  and then we'll refresh the products that you know are just what, what you

1077
01:01:20,395 --> 01:01:21,995
Speaker 6:  would call products that people already love.

1078
01:01:23,125 --> 01:01:25,785
Speaker 4:  I'm super fascinated by that moment because I feel like the Kindle's a really

1079
01:01:25,785 --> 01:01:29,625
Speaker 4:  unusual kind of device in that it just won

1080
01:01:30,205 --> 01:01:34,185
Speaker 4:  so long ago that there has been, I think you,

1081
01:01:34,205 --> 01:01:37,985
Speaker 4:  you can perceive Kindle as both like a giant success and

1082
01:01:38,045 --> 01:01:41,985
Speaker 4:  as kind of a slow moving product line. Over time there was a sense

1083
01:01:41,985 --> 01:01:45,905
Speaker 4:  of like, we, we did the thing, right? Like 10 years ago, just here's

1084
01:01:45,905 --> 01:01:48,425
Speaker 4:  the paper white, it's great. You're never gonna buy another one again because

1085
01:01:48,425 --> 01:01:52,305
Speaker 4:  you're not gonna have to. And in a certain way it was like victory for the

1086
01:01:52,305 --> 01:01:55,265
Speaker 4:  Kindle, right? And So I think there were people who were like, that's a great

1087
01:01:55,265 --> 01:01:58,145
Speaker 4:  thing. But on the other hand, also, there's other stuff happening. There

1088
01:01:58,145 --> 01:02:01,305
Speaker 4:  are other companies out there doing interesting things with ein and building

1089
01:02:01,365 --> 01:02:05,265
Speaker 4:  new kinds of things. We have, we've, we have people who like import

1090
01:02:05,435 --> 01:02:09,305
Speaker 4:  weird ein devices from China just to like, try what it looks like to

1091
01:02:09,305 --> 01:02:12,705
Speaker 4:  run Android on them. Like there's a, there's a whole

1092
01:02:12,895 --> 01:02:16,265
Speaker 4:  David's talking about himself. I am talking about myself, my book's. Palmer

1093
01:02:16,265 --> 01:02:18,945
Speaker 4:  is just outside of this room. And I, and I have a lot of questions for you.

1094
01:02:18,965 --> 01:02:19,485
Speaker 4:  You about it. Bring

1095
01:02:19,485 --> 01:02:21,845
Speaker 6:  It in here. Let me, let me evaluate. Let's do that off camera.

1096
01:02:22,395 --> 01:02:23,325
Speaker 4:  Fair enough. I'll take a look.

1097
01:02:23,715 --> 01:02:24,205
Speaker 6:  I'll help you.

1098
01:02:24,505 --> 01:02:28,165
Speaker 4:  But I'm curious, like in that moment you're like, okay, the Kindle is in

1099
01:02:28,165 --> 01:02:32,125
Speaker 4:  most ways a gigantic success for what it is. Right? Like it, it

1100
01:02:32,185 --> 01:02:35,645
Speaker 4:  won the thing. It was trying to win. How do we move this

1101
01:02:36,055 --> 01:02:39,925
Speaker 4:  along? Strikes me as kind of a complicated question. And it

1102
01:02:39,925 --> 01:02:42,405
Speaker 4:  also feels like, especially with something like the Scribe, you have given

1103
01:02:42,425 --> 01:02:45,765
Speaker 4:  the Kindle a new job to do for the first time in a really long time. Yeah.

1104
01:02:45,765 --> 01:02:48,885
Speaker 6:  But a very focused job. Okay. A very focused job. And I think that's part

1105
01:02:48,885 --> 01:02:51,645
Speaker 6:  of what Kindle is. Like Kindle's all about reading and now it's about reading

1106
01:02:51,705 --> 01:02:54,845
Speaker 6:  and writing. And it's that simple. These are both very innate

1107
01:02:55,565 --> 01:02:59,045
Speaker 6:  behaviors in humans. And just stay that focused,

1108
01:02:59,445 --> 01:03:03,325
Speaker 6:  distraction free, create while you write, create while you read. These are

1109
01:03:03,325 --> 01:03:04,525
Speaker 6:  big things for me, for the team.

1110
01:03:06,725 --> 01:03:09,585
Speaker 6:  I'm not sure what how to think about it other than I, when you say it, I

1111
01:03:09,585 --> 01:03:12,785
Speaker 6:  go, you know, Kindle Kindle is a fantastic brand. I don't think it's even

1112
01:03:12,935 --> 01:03:13,745
Speaker 6:  near its peak.

1113
01:03:14,295 --> 01:03:14,585
Speaker 4:  Okay.

1114
01:03:15,005 --> 01:03:18,905
Speaker 6:  Not even close. Not, I mean, not even close. Kendall's

1115
01:03:18,905 --> 01:03:22,815
Speaker 6:  also a very humble brand. I mean maybe that's why you say, oh, it

1116
01:03:22,815 --> 01:03:26,415
Speaker 6:  had its state. No, it's, it's, it's so meaningful to me. That's why I call

1117
01:03:26,415 --> 01:03:30,135
Speaker 6:  it a humble brand. So means a lot to people for sure. It it's made a difference

1118
01:03:30,135 --> 01:03:32,975
Speaker 6:  in their lives and still does. But here's a great example. Like If, you had

1119
01:03:32,975 --> 01:03:36,295
Speaker 6:  a paper wipe from four years ago. I mean, you'd love that paper White.

1120
01:03:37,265 --> 01:03:39,885
Speaker 6:  You do. Yeah. People love their Kindles like

1121
01:03:40,315 --> 01:03:43,925
Speaker 3:  Love. Yeah. But I think this would, like my wife loves her Kindle. Yeah.

1122
01:03:44,465 --> 01:03:47,405
Speaker 3:  I'm like, do you want a new one? And her answer is basically why.

1123
01:03:47,735 --> 01:03:48,085
Speaker 4:  Right?

1124
01:03:48,155 --> 01:03:49,725
Speaker 6:  Yeah. Until, and on the one

1125
01:03:49,725 --> 01:03:52,165
Speaker 4:  Hand you can read that is huge success. But also Absolutely.

1126
01:03:52,235 --> 01:03:55,405
Speaker 6:  It's rad. Yeah. Like, come on. If they're, if people are reading, let's take

1127
01:03:55,405 --> 01:03:59,085
Speaker 6:  it. That's a, that's a win. And why? It means it's a

1128
01:03:59,085 --> 01:04:02,285
Speaker 6:  robust and meaningful device and it's doing the job it was meant to do.

1129
01:04:02,725 --> 01:04:06,645
Speaker 6:  However, as an example, I'll challenge like, do this for me. Go

1130
01:04:06,645 --> 01:04:07,605
Speaker 6:  hand the new Paperweight.

1131
01:04:08,365 --> 01:04:11,365
Speaker 3:  I think if I hand the color one, then we'll have a different conversation.

1132
01:04:11,505 --> 01:04:11,885
Speaker 3:  Try both.

1133
01:04:11,995 --> 01:04:15,005
Speaker 6:  Yeah, try both. I think color changes the emotion.

1134
01:04:15,385 --> 01:04:17,445
Speaker 3:  Buy two Kindles. I I'm understanding my

1135
01:04:17,475 --> 01:04:21,285
Speaker 6:  Yeah. Keep buying instruction. Keep buying Kindles. No, no. Well,

1136
01:04:21,285 --> 01:04:24,165
Speaker 3:  But can I ask you actually a, a different variation on that question? 'cause

1137
01:04:24,165 --> 01:04:26,645
Speaker 3:  I, I think the answer So I think what you'll say will come out in the answer

1138
01:04:26,645 --> 01:04:27,045
Speaker 3:  to this question

1139
01:04:28,885 --> 01:04:29,325
Speaker 3:  I look at.

1140
01:04:29,475 --> 01:04:32,165
Speaker 6:  Yeah, I don't think David actually asked a question. I think he just made

1141
01:04:32,165 --> 01:04:34,845
Speaker 6:  a bunch of statements there. David is like, challenge me. Is that right?

1142
01:04:34,845 --> 01:04:35,085
Speaker 6:  Well,

1143
01:04:35,385 --> 01:04:38,725
Speaker 3:  The question is, does Kindle have a lot of competition and is there an ecosystem

1144
01:04:38,725 --> 01:04:42,565
Speaker 3:  of things, other devices using like ing screens to drive

1145
01:04:42,565 --> 01:04:45,685
Speaker 3:  that technology forward? Because there hasn't been a lot of action

1146
01:04:46,435 --> 01:04:49,805
Speaker 3:  like Ola displays, there's a lot of action in OLA displays that technology

1147
01:04:49,805 --> 01:04:53,445
Speaker 3:  is relentlessly moving forward. And you can build new kinds of products around

1148
01:04:53,645 --> 01:04:57,475
Speaker 3:  whatever those displays can do. Kindle is like the, it's the

1149
01:04:57,475 --> 01:05:01,355
Speaker 3:  main product in its category. Yeah. Do you think it has a bunch of con competition

1150
01:05:01,355 --> 01:05:03,875
Speaker 3:  that drives it forward? Do you think that the underlying ecosystem,

1151
01:05:04,075 --> 01:05:06,315
Speaker 6:  I think competition's always a great thing. You have to start there. I think

1152
01:05:06,465 --> 01:05:10,075
Speaker 6:  it's always been, it always will be like, just makes everybody better. It's

1153
01:05:10,075 --> 01:05:13,435
Speaker 6:  gotta be a good thing. But I would also say like, yeah, I don't think,

1154
01:05:13,935 --> 01:05:17,805
Speaker 6:  you know, the, the tech is not done. It's not even close. I think there's

1155
01:05:17,805 --> 01:05:20,445
Speaker 6:  another level that that comes. And it's actually purposeful.

1156
01:05:22,505 --> 01:05:25,755
Speaker 6:  I've had had several of these arguments in the past, but you know,

1157
01:05:26,385 --> 01:05:29,835
Speaker 6:  LCDs have its purpose. OLED has its purpose. That line blurs quite a bit.

1158
01:05:29,865 --> 01:05:32,755
Speaker 6:  Yeah. You know, where the, what that delta might be, what the purpose is

1159
01:05:32,755 --> 01:05:36,435
Speaker 6:  between each and so super close.

1160
01:05:36,535 --> 01:05:40,475
Speaker 6:  But when you get down to ink displays and just the softer feel,

1161
01:05:40,535 --> 01:05:44,155
Speaker 6:  softer on the eyes, what you're getting from it, and there is something about

1162
01:05:44,155 --> 01:05:46,715
Speaker 6:  it that is just, is romantic.

1163
01:05:49,585 --> 01:05:52,925
Speaker 6:  It, they, it will, they'll stay that Delta's critical. You know, this is

1164
01:05:52,985 --> 01:05:56,645
Speaker 6:  for, these are noisier, this is simple. But that

1165
01:05:56,645 --> 01:05:58,965
Speaker 6:  simplicity doesn't mean there isn't an innovation to be had. Yeah. There's

1166
01:05:58,965 --> 01:06:02,085
Speaker 6:  a ton of it left. You know, and you start, you can start getting into color,

1167
01:06:02,465 --> 01:06:05,365
Speaker 6:  you can start getting into ink. You can start getting into speeds.

1168
01:06:06,385 --> 01:06:09,965
Speaker 6:  All of it is important, but it doesn't need

1169
01:06:10,755 --> 01:06:14,435
Speaker 6:  knee light when you're making products. You don't need these

1170
01:06:14,435 --> 01:06:17,965
Speaker 6:  massive leaps to change people's lives.

1171
01:06:18,635 --> 01:06:21,485
Speaker 6:  Sometimes it's like the most subtle difference

1172
01:06:22,745 --> 01:06:26,645
Speaker 6:  has the, it's like just massive impact. So let's say, let's go back

1173
01:06:26,645 --> 01:06:29,835
Speaker 6:  to, let's just go back to reading.

1174
01:06:30,325 --> 01:06:33,995
Speaker 6:  We'll use your wife as the example since you, you put it on the table. She

1175
01:06:33,995 --> 01:06:36,645
Speaker 6:  loves her paper white. Yeah. Is that right?

1176
01:06:38,275 --> 01:06:41,685
Speaker 6:  Hand her the new paper. White color's a leap. You know, there's a different

1177
01:06:41,685 --> 01:06:44,365
Speaker 6:  level of emotion. So it's easy to understand, hey, this is the book. This

1178
01:06:44,365 --> 01:06:47,845
Speaker 6:  is how the author intends you to see the cover. Or you like reading

1179
01:06:47,945 --> 01:06:51,845
Speaker 6:  comics or take Trevor's new book or whatever. It's a color, it's a color

1180
01:06:51,845 --> 01:06:55,005
Speaker 6:  book. You just, you know, read through it. It's very cool. But If, you

1181
01:06:56,105 --> 01:07:00,005
Speaker 6:  If you take it just to its most simple level and you hand her

1182
01:07:00,005 --> 01:07:03,925
Speaker 6:  the new paper white and just have her use it. I think you'll experience

1183
01:07:03,925 --> 01:07:07,645
Speaker 6:  something. It's just back to this point of it's a very subtle change. It's

1184
01:07:07,645 --> 01:07:11,445
Speaker 6:  massive change really technically. But it's a subtle change to the

1185
01:07:11,445 --> 01:07:14,685
Speaker 6:  user, which is basically speed of page turns. It's the first thing I noticed

1186
01:07:14,685 --> 01:07:18,495
Speaker 6:  when I picked up the one David has. Dude, it doesn't, it's crazy. You

1187
01:07:18,565 --> 01:07:22,375
Speaker 6:  hand somebody who had a 4-year-old paperweight, the new one first.

1188
01:07:22,375 --> 01:07:23,295
Speaker 6:  They're like, I don't need it.

1189
01:07:25,375 --> 01:07:28,955
Speaker 6:  And then they turn a page and they're like, don't touch this.

1190
01:07:29,305 --> 01:07:33,155
Speaker 6:  It's mine. Yeah. I believe it. The emotion is, it's

1191
01:07:33,155 --> 01:07:35,755
Speaker 6:  not because there was color, it's not because it's huge leap. It's not because

1192
01:07:35,775 --> 01:07:39,755
Speaker 6:  you saw it. It's subtle, but you feel it. And when

1193
01:07:39,755 --> 01:07:43,595
Speaker 6:  you feel it, you know this like, it's so critical. Now

1194
01:07:43,595 --> 01:07:47,465
Speaker 6:  all of a sudden it's like, this feels better. And while it's a massive

1195
01:07:47,555 --> 01:07:50,705
Speaker 6:  technology shift in the product itself under the covers on,

1196
01:07:52,245 --> 01:07:56,025
Speaker 6:  in many ways, it's just totally different display stack. But you're now in

1197
01:07:56,025 --> 01:07:56,585
Speaker 6:  this place of

1198
01:07:58,105 --> 01:08:01,975
Speaker 6:  Wow. The user just felt it. And I think, I don't think she

1199
01:08:01,975 --> 01:08:05,735
Speaker 6:  gives it back. Yeah. Especially because all your books are there. Your

1200
01:08:05,735 --> 01:08:08,695
Speaker 6:  content came with you, you didn't lose anything. You're not starting over.

1201
01:08:08,765 --> 01:08:12,415
Speaker 6:  It's very seamless. And so now you're just back into the book you were in.

1202
01:08:12,415 --> 01:08:15,490
Speaker 6:  Now it's just faster. And it's not like people are gonna read faster.

1203
01:08:16,455 --> 01:08:20,225
Speaker 6:  You just feel better. And so when you're reading and you feel great, you

1204
01:08:20,325 --> 01:08:22,745
Speaker 6:  you read, you just, it's better. Well

1205
01:08:22,745 --> 01:08:25,785
Speaker 4:  It goes back to what's so interesting about the Kindle as a product for me

1206
01:08:25,785 --> 01:08:29,745
Speaker 4:  is that like, from the very beginning, the Kindle was always sort

1207
01:08:29,745 --> 01:08:33,665
Speaker 4:  of not about itself. Like the, the less you spent thinking about your

1208
01:08:33,865 --> 01:08:35,825
Speaker 4:  Kindle. Yeah. The more you, it's

1209
01:08:35,825 --> 01:08:38,545
Speaker 6:  Like the truth in a product that disappears into the background. No,

1210
01:08:38,545 --> 01:08:41,505
Speaker 3:  It, hold on, I'm just gonna disagree with David. That first Kindle really

1211
01:08:41,505 --> 01:08:42,345
Speaker 3:  wanted you to think about

1212
01:08:42,345 --> 01:08:43,185
Speaker 4:  It. It did. That's fair.

1213
01:08:43,255 --> 01:08:44,705
Speaker 3:  That thing was like, it's remarkable

1214
01:08:44,705 --> 01:08:46,305
Speaker 4:  Piece. It had a joystick was a whole

1215
01:08:46,675 --> 01:08:47,105
Speaker 3:  Wheel though.

1216
01:08:47,165 --> 01:08:48,545
Speaker 6:  It was a lot going on. It a

1217
01:08:49,175 --> 01:08:49,665
Speaker 3:  Arrived

1218
01:08:51,525 --> 01:08:51,745
Speaker 3:  it

1219
01:08:51,905 --> 01:08:51,985
Speaker 6:  Brilliant.

1220
01:08:52,435 --> 01:08:54,825
Speaker 3:  First one was a little out of control. Stick to the facts.

1221
01:08:55,385 --> 01:08:56,105
Speaker 4:  Physical keyboard was sick though.

1222
01:08:56,105 --> 01:08:56,945
Speaker 6:  Stick to the facts man.

1223
01:08:57,265 --> 01:09:01,185
Speaker 4:  Keyboard is awesome what you're talking about. Alright, fair

1224
01:09:01,185 --> 01:09:02,145
Speaker 4:  enough. Once like,

1225
01:09:02,145 --> 01:09:04,945
Speaker 6:  Like split keyboards are are one of my favorite things on the planet.

1226
01:09:05,145 --> 01:09:09,105
Speaker 4:  Once somebody other than Jeff was in charge of the Kindle design, it, it,

1227
01:09:09,805 --> 01:09:13,745
Speaker 4:  it hit a point where, and you know, we heard this from people for a

1228
01:09:13,745 --> 01:09:17,265
Speaker 4:  decade that like the goal is pen and paper, right? Like that is that that

1229
01:09:17,265 --> 01:09:20,505
Speaker 4:  was the north star of like, it should feel like that it should crumple like

1230
01:09:20,505 --> 01:09:24,065
Speaker 4:  that. It should have all the properties of a thing that you don't

1231
01:09:24,155 --> 01:09:27,945
Speaker 4:  think about or worry about as technology. And that's I think a good

1232
01:09:27,965 --> 01:09:31,145
Speaker 4:  and admirable goal in a lot of ways, but also makes building the product

1233
01:09:31,145 --> 01:09:33,785
Speaker 4:  really hard because you're like, okay, every cool thing we build

1234
01:09:34,875 --> 01:09:38,465
Speaker 4:  calls more attention to this device designed to not call attention to itself.

1235
01:09:38,725 --> 01:09:40,705
Speaker 4:  And it's like, if the goal is to just get people reading

1236
01:09:42,595 --> 01:09:46,075
Speaker 4:  anything that you do that isn't open your book faster and turn the pages

1237
01:09:46,075 --> 01:09:49,835
Speaker 4:  faster is both an upgrade and a downgrade in the

1238
01:09:49,835 --> 01:09:52,515
Speaker 4:  experience. Yeah. And that just strike me as a really complicated tension

1239
01:09:52,575 --> 01:09:54,035
Speaker 4:  to sort through with a device

1240
01:09:54,035 --> 01:09:54,795
Speaker 6:  Like this. Yeah.

1241
01:09:56,955 --> 01:09:59,815
Speaker 6:  Here's what it comes down to. Since people love the product so much, you

1242
01:09:59,815 --> 01:10:03,605
Speaker 6:  just have to listen to what they love. Like they love it.

1243
01:10:04,055 --> 01:10:06,885
Speaker 4:  Which is different than listening to what they're asking for. Correct. Yeah.

1244
01:10:06,885 --> 01:10:10,285
Speaker 6:  Listen to what they love. And you know,

1245
01:10:11,615 --> 01:10:15,465
Speaker 6:  with paper white just, just listen. And at the end of the day it is, they

1246
01:10:15,465 --> 01:10:18,065
Speaker 6:  don't, this isn't about thinking about the Kindle, it's about thinking about

1247
01:10:18,065 --> 01:10:21,745
Speaker 6:  what they're reading and disappearing into it. And then you start

1248
01:10:21,745 --> 01:10:24,145
Speaker 6:  getting into the nuance. Like, so what do you love? Like, I just like the

1249
01:10:24,145 --> 01:10:27,305
Speaker 6:  way it feels. I like the way it, how much it weighs. I like what I can lean

1250
01:10:27,305 --> 01:10:30,425
Speaker 6:  in any posture like that I can lay by the beach.

1251
01:10:31,275 --> 01:10:34,355
Speaker 6:  I like that I could spill my coffee on it. Like they don't say those words,

1252
01:10:34,355 --> 01:10:37,155
Speaker 6:  but you start listening like, I don't know, but one time I spilled my coffee

1253
01:10:37,295 --> 01:10:41,215
Speaker 6:  and then I just wiped it and I kept reading and I'm like, so you like

1254
01:10:41,215 --> 01:10:44,135
Speaker 6:  waterproof? You know what I mean? Yeah. And I'm laying at the beach like,

1255
01:10:44,235 --> 01:10:47,535
Speaker 6:  you know, that we test it with salt water, you know, that you can drop this

1256
01:10:47,535 --> 01:10:51,415
Speaker 6:  thing in the pool. Like what? You may not know it, but that's what you love

1257
01:10:51,465 --> 01:10:54,615
Speaker 6:  where you can do it. And now, but the real trick is the comfort that the

1258
01:10:54,615 --> 01:10:56,895
Speaker 6:  product brings when you're reading. So it's not in your way. And then it

1259
01:10:56,895 --> 01:11:00,535
Speaker 6:  disappears. Take the new paper white, like this screen

1260
01:11:00,605 --> 01:11:03,655
Speaker 6:  just got subtly bigger. It's up to seven inches now, but the footprint of

1261
01:11:03,655 --> 01:11:06,845
Speaker 6:  the device just barely grew.

1262
01:11:07,775 --> 01:11:11,045
Speaker 6:  Which means you still have that perfect center of gravity when you're holding

1263
01:11:11,065 --> 01:11:13,850
Speaker 6:  it. You still don't think about the weight. It feels like a feather, you

1264
01:11:13,850 --> 01:11:15,970
Speaker 6:  know, when you're holding it and reading it disappears lighter than a book.

1265
01:11:15,970 --> 01:11:17,885
Speaker 6:  And you're like, you get to this point of,

1266
01:11:20,045 --> 01:11:24,015
Speaker 6:  I've given, you've got, you know, team's given the user more real

1267
01:11:24,015 --> 01:11:27,975
Speaker 6:  estate, subtle back to one of those things. And now you just, you

1268
01:11:27,975 --> 01:11:30,855
Speaker 6:  see more very simple. The page is turning faster,

1269
01:11:31,665 --> 01:11:35,655
Speaker 6:  feels pretty good and, but you haven't taken away anything they love.

1270
01:11:35,675 --> 01:11:39,615
Speaker 6:  You just added to it. And I think critical. But it is

1271
01:11:39,655 --> 01:11:43,095
Speaker 6:  a product that I think disappears into the background sans 17 years ago.

1272
01:11:43,435 --> 01:11:45,495
Speaker 6:  I'm not gonna, I'm not, I'm not gonna comment, bring

1273
01:11:45,495 --> 01:11:49,095
Speaker 3:  Back the transf reflective scroll bar on the side of the display. Let's go.

1274
01:11:49,375 --> 01:11:49,495
Speaker 3:  I

1275
01:11:49,495 --> 01:11:52,655
Speaker 6:  Don't know. I'm not exactly sure. But it's all about reading and it works.

1276
01:11:52,955 --> 01:11:53,935
Speaker 6:  It works really well now.

1277
01:11:53,995 --> 01:11:57,535
Speaker 3:  So there's two parts of the Kindle. David mentioned the BS Palmer, which

1278
01:11:58,015 --> 01:12:01,455
Speaker 3:  I believe he caused the highest spike in their sales ever.

1279
01:12:02,275 --> 01:12:04,655
Speaker 3:  PE people like that device, they like other ink devices 'cause of what you're

1280
01:12:04,655 --> 01:12:08,295
Speaker 3:  talking about, right? Younger people especially know that their phones are

1281
01:12:08,695 --> 01:12:12,575
Speaker 3:  distracting. They're drawn to a cheaper e ink device that offers

1282
01:12:12,655 --> 01:12:16,495
Speaker 3:  a more focused experience or just a black and white experience to cut down

1283
01:12:16,495 --> 01:12:20,295
Speaker 3:  on distraction and noise. We can't, there's a dumb phone movement out in

1284
01:12:20,295 --> 01:12:22,615
Speaker 3:  the world. Like there's this idea that we should just not use our phones

1285
01:12:22,615 --> 01:12:26,375
Speaker 3:  for everything. I see that the Palma is

1286
01:12:26,815 --> 01:12:30,735
Speaker 3:  a fine piece of hardware. It's like a commodity e screen. The Kindle is like

1287
01:12:30,735 --> 01:12:33,015
Speaker 3:  integrated, right? It's hardware, software, there's a service behind it.

1288
01:12:33,325 --> 01:12:36,655
Speaker 3:  When I hear people complain the most about the Kindle, it's, I am locked

1289
01:12:36,655 --> 01:12:39,575
Speaker 3:  into the Kindle ecosystem. I can't go to other bookstores.

1290
01:12:40,215 --> 01:12:42,775
Speaker 3:  PDF on this device is messy. It's hard.

1291
01:12:44,515 --> 01:12:48,135
Speaker 3:  Am there's not like an app store for Kindles to let you extend the capabilities

1292
01:12:48,135 --> 01:12:51,615
Speaker 3:  of the device. There is a little bit of a back and forth there, right? Where

1293
01:12:51,615 --> 01:12:55,455
Speaker 3:  they love this device. It, it offers one very singular experience that might

1294
01:12:55,905 --> 01:12:59,815
Speaker 3:  bring people into an ecosystem. They might love it. And then to make it do

1295
01:12:59,815 --> 01:13:03,335
Speaker 3:  all the rest of things you might wanna do. Like the scribe, you have to let

1296
01:13:03,335 --> 01:13:04,455
Speaker 3:  it go be a computer.

1297
01:13:05,635 --> 01:13:06,975
Speaker 6:  You gotta let it be a writing device.

1298
01:13:07,405 --> 01:13:07,695
Speaker 3:  Okay.

1299
01:13:08,155 --> 01:13:10,855
Speaker 6:  You gotta let it be a writing device. I think you got, it's a very slippery

1300
01:13:10,905 --> 01:13:14,695
Speaker 6:  slope though. Like once you try and get kind of too cute with features

1301
01:13:14,715 --> 01:13:18,615
Speaker 6:  or go too far, you start getting away from what I'm,

1302
01:13:18,615 --> 01:13:22,415
Speaker 6:  what we really want. Which is the analogous, you know, moving from

1303
01:13:23,695 --> 01:13:27,505
Speaker 6:  the Analogue to the digital and just writing on paper. It's very

1304
01:13:27,745 --> 01:13:31,145
Speaker 6:  dangerous. You know, once you start introducing more by the way, you can,

1305
01:13:32,095 --> 01:13:35,905
Speaker 6:  it's why like we added a couple of gene AI features to it. But,

1306
01:13:36,085 --> 01:13:39,585
Speaker 6:  but two very simple. We have a list that we have such a long list. I think

1307
01:13:39,625 --> 01:13:43,345
Speaker 6:  I was telling David yesterday, like the amount of features we could,

1308
01:13:44,225 --> 01:13:44,505
Speaker 3:  Yeah,

1309
01:13:45,605 --> 01:13:49,065
Speaker 6:  But I don't, I don't think it's right to con to confuse this scenario.

1310
01:13:49,925 --> 01:13:53,305
Speaker 6:  If, you can create some ands great. But the end of the day what you need

1311
01:13:53,325 --> 01:13:56,385
Speaker 6:  is fundamentally put your pen down and start writing

1312
01:13:57,475 --> 01:14:01,235
Speaker 6:  and as if it was paper. and we

1313
01:14:01,475 --> 01:14:05,155
Speaker 6:  also introduced writing on a book as If. you were writing on a book. And

1314
01:14:05,155 --> 01:14:07,955
Speaker 6:  so that translation's also challenging. But I think we're getting pretty,

1315
01:14:08,155 --> 01:14:09,435
Speaker 6:  I think we're there. I think we're close,

1316
01:14:09,735 --> 01:14:13,165
Speaker 3:  But you're a unique person to talk about this with because if I, I was like,

1317
01:14:13,165 --> 01:14:17,125
Speaker 3:  who knows the most about running a full operating system with

1318
01:14:17,125 --> 01:14:18,805
Speaker 3:  a pen on a piece of custom hardware.

1319
01:14:19,845 --> 01:14:20,845
Speaker 6:  I gotta find that person.

1320
01:14:22,425 --> 01:14:24,445
Speaker 3:  And then it's like, and then you've got this other thing way at the other

1321
01:14:24,445 --> 01:14:26,245
Speaker 3:  end of the spectrum where like you can write on a book.

1322
01:14:27,205 --> 01:14:27,495
Speaker 6:  Yeah.

1323
01:14:27,665 --> 01:14:31,055
Speaker 3:  Those experiences are kind of headed towards each other

1324
01:14:32,385 --> 01:14:34,065
Speaker 6:  A little bit. I I mean, or

1325
01:14:34,285 --> 01:14:38,265
Speaker 3:  The, at least with the Kindle scribe, the, the more you add capability

1326
01:14:38,285 --> 01:14:41,585
Speaker 3:  to it to do anything else, even if the capability is just as simple as

1327
01:14:42,365 --> 01:14:46,145
Speaker 3:  you can access PDFs and write on them and get your notes

1328
01:14:46,205 --> 01:14:49,705
Speaker 3:  out. Well now you, now you're like, here's the file system,

1329
01:14:49,705 --> 01:14:52,145
Speaker 6:  Which you can, which you can right now. Right? But it with the new scribe,

1330
01:14:52,845 --> 01:14:56,115
Speaker 3:  But not, it's still like within the Kindle world, right?

1331
01:14:56,315 --> 01:14:56,475
Speaker 6:  Absolutely.

1332
01:14:56,475 --> 01:14:58,995
Speaker 3:  There's still, there's still a bunch of abstractions there that make it

1333
01:14:59,015 --> 01:15:01,035
Speaker 6:  Not, and the feeling you're not gonna get the extra distractions. There's

1334
01:15:01,035 --> 01:15:03,515
Speaker 6:  nothing better than when you go to attach a file to an email and you're like,

1335
01:15:03,515 --> 01:15:06,755
Speaker 6:  oh, but let me check the web right now. Oh, let me see. I'm reading about,

1336
01:15:08,095 --> 01:15:10,155
Speaker 6:  I'm reading about The Verge. Oh, let's see. Like,

1337
01:15:10,575 --> 01:15:11,715
Speaker 3:  And that's my goal actually. Then

1338
01:15:11,715 --> 01:15:12,075
Speaker 6:  You're down this,

1339
01:15:12,535 --> 01:15:14,155
Speaker 3:  How do I get The Verge on the kennel screen? But

1340
01:15:14,155 --> 01:15:15,235
Speaker 4:  I think, I think that's, that's

1341
01:15:15,255 --> 01:15:19,075
Speaker 3:  But all the way to a surface with a pen. Yeah. Right. That's, you're, you're

1342
01:15:19,075 --> 01:15:19,995
Speaker 3:  on the same spectrum

1343
01:15:20,345 --> 01:15:24,115
Speaker 4:  Somewhere between a device that exists only for reading books and nothing

1344
01:15:24,115 --> 01:15:24,835
Speaker 4:  else. And

1345
01:15:25,395 --> 01:15:26,555
Speaker 3:  A com, like a full and

1346
01:15:26,555 --> 01:15:29,235
Speaker 6:  Windows purpose-built matters. Let me just say that that's what you're saying.

1347
01:15:29,375 --> 01:15:31,035
Speaker 6:  It does man. It does.

1348
01:15:31,495 --> 01:15:33,475
Speaker 4:  Do you buy that for Kindle specifically or

1349
01:15:33,715 --> 01:15:35,995
Speaker 6:  Specifically for Kindle? Kindle, like be careful. Like this is one of the

1350
01:15:35,995 --> 01:15:38,555
Speaker 6:  beautiful things. Like there's so many different things that can come together

1351
01:15:38,575 --> 01:15:41,955
Speaker 6:  and make magic, don't get me wrong. And how they come together makes a difference.

1352
01:15:42,575 --> 01:15:46,395
Speaker 6:  Oh, I agree. But I think but but in, in specifically in this space,

1353
01:15:47,805 --> 01:15:48,095
Speaker 6:  like

1354
01:15:50,635 --> 01:15:54,455
Speaker 6:  of course like don't, of course you can, you should be able to write on your

1355
01:15:54,485 --> 01:15:58,415
Speaker 6:  iPad or a PC or a Surface or whatever it is. Of course you should. Of

1356
01:15:58,415 --> 01:16:01,735
Speaker 6:  course. You know, there's things to accomplish and things to do. There might

1357
01:16:01,735 --> 01:16:02,775
Speaker 6:  be a job to be done.

1358
01:16:04,655 --> 01:16:08,465
Speaker 6:  This is purpose driven. You don't need

1359
01:16:08,465 --> 01:16:12,305
Speaker 6:  your paper to browse the web. You just don't. As a matter of

1360
01:16:12,305 --> 01:16:16,145
Speaker 6:  fact, when you're writing, that's what you need to be doing. Sometimes. If

1361
01:16:16,165 --> 01:16:20,065
Speaker 6:  not all the time when I'm in a meeting, I take all my notes on my

1362
01:16:20,625 --> 01:16:21,025
Speaker 6:  scribe. Now

1363
01:16:22,965 --> 01:16:26,905
Speaker 6:  it, it can't imagine trying to do it on you just don't.

1364
01:16:26,935 --> 01:16:30,145
Speaker 6:  It's either that or a notebook. Yeah. But it's definitely not

1365
01:16:31,545 --> 01:16:35,065
Speaker 6:  a full functioning computer because it just

1366
01:16:35,345 --> 01:16:36,145
Speaker 6:  distracts me right out.

1367
01:16:36,935 --> 01:16:38,865
Speaker 3:  It's impossible. So that, that part where you take all your notes on the

1368
01:16:38,945 --> 01:16:39,625
Speaker 3:  scribe. Yeah. And then

1369
01:16:40,025 --> 01:16:43,905
Speaker 6:  I also do all my morning writing on the scribe. Like I, it's why we

1370
01:16:43,905 --> 01:16:45,665
Speaker 6:  brought this summarized feature together. Yeah.

1371
01:16:45,885 --> 01:16:48,425
Speaker 3:  So that's gotta go out my notes, right? I mean this is the service aspect

1372
01:16:48,425 --> 01:16:52,065
Speaker 3:  of it that Scribe is running some Kindle operating system.

1373
01:16:52,215 --> 01:16:55,505
Speaker 3:  It's running some set of gen AI features that helps you summarize and takes

1374
01:16:55,505 --> 01:16:58,025
Speaker 3:  the notes out. Those go up to a cloud service and then

1375
01:16:58,295 --> 01:17:00,385
Speaker 6:  Encrypted secure and sends it back to

1376
01:17:00,385 --> 01:17:01,785
Speaker 3:  Device and then they land encrypts

1377
01:17:01,785 --> 01:17:02,185
Speaker 6:  It on the device

1378
01:17:02,245 --> 01:17:04,785
Speaker 3:  Is text that you can use anywhere else. Yeah. They land

1379
01:17:04,805 --> 01:17:08,385
Speaker 6:  In. Yeah. So you, let's say in this case in the summarized feature, the gene

1380
01:17:08,385 --> 01:17:12,355
Speaker 6:  AI feature. You can, I have, I have, I don't know

1381
01:17:12,455 --> 01:17:16,235
Speaker 6:  so many notebooks now, but they're named by people. They're named by products.

1382
01:17:16,235 --> 01:17:20,155
Speaker 6:  They're named by meetings. You know, they're also, I have my morning

1383
01:17:20,155 --> 01:17:23,075
Speaker 6:  notes and generally it falls into one of those buckets. Unless there's a

1384
01:17:23,235 --> 01:17:25,595
Speaker 6:  creation bucket or an invention bucket. You know, I've got a few different

1385
01:17:25,595 --> 01:17:29,395
Speaker 6:  ways I laid out. But let's say there's 20 pages in a book,

1386
01:17:29,895 --> 01:17:33,765
Speaker 6:  one of my notebooks. Right. Those 20 pages

1387
01:17:33,785 --> 01:17:37,385
Speaker 6:  of notes. That's a lot. And by the way, there's something emotional about

1388
01:17:37,385 --> 01:17:39,865
Speaker 6:  writing. Yeah. 'cause there's recall, I remember I wrote this note right

1389
01:17:39,865 --> 01:17:42,505
Speaker 6:  here on this piece of paper. I know how I wrote it, I know why I wrote it.

1390
01:17:42,725 --> 01:17:46,665
Speaker 6:  But once you send this to the cloud, my 20 pages, it's gonna summarize

1391
01:17:46,665 --> 01:17:50,505
Speaker 6:  all 20. Send it back into a very simple format. Yeah. Think OCR handwriting

1392
01:17:50,505 --> 01:17:54,185
Speaker 6:  recognition. Sure. Take it. Look at the 20 pages, summarize,

1393
01:17:54,475 --> 01:17:58,385
Speaker 6:  bring it back in kind of a beautification form. Like pick the font you

1394
01:17:58,385 --> 01:18:02,225
Speaker 6:  wanna put it in. We got a number of them. You can make it longer or

1395
01:18:02,225 --> 01:18:05,945
Speaker 6:  shorter, whatever. But in very simplest form, it's two clicks comes down.

1396
01:18:06,325 --> 01:18:09,305
Speaker 6:  Here's a summary of all my notes. I've got a page of notes from 20 pages

1397
01:18:09,305 --> 01:18:10,505
Speaker 6:  written, which is powerful.

1398
01:18:10,845 --> 01:18:14,785
Speaker 3:  I'm just getting to, let's say AI is the platform shift. And now

1399
01:18:14,785 --> 01:18:18,025
Speaker 3:  instead of having one converged device on the phone, I have three devices.

1400
01:18:18,175 --> 01:18:21,825
Speaker 3:  I've got a paper to write on. I've got, I don't know, one of the many, many

1401
01:18:21,835 --> 01:18:24,905
Speaker 3:  microphone pins that David is constantly being forced to review

1402
01:18:25,815 --> 01:18:29,225
Speaker 3:  that he can, he can talk to all day long. And maybe, maybe I do have a phone

1403
01:18:29,225 --> 01:18:32,305
Speaker 3:  that is mostly a camera. Yeah. At some point I want all those things to talk

1404
01:18:32,305 --> 01:18:36,105
Speaker 3:  to each other. And the idea that my AI

1405
01:18:36,325 --> 01:18:39,825
Speaker 3:  pin does not know about the notes I took on my Amazon scribe

1406
01:18:40,775 --> 01:18:44,475
Speaker 3:  does not know about a email I read on my

1407
01:18:44,495 --> 01:18:48,335
Speaker 3:  laptop actually creates like the

1408
01:18:48,335 --> 01:18:52,055
Speaker 3:  desire for me to have more lock in. Right. So like fine, I'm just gonna buy

1409
01:18:52,055 --> 01:18:55,015
Speaker 3:  it all from one vendor. My phone already my, the phone company is already

1410
01:18:55,015 --> 01:18:58,495
Speaker 3:  selling me everything. How do you break that? Like do you, is it more

1411
01:18:58,515 --> 01:19:02,295
Speaker 3:  interoperability? Is it extending the Kindle operating system

1412
01:19:02,475 --> 01:19:04,295
Speaker 3:  to do more and more things?

1413
01:19:04,595 --> 01:19:07,335
Speaker 6:  No, I don't think it's that. I think, I think there's, I think interoperability

1414
01:19:07,355 --> 01:19:10,575
Speaker 6:  is a great thing. Yeah. And you, you know, you, you can find it, you can

1415
01:19:10,575 --> 01:19:13,895
Speaker 6:  find you can remove seams. Yeah. Between different oss for sure.

1416
01:19:15,015 --> 01:19:17,695
Speaker 6:  I don't really lose a lot of sleep over it. I also know that within the device

1417
01:19:17,695 --> 01:19:20,975
Speaker 6:  family that Amazon builds, like that'll all

1418
01:19:21,495 --> 01:19:24,615
Speaker 6:  continue because of AI become more seamless. Yeah. Back to 0.1, like the

1419
01:19:24,615 --> 01:19:28,455
Speaker 6:  opportunities off the charts. But I don't think you wanna lock it all in.

1420
01:19:28,535 --> 01:19:31,375
Speaker 6:  I think you still need the interoperability as well. So they're, I think

1421
01:19:31,375 --> 01:19:32,015
Speaker 6:  they both matter

1422
01:19:33,705 --> 01:19:35,725
Speaker 6:  and I think it's different for every person. Like you're gonna end up in

1423
01:19:35,725 --> 01:19:39,605
Speaker 6:  a place where you love a certain set of devices. I

1424
01:19:39,605 --> 01:19:42,645
Speaker 6:  don't think you're gonna have five in your bag, but if there's a purpose-built

1425
01:19:42,645 --> 01:19:45,805
Speaker 6:  device that you do need, you're gonna take it with you man. Makes a difference.

1426
01:19:45,805 --> 01:19:49,365
Speaker 6:  Yeah. You're gonna need that connectivity. But don't, don't be confused.

1427
01:19:49,425 --> 01:19:52,085
Speaker 6:  All your notes on your Kindle today show up on your iPhone.

1428
01:19:53,275 --> 01:19:56,485
Speaker 6:  Like on the Kindle app. It's right there. Yeah. Seamless. That integration's

1429
01:19:56,585 --> 01:19:59,965
Speaker 6:  pretty awesome. And eventually you'll have editing those docs on your iPhone

1430
01:19:59,965 --> 01:20:03,845
Speaker 6:  too, I'm sure. But so like, not to give away the future roadmap, but I, I

1431
01:20:03,845 --> 01:20:07,385
Speaker 6:  don't think there's a limit to that. So I don't, when you say it, it doesn't

1432
01:20:07,505 --> 01:20:10,105
Speaker 6:  resonate as much for me because we do believe in interoperability. Yeah.

1433
01:20:10,125 --> 01:20:13,745
Speaker 6:  We do wanna see it, you know, we see our products on all the other platforms

1434
01:20:13,765 --> 01:20:17,625
Speaker 6:  and in a way that's useful for customers where it matters to them. Not just

1435
01:20:17,625 --> 01:20:20,425
Speaker 6:  to do it or to check a box, but that it matters. I

1436
01:20:20,425 --> 01:20:22,185
Speaker 4:  Have one more question then we actually do need to let you go 'cause you

1437
01:20:22,185 --> 01:20:22,785
Speaker 4:  have other things to

1438
01:20:22,785 --> 01:20:24,945
Speaker 6:  Do. I do. It turns out you,

1439
01:20:25,165 --> 01:20:28,985
Speaker 4:  You were talking about the the sort of dedicated device

1440
01:20:28,985 --> 01:20:29,265
Speaker 4:  and the

1441
01:20:29,395 --> 01:20:33,345
Speaker 6:  Isn't it at some point, doesn't my team, doesn't our team save me at some

1442
01:20:33,345 --> 01:20:33,545
Speaker 6:  point

1443
01:20:33,635 --> 01:20:36,665
Speaker 4:  We're in this moment of like the supposed

1444
01:20:37,525 --> 01:20:41,185
Speaker 4:  disintermediation of the smartphone, right? There's like, we for years now,

1445
01:20:41,465 --> 01:20:45,225
Speaker 4:  companies are like, what is the thing that comes after phones and like digital

1446
01:20:45,225 --> 01:20:48,585
Speaker 4:  cameras are making a comeback. Everybody's buying cool pys from 20 years

1447
01:20:48,585 --> 01:20:52,305
Speaker 4:  ago again. Are they big trend? That's cool. You've been through

1448
01:20:53,125 --> 01:20:56,295
Speaker 4:  like, you've been making products through the whole rise and

1449
01:20:57,085 --> 01:21:00,055
Speaker 4:  sort of dominance of the smartphone. And you mentioned, you know, the Kindle

1450
01:21:00,055 --> 01:21:02,335
Speaker 4:  is a distraction for you device. It's been that thing for a long time. It's

1451
01:21:02,335 --> 01:21:06,095
Speaker 4:  been successful for a long time. Do you buy the like, big picture

1452
01:21:06,225 --> 01:21:10,055
Speaker 4:  trend here that we we shoved everything into a phone

1453
01:21:10,075 --> 01:21:12,215
Speaker 4:  and the next phase is like pulling it all back out again?

1454
01:21:12,515 --> 01:21:13,895
Speaker 6:  No, no. I don't buy that all.

1455
01:21:14,405 --> 01:21:14,695
Speaker 4:  Okay.

1456
01:21:15,005 --> 01:21:18,815
Speaker 6:  Yeah. I didn't know that was the big picture trend. There

1457
01:21:18,815 --> 01:21:21,135
Speaker 4:  Are a lot of people who would like you to believe that it is. I'm not sure

1458
01:21:21,135 --> 01:21:23,095
Speaker 4:  there they do any of them are everybody who

1459
01:21:23,095 --> 01:21:24,655
Speaker 6:  Wants to make, tell me, are they really important people? 'cause

1460
01:21:24,655 --> 01:21:27,615
Speaker 4:  Anybody who's not Google and Apple would really like that to be the case.

1461
01:21:27,855 --> 01:21:30,415
Speaker 4:  'cause that's a really great way for them to get around app store taxes.

1462
01:21:31,005 --> 01:21:31,295
Speaker 4:  Yeah.

1463
01:21:31,535 --> 01:21:34,535
Speaker 3:  I mean I, I think If, you believe AI is a platform shift and you,

1464
01:21:34,795 --> 01:21:36,575
Speaker 6:  AI is a platform shift. There's no question.

1465
01:21:36,575 --> 01:21:39,015
Speaker 3:  But then, so then you can control and you kind of use your interface, right?

1466
01:21:39,095 --> 01:21:41,735
Speaker 3:  I mean, that's the heart of it. Sure. And then maybe you can get people to

1467
01:21:41,735 --> 01:21:42,055
Speaker 3:  stop using

1468
01:21:42,055 --> 01:21:44,375
Speaker 6:  Their phone. Yeah. But I don't think the phone's going away. Yeah. Like all,

1469
01:21:44,375 --> 01:21:47,495
Speaker 6:  everything you said was right. I think the and then part was odd.

1470
01:21:48,915 --> 01:21:52,735
Speaker 6:  Yeah. I mean, look, phone's a

1471
01:21:52,865 --> 01:21:56,845
Speaker 6:  incredible utility in the product you have in your pocket right now. Probably

1472
01:21:56,865 --> 01:22:00,725
Speaker 6:  is probably a great product. I, and it has its purpose and form.

1473
01:22:00,965 --> 01:22:03,525
Speaker 6:  I do think jobs are gonna move off the phone,

1474
01:22:04,775 --> 01:22:08,595
Speaker 6:  but I don't think the phone goes away. I think we can make some magical

1475
01:22:08,715 --> 01:22:12,355
Speaker 6:  products that have literally nothing to do with the phone. Yeah.

1476
01:22:13,135 --> 01:22:16,785
Speaker 6:  And we're going to, I mean that's, that's why I'm here at Amazon.

1477
01:22:17,755 --> 01:22:21,685
Speaker 6:  Like, go back to your first question. That is why I'm here at Amazon.

1478
01:22:21,685 --> 01:22:25,325
Speaker 6:  Like, no question. Like we can, the

1479
01:22:25,325 --> 01:22:28,925
Speaker 6:  opportunity to make magic with the through line of ai, as you said earlier,

1480
01:22:29,505 --> 01:22:33,485
Speaker 6:  that's not fake. Yeah. That is a platform shift. But to get a silly

1481
01:22:33,485 --> 01:22:36,525
Speaker 6:  to say, you know, I remember 12 years ago when

1482
01:22:38,085 --> 01:22:41,485
Speaker 6:  13, so years ago when I, we had started surface. Lemme just give you an analogy.

1483
01:22:41,505 --> 01:22:45,435
Speaker 6:  Not that I wanna go back there. There were so many

1484
01:22:45,435 --> 01:22:48,275
Speaker 6:  people that told me the laptop is dead.

1485
01:22:49,815 --> 01:22:53,055
Speaker 6:  I mean, what are you doing? It's over. The phone has replaced it. That's,

1486
01:22:53,055 --> 01:22:55,895
Speaker 6:  that was the meme 13 years ago. And

1487
01:22:56,995 --> 01:23:00,875
Speaker 6:  that's not what was happening. Now what was happening is certain jobs were

1488
01:23:00,875 --> 01:23:04,235
Speaker 6:  moving to the phone, just shopping's great on the phone.

1489
01:23:04,865 --> 01:23:08,045
Speaker 6:  Social media is incredible on the phone, taking photos off the phone, pretty

1490
01:23:08,045 --> 01:23:10,245
Speaker 6:  damn good. Texting, communicating.

1491
01:23:11,865 --> 01:23:15,535
Speaker 6:  But then the jobs on the laptop just got stronger, which is

1492
01:23:15,735 --> 01:23:19,695
Speaker 6:  interesting. The jobs that had to be done on it, you know, walk into

1493
01:23:19,695 --> 01:23:23,375
Speaker 6:  any meeting and everybody opens their laptop. It's just what they do.

1494
01:23:24,355 --> 01:23:27,935
Speaker 6:  And in many places you can do a lot on your phone. But

1495
01:23:28,475 --> 01:23:32,085
Speaker 6:  what it's not that the PC was dying in. It's analogous now.

1496
01:23:32,705 --> 01:23:33,645
Speaker 6:  So take that analogy.

1497
01:23:36,365 --> 01:23:39,525
Speaker 6:  Same thing now. I think jobs are gonna move off the phone.

1498
01:23:40,515 --> 01:23:43,835
Speaker 6:  I think there's probably better products and I know there is that are coming,

1499
01:23:45,175 --> 01:23:48,125
Speaker 6:  you know, products that will bring more seamless,

1500
01:23:49,375 --> 01:23:52,265
Speaker 6:  more seamlessness for ai, make it more useful for people.

1501
01:23:54,025 --> 01:23:56,345
Speaker 6:  I mean I, you know, I might be working on some of those products right now

1502
01:23:56,365 --> 01:24:00,145
Speaker 6:  if it turns out, you know, where we started. I, I believe that.

1503
01:24:00,385 --> 01:24:03,505
Speaker 6:  I don't only believe it. I know it's, and I, and I know it's right for customers,

1504
01:24:03,505 --> 01:24:07,475
Speaker 6:  like for people, but to say it's going away. Come on. That's just,

1505
01:24:07,495 --> 01:24:10,635
Speaker 6:  that's silly. It just, I think jobs do move though. Does that analogy make

1506
01:24:10,635 --> 01:24:14,035
Speaker 6:  sense? Like the phone's aren't going away. Yeah. That screen in your pocket,

1507
01:24:14,215 --> 01:24:18,035
Speaker 6:  that's not the point. However, will they, will certain jobs move and be

1508
01:24:18,035 --> 01:24:21,995
Speaker 6:  better somewhere else? I think yeah, for sure. Now is

1509
01:24:21,995 --> 01:24:24,475
Speaker 6:  there a world where everyone has a hundred devices in their back? No, no,

1510
01:24:24,475 --> 01:24:28,315
Speaker 6:  no, no. But you know, some jobs move to your wrist and they're better

1511
01:24:28,315 --> 01:24:31,115
Speaker 6:  there. Some jobs stay in your pocket and they're better there. Some jobs

1512
01:24:31,115 --> 01:24:34,835
Speaker 6:  will be on your eyes. They're better there. And you know,

1513
01:24:34,835 --> 01:24:38,755
Speaker 6:  once that back to your seamless operations, like a

1514
01:24:38,755 --> 01:24:41,915
Speaker 6:  lot of things will be ambient devices where voice is powerful.

1515
01:24:42,585 --> 01:24:45,685
Speaker 6:  You know, I know a few of those things. We got over a hundred million people

1516
01:24:45,685 --> 01:24:48,805
Speaker 6:  using 'em right now. Like, jobs are gonna move there and they're gonna be

1517
01:24:48,805 --> 01:24:52,165
Speaker 6:  awesome. And by the way, unbelievably powerful jobs.

1518
01:24:52,745 --> 01:24:56,325
Speaker 6:  And you're gonna see it on devices that my team's building. Like literally,

1519
01:24:56,825 --> 01:25:00,045
Speaker 6:  I'm not supposed to talk about it. I gotta see my team's like, oh, don't

1520
01:25:00,045 --> 01:25:03,725
Speaker 6:  talk about it, don't you? Hold on, slow down on your, you know, I'm

1521
01:25:03,905 --> 01:25:07,485
Speaker 6:  so, stop hinting at Echo and Alexa, stop it. Like, but let's be clear. Like

1522
01:25:07,995 --> 01:25:11,285
Speaker 6:  there's reality between bringing together all these things. It's why I'm

1523
01:25:11,285 --> 01:25:15,165
Speaker 6:  here working with this amazing team at Amazon, man. Like, and I'm telling

1524
01:25:15,165 --> 01:25:18,495
Speaker 6:  you that product makers at Amazon are so good.

1525
01:25:19,275 --> 01:25:23,175
Speaker 6:  And so you, you just, there's this opportunity to pull, to

1526
01:25:23,175 --> 01:25:26,655
Speaker 6:  pull a lot of things together. But then go back to your original point. I'm

1527
01:25:26,655 --> 01:25:28,775
Speaker 6:  not, I'm not sitting here as a, you know,

1528
01:25:30,645 --> 01:25:34,545
Speaker 6:  as part of this industry saying yes. And the phone is going away. Like,

1529
01:25:34,565 --> 01:25:38,185
Speaker 6:  no, come on. Silly. Yeah, silly. Couldn't get me to say that about

1530
01:25:38,425 --> 01:25:41,625
Speaker 6:  technologies that matter every day in our lives. I, I might be wrong. Maybe

1531
01:25:42,565 --> 01:25:46,145
Speaker 6:  be happy to be proven wrong. It's fine by me. You know, we got other options.

1532
01:25:46,205 --> 01:25:46,425
Speaker 6:  But

1533
01:25:46,805 --> 01:25:47,505
Speaker 3:  Do you think AI

1534
01:26:42,795 --> 01:26:43,285
Speaker 3:  Yeah, this

1535
01:26:43,285 --> 01:26:44,725
Speaker 6:  Is great. Thanks guys. It was a lot of fun.

1536
01:28:06,745 --> 01:28:08,525
Speaker 3:  All right, we're back The lightning round.

1537
01:28:10,095 --> 01:28:13,705
Speaker 3:  This, this week. I sent Slacks about getting the lightning round

1538
01:28:13,705 --> 01:28:14,145
Speaker 3:  sponsored.

1539
01:28:14,495 --> 01:28:18,265
Speaker 4:  Whoa, did they accomplish anything? How rich are we now?

1540
01:28:18,705 --> 01:28:22,665
Speaker 3:  I will say we, there were some very creative ideas that are still not

1541
01:28:22,665 --> 01:28:25,905
Speaker 3:  the idea of just having us say the lightning round is sponsor. Mm.

1542
01:28:28,395 --> 01:28:31,415
Speaker 3:  If you've got a company with the word lightning in it, boy do they want to

1543
01:28:31,415 --> 01:28:31,855
Speaker 3:  talk to you?

1544
01:28:35,115 --> 01:28:35,405
Speaker 4:  Sure.

1545
01:28:36,395 --> 01:28:38,965
Speaker 3:  Yeah. It's a lot. We're working on it. Again, I have no

1546
01:28:40,205 --> 01:28:43,805
Speaker 3:  ability or sophistication or experience in selling ads,

1547
01:28:44,385 --> 01:28:48,125
Speaker 3:  so I'm just, my job is to just say it every week. It's just

1548
01:28:48,495 --> 01:28:48,845
Speaker 3:  speak

1549
01:28:49,245 --> 01:28:50,605
Speaker 4:  Advertising into existence is

1550
01:28:50,605 --> 01:28:52,685
Speaker 3:  Definitely our works. Someone else with some money show up and someone here,

1551
01:28:52,685 --> 01:28:53,365
Speaker 3:  we'll figure it out.

1552
01:28:53,765 --> 01:28:57,125
Speaker 4:  I hope it's like the Tampa Bay Lightning, the, the NHL team that eventually

1553
01:28:57,125 --> 01:28:58,285
Speaker 4:  sponsors the lightning round. Cool. That,

1554
01:28:58,285 --> 01:29:00,765
Speaker 3:  That's, that's basically where we're at. And I was like, I don't, it doesn't

1555
01:29:00,765 --> 01:29:04,725
Speaker 3:  have to, to be that complicated, like sponsored by George I think would

1556
01:29:04,725 --> 01:29:05,485
Speaker 3:  work at this point.

1557
01:29:07,045 --> 01:29:08,085
Speaker 4:  I like that. George,

1558
01:29:08,395 --> 01:29:12,205
Speaker 3:  Your name is George and you can write a check. Call us up. It's some number.

1559
01:29:12,325 --> 01:29:14,525
Speaker 3:  I don't know how it works. I don't know. If, you can call us up to buy an

1560
01:29:14,525 --> 01:29:17,485
Speaker 3:  ad. Anyway, there's kind of a lot in this lightning round.

1561
01:29:17,775 --> 01:29:18,245
Speaker 4:  There is,

1562
01:29:18,665 --> 01:29:19,605
Speaker 3:  You take the first one.

1563
01:29:20,225 --> 01:29:24,005
Speaker 4:  All right, so this happened today, Thursday, as we're recording,

1564
01:29:24,625 --> 01:29:28,365
Speaker 4:  Google announced some pretty big org chart

1565
01:29:28,705 --> 01:29:31,725
Speaker 4:  shifts. And this is the thing we've kind of been tracking all year. Google

1566
01:29:31,825 --> 01:29:35,805
Speaker 4:  has been pretty aggressively changing the way the company

1567
01:29:35,805 --> 01:29:39,485
Speaker 4:  works, partly in order to just Ai I

1568
01:29:39,485 --> 01:29:43,405
Speaker 4:  everything. But I think partly because Google has changed a lot as

1569
01:29:43,445 --> 01:29:46,565
Speaker 4:  a company. And you have a lot of people who've been there a long time who

1570
01:29:46,735 --> 01:29:50,685
Speaker 4:  maybe don't wanna be there anymore or are just tapped out on what

1571
01:29:50,685 --> 01:29:52,965
Speaker 4:  they've been doing for a long time. And so like, it's just changing a lot.

1572
01:29:52,965 --> 01:29:56,805
Speaker 4:  And the new one that happened on Thursday was that

1573
01:29:57,065 --> 01:30:00,165
Speaker 4:  PBA Raghavan who has run search ads,

1574
01:30:01,665 --> 01:30:05,235
Speaker 4:  several other things, but mostly he, he is I would say the single most important

1575
01:30:05,235 --> 01:30:08,955
Speaker 4:  person in terms of how Google makes money and has been for a very long time,

1576
01:30:09,455 --> 01:30:13,235
Speaker 4:  is now stepping down from that role and is becoming Google's, I think the

1577
01:30:13,235 --> 01:30:14,715
Speaker 4:  title is chief technologist.

1578
01:30:17,775 --> 01:30:21,675
Speaker 4:  What's the nice way to say this? That title doesn't mean anything. It's,

1579
01:30:21,675 --> 01:30:24,715
Speaker 4:  it's, it's like, this is what I mean, we, we went through this with Hiroshi

1580
01:30:24,715 --> 01:30:27,835
Speaker 4:  Lockheimer, right? Who was like, I'm not leaving Google, I'm just gonna go

1581
01:30:27,835 --> 01:30:31,355
Speaker 4:  take on other roles. And that's all fine and good. They're going to continue

1582
01:30:31,355 --> 01:30:35,305
Speaker 4:  to be interesting, important people inside of Google. But like the way

1583
01:30:35,305 --> 01:30:38,665
Speaker 4:  that Google works is If, you don't run a thing. You don't run a thing. You

1584
01:30:38,665 --> 01:30:41,985
Speaker 4:  know what I mean? And, and So I think the idea of being chief technologist,

1585
01:30:42,765 --> 01:30:46,025
Speaker 4:  it will be big and interesting and he'll like show up at conferences every

1586
01:30:46,025 --> 01:30:49,305
Speaker 4:  once in a while. But like, it is, it is super meaningful that he's leaving

1587
01:30:50,205 --> 01:30:52,145
Speaker 4:  the search team, which is

1588
01:30:52,165 --> 01:30:55,745
Speaker 3:  The team, the most important team under the most pressure,

1589
01:30:55,995 --> 01:30:59,145
Speaker 3:  right? Both from regulators and open ai, whatever.

1590
01:30:59,535 --> 01:31:03,425
Speaker 4:  Yeah, it is, it is the thing. And to that point, actually, the person who

1591
01:31:03,425 --> 01:31:07,265
Speaker 4:  is taking over that job is Nick Fox, who has been

1592
01:31:07,845 --> 01:31:11,585
Speaker 4:  at Google for like forever. And a thing

1593
01:31:11,745 --> 01:31:15,345
Speaker 4:  that I've heard internally over the years is that Nick is one of a very small

1594
01:31:15,345 --> 01:31:19,105
Speaker 4:  number of people who Sundar Pache believes are like his fixers.

1595
01:31:19,405 --> 01:31:23,345
Speaker 4:  He is the person who is tapped to like make a thing work. He had

1596
01:31:23,345 --> 01:31:26,705
Speaker 4:  to do it with messaging, which I, I'm David,

1597
01:31:28,065 --> 01:31:30,985
Speaker 3:  I would, I would just say your evidence does not support your claim.

1598
01:31:31,045 --> 01:31:35,025
Speaker 4:  No, but so yes, except RCS has

1599
01:31:35,025 --> 01:31:38,865
Speaker 4:  worked. Google Messages is now everywhere. Like to the extent

1600
01:31:38,865 --> 01:31:42,225
Speaker 4:  that Nick Fox had to solve an impossible problem, he actually did a pretty

1601
01:31:42,295 --> 01:31:45,905
Speaker 4:  good job. He ran assistant for a long time. He has, he

1602
01:31:46,185 --> 01:31:49,665
Speaker 4:  I think was one of the, who launched Google Phi, like

1603
01:31:50,455 --> 01:31:54,185
Speaker 4:  hits and misses. But, but he is a guy who has been tapped to do some of

1604
01:31:54,185 --> 01:31:57,345
Speaker 4:  Google's most important, most ambitious things at various times.

1605
01:31:58,365 --> 01:32:01,925
Speaker 4:  And So I think it's telling that he is showing up as the one,

1606
01:32:02,395 --> 01:32:05,525
Speaker 4:  he's not like a grizzled search executive, right? Like there are lots of

1607
01:32:05,525 --> 01:32:07,965
Speaker 4:  people inside of search who've been working inside of search for a long time.

1608
01:32:08,265 --> 01:32:12,205
Speaker 4:  He is a guy coming from another part of the company to presumably

1609
01:32:12,225 --> 01:32:16,205
Speaker 4:  change the way that search operates, which I think is very interesting. Then

1610
01:32:16,205 --> 01:32:20,045
Speaker 4:  the other big change is that the whole Gemini

1611
01:32:20,925 --> 01:32:24,805
Speaker 4:  division is now going under DeepMind DeepMind and Demi

1612
01:32:24,985 --> 01:32:28,605
Speaker 4:  Ava who runs DeepMind is just ruthlessly consolidating

1613
01:32:28,785 --> 01:32:31,965
Speaker 4:  AI power inside of Google. Demis just won a Nobel prize,

1614
01:32:32,775 --> 01:32:36,725
Speaker 4:  which is bananas. Like kudos to them for some of the

1615
01:32:36,725 --> 01:32:40,245
Speaker 4:  protein stuff that they've been doing. It's really cool. But like

1616
01:32:40,895 --> 01:32:44,485
Speaker 4:  piece by piece, every AI thing Google has been doing

1617
01:32:45,065 --> 01:32:47,485
Speaker 4:  has come under Demis and DeepMind and

1618
01:32:48,145 --> 01:32:52,125
Speaker 3:  Except for Google Assistant, which is going to platforms and devices,

1619
01:32:52,495 --> 01:32:52,845
Speaker 3:  which

1620
01:32:52,845 --> 01:32:56,165
Speaker 4:  Is I think a sign that Google Assistant is dying, right? Like Google Assistant

1621
01:32:56,165 --> 01:32:58,765
Speaker 4:  is going to be how you turn Bluetooth on and off on your phone and everything

1622
01:32:58,765 --> 01:33:01,885
Speaker 4:  else is gonna be Gemini. Like, that's, that's so clear where that's going

1623
01:33:01,885 --> 01:33:02,085
Speaker 4:  to be.

1624
01:33:02,305 --> 01:33:06,005
Speaker 3:  So that's the Rick Oslo group, that's the Pixel group and the Android group.

1625
01:33:06,425 --> 01:33:07,885
Speaker 4:  Oh, that's right. That is that group.

1626
01:33:08,915 --> 01:33:10,175
Speaker 3:  So that is just fascinating.

1627
01:33:11,055 --> 01:33:13,975
Speaker 4:  I that I, I actually think that makes perfect sense, right? That means that

1628
01:33:13,975 --> 01:33:17,655
Speaker 4:  becomes a, a feature of Android, not an AI thing

1629
01:33:17,955 --> 01:33:19,295
Speaker 3:  Or the home hub stuff.

1630
01:33:20,085 --> 01:33:24,015
Speaker 4:  Sure. It's a, it's a way to turn things on and off on your devices, which

1631
01:33:24,015 --> 01:33:26,455
Speaker 4:  is fine. Like you actually don't need AI to, but

1632
01:33:26,455 --> 01:33:29,255
Speaker 3:  Isn't the future of Google Assistant the future of Gemini, aren't they the

1633
01:33:29,255 --> 01:33:29,535
Speaker 3:  same thing?

1634
01:33:30,695 --> 01:33:33,835
Speaker 4:  No. Which is what's super annoying about using Android right now, because

1635
01:33:33,835 --> 01:33:36,995
Speaker 4:  Gemini can't do the things on your phone. Oh, oh yeah, but this is Google.

1636
01:33:37,395 --> 01:33:41,275
Speaker 4:  Like, come on. I mean, give it a minute and it'll all get rolled under Demis

1637
01:33:41,275 --> 01:33:42,195
Speaker 4:  at they'll this point anyway.

1638
01:33:42,455 --> 01:33:45,795
Speaker 3:  So what I take from this is actually no one knows how to organize these companies,

1639
01:33:46,365 --> 01:33:49,475
Speaker 3:  right? You're announcing a new chief technologist at your company. What is

1640
01:33:49,475 --> 01:33:52,235
Speaker 3:  the most important technology in the future of Google?

1641
01:33:53,465 --> 01:33:57,275
Speaker 3:  It's ai. Yeah. Is your new chief technologist gonna No, he's gonna

1642
01:33:57,275 --> 01:34:00,795
Speaker 3:  run right into your CEO of ai, the guy who just won a Nobel Prize.

1643
01:34:01,305 --> 01:34:04,835
Speaker 4:  Well, this is the problem with ai, right? Like If, you believe AI is,

1644
01:34:05,175 --> 01:34:09,115
Speaker 4:  is the future. It AI is everything. It's your infrastructure, it's

1645
01:34:09,435 --> 01:34:13,195
Speaker 4:  products, it's the like InBetween stuff that enables all this stuff.

1646
01:34:13,225 --> 01:34:16,635
Speaker 4:  It's, it's everything. AI is the whole stack, and

1647
01:34:17,015 --> 01:34:20,555
Speaker 4:  all these companies are putting someone in charge of ai, which is like, not

1648
01:34:20,555 --> 01:34:23,515
Speaker 4:  the same as making them the CEO of the company, but it's also not that different.

1649
01:34:23,785 --> 01:34:26,995
Speaker 3:  Well, So I mean, I would just compare and contrast to Microsoft, which has

1650
01:34:27,775 --> 01:34:31,635
Speaker 3:  now largely the same structure. Google has moved itself to the same

1651
01:34:31,665 --> 01:34:35,515
Speaker 3:  kind of structure as Microsoft. So Microsoft had Kevin Scott,

1652
01:34:35,515 --> 01:34:39,315
Speaker 3:  who's a CTO, famously still the person at Microsoft. He told me this

1653
01:34:39,335 --> 01:34:42,955
Speaker 3:  on decoder. Kevin Scott owns the GPU budget at Microsoft. Mm.

1654
01:34:43,215 --> 01:34:47,195
Speaker 3:  If you wanna buy a GPU, you gotta call Kevin. What? How do you

1655
01:34:47,195 --> 01:34:49,115
Speaker 3:  make yourself the most powerful person in the company?

1656
01:34:49,115 --> 01:34:49,835
Speaker 4:  Yeah, that's that's

1657
01:34:49,835 --> 01:34:53,555
Speaker 3:  Real. So he was the CTO, he was the one who did

1658
01:34:54,075 --> 01:34:57,245
Speaker 3:  a bunch of the opening, like early work to do the opening ideal. He was like,

1659
01:34:57,245 --> 01:35:01,205
Speaker 3:  figured it out. But then Microsoft, all the open

1660
01:35:01,225 --> 01:35:05,005
Speaker 3:  AI drama happened and Microsoft went out and sort of like just acquired

1661
01:35:05,065 --> 01:35:08,805
Speaker 3:  the talent from inflection. And now Mustafa Soliman is the CEO of AI at

1662
01:35:09,045 --> 01:35:12,605
Speaker 3:  Microsoft, and they have a CTO in Kevin Scottsdale that is just a complicated

1663
01:35:12,625 --> 01:35:14,965
Speaker 3:  org chart and it looks exactly like this.

1664
01:35:15,425 --> 01:35:16,445
Speaker 4:  Yep. A hundred percent.

1665
01:35:16,585 --> 01:35:19,685
Speaker 3:  And so you're just ending, these companies are starting to, they're trying

1666
01:35:19,685 --> 01:35:23,485
Speaker 3:  to figure out how to structure themselves to make all this work. And

1667
01:35:23,485 --> 01:35:27,285
Speaker 3:  the, the only difference to me is that Google's

1668
01:35:27,525 --> 01:35:31,485
Speaker 3:  business is under such regulatory threat that a bunch of people

1669
01:35:31,505 --> 01:35:35,445
Speaker 3:  are, I think are kind of choosing to bail instead of taking

1670
01:35:35,505 --> 01:35:36,125
Speaker 3:  the next turn.

1671
01:35:36,755 --> 01:35:39,965
Speaker 4:  Yeah. I mean, and again, even If, you think Google might come out of all

1672
01:35:39,965 --> 01:35:43,845
Speaker 4:  this regulatory stuff unscathed, it's gonna take so long. And

1673
01:35:43,845 --> 01:35:47,565
Speaker 4:  if I'm provocate raghavan, like, do you wanna sit and twiddle your

1674
01:35:47,565 --> 01:35:51,045
Speaker 4:  thumbs for the better part of the decade until all this antitrust stuff gets

1675
01:35:51,045 --> 01:35:54,045
Speaker 4:  sorted out? Or do you just wanna like dip and go work on other problems?

1676
01:35:54,365 --> 01:35:54,965
Speaker 4:  I kind of get it.

1677
01:35:55,155 --> 01:35:58,485
Speaker 3:  Yeah. They, they did all that consolidation. Android, Android and Google

1678
01:35:58,545 --> 01:36:02,485
Speaker 3:  is filing emergency motions with the court in the Epic case today to

1679
01:36:02,535 --> 01:36:06,125
Speaker 3:  delay opening up Android to other stores. Do you wanna do that or do you

1680
01:36:06,125 --> 01:36:06,885
Speaker 3:  just wanna wander the earth,

1681
01:36:07,525 --> 01:36:10,125
Speaker 4:  Right? Yeah. All right. What's yours?

1682
01:36:10,935 --> 01:36:14,125
Speaker 3:  Weird. I actually have more Google stuff. Oh, do you? But it's also Trump

1683
01:36:14,125 --> 01:36:17,845
Speaker 3:  stuff, and I, I apologize. Oh no, it's election season. Oh God. Trump

1684
01:36:17,905 --> 01:36:19,005
Speaker 3:  is talking a lot

1685
01:36:21,185 --> 01:36:23,725
Speaker 3:  And people are mad at us for covering this stuff, but, you know, there's

1686
01:36:23,725 --> 01:36:27,125
Speaker 3:  a, a meaningful chance he, he could win. And I would just point out

1687
01:36:27,635 --> 01:36:31,405
Speaker 3:  that we, we, we live through the tech policy of a first Trump administration,

1688
01:36:32,135 --> 01:36:35,855
Speaker 3:  which was bananas. I I've been made to

1689
01:36:36,135 --> 01:36:38,335
Speaker 3:  remember it recently, which I'm very upset about. Do you remember when I

1690
01:36:38,335 --> 01:36:40,975
Speaker 3:  just counted days since Trump announced Google would build a website for

1691
01:36:40,975 --> 01:36:44,695
Speaker 3:  Coronavirus testing like every week? Like that's where we're at again.

1692
01:36:44,765 --> 01:36:47,655
Speaker 3:  Yeah. Only this time he hates the tech companies

1693
01:36:48,625 --> 01:36:52,115
Speaker 3:  like JD Vance's answer to, did Donald Trump lose the election

1694
01:36:52,495 --> 01:36:56,115
Speaker 3:  is not yes or no, it's big tech interfered with the Hunter Biden

1695
01:36:56,175 --> 01:36:58,855
Speaker 3:  laptop story. Right? Which is not an answer,

1696
01:36:59,195 --> 01:37:00,455
Speaker 4:  But they're pro TikTok now,

1697
01:37:00,595 --> 01:37:03,335
Speaker 3:  But they're pro So none of this makes any sense, by the way, that's not an

1698
01:37:03,335 --> 01:37:07,175
Speaker 3:  answer. Like, you can be upset that people did or did not have

1699
01:37:07,525 --> 01:37:11,055
Speaker 3:  information. That does not mean that their votes don't count.

1700
01:37:11,305 --> 01:37:14,775
Speaker 3:  Right? Like I think a lot of people who voted for Hillary Clinton are pretty

1701
01:37:14,915 --> 01:37:18,255
Speaker 3:  mad that New York Times chose to make the word emails

1702
01:37:18,385 --> 01:37:22,095
Speaker 3:  incredibly relevant to everyone, such that The Verge dot com sells a

1703
01:37:22,215 --> 01:37:26,055
Speaker 3:  T-shirt that just says emails on it. But that doesn't mean their votes

1704
01:37:26,055 --> 01:37:29,735
Speaker 3:  didn't count. Yep. And so that whole Vance line of attack is nonsensical.

1705
01:37:29,735 --> 01:37:33,295
Speaker 3:  But it, what it's pointed at is we're, we're all mad at tech companies. So

1706
01:37:33,305 --> 01:37:34,455
Speaker 3:  Trump is on stage

1707
01:37:36,205 --> 01:37:39,885
Speaker 3:  at the Economic club of Chicago, being interviewed by John

1708
01:37:39,885 --> 01:37:42,925
Speaker 3:  Michelate, who's the editor-in-chief of Bloomberg News. John Michel, wait

1709
01:37:42,925 --> 01:37:46,685
Speaker 3:  is a very proper British man. He used to be the editor-in-Chief of the Economist.

1710
01:37:47,965 --> 01:37:50,665
Speaker 3:  He is not a guff taking

1711
01:37:51,975 --> 01:37:53,345
Speaker 3:  kind of dude. No. Do you

1712
01:37:53,345 --> 01:37:56,365
Speaker 4:  Know what I mean? Yeah. He's not, he's not a, a shenanigans kind of guy.

1713
01:37:56,475 --> 01:37:59,605
Speaker 3:  Yeah. I I, you know, I know a lot of EICs.

1714
01:38:01,165 --> 01:38:04,855
Speaker 3:  This isn't the one that is having a party on the boat, you know, I'm just

1715
01:38:04,855 --> 01:38:07,415
Speaker 3:  putting out. But there are other ones that are, I'm not gonna say who they

1716
01:38:07,415 --> 01:38:10,375
Speaker 3:  are, but if you're on my list, you're on my list. You know what I'm saying?

1717
01:38:10,375 --> 01:38:12,775
Speaker 3:  Okay. So John Michel Way is interviewing Donald Trump

1718
01:38:14,155 --> 01:38:17,215
Speaker 3:  and he says the Department of Justice wants to break up Google, what do you

1719
01:38:17,215 --> 01:38:20,975
Speaker 3:  think? And then Trump just says some

1720
01:38:21,105 --> 01:38:21,455
Speaker 3:  stuff

1721
01:38:23,655 --> 01:38:26,955
Speaker 3:  and all of it adds up to I wanna do some speech regulations.

1722
01:38:27,565 --> 01:38:31,435
Speaker 3:  Lemme just, I'm just gonna read it to you. Trump says, yeah, look,

1723
01:38:31,435 --> 01:38:34,315
Speaker 3:  Google's got a lot of power. They're very bad to me, very, very bad to me.

1724
01:38:34,355 --> 01:38:37,795
Speaker 3:  I can speak from that standpoint. They only have bad stories.

1725
01:38:38,175 --> 01:38:41,475
Speaker 3:  In other words, I have 20 good stories and 20 bad stories. Everyone's entitled

1726
01:38:41,475 --> 01:38:45,395
Speaker 3:  to that. You only see the 20 bad stories. I called the head of Google

1727
01:38:45,535 --> 01:38:49,235
Speaker 3:  the other day and I said I'm getting a lot of good stories lately, but you

1728
01:38:49,235 --> 01:38:52,795
Speaker 3:  don't find them in Google. I think it's a whole rigged deal. I think

1729
01:38:52,795 --> 01:38:55,875
Speaker 3:  Google's rigged just like our government's rigged all over the place.

1730
01:38:57,625 --> 01:39:01,555
Speaker 3:  Confusing. Yeah. So I. Think what he's talking about is if

1731
01:39:01,555 --> 01:39:05,115
Speaker 3:  there are 20 stories about good stuff Trump has done and 20 stories about

1732
01:39:05,115 --> 01:39:07,515
Speaker 3:  bad stuff Trump has done and you search for Donald Trump's name in Google

1733
01:39:07,545 --> 01:39:09,275
Speaker 3:  News, you only get the negative stories.

1734
01:39:11,275 --> 01:39:12,625
Speaker 3:  Presu, presumably. That is,

1735
01:39:13,065 --> 01:39:14,305
Speaker 4:  I believe that is what he's talking about.

1736
01:39:14,565 --> 01:39:17,905
Speaker 3:  And he called up, presumably Sundar Phai, and complained about this.

1737
01:39:19,025 --> 01:39:21,755
Speaker 3:  That is just core First Amendment activity. Maybe he

1738
01:39:21,755 --> 01:39:24,915
Speaker 4:  Called PBA and Bakker was like, I'm done with this. I'm out. Nevermind.

1739
01:39:26,195 --> 01:39:29,995
Speaker 3:  I don't know man. That is just, that is just straightforward. First amendment

1740
01:39:29,995 --> 01:39:32,955
Speaker 3:  protected activity. Yeah. We're gonna rank some stories.

1741
01:39:33,735 --> 01:39:36,315
Speaker 3:  You're gonna type in a search term and we're gonna show you a list of them.

1742
01:39:36,535 --> 01:39:40,455
Speaker 3:  And maybe you think Google should be more neutral, but

1743
01:39:40,455 --> 01:39:44,175
Speaker 3:  If, you wanna do something about it. You're gonna, you in this country

1744
01:39:44,365 --> 01:39:48,295
Speaker 3:  will run straight into the First Amendment and these companies have won

1745
01:39:49,055 --> 01:39:52,895
Speaker 3:  multiple cases asserting their first memo, right? Yep. So

1746
01:39:52,895 --> 01:39:56,695
Speaker 3:  then he pivots this conversation with Google to China and he says, I do something.

1747
01:39:57,155 --> 01:39:59,495
Speaker 3:  But you have to give them a lot of credit. They've become such a power, such

1748
01:39:59,495 --> 01:40:02,175
Speaker 3:  a power. You have to give 'em credit. How they became a power is really a

1749
01:40:02,175 --> 01:40:05,055
Speaker 3:  discussion. Is that an antitrust argument? I don't know. And then he says,

1750
01:40:05,055 --> 01:40:07,535
Speaker 3:  at the same time, it's a very dangerous thing because we want have great

1751
01:40:07,815 --> 01:40:11,735
Speaker 3:  companies. We don't want China to have these companies. Right now China

1752
01:40:11,875 --> 01:40:14,955
Speaker 3:  is afraid of Google. And then, and

1753
01:40:15,825 --> 01:40:19,755
Speaker 3:  then he says China is a very powerful, very smart group of

1754
01:40:19,755 --> 01:40:19,875
Speaker 3:  people.

1755
01:40:20,135 --> 01:40:22,395
Speaker 4:  I'm really glad you read that part. I was gonna make you read that part.

1756
01:40:22,395 --> 01:40:23,795
Speaker 4:  If you didn't otherwise, which

1757
01:40:23,795 --> 01:40:27,035
Speaker 3:  Is a great way to describe a country. Yeah. What is a country

1758
01:40:29,695 --> 01:40:33,435
Speaker 3:  So, I don't know man. Like is China

1759
01:40:33,435 --> 01:40:37,425
Speaker 3:  afraid of Google? A company that doesn't operate in China? I is he

1760
01:40:37,425 --> 01:40:41,345
Speaker 3:  talking about ai? I, I tru I, I've like

1761
01:40:41,345 --> 01:40:44,945
Speaker 3:  been trying to parse this for some time. So then Michel wait says, well if

1762
01:40:44,945 --> 01:40:48,905
Speaker 3:  you're afraid of China, China, you wanted to ban TikTok and now you're

1763
01:40:48,905 --> 01:40:52,265
Speaker 3:  gonna let TikTok operate in this country. And

1764
01:40:53,485 --> 01:40:56,765
Speaker 3:  I don't know, Trump just kind of just pivoted this

1765
01:40:56,765 --> 01:41:00,645
Speaker 3:  conversation. 'cause Michael Fright said, is TikTok a threat? And

1766
01:41:00,645 --> 01:41:04,165
Speaker 3:  Trump goes, I think it is a threat. Frankly. I think everything is a threat.

1767
01:41:04,165 --> 01:41:05,765
Speaker 3:  There's nothing that's not a threat.

1768
01:41:06,305 --> 01:41:07,405
Speaker 4:  We should put that on a T-shirt.

1769
01:41:07,925 --> 01:41:10,645
Speaker 3:  But sometimes you fight through the threats like Google, I'm not a fan of

1770
01:41:10,645 --> 01:41:13,485
Speaker 3:  Google. They treat me badly. But are you gonna destroy the company by doing

1771
01:41:13,485 --> 01:41:16,925
Speaker 3:  that If, you do that. Are you gonna destroy the com company? What you can

1772
01:41:16,925 --> 01:41:20,605
Speaker 3:  do without breaking it up is make sure it's more

1773
01:41:20,635 --> 01:41:23,805
Speaker 3:  fair. And then he ends with,

1774
01:41:24,865 --> 01:41:28,325
Speaker 3:  and it's only bad because of fake news because the news is really fake. That's

1775
01:41:28,325 --> 01:41:31,405
Speaker 3:  the one thing we have to straighten out. We have to straighten out the press

1776
01:41:31,405 --> 01:41:32,725
Speaker 3:  because we have a corrupt press

1777
01:41:34,655 --> 01:41:38,425
Speaker 3:  that all of that is speech regulations. Yeah. I want to make Google

1778
01:41:38,495 --> 01:41:42,295
Speaker 3:  more fair. That's a content moderation law. And we're gonna pass

1779
01:41:42,375 --> 01:41:45,575
Speaker 3:  a law insisting that Google is fair. I don't know how you do that. And then

1780
01:41:45,575 --> 01:41:46,815
Speaker 3:  we're gonna straighten out the press

1781
01:41:48,805 --> 01:41:52,755
Speaker 3:  how write the, like if you're mad at me for saying those, you

1782
01:41:52,755 --> 01:41:56,475
Speaker 3:  write, go ahead, write the law. Right? That straightens out the press put

1783
01:41:56,475 --> 01:41:58,555
Speaker 3:  in, involve the government in that process. Just

1784
01:41:58,555 --> 01:42:01,555
Speaker 4:  In the course of that, he drills all the way down to, actually the problem

1785
01:42:01,655 --> 01:42:05,115
Speaker 4:  is not fix Google, it's fix the people who are writing

1786
01:42:05,455 --> 01:42:09,035
Speaker 4:  the stories about Google or about me that get posted on

1787
01:42:09,275 --> 01:42:13,155
Speaker 4:  Google. Like it just, I don't know, If, you think

1788
01:42:13,155 --> 01:42:17,075
Speaker 4:  too hard about it. Your brain sort of explodes. But the, these are things

1789
01:42:17,075 --> 01:42:17,795
Speaker 4:  he said out loud.

1790
01:42:18,295 --> 01:42:21,915
Speaker 3:  And apparently he's Colin, CEO. So then the other story is

1791
01:42:22,565 --> 01:42:25,595
Speaker 3:  today he said Tim Cook called him.

1792
01:42:26,915 --> 01:42:30,255
Speaker 3:  So I'm just gonna read you this quote. He's on one of the many, many bro

1793
01:42:30,335 --> 01:42:34,055
Speaker 3:  podcasts that he's been going on lately. Like this man's on YouTube. Like

1794
01:42:34,105 --> 01:42:37,335
Speaker 3:  who's on YouTube? It's Mr. Beast. Logan Paul. It's Donald Trump. Like he's

1795
01:42:37,335 --> 01:42:40,695
Speaker 3:  just real. If you've got a YouTube bro podcast, call him up. He's ready to

1796
01:42:40,695 --> 01:42:44,615
Speaker 3:  go. So he is on one today, the PBD podcast. Please don't get mad at

1797
01:42:44,615 --> 01:42:46,895
Speaker 3:  me if you're like some huge YouTube fan of this podcast. I've never heard

1798
01:42:46,895 --> 01:42:49,575
Speaker 3:  of it before. This is what I'm telling you. And I'm looking at the thumbnail

1799
01:42:49,575 --> 01:42:52,615
Speaker 3:  here and I'm describing it as I'm describing it. He's on this podcast today

1800
01:42:52,955 --> 01:42:56,815
Speaker 3:  and he says, two hours ago, three hours ago, he cook called me. He

1801
01:42:56,815 --> 01:43:00,175
Speaker 3:  said, the European Union has just fined us $15 billion. On top of that, they

1802
01:43:00,175 --> 01:43:03,775
Speaker 3:  got fined by the European Union, another $2 billion, which is

1803
01:43:03,885 --> 01:43:07,415
Speaker 3:  true in March, the EU find Apple 2 billion

1804
01:43:07,665 --> 01:43:11,455
Speaker 3:  after finding that Apple was restricting music apps in some way.

1805
01:43:11,915 --> 01:43:15,895
Speaker 3:  And then they basically said, apple, it needs to pay 14.4 billion in

1806
01:43:15,895 --> 01:43:19,415
Speaker 3:  unpaid taxes. Totally different things. Yeah, totally different fines. And

1807
01:43:19,415 --> 01:43:22,775
Speaker 3:  then Trump goes on to say he cook said something that was interesting. He

1808
01:43:22,775 --> 01:43:26,215
Speaker 3:  said, they're using that to run their enterprise, meaning Europe is their

1809
01:43:26,215 --> 01:43:29,935
Speaker 3:  enterprise. And then he said, that's a lot, Tim, but I have to get elected

1810
01:43:29,935 --> 01:43:32,815
Speaker 3:  first, but I won't let them take advantage of our companies. That won't be

1811
01:43:32,815 --> 01:43:33,135
Speaker 3:  happening.

1812
01:43:33,775 --> 01:43:34,065
Speaker 4:  What?

1813
01:43:35,165 --> 01:43:38,775
Speaker 3:  Okay, first of all, I love the idea that either Tim Cook or Donald Trump

1814
01:43:38,775 --> 01:43:41,255
Speaker 3:  thinks that it costs $15 billion to run the eu.

1815
01:43:44,675 --> 01:43:48,495
Speaker 3:  I'm like, very good. The most efficient government in world history. That

1816
01:43:48,495 --> 01:43:48,855
Speaker 3:  would be great.

1817
01:43:50,445 --> 01:43:53,085
Speaker 3:  Unclear how any us politician

1818
01:43:54,585 --> 01:43:58,245
Speaker 3:  can negotiate tax rates in other

1819
01:43:59,045 --> 01:44:02,645
Speaker 3:  countries. That's just a, that's just a thing. Like if

1820
01:44:03,035 --> 01:44:06,245
Speaker 3:  Germany showed up on our doorstep and it was like, we've got some ideas about

1821
01:44:06,245 --> 01:44:10,125
Speaker 3:  your tax. Like we wouldn't, we wish wouldn't do it. I

1822
01:44:10,125 --> 01:44:11,365
Speaker 3:  don't know. I'd be like, go away Germany,

1823
01:44:14,165 --> 01:44:17,605
Speaker 3:  American flag. Like, get outta here. So, I.

1824
01:44:18,385 --> 01:44:21,285
Speaker 3:  That's confusing. Yeah. Maybe, maybe there's something the president can

1825
01:44:21,285 --> 01:44:21,765
Speaker 3:  do. In that case,

1826
01:44:23,425 --> 01:44:27,085
Speaker 3:  the weirder thing is, he just said it. He said,

1827
01:44:27,465 --> 01:44:31,125
Speaker 3:  you know, in the Google case, he said, I called the head of Google and I

1828
01:44:31,125 --> 01:44:34,965
Speaker 3:  said, some outlandish nonsense. Okay. We, we asked Google, they didn't say

1829
01:44:35,045 --> 01:44:38,285
Speaker 3:  anything. But that's Trump's claim that he called, and maybe he's lying in

1830
01:44:38,285 --> 01:44:41,945
Speaker 3:  this one. He says, cook called him to complain about EU

1831
01:44:41,945 --> 01:44:45,105
Speaker 3:  regulations, which is a very interesting thing to, for Tim Cook to have done.

1832
01:44:46,005 --> 01:44:49,945
Speaker 3:  He put a timeframe on it. He said three hours ago he called me. So

1833
01:44:49,945 --> 01:44:53,265
Speaker 3:  we know approximately when that's today as we're speaking.

1834
01:44:54,005 --> 01:44:56,865
Speaker 3:  And so we asked Apple about this. Apple flatly doesn't respond.

1835
01:44:58,025 --> 01:45:01,465
Speaker 3:  I will tell you, we talk to Apple a lot. We send a lot of notes to a lot

1836
01:45:01,465 --> 01:45:04,745
Speaker 3:  of companies. Hey, did this happen? Hey, we need a statement. Hey, here's

1837
01:45:04,745 --> 01:45:08,715
Speaker 3:  this thing. Hey, I have a lot of thoughts about your iPhone camera. We

1838
01:45:08,735 --> 01:45:11,755
Speaker 3:  we talk to these companies a lot. Yeah. Dead silence. I don't know what it

1839
01:45:11,755 --> 01:45:15,675
Speaker 3:  means. I I can't, I'm not gonna interpret it. I'm just saying it is, there's

1840
01:45:15,675 --> 01:45:19,515
Speaker 3:  not, I don't have to like go to a magistrate judge and file a form

1841
01:45:19,515 --> 01:45:23,195
Speaker 3:  in triplicate to get a comment from a big tech company, right? Like, this

1842
01:45:23,195 --> 01:45:25,835
Speaker 3:  is the thing that we do all the way. So they just didn't respond.

1843
01:45:28,065 --> 01:45:29,545
Speaker 3:  I don't, I I don't know how to interpret this one.

1844
01:45:30,105 --> 01:45:33,865
Speaker 4:  I don't either. It's very, it's very odd. I mean, I think to some

1845
01:45:33,865 --> 01:45:37,585
Speaker 4:  extent the idea that a lot of tech CEOs

1846
01:45:37,805 --> 01:45:41,465
Speaker 4:  are somewhere between actively

1847
01:45:41,575 --> 01:45:45,425
Speaker 4:  rooting for a Trump presidency and hedging their bets in case he

1848
01:45:45,455 --> 01:45:49,225
Speaker 4:  wins by, you know, sucking up to him in various

1849
01:45:49,255 --> 01:45:53,065
Speaker 4:  ways. That's real. That's it happened the last time he was

1850
01:45:53,065 --> 01:45:56,945
Speaker 4:  president. It, it seems pretty clearly it's happening now. Tim

1851
01:45:56,945 --> 01:46:00,785
Speaker 4:  Cook is not the like jump on stage at a rally. Tim

1852
01:46:00,785 --> 01:46:03,545
Speaker 3:  Cook opened a fake factory for Donald Trump. Do you remember this?

1853
01:46:03,545 --> 01:46:04,625
Speaker 4:  This is what I mean. Like this is not,

1854
01:46:04,685 --> 01:46:07,505
Speaker 3:  He was like, they're making iPhones and Macs in America again, right? And

1855
01:46:07,505 --> 01:46:11,305
Speaker 3:  Tim Cook was like, we've sure come to this factory where we've been doing

1856
01:46:11,305 --> 01:46:12,505
Speaker 3:  it for some time. This

1857
01:46:12,505 --> 01:46:14,625
Speaker 4:  Is what I mean, right? So like it's, it wouldn't be

1858
01:46:16,175 --> 01:46:19,095
Speaker 4:  completely out of character for Tim Cook to have done that essentially as

1859
01:46:19,095 --> 01:46:22,855
Speaker 4:  like a make the man feel good, right? Like it, that is the, the

1860
01:46:22,855 --> 01:46:26,735
Speaker 4:  overwhelming advice on how to get things out of Donald Trump

1861
01:46:26,755 --> 01:46:29,135
Speaker 4:  is, is flatter him. And so to call him and be like, Donald,

1862
01:46:30,415 --> 01:46:33,735
Speaker 4:  WTF, you're up. Am I right? It is like, I can see why you would make that

1863
01:46:33,735 --> 01:46:37,455
Speaker 4:  phone call if you're, if you're Tim Cook. I also can see a

1864
01:46:37,455 --> 01:46:41,415
Speaker 4:  series of ways in which this story is not true and why Apple

1865
01:46:42,145 --> 01:46:45,935
Speaker 4:  would decide that there is literally no upside to responding at all. So again,

1866
01:46:45,955 --> 01:46:48,695
Speaker 4:  I'm, I'm in a, I'm in the same place of like, I don't know what to make of

1867
01:46:48,695 --> 01:46:52,525
Speaker 4:  this all the way on the spectrum from none of this happened to, this happened

1868
01:46:52,525 --> 01:46:55,045
Speaker 4:  exactly the way that he describes. I don't know how to interpret any of the

1869
01:46:55,165 --> 01:46:57,045
Speaker 4:  possible outcomes. It's bananas.

1870
01:46:57,365 --> 01:47:01,125
Speaker 3:  I do love the idea that Tim Cook was like, they run Europe on my taxes.

1871
01:47:01,265 --> 01:47:04,425
Speaker 3:  And it's like, well first of all, they're mad at you because you haven't

1872
01:47:04,425 --> 01:47:05,505
Speaker 3:  paid them. Right?

1873
01:47:05,615 --> 01:47:08,065
Speaker 4:  They actually don't. And that's the problem.

1874
01:47:08,485 --> 01:47:09,025
Speaker 3:  To be clear,

1875
01:47:10,605 --> 01:47:13,505
Speaker 3:  So I, I don't think that's enough to run Europe. I, you know, I've never

1876
01:47:13,505 --> 01:47:16,785
Speaker 3:  run Europe before. I've imagined it as all children in the Midwest do.

1877
01:47:18,045 --> 01:47:21,345
Speaker 3:  And it just, I, my budget was higher as I, when I was working out in high

1878
01:47:21,345 --> 01:47:23,985
Speaker 3:  school in Wisconsin. I was like, I think it's gonna take like one or two

1879
01:47:23,985 --> 01:47:24,705
Speaker 3:  trail to run Europe.

1880
01:47:26,515 --> 01:47:29,305
Speaker 3:  Again, not an economist. I didn't have any formal training at the time. I

1881
01:47:29,305 --> 01:47:33,185
Speaker 3:  just think it's more than 14.4. We'll, see, we asked all these companies

1882
01:47:33,185 --> 01:47:36,705
Speaker 3:  to respond to this. I will say that, that the two comments

1883
01:47:37,645 --> 01:47:41,105
Speaker 3:  run right into each other, right? If you're Apple and you're mad at Europe,

1884
01:47:41,105 --> 01:47:43,985
Speaker 3:  you're probably also mad at the United States Department of Justice for filing

1885
01:47:44,045 --> 01:47:47,785
Speaker 3:  an antitrust case against you. And Donald Trump is here

1886
01:47:47,785 --> 01:47:51,425
Speaker 3:  saying something has to be done about Google, which just lost its big

1887
01:47:51,495 --> 01:47:55,345
Speaker 3:  antitrust case at the United States Department of Justice. The main

1888
01:47:55,345 --> 01:47:58,345
Speaker 3:  result of which is that Google's gonna stop paying Apple the money to be

1889
01:47:58,345 --> 01:48:01,355
Speaker 3:  the default search provider on the iPhone. So

1890
01:48:02,715 --> 01:48:05,725
Speaker 3:  it's just kind of all the same problem. And

1891
01:48:06,495 --> 01:48:10,365
Speaker 3:  Trump is Trump and he, I think he likes Tim Cook and is mad at

1892
01:48:10,365 --> 01:48:10,925
Speaker 3:  Google search.

1893
01:48:11,615 --> 01:48:14,585
Speaker 4:  Yeah. Two easy things to be right now if you're, if you're Donald Trump,

1894
01:48:14,585 --> 01:48:15,105
Speaker 4:  you know what I mean?

1895
01:48:17,525 --> 01:48:21,145
Speaker 3:  And really that man is searching for the simplest one. All right,

1896
01:48:21,395 --> 01:48:24,945
Speaker 3:  let's end with, let's end with Anthropic and ai. 'cause I think we should

1897
01:48:24,945 --> 01:48:27,185
Speaker 3:  end with a vision of utopia. What's going on with this one?

1898
01:48:27,695 --> 01:48:31,545
Speaker 4:  Okay, so, so Dario Am who is the, the CEO of Anthropic

1899
01:48:32,835 --> 01:48:36,745
Speaker 4:  wrote, I think it's, it's, it's either 13,000 or 14,000

1900
01:48:36,745 --> 01:48:39,745
Speaker 4:  words. It's so many words. My man wrote like a short book

1901
01:48:40,575 --> 01:48:43,625
Speaker 4:  basically making the case for ai.

1902
01:48:44,485 --> 01:48:47,545
Speaker 4:  And I think it, it's particularly interesting that he's doing this because

1903
01:48:47,745 --> 01:48:51,425
Speaker 4:  a Sam Altman recently wrote his sort of opus about why

1904
01:48:51,565 --> 01:48:55,145
Speaker 4:  AI is gonna make everything wonderful. And Anthropic in a lot of ways has

1905
01:48:55,145 --> 01:48:58,905
Speaker 4:  been kind of a, a tonal counter to open

1906
01:48:59,005 --> 01:49:02,985
Speaker 4:  ai that they've been much quieter about what they're building. They've

1907
01:49:02,985 --> 01:49:06,865
Speaker 4:  been much less utopian, they've been much more concerned with security. They've

1908
01:49:06,865 --> 01:49:10,625
Speaker 4:  talked a much more like realistic game about what they're doing.

1909
01:49:11,565 --> 01:49:15,345
Speaker 4:  But as, as Kylie Robinson on our team pointed out, they

1910
01:49:15,345 --> 01:49:19,265
Speaker 4:  also need to raise astounding amounts of money in order to do

1911
01:49:19,265 --> 01:49:22,225
Speaker 4:  any of the stuff that they want to do. And it's much harder to raise money

1912
01:49:22,365 --> 01:49:25,665
Speaker 4:  on like a careful case for why this stuff might be interesting than it is

1913
01:49:25,665 --> 01:49:29,225
Speaker 4:  to just say out loud, I am building God. Right? Like Kylie has just been

1914
01:49:29,225 --> 01:49:31,585
Speaker 4:  running around the newsroom being like, this is why they're doing this. And

1915
01:49:31,585 --> 01:49:34,345
Speaker 4:  I think she's right. And so what Dario did here basically was,

1916
01:49:35,275 --> 01:49:38,985
Speaker 4:  right, a more reasoned

1917
01:49:39,525 --> 01:49:43,065
Speaker 4:  but still like wildly outrageously optimistic

1918
01:49:43,245 --> 01:49:47,105
Speaker 4:  vision for what AI can be. And I think, and

1919
01:49:47,175 --> 01:49:51,135
Speaker 4:  I think a lot of it is about the stuff that doesn't get talked

1920
01:49:51,135 --> 01:49:53,695
Speaker 4:  about a lot when we talk about ai, which I actually really appreciate. People

1921
01:49:53,695 --> 01:49:57,175
Speaker 4:  should read this. It's, it's this and Steven

1922
01:49:57,285 --> 01:50:00,855
Speaker 4:  Wolfram's thing about how chat GPT works from like two years ago are two

1923
01:50:01,125 --> 01:50:04,455
Speaker 4:  very instructive primers on like what is going on in this space. And I think

1924
01:50:04,455 --> 01:50:06,895
Speaker 4:  everybody should read both of them. They're both incredibly long, but they're

1925
01:50:06,895 --> 01:50:10,815
Speaker 4:  very good. And he just, I'll just read you the five things that he

1926
01:50:10,815 --> 01:50:14,455
Speaker 4:  says are the categories he's most excited about. It's biology and physical

1927
01:50:14,455 --> 01:50:18,015
Speaker 4:  health, neuroscience and mental health, economic development and poverty,

1928
01:50:18,425 --> 01:50:22,415
Speaker 4:  peace and governance work. And meaning first of all, that's everything.

1929
01:50:22,975 --> 01:50:24,415
Speaker 4:  It's all the things. It's

1930
01:50:24,415 --> 01:50:26,975
Speaker 3:  Just, that's, that's Europe and If. you have If,

1931
01:50:27,115 --> 01:50:27,775
Speaker 4:  You Europe pays

1932
01:50:28,175 --> 01:50:29,255
Speaker 3:  14.4. You too can,

1933
01:50:31,235 --> 01:50:34,495
Speaker 4:  But he makes a bunch of interesting cases and I think does a good job of

1934
01:50:34,495 --> 01:50:38,335
Speaker 4:  explaining like, here is what it's gonna take to get to

1935
01:50:38,335 --> 01:50:42,255
Speaker 4:  this. That we need AI that is sufficiently powerful and has

1936
01:50:42,255 --> 01:50:45,775
Speaker 4:  lots of different interfaces. And you can poke holes in all of this because

1937
01:50:46,125 --> 01:50:49,935
Speaker 4:  none of it exists. Most of it is going to be wildly difficult. And

1938
01:50:49,935 --> 01:50:52,975
Speaker 4:  he just says there's a line where he just says in it, it has all the interfaces

1939
01:50:52,975 --> 01:50:56,455
Speaker 4:  available to a human working virtually as if that's just like a, like a feature

1940
01:50:56,475 --> 01:51:00,015
Speaker 4:  you can ship tomorrow. So I. I take this less as

1941
01:51:00,415 --> 01:51:04,135
Speaker 4:  a real roadmap towards anything and more just like an actually really

1942
01:51:04,135 --> 01:51:07,935
Speaker 4:  thoughtful idea about what AI could be in the

1943
01:51:08,375 --> 01:51:12,295
Speaker 4:  absolute best case. And in that way it's a, it's a really good

1944
01:51:12,295 --> 01:51:15,535
Speaker 4:  read. He talks a lot about what it could mean for medicine and what it could

1945
01:51:15,535 --> 01:51:18,975
Speaker 4:  mean for how we interact with each other and with technology. And we've talked

1946
01:51:19,015 --> 01:51:22,495
Speaker 4:  a lot about like the relationships people are building with AI characters.

1947
01:51:22,715 --> 01:51:26,255
Speaker 4:  He mentions that kind of stuff. There's a lot of stuff in here and you get

1948
01:51:26,255 --> 01:51:30,095
Speaker 4:  to the end and you're like, hell yeah, ai, let's go. And then it's like,

1949
01:51:30,095 --> 01:51:33,615
Speaker 4:  oh, there's, there's other things. And also none of this exists or

1950
01:51:34,095 --> 01:51:36,975
Speaker 4:  probably will anytime soon. And that's where we land. And the thing I've

1951
01:51:36,975 --> 01:51:40,575
Speaker 4:  seen most people say about this is like, even if he's right about all of

1952
01:51:40,575 --> 01:51:43,975
Speaker 4:  this, his timelines are off by orders of magnitude and So, I think If, you

1953
01:51:43,975 --> 01:51:46,735
Speaker 4:  go into it thinking with that perspective. I actually think this is a super

1954
01:51:46,755 --> 01:51:47,215
Speaker 4:  fun read.

1955
01:51:47,565 --> 01:51:50,735
Speaker 3:  Yeah, it's funny. 'cause right next to it is the New York Times warning

1956
01:51:50,945 --> 01:51:54,335
Speaker 3:  perplexity to stop using its content, right? And it's like kind of all of

1957
01:51:54,335 --> 01:51:58,175
Speaker 3:  this is built on just like taking everything. Yeah. Like all of the

1958
01:51:58,455 --> 01:51:59,735
Speaker 3:  electricity and all of the content,

1959
01:52:01,335 --> 01:52:05,155
Speaker 3:  all of the money. And it's like you had, I guess you in

1960
01:52:05,155 --> 01:52:06,875
Speaker 3:  return you have to promise digital God.

1961
01:52:07,955 --> 01:52:08,795
Speaker 4:  I mean, and and to

1962
01:52:08,795 --> 01:52:10,515
Speaker 3:  Be clear, but what is worth all of that taking? And it's

1963
01:52:10,515 --> 01:52:14,275
Speaker 4:  Like what this does promise is digital God. He doesn't say it in as

1964
01:52:14,305 --> 01:52:18,235
Speaker 4:  many words. And he's actually, he's very careful to not say a GI,

1965
01:52:18,485 --> 01:52:22,075
Speaker 4:  which is what has become the synonym for digital God. I think he just calls

1966
01:52:22,075 --> 01:52:25,595
Speaker 4:  it powerful ai, which doesn't sound less

1967
01:52:25,715 --> 01:52:29,195
Speaker 4:  alarming, it's just different alarming I guess. But yeah, it is, it,

1968
01:52:29,745 --> 01:52:33,395
Speaker 4:  this is the size of the promise you have to make if you're one of these

1969
01:52:33,635 --> 01:52:37,155
Speaker 4:  companies in order to do everything you need to do to get there. And like

1970
01:52:37,305 --> 01:52:41,115
Speaker 4:  this is as neat and reasoned a summation of

1971
01:52:41,145 --> 01:52:44,675
Speaker 4:  that stance as I've seen yet. Yeah. Like he might be wrong about everything,

1972
01:52:44,775 --> 01:52:48,645
Speaker 4:  but it's, it's like If, you want to get inside the rational brain of

1973
01:52:48,865 --> 01:52:51,685
Speaker 4:  the AI industry right now. This is about as close as I've seen.

1974
01:52:52,835 --> 01:52:54,135
Speaker 3:  And and they have to take everything,

1975
01:52:54,585 --> 01:52:57,495
Speaker 4:  Right? It's like it takes 14,000 words to explain.

1976
01:52:58,845 --> 01:53:02,095
Speaker 3:  It's just like, and one lawsuit from Sarah Silverman could bring this all

1977
01:53:02,095 --> 01:53:02,775
Speaker 3:  to a grinding.

1978
01:53:03,015 --> 01:53:06,895
Speaker 4:  A hundred percent. Yeah. You put this next to, was

1979
01:53:06,895 --> 01:53:10,695
Speaker 4:  it Mark Andreessen who was like, you, you can't force us to pay for this

1980
01:53:10,695 --> 01:53:13,815
Speaker 4:  because then we won't be able to do it. Yeah. Like take those two statements

1981
01:53:13,815 --> 01:53:16,255
Speaker 4:  next to each other and it becomes very hard to know where any of this is

1982
01:53:16,255 --> 01:53:17,015
Speaker 4:  gonna go. Yeah.

1983
01:53:17,195 --> 01:53:20,015
Speaker 3:  And that, by the way, was it Mark Andreessen said that in a filing to the

1984
01:53:20,015 --> 01:53:20,655
Speaker 3:  United States

1985
01:54:23,655 --> 01:54:27,335
Speaker 3:  making this go and it's very good. So go click on all the links, we'll put

1986
01:54:27,335 --> 01:54:31,135
Speaker 3:  them there. That's, that's happening. And then thanks to Panas for coming

1987
01:54:31,135 --> 01:54:34,895
Speaker 3:  on the show. We're gonna have them back when it's Alexa time. Yeah,

1988
01:54:35,495 --> 01:54:39,135
Speaker 3:  I, I think that, I think, I think we can say that. Alright, that's it. That's

1989
01:54:39,255 --> 01:54:39,895
Speaker 3:  Vergecast Rock and roll.

1990
01:54:44,155 --> 01:54:47,255
Speaker 1:  And that's it for The Vergecast this week. Hey, we'd love to hear from you.

1991
01:54:47,365 --> 01:54:51,135
Speaker 1:  Give us a call at eight six six VERGE one. One The Vergecast is a

1992
01:54:51,135 --> 01:54:54,775
Speaker 1:  production of The Verge and Vox Media Podcast Network. Our show is produced

1993
01:54:54,975 --> 01:54:58,935
Speaker 1:  by Liam James Wil Pour and Eric Gomez. And that's it. We'll see

1994
01:54:58,935 --> 01:54:59,375
Speaker 1:  you next week.

