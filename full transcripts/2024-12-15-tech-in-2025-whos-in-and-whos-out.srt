1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 797b8eca-422c-4d4d-be69-d264e05f9606
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/2986318099900666798/7434659834380060549/s93290-US-3330s-1734260811.mp3
Description: For the second episode in our two-part 2025 preview, Nilay and David are once again joined by Wall Street Journal columnist (and friend of The Verge) Joanna Stern to talk about what will, and won't, happen in tech next year. This time, David joins us after a quick jaunt to the end of next year, and relays a bunch of things that happened in tech in 2025. But some of them are lies. Joanna and Nilay have to decide which things really will happen next year, and which won't. As always, the hosts get points for good guesses and negative points for bad ones. And once we're all in late 2025, we'll declare a winner.
Email us at vergecast@theverge.com or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Enabled (10 ads detected)

2
00:00:02,035 --> 00:00:05,765
Speaker 1:  Welcome To The Vergecast, the flagship podcast of Low Stakes Time Travel.

3
00:00:06,025 --> 00:00:09,445
Speaker 1:  I'm your friend David Pierce, and I am sitting here doing my New Year's resolutions.

4
00:00:09,645 --> 00:00:12,405
Speaker 1:  I discovered a long time ago that if I do my New Year's resolutions, like

5
00:00:12,865 --> 00:00:16,165
Speaker 1:  on December 29th, or more likely like January 17th,

6
00:00:16,875 --> 00:00:20,765
Speaker 1:  they don't actually get done, or I'm just tired. And so my

7
00:00:20,965 --> 00:00:24,925
Speaker 1:  ambitions are like, go outside once this year. And so

8
00:00:24,985 --> 00:00:28,805
Speaker 1:  my goal now is to find a day, usually in December where I'm

9
00:00:29,035 --> 00:00:32,885
Speaker 1:  more present, more active, feeling better, feeling more ambitious, and that's

10
00:00:32,885 --> 00:00:35,925
Speaker 1:  when I do some real goal setting. And I try to think of it like goal setting,

11
00:00:36,065 --> 00:00:40,005
Speaker 1:  not resolutions. I've also learned that I should make them

12
00:00:40,005 --> 00:00:43,245
Speaker 1:  very small and very actionable. So like a couple of years ago, my goal was

13
00:00:43,245 --> 00:00:46,485
Speaker 1:  to read one page of a book every single day just as a way to

14
00:00:46,995 --> 00:00:50,965
Speaker 1:  kickstart some of that energy again. And it was such a small thing

15
00:00:50,965 --> 00:00:53,685
Speaker 1:  that I would feel guilty not doing it. So I actually did it every day that

16
00:00:53,685 --> 00:00:57,605
Speaker 1:  year because it's only one page. But the idea is when you read one page,

17
00:00:57,605 --> 00:01:00,965
Speaker 1:  you read more than one page, and then all of a sudden you're reading a lot

18
00:01:00,965 --> 00:01:04,925
Speaker 1:  more in a way that feels less sort of over your head than

19
00:01:04,925 --> 00:01:08,405
Speaker 1:  the idea of like, I'm going to read 50 books this year, and I read more than

20
00:01:08,405 --> 00:01:12,005
Speaker 1:  50 books that year. Perfect strategy. Absolutely no notes. Anyway,

21
00:01:12,325 --> 00:01:15,645
Speaker 1:  I will share my tech resolutions at some point. By the way, I've done that

22
00:01:15,645 --> 00:01:19,405
Speaker 1:  before and people have said they like it, just having some ideas about how

23
00:01:19,445 --> 00:01:23,045
Speaker 1:  I want to use tech better next year. So I'll share those, but

24
00:01:23,465 --> 00:01:26,605
Speaker 1:  that's for another episode. Still gotta figure some of those out. Use my

25
00:01:26,605 --> 00:01:30,485
Speaker 1:  phone less. Didn't work. So we're gonna try some new things Today. We're

26
00:01:30,485 --> 00:01:34,165
Speaker 1:  doing the second episode in our series, previewing 2025.

27
00:01:34,275 --> 00:01:38,165
Speaker 1:  Like we said last week, 2025 is going to be a big year. There's

28
00:01:38,165 --> 00:01:41,405
Speaker 1:  regulation stuff happening, there's a new administration coming in in the

29
00:01:41,465 --> 00:01:45,125
Speaker 1:  us. There's questions about the Fedi verse. There's questions about ai. Is

30
00:01:45,125 --> 00:01:48,765
Speaker 1:  all of this going to amount to like the next big thing in technology

31
00:01:49,265 --> 00:01:52,485
Speaker 1:  or not? I think 2025 is going to be the year

32
00:01:53,075 --> 00:01:56,125
Speaker 1:  that either things change or they don't. And we're gonna find out in some

33
00:01:56,125 --> 00:01:59,965
Speaker 1:  really interesting ways with pretty high stakes. Last week

34
00:02:00,325 --> 00:02:04,165
Speaker 1:  I had Neela Patel and Joanna Stern on, and they just ran through some predictions.

35
00:02:04,165 --> 00:02:07,565
Speaker 1:  We had mild, medium, and spicy predictions. We talked about them all. We

36
00:02:07,565 --> 00:02:11,285
Speaker 1:  agreed or disagreed. It was a lot of fun. I think I've figured

37
00:02:11,345 --> 00:02:14,765
Speaker 1:  out the points system. We'll lay that out at some point. We got 12 months

38
00:02:14,765 --> 00:02:18,605
Speaker 1:  to figure it out. We'll come back to it for this episode. We're gonna do

39
00:02:18,605 --> 00:02:22,165
Speaker 1:  something slightly different. So I asked all of you to give me basically

40
00:02:22,225 --> 00:02:25,965
Speaker 1:  things that either will or won't happen in 2025. We will

41
00:02:25,995 --> 00:02:29,965
Speaker 1:  land on Mars, don't know yet. By the end of 2025, know the answer.

42
00:02:30,555 --> 00:02:34,485
Speaker 1:  Will there be a new CEO of Google? Don't know. We'll

43
00:02:34,485 --> 00:02:37,525
Speaker 1:  know by the end of 25. So these things that are kind of either going to happen

44
00:02:37,545 --> 00:02:41,045
Speaker 1:  or not going to happen, I made a big list of them and I'm gonna throw them

45
00:02:41,145 --> 00:02:44,805
Speaker 1:  at Neli and Joanna and we're gonna see what we think about all of them.

46
00:02:44,945 --> 00:02:48,685
Speaker 1:  And again, this goes on the same point scoring system. So if you're right

47
00:02:49,145 --> 00:02:52,765
Speaker 1:  by the end of 2025, you get a point wrong.

48
00:02:53,145 --> 00:02:56,925
Speaker 1:  No points. Whoever gets the most points gets a prize. We as a group

49
00:02:56,945 --> 00:02:59,965
Speaker 1:  are going to decide the prize together. So we'll figure that out later on

50
00:02:59,965 --> 00:03:03,765
Speaker 1:  in the year. But the idea is just if I'm a time traveler from the

51
00:03:04,105 --> 00:03:07,565
Speaker 1:  end of 2025 coming back and I have some things to say to you, some of them

52
00:03:07,565 --> 00:03:10,085
Speaker 1:  are true and some of 'em are false, what are we gonna do?

53
00:03:11,425 --> 00:03:14,965
Speaker 1:  It was very fun. We had a very good time and I think you will enjoy this.

54
00:03:14,965 --> 00:03:18,765
Speaker 1:  We agreed more than I wanted to, but we'll make it work. Anyway,

55
00:03:18,865 --> 00:03:22,645
Speaker 1:  All of that is coming up in just a second. But first I'm gonna go read one

56
00:03:22,645 --> 00:03:26,445
Speaker 1:  page of a book because I am now like three years into this resolution and

57
00:03:26,445 --> 00:03:29,685
Speaker 1:  it continues to work really well, and I'm not losing it today. This is The

58
00:03:29,765 --> 00:03:30,805
Speaker 1:  Vergecast. We'll be right back.

59
00:04:07,595 --> 00:04:10,125
Speaker 1:  Welcome back, Neil Patellas here again.

60
00:04:10,295 --> 00:04:10,645
Speaker 4:  Again.

61
00:04:12,035 --> 00:04:12,325
Speaker 1:  Once

62
00:04:12,375 --> 00:04:14,285
Speaker 4:  Again, David has dragged me into the studio.

63
00:04:14,385 --> 00:04:16,725
Speaker 1:  If you're all wondering why we're wearing the same clothes and don't look

64
00:04:16,725 --> 00:04:20,085
Speaker 1:  like we've moved, we did. It's been a full week since we recorded this. Don't

65
00:04:20,085 --> 00:04:21,885
Speaker 1:  worry about it. Joanna Sterns also here. Hi

66
00:04:21,885 --> 00:04:23,285
Speaker 3:  Joanna. I looks like I wear this every day.

67
00:04:23,315 --> 00:04:25,445
Speaker 1:  Yeah, it's this is, this is my podcast. I sweat.

68
00:04:25,565 --> 00:04:28,125
Speaker 3:  I moved to just basically wearing like I have the same shirt. You're Steve

69
00:04:28,125 --> 00:04:29,845
Speaker 3:  Jobs now. I am. I really am. I have done that.

70
00:04:30,005 --> 00:04:31,085
Speaker 4:  A closet full of the miyaki.

71
00:04:31,495 --> 00:04:34,085
Speaker 1:  Truly, the older I get, the more I understand that person. But

72
00:04:34,085 --> 00:04:35,285
Speaker 3:  Legitimately, I have three of these shirts.

73
00:04:35,355 --> 00:04:38,165
Speaker 4:  Yeah. And in one day you're gonna break out the Obama tan suit,

74
00:04:39,275 --> 00:04:40,645
Speaker 4:  full Fox news cycle.

75
00:04:42,675 --> 00:04:46,605
Speaker 1:  Okay, so last week we did our predictions for

76
00:04:46,605 --> 00:04:50,285
Speaker 1:  2025. We all had homework. We all talked it through. We still haven't figured

77
00:04:50,305 --> 00:04:52,845
Speaker 1:  out the point system, but I have a whole year to figure out the point system.

78
00:04:53,305 --> 00:04:56,845
Speaker 1:  I'm probably gonna win. But we'll see. What we're gonna do today is I have

79
00:04:56,845 --> 00:05:00,405
Speaker 1:  written down a, a long list of things that either

80
00:05:00,755 --> 00:05:04,725
Speaker 1:  will or will not happen in 2025. And the way we're gonna set this up is

81
00:05:04,805 --> 00:05:08,645
Speaker 1:  I am a time traveler from the end of 2025, and

82
00:05:08,805 --> 00:05:12,245
Speaker 1:  I'm coming back and I'm telling you a bunch of things that happened. And

83
00:05:12,245 --> 00:05:15,365
Speaker 1:  you have to decide which ones are true and which ones are lies. Does that

84
00:05:15,365 --> 00:05:15,645
Speaker 1:  make sense?

85
00:05:16,585 --> 00:05:16,805
Speaker 4:  All

86
00:05:16,805 --> 00:05:18,165
Speaker 1:  Lies fabulous. Why

87
00:05:18,165 --> 00:05:19,485
Speaker 3:  Are all these games so complicated?

88
00:05:19,675 --> 00:05:22,525
Speaker 1:  It's not complicated. I'm gonna, I'm gonna say a thing that happened at the

89
00:05:22,525 --> 00:05:26,005
Speaker 1:  end of 20. Okay, by the end of 2025. And you have to decide. Did it or did

90
00:05:26,005 --> 00:05:28,115
Speaker 1:  it not happen? Good.

91
00:05:28,655 --> 00:05:30,075
Speaker 3:  You should have done a costume change.

92
00:05:30,595 --> 00:05:31,555
Speaker 1:  I do. I should have,

93
00:05:31,795 --> 00:05:33,995
Speaker 3:  Honestly. 'cause then you could have been like, I am dressed, I'm coming

94
00:05:33,995 --> 00:05:37,915
Speaker 3:  back from, I am David from the end of 2025. Ooh.

95
00:05:38,425 --> 00:05:41,955
Speaker 1:  Like, like jeans get even bigger in 2025, right? So I'm gonna come back.

96
00:05:42,215 --> 00:05:42,435
Speaker 1:  You

97
00:05:42,435 --> 00:05:45,425
Speaker 3:  Have a mustache. Anyway, a

98
00:05:45,425 --> 00:05:46,585
Speaker 1:  Beret. Beret is, this

99
00:05:46,585 --> 00:05:47,865
Speaker 4:  Is what AI is for. Berets

100
00:05:47,865 --> 00:05:48,385
Speaker 1:  Are huge in

101
00:05:48,385 --> 00:05:52,145
Speaker 4:  Tony's when this actually publishes will, we replaced David with ai mustache,

102
00:05:53,065 --> 00:05:55,105
Speaker 4:  seventies. David will be here. Adobe. And the full flares,

103
00:05:56,645 --> 00:06:00,165
Speaker 1:  The only facial hair I can grow is like a pretty like evil goatee. So we

104
00:06:00,165 --> 00:06:02,285
Speaker 1:  could do that. Evil David could be,

105
00:06:02,645 --> 00:06:05,005
Speaker 4:  I don't think the end of 2020 have a choice but to grow an evil

106
00:06:05,145 --> 00:06:08,165
Speaker 1:  Goatee, my friend. Okay. I've

107
00:06:08,475 --> 00:06:09,245
Speaker 4:  Ordered these

108
00:06:09,245 --> 00:06:13,165
Speaker 1:  Loosely into categories, but the categories don't really

109
00:06:13,165 --> 00:06:15,405
Speaker 1:  matter. So we're just gonna blow through as many of these as we can until

110
00:06:15,645 --> 00:06:19,405
Speaker 1:  we have to get outta here. And again, the the, the thing we all have to decide

111
00:06:19,405 --> 00:06:23,365
Speaker 1:  individually is is this true by the end of 2025 or is it not?

112
00:06:23,975 --> 00:06:27,885
Speaker 1:  Thing number one, not only is Tim Cook still the CEO of Apple, all four

113
00:06:27,945 --> 00:06:29,245
Speaker 1:  big tech CEOs are still the same.

114
00:06:30,375 --> 00:06:33,575
Speaker 4:  Oh, absolutely true. Unless Google breaks itself up.

115
00:06:35,395 --> 00:06:38,845
Speaker 1:  Okay. But then would student dar Shai still be the CEO O of Google in that

116
00:06:38,965 --> 00:06:41,565
Speaker 3:  Instance? I, that's the one where I have a question mark.

117
00:06:42,825 --> 00:06:46,345
Speaker 4:  I think right now the only thing that the big tech

118
00:06:46,625 --> 00:06:50,305
Speaker 4:  companies can do is put familiar faces in front of Donald Trump. And

119
00:06:50,545 --> 00:06:54,345
Speaker 4:  anything that disturbs that is a huge risk. Donald Trump saying,

120
00:06:54,505 --> 00:06:57,505
Speaker 4:  Sundar Shai called me to say I was the most important thing on Google is

121
00:06:57,565 --> 00:07:01,185
Speaker 4:  the thing that protects Google from regulatory risk. You change out that

122
00:07:01,185 --> 00:07:05,105
Speaker 4:  face that name, that relationship suddenly Donald's like, I

123
00:07:05,105 --> 00:07:07,145
Speaker 4:  don't like this new guy. And all goes to hell.

124
00:07:07,655 --> 00:07:11,065
Speaker 3:  Yeah, I mean, definitely. I there's yeah, true.

125
00:07:11,485 --> 00:07:14,825
Speaker 1:  But you don't think there's, it's possible that one of these CEOs will just

126
00:07:14,825 --> 00:07:18,785
Speaker 1:  decide it's not worth it anymore. That like faced with the prospect of what's

127
00:07:18,785 --> 00:07:22,705
Speaker 1:  coming in so many different directions. It's, they're not just gonna be like,

128
00:07:22,705 --> 00:07:22,865
Speaker 1:  eh,

129
00:07:23,145 --> 00:07:26,585
Speaker 3:  I think they want to, but they're, they're boards to what Eli's saying they

130
00:07:26,585 --> 00:07:26,945
Speaker 3:  can, he

131
00:07:26,945 --> 00:07:30,905
Speaker 4:  Says, are all sharks. They think they can win. That's fair. This, this

132
00:07:30,905 --> 00:07:34,665
Speaker 4:  is not, this is no longer a game about strategy. You don't, Tim,

133
00:07:34,665 --> 00:07:36,905
Speaker 4:  it's a game about personality and deal making and

134
00:07:36,975 --> 00:07:40,505
Speaker 3:  Yeah, I think Tim Cook's getting ready. He's like excited about it.

135
00:07:42,185 --> 00:07:43,585
Speaker 3:  I think Tim Cook's excited to retire.

136
00:07:44,085 --> 00:07:46,585
Speaker 4:  Oh, yeah. Yeah. He's been laying the groundwork to retire for a long time.

137
00:07:46,735 --> 00:07:50,025
Speaker 4:  He's excited. This is why John Turner, his name keeps getting floated. Right?

138
00:07:50,285 --> 00:07:53,515
Speaker 4:  But he cannot, he's sad. Apple is a small country.

139
00:07:54,135 --> 00:07:57,875
Speaker 3:  No, it's sa he's, Tim Cook is sad. I don't know this. I think

140
00:07:57,935 --> 00:07:58,995
Speaker 3:  Tim Cook is sad that

141
00:07:59,475 --> 00:08:02,395
Speaker 4:  I, I would say we published this story about

142
00:08:03,195 --> 00:08:06,235
Speaker 4:  Donald Trump saying Tim Cook had called him about European regulations and

143
00:08:06,235 --> 00:08:09,075
Speaker 4:  the number of comments and responses we got that was like, he would never,

144
00:08:09,495 --> 00:08:12,595
Speaker 4:  oh yeah, he did. This is just salacious slander. I'm like, no, he definitely

145
00:08:12,595 --> 00:08:15,795
Speaker 4:  did. Yeah, he did. Like this man opened a fake factory for Doc Donald Trump.

146
00:08:17,065 --> 00:08:17,965
Speaker 1:  He is good at this game,

147
00:08:19,145 --> 00:08:23,045
Speaker 4:  But If you don't know what that he reopened the Mac Pro factory where they

148
00:08:23,045 --> 00:08:26,845
Speaker 4:  were already making the Mack Pro. And Trump got to go there and pretend they'd

149
00:08:26,845 --> 00:08:27,365
Speaker 4:  open a factory.

150
00:08:27,705 --> 00:08:31,245
Speaker 1:  As long as you cut a ribbon, it's new. You know what I mean? It counts. All

151
00:08:31,245 --> 00:08:32,325
Speaker 1:  right. So we're all, we're all saying yes,

152
00:08:32,625 --> 00:08:36,565
Speaker 4:  By the way, corollary. Do we think Donald Trump knows who Andy Jassy

153
00:08:36,565 --> 00:08:36,685
Speaker 4:  is?

154
00:08:38,265 --> 00:08:42,135
Speaker 4:  No. The CEO of Amazon. Yeah. I think he knows who Jeff Bezos is.

155
00:08:42,135 --> 00:08:42,295
Speaker 4:  Yeah.

156
00:08:42,295 --> 00:08:43,375
Speaker 3:  Yeah. Right. No, he, and

157
00:08:43,375 --> 00:08:43,815
Speaker 1:  I think the fact,

158
00:08:43,885 --> 00:08:45,255
Speaker 4:  This is what I, this is the point. I think, think

159
00:08:45,255 --> 00:08:48,695
Speaker 1:  Andy Chassy's favorite thing in the whole world is probably that everybody

160
00:08:48,695 --> 00:08:52,615
Speaker 1:  knows who Jeff Bezos is. That like Ev people are, people are

161
00:08:52,615 --> 00:08:56,485
Speaker 1:  very mad at Jeff Bezos about things that Jeff Bezos

162
00:08:56,485 --> 00:08:59,485
Speaker 1:  is no longer in control of. And I think if you're Andy Jassy, that's a pretty

163
00:08:59,485 --> 00:09:00,125
Speaker 1:  nice place to be.

164
00:09:00,235 --> 00:09:04,205
Speaker 4:  Yeah, I'm just saying, I, the, we are entering a period

165
00:09:04,205 --> 00:09:08,045
Speaker 4:  where people's personal relationships with the president will determine how

166
00:09:08,405 --> 00:09:11,085
Speaker 4:  American tech regulation goes. And none of these guys can move.

167
00:09:12,485 --> 00:09:13,645
Speaker 4:  Introducing a new face is,

168
00:09:14,465 --> 00:09:17,365
Speaker 1:  And also Mark Zuckerberg is un killable. So he, he doesn't Oh,

169
00:09:17,625 --> 00:09:19,285
Speaker 4:  He is by far the most stable. No,

170
00:09:19,285 --> 00:09:19,765
Speaker 3:  He's, he's

171
00:09:19,765 --> 00:09:21,645
Speaker 4:  In right. Founder, CEO. He's staying forever.

172
00:09:21,755 --> 00:09:25,085
Speaker 1:  Okay. All right. Moving on. We're all saying Yes. End of

173
00:09:25,085 --> 00:09:27,885
Speaker 1:  2025. Nvidia is the most valuable company in the world.

174
00:09:29,645 --> 00:09:29,865
Speaker 4:  No.

175
00:09:30,955 --> 00:09:31,245
Speaker 1:  Okay.

176
00:09:32,415 --> 00:09:33,345
Speaker 3:  What is more valuable?

177
00:09:34,295 --> 00:09:36,965
Speaker 4:  Right now it's, it's Apple on Microsoft every day. Go back and forth, right?

178
00:09:36,965 --> 00:09:39,205
Speaker 1:  Yeah. But NVIDIA's right there. Yeah.

179
00:09:39,565 --> 00:09:42,685
Speaker 4:  I just think that my prediction on the last episode was the AI bubble's gonna

180
00:09:42,685 --> 00:09:42,885
Speaker 4:  pop.

181
00:09:43,015 --> 00:09:43,365
Speaker 3:  Right?

182
00:09:44,255 --> 00:09:47,715
Speaker 4:  And so if that necessarily means demand for chips will drop,

183
00:09:48,065 --> 00:09:51,725
Speaker 1:  Okay. I'm saying yes, say yes because

184
00:09:52,065 --> 00:09:55,925
Speaker 1:  Nvidia seems to be so far ahead of this game right now. And

185
00:09:56,075 --> 00:09:58,805
Speaker 1:  even if what you're saying is true, there's gonna be some

186
00:10:00,305 --> 00:10:03,405
Speaker 1:  lag to that. Like I think if the AI bubble does burst, I don't think it's

187
00:10:03,405 --> 00:10:07,125
Speaker 1:  gonna happen in 2025. And I think we're gonna get one more

188
00:10:07,155 --> 00:10:10,965
Speaker 1:  year of wild frothiness and then something is gonna

189
00:10:10,965 --> 00:10:11,725
Speaker 1:  happen and it's

190
00:10:11,725 --> 00:10:13,805
Speaker 3:  All gonna fall apart. Yeah. People are gonna keep buying these Blackwell

191
00:10:14,175 --> 00:10:16,885
Speaker 3:  chips. That's gonna just keep happening. Yeah. Maybe it,

192
00:10:18,035 --> 00:10:20,215
Speaker 4:  But all of that forward investment has to turn into revenue,

193
00:10:21,205 --> 00:10:22,105
Speaker 3:  Not for Nvidia.

194
00:10:22,735 --> 00:10:23,825
Speaker 1:  Yeah. And NVIDIA's good.

195
00:10:24,105 --> 00:10:25,785
Speaker 3:  NVIDIA's, they're selling 'em. Yeah.

196
00:10:25,795 --> 00:10:29,145
Speaker 4:  Right. But then at some point when the companys stop booking, sure.

197
00:10:29,525 --> 00:10:31,145
Speaker 3:  At some point, but maybe it doesn't happen in 2026.

198
00:10:31,635 --> 00:10:34,585
Speaker 4:  Lemme say again. At some point when the companies don't have business models

199
00:10:34,925 --> 00:10:38,705
Speaker 4:  to run on their Nvidia chips, Nvidia will stop selling as many

200
00:10:38,705 --> 00:10:40,785
Speaker 4:  chips. But that might not happen until the end. And it's coming faster.

201
00:10:41,045 --> 00:10:42,465
Speaker 3:  You think it's gonna happen in 2025?

202
00:10:43,625 --> 00:10:44,835
Speaker 4:  Yeah. But these companies

203
00:10:45,135 --> 00:10:48,275
Speaker 3:  Are promising their AI agents and they're all, they're all on in, they're

204
00:10:48,275 --> 00:10:48,875
Speaker 3:  all in in next year.

205
00:10:49,885 --> 00:10:52,035
Speaker 4:  Right. And then they have to ship them.

206
00:10:53,205 --> 00:10:53,695
Speaker 3:  Sure. And then,

207
00:10:53,855 --> 00:10:56,655
Speaker 4:  I mean, there are companies right now like cloud computing companies that

208
00:10:56,655 --> 00:11:00,095
Speaker 4:  are taking out loans to buy Nvidia chips. And the collateral they're putting

209
00:11:00,095 --> 00:11:02,015
Speaker 4:  up for their loans is the Nvidia chips.

210
00:11:04,295 --> 00:11:04,495
Speaker 3:  I just,

211
00:11:04,555 --> 00:11:05,815
Speaker 4:  That's bananas. That is the

212
00:11:05,975 --> 00:11:07,575
Speaker 1:  Bubbliest bubble you could possibly describe.

213
00:11:08,315 --> 00:11:09,495
Speaker 3:  We might have time.

214
00:11:10,425 --> 00:11:13,805
Speaker 4:  Oh, serious. Okay. I, but yeah, but I think if the straight

215
00:11:13,805 --> 00:11:14,765
Speaker 3:  Prediction like it's gonna keep going

216
00:11:14,765 --> 00:11:17,045
Speaker 4:  Up, is the stock, right? That's how I'm measuring it's

217
00:11:17,045 --> 00:11:18,085
Speaker 3:  Market cap happen. Yes.

218
00:11:19,755 --> 00:11:21,175
Speaker 4:  I'm out. Okay. I don't think so.

219
00:11:21,435 --> 00:11:22,935
Speaker 1:  Are you in I'll be in, I'm too

220
00:11:25,205 --> 00:11:27,665
Speaker 1:  End of 2025, somebody has acquired Snap.

221
00:11:28,725 --> 00:11:29,665
Speaker 3:  Mm. That's a

222
00:11:29,665 --> 00:11:29,985
Speaker 4:  Good one.

223
00:11:32,675 --> 00:11:32,895
Speaker 3:  Who?

224
00:11:34,915 --> 00:11:37,595
Speaker 1:  Somebody, I can't tell you. I forgot. I have a lot to remember. Coming back

225
00:11:37,595 --> 00:11:39,155
Speaker 1:  from December, 2025.

226
00:11:39,815 --> 00:11:42,485
Speaker 3:  Is it Apple? No, it's not Apple.

227
00:11:43,715 --> 00:11:44,515
Speaker 1:  I don't think it would be Apple.

228
00:11:44,515 --> 00:11:46,635
Speaker 3:  Apple doesn't want, no, apple doesn't want it, but they, I think it's,

229
00:11:47,205 --> 00:11:48,955
Speaker 1:  Maybe it's Walmart again. Walmart.

230
00:11:49,385 --> 00:11:49,875
Speaker 3:  Walmart.

231
00:11:50,225 --> 00:11:53,325
Speaker 4:  Just TikTok and Snap. Yeah. No, no.

232
00:11:54,115 --> 00:11:55,365
Speaker 4:  Just 'cause it's a public company.

233
00:11:56,465 --> 00:11:57,555
Speaker 1:  It's just hard to do. It.

234
00:11:57,555 --> 00:12:01,475
Speaker 4:  Just, it is gotta fail on its own. Activist investor shows up and tries

235
00:12:01,475 --> 00:12:05,355
Speaker 4:  to push out Evan Spiegel. Mm sure. Okay. A straightforward

236
00:12:06,255 --> 00:12:09,595
Speaker 4:  GE is here by Snapchat. I don't know. I don't think so.

237
00:12:09,745 --> 00:12:13,115
Speaker 1:  Yeah, I think Eileen the same way. Just because I don't know where it goes.

238
00:12:13,275 --> 00:12:14,035
Speaker 3:  I don't know where it goes.

239
00:12:14,225 --> 00:12:17,835
Speaker 1:  Yeah. Because I think Snap's problem Yep. Continues to be

240
00:12:18,185 --> 00:12:21,635
Speaker 1:  that it is a phenomenally successful product that is essentially impossible

241
00:12:21,635 --> 00:12:25,195
Speaker 1:  to turn into a business. And I don't think anybody else has ways to solve

242
00:12:25,195 --> 00:12:25,395
Speaker 1:  that.

243
00:12:25,855 --> 00:12:27,555
Speaker 3:  And I don't know who would want it. Like

244
00:12:27,555 --> 00:12:31,275
Speaker 1:  Maybe it's one of the big adver, like maybe Amazon buys it just because it's

245
00:12:31,275 --> 00:12:34,955
Speaker 1:  like we're better at selling ads. We, we can do that, but I don't, I don't

246
00:12:34,955 --> 00:12:37,675
Speaker 1:  totally see it, so, all right. I'm out on that one. We're all out on that

247
00:12:37,675 --> 00:12:40,635
Speaker 1:  one. Yep. Okay. Number four.

248
00:12:41,375 --> 00:12:44,875
Speaker 1:  OpenAI is a officially a for-profit company and it's making money.

249
00:12:46,275 --> 00:12:47,505
Speaker 3:  Those should be two separate things.

250
00:12:47,725 --> 00:12:49,505
Speaker 4:  Making money or making a profit.

251
00:12:51,255 --> 00:12:52,185
Speaker 3:  Well, yeah, that's

252
00:12:52,445 --> 00:12:55,265
Speaker 1:  All right. You're right. Let's, let's split them. OpenAI is officially a

253
00:12:55,265 --> 00:12:55,985
Speaker 1:  for-profit company.

254
00:12:56,705 --> 00:12:57,345
Speaker 3:  I would say yes.

255
00:13:00,665 --> 00:13:02,325
Speaker 3:  Making a profit, I would say, no,

256
00:13:02,515 --> 00:13:03,605
Speaker 1:  This one's hard for Neli.

257
00:13:04,585 --> 00:13:08,025
Speaker 4:  I think that, I think that's a harder, longer fight than

258
00:13:08,795 --> 00:13:10,525
Speaker 4:  anybody thinks. But

259
00:13:12,825 --> 00:13:14,145
Speaker 4:  can they pull it off in a year?

260
00:13:15,745 --> 00:13:19,385
Speaker 1:  A year is both a long time and not a long time. I mean, in like

261
00:13:19,695 --> 00:13:23,385
Speaker 1:  this, this lawsuit with Elon Musk is gonna keep getting messier.

262
00:13:23,525 --> 00:13:26,905
Speaker 1:  He just, he's going to paperwork everybody into oblivion.

263
00:13:27,365 --> 00:13:29,065
Speaker 1:  It appears for however long it takes.

264
00:13:30,585 --> 00:13:34,465
Speaker 1:  I think OpenAI gets it done just because there is so much money

265
00:13:34,525 --> 00:13:38,115
Speaker 1:  at stake that they're just gonna have to figure out how to do it.

266
00:13:38,335 --> 00:13:42,035
Speaker 1:  And again, If you believe that the AI bubble is going to burst, it is in

267
00:13:42,275 --> 00:13:45,115
Speaker 1:  everyone's best interest to get that done as quickly as humanly possible.

268
00:13:45,265 --> 00:13:47,355
Speaker 1:  Because then a bunch of people are gonna get liquid

269
00:13:49,315 --> 00:13:53,215
Speaker 1:  and take that money out. And that's how they win. I think everyone has an

270
00:13:53,215 --> 00:13:53,535
Speaker 1:  incentive

271
00:13:53,755 --> 00:13:56,575
Speaker 4:  To do this really fast. So I'm with you that they will get it done. I'm out

272
00:13:56,575 --> 00:13:58,095
Speaker 4:  that they will turn $1 of profit.

273
00:13:58,325 --> 00:14:01,615
Speaker 1:  Okay. All right. So we're, we're all in on, OpenAI is officially a for-profit

274
00:14:01,615 --> 00:14:05,335
Speaker 1:  company. Yeah. OpenAI is a profitable company. No way. No. Yeah. Easy. No,

275
00:14:05,685 --> 00:14:06,455
Speaker 1:  it's like, okay.

276
00:14:08,215 --> 00:14:11,495
Speaker 1:  I think I would honestly have a harder time with the, like,

277
00:14:12,085 --> 00:14:15,935
Speaker 1:  open AI is on an obvious path to being a profitable company

278
00:14:16,045 --> 00:14:19,975
Speaker 1:  than this one. Right? Right. Can is this company going to be

279
00:14:19,975 --> 00:14:23,215
Speaker 1:  around for a while? Probably. Are they ever gonna make a dime?

280
00:14:23,975 --> 00:14:26,855
Speaker 1:  I have absolutely no idea. Alright, last one.

281
00:14:27,805 --> 00:14:29,675
Speaker 4:  What? Oh, sorry.

282
00:14:30,775 --> 00:14:33,035
Speaker 1:  All right, last one for this section then we're gonna take a quick break.

283
00:14:33,255 --> 00:14:37,225
Speaker 1:  The government is breaking up one of the big tech companies. Lot of possible

284
00:14:37,225 --> 00:14:39,905
Speaker 1:  candidates on this one. Google seems like probably the most likely Yeah.

285
00:14:40,005 --> 00:14:40,985
Speaker 1:  In our current timeline.

286
00:14:41,175 --> 00:14:45,045
Speaker 3:  Okay. Let's talk about the verb there. Breaking up has

287
00:14:45,045 --> 00:14:45,605
Speaker 3:  broken up.

288
00:14:46,505 --> 00:14:50,045
Speaker 1:  Ha. I would say I would allow anything from has broken up to,

289
00:14:50,385 --> 00:14:54,365
Speaker 1:  has officially decided and won required court cases in order to break

290
00:14:54,365 --> 00:14:58,285
Speaker 1:  up. It has to be, it has to be done and

291
00:14:58,565 --> 00:15:01,125
Speaker 1:  official that it is happening, but it doesn't have to have happened yet.

292
00:15:02,365 --> 00:15:04,785
Speaker 4:  Oh, I think Google and yes, Google is in for it.

293
00:15:05,825 --> 00:15:06,755
Speaker 3:  Yeah, I agree. What do

294
00:15:06,755 --> 00:15:07,795
Speaker 1:  You think it looks like the

295
00:15:07,795 --> 00:15:11,155
Speaker 4:  One with Chrome and search,

296
00:15:12,435 --> 00:15:16,245
Speaker 4:  it's kind of on the exact same timeline as the Microsoft

297
00:15:16,245 --> 00:15:19,645
Speaker 4:  case where like the Clinton administration won that suit and then the Bush

298
00:15:19,645 --> 00:15:23,365
Speaker 4:  administration like settled that suit. So like you can see how

299
00:15:24,055 --> 00:15:26,685
Speaker 4:  maybe you're just gonna get a bunch of weird compliance stuff happening.

300
00:15:27,465 --> 00:15:29,525
Speaker 4:  The other one though, the ad tech won,

301
00:15:31,345 --> 00:15:34,955
Speaker 4:  like someone in the Trump administration has to understand what's going on

302
00:15:35,335 --> 00:15:36,355
Speaker 4:  in order to stop it.

303
00:15:36,465 --> 00:15:40,035
Speaker 1:  True. But that one would also be the cleanest If you wanted like the, the

304
00:15:40,255 --> 00:15:43,915
Speaker 1:  answer to what to do about that one is just split the two things apart. Right?

305
00:15:43,915 --> 00:15:46,155
Speaker 1:  Right. That's the whole argument is these two things should not be together.

306
00:15:46,155 --> 00:15:49,915
Speaker 1:  We are going to take them apart and then everything will be better. And so

307
00:15:49,915 --> 00:15:53,035
Speaker 1:  if you're the government and you win that case, we don't have to do all this

308
00:15:53,035 --> 00:15:56,115
Speaker 1:  other, like, what are the right remedy? You just split the two things apart.

309
00:15:57,125 --> 00:16:00,425
Speaker 4:  And the reason I say someone in the Trump administration has to understand

310
00:16:00,425 --> 00:16:03,985
Speaker 4:  what's going on is who knows. But the people

311
00:16:04,005 --> 00:16:07,745
Speaker 4:  around the Trump administration hate Google. I guess JD Vance is in the Trump

312
00:16:07,745 --> 00:16:09,705
Speaker 4:  administration, but like he's the vice president. Like what's he gonna do?

313
00:16:11,175 --> 00:16:11,985
Speaker 4:  It's like the nature,

314
00:16:12,095 --> 00:16:13,825
Speaker 1:  He's gonna be busy. Like getting kids to be more active.

315
00:16:13,895 --> 00:16:16,625
Speaker 4:  Yeah. Right. The nature of the vice president is not like you get to break

316
00:16:16,625 --> 00:16:20,345
Speaker 4:  up Google. Right. But Mark Andreessen hates Google. Peter Thiel

317
00:16:20,355 --> 00:16:24,145
Speaker 4:  hates Google. There's a lot of antipathy towards Google. Yeah.

318
00:16:24,485 --> 00:16:28,265
Speaker 4:  JD Vance, by the way, also hates Google. He has been on stage at events being

319
00:16:28,265 --> 00:16:31,905
Speaker 4:  like, Google is a problem. So I, that one seems

320
00:16:32,135 --> 00:16:36,105
Speaker 4:  assured to me whether or not the search case is the

321
00:16:36,105 --> 00:16:36,505
Speaker 4:  mechanism

322
00:16:38,205 --> 00:16:41,865
Speaker 4:  that's like too fancy. Yeah. Like the Trump administration made

323
00:16:42,005 --> 00:16:45,275
Speaker 4:  Google sell Chrome with all whatever

324
00:16:45,755 --> 00:16:49,135
Speaker 4:  DOJ shakeup is happening. Maybe that's too much.

325
00:16:49,465 --> 00:16:52,735
Speaker 4:  Trump administration forces Google to divest ad tech.

326
00:16:53,725 --> 00:16:57,505
Speaker 4:  Who cares? Like, right. Try try to get that story

327
00:16:57,505 --> 00:16:59,425
Speaker 4:  across the Fox News channel. Like we'll see.

328
00:17:00,435 --> 00:17:04,325
Speaker 1:  Yeah. I, I tend to agree and I also think like, as we've talked about

329
00:17:04,325 --> 00:17:08,285
Speaker 1:  on the show, that Google search stuff seems more likely to end with a bunch

330
00:17:08,285 --> 00:17:12,085
Speaker 1:  of like behavioral remedies, right? Like Google's gonna have to do the weird

331
00:17:12,555 --> 00:17:15,885
Speaker 1:  data sharing stuff, it's gonna have to stop making the default deals. That's

332
00:17:15,885 --> 00:17:16,605
Speaker 1:  not the same thing as

333
00:17:17,365 --> 00:17:17,605
Speaker 4:  Breaking it

334
00:17:17,605 --> 00:17:19,565
Speaker 1:  Off. I don't even think they end up selling Chrome. Right. Like would be

335
00:17:19,565 --> 00:17:20,525
Speaker 1:  my prediction. That's

336
00:17:20,525 --> 00:17:23,645
Speaker 3:  What I was wondering. Like do some of these concessions happen and would

337
00:17:23,645 --> 00:17:24,525
Speaker 3:  that happen? Oh,

338
00:17:24,525 --> 00:17:27,445
Speaker 4:  And all of those concessions are like First Amendment nightmares. I just

339
00:17:27,445 --> 00:17:30,805
Speaker 4:  wanna be very clear about this. Oh, for sure. Right. Google is not allowed

340
00:17:30,805 --> 00:17:34,645
Speaker 4:  to have Google search be the default in Chrome. But, but like

341
00:17:34,645 --> 00:17:38,165
Speaker 4:  right wing search.com has to be, the default search in Chrome is a real outcome

342
00:17:38,165 --> 00:17:42,045
Speaker 4:  here. Covid is cool. Dot com is the new default homepage

343
00:17:42,045 --> 00:17:45,445
Speaker 4:  of every Chrome browser is like a real outcome we could get to.

344
00:17:46,545 --> 00:17:49,125
Speaker 3:  But does that ha, could that happen sooner than

345
00:17:50,365 --> 00:17:52,375
Speaker 3:  they break off the ad tech business?

346
00:17:53,575 --> 00:17:55,105
Speaker 4:  Well that case is already decided.

347
00:17:56,135 --> 00:17:56,915
Speaker 3:  But they

348
00:17:56,915 --> 00:17:59,875
Speaker 4:  Have, right. So Google is like ruled a monopolist. They're guilty of it.

349
00:18:00,125 --> 00:18:03,075
Speaker 4:  We're onto the what are we gonna do about it phase, right? Right. The Trump

350
00:18:03,075 --> 00:18:05,795
Speaker 4:  administration is gonna, well that, yeah, that'll all go back and forth.

351
00:18:06,375 --> 00:18:09,995
Speaker 4:  But somewhere in here, the Trump administration now has the ability to settle

352
00:18:09,995 --> 00:18:13,835
Speaker 4:  that case. Right. And like who knows what will happen and

353
00:18:13,835 --> 00:18:16,715
Speaker 4:  whether or not those settlements are a bunch of weird First Amendment ideas

354
00:18:17,875 --> 00:18:21,285
Speaker 4:  that Trump already has about Google. Right. I get such bad results in Google

355
00:18:21,305 --> 00:18:25,205
Speaker 4:  as a thing Trump says out loud it, that's all messy. Yeah. And the ad tech

356
00:18:25,205 --> 00:18:26,845
Speaker 4:  one is like not messy. This

357
00:18:26,845 --> 00:18:30,605
Speaker 3:  All comes back to me about time. Like how much can they really do in a year?

358
00:18:30,715 --> 00:18:31,005
Speaker 3:  That

359
00:18:31,005 --> 00:18:32,325
Speaker 1:  Is fair. I think that's the,

360
00:18:32,465 --> 00:18:33,485
Speaker 3:  That's what I guess I'm trying to,

361
00:18:33,485 --> 00:18:36,845
Speaker 1:  The most compelling reason to bet against would be that this stuff all just

362
00:18:36,845 --> 00:18:38,165
Speaker 1:  takes a long time to get done.

363
00:18:38,295 --> 00:18:42,045
Speaker 4:  Right. Hai calls Donald Trump and says, Hey, I will

364
00:18:42,045 --> 00:18:45,845
Speaker 4:  make you the number one result for every query in Google search.

365
00:18:46,425 --> 00:18:49,765
Speaker 4:  If you settle this case with us, is a thing that could happen. Yep.

366
00:18:51,935 --> 00:18:52,915
Speaker 1:  But you're still saying yes.

367
00:18:53,425 --> 00:18:56,075
Speaker 4:  Yeah. Okay. Something will happen with Google like the, I think,

368
00:18:56,175 --> 00:18:58,995
Speaker 3:  But something will happen and they break off their business or something

369
00:18:58,995 --> 00:19:00,115
Speaker 3:  will happen and there will be

370
00:19:02,705 --> 00:19:04,885
Speaker 3:  clear concessions made,

371
00:19:05,565 --> 00:19:06,165
Speaker 4:  I guess. Clear

372
00:19:06,165 --> 00:19:06,725
Speaker 3:  Concessions.

373
00:19:07,015 --> 00:19:07,765
Speaker 4:  Clear concessions.

374
00:19:07,995 --> 00:19:08,685
Speaker 3:  Okay. Okay.

375
00:19:09,605 --> 00:19:11,625
Speaker 1:  I'm in too. What do you think? Yeah, we're all in. I

376
00:19:11,625 --> 00:19:15,445
Speaker 3:  Don't know, I'm, my whole thing is This time, like a year is

377
00:19:15,445 --> 00:19:17,125
Speaker 3:  long. I mean, but it's also not betting

378
00:19:17,125 --> 00:19:19,765
Speaker 1:  On the legal system, taking a really long time Right. Is a pretty safe bet

379
00:19:19,765 --> 00:19:22,445
Speaker 1:  most of the time. Right. So I think it's not, it's not crazy. But now you

380
00:19:22,445 --> 00:19:23,565
Speaker 1:  have to decide, you know, you're out. I'm

381
00:19:23,565 --> 00:19:24,525
Speaker 3:  Out. Then I'm just right

382
00:19:25,545 --> 00:19:26,845
Speaker 1:  To the other side. All right. But

383
00:19:26,905 --> 00:19:28,805
Speaker 4:  By the way, I have no idea what's gonna happen with the Apple cases.

384
00:19:29,435 --> 00:19:29,725
Speaker 3:  Yeah.

385
00:19:30,095 --> 00:19:32,685
Speaker 4:  Right. Yeah. They might not even arrive. Right?

386
00:19:33,085 --> 00:19:33,205
Speaker 3:  Yeah.

387
00:19:33,505 --> 00:19:36,205
Speaker 1:  And there's Amazon stuff floating around and there's Microsoft stuff floating.

388
00:19:36,355 --> 00:19:38,845
Speaker 1:  Like I think all that stuff definitely takes too long.

389
00:19:38,865 --> 00:19:41,405
Speaker 3:  Amazon stuff is such an, I mean whatever. Yeah. Alright. Okay.

390
00:19:41,405 --> 00:19:44,845
Speaker 1:  One more for this section then we're gonna take a break. We have had a huge

391
00:19:45,555 --> 00:19:49,325
Speaker 1:  society shaking AI scandal that made everybody think

392
00:19:49,325 --> 00:19:51,605
Speaker 1:  differently about AI end of 2025.

393
00:19:52,685 --> 00:19:55,585
Speaker 4:  Oh yeah. I think they're already happening. I just think we don't know how

394
00:19:55,585 --> 00:19:59,385
Speaker 4:  to talk about them. I think that the sort of like deep fake bullying in

395
00:19:59,385 --> 00:20:03,305
Speaker 4:  schools will reach a crisis point like so much faster than we

396
00:20:03,305 --> 00:20:06,635
Speaker 4:  think. And none of the big platforms have any real plans to stop it.

397
00:20:07,815 --> 00:20:09,305
Speaker 4:  Like it's, it's, it's already here.

398
00:20:09,725 --> 00:20:13,185
Speaker 1:  But do you think, I would argue that would have to get bigger than some of

399
00:20:13,185 --> 00:20:17,145
Speaker 1:  this stuff. Like, that would have to be an order of magnitude bigger than

400
00:20:17,145 --> 00:20:19,825
Speaker 1:  like the stuff that has been happening on Instagram already. And like cyber

401
00:20:19,985 --> 00:20:22,345
Speaker 1:  bullying stuff and the, the mental health crisis on Instagram. That stuff

402
00:20:22,345 --> 00:20:24,785
Speaker 1:  didn't, it never hit the level of like,

403
00:20:27,225 --> 00:20:29,725
Speaker 1:  the most important thing to everybody. Yeah.

404
00:20:30,715 --> 00:20:34,445
Speaker 3:  Yeah. I think it's probably gonna happen in some sort of like,

405
00:20:34,445 --> 00:20:38,325
Speaker 3:  institutional way to make people care. 'cause like, I'm not

406
00:20:38,325 --> 00:20:41,805
Speaker 3:  sure people keep caring about these one-off issues about kids, but if there's

407
00:20:41,875 --> 00:20:45,605
Speaker 3:  some big hospital or some big company

408
00:20:45,955 --> 00:20:49,805
Speaker 3:  that has some AI flaw and they're put it all on, you know, they

409
00:20:49,805 --> 00:20:53,605
Speaker 3:  lose a lot of money or at worse they lose some lives and they put it on ai,

410
00:20:53,605 --> 00:20:56,325
Speaker 3:  then that's probably a likely thing. Yeah.

411
00:20:56,325 --> 00:20:59,805
Speaker 4:  America is very much in the Let's touch the stove Yeah. Moment. Yep. Right?

412
00:20:59,805 --> 00:21:02,885
Speaker 4:  Like, let's just see is it hot? Right. Let's just super, it's touch it as

413
00:21:02,885 --> 00:21:06,765
Speaker 4:  hard as we can and I think that's where we are with AI. And I, I just think

414
00:21:06,765 --> 00:21:10,655
Speaker 4:  that we're also in a moment where a bunch of parents are

415
00:21:10,655 --> 00:21:13,495
Speaker 4:  really rethinking the value of the phones for their kids. Yes. Just across

416
00:21:13,555 --> 00:21:17,445
Speaker 4:  the board and one or two more of these

417
00:21:17,445 --> 00:21:20,885
Speaker 4:  stories where a bunch of kids circulate

418
00:21:20,905 --> 00:21:23,405
Speaker 4:  non-consensual deep fake nudes of each other.

419
00:21:25,385 --> 00:21:28,125
Speaker 4:  You can just, right. It's like we're also in a political environment where

420
00:21:28,125 --> 00:21:30,885
Speaker 4:  we have a bunch of politicians, we're like, I'm I'm gonna do stuff. Right.

421
00:21:31,185 --> 00:21:33,925
Speaker 4:  And this is, you can just point a lot of that energy at this 'cause no one

422
00:21:33,925 --> 00:21:34,565
Speaker 4:  can argue about it.

423
00:21:34,945 --> 00:21:35,165
Speaker 2:  Yep.

424
00:21:35,775 --> 00:21:38,825
Speaker 1:  Yeah. I think I'm, I'm, I'm a yes on this one. I have no idea what it'll

425
00:21:38,825 --> 00:21:42,025
Speaker 1:  look like, but I think the idea that I, I just think about like Cambridge

426
00:21:42,265 --> 00:21:44,345
Speaker 1:  Analytica, which was one of those things that Right. For,

427
00:21:44,405 --> 00:21:47,145
Speaker 3:  For, I think that's what we we're gonna, we're definitely going to get one

428
00:21:47,145 --> 00:21:47,945
Speaker 3:  of those at some point.

429
00:21:47,945 --> 00:21:50,985
Speaker 1:  Yeah. For whatever Cambridge Analytica was. Right. And wasn't, it was like,

430
00:21:51,085 --> 00:21:54,865
Speaker 1:  it was a thing everyone Yes. Knew about and could reference and talked

431
00:21:54,865 --> 00:21:58,505
Speaker 1:  about. And I think we haven't had any of those with AI specifically yet.

432
00:21:58,505 --> 00:21:59,545
Speaker 1:  And I think we're gonna get one actually.

433
00:21:59,545 --> 00:22:02,185
Speaker 3:  And that's why I think it's gonna be like, something institutional, like

434
00:22:02,265 --> 00:22:02,985
Speaker 3:  it's gonna touch

435
00:22:03,945 --> 00:22:06,665
Speaker 1:  A hospital is a really interesting one. Honestly. Like you could see a bunch

436
00:22:06,665 --> 00:22:07,705
Speaker 1:  of ways that could get, I think

437
00:22:07,705 --> 00:22:10,425
Speaker 3:  It's gonna touch some part of life and I hear what ne is saying about the

438
00:22:10,455 --> 00:22:14,185
Speaker 3:  kids, but I just don't think there's enough outrage. Like there's outrage

439
00:22:14,185 --> 00:22:17,665
Speaker 3:  about it, but like Yeah. Everyone agrees. Like, you know, kids have too much

440
00:22:17,665 --> 00:22:17,865
Speaker 3:  tech

441
00:22:17,895 --> 00:22:19,225
Speaker 1:  Kids don't have the juice. Yeah.

442
00:22:20,055 --> 00:22:23,705
Speaker 3:  Like there's already all, everyone like it. Every side

443
00:22:23,725 --> 00:22:24,145
Speaker 3:  agrees.

444
00:22:24,775 --> 00:22:28,625
Speaker 1:  Yeah. And yet here we are. Yeah. Alright. Bye. So

445
00:22:28,625 --> 00:22:30,305
Speaker 1:  we're, we're all in on this one. Alright, let's

446
00:23:44,685 --> 00:23:48,165
Speaker 1:  All right. Right. We're back. I have a bunch of streaming ones that we're

447
00:23:48,165 --> 00:23:51,925
Speaker 1:  gonna do, streaming entertainment, et cetera. I'm gonna get you outta here

448
00:23:51,925 --> 00:23:53,565
Speaker 1:  on time. I promise. I see you looking at your watch.

449
00:23:55,745 --> 00:23:59,525
Speaker 1:  One or more of Max Paramount Plus and Peacock no longer exists.

450
00:24:02,325 --> 00:24:06,185
Speaker 4:  Max, I feel like I have to disclose already. 'cause

451
00:24:06,305 --> 00:24:10,145
Speaker 4:  Peacock is owned by Comcast, a Comcast investor on Rocks Media. I made a

452
00:24:10,145 --> 00:24:10,745
Speaker 4:  Netflix show.

453
00:24:11,645 --> 00:24:12,825
Speaker 3:  Do you really have to disclose these

454
00:24:12,825 --> 00:24:15,385
Speaker 4:  Things? We do it every time. Really? And when we don't do it, the people

455
00:24:15,385 --> 00:24:16,345
Speaker 4:  yell at us. Okay.

456
00:24:16,475 --> 00:24:18,425
Speaker 1:  Disclosure is our brand. Joanna? Yeah. Okay.

457
00:24:19,015 --> 00:24:20,675
Speaker 4:  One time in our disclosure Start Joanna.

458
00:24:20,675 --> 00:24:22,235
Speaker 1:  Want an Emmy? Can we disclose that? And we should

459
00:24:22,735 --> 00:24:22,955
Speaker 4:  Dis

460
00:24:22,955 --> 00:24:23,195
Speaker 3:  Disclosed?

461
00:24:23,835 --> 00:24:25,315
Speaker 1:  'cause it done disclose Disclosure

462
00:24:25,835 --> 00:24:26,475
Speaker 3:  Happened. Done.

463
00:24:28,355 --> 00:24:31,735
Speaker 4:  One time I reviewed starlink and I said this is kind of spotty If you shine

464
00:24:31,735 --> 00:24:35,015
Speaker 4:  it through trees and most people have trees in the backyard. And then I was

465
00:24:35,015 --> 00:24:38,965
Speaker 4:  like, what's the disclosure? My wired internet connection is superior

466
00:24:38,965 --> 00:24:42,725
Speaker 4:  to this. And I was accused of being a Comcast show because I said wireless

467
00:24:42,895 --> 00:24:45,685
Speaker 4:  wired connections are better than wireless ones. And I was like, if that's

468
00:24:45,685 --> 00:24:46,165
Speaker 4:  where we're at,

469
00:24:46,785 --> 00:24:48,045
Speaker 3:  Was Peacock an option there?

470
00:24:48,115 --> 00:24:51,965
Speaker 1:  Peacock Paramount plus Max One or more of those three services

471
00:24:51,965 --> 00:24:54,685
Speaker 1:  in particular. Paramount Plus is Gone. Does not exist at the end of 2025.

472
00:24:55,165 --> 00:24:58,005
Speaker 4:  Although I will say they're like all in on letting Taylor Sheridan do whatever

473
00:24:58,005 --> 00:25:01,885
Speaker 4:  he wants, which is like a reasonable strategy

474
00:25:02,205 --> 00:25:04,645
Speaker 4:  actually. Like I watched Landman, it does

475
00:25:04,645 --> 00:25:05,405
Speaker 1:  Kind of work. Yeah.

476
00:25:05,585 --> 00:25:08,165
Speaker 4:  The Billy Bob Thornton one, I was like, oh, you should just let Teo Sheridan

477
00:25:08,165 --> 00:25:12,065
Speaker 4:  do whatever he wants. It's pretty good. He's kind of like redneck

478
00:25:12,065 --> 00:25:15,985
Speaker 4:  Aaron Sorkin. Like, it's just like a, a lot of nothing happens in these

479
00:25:15,985 --> 00:25:17,385
Speaker 4:  shows. And then there's an explosion.

480
00:25:17,735 --> 00:25:20,505
Speaker 1:  Yeah. But like the dialogue is crisp right through

481
00:25:20,505 --> 00:25:24,305
Speaker 4:  Out and like everyone's walking and talking and they're like, man, that's

482
00:25:24,305 --> 00:25:25,785
Speaker 4:  been about an hour. Something should blow up

483
00:25:27,595 --> 00:25:28,905
Speaker 4:  every one of these episodes. Yeah.

484
00:25:28,905 --> 00:25:31,825
Speaker 1:  He's Aaron Sorkin, not Coastal Elite.

485
00:25:33,145 --> 00:25:34,905
Speaker 1:  I love it. It's good. Okay. But

486
00:25:34,905 --> 00:25:37,825
Speaker 4:  I but they're done. That deal will go away. That's not him. Drive enough

487
00:25:37,825 --> 00:25:38,225
Speaker 4:  steps for them.

488
00:25:39,505 --> 00:25:43,105
Speaker 3:  I really love Max. That's my, that's my contribution here. Oh, I

489
00:25:43,105 --> 00:25:43,905
Speaker 4:  Should have picked Max

490
00:25:44,825 --> 00:25:48,805
Speaker 1:  To Die. To die. Yeah. I think I love Max. One of Max on. Max. Max

491
00:25:48,805 --> 00:25:51,205
Speaker 1:  in Paramount Plus is gonna be gone. I don't which one. It's Max forever.

492
00:25:51,555 --> 00:25:52,765
Speaker 1:  There's gonna be some, max

493
00:25:52,785 --> 00:25:53,685
Speaker 3:  Has to be doing pretty good

494
00:25:54,605 --> 00:25:57,655
Speaker 4:  Because they're being run so well by Warner Brothers. Discovery. Yeah.

495
00:25:57,655 --> 00:25:59,055
Speaker 1:  That's, that's going great.

496
00:25:59,965 --> 00:26:01,415
Speaker 3:  They have decent programming on there.

497
00:26:01,925 --> 00:26:02,935
Speaker 4:  What do you watch on Max?

498
00:26:04,605 --> 00:26:05,965
Speaker 3:  I just watched all of industry.

499
00:26:06,475 --> 00:26:08,485
Speaker 4:  Sure. Okay. Industry solid people like that show. Yeah.

500
00:26:08,595 --> 00:26:10,685
Speaker 1:  Yeah. Gen Z succession. They call it

501
00:26:10,785 --> 00:26:11,685
Speaker 4:  One One. Show

502
00:26:12,855 --> 00:26:13,205
Speaker 3:  Hacks.

503
00:26:13,975 --> 00:26:15,485
Speaker 1:  Hacks is good. Hacks.

504
00:26:16,635 --> 00:26:18,995
Speaker 3:  I think we watch Paw Patrol through Max.

505
00:26:20,695 --> 00:26:21,485
Speaker 3:  Maybe not.

506
00:26:21,785 --> 00:26:24,005
Speaker 4:  It sucks that my kid is named Max. Yeah, it

507
00:26:24,005 --> 00:26:27,765
Speaker 1:  Does. It does. Joanna just calls Max and says, describe

508
00:26:27,825 --> 00:26:28,525
Speaker 1:  Paw Patrol to me.

509
00:26:28,785 --> 00:26:30,605
Speaker 3:  We also watched Jurassic Park on there.

510
00:26:30,785 --> 00:26:34,705
Speaker 4:  Did your kids have a crush on Chase The dog. Max had a,

511
00:26:34,705 --> 00:26:38,185
Speaker 4:  like a baby crush the dog. Like Chase was her favorite dog on Paw Patrol.

512
00:26:38,185 --> 00:26:42,145
Speaker 4:  And I was like, why'd you pick the cop? Like why, why not? There's a water

513
00:26:42,145 --> 00:26:42,345
Speaker 4:  dog.

514
00:26:42,345 --> 00:26:46,205
Speaker 3:  Alex does. Alex does like, no, I think he, he really likes rubble. Yeah,

515
00:26:46,285 --> 00:26:48,965
Speaker 4:  Rubble's great. Rubble's great. You know, he like, he fixes stuff.

516
00:26:49,145 --> 00:26:50,245
Speaker 3:  Do we watch it through Max

517
00:26:50,625 --> 00:26:51,085
Speaker 4:  Cop dog?

518
00:26:51,775 --> 00:26:55,705
Speaker 1:  Yeah. See, I would argue this, this might not be the great case

519
00:26:55,705 --> 00:26:56,825
Speaker 1:  for Max that you think it's,

520
00:26:57,045 --> 00:27:00,625
Speaker 3:  But watch that on Max. Okay. I'll be honest. Like we had Peacock for the

521
00:27:00,905 --> 00:27:04,545
Speaker 3:  Olympics. Don't have it anymore. Paramount. Don't have it anymore. Oh.

522
00:27:04,545 --> 00:27:07,545
Speaker 4:  This is my other prediction. They will all solve this problem by not letting

523
00:27:07,545 --> 00:27:09,025
Speaker 4:  you churn as hard as you can churn right now.

524
00:27:09,375 --> 00:27:11,345
Speaker 3:  That I believe that I will a good one. Put

525
00:27:11,345 --> 00:27:12,545
Speaker 1:  A lot on a good, that's a really good one.

526
00:27:12,925 --> 00:27:16,855
Speaker 3:  But yeah, there was just that legisl like there's, was it, what's the

527
00:27:16,855 --> 00:27:19,095
Speaker 3:  legislation that just happened that makes it, you have to make it. That's

528
00:27:19,095 --> 00:27:19,375
Speaker 3:  click a cancel.

529
00:27:19,445 --> 00:27:20,015
Speaker 4:  Yeah. Yeah.

530
00:27:20,155 --> 00:27:21,255
Speaker 3:  So how are they gonna get around that?

531
00:27:21,255 --> 00:27:23,655
Speaker 4:  That's going away in the Trump administration. Yeah. Wow. Wow. A federal

532
00:27:23,675 --> 00:27:27,335
Speaker 4:  agency doing stuff. Yeah. That's, that's all over now. Yeah.

533
00:27:27,335 --> 00:27:28,775
Speaker 4:  Especially 'cause Lena Conn did it.

534
00:27:29,995 --> 00:27:32,095
Speaker 1:  All right. We're all saying yes to that one. Right. We're all,

535
00:27:32,095 --> 00:27:33,575
Speaker 4:  We're all one of the three. You don't have to

536
00:27:33,575 --> 00:27:37,455
Speaker 1:  Pick one, one or more of the three is is gone. Yeah. Again, my my time

537
00:27:37,455 --> 00:27:40,735
Speaker 1:  travel is, you lose some stuff. It's hard to remember everything in the time

538
00:27:40,735 --> 00:27:44,695
Speaker 1:  travel. Netflix is killing it in

539
00:27:44,695 --> 00:27:47,335
Speaker 1:  live TV and is already the biggest thing in life.

540
00:27:47,835 --> 00:27:48,055
Speaker 4:  No,

541
00:27:48,555 --> 00:27:48,775
Speaker 3:  No

542
00:27:49,425 --> 00:27:51,495
Speaker 4:  Disclosure. You already know this.

543
00:27:51,515 --> 00:27:52,455
Speaker 1:  We did that already. Disclosure,

544
00:27:52,995 --> 00:27:55,735
Speaker 3:  How long ago did that show? How long do you have? Many years. You have to

545
00:27:55,735 --> 00:27:55,975
Speaker 3:  say that

546
00:27:56,365 --> 00:27:57,415
Speaker 1:  Forever since

547
00:27:57,415 --> 00:27:58,775
Speaker 3:  It's on there, it's gonna be on there

548
00:27:58,775 --> 00:28:00,375
Speaker 1:  Forever. Video on demand. That's

549
00:28:00,375 --> 00:28:02,255
Speaker 4:  Happens. Yeah. I didn't even paid for it. This is like the funniest part

550
00:28:02,255 --> 00:28:05,015
Speaker 4:  of this. It's like, not even a conflict of interest. I just did the thing.

551
00:28:05,675 --> 00:28:08,095
Speaker 3:  Do I have to have a disclosure that I talked to you when you were doing,

552
00:28:08,535 --> 00:28:09,135
Speaker 3:  working on that

553
00:28:09,135 --> 00:28:11,735
Speaker 4:  Show? If you wanna Sure. If you, if everyone like to remind everyone else

554
00:28:11,845 --> 00:28:14,535
Speaker 4:  that I made an Netflix show, that's great for me personally.

555
00:28:15,105 --> 00:28:15,775
Speaker 1:  Disclosure,

556
00:28:16,535 --> 00:28:20,495
Speaker 3:  I spoke to Eli when he was working on Netflix, his Netflix show. And I also

557
00:28:20,495 --> 00:28:21,495
Speaker 3:  talked to him when he had Comcast.

558
00:28:22,005 --> 00:28:24,575
Speaker 1:  Well, you're clearly in somebody's pocket. Yeah. I don't know who

559
00:28:24,575 --> 00:28:27,455
Speaker 4:  It's if I had Comcast, you mean the service in Chicago? You

560
00:28:27,455 --> 00:28:27,895
Speaker 3:  Still have Comcast?

561
00:28:28,235 --> 00:28:30,015
Speaker 4:  No, I, we, there's no Comcast out here.

562
00:28:30,285 --> 00:28:33,095
Speaker 3:  What do you have? Xfinity. Isn't Xfinity

563
00:28:33,095 --> 00:28:36,415
Speaker 4:  Content? Do I have to disclosure? I Fios and it rules. I dis

564
00:28:36,745 --> 00:28:38,935
Speaker 4:  wired. Internet is better than wireless internet. My friend

565
00:28:38,935 --> 00:28:40,255
Speaker 3:  Disclosure. I also have Fios.

566
00:28:40,485 --> 00:28:41,855
Speaker 1:  Well, I have Ting. Let's go.

567
00:28:41,865 --> 00:28:42,815
Speaker 4:  We're conflicted out.

568
00:28:43,375 --> 00:28:47,015
Speaker 1:  Ting maybe. All right, next one. We're all saying no on that one. Yeah, we're

569
00:28:47,015 --> 00:28:48,855
Speaker 1:  good. Okay. They

570
00:28:48,855 --> 00:28:50,095
Speaker 4:  They have a long way to go. Yeah.

571
00:28:51,085 --> 00:28:53,575
Speaker 1:  Jake Paul needs to fight somebody else and then they

572
00:28:53,575 --> 00:28:56,975
Speaker 4:  Have a big test Christmas this Christmas. Yeah. I I I reserve the right to

573
00:28:56,995 --> 00:29:00,535
Speaker 4:  revise this after the NFL on Christmas on Netflix.

574
00:29:00,795 --> 00:29:01,615
Speaker 4:  But I, yeah, I

575
00:29:01,615 --> 00:29:03,495
Speaker 1:  Don't think they're right. Netflix certainly has the money to do it, but

576
00:29:03,495 --> 00:29:07,215
Speaker 1:  it's, it's harder work than anybody thinks. Grand Theft auto launched

577
00:29:07,425 --> 00:29:10,935
Speaker 1:  Grand Theft Auto six rather. Grand Theft Auto six launched. And it is the

578
00:29:11,175 --> 00:29:14,975
Speaker 1:  single most successful game in history and has basically changed the video

579
00:29:14,975 --> 00:29:16,095
Speaker 1:  game industry all by itself.

580
00:29:17,145 --> 00:29:20,895
Speaker 4:  That's a, that's too many ideas. So I I say yes

581
00:29:20,995 --> 00:29:21,575
Speaker 4:  to launch

582
00:29:21,625 --> 00:29:24,455
Speaker 1:  Grand Theft Auto six is the Prince that was promised. Yeah.

583
00:29:24,885 --> 00:29:25,815
Speaker 4:  It's too many ideas.

584
00:29:25,915 --> 00:29:26,455
Speaker 3:  It launches.

585
00:29:26,815 --> 00:29:30,375
Speaker 4:  It launches, it makes a bunch of money. Agreed. Okay. Everyone else has

586
00:29:30,655 --> 00:29:33,895
Speaker 4:  already tried to do the big game as a service

587
00:29:35,635 --> 00:29:39,625
Speaker 4:  thing. What was the Sony one that just failed Concord. Yeah. Everyone

588
00:29:39,625 --> 00:29:43,605
Speaker 4:  just wanted to do Fortnite and it like didn't work. You need to have the

589
00:29:43,605 --> 00:29:46,045
Speaker 4:  big property that can support it. Grand Theft Auto is one of those properties.

590
00:29:46,105 --> 00:29:49,405
Speaker 4:  Yep. Changes the, I think everyone's gonna be like, man, I wish we'd invented

591
00:29:49,405 --> 00:29:52,805
Speaker 4:  Grand Theft Auto. And they will continue not investing money into these things

592
00:29:52,805 --> 00:29:53,165
Speaker 4:  that fail.

593
00:29:54,355 --> 00:29:58,265
Speaker 1:  But you think Grand Theft Auto on its own big hit's gonna

594
00:29:58,265 --> 00:29:58,985
Speaker 1:  work. Yeah.

595
00:29:59,585 --> 00:30:02,265
Speaker 4:  I mean, assuming it's not a disaster, but I think a lot of people are gonna

596
00:30:02,265 --> 00:30:02,505
Speaker 4:  die. Well,

597
00:30:02,505 --> 00:30:06,065
Speaker 1:  No, this is, this is the prediction we have to make here. It's, I mean the,

598
00:30:06,085 --> 00:30:10,025
Speaker 1:  the reason I put this in is that we have had a long run of huge

599
00:30:10,295 --> 00:30:13,745
Speaker 1:  expensive games that haven't worked for one reason or another.

600
00:30:14,695 --> 00:30:18,355
Speaker 1:  And if that happens to GTA six, it's gonna be a disaster. Yeah.

601
00:30:18,505 --> 00:30:22,075
Speaker 1:  Like this, this is the most hyped game in forever

602
00:30:22,815 --> 00:30:26,315
Speaker 1:  and it has been around for forever there. It has like loomed over the gaming

603
00:30:26,635 --> 00:30:30,555
Speaker 1:  industry for years and if it doesn't hit and it's not as

604
00:30:30,555 --> 00:30:34,395
Speaker 1:  good and big and exciting and cool and groundbreaking, like GTA

605
00:30:34,395 --> 00:30:38,195
Speaker 1:  five is still a wildly successful game. If GTA six flops,

606
00:30:38,645 --> 00:30:41,795
Speaker 4:  Chris Grant, who's our publisher and the founder of Polygon is always showing

607
00:30:41,795 --> 00:30:44,635
Speaker 4:  me this chart that's like the highest grossing games in the world. And they're

608
00:30:44,635 --> 00:30:48,395
Speaker 4:  all over like seven years old. Yeah. They're all very old. 'cause they've

609
00:30:48,395 --> 00:30:51,315
Speaker 4:  all just turned into these places where people hang out. So GT six has a

610
00:30:51,315 --> 00:30:51,915
Speaker 4:  long road.

611
00:30:52,455 --> 00:30:52,795
Speaker 1:  It does

612
00:30:53,355 --> 00:30:57,325
Speaker 4:  Like cyberpunk 27 7 came out and it like didn't work and then now it works

613
00:30:57,325 --> 00:30:58,205
Speaker 4:  and like everyone loves it,

614
00:30:58,785 --> 00:31:01,765
Speaker 1:  But a lot of, a lot of heads rolled in the meantime. Yeah. All right. I'm

615
00:31:01,765 --> 00:31:03,165
Speaker 1:  in on this one. Sounds like you are too.

616
00:31:03,725 --> 00:31:04,885
Speaker 3:  I have no idea what you're talking about.

617
00:31:04,885 --> 00:31:08,445
Speaker 1:  Okay. Joanna's, just a big question mark. Okay,

618
00:31:09,425 --> 00:31:13,365
Speaker 1:  few more. It's the end of 2025. And folding phones are

619
00:31:13,365 --> 00:31:14,485
Speaker 1:  completely mainstream now

620
00:31:16,585 --> 00:31:19,125
Speaker 3:  Unless Apple's releasing one and they're not. So no,

621
00:31:20,045 --> 00:31:20,745
Speaker 4:  You don't think they are.

622
00:31:21,605 --> 00:31:23,065
Speaker 1:  One of the other ones I was gonna put is

623
00:31:23,565 --> 00:31:25,935
Speaker 3:  In 2025. I don't think So.

624
00:31:26,775 --> 00:31:29,655
Speaker 4:  I think it's actually very funny that Apple thought I could drive a supercycle

625
00:31:29,655 --> 00:31:32,415
Speaker 4:  with AI and really it just needs to make the phone fold over and that would

626
00:31:32,415 --> 00:31:32,895
Speaker 4:  be the thing.

627
00:31:32,925 --> 00:31:34,495
Speaker 3:  Yeah. Well a hundred percent drive a supercycle.

628
00:31:34,525 --> 00:31:38,375
Speaker 1:  What if I changed it to Apple released a foldable iPhone or iPad.

629
00:31:38,545 --> 00:31:40,975
Speaker 1:  Apple released a foldable something in 2025.

630
00:31:42,155 --> 00:31:42,935
Speaker 4:  The displays aren't gonna have

631
00:31:42,955 --> 00:31:46,575
Speaker 3:  It. They released a foldable MacBook, which is just a MacBook as it's a laptop,

632
00:31:46,915 --> 00:31:49,855
Speaker 1:  But it's a MacBook. You can, you can, it just folds scrunch up into your

633
00:31:49,855 --> 00:31:49,975
Speaker 1:  pocket.

634
00:31:50,125 --> 00:31:52,855
Speaker 3:  It's just like that. But it has a better chip that's, they're foldable for

635
00:31:52,855 --> 00:31:53,135
Speaker 3:  the year.

636
00:31:54,445 --> 00:31:57,455
Speaker 1:  Alright, so you're out on foldable phones going mainstream.

637
00:31:57,735 --> 00:32:00,135
Speaker 3:  I think they will go mainstream once Apple has one.

638
00:32:00,195 --> 00:32:01,775
Speaker 1:  But you don't think it's next year? No.

639
00:32:02,045 --> 00:32:02,335
Speaker 3:  Okay.

640
00:32:02,885 --> 00:32:03,175
Speaker 1:  Neli?

641
00:32:03,795 --> 00:32:05,055
Speaker 4:  No, not next year.

642
00:32:05,165 --> 00:32:08,845
Speaker 1:  Yeah, I'm out too. I think it's coming. Yeah.

643
00:32:08,845 --> 00:32:09,805
Speaker 1:  Think I continue to

644
00:32:09,805 --> 00:32:10,805
Speaker 3:  Use 26 is was

645
00:32:11,155 --> 00:32:15,005
Speaker 1:  Fold foldable phones and flip phones, which I all Yeah. Collapse into

646
00:32:15,005 --> 00:32:18,205
Speaker 1:  folding phones. It will be a thing are going to happen. Yeah.

647
00:32:18,435 --> 00:32:21,005
Speaker 3:  Yeah. They're getting better. Not next year. I see 'em, I see 'em a lot now.

648
00:32:21,555 --> 00:32:25,525
Speaker 1:  Okay. The Pixel 10 is by far the best and

649
00:32:25,525 --> 00:32:26,645
Speaker 1:  most successful Android phone.

650
00:32:27,315 --> 00:32:29,245
Speaker 3:  What is success? How is Best Measured?

651
00:32:29,245 --> 00:32:31,205
Speaker 1:  I'll, let's just land on best. It is by far the best Android phone.

652
00:32:31,385 --> 00:32:32,525
Speaker 3:  How is Best Measured?

653
00:32:32,945 --> 00:32:33,605
Speaker 4:  You are a product

654
00:32:33,605 --> 00:32:34,765
Speaker 1:  Reviewer. Yeah. Right. You

655
00:32:34,765 --> 00:32:37,205
Speaker 4:  Are the lead product reviewer of the Wall Street Journal.

656
00:32:37,505 --> 00:32:37,925
Speaker 3:  How is it

657
00:32:38,085 --> 00:32:40,525
Speaker 4:  Measured? How are you having this like, existential debate about what's a

658
00:32:40,525 --> 00:32:43,165
Speaker 4:  good phone? How do you, what do you think a good phone is?

659
00:32:44,275 --> 00:32:47,525
Speaker 3:  Best? Fine. I think we've all agreed that it's been the best Android phone

660
00:32:47,525 --> 00:32:48,725
Speaker 3:  for a long time. Wait,

661
00:32:48,725 --> 00:32:50,005
Speaker 4:  Are we agreed on that? I

662
00:32:50,005 --> 00:32:50,165
Speaker 3:  Mean,

663
00:32:52,705 --> 00:32:53,125
Speaker 4:  Go on.

664
00:32:56,025 --> 00:32:59,865
Speaker 3:  I will say I do not think Samsung has, other

665
00:33:00,065 --> 00:33:03,785
Speaker 3:  than some hardware improvements, I do not think they've had substantial

666
00:33:03,785 --> 00:33:04,865
Speaker 3:  improvements to their phones.

667
00:33:06,525 --> 00:33:10,185
Speaker 3:  And I think they lean very heavily on their relationship with Google to do

668
00:33:10,185 --> 00:33:13,975
Speaker 3:  all the work. And Yeah. Like at this point, like

669
00:33:14,535 --> 00:33:14,955
Speaker 3:  nobody,

670
00:33:15,175 --> 00:33:17,435
Speaker 4:  You don't think the Galaxy fold is better than the pixel fold?

671
00:33:18,795 --> 00:33:22,445
Speaker 3:  Yeah. I guess Foldables, I would say they've done a better job on the

672
00:33:22,605 --> 00:33:25,915
Speaker 3:  hardware and they're fine. But I guess I'm talking about like

673
00:33:26,115 --> 00:33:29,875
Speaker 3:  flagship phones that continue to be the most popular. Yeah. That is

674
00:33:29,875 --> 00:33:33,765
Speaker 3:  always gonna be Samsung. They're going to, sorry. And I say this by

675
00:33:33,765 --> 00:33:37,685
Speaker 3:  sales, Samsung will continue to sell more phones whether they

676
00:33:37,685 --> 00:33:41,565
Speaker 3:  have the best one or they don't. And that's just been the story of Android

677
00:33:41,665 --> 00:33:42,645
Speaker 3:  for how many years?

678
00:33:43,785 --> 00:33:44,645
Speaker 1:  All of them. Pretty

679
00:33:44,645 --> 00:33:47,525
Speaker 3:  Much. Is that going to change in 20 20, 20 25? Well,

680
00:33:47,525 --> 00:33:50,245
Speaker 4:  You think right now the pixel's a better phone than whatever Galaxy?

681
00:33:52,345 --> 00:33:52,465
Speaker 3:  I

682
00:33:54,625 --> 00:33:57,705
Speaker 3:  I prefer, I will always prefer the software experience of the Pixel.

683
00:33:58,765 --> 00:33:59,205
Speaker 3:  I just do.

684
00:33:59,835 --> 00:34:01,685
Speaker 4:  Yeah. I I I don't disagree with you. Yeah.

685
00:34:01,685 --> 00:34:04,485
Speaker 3:  Yeah. So I mean, like, you know, I I don't know the, like

686
00:34:05,655 --> 00:34:09,435
Speaker 3:  can it, the Galaxy take slightly better photos in

687
00:34:09,455 --> 00:34:13,275
Speaker 3:  my last testing like two years ago. I don't know, like did that change?

688
00:34:13,455 --> 00:34:17,025
Speaker 3:  You guys tell me. Not at all. I haven't done camera testing of the Pixel

689
00:34:17,085 --> 00:34:18,945
Speaker 3:  in the Samsung in probably two years.

690
00:34:19,375 --> 00:34:22,545
Speaker 4:  They, at this point, they're all on top of each other. It's

691
00:34:22,545 --> 00:34:26,225
Speaker 3:  Like, yeah. Right. So I come down to on, okay, there's a great

692
00:34:26,625 --> 00:34:30,305
Speaker 3:  software experience on the Pixel and people, they,

693
00:34:30,375 --> 00:34:34,065
Speaker 3:  they gained one point of market share I believe

694
00:34:34,385 --> 00:34:34,545
Speaker 3:  this

695
00:34:34,545 --> 00:34:35,825
Speaker 4:  Year. Well they also, according

696
00:34:35,825 --> 00:34:36,225
Speaker 3:  To IDC,

697
00:34:36,245 --> 00:34:39,985
Speaker 4:  Google can't try very hard. This is a real,

698
00:34:39,985 --> 00:34:42,865
Speaker 4:  they'll break them up. This is a real problem for them. Right. Because they

699
00:34:42,865 --> 00:34:44,265
Speaker 4:  can't piss off Samsung. Right.

700
00:34:44,765 --> 00:34:48,605
Speaker 3:  So I guess that's where I was like success and best. Like sure

701
00:34:48,635 --> 00:34:52,315
Speaker 3:  it's the best. But you first said success, which you

702
00:34:52,315 --> 00:34:53,195
Speaker 3:  changed. Wait,

703
00:34:53,195 --> 00:34:54,195
Speaker 4:  Read, read your thing again. If we

704
00:34:54,195 --> 00:34:57,275
Speaker 1:  Wanna just, I originally said best and most successful,

705
00:34:58,455 --> 00:35:00,395
Speaker 1:  but if we wanna split hairs, we can do one and the

706
00:35:00,395 --> 00:35:02,195
Speaker 3:  Other. I think those are very different things. Yeah.

707
00:35:02,195 --> 00:35:04,635
Speaker 1:  Well, yeah, they are different things, but I'm telling you both happened

708
00:35:04,635 --> 00:35:05,555
Speaker 1:  hairs in 2025.

709
00:35:05,855 --> 00:35:09,275
Speaker 4:  Oh, then that's a hard no. If it's both absolutely not.

710
00:35:09,375 --> 00:35:11,555
Speaker 3:  That's what I'm saying. Okay. Okay.

711
00:35:11,935 --> 00:35:12,155
Speaker 1:  All

712
00:35:12,155 --> 00:35:14,915
Speaker 4:  Right. But I will it remain the best one. Yeah.

713
00:35:17,535 --> 00:35:20,995
Speaker 1:  How do I write that in my notes about what you guys said? All right. Yeah.

714
00:35:20,995 --> 00:35:22,755
Speaker 1:  I think we're all, we're all No on that one. I

715
00:35:22,755 --> 00:35:25,555
Speaker 3:  Mean, but like, what is the most exciting thing that's gonna happen in smartphones

716
00:35:25,555 --> 00:35:26,115
Speaker 3:  in the next year?

717
00:35:27,825 --> 00:35:30,515
Speaker 3:  What are we all gonna be excited about when Samsung comes out with the gala?

718
00:35:30,625 --> 00:35:31,515
Speaker 1:  Ossibly, it's ai.

719
00:35:32,135 --> 00:35:33,745
Speaker 3:  And is that something we're gonna get excited about?

720
00:35:34,405 --> 00:35:34,625
Speaker 1:  No.

721
00:35:35,095 --> 00:35:36,025
Speaker 4:  Bluetooth six

722
00:35:37,755 --> 00:35:40,885
Speaker 3:  Bluetooth is ai. I've come full circle.

723
00:35:41,345 --> 00:35:43,565
Speaker 1:  All right, let's do a couple more. Joanna, you have to leave here in a minute.

724
00:35:43,575 --> 00:35:47,325
Speaker 1:  Let's do a couple more. Apple is actually making a television. It's

725
00:35:47,525 --> 00:35:47,685
Speaker 1:  official.

726
00:35:48,545 --> 00:35:50,835
Speaker 4:  There's, there's been rumored again recently. Yeah.

727
00:35:50,945 --> 00:35:52,395
Speaker 3:  They've been making television.

728
00:35:52,545 --> 00:35:55,035
Speaker 1:  It's real. This time Apple is going to sell you a television

729
00:35:55,035 --> 00:35:56,355
Speaker 3:  It thousand and eight,

730
00:35:57,695 --> 00:36:01,595
Speaker 4:  Not in 2025. But they, I think that the rumors on this will heat up. Apple

731
00:36:01,655 --> 00:36:05,115
Speaker 4:  is out of markets. This is a real problem. They don't make enough stuff.

732
00:36:05,865 --> 00:36:07,995
Speaker 4:  It's weird that they don't make enough stuff. The

733
00:36:08,015 --> 00:36:10,835
Speaker 1:  The longer I, I wrote this one down originally, like as kind of a joke. And

734
00:36:10,835 --> 00:36:12,995
Speaker 1:  the longer I think about it, the more I wanna say yes. Right. But

735
00:36:12,995 --> 00:36:13,395
Speaker 3:  This year,

736
00:36:14,385 --> 00:36:15,235
Speaker 1:  Yeah, I think it's

737
00:36:15,355 --> 00:36:17,475
Speaker 4:  Possible. It's, I mean, it's not like hard to do

738
00:36:18,025 --> 00:36:18,315
Speaker 1:  Yeah.

739
00:36:18,585 --> 00:36:21,155
Speaker 4:  TV's right? Like at the end of the day, they gotta buy an OLA panel from

740
00:36:21,155 --> 00:36:24,275
Speaker 4:  Samsung. They gotta glue an Apple TV to the back of it and they're gonna

741
00:36:24,275 --> 00:36:25,315
Speaker 4:  be like $6,000

742
00:36:25,315 --> 00:36:27,515
Speaker 3:  And they gotta make some nice frames Yeah. To put around it.

743
00:36:29,545 --> 00:36:32,955
Speaker 4:  It's weird. 'cause the thing you're saying about cable television dying and

744
00:36:33,035 --> 00:36:35,875
Speaker 4:  all this other stuff like runs against Apple doing a tv.

745
00:36:36,175 --> 00:36:36,395
Speaker 1:  Yes.

746
00:36:37,155 --> 00:36:40,445
Speaker 4:  It's a real problem. I I think they might have missed the window on doing

747
00:36:40,445 --> 00:36:40,765
Speaker 4:  this. I think

748
00:36:40,765 --> 00:36:43,445
Speaker 1:  Unless Apple thinks there's a giant ads business in being

749
00:36:44,125 --> 00:36:47,685
Speaker 4:  A, or or an extension of their services business. Sure. But they were chasing

750
00:36:47,735 --> 00:36:51,165
Speaker 4:  other huge iPhone sized markets and the only ones that could identify were

751
00:36:51,285 --> 00:36:55,095
Speaker 4:  healthcare and cars. And they got run outta cars. Yeah. It's too hard. I

752
00:36:55,095 --> 00:36:56,335
Speaker 4:  know what they're gonna do in healthcare over time,

753
00:36:56,835 --> 00:37:00,335
Speaker 3:  But if the home, which seems to be this big place, they're gonna focus some

754
00:37:00,335 --> 00:37:04,135
Speaker 3:  of the effort this year. And they do this home tablet sometime this

755
00:37:04,135 --> 00:37:07,585
Speaker 3:  spring. Seems like something between an iPad and a

756
00:37:07,995 --> 00:37:11,785
Speaker 3:  Apple TV type of thing. Yeah. In terms of like

757
00:37:12,065 --> 00:37:12,625
Speaker 3:  software. Yeah.

758
00:37:12,625 --> 00:37:14,865
Speaker 4:  Right. Yeah. They gotta put another screen in your house and they gotta find

759
00:37:14,905 --> 00:37:15,385
Speaker 4:  a way to charge you

760
00:37:15,385 --> 00:37:18,105
Speaker 3:  Money garage. So let's say they put another screen in your house that's home-based.

761
00:37:18,245 --> 00:37:20,025
Speaker 3:  Is it a TV this year or is it this like

762
00:37:20,285 --> 00:37:22,145
Speaker 4:  Tablet? No, they're gonna do this little thing first.

763
00:37:22,315 --> 00:37:25,985
Speaker 3:  Right. So I don't know if, I think this TV thing is to your point, like they've

764
00:37:25,985 --> 00:37:29,385
Speaker 3:  gotta go to other markets. This makes sense. They can finally say, Hey, we've

765
00:37:29,385 --> 00:37:32,705
Speaker 3:  got it all integrated. It's just one cord into the wall. Like, great. Yeah.

766
00:37:33,445 --> 00:37:35,505
Speaker 3:  But then does that happen this year?

767
00:37:37,065 --> 00:37:37,285
Speaker 1:  I'm

768
00:37:37,285 --> 00:37:39,285
Speaker 3:  Saying that, I don't think it happens this year. No,

769
00:37:39,505 --> 00:37:40,125
Speaker 1:  I'm in on it.

770
00:37:40,765 --> 00:37:43,925
Speaker 4:  I think, I think we're gonna hear a lot about it this year. They're gonna

771
00:37:43,925 --> 00:37:46,325
Speaker 4:  feel that just a ma like Apple making a TV like

772
00:37:46,325 --> 00:37:46,645
Speaker 3:  Reports.

773
00:37:47,075 --> 00:37:48,565
Speaker 4:  Yeah. We're gonna hear a lot of noise.

774
00:37:48,565 --> 00:37:50,845
Speaker 3:  This Mark Urman is gonna be very busy talking about this this year.

775
00:37:51,195 --> 00:37:52,925
Speaker 4:  Does an Apple TV have HTM I ports?

776
00:37:53,465 --> 00:37:53,685
Speaker 3:  No.

777
00:37:54,235 --> 00:37:56,205
Speaker 4:  Well then what are all the people Psi gonna do?

778
00:37:56,475 --> 00:37:57,765
Speaker 3:  They're not, they're

779
00:37:57,765 --> 00:38:00,445
Speaker 4:  Not. So you're gonna make it a TV that just excludes No.

780
00:38:00,445 --> 00:38:01,525
Speaker 1:  It'll it'll have ht MI

781
00:38:01,525 --> 00:38:02,445
Speaker 3:  Ports. You think so? This

782
00:38:02,445 --> 00:38:04,685
Speaker 4:  Is complicated. It immediately makes it complicated.

783
00:38:04,985 --> 00:38:08,725
Speaker 3:  See, I think that's what they've wanted to do, is to like one port.

784
00:38:08,755 --> 00:38:10,045
Speaker 3:  Like it just plugs in.

785
00:38:10,465 --> 00:38:13,765
Speaker 1:  But again, if, if you're doing, if you're doing the home stuff you're talking

786
00:38:13,765 --> 00:38:17,325
Speaker 1:  about, you could sell me a bunch of new screens or you could take advantage

787
00:38:17,345 --> 00:38:21,045
Speaker 1:  of the big screen that sits in the middle of everyone's house and is like

788
00:38:21,315 --> 00:38:25,245
Speaker 1:  this Gen tui on our team keeps railing on this. Like, the TV

789
00:38:25,425 --> 00:38:28,365
Speaker 1:  is the center of the smart home. It is. I love that. It's ridiculous. Love

790
00:38:28,365 --> 00:38:29,445
Speaker 1:  that. That no one has solved this yet.

791
00:38:30,005 --> 00:38:33,765
Speaker 3:  I love when my garage door opens and I see a little alert on my TV

792
00:38:33,835 --> 00:38:35,370
Speaker 3:  that says Garage door open

793
00:38:35,745 --> 00:38:38,485
Speaker 1:  And it's two o'clock in the morning. And you didn't do that on purpose. And

794
00:38:38,485 --> 00:38:42,085
Speaker 1:  here we are. All right. Last one. And then Joanna, you're gonna go,

795
00:38:43,715 --> 00:38:47,165
Speaker 1:  what do I wanna do? Last Waymo's self-driving cars are now everywhere in

796
00:38:47,165 --> 00:38:47,645
Speaker 1:  New York City.

797
00:38:48,855 --> 00:38:52,755
Speaker 3:  No, I just interviewed the CEO. No, but I, but they will

798
00:38:52,755 --> 00:38:54,915
Speaker 3:  be like in a lot of other cities.

799
00:38:55,305 --> 00:38:58,915
Speaker 1:  Okay. I I picked New York specifically. Yeah, because it is, it is probably

800
00:38:58,975 --> 00:38:59,315
Speaker 1:  the highest

801
00:38:59,455 --> 00:39:03,235
Speaker 3:  Bar. I think New York is like New York. They are working on, but it's,

802
00:39:03,265 --> 00:39:04,795
Speaker 3:  it's not, not yet. You don't

803
00:39:04,795 --> 00:39:07,995
Speaker 4:  Think so New York also has the weather issue that they are, the last time

804
00:39:07,995 --> 00:39:11,475
Speaker 4:  I talked to to Cadra, she was, I was like, can you get this thing in

805
00:39:11,765 --> 00:39:15,355
Speaker 4:  Aspen, Colorado? And she's like, no. Right. She's like, no. Like

806
00:39:15,575 --> 00:39:17,915
Speaker 4:  we can't solve that problem yet. Like, weather is too hard. And New York

807
00:39:17,935 --> 00:39:19,635
Speaker 4:  has enough weather where I think it's too, that's

808
00:39:19,635 --> 00:39:22,045
Speaker 3:  True. Do you think they'll, they're testing here. Apparently

809
00:39:22,195 --> 00:39:25,925
Speaker 4:  They are. And there's aspects of New York that are Make it simpler.

810
00:39:25,925 --> 00:39:29,205
Speaker 4:  Totally. It's a big grid. Yeah. You can just like solve that problem. But

811
00:39:29,515 --> 00:39:33,055
Speaker 4:  there's two feet of snow on the ground gets rolled icy.

812
00:39:33,695 --> 00:39:36,265
Speaker 3:  There's not bike lanes. I think New York's really challenging.

813
00:39:36,805 --> 00:39:39,785
Speaker 4:  No, I'm saying there are aspects of New York that make it simpler. Yes. Than

814
00:39:40,005 --> 00:39:41,505
Speaker 4:  LA or whatever. Right? Like, So

815
00:39:41,505 --> 00:39:43,785
Speaker 3:  I think like Brooklyn makes a lot of sense.

816
00:39:44,795 --> 00:39:46,725
Speaker 4:  Just like no laws in Brooklyn, no laws in

817
00:39:46,845 --> 00:39:46,965
Speaker 1:  Brooklyn,

818
00:39:48,385 --> 00:39:51,765
Speaker 3:  But like, you go down Manhattan. Manhattan is gonna be tough for them. But

819
00:39:51,835 --> 00:39:55,365
Speaker 3:  whether there's a lot of reasons, I think. No, but I think we are gonna,

820
00:39:55,565 --> 00:39:58,955
Speaker 3:  I I think that 2025 is the year that

821
00:39:59,655 --> 00:40:00,955
Speaker 3:  me, I don't wanna say most people,

822
00:40:02,925 --> 00:40:05,885
Speaker 3:  A lot of people will go in Waymo's for their first time. Mm. Okay. And you'll

823
00:40:05,885 --> 00:40:07,645
Speaker 3:  see tons of it on social media.

824
00:40:08,795 --> 00:40:10,005
Speaker 1:  It's it's gonna have its moment.

825
00:40:10,005 --> 00:40:13,125
Speaker 3:  Yeah. It's gonna have its moment. Okay. Because like, I was in LA last week

826
00:40:13,125 --> 00:40:16,605
Speaker 3:  and everyone who was in LA was trying it. It was like a total viral thing.

827
00:40:16,745 --> 00:40:20,665
Speaker 3:  So it's coming to Austin. Phoenix. They're already

828
00:40:20,665 --> 00:40:23,665
Speaker 3:  in San Francisco. They're working on getting on highways. It's already in

829
00:40:23,685 --> 00:40:27,105
Speaker 3:  la. They expanded. It's gonna, people are gonna talk about it when they go

830
00:40:27,105 --> 00:40:27,825
Speaker 3:  to these cities. Okay.

831
00:40:28,105 --> 00:40:30,985
Speaker 1:  I like this one. I'm changing this to Waymo is going to have its moment.

832
00:40:31,555 --> 00:40:35,065
Speaker 4:  Waymo has a real problem though because their platform is the Jaguar I pace.

833
00:40:35,605 --> 00:40:39,385
Speaker 4:  Oh. And Jaguar has decided to just Yeah. Be an

834
00:40:39,385 --> 00:40:42,505
Speaker 4:  influencer company now or whatever it is. Like they need a new

835
00:42:28,905 --> 00:42:32,795
Speaker 1:  All right, we're back. Okay. I have a couple here that rhyme

836
00:42:33,035 --> 00:42:36,915
Speaker 1:  slightly with some of the stuff we were talking about last week. The first

837
00:42:36,935 --> 00:42:40,915
Speaker 1:  one I have here is the new Alexa is sick and everybody likes it.

838
00:42:42,155 --> 00:42:42,715
Speaker 3:  I like sick.

839
00:42:43,065 --> 00:42:45,315
Speaker 1:  It's sick. It's not just like, it

840
00:42:45,475 --> 00:42:46,395
Speaker 3:  Actually physically

841
00:42:46,395 --> 00:42:47,155
Speaker 1:  Gets sick. Sick.

842
00:42:48,105 --> 00:42:48,515
Speaker 4:  It's literal

843
00:42:48,855 --> 00:42:51,155
Speaker 1:  Cold's. Like my Alexa has been throwing up on me.

844
00:42:51,155 --> 00:42:53,075
Speaker 3:  It's so sentient. It's like, ugh,

845
00:42:53,385 --> 00:42:56,075
Speaker 4:  Wait, wait, I'm in. If we are like, it has an illness,

846
00:42:56,555 --> 00:42:57,755
Speaker 3:  I cannot send it timer

847
00:42:57,855 --> 00:43:01,235
Speaker 4:  If we're, if if it's sick, it's so cool. It's sick. I'm out.

848
00:43:01,235 --> 00:43:02,235
Speaker 1:  It's, it's so cool. It's sick.

849
00:43:02,655 --> 00:43:05,075
Speaker 4:  Has it appears to have an illness I'm in.

850
00:43:05,655 --> 00:43:09,195
Speaker 3:  It appears to have an illness and it's, so it's, it has such a strong

851
00:43:09,195 --> 00:43:12,835
Speaker 3:  personality that it develops sicknesses and

852
00:43:13,045 --> 00:43:16,075
Speaker 3:  colds and has Stomach Pro. It's like, oh, you ordered. I would say If you

853
00:43:16,075 --> 00:43:16,795
Speaker 3:  ordered too much Whole

854
00:43:16,795 --> 00:43:19,915
Speaker 1:  Foods, If you could set the character as just like your ill relative who

855
00:43:19,915 --> 00:43:20,915
Speaker 1:  lives with you, that would be incredible.

856
00:43:23,855 --> 00:43:26,075
Speaker 1:  And anytime you ask it for anything, it's like, ugh.

857
00:43:26,535 --> 00:43:29,395
Speaker 3:  Anyway, I'm totally in on Alexa having an illness. Okay.

858
00:43:29,395 --> 00:43:31,315
Speaker 4:  Yeah. Well, I think we're both, we're both picking illness.

859
00:43:31,665 --> 00:43:35,555
Speaker 1:  Yeah. I'm, I'm writing illness. I'm in on

860
00:43:35,555 --> 00:43:39,475
Speaker 1:  this one. My, I I think Amazon

861
00:43:39,475 --> 00:43:40,155
Speaker 1:  is, that

862
00:43:40,155 --> 00:43:43,955
Speaker 3:  Is actually a best case scenario for the launch is they, they put these in

863
00:43:43,955 --> 00:43:47,915
Speaker 3:  homes and it's so sentient and it's, and it, and it believes

864
00:43:47,915 --> 00:43:51,635
Speaker 3:  it's alive that it's like, sorry, I can't, I can't order the Whole Foods

865
00:43:51,725 --> 00:43:52,075
Speaker 3:  today.

866
00:43:54,325 --> 00:43:58,115
Speaker 3:  Sorry, I can't tell you if the package was delivered. Do you like my

867
00:43:58,295 --> 00:43:59,155
Speaker 3:  Oh, sick Alexa voice.

868
00:43:59,155 --> 00:43:59,955
Speaker 1:  That's pretty good. I

869
00:44:00,605 --> 00:44:02,555
Speaker 4:  Don't worry that if I react to it too much, it's racist.

870
00:44:06,505 --> 00:44:08,955
Speaker 4:  Like it's like a little too neurotic. You know what I mean? Yeah.

871
00:44:08,955 --> 00:44:10,635
Speaker 1:  Yeah. That's fair. All right. Well

872
00:44:10,635 --> 00:44:14,235
Speaker 4:  I could do anxious Indian mom. Yeah. Do it. Like, do you think that's gonna

873
00:44:14,235 --> 00:44:14,395
Speaker 4:  work?

874
00:44:16,955 --> 00:44:19,435
Speaker 3:  I think you need more of a stronger accent there, but I get You're not wanting

875
00:44:19,435 --> 00:44:20,755
Speaker 3:  to go racist. Okay.

876
00:44:20,755 --> 00:44:22,435
Speaker 1:  Should I go to med school? Yeah.

877
00:44:22,615 --> 00:44:23,035
Speaker 4:  See what I

878
00:44:23,035 --> 00:44:26,875
Speaker 1:  Mean? All right. Next up. Blue Sky is every bit as big

879
00:44:26,875 --> 00:44:27,515
Speaker 1:  as threads.

880
00:44:28,645 --> 00:44:30,765
Speaker 3:  I think it already kind of is. I don't know. Is it,

881
00:44:31,785 --> 00:44:34,965
Speaker 4:  You're having a real, what? Is everything existential crisis over there?

882
00:44:35,265 --> 00:44:37,885
Speaker 4:  No, absolutely not. They're gonna keep juicing the threads, numbers with

883
00:44:37,885 --> 00:44:41,805
Speaker 4:  Instagram forever. Is Blue Sky more relevant on threads?

884
00:44:41,905 --> 00:44:42,125
Speaker 4:  Yes.

885
00:44:43,455 --> 00:44:44,095
Speaker 3:  Relevant? Yeah.

886
00:44:44,325 --> 00:44:45,375
Speaker 4:  Because of the

887
00:44:45,375 --> 00:44:45,775
Speaker 3:  People that are there.

888
00:44:45,775 --> 00:44:47,895
Speaker 4:  Because of the people that are there. Is that where the conversation is?

889
00:44:48,005 --> 00:44:48,295
Speaker 4:  Okay.

890
00:44:48,565 --> 00:44:52,535
Speaker 1:  I'll, I'll allow both of these. So Blue Sky is more relevant than

891
00:44:52,535 --> 00:44:53,775
Speaker 1:  Threads, you're saying? Yeah. But

892
00:44:53,775 --> 00:44:56,495
Speaker 4:  Threads will be huge and Threads is just gonna be, it's already hundreds

893
00:44:56,495 --> 00:44:57,815
Speaker 4:  of millions of people, right? Yeah.

894
00:44:57,965 --> 00:45:01,695
Speaker 1:  It's, it's probably given what we've heard from earnings and since they're

895
00:45:01,815 --> 00:45:03,495
Speaker 1:  probably like knocking on the door of 300 million users.

896
00:45:03,645 --> 00:45:06,095
Speaker 4:  Yeah. That's, and they're gonna keep juicing it with Instagram and it's a

897
00:45:06,095 --> 00:45:09,855
Speaker 4:  creator platform and it will, that will be a thing. I think

898
00:45:09,855 --> 00:45:13,375
Speaker 4:  Blue Sky, who knows how big it will get. I'm very high on

899
00:45:13,485 --> 00:45:17,415
Speaker 4:  interop and Fed verse and all this stuff, but the, the ceiling

900
00:45:17,445 --> 00:45:21,335
Speaker 4:  that we know of is Twitter, which at its heyday was 325 million

901
00:45:21,335 --> 00:45:24,875
Speaker 4:  people. And So I think Threads can get bigger than that because they can

902
00:45:24,875 --> 00:45:26,395
Speaker 4:  just keep juicing it with Instagram.

903
00:45:27,475 --> 00:45:31,395
Speaker 1:  Hmm. That seems right to me. I think the threads is going to be so big and

904
00:45:31,415 --> 00:45:35,355
Speaker 1:  so integrated into Instagram that it's actually going to be more

905
00:45:35,915 --> 00:45:39,795
Speaker 1:  powerful than it would've been on its own. But I think the cool kids

906
00:45:39,795 --> 00:45:43,715
Speaker 1:  will be on Blue Sky and that matters like the what are, what are people on

907
00:45:43,715 --> 00:45:47,115
Speaker 1:  cable news going to read and put on the screen as they talk about it?

908
00:45:48,115 --> 00:45:51,915
Speaker 1:  I would bet on Blue Sky. Yeah. Over Threads. If it's those two

909
00:45:51,915 --> 00:45:53,755
Speaker 1:  against each other, I would bet on Blue Sky.

910
00:45:53,825 --> 00:45:57,475
Speaker 3:  Well, this goes back to your cable dying thing from last week.

911
00:45:57,615 --> 00:46:00,125
Speaker 3:  But I think those people continue to stay on X.

912
00:46:01,215 --> 00:46:04,205
Speaker 1:  Interesting. Okay. So the answer is kind of neither one.

913
00:46:04,965 --> 00:46:08,205
Speaker 3:  I I think it depends, but like, I hear what Neil is saying on the relevant,

914
00:46:08,635 --> 00:46:12,485
Speaker 3:  like, if, if it continues at this pace, and it can bring over people

915
00:46:12,555 --> 00:46:16,285
Speaker 3:  that are breaking news there, and it is more of the conversation, but they've

916
00:46:16,305 --> 00:46:20,125
Speaker 3:  got to keep, I mean, this is where the Reds has done a slightly better job,

917
00:46:20,125 --> 00:46:23,805
Speaker 3:  is getting politicians and celebrities and they've had those people, but

918
00:46:23,805 --> 00:46:27,445
Speaker 3:  they're not actively posting there. Right. So if they can build the

919
00:46:27,725 --> 00:46:31,485
Speaker 3:  relevancy on Blue Sky and get those people coming over and actually consistently

920
00:46:31,485 --> 00:46:33,325
Speaker 3:  posting, I'm in.

921
00:46:34,235 --> 00:46:34,965
Speaker 1:  Okay. It is,

922
00:46:35,365 --> 00:46:38,765
Speaker 4:  I don't think they're gonna say an X though. X has gonna have the same algorithmic

923
00:46:38,765 --> 00:46:39,765
Speaker 4:  brain rot as threads.

924
00:46:40,315 --> 00:46:40,605
Speaker 3:  Yeah.

925
00:46:41,055 --> 00:46:41,405
Speaker 4:  Right.

926
00:46:41,635 --> 00:46:43,565
Speaker 1:  It's just a different kind of gas leak social network. Yeah.

927
00:46:43,595 --> 00:46:46,565
Speaker 4:  Yeah. It's just like threads. Like I keep making this distinction and I probably

928
00:46:46,565 --> 00:46:50,235
Speaker 4:  need to like explain it better, but I think you have

929
00:46:50,385 --> 00:46:54,235
Speaker 4:  creator platforms now and you have social media platforms and like most

930
00:46:54,235 --> 00:46:57,755
Speaker 4:  things have become creator platforms where they're walled gardens. They're

931
00:46:57,755 --> 00:47:01,395
Speaker 4:  focused on keeping your engaged time on those sites high. They're algorithmic

932
00:47:01,575 --> 00:47:04,955
Speaker 4:  for you recommendations. They're entirely built around

933
00:47:04,955 --> 00:47:08,115
Speaker 4:  incentivizing creators to run content businesses on the terms of the platforms.

934
00:47:08,615 --> 00:47:11,635
Speaker 4:  That's threads. Got you. Like that's the shape of threads.

935
00:47:11,635 --> 00:47:15,275
Speaker 3:  Yeah. But you're talking old school social media. You go, you share your

936
00:47:15,275 --> 00:47:17,795
Speaker 3:  thing. You don't care if people leave. You're, you've got links. Yeah. You're,

937
00:47:17,795 --> 00:47:19,635
Speaker 3:  it's, it's a portal to the web. Right.

938
00:47:19,635 --> 00:47:22,715
Speaker 4:  Well, I mean that part is interesting, but the part where it's like, I'm

939
00:47:22,715 --> 00:47:24,755
Speaker 4:  going here to follow a bunch of people and see what they're talking about.

940
00:47:25,255 --> 00:47:27,355
Speaker 4:  And those people are not professional content creators

941
00:47:27,855 --> 00:47:30,605
Speaker 3:  And they're not totally like after the algorithm and juicing the

942
00:47:30,605 --> 00:47:34,085
Speaker 4:  Algorithm. Right. And so Blue Sky just is much more of that. And Twitter

943
00:47:34,115 --> 00:47:38,045
Speaker 4:  used to be that to whatever extent. Yeah. And I think that that

944
00:47:38,045 --> 00:47:41,885
Speaker 4:  is gonna be where that class of people wants to gather because the

945
00:47:42,245 --> 00:47:45,245
Speaker 4:  economics and the in incentives of creator platform algorithms

946
00:47:45,995 --> 00:47:46,285
Speaker 4:  just

947
00:47:46,595 --> 00:47:47,165
Speaker 3:  Make it that way.

948
00:47:47,195 --> 00:47:51,045
Speaker 4:  They just make it that way. And X is headed that way. Yep. In a, in like

949
00:47:51,085 --> 00:47:51,765
Speaker 4:  a meaningful,

950
00:47:52,565 --> 00:47:54,285
Speaker 3:  Explicit way. It's also like all they know how to do. Yeah.

951
00:47:54,625 --> 00:47:57,725
Speaker 4:  So I, and that's what Ellan wants, like Elon's, like just don't do lazy links,

952
00:47:57,725 --> 00:47:58,885
Speaker 4:  just like put your content on the X

953
00:47:59,045 --> 00:48:01,885
Speaker 1:  Platform. I was just gonna say, I keep being really struck by how meaningful

954
00:48:01,925 --> 00:48:04,085
Speaker 1:  a thing it is that Blue Sky is the only one that's like, we love when you

955
00:48:04,085 --> 00:48:07,205
Speaker 1:  link to stuff. Yeah. It's like there's a whole group of people on the internet

956
00:48:07,205 --> 00:48:10,965
Speaker 1:  who are very important who just link to stuff. Yeah. And, and if all of those

957
00:48:10,965 --> 00:48:13,565
Speaker 1:  people go to Blue Sky like that, that's a pretty meaningful thing.

958
00:48:13,565 --> 00:48:16,645
Speaker 4:  Yeah. But I don't know if that, that ceiling is bigger than 325 million people.

959
00:48:16,955 --> 00:48:17,245
Speaker 4:  Yeah.

960
00:48:17,695 --> 00:48:18,645
Speaker 1:  Maybe not. Hmm.

961
00:48:18,645 --> 00:48:20,045
Speaker 4:  Like that was as big as Twitter ever got.

962
00:48:22,005 --> 00:48:25,155
Speaker 3:  Comes back to my prediction from last week. We're all going to be just posting

963
00:48:25,155 --> 00:48:25,635
Speaker 3:  everywhere.

964
00:48:25,905 --> 00:48:27,275
Speaker 1:  Yeah. I'm with you. But

965
00:48:27,275 --> 00:48:29,515
Speaker 3:  Hopefully there's a system where it's

966
00:48:29,515 --> 00:48:32,235
Speaker 1:  Easy. Yeah. All right. Two more and then we're outta here. Apple launched

967
00:48:32,255 --> 00:48:35,235
Speaker 1:  the search engine. Call it, it, it doesn't have to look exactly like Google,

968
00:48:35,295 --> 00:48:37,115
Speaker 1:  but it is recognizably a web search engine.

969
00:48:38,375 --> 00:48:38,595
Speaker 4:  Yes.

970
00:48:39,655 --> 00:48:39,945
Speaker 1:  Yeah.

971
00:48:40,455 --> 00:48:43,505
Speaker 4:  Apple's gonna start to hedge and the AI will give them the cover to Hedge.

972
00:48:43,505 --> 00:48:43,865
Speaker 4:  Yeah, I

973
00:48:43,865 --> 00:48:47,585
Speaker 3:  Was gonna say, I think yes, but it's under the guise of AI

974
00:48:48,635 --> 00:48:52,415
Speaker 3:  and it might link into, you might be able to search chat GBT or

975
00:48:52,555 --> 00:48:56,415
Speaker 3:  Gemini or I don't know, Claude, whatever businesses they actually partner

976
00:48:56,415 --> 00:48:59,535
Speaker 3:  with. I think we're gonna see those partnerships happen this year. And so

977
00:48:59,535 --> 00:49:00,615
Speaker 3:  that's their answer to search.

978
00:49:01,395 --> 00:49:02,765
Speaker 1:  Do you think they do it? I think

979
00:49:02,765 --> 00:49:06,685
Speaker 3:  Apple will also knows people are using these apps, these AI apps as search.

980
00:49:06,995 --> 00:49:10,045
Speaker 3:  Yeah. Oh yeah. So they're getting ahead of that and they will, well, they'll

981
00:49:10,045 --> 00:49:11,525
Speaker 3:  be a little bit behind that in some ways.

982
00:49:12,735 --> 00:49:16,565
Speaker 4:  Apple also has a giant library of content that they

983
00:49:16,695 --> 00:49:20,605
Speaker 4:  don't really expose to anyone. And Apple News, like if what you want is like

984
00:49:20,605 --> 00:49:22,965
Speaker 4:  a bunch of recipes, they're in Apple News. Apple,

985
00:49:23,085 --> 00:49:26,855
Speaker 3:  I think this is a year for Apple News. Like more happens

986
00:49:26,875 --> 00:49:30,725
Speaker 3:  in Apple News or more hooks into Apple News to your

987
00:49:30,725 --> 00:49:33,165
Speaker 3:  point. Yeah. I mean it's just because I think that, I think Apple News is

988
00:49:33,165 --> 00:49:36,365
Speaker 3:  another place with that home display where they can really take advantage

989
00:49:36,365 --> 00:49:36,645
Speaker 3:  of it.

990
00:49:37,025 --> 00:49:39,485
Speaker 4:  Oh, for sure. Yeah. And, and if your thing is like the web is getting poisoned

991
00:49:39,485 --> 00:49:42,085
Speaker 4:  and search is bad and that thing, you're like, well, I'll just point to people

992
00:49:42,475 --> 00:49:44,245
Speaker 4:  Yeah. To high quality content to

993
00:49:44,245 --> 00:49:44,725
Speaker 3:  The source.

994
00:49:45,365 --> 00:49:48,365
Speaker 4:  I mean, If you go look at what's trending Apple News, you will Yeah. I'm,

995
00:49:48,505 --> 00:49:48,805
Speaker 3:  I'm aware.

996
00:49:49,105 --> 00:49:52,005
Speaker 4:  I'm aware. It's, it's like a lot of like old people yelling at stuff, you

997
00:49:52,005 --> 00:49:55,965
Speaker 4:  know, like the number one story at Apple is always a Buzzfeed article

998
00:49:55,965 --> 00:49:57,205
Speaker 4:  that's like, why are these kids stupid?

999
00:49:57,315 --> 00:49:59,885
Speaker 3:  It's our like a Huffington Post thing that's like ripped off three times

1000
00:50:00,115 --> 00:50:00,925
Speaker 3:  from something else.

1001
00:50:02,145 --> 00:50:05,125
Speaker 4:  You can really get a sense of who a platforms users are. Yeah. By the most

1002
00:50:05,125 --> 00:50:06,485
Speaker 4:  popular post on the platform.

1003
00:50:06,755 --> 00:50:09,365
Speaker 1:  Yeah. I, I'm out on this one just because I think

1004
00:50:11,305 --> 00:50:14,725
Speaker 1:  the $20 billion from Google really spends, and I think if you're Apple

1005
00:50:16,045 --> 00:50:19,985
Speaker 1:  trying to balance those two things, you're just gonna land

1006
00:50:20,105 --> 00:50:22,385
Speaker 1:  on the side of we're gonna keep taking the money as long as the money is

1007
00:50:22,385 --> 00:50:22,505
Speaker 1:  here.

1008
00:50:23,125 --> 00:50:26,385
Speaker 3:  And Yeah. I mean it doesn't necessarily mean they like change what happens

1009
00:50:26,385 --> 00:50:30,045
Speaker 3:  through Safari search. I just think they're going to, maybe they don't call

1010
00:50:30,045 --> 00:50:30,525
Speaker 3:  it search,

1011
00:50:30,745 --> 00:50:33,445
Speaker 1:  But it was part of, part of the stuff that came up during the search trial

1012
00:50:33,505 --> 00:50:36,445
Speaker 1:  was essentially Apple agreeing not to launch a search engine while they had

1013
00:50:36,445 --> 00:50:39,085
Speaker 1:  these deals. So I think that stuff is just, I think, gonna take a while to

1014
00:50:39,085 --> 00:50:42,965
Speaker 1:  unwind. I think If you gave me like three years instead of one year, I would

1015
00:50:43,465 --> 00:50:47,375
Speaker 1:  say yes, but I don't know. Doesn't seem

1016
00:50:47,375 --> 00:50:50,175
Speaker 1:  like it's gonna happen this fast. But you also may be right that like they're

1017
00:50:50,175 --> 00:50:53,775
Speaker 1:  one button away from the chat GPT integration. Yeah. Just being live web

1018
00:50:53,775 --> 00:50:55,055
Speaker 1:  search. Like it just could happen.

1019
00:50:55,285 --> 00:50:57,295
Speaker 3:  It's really slow and bothersome anyway.

1020
00:50:57,495 --> 00:51:00,775
Speaker 1:  Agreed. Okay, last one. The Nintendo Switch came out,

1021
00:51:01,275 --> 00:51:03,335
Speaker 1:  and I hate to break this to you, but it's kind of a bust.

1022
00:51:04,995 --> 00:51:08,855
Speaker 4:  Ooh, that's tough. It all, it all

1023
00:51:08,855 --> 00:51:09,895
Speaker 4:  depends on the packing game.

1024
00:51:12,015 --> 00:51:15,115
Speaker 4:  No, I'm out. There's no way They, they, they, they won't blow it. That's,

1025
00:51:15,115 --> 00:51:16,235
Speaker 4:  that's too outta character for

1026
00:51:16,235 --> 00:51:19,795
Speaker 1:  Nintendo. I don't know. The Weu exists. They did, they did do the Weu.

1027
00:51:22,545 --> 00:51:23,845
Speaker 4:  No, not still out. No.

1028
00:51:23,985 --> 00:51:27,645
Speaker 1:  All right. I I, I wanna believe I'm saying,

1029
00:51:27,825 --> 00:51:31,725
Speaker 1:  I'm saying no just because I am at this

1030
00:51:31,725 --> 00:51:35,325
Speaker 1:  moment avoiding buying a PS five because I want the new switch very badly.

1031
00:51:35,625 --> 00:51:39,365
Speaker 1:  And if it sucks, I'm going to have wasted six months of not buying a game

1032
00:51:39,365 --> 00:51:41,005
Speaker 1:  console. So I need the new

1033
00:51:41,005 --> 00:51:41,845
Speaker 3:  Switch. Is the switch supposed to come out

1034
00:51:43,405 --> 00:51:47,085
Speaker 1:  Sometime before the end of March was what Nintendo promised.

1035
00:51:47,185 --> 00:51:50,285
Speaker 1:  So like with, we're, we're, we're in the sort of any minute now phase

1036
00:51:51,545 --> 00:51:52,835
Speaker 3:  That changes some things for me.

1037
00:51:54,865 --> 00:51:58,145
Speaker 3:  Hmm. They couldn't get it out before holiday anyway. I, I have no, maybe

1038
00:51:58,145 --> 00:51:58,305
Speaker 3:  that's

1039
00:51:58,505 --> 00:51:58,905
Speaker 1:  'cause it sucks

1040
00:51:58,905 --> 00:52:00,785
Speaker 3:  This's the first time I'm hearing of this, So I I do not,

1041
00:52:00,945 --> 00:52:01,745
Speaker 4:  I don't dunno what video games are,

1042
00:52:02,265 --> 00:52:05,265
Speaker 3:  Whatever video games I'm gonna learn soon. 'cause I have a kid that finally

1043
00:52:05,265 --> 00:52:06,145
Speaker 3:  into video games.

1044
00:52:06,285 --> 00:52:07,105
Speaker 1:  You gonna buy him a switch?

1045
00:52:07,415 --> 00:52:08,465
Speaker 3:  Well, I was going to,

1046
00:52:08,805 --> 00:52:09,585
Speaker 1:  But maybe it sucks,

1047
00:52:09,885 --> 00:52:11,545
Speaker 3:  But now I'm waiting 'cause I don't know.

1048
00:52:13,575 --> 00:52:13,695
Speaker 4:  Hmm.

1049
00:52:14,255 --> 00:52:15,415
Speaker 1:  I will say I have,

1050
00:52:15,475 --> 00:52:16,375
Speaker 3:  So I should wait now.

1051
00:52:16,435 --> 00:52:19,735
Speaker 1:  The current switch and it is slow and I would very much like the new one

1052
00:52:19,735 --> 00:52:20,375
Speaker 1:  to be faster.

1053
00:52:20,635 --> 00:52:23,655
Speaker 3:  I'm sure they'll do that. You would hope So. I'm waiting then.

1054
00:52:24,385 --> 00:52:26,875
Speaker 3:  Yeah. It's successful because I have bought one.

1055
00:52:29,335 --> 00:52:32,795
Speaker 4:  You've already bought one. Perfect. No, there's no way that it's a bust.

1056
00:52:33,065 --> 00:52:36,755
Speaker 1:  Okay, great. I hope, I hope we're right. Yeah. I believe in all of us. All

1057
00:52:36,755 --> 00:52:39,555
Speaker 1:  right. I, this is too many things to go back over. I'm gonna put all the

1058
00:52:39,555 --> 00:52:42,435
Speaker 1:  results in the show notes, but thank you both. This is delightful.

1059
00:52:43,455 --> 00:52:46,555
Speaker 1:  We agreed more than I wanted to, but it's okay. We did all right.

1060
00:52:46,775 --> 00:52:49,995
Speaker 3:  You seem like you've had a great year. I've won. 2025 was good to you, David.

1061
00:52:49,995 --> 00:52:53,835
Speaker 1:  2025. Listen, it's been complicated. Yeah. I've forgotten some of the details,

1062
00:52:54,895 --> 00:52:57,795
Speaker 1:  but I'm killing it. Yeah, that's all I can tell you. Yeah, you, I'm on top

1063
00:52:57,795 --> 00:52:57,995
Speaker 1:  of the world.

1064
00:52:57,995 --> 00:52:59,995
Speaker 3:  You still fitting your clothes from 2024? I,

1065
00:53:00,115 --> 00:53:04,075
Speaker 1:  I have been wearing this sweater for 365 days and no one has noticed until

1066
00:53:04,075 --> 00:53:04,675
Speaker 1:  you just now

1067
00:53:04,905 --> 00:53:08,115
Speaker 3:  It's just, you own that many versions of that sweater. It's a good year for

1068
00:53:08,115 --> 00:53:08,235
Speaker 3:  you.

1069
00:53:09,095 --> 00:53:09,835
Speaker 1:  All right, thank you both.

1070
00:53:11,745 --> 00:53:15,675
Speaker 1:  Alright, that is it for The Vergecast today, and that's it for our two part

1071
00:53:15,785 --> 00:53:19,635
Speaker 1:  mini series about 2025. Thank you to Neli and Joanna for

1072
00:53:19,635 --> 00:53:23,155
Speaker 1:  doing this deeply silly thing with me. And thank you As always for listening.

1073
00:53:23,275 --> 00:53:27,245
Speaker 1:  I hope this was fun. I really enjoyed doing these two. We just got to

1074
00:53:27,245 --> 00:53:31,085
Speaker 1:  have some wild speculation time and that is rare in this

1075
00:53:31,245 --> 00:53:34,725
Speaker 1:  business. We had a good time. There is lots more on all of this at The Verge

1076
00:53:34,745 --> 00:53:38,165
Speaker 1:  dot com and there's going to be lots more on all of this for the next year.

1077
00:53:38,325 --> 00:53:42,245
Speaker 1:  I think inside of these two episodes, you can sort of see what we're thinking

1078
00:53:42,245 --> 00:53:45,765
Speaker 1:  about for the next year. A lot's gonna change. A lot's gonna happen.

1079
00:53:46,535 --> 00:53:49,845
Speaker 1:  We're probably not going to Mars in 2025, but a lot of things are gonna happen

1080
00:53:50,145 --> 00:53:53,525
Speaker 1:  and we're gonna be covering it all. So keep it locked on The Verge dot com.

1081
00:53:53,835 --> 00:53:57,045
Speaker 1:  It's a good website. I'm slightly biased, but I kinda like it. And As always,

1082
00:53:57,045 --> 00:54:00,925
Speaker 1:  If you have thoughts, questions, feelings, or other things that you definitely

1083
00:54:01,145 --> 00:54:05,125
Speaker 1:  for sure a hundred percent think are gonna happen in 2025, you can always

1084
00:54:05,125 --> 00:54:08,605
Speaker 1:  email us at Vergecast to The Verge dot com or call the hotline eight six six

1085
00:54:08,765 --> 00:54:12,685
Speaker 1:  VERGE one one. We truly, truly love hearing from you. We're gonna do a couple

1086
00:54:12,685 --> 00:54:16,365
Speaker 1:  more hotlines at the end of this year and then we have a big plan for all

1087
00:54:16,365 --> 00:54:20,165
Speaker 1:  of the stuff we're gonna get to do next year. So keep calling, keep emailing,

1088
00:54:20,755 --> 00:54:23,965
Speaker 1:  keep it locked on The Vergecast. This show is produced by Liam James Wil

1089
00:54:23,965 --> 00:54:26,965
Speaker 1:  Pour and Eric Gomez. The Vergecast is VERGE Production and part of the Vox

1090
00:54:26,965 --> 00:54:30,885
Speaker 1:  Media podcast network. We'll be back on Tuesday and Friday with your regularly

1091
00:54:30,885 --> 00:54:33,885
Speaker 1:  scheduled programming. We are nearing the end of the year and we're gonna

1092
00:54:33,885 --> 00:54:36,325
Speaker 1:  take a break at the end of the year, but we got a couple more fun things

1093
00:54:36,325 --> 00:54:39,085
Speaker 1:  for you before we do. We'll see you then. Rock and roll

1094
00:54:48,115 --> 00:54:51,845
Speaker 2:  Support for The Vergecast comes from Polestar Pole Star's. First, all

1095
00:54:52,085 --> 00:54:55,725
Speaker 2:  electric SUV Polestar three is now on the roads across the US

1096
00:54:56,145 --> 00:54:59,405
Speaker 2:  and it's ready to make an impression. It's got a sleek

1097
00:54:59,475 --> 00:55:02,965
Speaker 2:  aerodynamic exterior and a spacious, minimalist interior.

1098
00:55:03,585 --> 00:55:07,045
Speaker 2:  Its custom developed. Android Automotive OS is totally integrated

1099
00:55:07,395 --> 00:55:10,885
Speaker 2:  made to enhance your driving experience. That includes an intuitive

1100
00:55:10,885 --> 00:55:14,725
Speaker 2:  infotainment screen, smart voice controls, and over the air updates.

1101
00:55:15,065 --> 00:55:18,525
Speaker 2:  And you can have Google Turn on your favorite podcast whenever you want to

1102
00:55:18,525 --> 00:55:22,445
Speaker 2:  be immersed in 3D surround sound by Bowers and Wilkins. See what

1103
00:55:22,445 --> 00:55:25,965
Speaker 2:  else Polestar three has to offer when you test drive at your local Polestar

1104
00:55:25,965 --> 00:55:28,605
Speaker 2:  space. Book yours today@polestar.com.

