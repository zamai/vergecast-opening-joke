1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: edfc3328-2c7d-4baa-9014-ced03ac19c37
Status: Done
Stage: Done
Title: How Planet Earth — and the Netflix homepage — get made
Audio URL: https://jfe93e.s3.amazonaws.com/-5749970406947952433/1287900301963792438/s93290-US-6076s-1701246874.mp3
Description: Today on the flagship podcast of multi-drone camera setups:
03:19 - The Verge's David Pierce chats with Planet Earth III producer Alex Walters and director Theo Webb about the gear used to make the latest nature documentary series.
30:13 - Netflix's Pat Flemming joins the show to discuss how Netflix figures out what to show when you open the app, and how to keep you coming back.
1:20:29 -The Verge's publisher Helen Havlak and editor-in-chief Nilay Patel join the show to answer this week's hotline question.

Email us at vergecast@theverge.com or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Enabled (8 ads detected)

2
00:00:02,515 --> 00:00:06,165
Speaker 2:  Welcome To The Vergecast, the flagship podcast of multi drone camera

3
00:00:06,265 --> 00:00:10,085
Speaker 2:  setups. I'm your friend David Pierce, and I am currently sitting here at

4
00:00:10,085 --> 00:00:13,885
Speaker 2:  my desk comparison shopping monitors, So I. Do this thing

5
00:00:13,885 --> 00:00:17,765
Speaker 2:  where I would say once every nine months or So I get this

6
00:00:17,795 --> 00:00:21,365
Speaker 2:  idea in my head that what I need is a different number of

7
00:00:21,395 --> 00:00:25,365
Speaker 2:  screens of different size. Sometimes I'm like, I'm just gonna be a laptop

8
00:00:25,385 --> 00:00:29,285
Speaker 2:  guy. I'm gonna be more focused. I'm just gonna sit here and look at

9
00:00:29,285 --> 00:00:32,885
Speaker 2:  this one small screen. It's gonna keep me on task, it's gonna be great. That

10
00:00:32,885 --> 00:00:36,525
Speaker 2:  never works. So then I'm like, okay, I'm gonna have a command station.

11
00:00:36,785 --> 00:00:39,805
Speaker 2:  I'm gonna get a bunch of monitors. One of them is gonna be vertical, one

12
00:00:39,805 --> 00:00:42,565
Speaker 2:  of them is gonna be curved, one of 'em is gonna be humongous. I'm gonna get

13
00:00:42,565 --> 00:00:45,805
Speaker 2:  so much done. You're gonna freak out. You don't even know that doesn't work

14
00:00:45,805 --> 00:00:49,445
Speaker 2:  either. And then eventually I end up back at one monitor.

15
00:00:49,575 --> 00:00:53,525
Speaker 2:  Right now I have 1 24 inch, 4K monitor. I've had this for the

16
00:00:53,525 --> 00:00:57,245
Speaker 2:  last year or so. It works fine, but it's starting to feel kind of

17
00:00:57,665 --> 00:01:01,365
Speaker 2:  small. So what I'm gonna do next is attempt to not

18
00:01:01,785 --> 00:01:05,485
Speaker 2:  swing one way or the other on this pendulum, but just add one more

19
00:01:05,815 --> 00:01:09,725
Speaker 2:  monitor, maybe 27 inches, maybe 24. Everything's on sale.

20
00:01:09,725 --> 00:01:13,685
Speaker 2:  Who knows? Anyway, we have an awesome show coming up for you today. Today

21
00:01:13,685 --> 00:01:16,285
Speaker 2:  turned out to be one of those episodes where we're kind of accidentally on

22
00:01:16,285 --> 00:01:20,085
Speaker 2:  a theme, and I would say the theme is How Stuff Appears on

23
00:01:20,085 --> 00:01:23,525
Speaker 2:  your television. We're gonna talk to the folks who made Planet Earth,

24
00:01:23,805 --> 00:01:27,685
Speaker 2:  the documentary series from the B, B, C, all about the technology it takes

25
00:01:27,685 --> 00:01:31,485
Speaker 2:  to make that show and to get into the lives of

26
00:01:31,585 --> 00:01:35,565
Speaker 2:  animals and the Planet. Then we're gonna talk to Pat Flemming, who is

27
00:01:35,565 --> 00:01:39,245
Speaker 2:  one of the heads of product at Netflix, all about recommendations and basically

28
00:01:39,675 --> 00:01:43,125
Speaker 2:  what it takes to show you exactly what you wanna watch

29
00:01:43,465 --> 00:01:47,125
Speaker 2:  at exactly the right time. It's much harder and much higher stakes

30
00:01:47,195 --> 00:01:50,445
Speaker 2:  than you might think. All of that is coming up in just a second. But first

31
00:01:50,845 --> 00:01:54,645
Speaker 2:  I have to figure out if this Asus monitor I'm looking at is different

32
00:01:54,645 --> 00:01:57,765
Speaker 2:  from this other assu monitor I'm looking at, because I've been staring at

33
00:01:57,765 --> 00:02:01,165
Speaker 2:  these two pages for 10 minutes and I just realized they might be the same

34
00:02:01,165 --> 00:02:04,485
Speaker 2:  monitor. That's how this is going. This is The Vergecast. See you in a sec.

35
00:03:19,945 --> 00:03:23,635
Speaker 2:  Welcome back. The thing you should know before we get into this segment

36
00:03:23,895 --> 00:03:27,355
Speaker 2:  is that I'm kind of obsessed with the TV series, Planet Earth.

37
00:03:27,975 --> 00:03:31,515
Speaker 6:  We can now show life on our Planet in entirely new ways.

38
00:03:33,445 --> 00:03:36,915
Speaker 6:  Bring you closer to animals than ever before

39
00:03:37,775 --> 00:03:41,595
Speaker 6:  and reveal new wildlife dramas for the

40
00:03:41,595 --> 00:03:42,435
Speaker 6:  very first time.

41
00:03:43,735 --> 00:03:47,675
Speaker 2:  The truth is, I'll watch anything that's just like slow moving drone

42
00:03:47,685 --> 00:03:51,555
Speaker 2:  shots of beautiful landscapes and then super tight shots of animals

43
00:03:51,555 --> 00:03:55,395
Speaker 2:  while someone talks in a cool accent about a whole part of the

44
00:03:55,395 --> 00:03:58,675
Speaker 2:  earth I've never heard of before, and there are a lot of those shows out

45
00:03:58,675 --> 00:04:02,515
Speaker 2:  there, but Planet Earth does it better than everybody else. I mean, just

46
00:04:02,515 --> 00:04:05,555
Speaker 2:  like listen to this clip for a second from Planet Earth too.

47
00:04:06,215 --> 00:04:09,115
Speaker 6:  He listens carefully to pinpoint his target.

48
00:04:11,905 --> 00:04:12,595
Speaker 6:  It's moving

49
00:04:25,315 --> 00:04:25,675
Speaker 6:  a vo.

50
00:04:26,435 --> 00:04:30,315
Speaker 2:  I mean, come on. That is the stuff right there. I love it. Anyway, the

51
00:04:30,315 --> 00:04:33,995
Speaker 2:  third Planet Earth series is out now. It's been seven years since season

52
00:04:34,015 --> 00:04:37,835
Speaker 2:  two aired, and now we get more Planet Earth and I mean, this is not a spoiler

53
00:04:37,835 --> 00:04:41,475
Speaker 2:  and it's not surprising, but it's awesome. And it's actually a really fun

54
00:04:41,875 --> 00:04:45,515
Speaker 2:  snapshot of technology progress too. These folks spend years

55
00:04:45,615 --> 00:04:49,555
Speaker 2:  trying to access new places and get new kinds of shots and tell

56
00:04:49,815 --> 00:04:53,755
Speaker 2:  new stories about the world in different kinds of ways. And so much of that

57
00:04:53,755 --> 00:04:57,195
Speaker 2:  is actually about technology. So I called up two of the people who worked

58
00:04:57,195 --> 00:05:00,995
Speaker 2:  on Planet Earth, three Theo Webb and Alex Walters. To get into the

59
00:05:00,995 --> 00:05:03,795
Speaker 2:  weeds a bit about the tech involved in making a series like this.

60
00:05:04,295 --> 00:05:08,075
Speaker 7:  I'm Theo Webb. I am a producer director on the Extremes

61
00:05:08,075 --> 00:05:09,355
Speaker 7:  episode of Planet Earth three.

62
00:05:09,855 --> 00:05:13,715
Speaker 8:  My name's Alex Walters and I'm an assistant producer on Planet Earth.

63
00:05:13,715 --> 00:05:13,955
Speaker 8:  Three

64
00:05:14,425 --> 00:05:17,995
Speaker 2:  Between them, they've basically seen how all of the sausage gets made.

65
00:05:18,315 --> 00:05:21,435
Speaker 2:  I had this theory when I started watching Planet Earth three, that the big

66
00:05:21,435 --> 00:05:25,195
Speaker 2:  difference is going to be how much less gear was involved in making every

67
00:05:25,195 --> 00:05:28,955
Speaker 2:  episode. Maybe they'd shoot everything on smartphones, and certainly the

68
00:05:28,975 --> 00:05:32,675
Speaker 2:  big cameras would be smaller and more maneuverable. Maybe you can shoot with

69
00:05:32,675 --> 00:05:36,435
Speaker 2:  like a phone, A-D-S-L-R and a DJ I drone and boom,

70
00:05:36,495 --> 00:05:39,675
Speaker 2:  you're done. But then you watch the behind the scenes at the end of every

71
00:05:39,675 --> 00:05:43,395
Speaker 2:  episode and no, it's still a ton of gear.

72
00:05:43,465 --> 00:05:47,435
Speaker 2:  There's one whole thing that's just a panning shot of all the

73
00:05:47,675 --> 00:05:51,595
Speaker 2:  batteries they had to charge, and it's terrifying to look at. And Theo

74
00:05:51,595 --> 00:05:54,555
Speaker 2:  said, actually, if anything, it's more gear this time.

75
00:05:55,055 --> 00:05:58,925
Speaker 7:  Oh, and like a hundred percent we need, we needed so much stuff. We wanted

76
00:05:58,925 --> 00:06:02,565
Speaker 7:  to film macro, we wanted to kind of get as much moving imagery as possible,

77
00:06:02,835 --> 00:06:06,805
Speaker 7:  sliders, et cetera. We weren't quite sure what tool would be, right. And

78
00:06:07,085 --> 00:06:10,925
Speaker 7:  actually we took a lot of stuff, but almost all of it we used actually

79
00:06:10,945 --> 00:06:14,805
Speaker 7:  for at least one shot. Some of the times, yes, you take a bit of kit out

80
00:06:14,805 --> 00:06:18,725
Speaker 7:  to a location and you know it sits in a box and you're like, well, that

81
00:06:18,725 --> 00:06:22,365
Speaker 7:  was a waste of time and effort. But on this occasion, actually,

82
00:06:22,505 --> 00:06:26,045
Speaker 7:  the poor people that carried it round the cave, they did not do it in vain.

83
00:06:26,145 --> 00:06:29,285
Speaker 7:  It was worthwhile. Like there was so much reused. But the funny thing is

84
00:06:29,565 --> 00:06:33,365
Speaker 7:  a lot of that behind the scenes segment that was actually shot

85
00:06:33,365 --> 00:06:37,165
Speaker 7:  with iPhone. And we found that because

86
00:06:37,165 --> 00:06:40,845
Speaker 7:  there's that inbuilt software that's processing the images so much more

87
00:06:40,845 --> 00:06:44,685
Speaker 7:  clearly than let's say, a camcorder, which is just basically built for, for

88
00:06:44,685 --> 00:06:48,125
Speaker 7:  outdoor use that we would normally take as a behind the scenes camera. The

89
00:06:48,125 --> 00:06:51,565
Speaker 7:  iPhone was processing it and you could just get that live feedback of what

90
00:06:51,565 --> 00:06:54,885
Speaker 7:  you're filming and it dealt with the noise and with the low light so well

91
00:06:54,885 --> 00:06:57,965
Speaker 7:  that that actually became the easiest thing. It meant you've got it in your

92
00:06:57,965 --> 00:07:01,925
Speaker 7:  pocket. And I dream of the day that we can just take that out as our main

93
00:07:01,925 --> 00:07:03,365
Speaker 7:  make off camera. So easy.

94
00:07:03,855 --> 00:07:07,725
Speaker 2:  Maybe by Planet Earth four, when I guess we'll be on the iPhone 22,

95
00:07:08,335 --> 00:07:12,205
Speaker 2:  it'll be fully up for the task. Probably not, but we can hope for

96
00:07:12,205 --> 00:07:15,965
Speaker 2:  now though, making a show like this is still an incredible amount of work

97
00:07:16,345 --> 00:07:20,165
Speaker 2:  and an incredible amount of specialized equipment like the microphones

98
00:07:20,165 --> 00:07:23,925
Speaker 2:  that Alex and a crew use to capture these tiny things called

99
00:07:24,075 --> 00:07:26,285
Speaker 2:  tree hoppers. In an episode titled Forests,

100
00:07:29,395 --> 00:07:32,605
Speaker 6:  This Tree Hopper mother communicates with her young,

101
00:07:34,125 --> 00:07:37,965
Speaker 6:  encouraging them to stay together so that she can protect

102
00:07:37,965 --> 00:07:38,165
Speaker 6:  them.

103
00:07:40,535 --> 00:07:44,085
Speaker 2:  These things are the size of a pinhead, so they're not easy to find

104
00:07:44,345 --> 00:07:48,125
Speaker 2:  or capture at all. So what Alex and the other producers do

105
00:07:48,185 --> 00:07:52,005
Speaker 2:  in a situation like that is they talk to researchers and scientists who

106
00:07:52,005 --> 00:07:55,885
Speaker 2:  know these animals really well and know where they'll be and how to

107
00:07:56,085 --> 00:07:59,925
Speaker 2:  interact with them. They're actually, as a result, sometimes able to storyboard

108
00:07:59,985 --> 00:08:03,925
Speaker 2:  the shots they're going to get knowing how these animals work. But to be

109
00:08:03,925 --> 00:08:06,245
Speaker 2:  fair, it really never seems to go to plan at all.

110
00:08:06,925 --> 00:08:10,725
Speaker 8:  I was talking to a scientist in America called Rex Kroft, who

111
00:08:10,725 --> 00:08:14,285
Speaker 8:  is an absolute genius and he spends his life listening

112
00:08:14,505 --> 00:08:18,285
Speaker 8:  in on conversations between animals, specifically tree hoppers.

113
00:08:18,585 --> 00:08:22,485
Speaker 8:  So he was really key to this and he helped us develop the technology

114
00:08:22,485 --> 00:08:26,365
Speaker 8:  to be able to listen in on them. And then alongside that, we had

115
00:08:26,625 --> 00:08:30,365
Speaker 8:  Javier, who was our specialist, he's a, he's a photographer

116
00:08:30,645 --> 00:08:34,365
Speaker 8:  actually, and he was the one who brought this story to us about the tree

117
00:08:34,365 --> 00:08:38,045
Speaker 8:  hoppers interacting with this symbiotic relationship with

118
00:08:38,235 --> 00:08:41,885
Speaker 8:  bees. They're like bodyguards. These bees come in and protect the tree hoppers.

119
00:08:41,885 --> 00:08:45,685
Speaker 8:  So actually it was a combination of different scientists and I

120
00:08:45,685 --> 00:08:48,885
Speaker 8:  spent a lot of time talking to them and planning in advance for the shoot.

121
00:08:49,065 --> 00:08:53,045
Speaker 8:  But the tree hoppers, it's inaudible to the human ear. So we use

122
00:08:53,045 --> 00:08:56,765
Speaker 8:  these pizo discs that we would attach the microphone

123
00:08:56,945 --> 00:09:00,925
Speaker 8:  and we would put them on the branches to be able to listen in on this

124
00:09:00,935 --> 00:09:04,485
Speaker 8:  world of these tiny little insects while they communicate to each other.

125
00:09:04,635 --> 00:09:08,165
Speaker 8:  They all have different language. There's over 3000 species and they all

126
00:09:08,525 --> 00:09:11,365
Speaker 8:  communicate with different sounds and they mean different things. So some

127
00:09:11,365 --> 00:09:15,085
Speaker 8:  of them talk to each other about finding a mate. Some of them

128
00:09:15,435 --> 00:09:19,005
Speaker 8:  tell at each other where food sources are. Others will talk about where

129
00:09:19,285 --> 00:09:22,845
Speaker 8:  predators are, which is part of the sequence that we filmed. So they are

130
00:09:23,165 --> 00:09:26,285
Speaker 8:  absolutely fascinating and their sounds are really bizarre. They sound like

131
00:09:26,285 --> 00:09:27,645
Speaker 8:  they're out of space or something.

132
00:09:28,255 --> 00:09:32,165
Speaker 2:  There are stories like this for basically every single frame

133
00:09:32,265 --> 00:09:36,005
Speaker 2:  and moment of Planet earth. Like there's this one shot in the extremes episode

134
00:09:36,015 --> 00:09:39,525
Speaker 2:  where we're inside this huge colony of butterflies,

135
00:09:39,565 --> 00:09:43,005
Speaker 2:  hundreds of thousands of them all hunkered down for the winter.

136
00:09:43,465 --> 00:09:46,765
Speaker 2:  And if you disturb these butterflies, you're gonna send thousands of them

137
00:09:46,945 --> 00:09:50,565
Speaker 2:  flying off, which A ruins the shot. And B also probably

138
00:09:50,615 --> 00:09:54,205
Speaker 2:  kills a lot of the butterflies. So you end up having to get creative

139
00:09:54,385 --> 00:09:55,925
Speaker 2:  trying to figure out how to get in there.

140
00:09:56,545 --> 00:10:00,125
Speaker 7:  The fun thing about this shoot is it relied on a very specific

141
00:10:00,425 --> 00:10:04,325
Speaker 7:  bit of technology, which is socks. Without socks,

142
00:10:04,825 --> 00:10:08,605
Speaker 7:  the whole shoe would've been ruined. So these butterflies, they

143
00:10:08,655 --> 00:10:12,485
Speaker 7:  can't really afford to lose too much energy over that winter

144
00:10:12,485 --> 00:10:16,285
Speaker 7:  period, otherwise they won't make it through. So the crew had

145
00:10:16,285 --> 00:10:20,085
Speaker 7:  to be as quiet as possible, which literally meant taking off their

146
00:10:20,085 --> 00:10:23,885
Speaker 7:  shoes and walking around in socks. So they'd be setting up cable dollies

147
00:10:24,065 --> 00:10:27,925
Speaker 7:  on a tree without butterflies on, et cetera, you know, put one on it

148
00:10:28,065 --> 00:10:31,925
Speaker 7:  and then they'd be kind of moving this cable dolly silently through.

149
00:10:32,265 --> 00:10:35,805
Speaker 7:  They'd have their socks on and they'd just be, they'd just be waiting. Meanwhile,

150
00:10:35,835 --> 00:10:38,805
Speaker 7:  it's, it's not actually that warmer place. It looks kind of quite nice and

151
00:10:38,805 --> 00:10:42,245
Speaker 7:  warm and cozy, but it's actually quite a high altitude. Forest in Mexico

152
00:10:42,775 --> 00:10:46,525
Speaker 7:  drops below freezing easily at night, which is half a problem for the

153
00:10:46,525 --> 00:10:49,725
Speaker 7:  butterflies. But the butterflies, they have this, you know, perfect little

154
00:10:49,725 --> 00:10:52,885
Speaker 7:  ecosystem in, in the canopy there, which keeps them nice and warm. But for

155
00:10:52,885 --> 00:10:56,205
Speaker 7:  the, for the crew on the ground that was less comfy, but socks who knew it,

156
00:10:56,675 --> 00:11:00,405
Speaker 2:  Some shots, they know they can get, animals have patterns. Big

157
00:11:00,535 --> 00:11:03,765
Speaker 2:  caves are probably still going to be there next year. One thing I've heard

158
00:11:03,765 --> 00:11:07,685
Speaker 2:  from a lot of nature filmmakers over the years is that if you just show up

159
00:11:07,985 --> 00:11:11,885
Speaker 2:  and stay there, eventually most animals will get used to you and

160
00:11:11,885 --> 00:11:15,725
Speaker 2:  just carry on living their lives so you can get what you need as long as

161
00:11:15,725 --> 00:11:19,285
Speaker 2:  you're patient enough. That's why you see a lot of hides and camera

162
00:11:19,495 --> 00:11:23,365
Speaker 2:  traps. Really, a camera trap is actually a staple of Planet earth. You set

163
00:11:23,525 --> 00:11:27,445
Speaker 2:  up a camera in some slightly hidden but very central place, turn it on

164
00:11:27,625 --> 00:11:31,445
Speaker 2:  and just wait. And knowing where to put those cameras and

165
00:11:31,725 --> 00:11:35,325
Speaker 2:  actually how to place them and angle them and focus them is a real skill.

166
00:11:35,595 --> 00:11:39,285
Speaker 2:  Like when you're prepared to capture 8,000 hours of footage trying to catch

167
00:11:39,445 --> 00:11:42,045
Speaker 2:  a glimpse of a snow leopard in Mongolia,

168
00:11:42,625 --> 00:11:46,405
Speaker 7:  The guy who did that, a guy called Jake Davis, he's really specialized

169
00:11:46,705 --> 00:11:49,845
Speaker 7:  in these camera traps and he has this amazing

170
00:11:50,275 --> 00:11:53,565
Speaker 7:  ability to get into the, the head of the animal. And you know, when you're

171
00:11:53,565 --> 00:11:56,165
Speaker 7:  setting up a camera trap, it's gotta be the right height. You set up, you

172
00:11:56,165 --> 00:11:58,805
Speaker 7:  know, the height of my head. You're never gonna, you don't film anything.

173
00:11:58,875 --> 00:12:01,805
Speaker 7:  It's gotta be down at the right, the eye line, you know, you wanna make it

174
00:12:01,805 --> 00:12:05,765
Speaker 7:  cinematic as well as functional. So you get it down, you get it set

175
00:12:05,765 --> 00:12:08,525
Speaker 7:  up, and then you have to crawl through the frame, right, pretending you're

176
00:12:08,525 --> 00:12:11,005
Speaker 7:  a snow leo to kind of mimic the, the action.

177
00:12:11,345 --> 00:12:14,165
Speaker 2:  But also, and this is the thing you hear from nature filmmakers over and

178
00:12:14,165 --> 00:12:16,525
Speaker 2:  over, is sometimes you just get lucky.

179
00:12:16,985 --> 00:12:20,565
Speaker 7:  But actually my favorite shot in that sequence was one actually

180
00:12:20,885 --> 00:12:23,965
Speaker 7:  designed by the snow leopard themselves. The camera trap was placed down,

181
00:12:24,225 --> 00:12:28,165
Speaker 7:  but the cat decided, I didn't really like the position of that. So they like

182
00:12:28,225 --> 00:12:31,885
Speaker 7:  it rubbed themselves on it, they'd carried it, they'd moved it, and they

183
00:12:31,885 --> 00:12:35,125
Speaker 7:  just put it down, right? And then a couple of days later, I think it was

184
00:12:35,125 --> 00:12:38,925
Speaker 7:  the ca same cat walked down right in front of it. But what the, what the

185
00:12:38,925 --> 00:12:42,285
Speaker 7:  frame had done was, because it had been put a slight angle, but also pointed

186
00:12:42,285 --> 00:12:45,365
Speaker 7:  to the ground, there was a super shallow depth of field and the cat just

187
00:12:45,365 --> 00:12:48,845
Speaker 7:  placed its foot right in the middle of that depth of field. And it's like

188
00:12:49,065 --> 00:12:52,725
Speaker 7:  the most perfect snow leopard shot you could have imagined. But you know,

189
00:12:52,785 --> 00:12:55,245
Speaker 7:  he can't take credit for that 'cause it was a snow Leo that did it.

190
00:12:55,815 --> 00:12:59,645
Speaker 2:  There are a lot of moments in making something like this where you just prepare

191
00:12:59,665 --> 00:13:03,285
Speaker 2:  as best you can and then wait as long as possible. But sometimes you're

192
00:13:03,285 --> 00:13:06,885
Speaker 2:  literally only going to get one shot. Like there's this one moment

193
00:13:07,105 --> 00:13:11,005
Speaker 2:  in the forests episode where a tree almost 200 feet tall, goes

194
00:13:11,125 --> 00:13:14,845
Speaker 2:  crashing down in the middle of a forest. You know, if a tree falls in the

195
00:13:14,845 --> 00:13:17,725
Speaker 2:  forest and you're not there to film it, does it? Nah, nevermind. That's a

196
00:13:17,805 --> 00:13:20,725
Speaker 2:  terrible joke. Anyway, it's a really hard thing to film. It turns out

197
00:13:21,185 --> 00:13:25,165
Speaker 8:  The tree fall was really complicated and took a huge amount of

198
00:13:25,365 --> 00:13:28,205
Speaker 8:  planning, as you can imagine, and a, a big risk assessment that I had to

199
00:13:28,205 --> 00:13:32,045
Speaker 8:  write. But yeah, so that one, we had quite a big

200
00:13:32,115 --> 00:13:35,965
Speaker 8:  crew. We had three drone operators who were flying at the same time.

201
00:13:36,425 --> 00:13:39,845
Speaker 8:  So two of the drones were static to keep it, you know, simple and, and so

202
00:13:39,845 --> 00:13:43,605
Speaker 8:  they, you know, no disturbances within each other's shots. And then one that

203
00:13:43,605 --> 00:13:47,245
Speaker 8:  was moving and reacting with the tree as it fell. So that's like a sweeping

204
00:13:47,245 --> 00:13:50,965
Speaker 8:  shot that pulls back. And then we had ground cameras. So

205
00:13:51,145 --> 00:13:55,085
Speaker 8:  myself and Yuri van and another camera operator, we were operating the ground

206
00:13:55,085 --> 00:13:58,845
Speaker 8:  cameras. We had six of them placed. We knew this tree was around 60

207
00:13:58,985 --> 00:14:02,765
Speaker 8:  meters high. We'd measured it with the drone and sort of seen how high it

208
00:14:02,765 --> 00:14:06,565
Speaker 8:  was with that. And then we'd measured on the ground how far we need the

209
00:14:06,565 --> 00:14:10,365
Speaker 8:  cameras to be away to get this whoosh of all the leaves and

210
00:14:10,455 --> 00:14:13,645
Speaker 8:  everything breaking, coming up towards the camera, which is one of the shots

211
00:14:13,645 --> 00:14:17,085
Speaker 8:  you'll see in the forest episode. But you know, not having the cameras completely

212
00:14:17,085 --> 00:14:20,845
Speaker 8:  smashed the Smith rains, which was a real risk. You know, some of the

213
00:14:21,005 --> 00:14:24,365
Speaker 8:  cameras were GoPros and we were like, you know, if we lose a GoPro then it's

214
00:14:24,365 --> 00:14:27,165
Speaker 8:  not the end of the world. But you know, some of them are these red cameras

215
00:14:27,235 --> 00:14:30,485
Speaker 8:  that'll, you know how much they, they're very expensive cameras with very

216
00:14:30,485 --> 00:14:34,405
Speaker 8:  expensive lenses. So they were based more at the base of the tree, sort of

217
00:14:34,405 --> 00:14:37,965
Speaker 8:  where we knew it definitely wasn't gonna fall in that direction. We then

218
00:14:37,965 --> 00:14:41,845
Speaker 8:  worked with some locals who allowed us to film them, fell,

219
00:14:41,915 --> 00:14:45,845
Speaker 8:  they selectively fell the tree. They told us, we know that when we take

220
00:14:45,955 --> 00:14:49,645
Speaker 8:  this route off, it's going to fall in that direction. So we knew the direction

221
00:14:49,645 --> 00:14:53,405
Speaker 8:  it was going to fall. So there was a lot of planning, a lot of talking

222
00:14:53,595 --> 00:14:57,445
Speaker 8:  with the local people and that was key. And none of the cameras

223
00:14:57,545 --> 00:14:59,445
Speaker 8:  got smashed, which was absolutely amazing.

224
00:15:00,125 --> 00:15:03,605
Speaker 2:  I could do this forever, honestly. There are fun technology stories behind

225
00:15:03,715 --> 00:15:07,445
Speaker 2:  basically everything in the show. But let's just do two more here. First,

226
00:15:07,475 --> 00:15:11,405
Speaker 2:  there's this section of the Extremes episode filmed in a cave in Vietnam

227
00:15:11,475 --> 00:15:14,925
Speaker 2:  that is thought to be the world's largest cave. It's called Hang Sun Don

228
00:15:15,105 --> 00:15:18,925
Speaker 2:  the crew spent more than two weeks in this cave filming it in all sorts of

229
00:15:18,925 --> 00:15:22,765
Speaker 2:  different ways, but the most remarkable thing I think that they did is

230
00:15:22,845 --> 00:15:26,605
Speaker 2:  a two drone setup to try and capture the true size

231
00:15:26,745 --> 00:15:27,885
Speaker 2:  and scope of this place.

232
00:15:28,345 --> 00:15:31,365
Speaker 7:  We had a team of fourth cinematographers, but we chose one in particular

233
00:15:31,365 --> 00:15:35,165
Speaker 7:  because he'd been down inside Ong Don Cave, he, he's been down like

234
00:15:35,165 --> 00:15:38,845
Speaker 7:  almost 15 times or something like that. So he knows the cave really well.

235
00:15:38,945 --> 00:15:42,325
Speaker 7:  He shot a lot for himself, but he'd never done what we wanted to do, which

236
00:15:42,325 --> 00:15:46,245
Speaker 7:  is take sort of cinema cameras down there and show the cave off

237
00:15:46,245 --> 00:15:50,045
Speaker 7:  in a, in a different, in a different way. He'd also never spent, I don't

238
00:15:50,045 --> 00:15:52,645
Speaker 7:  think, more than three or four days there. So the fact that we were gonna

239
00:15:52,645 --> 00:15:56,045
Speaker 7:  spend 18 days underground in that cave

240
00:15:56,395 --> 00:16:00,125
Speaker 7:  sort of blew his mind and also made him incredibly excited at the same time.

241
00:16:00,185 --> 00:16:04,005
Speaker 7:  He was like, oh my God, think about what I can do out here. So first of all,

242
00:16:04,005 --> 00:16:07,925
Speaker 7:  what he thought about was how, how to light it, right? Because as you say,

243
00:16:07,985 --> 00:16:11,765
Speaker 7:  the paradox of filming underground is that unless you're so light, there

244
00:16:11,765 --> 00:16:15,405
Speaker 7:  is nothing to see. And yet you want to keep some of it

245
00:16:15,515 --> 00:16:19,365
Speaker 7:  dark to keep it like mysterious, but also it helps with that sense of scale.

246
00:16:19,365 --> 00:16:22,805
Speaker 7:  If you like the whole thing, you lose that scale, you lose the texture, you

247
00:16:22,805 --> 00:16:26,405
Speaker 7:  lose everything. So what we, what we decided to do and, and with his

248
00:16:26,405 --> 00:16:30,365
Speaker 7:  assistance, we built these kind of four panel arrays of custom LEDs,

249
00:16:30,615 --> 00:16:34,485
Speaker 7:  which are super bright LED panel and they have a cone attached to them

250
00:16:34,485 --> 00:16:37,325
Speaker 7:  and you can bolt them together, which is how we created this sort of four

251
00:16:37,325 --> 00:16:41,125
Speaker 7:  panel array. We tucked that underneath this heavy lift drone, so A

252
00:16:41,205 --> 00:16:45,165
Speaker 7:  DDI matri 600, which is, you know, 10 kilos heavy,

253
00:16:45,415 --> 00:16:49,205
Speaker 7:  about a meter wide. It's a huge beast. We'd put that up in the air

254
00:16:49,585 --> 00:16:53,325
Speaker 7:  and the 15 minute timer would start ticking. So the lights outta their own

255
00:16:53,325 --> 00:16:56,245
Speaker 7:  battery source and they were the weak link if you like. They ran out about

256
00:16:56,245 --> 00:17:00,165
Speaker 7:  15 minutes at the same time, we'd send up A-A-D-G-I Mavic

257
00:17:00,285 --> 00:17:04,125
Speaker 7:  three pro and, and that would be our filming camera. I

258
00:17:04,125 --> 00:17:07,725
Speaker 7:  see that the other kind of fun thing about filming inside a cave, right,

259
00:17:07,745 --> 00:17:11,645
Speaker 7:  is that obviously you've got no GPS on the drones, right? GPS is

260
00:17:11,645 --> 00:17:15,285
Speaker 7:  non-functional, and when you take that away from a lot of consumer

261
00:17:15,345 --> 00:17:19,205
Speaker 7:  drones, they freak out. They have this inbuilt cap, right? They only

262
00:17:19,365 --> 00:17:23,205
Speaker 7:  go 10 meters high, so you can't do anything crazy with 'em. So

263
00:17:23,545 --> 00:17:27,405
Speaker 7:  we actually had to work with DGI to take those caps off for this very

264
00:17:27,685 --> 00:17:31,525
Speaker 7:  specific case. Didn't work with the DGI MA three. So we had

265
00:17:31,525 --> 00:17:35,325
Speaker 7:  to hack it in the cave by, by doing these crazy flight stunts.

266
00:17:35,345 --> 00:17:39,045
Speaker 7:  So we'd worked out that if you use the topography of the cave, it would

267
00:17:39,145 --> 00:17:42,805
Speaker 7:  baffle the drone and it would think that it was above or below

268
00:17:42,945 --> 00:17:46,525
Speaker 7:  10 meters, whatever. Anyway, so we'd fly over this bit of topography, it

269
00:17:46,525 --> 00:17:50,045
Speaker 7:  would think, oh, it's cool. I I I'm still within my 10 meter zone anyway,

270
00:17:50,045 --> 00:17:53,005
Speaker 7:  we could fly at a hundred meters high, which is crazy in itself because we're

271
00:17:53,005 --> 00:17:56,685
Speaker 7:  underground in this, well, a hundred meter plus cavern, right? Huge thing.

272
00:17:56,785 --> 00:18:00,165
Speaker 7:  So we take our fly around with that and, and meanwhile we're, whilst we're

273
00:18:00,165 --> 00:18:04,045
Speaker 7:  filming with this Mavic, we would swing the lighting drone around

274
00:18:04,145 --> 00:18:07,645
Speaker 7:  in arcs around the object that we are trying to film. What it would do, it

275
00:18:07,645 --> 00:18:11,205
Speaker 7:  was, it would move the pool of light to both reveal and hide

276
00:18:11,205 --> 00:18:14,925
Speaker 7:  certain areas of the cave, which would also enhance the shadows

277
00:18:15,025 --> 00:18:18,885
Speaker 7:  and, and the textures of the cave features. And it was a way that

278
00:18:18,905 --> 00:18:22,725
Speaker 7:  we could introduce scale into the cave and also

279
00:18:22,725 --> 00:18:25,925
Speaker 7:  just show this underworld like has never been shown before.

280
00:18:26,905 --> 00:18:30,045
Speaker 2:  One cool thing, by the way, about that drone footage and about a lot of the

281
00:18:30,045 --> 00:18:33,925
Speaker 2:  stuff in the cave is that you see people in the shots a lot. The crew members

282
00:18:34,025 --> 00:18:37,725
Speaker 2:  are actually in this series much more than in previous Planet Earth, which

283
00:18:37,755 --> 00:18:41,485
Speaker 2:  Alex and Theo both said was a deliberate choice. They both wanted to show

284
00:18:41,495 --> 00:18:45,205
Speaker 2:  scale, but also to remind people that humans are part of

285
00:18:45,625 --> 00:18:49,525
Speaker 2:  and change every single one of these stories. It works really well in actually

286
00:18:49,525 --> 00:18:53,405
Speaker 2:  both ways and is pretty wild in particular in the cave. So

287
00:18:53,405 --> 00:18:56,325
Speaker 2:  that's the big stuff. And then all the way on the other end of the spectrum,

288
00:18:56,615 --> 00:18:59,845
Speaker 2:  there are two sequences in the episodes we're talking about where we actually

289
00:18:59,845 --> 00:19:03,525
Speaker 2:  get to see inside of nest. One is inside a

290
00:19:03,525 --> 00:19:06,565
Speaker 2:  termite mound in the grasslands of Australia where parrots are hatching their

291
00:19:06,565 --> 00:19:09,765
Speaker 2:  eggs and another with oriental pied hornbills

292
00:19:10,285 --> 00:19:13,045
Speaker 2:  burying into a tree to make a nest In Borneo,

293
00:19:13,635 --> 00:19:17,565
Speaker 6:  Once settled inside, the female does something

294
00:19:17,695 --> 00:19:19,045
Speaker 6:  truly bizarre.

295
00:19:21,625 --> 00:19:24,165
Speaker 6:  She pulls out her flight feathers,

296
00:19:27,905 --> 00:19:31,765
Speaker 6:  she is not going to need them because she will be

297
00:19:31,765 --> 00:19:34,365
Speaker 6:  staying in here for quite some time.

298
00:19:37,115 --> 00:19:41,045
Speaker 2:  Both times you're in this teeny tiny space that is somehow well lit,

299
00:19:41,275 --> 00:19:45,005
Speaker 2:  shot in high resolution, and doesn't drive the animals totally

300
00:19:45,345 --> 00:19:48,685
Speaker 2:  insane. It's wild. And it's really hard to put together

301
00:19:49,135 --> 00:19:52,525
Speaker 7:  These parrots, these golden shoulder parrots like beautiful. They live in

302
00:19:52,525 --> 00:19:56,405
Speaker 7:  these grasslands in, in Northern Australia, they're super rare. You got,

303
00:19:56,405 --> 00:20:00,165
Speaker 7:  they, you gotta be super sensitive, right? You, you know, one failed nest

304
00:20:00,465 --> 00:20:04,045
Speaker 7:  equals a whole generation for that family not pledging and

305
00:20:04,045 --> 00:20:07,965
Speaker 7:  replenishing the population. So we had to work with a

306
00:20:07,965 --> 00:20:11,405
Speaker 7:  landowner who has, who has loved, who has studied,

307
00:20:11,865 --> 00:20:15,325
Speaker 7:  who has looked after and cared for her land. And these

308
00:20:15,395 --> 00:20:19,325
Speaker 7:  parrots for like decades. She works with this amazing scientist, Steve

309
00:20:19,345 --> 00:20:23,285
Speaker 7:  Murphy, who allowed us to make a small hole in the

310
00:20:23,285 --> 00:20:27,085
Speaker 7:  back of the termite mound once the chicks had hatched.

311
00:20:27,145 --> 00:20:29,885
Speaker 7:  So they're much more relaxed, so they're feeding, they're feeding. So when

312
00:20:29,885 --> 00:20:32,685
Speaker 7:  the mom and dad are away, we need this small hole in and using, using our

313
00:20:32,685 --> 00:20:36,525
Speaker 7:  probe blends, this lower probe blends, we are able to, to get it through.

314
00:20:36,545 --> 00:20:39,845
Speaker 7:  And it's super wide lens. So you can, you can see the whole, whole nest.

315
00:20:40,065 --> 00:20:43,725
Speaker 7:  The, the nest is probably only the size of like a don don't know a grapefruit,

316
00:20:43,725 --> 00:20:47,365
Speaker 7:  right? So it's, it's actually pretty small. So you're getting this really

317
00:20:47,605 --> 00:20:50,805
Speaker 7:  intimate view in, and then of course the lighter, it, it's, it's super important

318
00:20:50,805 --> 00:20:53,645
Speaker 7:  because if you, if you just rely on the lighting from the, from the hole,

319
00:20:53,705 --> 00:20:57,325
Speaker 7:  you just, everything's really back lit and, and dark and bright and it's,

320
00:20:57,325 --> 00:21:01,085
Speaker 7:  it's awful. So you've gotta make another tiny hole for the tiny little, little

321
00:21:01,245 --> 00:21:04,165
Speaker 7:  LED lights that we could, we could shine through it at creative angle and

322
00:21:04,165 --> 00:21:07,965
Speaker 7:  and light it inside. And then we'd run a cable away to a hide 20,

323
00:21:07,965 --> 00:21:11,445
Speaker 7:  30 meters away. And, and then it'd be remote triggered. So once it's there,

324
00:21:11,545 --> 00:21:15,245
Speaker 7:  it was, it was all set, but we wanted to film at, at different stages. So,

325
00:21:15,265 --> 00:21:18,805
Speaker 7:  so we would, you know, we'd we'd film for a day go, yeah, pretty much we've

326
00:21:18,805 --> 00:21:22,205
Speaker 7:  got enough kind of feeding moments. We'd, we'd withdraw the camera. We thought,

327
00:21:22,205 --> 00:21:25,045
Speaker 7:  okay, two weeks later we'll come back and stick it in and get the next part

328
00:21:25,045 --> 00:21:29,005
Speaker 7:  of the life stage. By which time, by which time the, the termites, they're

329
00:21:29,005 --> 00:21:32,085
Speaker 7:  so industrious, right over that short period of time, they'd sealed back

330
00:21:32,085 --> 00:21:35,525
Speaker 7:  that hole. So they're like, oh God, So I had to make that hole again, do

331
00:21:35,525 --> 00:21:38,085
Speaker 7:  this whole thing. But anyway, once we learned how to do that, the, the camera

332
00:21:38,325 --> 00:21:42,125
Speaker 7:  op Mitch decided to put a cork in it. I think actually it just,

333
00:21:42,125 --> 00:21:45,765
Speaker 7:  just a plug, which, which meant the, the termite sealed around the plug.

334
00:21:45,785 --> 00:21:48,765
Speaker 7:  So it was with air tie and everything, but it meant they could just pop it

335
00:21:48,765 --> 00:21:52,605
Speaker 7:  out and put the lens back in. It was a super privileged look into these super

336
00:21:52,605 --> 00:21:56,045
Speaker 7:  rare parrots and, and I'm really pleased to say that they all fledged absolutely

337
00:21:56,045 --> 00:21:59,845
Speaker 7:  beautifully. It was joyous to see them all fly away. But

338
00:21:59,845 --> 00:22:02,725
Speaker 7:  Alex your story and the horn bell, it's amazing, right?

339
00:22:03,155 --> 00:22:07,125
Speaker 8:  Yeah. So we use a very similar setup to Theo's. We, we've actually

340
00:22:07,125 --> 00:22:10,525
Speaker 8:  used some of the same lighting and the same lens. So we sent all of that

341
00:22:10,525 --> 00:22:14,325
Speaker 8:  to Borneo for our team in Borneo, to use And. what they had to do, because

342
00:22:14,395 --> 00:22:18,285
Speaker 8:  it's, it's such a long process's nesting period is very

343
00:22:18,355 --> 00:22:22,285
Speaker 8:  long. First of all, we had to guess which nests that these

344
00:22:22,285 --> 00:22:26,085
Speaker 8:  hornbills would use because we didn't want to disturb them. So we

345
00:22:26,085 --> 00:22:30,005
Speaker 8:  chose five nests and the guys out there worked with scientists who studies

346
00:22:30,145 --> 00:22:33,965
Speaker 8:  the Hornbills. So they went out and they set up tree platforms attached

347
00:22:34,025 --> 00:22:37,845
Speaker 8:  to the side of the trees for the camera to go on eventually if that

348
00:22:38,005 --> 00:22:41,965
Speaker 8:  female chose that nest hole. And then they waited for them to

349
00:22:41,965 --> 00:22:44,765
Speaker 8:  sort of, for their behavior to start happening where they could see which

350
00:22:44,765 --> 00:22:48,565
Speaker 8:  nest they would be choosing. And then just like the termite mounds with

351
00:22:48,635 --> 00:22:51,845
Speaker 8:  Theo, we, we drilled very, very tiny holes and used this almost

352
00:22:52,015 --> 00:22:55,845
Speaker 8:  endoscopic laa probe to sort of film

353
00:22:55,845 --> 00:22:59,685
Speaker 8:  inside the nest. So we inserted, we'd made a hole for that. And then we also

354
00:22:59,715 --> 00:23:03,125
Speaker 8:  made I think three holes for lighting because you know, endo, these

355
00:23:03,125 --> 00:23:06,925
Speaker 8:  endoscopic cameras, they need a lot of lighting to get the light into these

356
00:23:06,925 --> 00:23:10,285
Speaker 8:  very dark cavities. And then what we had to do is

357
00:23:10,615 --> 00:23:14,525
Speaker 8:  again, the cameras were tethered and the lights were tethered. So once she

358
00:23:14,525 --> 00:23:18,045
Speaker 8:  decided which nest she was in, we had to wait sort of a week or so

359
00:23:18,305 --> 00:23:22,205
Speaker 8:  for her to settle in. And then in the nighttime, well in

360
00:23:22,205 --> 00:23:25,925
Speaker 8:  the very early morning, they then unplugged the hole,

361
00:23:26,015 --> 00:23:29,685
Speaker 8:  which they'd plugged up with clay because obviously it's a living tree and

362
00:23:29,685 --> 00:23:33,365
Speaker 8:  you don't want to add any bacteria or anything. So they used clay and then

363
00:23:33,875 --> 00:23:37,645
Speaker 8:  they would gently put in the probe blends and then they would

364
00:23:37,675 --> 00:23:41,605
Speaker 8:  also put in the lights and then will foster Grundy. Our camera

365
00:23:41,925 --> 00:23:45,685
Speaker 8:  operator would also gradually turn up the lights as the

366
00:23:45,885 --> 00:23:49,565
Speaker 8:  daylight started coming up. They've got quite big eyes, these birds and they're

367
00:23:49,565 --> 00:23:53,525
Speaker 8:  very sensitive to their surroundings. And so there were times she definitely

368
00:23:53,525 --> 00:23:56,885
Speaker 8:  muddied, you know, she's, she's expert, you know, muddying up herself into

369
00:23:56,885 --> 00:24:00,805
Speaker 8:  this tree hole and creating this little gap for her to live in. But she would

370
00:24:00,805 --> 00:24:04,725
Speaker 8:  then muddy up the lights and the camera. It

371
00:24:04,725 --> 00:24:08,405
Speaker 8:  was frustrating but like they work so delicately and they

372
00:24:08,405 --> 00:24:12,125
Speaker 8:  managed to get the full behavior of her. And yeah, she accepted it

373
00:24:12,125 --> 00:24:16,085
Speaker 8:  eventually and we got this absolutely incredible intimate view of inside

374
00:24:16,085 --> 00:24:19,645
Speaker 8:  the nest, which you know, without that the story wouldn't have been half

375
00:24:19,645 --> 00:24:23,365
Speaker 8:  as good, you know, to be able to see her perspective, you know, almost as

376
00:24:23,365 --> 00:24:27,325
Speaker 8:  if she's in this pri this prison and it's just, yeah, I think it

377
00:24:27,325 --> 00:24:28,645
Speaker 8:  made for an excellent sequence.

378
00:24:29,865 --> 00:24:32,905
Speaker 2:  Ultimately in talking to Theo and Alex, it didn't sound like there was much

379
00:24:32,935 --> 00:24:36,905
Speaker 2:  they couldn't do technologically speaking. It's all a lot of work and a

380
00:24:36,905 --> 00:24:40,785
Speaker 2:  lot of gear. It takes forever and this show is expensive

381
00:24:41,045 --> 00:24:44,905
Speaker 2:  to make, but most of it is doable still though Alex

382
00:24:44,965 --> 00:24:48,905
Speaker 2:  and Theo said they both have some ideas about how tech could make life easier

383
00:24:49,245 --> 00:24:52,985
Speaker 2:  for say, Planet Earth four in a few years. And even beyond that,

384
00:24:53,585 --> 00:24:56,185
Speaker 8:  I think personally I would like the camera equipment to be a bit lighter

385
00:24:56,865 --> 00:25:00,705
Speaker 8:  because you know, it is getting smaller but actually we end

386
00:25:00,705 --> 00:25:04,265
Speaker 8:  up with just as much clobber, we have just as much here, even though

387
00:25:04,575 --> 00:25:08,065
Speaker 8:  it's becoming smarter because you know, you have this specialized bit of

388
00:25:08,555 --> 00:25:11,905
Speaker 8:  cable that's used for this camera but not for that camera. So you end up

389
00:25:11,905 --> 00:25:15,185
Speaker 8:  with loads nodes of stuff. So it would be nice if things actually just became

390
00:25:15,265 --> 00:25:18,745
Speaker 8:  a bit smaller and a bit lighter, but then sometimes things like tripods,

391
00:25:18,745 --> 00:25:21,945
Speaker 8:  you need them to be heavy for that stability. But that for me that would

392
00:25:21,945 --> 00:25:25,625
Speaker 8:  be great. But then for the making of, you know, as Theo was saying earlier,

393
00:25:25,965 --> 00:25:29,905
Speaker 8:  having an iPhone to film, that has changed and I think that will

394
00:25:30,185 --> 00:25:30,705
Speaker 8:  continue changing.

395
00:25:31,375 --> 00:25:34,865
Speaker 7:  Okay, I've got two. One is drones with telephoto

396
00:25:34,865 --> 00:25:38,505
Speaker 7:  capability. That will change everything because

397
00:25:38,765 --> 00:25:42,625
Speaker 7:  as soon as you can start getting stabilization good enough to get like

398
00:25:42,725 --> 00:25:46,665
Speaker 7:  10 times zooms on, plus you know you are, you're starting to

399
00:25:46,665 --> 00:25:50,545
Speaker 7:  be able to film really, really cool behavior in a really

400
00:25:50,545 --> 00:25:54,145
Speaker 7:  cinematic way, right? You'll be able to get incredible language shots which

401
00:25:54,145 --> 00:25:57,985
Speaker 7:  are moving and yet compressed because you're at a 300 mil or whatever

402
00:25:58,175 --> 00:26:02,105
Speaker 7:  that will be game changing. The miniaturization of zone of drones is a

403
00:26:02,105 --> 00:26:05,865
Speaker 7:  part of that as well. And that will definitely kind of fill that space

404
00:26:05,885 --> 00:26:09,465
Speaker 7:  and it'll be great. My rogue prediction, maybe not for six years but maybe

405
00:26:10,105 --> 00:26:13,985
Speaker 7:  slightly longer, is utilizing space imagery more. We had a great

406
00:26:13,985 --> 00:26:17,145
Speaker 7:  series a few years ago called Strom Space, which which utilized

407
00:26:17,635 --> 00:26:21,065
Speaker 7:  space imagery to get images of something happening on the ground at pretty

408
00:26:21,095 --> 00:26:24,705
Speaker 7:  high, super high resolution, which would then merge with

409
00:26:24,965 --> 00:26:28,865
Speaker 7:  drones filming that same event. And you'd have this crazy interface

410
00:26:28,865 --> 00:26:32,665
Speaker 7:  right from from outer space down and you could fly

411
00:26:32,775 --> 00:26:36,625
Speaker 7:  effectively straight into the action from space. And it was brilliant,

412
00:26:36,765 --> 00:26:40,625
Speaker 7:  it was super cool and I think that was way more innovative than the kind

413
00:26:40,625 --> 00:26:44,205
Speaker 7:  of time should allow for. And I think that imagery from space,

414
00:26:44,625 --> 00:26:48,565
Speaker 7:  the more resolution you can get, the more focus will allow us to do so much

415
00:26:48,565 --> 00:26:52,365
Speaker 7:  more. Both in a filmmaking perspective but also from a science perspective.

416
00:26:52,805 --> 00:26:56,285
Speaker 7:  Counting animals, you know, that's super important what they do with

417
00:26:56,565 --> 00:27:00,125
Speaker 7:  satellite imagery now for like counting penguin colonies is crazy.

418
00:27:00,505 --> 00:27:04,125
Speaker 7:  You know, they look for shit, basically they look for penguin shit on the

419
00:27:04,125 --> 00:27:07,525
Speaker 7:  ice and they go, oh look, there's a whole new colony there. We had no idea

420
00:27:07,525 --> 00:27:10,565
Speaker 7:  there was that many more penguins or that many less penguins. And they can

421
00:27:10,595 --> 00:27:14,005
Speaker 7:  tell how close they are to being like, well

422
00:27:14,255 --> 00:27:18,165
Speaker 7:  wiped off by kind of by ice loss basically. And so

423
00:27:18,165 --> 00:27:22,005
Speaker 7:  that kind of technology will feed into science and it'll feed

424
00:27:22,005 --> 00:27:25,845
Speaker 7:  into what we do as wildlife filmmakers so much more and and I'm super excited

425
00:27:25,845 --> 00:27:28,005
Speaker 7:  about that. And then filming on Mars,

426
00:27:28,585 --> 00:27:32,285
Speaker 2:  You heard it here first. Friends Planet Earth for the Mars edition.

427
00:27:32,835 --> 00:27:35,765
Speaker 2:  Alright, we have to take a break and then we are gonna come back and talk

428
00:27:35,765 --> 00:27:39,485
Speaker 2:  about TV algorithms and how to get recommendations, right? We'll be right

429
00:27:39,485 --> 00:27:39,645
Speaker 2:  back.

430
00:30:15,105 --> 00:30:18,835
Speaker 2:  Welcome back, we're gonna stay on the theme of, like I said,

431
00:30:19,055 --> 00:30:22,275
Speaker 2:  how stuff appears on your television, but I wanna take a look at it in a

432
00:30:22,275 --> 00:30:26,155
Speaker 2:  really different way. For years I have been trying to figure out how

433
00:30:26,155 --> 00:30:29,755
Speaker 2:  streaming apps are supposed to work the way they do work,

434
00:30:29,925 --> 00:30:33,715
Speaker 2:  where you open the app and you're presented with like a hundred million tiles

435
00:30:33,715 --> 00:30:37,475
Speaker 2:  of shows and movies you might like and then you spend forever scrolling through

436
00:30:37,475 --> 00:30:40,835
Speaker 2:  them and never find anything to watch and you eventually just give up and

437
00:30:40,835 --> 00:30:44,435
Speaker 2:  throw your TV into a river and move on with your life. That can't possibly

438
00:30:44,455 --> 00:30:48,355
Speaker 2:  be the best way, but what is the best way? A bunch of years ago I

439
00:30:48,355 --> 00:30:52,275
Speaker 2:  asked somebody at Hulu what the goal was, like the North Star for how they

440
00:30:52,275 --> 00:30:55,795
Speaker 2:  think about this. And he said it was just like a play button.

441
00:30:56,055 --> 00:30:59,995
Speaker 2:  You open the app and it should just know what you wanna watch and maybe even

442
00:30:59,995 --> 00:31:03,915
Speaker 2:  start playing it for you. I'm not sure that's the answer either. So

443
00:31:04,105 --> 00:31:08,035
Speaker 2:  what is the answer there are in the world? Few people better

444
00:31:08,315 --> 00:31:11,235
Speaker 2:  equipped to know the answer to that question than Pat Flemming.

445
00:31:11,555 --> 00:31:14,955
Speaker 12:  I am a senior director of product management here. So I Lead the member

446
00:31:14,955 --> 00:31:18,875
Speaker 12:  experience PM team. Think of that as the group responsible for how

447
00:31:18,875 --> 00:31:22,595
Speaker 12:  profiles work, how the core browse and discovery experience works. How

448
00:31:22,975 --> 00:31:26,875
Speaker 12:  you watch something great tonight or play something great if you're playing

449
00:31:26,875 --> 00:31:30,835
Speaker 12:  games across iOS and Android. And that's across TV devices,

450
00:31:31,215 --> 00:31:34,275
Speaker 12:  the website, iOS and Android phones and tablets,

451
00:31:34,855 --> 00:31:38,475
Speaker 2:  In case you're counting, that's a lot of jobs, but one of them is very much

452
00:31:38,495 --> 00:31:42,115
Speaker 2:  to figure out what should happen when I open the app. Netflix

453
00:31:42,495 --> 00:31:45,955
Speaker 2:  is famous for all the time it spends thinking about these recommendation

454
00:31:45,955 --> 00:31:49,315
Speaker 2:  systems. Do you remember a bunch of years ago when it offered a million dollars

455
00:31:49,415 --> 00:31:52,915
Speaker 2:  to any developer that could improve the system in a meaningful way?

456
00:31:53,265 --> 00:31:56,795
Speaker 2:  Even now picture the app, there's that huge banner that shows up whenever

457
00:31:56,795 --> 00:32:00,635
Speaker 2:  you open Netflix and then below it there's all those endless rows

458
00:32:00,895 --> 00:32:04,755
Speaker 2:  of increasingly specific genres and what's popular And, what you've watched

459
00:32:04,755 --> 00:32:08,515
Speaker 2:  before. And there are a million ways, big and small

460
00:32:08,585 --> 00:32:12,395
Speaker 2:  that Netflix is choosing and influencing what you see and in

461
00:32:12,395 --> 00:32:16,155
Speaker 2:  what order as a result, I guess more than most companies, I found myself

462
00:32:16,165 --> 00:32:19,995
Speaker 2:  often sitting there wondering why Netflix is showing me what

463
00:32:19,995 --> 00:32:23,315
Speaker 2:  it's showing me. So that's what Pat and I talked about. I started by asking

464
00:32:23,335 --> 00:32:26,915
Speaker 2:  him that big picture question I've been asking people for years, the one

465
00:32:26,915 --> 00:32:30,435
Speaker 2:  that I asked that guy at Hulu all those years ago. What is the best case

466
00:32:30,715 --> 00:32:34,515
Speaker 2:  scenario here? When I open Netflix, is the goal to show me a million

467
00:32:34,515 --> 00:32:38,115
Speaker 2:  options? Is it to show me three options, 300 options?

468
00:32:38,455 --> 00:32:42,085
Speaker 2:  Is it to get so good at recommendations that it does get

469
00:32:42,085 --> 00:32:46,005
Speaker 2:  everything right immediately, every time and just starts playing the

470
00:32:46,095 --> 00:32:48,645
Speaker 2:  exact perfect thing? Is that the plan?

471
00:32:49,075 --> 00:32:52,285
Speaker 12:  That would be so cool, but it's, it's quite hard. Okay, right? So people

472
00:32:52,285 --> 00:32:55,645
Speaker 12:  have such diverse tastes and interests. So it's not just that you might

473
00:32:55,835 --> 00:32:59,605
Speaker 12:  love sports documentaries and dramas and

474
00:32:59,605 --> 00:33:03,405
Speaker 12:  baking shows for example. It's also that tonight you might be interested

475
00:33:03,405 --> 00:33:06,285
Speaker 12:  in watching Beckham, but tomorrow you might be interested in watching The

476
00:33:06,285 --> 00:33:09,085
Speaker 12:  Crown. And it's quite difficult for us to know that when you sit down on

477
00:33:09,085 --> 00:33:12,645
Speaker 12:  the couch, so by definition that hit the button on your remote and

478
00:33:13,205 --> 00:33:16,165
Speaker 12:  Beckham or the Crown starts playing. Like that's those, that's a hard, that's

479
00:33:16,165 --> 00:33:19,965
Speaker 12:  a hard game for us to win at at very high frequency and So

480
00:33:20,445 --> 00:33:23,765
Speaker 12:  I think the other thing to say is people like to browse. It's not that people

481
00:33:23,765 --> 00:33:27,165
Speaker 12:  don't like browsing, it's that people don't like bad browsing experiences.

482
00:33:27,385 --> 00:33:31,125
Speaker 12:  So if we can deliver a great discovery experience, that's the word we would

483
00:33:31,125 --> 00:33:35,005
Speaker 12:  use internally and make that browsing experience feel great, feel

484
00:33:35,105 --> 00:33:37,645
Speaker 12:  the right amount, fast, the right amount, compelling, give you the right

485
00:33:37,645 --> 00:33:41,565
Speaker 12:  amount of options, then you're satisfied when you land on one that's that's

486
00:33:41,565 --> 00:33:45,405
Speaker 12:  perfect for you. The other thing to know is that you might not know what

487
00:33:45,405 --> 00:33:48,805
Speaker 12:  you love. So let's take those, those genre examples. So let's say I'm into

488
00:33:48,825 --> 00:33:52,685
Speaker 12:  sports stocks and dramas and let's say many folks

489
00:33:53,145 --> 00:33:57,085
Speaker 12:  who use Netflix are into sports docs, dramas and baking shows.

490
00:33:57,135 --> 00:34:00,605
Speaker 12:  Let's say I haven't tried a baking show yet. The beauty of personalization

491
00:34:00,625 --> 00:34:03,765
Speaker 12:  is that it's nearly a certainty that we would then try to recommend baking

492
00:34:03,765 --> 00:34:06,485
Speaker 12:  shows to me because there's lots of folks out there for whatever reason,

493
00:34:06,485 --> 00:34:09,965
Speaker 12:  who happen to share many of the same similar tastes and preferences I do

494
00:34:10,065 --> 00:34:13,965
Speaker 12:  and this one that I haven't demonstrated yet, but it's plausible that I

495
00:34:13,965 --> 00:34:16,365
Speaker 12:  might. And so we would make that recommendation, hopefully you find it.

496
00:34:16,365 --> 00:34:19,805
Speaker 12:  That's hard for us to do if we're just gonna go for that most likely thing

497
00:34:19,805 --> 00:34:20,565
Speaker 12:  on any given night,

498
00:34:20,935 --> 00:34:24,685
Speaker 2:  Right? Yeah, it does seem like a, if you were to do that you would end just

499
00:34:24,685 --> 00:34:27,925
Speaker 2:  playing for me like the safest thing where it's like if I just booted it

500
00:34:27,925 --> 00:34:31,085
Speaker 2:  up and it like you just showed me community every single time I turn on Netflix,

501
00:34:31,115 --> 00:34:34,125
Speaker 2:  like that's a, I'd have an okay time with that, right? Like if, if it was

502
00:34:34,125 --> 00:34:36,925
Speaker 2:  just a community machine for me, like I'm very rarely gonna be mad at that.

503
00:34:37,025 --> 00:34:40,925
Speaker 2:  But there's also no way to ever find me anything new in that world. And

504
00:34:40,925 --> 00:34:44,125
Speaker 2:  it also seems like one theory I have that I can't prove because no one has

505
00:34:44,125 --> 00:34:46,605
Speaker 2:  ever tried it, but I hope somebody does So I can see if it's true is that

506
00:34:46,605 --> 00:34:50,525
Speaker 2:  even if you showed me the right thing, like if I was deciding do

507
00:34:50,525 --> 00:34:53,845
Speaker 2:  I wanna watch the Crown or do I wanna watch Beckham, I think I would reflexively

508
00:34:54,225 --> 00:34:57,085
Speaker 2:  not wanna watch whatever you showed me. Hmm. There's just something about

509
00:34:57,085 --> 00:35:00,965
Speaker 2:  being sort of force fed that makes people not

510
00:35:01,075 --> 00:35:04,005
Speaker 2:  want to do it. I kind of can't describe it but there's something that feels

511
00:35:04,065 --> 00:35:07,845
Speaker 2:  bad about the UI of being told what I'm gonna watch even when

512
00:35:07,845 --> 00:35:08,525
Speaker 2:  it's the right thing.

513
00:35:08,885 --> 00:35:11,325
Speaker 12:  I like that theory. I think it's very plausible. I think we probably hear

514
00:35:11,325 --> 00:35:15,165
Speaker 12:  that in research from time to time that giving me options and then the right

515
00:35:15,165 --> 00:35:18,525
Speaker 12:  amount of what we would call evidence by the way to help me make an informed

516
00:35:18,725 --> 00:35:22,045
Speaker 12:  decision feels more satisfying than us just pushing something to you and

517
00:35:22,045 --> 00:35:25,085
Speaker 12:  that that is the truth of it members and and our incentives are completely

518
00:35:25,085 --> 00:35:28,645
Speaker 12:  aligned. We want to find you something awesome to watch and also make it

519
00:35:28,645 --> 00:35:31,885
Speaker 12:  delightful for you to get there. The simplicity of the Netflix business

520
00:35:31,885 --> 00:35:35,565
Speaker 12:  model is its subscription and so towards the end of the month

521
00:35:35,945 --> 00:35:38,885
Speaker 12:  if you find something, the odds are you're gonna subscribe again tomorrow

522
00:35:38,985 --> 00:35:42,285
Speaker 12:  for the next month. And so that's, that's what we're after and whatever

523
00:35:42,345 --> 00:35:46,165
Speaker 12:  way works best for you, we wanna make that happen. So to the point of making

524
00:35:46,195 --> 00:35:49,845
Speaker 12:  that decision feel good to you. So to your question on like, well would

525
00:35:49,845 --> 00:35:53,125
Speaker 12:  it be better just to kind of push the one thing or do people like the choices?

526
00:35:53,635 --> 00:35:57,445
Speaker 12:  Something you might not know is that the way the choices are

527
00:35:57,445 --> 00:36:01,285
Speaker 12:  presented to you or in any particular country might be a little bit

528
00:36:01,285 --> 00:36:05,245
Speaker 12:  different. So take Squid game for example. You know we would try a variety

529
00:36:05,305 --> 00:36:08,965
Speaker 12:  of different ways to position Squid game to you.

530
00:36:09,105 --> 00:36:12,845
Speaker 12:  And so we would have different sets of static artwork, slightly

531
00:36:12,845 --> 00:36:16,685
Speaker 12:  different synopsis, slightly different ways to promote via video.

532
00:36:16,785 --> 00:36:20,405
Speaker 12:  So like a trailer for example. And then we would try those different ways

533
00:36:20,715 --> 00:36:23,725
Speaker 12:  perhaps in different countries to different groups and they would all be

534
00:36:23,725 --> 00:36:27,205
Speaker 12:  reflective of what Squid game is about, but they would be oriented to try

535
00:36:27,205 --> 00:36:30,245
Speaker 12:  to find what would be best for you to understand what a particular title

536
00:36:30,265 --> 00:36:33,565
Speaker 12:  is about and then make a very informed decision. So that's another element

537
00:36:33,585 --> 00:36:37,045
Speaker 12:  of the personalization again to help you be super satisfied with whatever

538
00:36:37,045 --> 00:36:40,965
Speaker 12:  you click play on so that we're doing our best job we can being a matchmaker

539
00:36:41,025 --> 00:36:41,365
Speaker 12:  for you.

540
00:36:41,825 --> 00:36:44,285
Speaker 2:  That's really interesting. So yeah, let's actually talk about Squid game.

541
00:36:44,445 --> 00:36:46,685
Speaker 2:  'cause I think the question I've always had about Netflix, right is like

542
00:36:46,685 --> 00:36:50,285
Speaker 2:  how something goes from sort of appearing on Netflix

543
00:36:50,665 --> 00:36:54,525
Speaker 2:  to suddenly being everywhere. And I think we talk about it like it's a

544
00:36:54,525 --> 00:36:58,485
Speaker 2:  certain kind of either accidental magic or like brute

545
00:36:58,485 --> 00:37:02,325
Speaker 2:  corporate force from Netflix. And I think that the truth is probably somewhere

546
00:37:02,325 --> 00:37:04,885
Speaker 2:  in the middle. But I do think that the last sort of big picture question

547
00:37:04,885 --> 00:37:07,525
Speaker 2:  I have and then I want to kind of tell this good game story. One of the things

548
00:37:07,525 --> 00:37:10,565
Speaker 2:  I've always wondered about Netflix is it seems to me like you're talking

549
00:37:10,565 --> 00:37:14,485
Speaker 2:  about being a subscription business. All that really matters is that

550
00:37:14,565 --> 00:37:18,005
Speaker 2:  I find something to watch as long as I'm

551
00:37:18,405 --> 00:37:21,485
Speaker 2:  satisfied. Every time I open the app, everybody wins. Odds are I'm gonna

552
00:37:21,485 --> 00:37:25,205
Speaker 2:  keep subscribing and it sounds like that's the case. So what is the upside

553
00:37:25,225 --> 00:37:28,845
Speaker 2:  for Netflix and having these kind of cultural

554
00:37:28,875 --> 00:37:32,565
Speaker 2:  moments. We talk a lot about sort of the the death of the like show everybody's

555
00:37:32,765 --> 00:37:35,845
Speaker 2:  watching. If you're on Netflix, do you care? As long as I'm finding something

556
00:37:35,885 --> 00:37:38,605
Speaker 2:  I like what does it matter if it's the same thing that everybody else is

557
00:37:38,805 --> 00:37:38,925
Speaker 2:  watching?

558
00:37:39,485 --> 00:37:43,205
Speaker 12:  I mean isn't it so fun when something like Squid Game or Wednesday

559
00:37:43,465 --> 00:37:47,005
Speaker 12:  or La Casa de Propel happens? I mean that it's fun. Is it required?

560
00:37:47,585 --> 00:37:50,485
Speaker 12:  No, probably not. And that's the beauty of personalization. So when when

561
00:37:50,485 --> 00:37:53,565
Speaker 12:  you open the app and when I open the app, we're gonna see completely different

562
00:37:53,565 --> 00:37:56,245
Speaker 12:  home experiences 'cause we probably have completely different tastes and

563
00:37:56,245 --> 00:38:00,165
Speaker 12:  preferences. But when it happens it sure feels magical. And so take

564
00:38:00,405 --> 00:38:04,245
Speaker 12:  Squid Game as the example, the beginning of any of these sort of large phenomenons

565
00:38:04,545 --> 00:38:08,165
Speaker 12:  is phenomena is an incredible story. So Squid game,

566
00:38:08,515 --> 00:38:12,445
Speaker 12:  very Korean, you can define it as violent as a

567
00:38:12,645 --> 00:38:16,525
Speaker 12:  a commentary on society. It's funny at times, it's certainly dark,

568
00:38:16,795 --> 00:38:19,085
Speaker 12:  it's exciting, it's thrilling, it's a game show. It's all these different

569
00:38:19,085 --> 00:38:22,925
Speaker 12:  things packed together, created distinctly for a Korean audience. There

570
00:38:22,925 --> 00:38:26,565
Speaker 12:  was no illusions at the outset that that would necessarily be a huge global

571
00:38:26,625 --> 00:38:30,525
Speaker 12:  hit. But what happens is that starts to play incredibly well in

572
00:38:30,525 --> 00:38:34,005
Speaker 12:  Korea. So we start with an audience that is likely to be quite highly qualified

573
00:38:34,005 --> 00:38:37,805
Speaker 12:  in terms of delivering impressions, recommending Squid game for that group.

574
00:38:38,465 --> 00:38:41,845
Speaker 12:  And then because Squid Game and other Netflix

575
00:38:42,285 --> 00:38:46,245
Speaker 12:  originals are available globally, we've got dubs and subtitles

576
00:38:46,345 --> 00:38:50,165
Speaker 12:  and often over the 30 languages. So in the case of Squid game

577
00:38:50,665 --> 00:38:54,605
Speaker 12:  for Brazilian Portuguese and for Latin American Spanish, it

578
00:38:54,605 --> 00:38:58,525
Speaker 12:  started to take off in Latin America. And from there it's sort of difficult

579
00:38:58,525 --> 00:39:01,685
Speaker 12:  to know the causality because it's lots of things are happening outside

580
00:39:01,685 --> 00:39:04,605
Speaker 12:  of Netflix. So people started talking about Squid Game and this became kind

581
00:39:04,605 --> 00:39:08,525
Speaker 12:  of a global thing on social and then people are searching for Squid game

582
00:39:08,745 --> 00:39:12,725
Speaker 12:  on Netflix and that provides us another signal to further change

583
00:39:12,785 --> 00:39:16,205
Speaker 12:  how we're recommending Squid game. And from there the fire just continues

584
00:39:16,205 --> 00:39:19,925
Speaker 12:  to burn and all of a sudden everywhere you're hearing about Squid Game and

585
00:39:19,925 --> 00:39:23,445
Speaker 12:  you open Netflix and you find it happens to be there. And so that's a pretty

586
00:39:23,445 --> 00:39:25,925
Speaker 12:  good example of how it would work. I think La Casa de Papell would probably

587
00:39:25,925 --> 00:39:29,285
Speaker 12:  be another example. Our goal is not necessarily to

588
00:39:29,995 --> 00:39:33,805
Speaker 12:  have titles like Squid Game be the one thing everyone is talking about

589
00:39:34,085 --> 00:39:37,925
Speaker 12:  globally. We want to make titles that are authentically local and can potentially

590
00:39:38,275 --> 00:39:41,565
Speaker 12:  find great audiences all around the world. And that's incredible when they

591
00:39:41,565 --> 00:39:44,685
Speaker 12:  do, it's not always the case. In fact it's more rare than not, but it's

592
00:39:44,685 --> 00:39:45,765
Speaker 12:  super exciting when it does happen.

593
00:39:46,355 --> 00:39:49,685
Speaker 2:  Okay. So you just breeze through a bunch of, I think really interesting like

594
00:39:49,925 --> 00:39:52,965
Speaker 2:  personalization and discovery things. So take the squid game thinking, go

595
00:39:53,035 --> 00:39:56,765
Speaker 2:  like rewind all the way back to the beginning. So like not the why we think

596
00:39:56,765 --> 00:39:59,605
Speaker 2:  the show is interesting thing like that. I get you make the show 'cause you

597
00:39:59,605 --> 00:40:02,645
Speaker 2:  think it's gonna be cool at the very beginning. It seems like with something

598
00:40:02,645 --> 00:40:06,045
Speaker 2:  like that, like I'm assuming sort of from your perch, the job is to figure

599
00:40:06,065 --> 00:40:09,725
Speaker 2:  out like who are we confident? This is gonna be interesting to

600
00:40:10,195 --> 00:40:13,685
Speaker 2:  when you're at the point nobody has seen it. You can either just like beat

601
00:40:13,685 --> 00:40:17,005
Speaker 2:  people over the head with it and make them see it. Or you can try and guess

602
00:40:17,145 --> 00:40:20,645
Speaker 2:  who you think is most likely to like it and show it to them first. Is that,

603
00:40:20,645 --> 00:40:21,605
Speaker 2:  am I thinking about that the right way?

604
00:40:21,715 --> 00:40:25,285
Speaker 12:  Totally the right way. So like two good examples to give you on this one.

605
00:40:25,745 --> 00:40:29,245
Speaker 12:  One, let's keep it with Squid Game. You can go find out about

606
00:40:29,785 --> 00:40:33,485
Speaker 12:  titles that are going to launch on Netflix in an area on Netflix,

607
00:40:33,485 --> 00:40:37,245
Speaker 12:  either on mobile, across iOS and Android or on tv. You can see

608
00:40:37,245 --> 00:40:39,525
Speaker 12:  coming set of coming soon titles, right? And so is

609
00:40:39,525 --> 00:40:42,485
Speaker 2:  That a popular thing? Like do people interact with that a lot? People

610
00:40:42,635 --> 00:40:46,005
Speaker 12:  Love watching trailers and finding out about what's coming, whether it's

611
00:40:46,005 --> 00:40:49,165
Speaker 12:  with us or with other services. So I'd say generally yes, of course. I think

612
00:40:49,165 --> 00:40:52,645
Speaker 12:  people love to sort of anticipate what, what will be fun for them next on

613
00:40:52,645 --> 00:40:56,485
Speaker 12:  Netflix. And so you can tell us directly I'm

614
00:40:56,485 --> 00:40:58,965
Speaker 12:  interested in this thing. So you would, you would literally click remind

615
00:40:58,965 --> 00:41:02,805
Speaker 12:  me and then we would remind you we'd, we would follow up on that obligation.

616
00:41:02,825 --> 00:41:06,445
Speaker 12:  So we'd send you a push notification or an email or remind you in in the

617
00:41:06,445 --> 00:41:10,405
Speaker 12:  app when you open up Netflix. But in addition, that gives us this very

618
00:41:10,685 --> 00:41:14,565
Speaker 12:  explicit signal of the kinds of members who are likely to

619
00:41:14,565 --> 00:41:17,805
Speaker 12:  be interested. Now it's not perfect 'cause you could say, you know, remind

620
00:41:17,805 --> 00:41:21,525
Speaker 12:  me for let's say you know the next season of the Crown, but you have no

621
00:41:21,525 --> 00:41:24,005
Speaker 12:  intention of watching it. You haven't watched the prior seasons, it was

622
00:41:24,005 --> 00:41:27,125
Speaker 12:  like an accident or like you think your partner might wanna watch it with

623
00:41:27,125 --> 00:41:29,885
Speaker 12:  you. So it's not a perfect correlation that when you hit Remind me, you

624
00:41:29,885 --> 00:41:32,605
Speaker 12:  will definitely wanna watch. But it's a pretty good signal for us to work

625
00:41:32,605 --> 00:41:36,485
Speaker 12:  from. And then we would use that to extrapolate. If people like

626
00:41:36,485 --> 00:41:39,965
Speaker 12:  David are hitting remind me at very high rates and people like David watch

627
00:41:39,965 --> 00:41:43,805
Speaker 12:  these kinds of things, then we would probably expand that initial audience

628
00:41:43,805 --> 00:41:47,165
Speaker 12:  to reflect people like you, whether or not again, people like you based

629
00:41:47,165 --> 00:41:51,005
Speaker 12:  on what they watch, we would then recommend. And then from there it just

630
00:41:51,305 --> 00:41:55,245
Speaker 12:  builds. And the beauty again is that it's quite pure and

631
00:41:55,245 --> 00:41:58,925
Speaker 12:  that all we really care about is being a great matchmaker. We worship

632
00:41:59,025 --> 00:42:03,005
Speaker 12:  at the altar of customer satisfaction. So for us to deliver a bad recommendation

633
00:42:03,005 --> 00:42:05,885
Speaker 12:  is for us to have missed out on delivering you a great recommendation. So

634
00:42:06,465 --> 00:42:09,485
Speaker 12:  at the beginning we know very little. And so the other example I would give

635
00:42:09,765 --> 00:42:13,405
Speaker 12:  you here is if you're a brand new member to Netflix, we know

636
00:42:13,425 --> 00:42:16,885
Speaker 12:  almost nothing about you, right? We know where you are, the device, whether

637
00:42:16,885 --> 00:42:20,805
Speaker 12:  it's a phone or TV or laptop that you signed up on. And then

638
00:42:21,265 --> 00:42:24,685
Speaker 12:  all you have to do is tell us just a very little bit about your interest.

639
00:42:24,705 --> 00:42:28,285
Speaker 12:  So we ask you tell us a few titles that you're interested in. And that

640
00:42:28,605 --> 00:42:32,165
Speaker 12:  is the initial spark for personalization where we'll say, okay, based on

641
00:42:32,165 --> 00:42:36,085
Speaker 12:  those expressed stated tastes of preferences, here are the

642
00:42:36,085 --> 00:42:39,565
Speaker 12:  kinds of things that folks who watch those things also like, right?

643
00:42:39,905 --> 00:42:43,285
Speaker 2:  And it seems like, I was reading through the guidelines to the recommendation

644
00:42:43,285 --> 00:42:46,485
Speaker 2:  system that are on your website and it seems like basically everything about

645
00:42:46,745 --> 00:42:50,525
Speaker 2:  the system is either metadata about the thing itself or

646
00:42:50,875 --> 00:42:54,685
Speaker 2:  your viewing activity and that there's almost nothing else that

647
00:42:54,685 --> 00:42:58,485
Speaker 2:  you're thinking about in that. Like I expected my age and zip code

648
00:42:58,545 --> 00:43:02,325
Speaker 2:  and ethnicity and don don't know net worth, whatever. Like I, there are

649
00:43:02,325 --> 00:43:05,285
Speaker 2:  million signals that we've been trained by the internet to believe are super

650
00:43:05,525 --> 00:43:09,485
Speaker 2:  relevant and targeting to us. And at least from what the stuff I

651
00:43:09,485 --> 00:43:12,125
Speaker 2:  was reading says, you don't care about most of that.

652
00:43:12,505 --> 00:43:16,485
Speaker 12:  That's the beauty of it is that our goal is just to match you with something

653
00:43:16,585 --> 00:43:20,325
Speaker 12:  you are going to love watching tonight. And the best input for what you

654
00:43:20,325 --> 00:43:24,045
Speaker 12:  might love watching tonight or tomorrow or next week is what you've watched

655
00:43:24,105 --> 00:43:28,045
Speaker 12:  or spent time with before. And those other signals might be

656
00:43:28,365 --> 00:43:32,325
Speaker 12:  additive, but the thing that really matters is what have you demonstrated

657
00:43:32,325 --> 00:43:35,885
Speaker 12:  that you're really interested in via your behavior? And that's sort of the

658
00:43:35,885 --> 00:43:38,845
Speaker 12:  beauty of it. So yes, as you point out, you could think of titles as being

659
00:43:38,845 --> 00:43:42,765
Speaker 12:  broken down into these constituent components, this metadata, it's, is

660
00:43:42,765 --> 00:43:46,165
Speaker 12:  it a movie or a film? What's its originating country? How long is it?

661
00:43:46,915 --> 00:43:50,805
Speaker 12:  What language is it available in genre? Perhaps some tagging about

662
00:43:50,805 --> 00:43:53,645
Speaker 12:  attributes of the title. And those things all help to sort of round out

663
00:43:53,645 --> 00:43:57,125
Speaker 12:  what a title is like, and then you match that against member

664
00:43:57,265 --> 00:44:00,925
Speaker 12:  tastes and preferences. And again, take that sports docs,

665
00:44:01,535 --> 00:44:05,365
Speaker 12:  drama, baking shows, if you watch any two of those things and

666
00:44:05,395 --> 00:44:08,445
Speaker 12:  lots of people watch all three of those things, then it's a pretty good

667
00:44:08,445 --> 00:44:12,405
Speaker 12:  chance that that third genre might be interesting to you. And so some point

668
00:44:12,405 --> 00:44:15,485
Speaker 12:  in time you'll discover some genre that what wouldn't otherwise have been

669
00:44:15,485 --> 00:44:19,285
Speaker 12:  your consciousness and try it out on Netflix. Now the thing that we

670
00:44:19,315 --> 00:44:23,205
Speaker 12:  also do is inject some randomness into these recommendations

671
00:44:23,205 --> 00:44:27,125
Speaker 12:  because again, to the point of tonight when you sit down on the couch, don

672
00:44:27,125 --> 00:44:30,405
Speaker 12:  don't know what mood you're in necessarily or who's on the couch with you.

673
00:44:30,585 --> 00:44:33,285
Speaker 12:  And it could be just something different tonight would be better for you.

674
00:44:33,545 --> 00:44:37,165
Speaker 12:  And in that case we inject just a little bit of serendipity because we know

675
00:44:37,165 --> 00:44:40,485
Speaker 12:  it's quite hard for us to get it right every time. And that also helps continue

676
00:44:40,485 --> 00:44:42,845
Speaker 12:  to broaden what could be recommended to you.

677
00:44:43,315 --> 00:44:47,245
Speaker 2:  Yeah, what is the right balance there? I think about like the great innovation

678
00:44:47,245 --> 00:44:50,965
Speaker 2:  of TikTok was that it made it really low stakes for

679
00:44:50,965 --> 00:44:54,685
Speaker 2:  TikTok to be wrong. Which because it's so easy to scroll, it's so easy to

680
00:44:54,685 --> 00:44:58,125
Speaker 2:  just flip past something you don't like that TikTok can just show you stuff.

681
00:44:58,135 --> 00:45:02,085
Speaker 2:  Everything in there is just pure randomness and you

682
00:45:02,085 --> 00:45:05,165
Speaker 2:  don't really penalize it because it's so easy to scroll. I don't think you

683
00:45:05,165 --> 00:45:09,085
Speaker 2:  have quite the same permission because by the time I'm like 20

684
00:45:09,085 --> 00:45:12,285
Speaker 2:  minutes into a show and decide that I hate it, that's a much bigger commitment

685
00:45:12,285 --> 00:45:16,245
Speaker 2:  than one and a half seconds on a TikTok thing. So I would think there's less

686
00:45:16,395 --> 00:45:20,245
Speaker 2:  room to just sort of throw something at me just on the off chance I might

687
00:45:20,245 --> 00:45:23,365
Speaker 2:  like it to see how I react. How do you think about that? Like you could make

688
00:45:23,365 --> 00:45:27,325
Speaker 2:  the safe recommendation, you could just throw spaghetti at the wall and

689
00:45:27,325 --> 00:45:30,605
Speaker 2:  see what sticks, but neither of those feels exactly right for Netflix.

690
00:45:31,095 --> 00:45:33,725
Speaker 12:  We're definitely trying to not throw spaghetti at the wall. Okay, so we're,

691
00:45:33,725 --> 00:45:37,445
Speaker 12:  we're trying to make recommendations, think about it as we're doing our

692
00:45:37,445 --> 00:45:40,965
Speaker 12:  best to predict what might be interesting to you based on everything that's

693
00:45:40,965 --> 00:45:44,565
Speaker 12:  known about your taste and preferences before you open Netflix tonight.

694
00:45:44,785 --> 00:45:45,125
Speaker 12:  But if

695
00:45:45,205 --> 00:45:48,325
Speaker 2:  You follow that all the way out, you just show me community every time, right?

696
00:45:48,355 --> 00:45:48,645
Speaker 2:  Like,

697
00:45:49,065 --> 00:45:52,045
Speaker 12:  And then we're trying to help you find, always have something great to watch.

698
00:45:52,145 --> 00:45:55,165
Speaker 12:  So, so yes to your point like that, that you know, the, maybe you might

699
00:45:55,165 --> 00:45:57,925
Speaker 12:  generalize that community challenge. And for me it might be like,

700
00:45:58,935 --> 00:46:01,165
Speaker 12:  let's see, what could I watch every night? I mean, Seinfeld would be fun

701
00:46:01,165 --> 00:46:02,645
Speaker 12:  for me most nights, right? Yeah.

702
00:46:02,645 --> 00:46:06,165
Speaker 2:  I'm not mad at community. No. It's just like, I'm just only gonna like, yeah.

703
00:46:06,225 --> 00:46:09,085
Speaker 2:  Or it's like, I think about the, the one that happens to us all the time

704
00:46:09,085 --> 00:46:12,645
Speaker 2:  is we watch one trashy and I don't use that as an insult

705
00:46:12,715 --> 00:46:16,605
Speaker 2:  reality show. And then it's just infinite trashy reality

706
00:46:16,605 --> 00:46:19,885
Speaker 2:  shows. And that actually makes a lot of sense. But at the same time there's

707
00:46:19,925 --> 00:46:23,165
Speaker 2:  a finite amount of trashy reality TV that I actually wanna watch.

708
00:46:23,705 --> 00:46:26,805
Speaker 2:  And so, but then to just show up and be like, oh, you like trashy reality

709
00:46:26,905 --> 00:46:30,645
Speaker 2:  tv? Would you like the Great British Baking Show? That seems like a hard

710
00:46:30,645 --> 00:46:33,245
Speaker 2:  leap to make, but when you eventually kind of have to make,

711
00:46:33,565 --> 00:46:36,845
Speaker 12:  I think customers might say they would watch community every night,

712
00:46:37,385 --> 00:46:41,325
Speaker 12:  but when we, as I say, add a little bit of serendipity,

713
00:46:41,325 --> 00:46:45,205
Speaker 12:  what we find is customers are more satisfied when they have a little bit

714
00:46:45,205 --> 00:46:49,045
Speaker 12:  more breadth in terms of what they watch. And I think if intuitively

715
00:46:49,045 --> 00:46:52,645
Speaker 12:  when you run that by members and you talk to them and you ask qualitatively

716
00:46:52,645 --> 00:46:55,685
Speaker 12:  like how does it feel when you, when you've been watching a greater breadth

717
00:46:55,685 --> 00:46:59,405
Speaker 12:  of things versus more narrowly say only a couple of genres. I

718
00:46:59,565 --> 00:47:01,925
Speaker 12:  think intuitively it makes sense. And I think qualitatively you would hear

719
00:47:01,925 --> 00:47:04,805
Speaker 12:  that from from people as well if you just ask them. And so what we find

720
00:47:04,805 --> 00:47:08,685
Speaker 12:  in the data as well is that when we diversify slightly beyond

721
00:47:08,715 --> 00:47:12,325
Speaker 12:  your very narrow tried and true, David always loves

722
00:47:12,325 --> 00:47:16,005
Speaker 12:  community types of recommendations, we find that you'll eventually

723
00:47:16,225 --> 00:47:19,965
Speaker 12:  try one or multiple. And by the way, those will be a great fit. And

724
00:47:19,965 --> 00:47:23,365
Speaker 12:  that's sort of the fun of it, is that especially when we're

725
00:47:23,725 --> 00:47:26,965
Speaker 12:  introducing new stories to the world, like there's never been something

726
00:47:26,965 --> 00:47:30,485
Speaker 12:  like squid game before. No one would say, oh, I was hoping I could watch

727
00:47:30,605 --> 00:47:33,445
Speaker 12:  Squid Game tonight. But you find it and you get into it and you're lost.

728
00:47:33,445 --> 00:47:36,125
Speaker 12:  Whether it's for a handful of hours tonight or more than a handful of hours

729
00:47:36,145 --> 00:47:39,805
Speaker 12:  or over the next couple of weeks. That's kind of the magic of great storytelling.

730
00:47:40,395 --> 00:47:42,685
Speaker 2:  Yeah. So that, that's part of the squid game story that I think is really

731
00:47:42,805 --> 00:47:45,085
Speaker 2:  interesting. And you're talking about this and you know it, it's starts in

732
00:47:45,575 --> 00:47:49,445
Speaker 2:  Korea, it's doing super well. It's doing, it sounds like better

733
00:47:49,445 --> 00:47:53,125
Speaker 2:  than expected even in the place where you expected it to do very well. What

734
00:47:53,125 --> 00:47:56,125
Speaker 2:  happens next? Like is there a meeting where somebody's like, people love

735
00:47:56,125 --> 00:47:59,845
Speaker 2:  this show, this might be huge. We have to like turn up the randomness

736
00:47:59,845 --> 00:48:03,365
Speaker 2:  knob on the wall and start showing it to more people. Like what, how do you

737
00:48:03,365 --> 00:48:06,565
Speaker 2:  take it from It's doing well among the people we thought it would do well

738
00:48:06,615 --> 00:48:10,365
Speaker 2:  among to, let's show this to people

739
00:48:10,505 --> 00:48:14,165
Speaker 2:  who have not necessarily shown us they would like something like this.

740
00:48:14,785 --> 00:48:16,645
Speaker 2:  But the early signals say that they might,

741
00:48:17,665 --> 00:48:21,005
Speaker 12:  The, the beauty of this approach to personalization is

742
00:48:21,745 --> 00:48:24,965
Speaker 12:  no knobs, no buttons, no nothing needed to happen.

743
00:48:25,425 --> 00:48:28,605
Speaker 2:  I'm convinced there's a knob. You can't convince me there's not a knob that's

744
00:48:28,605 --> 00:48:31,325
Speaker 2:  just, it's the viewer's knob that you're just like show this to everybody,

745
00:48:31,825 --> 00:48:34,845
Speaker 12:  It it, sometimes it appears that way, but that's, that's what's so sort

746
00:48:34,845 --> 00:48:37,645
Speaker 12:  of magical about it. As I was saying, in the case of Squid Game, it's a

747
00:48:37,645 --> 00:48:41,565
Speaker 12:  little difficult to know for sure how much the conversation outside of Netflix

748
00:48:42,135 --> 00:48:45,845
Speaker 12:  drove what we saw, sort of some of the behavior. So sure, as soon as people

749
00:48:45,845 --> 00:48:48,965
Speaker 12:  started to talk about Squid game, then we start to see as I say, some

750
00:48:49,355 --> 00:48:53,165
Speaker 12:  signals of increased demand that we wouldn't otherwise be able to

751
00:48:53,165 --> 00:48:54,245
Speaker 12:  observe. And so the the

752
00:48:54,245 --> 00:48:56,045
Speaker 2:  Meaning like people searching for it more,

753
00:48:56,435 --> 00:48:59,805
Speaker 12:  Exactly A great example that would be searching. So if people are,

754
00:49:00,195 --> 00:49:04,045
Speaker 12:  most members at that point probably wouldn't, especially English primary

755
00:49:04,045 --> 00:49:07,725
Speaker 12:  members of folks in the US for example, wouldn't necessarily have spent

756
00:49:07,795 --> 00:49:11,645
Speaker 12:  lots of time watching original language, Korean content before they

757
00:49:11,675 --> 00:49:15,045
Speaker 12:  were introduced to Squid Game. And so it would not necessarily have been

758
00:49:15,045 --> 00:49:17,765
Speaker 12:  something that would've been high up there list of say stated preferences

759
00:49:17,785 --> 00:49:21,205
Speaker 12:  or stated, I'm excited to watch a dark gritty

760
00:49:21,995 --> 00:49:25,845
Speaker 12:  game show oriented thriller series from Korea. But once

761
00:49:25,845 --> 00:49:28,645
Speaker 12:  people started talking about it and we started to see some again for example

762
00:49:28,645 --> 00:49:32,365
Speaker 12:  that search activity that helps then reinforce for

763
00:49:33,345 --> 00:49:37,245
Speaker 12:  the algorithms that it's time to maybe open up the audience a little

764
00:49:37,245 --> 00:49:41,205
Speaker 12:  bit. And as I say, that's automatic in nature. There's no need

765
00:49:41,265 --> 00:49:45,045
Speaker 12:  for for dials or buttons. And what we're doing all the time is

766
00:49:45,045 --> 00:49:48,965
Speaker 12:  trying to tune more generally. So we would like to always be improving

767
00:49:48,985 --> 00:49:52,885
Speaker 12:  the way we're making recommendations. So for example, we have a view that

768
00:49:52,885 --> 00:49:56,765
Speaker 12:  maybe not necessarily every say half an hour you spend with Netflix

769
00:49:56,945 --> 00:50:00,925
Speaker 12:  is worth the same to you as a customer. So we would like to be able to learn

770
00:50:00,965 --> 00:50:04,085
Speaker 12:  a little bit more and be able to recommend say a half hour

771
00:50:04,475 --> 00:50:07,925
Speaker 12:  episode of something that you would love tonight versus a half hour of something

772
00:50:07,925 --> 00:50:10,325
Speaker 12:  you would be just okay with. So community for you might be a good example,

773
00:50:10,325 --> 00:50:13,725
Speaker 12:  like you'd be satisfied with community tonight but you would love if you

774
00:50:13,725 --> 00:50:17,405
Speaker 12:  found something new. And helping to tune finding that what you might love

775
00:50:17,425 --> 00:50:21,125
Speaker 12:  and be able to make those recommendations with better precision is, is something

776
00:50:21,125 --> 00:50:21,765
Speaker 12:  that we're always after.

777
00:50:22,185 --> 00:50:25,885
Speaker 2:  Got it. Okay. So is there really, there's no human interaction

778
00:50:26,025 --> 00:50:29,685
Speaker 2:  in this process where like something like Squid Game starts?

779
00:50:29,965 --> 00:50:32,445
Speaker 2:  'cause the, one of the funniest things about Squid Game to me is you could

780
00:50:32,445 --> 00:50:36,285
Speaker 2:  look at it at some point early in the process and think, oh the

781
00:50:36,285 --> 00:50:40,245
Speaker 2:  algorithm has gone completely haywire here. There's no way this

782
00:50:40,245 --> 00:50:43,605
Speaker 2:  many people in this many places wanna watch this specific show

783
00:50:44,075 --> 00:50:47,525
Speaker 2:  that we never in a million years would've put on this particular trajectory.

784
00:50:47,785 --> 00:50:51,685
Speaker 2:  And on the other hand, it's obviously like a smashing success for the system

785
00:50:52,075 --> 00:50:55,645
Speaker 2:  that it essentially, I'm assuming at some point basically told every person

786
00:50:55,705 --> 00:50:58,445
Speaker 2:  on Planet Earth, you should probably watch Squid Game. Everybody else is

787
00:50:58,605 --> 00:51:01,605
Speaker 2:  watching it and seems to like it. So is is there not a moment where you're,

788
00:51:01,605 --> 00:51:04,805
Speaker 2:  it's like jumping up the graph and you you have to have a meeting where you're

789
00:51:04,805 --> 00:51:06,925
Speaker 2:  like, what is happening here? Is this what's supposed to be going on?

790
00:51:07,235 --> 00:51:10,365
Speaker 12:  This is the beauty of it. We, it wasn't even necessary for Squid Game. It

791
00:51:10,365 --> 00:51:14,085
Speaker 12:  became big on its own. I think suits in the US is another good

792
00:51:14,085 --> 00:51:18,005
Speaker 12:  example where you maybe wouldn't have necessarily expected in advance

793
00:51:18,185 --> 00:51:21,765
Speaker 12:  how big suits could be at this point in time. And it's been

794
00:51:21,915 --> 00:51:25,445
Speaker 12:  huge. And so that's kind of the beauty of it where there's no need to be

795
00:51:25,445 --> 00:51:29,325
Speaker 12:  in the background pulling a separate lever. It's just again,

796
00:51:29,905 --> 00:51:33,765
Speaker 12:  try to think about from how do we be the best possible matchmaker

797
00:51:33,765 --> 00:51:37,285
Speaker 12:  between all the possible options you could have on Netflix and other services

798
00:51:37,285 --> 00:51:40,685
Speaker 12:  you might subscribe to and make the best, most compelling

799
00:51:40,685 --> 00:51:44,605
Speaker 12:  recommendations and the easiest, most hopefully fun To the extent browsing

800
00:51:44,605 --> 00:51:48,445
Speaker 12:  and finding something to watch tonight can be fun way so that when you do

801
00:51:48,445 --> 00:51:51,885
Speaker 12:  settle in on what you're gonna watch, you hit play and it's like ah,

802
00:51:52,355 --> 00:51:53,685
Speaker 12:  this was perfect for me.

803
00:51:54,245 --> 00:51:57,285
Speaker 2:  I would assume though that at some point kind of popularity begets

804
00:51:57,575 --> 00:52:01,485
Speaker 2:  popularity that like the bigger something gets the more comfortable the

805
00:52:01,485 --> 00:52:05,205
Speaker 2:  system gets recommending it more widely to people, maybe even

806
00:52:05,205 --> 00:52:08,805
Speaker 2:  further out of sort of the traditional strike zone of a show like that.

807
00:52:09,075 --> 00:52:12,605
Speaker 12:  Well I think again take, we can just focus on Squid game there as an example

808
00:52:12,615 --> 00:52:16,445
Speaker 12:  where yes of if you're thinking about that randomness

809
00:52:16,445 --> 00:52:19,965
Speaker 12:  or serendipity, imagine you're a member who's again never watched

810
00:52:20,385 --> 00:52:23,925
Speaker 12:  any Korean language content before. We can more

811
00:52:23,925 --> 00:52:27,765
Speaker 12:  confidently make that recommendation to you the more popular something

812
00:52:27,765 --> 00:52:31,525
Speaker 12:  is, especially among folks who are also members of Netflix

813
00:52:31,625 --> 00:52:33,765
Speaker 12:  who watch similar things to you. So yes, I'd say that's fair.

814
00:52:34,035 --> 00:52:37,285
Speaker 2:  Okay. And is there, is there any upside to having kind of

815
00:52:37,935 --> 00:52:41,885
Speaker 2:  human or editorial or or curatorial input here? I mean I

816
00:52:41,885 --> 00:52:44,645
Speaker 2:  think about like we, we talk to a lot of the folks at music services. We

817
00:52:44,645 --> 00:52:47,485
Speaker 2:  talk a lot about you have this giant corpus of stuff, we can do some really

818
00:52:47,685 --> 00:52:50,765
Speaker 2:  interesting personalization but also maybe what you want to know is what

819
00:52:50,965 --> 00:52:54,245
Speaker 2:  a person you think is smart likes or we can

820
00:52:54,685 --> 00:52:58,645
Speaker 2:  recommend don don't know, like Halloween is a good example, right? It was

821
00:52:58,645 --> 00:53:01,925
Speaker 2:  just Halloween. Let's put together a thing that is like some of our favorite

822
00:53:01,985 --> 00:53:05,605
Speaker 2:  old school Halloween movies. People love that kind of stuff. And if you do

823
00:53:05,605 --> 00:53:09,245
Speaker 2:  that at Netflix, you do it less obviously than some others.

824
00:53:09,425 --> 00:53:12,605
Speaker 2:  Is that kind of just not something you think is, is necessary at your scale?

825
00:53:13,265 --> 00:53:17,165
Speaker 12:  We, we do from time to time do things like that where we're offering

826
00:53:18,035 --> 00:53:21,325
Speaker 12:  collections that are representative of a moment in time. So

827
00:53:21,475 --> 00:53:24,485
Speaker 12:  Halloween would be, you know, that would be a very good example or other

828
00:53:24,485 --> 00:53:28,405
Speaker 12:  collections seasonally. So those kinds of collections do exist on Netflix

829
00:53:28,545 --> 00:53:31,805
Speaker 12:  and you can either seek them out yourself or from time to time you might

830
00:53:31,805 --> 00:53:35,565
Speaker 12:  find them, those kinds of recommendations promoted either on TV or on other

831
00:53:35,845 --> 00:53:39,645
Speaker 12:  platforms. You should think of those collections as still

832
00:53:39,805 --> 00:53:43,605
Speaker 12:  personalized in nature. So I, imagine you've had say a hundred candidates

833
00:53:43,665 --> 00:53:46,885
Speaker 12:  for a, some kind of a seasonal collection. We would still want to present

834
00:53:47,185 --> 00:53:50,605
Speaker 12:  titles to you in a personalized way. So whether that's what order they would

835
00:53:50,605 --> 00:53:54,045
Speaker 12:  be presented in or how they're positioned to you. As I was mentioning earlier,

836
00:53:54,095 --> 00:53:57,525
Speaker 12:  we've got a incredible creative production team that's thinking about what

837
00:53:57,525 --> 00:54:00,525
Speaker 12:  are all the possible ways you could represent a title, whether that's with

838
00:54:00,745 --> 00:54:04,605
Speaker 12:  art or the synopsis or video promotional assets. And

839
00:54:04,705 --> 00:54:07,765
Speaker 12:  we would still wanna do that in a way that positions any of those particular

840
00:54:07,765 --> 00:54:11,645
Speaker 12:  titles within a say more curated seasonal set in a way that would

841
00:54:11,645 --> 00:54:13,245
Speaker 12:  really hopefully resonate with you individually.

842
00:54:13,715 --> 00:54:17,565
Speaker 2:  Yeah, one of my favorite things to do on Netflix is scroll around and

843
00:54:17,665 --> 00:54:21,405
Speaker 2:  try to guess why the system picked that particular

844
00:54:21,865 --> 00:54:25,125
Speaker 2:  poster to show me for any given thing. 'cause I know there's a bunch of options,

845
00:54:25,385 --> 00:54:28,445
Speaker 2:  it shows them in lots of different ways. And I saw one that was just like,

846
00:54:28,965 --> 00:54:31,685
Speaker 2:  I forget what movie it was, but it was a movie in which Tom Cruise was like

847
00:54:31,685 --> 00:54:34,565
Speaker 2:  the fourth most important character in the movie, but the poster I saw was

848
00:54:34,565 --> 00:54:38,365
Speaker 2:  just Tom Cruise. And I was like, you know what? Like you're not wrong Netflix,

849
00:54:38,785 --> 00:54:41,845
Speaker 2:  but I wonder what it says about me as a person that it was like, you know

850
00:54:41,845 --> 00:54:44,005
Speaker 2:  what, David wants to watch this movie as Tom Cruise.

851
00:54:44,665 --> 00:54:47,245
Speaker 12:  You might be a huge Tom Cruise fan. You might have just revealed that. Oh

852
00:54:47,245 --> 00:54:50,565
Speaker 2:  Yeah, it's not wrong to be clear, it's not wrong at all, but it's, it was,

853
00:54:50,565 --> 00:54:53,485
Speaker 2:  yeah, it's just a very funny thing. And I think actually to that point, one

854
00:54:53,485 --> 00:54:57,125
Speaker 2:  of the things that I think has always been tricky about personalization over

855
00:54:57,125 --> 00:55:01,085
Speaker 2:  the years is pairing that with transparency. Like

856
00:55:01,085 --> 00:55:03,885
Speaker 2:  I think there's, there's a, an interesting thing that we found, and this

857
00:55:03,885 --> 00:55:06,685
Speaker 2:  is especially true I think on social media where we, we have these ranked

858
00:55:06,695 --> 00:55:10,405
Speaker 2:  feeds and people are like, why am I being shown this thing

859
00:55:10,715 --> 00:55:14,405
Speaker 2:  this way in this order? And there's, there's something about kind of

860
00:55:14,405 --> 00:55:18,205
Speaker 2:  understanding the order that is being presented to you that actually is really

861
00:55:18,205 --> 00:55:21,285
Speaker 2:  comforting and makes people feel better. And to some extent on Netflix, like

862
00:55:21,305 --> 00:55:25,005
Speaker 2:  you've done a bunch of work, it seems like making even just like the rows

863
00:55:25,005 --> 00:55:27,765
Speaker 2:  are fairly self-explanatory. Like here's what's trending, here's what's this

864
00:55:28,005 --> 00:55:31,165
Speaker 2:  category. But do you think about trying to sort of telegraph the reasons

865
00:55:31,185 --> 00:55:34,085
Speaker 2:  behind what you're showing people as you go? I

866
00:55:34,085 --> 00:55:37,445
Speaker 12:  Love this question because I think we've got opportunity to do better here.

867
00:55:37,465 --> 00:55:41,125
Speaker 12:  So we would call all the ways that we would position a recommendation or

868
00:55:41,125 --> 00:55:44,725
Speaker 12:  set of recommendations to you evidence for why something might be

869
00:55:44,725 --> 00:55:48,045
Speaker 12:  compelling to you. Right? And so explaining that evidence,

870
00:55:48,355 --> 00:55:52,325
Speaker 12:  there's good thinking behind that that is helpful for folks. So

871
00:55:52,465 --> 00:55:55,925
Speaker 12:  why is something presented to me, So I think we've made some good progress

872
00:55:55,925 --> 00:55:59,605
Speaker 12:  there on broadening the candidate set of reasons why something could

873
00:55:59,605 --> 00:56:02,285
Speaker 12:  potentially be a good fit for you. So I've hit on a few of those whether

874
00:56:02,315 --> 00:56:06,245
Speaker 12:  it's the art being tailored to you or the synopsis

875
00:56:06,305 --> 00:56:10,165
Speaker 12:  or other individual pieces of evidence, for example the cast or other

876
00:56:10,165 --> 00:56:13,845
Speaker 12:  folks involved in bringing that title to life and how that might resonate

877
00:56:13,845 --> 00:56:17,485
Speaker 12:  with you. But I think we can do even more, which is to say make the connection

878
00:56:17,485 --> 00:56:20,925
Speaker 12:  between here's really specifically why we think this might be a good fit

879
00:56:21,055 --> 00:56:24,725
Speaker 12:  based on whatever the meaningful to you reason might be. Whether it's

880
00:56:25,185 --> 00:56:28,445
Speaker 12:  for example in the Tom Cruise case, you've binged everything we have on

881
00:56:28,465 --> 00:56:31,925
Speaker 12:  Tom Cruise and this is why we think this would be awesome for you. Or it

882
00:56:31,925 --> 00:56:35,205
Speaker 12:  looks like you're ready to break out of your community Rutt here's what

883
00:56:35,205 --> 00:56:38,765
Speaker 12:  folks love, here's to cruise just broken, broken, here's Tom Cruise. Exactly.

884
00:56:39,105 --> 00:56:41,845
Speaker 12:  And when you wanna break outta your community rut, Tom Cruise is the

885
00:56:41,845 --> 00:56:45,005
Speaker 2:  Solve that's So I tell people that all the time. That makes sense and I think

886
00:56:45,115 --> 00:56:48,645
Speaker 2:  that it's another really interesting UI question over time.

887
00:56:48,905 --> 00:56:52,325
Speaker 2:  One of the things I love talking to people about on Netflix is the thumbs

888
00:56:52,325 --> 00:56:55,325
Speaker 2:  up, thumbs down system. don don't know if this is true. I haven't quizzed

889
00:56:55,325 --> 00:56:57,965
Speaker 2:  random strangers on this in a while, but for a long time I think the thing

890
00:56:57,965 --> 00:57:00,925
Speaker 2:  where it would say, you know, it would have the green thumbs up and it would

891
00:57:00,925 --> 00:57:04,805
Speaker 2:  be like 89% match, I think most people would read that

892
00:57:04,805 --> 00:57:07,965
Speaker 2:  as a sort of rotten tomato score that's like most people like this thing.

893
00:57:08,185 --> 00:57:12,085
Speaker 2:  That's not what it is, is my understanding. It is something closer to like

894
00:57:12,085 --> 00:57:15,685
Speaker 2:  the likelihood that you're gonna like this thing, but it's just a really

895
00:57:15,965 --> 00:57:19,285
Speaker 2:  fascinating thing of trying to telegraph. You have all this information about

896
00:57:19,285 --> 00:57:23,005
Speaker 2:  what I'm likely to like and why and to some

897
00:57:23,005 --> 00:57:26,925
Speaker 2:  extent all of that is useful for me to see as I'm browsing

898
00:57:27,115 --> 00:57:29,485
Speaker 2:  because by the time I've been doing this for a while, I have a fair amount

899
00:57:29,485 --> 00:57:32,245
Speaker 2:  of faith in Netflix's ability to show me something I'm gonna like. But the

900
00:57:32,245 --> 00:57:35,085
Speaker 2:  more you can tell me about it, the faster you can help me make those decisions.

901
00:57:35,545 --> 00:57:38,685
Speaker 2:  But A, you don't wanna overwhelm people I wouldn't think. And B,

902
00:57:39,385 --> 00:57:42,285
Speaker 2:  it just gets confusing at some point. There's just only so much you can show

903
00:57:42,285 --> 00:57:45,565
Speaker 2:  me. Especially if it's like you liked Beckham and the Crown, we think you'll

904
00:57:45,565 --> 00:57:47,845
Speaker 2:  love the great British speaking show. People are like, what the hell are

905
00:57:47,845 --> 00:57:51,405
Speaker 2:  you talking about? And so, so like I wonder even just from a UI perspective

906
00:57:51,665 --> 00:57:54,765
Speaker 2:  how you think about putting that stuff in front of people. Well

907
00:57:54,765 --> 00:57:57,565
Speaker 12:  You're absolutely right that it's, you've gotta make hard trade offs and

908
00:57:57,565 --> 00:58:01,165
Speaker 12:  that's, that's a hard design challenge when you're constrained

909
00:58:01,385 --> 00:58:05,005
Speaker 12:  in the UI. And so for the many tens of

910
00:58:05,405 --> 00:58:08,925
Speaker 12:  possible reasons why a title could be a great fit for you, if you think

911
00:58:08,925 --> 00:58:11,765
Speaker 12:  about this in the weeds a little bit on how someone's actually experiencing

912
00:58:11,765 --> 00:58:15,725
Speaker 12:  Netflix when you're browsing, you've got that first glimpse of a title

913
00:58:15,905 --> 00:58:19,325
Speaker 12:  and you're somewhat more restricted in what can be shown to you there. We

914
00:58:19,325 --> 00:58:23,125
Speaker 12:  want to try to present the evidence that is most compelling

915
00:58:23,125 --> 00:58:26,205
Speaker 12:  individually for you. So imagine again, there's tens of possible options

916
00:58:26,265 --> 00:58:30,205
Speaker 12:  say we'd wanna hopefully think about how we might rank those

917
00:58:30,265 --> 00:58:33,245
Speaker 12:  and then present the ones that are most compelling initially, which would

918
00:58:33,245 --> 00:58:36,405
Speaker 12:  then generate a little bit more interest from you. And then if you're one

919
00:58:36,405 --> 00:58:40,205
Speaker 12:  level deeper in that discovery journey revealed a little bit

920
00:58:40,205 --> 00:58:43,765
Speaker 12:  more, that would then be helpful. So as you're for example watching a trailer,

921
00:58:43,905 --> 00:58:46,205
Speaker 12:  you might learn a little bit more about the title just by watching the trailer,

922
00:58:46,205 --> 00:58:50,125
Speaker 12:  but there may be also additional longer form synopsis evidence or a

923
00:58:50,125 --> 00:58:53,765
Speaker 12:  little bit more on the cast or a little bit more on why this title is similar

924
00:58:53,785 --> 00:58:57,205
Speaker 12:  to others you've watched and why that might be a compelling match. So it's

925
00:58:57,385 --> 00:59:01,325
Speaker 12:  for sure a hard challenge. It tends to be great dividends for members

926
00:59:01,425 --> 00:59:03,925
Speaker 12:  to know a little bit more 'cause they're excited to know about well why

927
00:59:03,925 --> 00:59:07,045
Speaker 12:  would this be a good fit for me? And the way it manifests for us is

928
00:59:07,475 --> 00:59:11,365
Speaker 12:  hopefully we observe then better matches between our recommendations

929
00:59:11,365 --> 00:59:14,925
Speaker 12:  of what ultimately gets played and then ultimately higher member satisfaction.

930
00:59:15,665 --> 00:59:18,765
Speaker 2:  Got it. Okay. So again with, not to keep coming back to Squid Game, but with

931
00:59:18,765 --> 00:59:21,725
Speaker 2:  something like Squid Game, how do you tell that story to people? Do you eventually

932
00:59:21,725 --> 00:59:24,645
Speaker 2:  just turn it around and it's like just everybody's watching this like shut

933
00:59:24,645 --> 00:59:26,965
Speaker 2:  up hit play. Everybody's watching this show

934
00:59:27,265 --> 00:59:30,965
Speaker 12:  On that one. It's a, again, it's a good example of the

935
00:59:31,095 --> 00:59:34,925
Speaker 12:  robot in the art became particularly compelling and sure visually

936
00:59:35,205 --> 00:59:37,925
Speaker 12:  interesting. I think there's just something about that that was intriguing

937
00:59:37,925 --> 00:59:41,885
Speaker 12:  to folks And then for sure popularity plays a role there. So as something

938
00:59:41,995 --> 00:59:45,645
Speaker 12:  gets bigger and bigger and it's for example high up the top 10 list

939
00:59:45,835 --> 00:59:49,085
Speaker 12:  also your friends are talking about it, that social

940
00:59:49,815 --> 00:59:53,405
Speaker 12:  proof is often super compelling. And again, that's happening. You know,

941
00:59:53,425 --> 00:59:57,005
Speaker 12:  we don't wanna take too much credit in Netflix that's happening outside

942
00:59:57,075 --> 01:00:00,925
Speaker 12:  with your friends when you're on a run on a walk on social media, you're

943
01:00:00,925 --> 01:00:04,605
Speaker 12:  hearing about things and so that's happening just as much if not more off

944
01:00:04,605 --> 01:00:07,365
Speaker 12:  Netflix and the biggest versions of success when something is really blowing

945
01:00:07,385 --> 01:00:07,605
Speaker 12:  up.

946
01:00:07,795 --> 01:00:11,765
Speaker 2:  Yeah. Where do you see signals of that? I mean you mentioned searches increasing

947
01:00:12,225 --> 01:00:16,085
Speaker 2:  but also this elusive sort of sense of buzz is a very hard thing to

948
01:00:16,485 --> 01:00:20,405
Speaker 2:  quantify, but if you can becomes really useful. So like how, how

949
01:00:20,425 --> 01:00:23,725
Speaker 2:  do you, especially in that sort of growth moment before a show

950
01:00:24,155 --> 01:00:27,685
Speaker 2:  like Squid Game or Wednesday or whatever kind of takes over the world, what

951
01:00:27,705 --> 01:00:31,605
Speaker 2:  do you look at as those moments that like somebody is telling me on

952
01:00:31,605 --> 01:00:35,365
Speaker 2:  a run that I should go watch this show? Like you, you want to capture that

953
01:00:35,365 --> 01:00:39,005
Speaker 2:  and I, and the best case scenario would be when I go sit down on my couch

954
01:00:39,215 --> 01:00:42,365
Speaker 2:  there it is the thing that my friend just recommended to me, right? How do

955
01:00:42,365 --> 01:00:43,765
Speaker 2:  you, how do you bridge those two things?

956
01:00:44,025 --> 01:00:47,405
Speaker 12:  You should think of those, those things as like super indirect, right? And

957
01:00:47,405 --> 01:00:50,885
Speaker 12:  So I mentioned a couple of ways that would manifest the, the first before

958
01:00:50,885 --> 01:00:54,845
Speaker 12:  something launches that would be you come to Netflix and maybe in the case

959
01:00:54,845 --> 01:00:57,485
Speaker 12:  before Squid Game launches you say, oh I heard, I heard someone told me

960
01:00:57,485 --> 01:01:00,005
Speaker 12:  about this and you search for it and then you get to watch the trailer in

961
01:01:00,005 --> 01:01:02,525
Speaker 12:  advance and you find out it's not available yet you, you click remind me

962
01:01:02,525 --> 01:01:05,645
Speaker 12:  that same would be true on something like the Netflix Cup next week where

963
01:01:05,705 --> 01:01:08,285
Speaker 12:  not available yet. You can learn a little bit if you open the app and you

964
01:01:08,285 --> 01:01:12,125
Speaker 12:  hit remind me. So that's one indirect way. And then the other

965
01:01:12,125 --> 01:01:15,765
Speaker 12:  one would be search. And that tends to be great at

966
01:01:16,045 --> 01:01:20,005
Speaker 12:  indicating what people are excited about. And the great thing

967
01:01:20,005 --> 01:01:23,805
Speaker 12:  about the search results experience is it's also personalized and will

968
01:01:23,965 --> 01:01:27,685
Speaker 12:  continue to improve over time as behavior indicates what

969
01:01:28,105 --> 01:01:31,765
Speaker 12:  are the right responses to particular queries. So at the outside,

970
01:01:31,945 --> 01:01:35,885
Speaker 12:  for example, when someone first searches for Squid Game, maybe the results

971
01:01:35,885 --> 01:01:39,525
Speaker 12:  would not have Squid Game in precisely the first results position. But over

972
01:01:39,525 --> 01:01:42,845
Speaker 12:  time we would learn as people are playing Squid game after they type

973
01:01:43,545 --> 01:01:46,485
Speaker 12:  ssq and then immediately Squid game gets played at very high rates, then

974
01:01:46,485 --> 01:01:50,085
Speaker 12:  we would change those, the ordering of those

975
01:01:50,085 --> 01:01:53,685
Speaker 12:  recommendations and search results and hopefully match you very quickly

976
01:01:53,685 --> 01:01:55,205
Speaker 12:  with the thing that you actually have intent for.

977
01:01:55,385 --> 01:01:58,125
Speaker 2:  Got it. Okay. One of the smartest things I think Netflix has always done

978
01:01:58,125 --> 01:02:01,765
Speaker 2:  is that when you search for something that isn't on Netflix, it tries to

979
01:02:02,045 --> 01:02:05,645
Speaker 2:  recommend you. Things like that thing which is just the, the most like

980
01:02:05,945 --> 01:02:09,805
Speaker 2:  subtle devious stroke of genius, it's great. It's like we don't have this

981
01:02:09,805 --> 01:02:13,125
Speaker 2:  movie, don't worry about that. Watch these other movies. And I suspect that

982
01:02:13,125 --> 01:02:16,685
Speaker 2:  works. It's worked for me many times where it's like it picks something

983
01:02:17,075 --> 01:02:19,965
Speaker 2:  spiritually close enough that I'm like, oh okay, I'll, I've been meaning

984
01:02:19,965 --> 01:02:23,725
Speaker 2:  to watch that anyway. I had not really thought of search results as a discovery

985
01:02:23,785 --> 01:02:25,405
Speaker 2:  engine, but it kind of is one

986
01:02:25,875 --> 01:02:29,045
Speaker 12:  Very meaningful discovery source of discovery and you're right that it it,

987
01:02:29,045 --> 01:02:32,445
Speaker 12:  it can be frustrating if you're searching for that thing that is either

988
01:02:32,505 --> 01:02:36,285
Speaker 12:  not available yet or isn't available on Netflix and in your country and

989
01:02:36,585 --> 01:02:40,005
Speaker 12:  we still really want to help you have an incredible

990
01:02:40,255 --> 01:02:43,925
Speaker 12:  night tonight with Netflix and so hopefully we've got something if not exactly

991
01:02:43,955 --> 01:02:45,645
Speaker 12:  that thing that would be a good fit.

992
01:02:46,115 --> 01:02:49,245
Speaker 2:  What do you call the thing at the top, the super big thing? Is it like the

993
01:02:49,245 --> 01:02:51,885
Speaker 2:  hero? Is it the marquee? What do you call it? We

994
01:02:51,885 --> 01:02:53,845
Speaker 12:  Call that internally the billboard. The billboard.

995
01:02:53,845 --> 01:02:57,365
Speaker 2:  Okay. Let's talk about the billboard. The theory I hear about the billboard

996
01:02:57,365 --> 01:03:01,205
Speaker 2:  most often is that a, it is an unbelievably powerful piece of

997
01:03:01,205 --> 01:03:05,085
Speaker 2:  streaming real estate. That whatever you put there a lot of people are going

998
01:03:05,085 --> 01:03:08,965
Speaker 2:  to interact with in some way, shape or form. And that B, that

999
01:03:08,965 --> 01:03:12,805
Speaker 2:  is where Netflix brute forces things to be popular by force feeding it to

1000
01:03:13,685 --> 01:03:16,445
Speaker 2:  a hundred million people whenever it feels like it, just because it wants

1001
01:03:16,445 --> 01:03:19,685
Speaker 2:  to make a show popular. I have questions about both parts of that, but start

1002
01:03:19,685 --> 01:03:23,525
Speaker 2:  with the beginning is that as powerful a piece of screen real

1003
01:03:23,525 --> 01:03:26,685
Speaker 2:  estate as it seems like it might be that whatever you put there is going

1004
01:03:26,685 --> 01:03:29,645
Speaker 2:  to be more noticed by people

1005
01:03:29,915 --> 01:03:33,725
Speaker 12:  Certainly meaningful. But if you think about how members are spending time

1006
01:03:33,725 --> 01:03:37,485
Speaker 12:  with Netflix, they're coming in with something in mind and going to

1007
01:03:37,485 --> 01:03:41,325
Speaker 12:  search or they have a category in mind, whether it's a film or a genre

1008
01:03:41,505 --> 01:03:45,125
Speaker 12:  or this is the kind of mood I'm in tonight. So it's one of many

1009
01:03:45,555 --> 01:03:49,285
Speaker 12:  ways that folks do find what they wanna watch it. I won't disagree. It's

1010
01:03:49,285 --> 01:03:52,685
Speaker 12:  important, it's the first thing you see after you select your profile. Is

1011
01:03:52,685 --> 01:03:55,885
Speaker 12:  it the most important. There's lots of ways folks are expressing what they're

1012
01:03:55,885 --> 01:03:57,885
Speaker 12:  interested in to watch watching tonight.

1013
01:03:58,195 --> 01:04:00,845
Speaker 2:  Okay. And do you think this is a total aside, I'm gonna get to my second

1014
01:04:00,965 --> 01:04:03,245
Speaker 2:  question in a second, but I think that the way you just described that is

1015
01:04:03,245 --> 01:04:06,605
Speaker 2:  really interesting 'cause it sort of assumes people come in with like one

1016
01:04:06,605 --> 01:04:10,445
Speaker 2:  data point about what they're looking for, which sort of makes sense. But

1017
01:04:10,445 --> 01:04:13,765
Speaker 2:  also III can imagine there's a set of people out there who just open Netflix.

1018
01:04:13,915 --> 01:04:17,445
Speaker 2:  Like I think this is the unique thing about Netflix at this point is that

1019
01:04:17,585 --> 01:04:21,525
Speaker 2:  you're big enough to essentially just be the thing and I'm just gonna open

1020
01:04:21,525 --> 01:04:24,845
Speaker 2:  it and see what happens. Does that behavior exist and do you have to treat

1021
01:04:24,845 --> 01:04:27,605
Speaker 2:  those people differently who sincerely have no idea what they want, they

1022
01:04:27,605 --> 01:04:29,205
Speaker 2:  just wanna watch something

1023
01:04:29,555 --> 01:04:33,525
Speaker 12:  That would be nirvana for us where you're, you're, you're so confident that

1024
01:04:33,525 --> 01:04:37,165
Speaker 12:  we're gonna have both options and make great recommendations

1025
01:04:37,175 --> 01:04:41,005
Speaker 12:  among those options that when you wanna relax

1026
01:04:41,625 --> 01:04:45,525
Speaker 12:  and you're ready to watch or play something that you

1027
01:04:45,525 --> 01:04:49,125
Speaker 12:  think of us first. And so you sit down on the couch and

1028
01:04:49,345 --> 01:04:52,805
Speaker 12:  you just hit the Netflix button on your remote because you're so confident

1029
01:04:52,805 --> 01:04:56,525
Speaker 12:  you're gonna find something great on Netflix, you are

1030
01:04:56,525 --> 01:04:59,845
Speaker 12:  completely right that there's this spectrum where some nights

1031
01:05:00,305 --> 01:05:03,765
Speaker 12:  you know exactly what you're excited about. So when you're

1032
01:05:04,055 --> 01:05:07,965
Speaker 12:  right in the middle of the newest season of, for

1033
01:05:07,965 --> 01:05:11,485
Speaker 12:  example now for me right now it's the crown where I'm, I'm watching it on

1034
01:05:11,485 --> 01:05:15,245
Speaker 12:  our internal employee preview and I'm like, I am so excited tonight

1035
01:05:15,265 --> 01:05:18,765
Speaker 12:  to sit down on the couch and and watch, watch the next episode. So that's

1036
01:05:18,765 --> 01:05:21,445
Speaker 12:  gonna be more likely that I'm gonna continue watching something as opposed

1037
01:05:21,445 --> 01:05:25,125
Speaker 12:  to be looking for something new. And then there's lots of nights where

1038
01:05:25,135 --> 01:05:29,085
Speaker 12:  folks sit down and they have no idea and they just want

1039
01:05:29,085 --> 01:05:32,365
Speaker 12:  to find something great and they're willing to sit down and and go on a

1040
01:05:32,365 --> 01:05:35,725
Speaker 12:  discovery journey. And that's the fun, quite challenging problem we have

1041
01:05:35,845 --> 01:05:39,725
Speaker 12:  is how do we make that the right amount fun, serendipitous

1042
01:05:39,725 --> 01:05:43,045
Speaker 12:  but also efficient so that it doesn't feel like I'm slogging through it.

1043
01:05:43,045 --> 01:05:46,685
Speaker 12:  So we, we want to go from inexperience that can at times feel

1044
01:05:46,765 --> 01:05:50,685
Speaker 12:  overwhelming to an experience that feels most of the time incredibly

1045
01:05:50,685 --> 01:05:53,805
Speaker 12:  delightful so that when you do finally land on the thing that's a perfect

1046
01:05:53,905 --> 01:05:57,805
Speaker 12:  fit for you, you look back on that discovery journey and it felt great.

1047
01:05:58,185 --> 01:06:02,045
Speaker 2:  Is that a thing you can discern in real time that like if

1048
01:06:02,125 --> 01:06:05,965
Speaker 2:  I open up the app and I scroll past continue watching

1049
01:06:05,965 --> 01:06:09,365
Speaker 2:  and I'm now five rows deep, you can suddenly like assume that I'm

1050
01:06:09,865 --> 01:06:13,485
Speaker 2:  on a more open-ended discovery experience and show me different stuff. Like

1051
01:06:13,485 --> 01:06:17,245
Speaker 2:  is that, can you be that sort of responsive to what people are doing?

1052
01:06:17,675 --> 01:06:19,405
Speaker 2:  Even like button click to button click

1053
01:06:20,015 --> 01:06:23,685
Speaker 12:  We're humble and we, we know we can always do better on that front but

1054
01:06:24,005 --> 01:06:26,805
Speaker 12:  I think you make a good, you know, your hunch there is probably a good one

1055
01:06:26,805 --> 01:06:30,085
Speaker 12:  where if you're completely in in the mode for the thing that you were

1056
01:06:30,725 --> 01:06:33,805
Speaker 12:  watching last night and you're ready to watch the next episode, then it's

1057
01:06:33,805 --> 01:06:36,805
Speaker 12:  a pretty good chance you might go straight to it. But if you skip over it

1058
01:06:36,825 --> 01:06:40,645
Speaker 12:  and you start to demonstrate interest more broadly than that, a job

1059
01:06:40,665 --> 01:06:44,565
Speaker 12:  we want to do much better is be able to pick up on what

1060
01:06:44,565 --> 01:06:47,925
Speaker 12:  you might be in the mood for tonight more quickly and adapt our

1061
01:06:47,925 --> 01:06:51,765
Speaker 12:  recommendations accordingly right in the moment so that like if

1062
01:06:51,765 --> 01:06:55,365
Speaker 12:  you're, seems like oh tonight might be a movie night for David

1063
01:06:55,665 --> 01:06:59,605
Speaker 12:  and based on his browsing right now it might be a Tom Cruise movie night.

1064
01:07:00,025 --> 01:07:04,005
Speaker 12:  We want to accordingly adjust and make it easy for you to then

1065
01:07:04,005 --> 01:07:07,005
Speaker 12:  satisfy that interest. And you might not have known that before you, before

1066
01:07:07,005 --> 01:07:10,445
Speaker 12:  you showed up, but it might have as you sort of browsing is like, oh this

1067
01:07:10,465 --> 01:07:12,245
Speaker 12:  is, this is a Tom Cruise movie night for me,

1068
01:07:12,525 --> 01:07:15,645
Speaker 2:  I really like the idea that the longer I spend browsing Netflix, like the

1069
01:07:15,645 --> 01:07:18,765
Speaker 2:  weirder the recommendations would start to get that it's eventually just

1070
01:07:18,765 --> 01:07:21,965
Speaker 2:  like don don't know just, just watch this. You, you clearly don't know what

1071
01:07:21,965 --> 01:07:24,205
Speaker 2:  you want, we don't know what you want. Like here's some stuff, let's see

1072
01:07:24,205 --> 01:07:25,565
Speaker 2:  what happens. I kinda enjoy that.

1073
01:07:25,745 --> 01:07:29,565
Speaker 12:  The magic would be the longer that you spend, the better that the, that

1074
01:07:29,565 --> 01:07:32,765
Speaker 12:  final recommendation would be because we would then have known so much more

1075
01:07:32,765 --> 01:07:35,205
Speaker 12:  about the things you could have been interested in and might not have been

1076
01:07:35,205 --> 01:07:39,085
Speaker 12:  interested in. So one thing that's a little more challenging is extracting

1077
01:07:39,745 --> 01:07:43,005
Speaker 12:  say negative feedback from you. So it would be nice for us to know with

1078
01:07:43,005 --> 01:07:46,365
Speaker 12:  a little bit more precision when you skip over something, whether you spend

1079
01:07:46,365 --> 01:07:50,125
Speaker 12:  a little bit of time with a trailer and you say, oh that's not for me

1080
01:07:50,125 --> 01:07:53,445
Speaker 12:  tonight. Sometimes that's a little more challenging for us to know precisely

1081
01:07:53,445 --> 01:07:55,725
Speaker 12:  in the moment and that's an area where we wanna spend a little more time.

1082
01:07:55,825 --> 01:07:56,245
Speaker 12:  That's

1083
01:07:56,365 --> 01:07:59,125
Speaker 2:  Interesting the question of like is this something that's not interesting

1084
01:07:59,125 --> 01:08:02,925
Speaker 2:  to me or just not what I wanna watch tonight but like show this to me

1085
01:08:02,925 --> 01:08:04,165
Speaker 2:  again in a few days kind of thing?

1086
01:08:04,195 --> 01:08:07,045
Speaker 12:  Exactly. What a fun hard problem where it's like it's very difficult to

1087
01:08:07,045 --> 01:08:10,965
Speaker 12:  necessarily parse, I never want to see this again. So a thumbs down means

1088
01:08:10,965 --> 01:08:14,685
Speaker 12:  please never show this thing to me again or I'm just not in the mood for

1089
01:08:14,685 --> 01:08:15,405
Speaker 12:  it tonight. Yeah.

1090
01:08:15,595 --> 01:08:18,845
Speaker 2:  Okay. The second question is, I think the overarching

1091
01:08:19,305 --> 01:08:23,005
Speaker 2:  theory about the billboard is that that is where Netflix like

1092
01:08:23,345 --> 01:08:27,165
Speaker 2:  flexes, its originals and says we spend a bunch of money on this

1093
01:08:27,165 --> 01:08:29,725
Speaker 2:  show, you're gonna watch it so we're gonna show it to you every time you

1094
01:08:29,725 --> 01:08:33,645
Speaker 2:  open the app whether you want to or not. Here it is, watch it. We

1095
01:08:33,645 --> 01:08:34,965
Speaker 2:  demand is that how It works?

1096
01:08:35,715 --> 01:08:39,005
Speaker 12:  Follows the same approach that we've been talking about for, for the last

1097
01:08:39,005 --> 01:08:42,645
Speaker 12:  40 minutes or so personalized to you. We want to, our, our goals

1098
01:08:42,895 --> 01:08:46,885
Speaker 12:  every time you open the app are to match you with something compelling and

1099
01:08:46,885 --> 01:08:50,645
Speaker 12:  whether that's a Netflix original or not, something we license

1100
01:08:50,715 --> 01:08:54,565
Speaker 12:  from a studio supplier doesn't matter to us at all. We want you

1101
01:08:54,565 --> 01:08:56,725
Speaker 12:  to be incredibly satisfied. I

1102
01:08:56,725 --> 01:08:59,525
Speaker 2:  Really want to believe you. Like I, I really earnestly wanna believe you

1103
01:08:59,525 --> 01:09:02,045
Speaker 2:  but I can also see a bunch of really good reasons it would be the other way,

1104
01:09:02,055 --> 01:09:06,005
Speaker 2:  right? Like it makes sense for Netflix as of service

1105
01:09:06,185 --> 01:09:09,965
Speaker 2:  to prioritize the stuff that it owns for lots of reasons that it's not gonna

1106
01:09:09,965 --> 01:09:13,725
Speaker 2:  leave the service anytime soon. You have control over the ip, you can do

1107
01:09:13,725 --> 01:09:17,085
Speaker 2:  all kinds of stuff with more popular shows that you make than something that

1108
01:09:17,085 --> 01:09:20,685
Speaker 2:  you've licensed from somebody else. Also there are costs associated with

1109
01:09:20,685 --> 01:09:23,405
Speaker 2:  these things and you wanna recoup the costs and you made them because you

1110
01:09:23,405 --> 01:09:25,165
Speaker 2:  think people are gonna like them. So you wanna put them in front of people.

1111
01:09:25,665 --> 01:09:29,285
Speaker 2:  So I guess why not put some of that in there? Like

1112
01:09:29,505 --> 01:09:32,685
Speaker 2:  are the, is there an internal balance that you have to strike in how to get

1113
01:09:32,685 --> 01:09:34,525
Speaker 2:  that stuff right even if you're not showing it to people?

1114
01:09:34,825 --> 01:09:38,285
Speaker 12:  If you again come back to our business model, the nice thing is we have

1115
01:09:38,285 --> 01:09:42,045
Speaker 12:  really good alignment here. So with the subscription business model, you've

1116
01:09:42,045 --> 01:09:45,685
Speaker 12:  got a choice every month and the trade is your hard earned money

1117
01:09:45,865 --> 01:09:49,725
Speaker 12:  for incredible entertainment every month. And so our, our end of the bargain

1118
01:09:49,865 --> 01:09:53,845
Speaker 12:  is match you up with hopefully something great among an increasingly

1119
01:09:54,015 --> 01:09:57,925
Speaker 12:  broad catalog. And so if we have a choice between something that's

1120
01:09:57,925 --> 01:10:01,325
Speaker 12:  less good for you but is a Netflix original or something that is better

1121
01:10:01,345 --> 01:10:04,005
Speaker 12:  for you and not a Netflix original, we're gonna take that better for you

1122
01:10:04,135 --> 01:10:07,925
Speaker 12:  every single time because our goal is for you to be

1123
01:10:08,215 --> 01:10:12,005
Speaker 12:  incredibly satisfied and to be entertained. And so at any given night,

1124
01:10:12,105 --> 01:10:15,285
Speaker 12:  if that's less likely to be an Netflix original based on what you like to

1125
01:10:15,285 --> 01:10:17,365
Speaker 12:  watch or what you're in the mood for tonight, that's okay with us.

1126
01:10:17,945 --> 01:10:20,525
Speaker 2:  So do you think the people who feel like they're being sort of, you know,

1127
01:10:20,805 --> 01:10:23,885
Speaker 2:  bludgeoned over the head with squid game or whatever else, is that mostly

1128
01:10:24,185 --> 01:10:27,845
Speaker 2:  due to like having a hard time reading those negative signals where it's

1129
01:10:27,845 --> 01:10:31,245
Speaker 2:  like okay you skipped past this, is that because you hate it and never wanna

1130
01:10:31,245 --> 01:10:33,765
Speaker 2:  see it again? Or just because it's not what you're in the mood for right

1131
01:10:33,765 --> 01:10:37,565
Speaker 2:  now? Like as it as you get better at understanding what people are doing,

1132
01:10:37,635 --> 01:10:40,925
Speaker 2:  sort of click to click, do you think people will feel less and less of that

1133
01:10:40,925 --> 01:10:43,845
Speaker 2:  sense of like this thing is here every time I open the app even though I

1134
01:10:43,845 --> 01:10:44,365
Speaker 2:  don't wanna watch it?

1135
01:10:44,595 --> 01:10:47,725
Speaker 12:  Some of that could be popularity oriented. Okay as you mentioned earlier.

1136
01:10:47,865 --> 01:10:51,805
Speaker 12:  So if something is quite popular and it's not for you then you might

1137
01:10:51,825 --> 01:10:55,485
Speaker 12:  see that in something like the top 10 list, which is quite literally what

1138
01:10:55,485 --> 01:10:58,845
Speaker 12:  are the series and films in your country that are top 10? That one

1139
01:10:58,845 --> 01:11:00,445
Speaker 2:  I think is fairly understandable. Yeah. Yeah.

1140
01:11:00,745 --> 01:11:04,365
Speaker 12:  So those sorts of popularity signals can be hard to get around. I think

1141
01:11:04,365 --> 01:11:08,085
Speaker 12:  as I mentioned earlier, I think we have more to do on incorporating both

1142
01:11:08,115 --> 01:11:11,365
Speaker 12:  more major and then that more modest negative feedback like please don't

1143
01:11:11,525 --> 01:11:13,765
Speaker 12:  recommend this to me anymore. And So I think think there's more we can do

1144
01:11:13,765 --> 01:11:14,245
Speaker 12:  there for sure

1145
01:11:14,745 --> 01:11:17,765
Speaker 2:  All right. I have two more questions for you. One question people ask a lot

1146
01:11:17,765 --> 01:11:21,205
Speaker 2:  about kind of anything that is algorithmically curated like this is

1147
01:11:21,625 --> 01:11:25,485
Speaker 2:  how do I exert some control over it, right? I think like

1148
01:11:25,605 --> 01:11:29,005
Speaker 2:  I, I want to teach Netflix what I like and don't like and I think,

1149
01:11:29,745 --> 01:11:32,285
Speaker 2:  I'm assuming the first thing you're gonna say is like watch stuff you like,

1150
01:11:32,285 --> 01:11:36,045
Speaker 2:  which fair enough. But what else do you look at as sort of strong

1151
01:11:36,275 --> 01:11:40,085
Speaker 2:  like actual user action signals that

1152
01:11:40,305 --> 01:11:43,045
Speaker 2:  can push Netflix in the direction of stuff that they like?

1153
01:11:43,425 --> 01:11:45,925
Speaker 12:  Let us know when you really love something and the best way you can do that

1154
01:11:46,065 --> 01:11:49,805
Speaker 12:  is when you really love it, give it two thumbs up when you love it,

1155
01:11:50,035 --> 01:11:52,765
Speaker 12:  give it a thumbs up and if you didn't like it, that's okay. Let us know.

1156
01:11:52,765 --> 01:11:55,685
Speaker 12:  Give it a thumbs down. So that's one very concrete way I

1157
01:11:55,685 --> 01:11:57,805
Speaker 2:  Would think the thumbs down is a very strong signal

1158
01:11:58,075 --> 01:12:01,205
Speaker 12:  That is generally a strong signal, but that's okay. Yeah, we, we, we would,

1159
01:12:01,205 --> 01:12:04,245
Speaker 12:  like I said, as I said we'd like to hear it because that then helps us know

1160
01:12:04,275 --> 01:12:08,045
Speaker 12:  what resonated versus what didn't. So that's probably the best place to

1161
01:12:08,045 --> 01:12:11,965
Speaker 12:  do it. And then generally speaking, we don't want to force

1162
01:12:12,185 --> 01:12:16,125
Speaker 12:  effort on members. We want to make it effortless for you to both find

1163
01:12:16,125 --> 01:12:19,485
Speaker 12:  something to watch and then enjoy watching it. So that's have an incredible

1164
01:12:19,485 --> 01:12:22,965
Speaker 12:  discovery experience, have an playback experience that never

1165
01:12:23,165 --> 01:12:26,165
Speaker 12:  rebuffs and always feels wonderful and makes it easy for you to

1166
01:12:26,915 --> 01:12:30,565
Speaker 12:  turn on subs for a night that you want subs on and

1167
01:12:30,755 --> 01:12:34,005
Speaker 12:  have, you know, hopefully magically know that for this particular

1168
01:12:35,005 --> 01:12:38,205
Speaker 12:  language and content type combination you would never want subs. So, so

1169
01:12:38,205 --> 01:12:41,565
Speaker 12:  we wouldn't automatically do that but that's it. Literally just watch as

1170
01:12:41,565 --> 01:12:44,565
Speaker 12:  you, as you guessed, watch things that you like and then give us the feedback

1171
01:12:44,585 --> 01:12:47,205
Speaker 12:  and, and then the best way you can do that is thumbs up, thumbs down or

1172
01:12:47,205 --> 01:12:47,845
Speaker 12:  double thumbs up.

1173
01:12:48,195 --> 01:12:51,605
Speaker 2:  Okay. Why not give people tons more tools to

1174
01:12:51,995 --> 01:12:54,885
Speaker 2:  show you what they do and don't like. I know there's the don don't know if

1175
01:12:54,885 --> 01:12:57,925
Speaker 2:  you still do it, I haven't signed up for Netflix in a long time, but the

1176
01:12:57,925 --> 01:13:00,645
Speaker 2:  thing where you would sort of solve the cold start problem by saying just

1177
01:13:00,645 --> 01:13:03,445
Speaker 2:  like rate a few things that here, here are some things, do you like these

1178
01:13:03,445 --> 01:13:06,605
Speaker 2:  or not? And that's a decent way of the Cold Start problem. But I know there

1179
01:13:06,605 --> 01:13:09,765
Speaker 2:  are a lot of tools where you can like make lists and some people have sort

1180
01:13:09,765 --> 01:13:12,965
Speaker 2:  of stolen the Tinder mechanic of like right and left swiping stuff you like

1181
01:13:12,965 --> 01:13:16,885
Speaker 2:  and don't like. Why not give people access to sort of all that

1182
01:13:16,885 --> 01:13:19,605
Speaker 2:  kind of stuff that is just like, tell us everything you want to tell us about

1183
01:13:19,605 --> 01:13:21,645
Speaker 2:  what you like so that we can tune it for you. Do

1184
01:13:21,645 --> 01:13:24,365
Speaker 12:  We still do that taste tuning when you first sign up for Netflix? Okay,

1185
01:13:24,385 --> 01:13:27,645
Speaker 12:  so you tell us a little bit about a handful of series or films that you

1186
01:13:27,645 --> 01:13:30,645
Speaker 12:  like so that we can do a little bit better with that cold start problem

1187
01:13:30,645 --> 01:13:33,605
Speaker 12:  and get you started with good recommendations. I think it's a fair question

1188
01:13:33,615 --> 01:13:37,605
Speaker 12:  could from time to time you be asked to maybe retune

1189
01:13:37,605 --> 01:13:40,445
Speaker 12:  every now and then and members might have an interest in that. So that's

1190
01:13:40,445 --> 01:13:43,445
Speaker 12:  there's, we've tried things like that in the past. We don't have anything

1191
01:13:43,675 --> 01:13:47,205
Speaker 12:  running right now or that does exactly that, but you could imagine for example,

1192
01:13:47,745 --> 01:13:51,685
Speaker 12:  if you've got a, a list of titles you watched and you want to provide

1193
01:13:51,685 --> 01:13:55,325
Speaker 12:  ratings on those titles, then that might be a way for us to improve your

1194
01:13:55,325 --> 01:13:57,685
Speaker 12:  recommendations even more so we can get that explicit feedback. So you've,

1195
01:13:57,685 --> 01:14:00,445
Speaker 12:  you've got a queue of 10 things you've finished over the last handful of

1196
01:14:00,445 --> 01:14:03,365
Speaker 12:  months, why, why wouldn't we ask you a little bit more directly? Give us

1197
01:14:03,365 --> 01:14:06,965
Speaker 12:  a thumbs up, thumbs down, et cetera. So possible, you know, nothing on the

1198
01:14:06,965 --> 01:14:08,965
Speaker 12:  horizon there precisely, but I like the idea.

1199
01:14:09,515 --> 01:14:12,845
Speaker 2:  Okay, fair enough. And then the last thing I'm curious about is how

1200
01:14:13,845 --> 01:14:16,885
Speaker 2:  specifically it is useful to personalize, like we talk about personalization,

1201
01:14:16,945 --> 01:14:20,405
Speaker 2:  but there's a whole spectrum of things that that means. So like when you

1202
01:14:20,405 --> 01:14:23,965
Speaker 2:  think about Netflix personalization, is that to me David,

1203
01:14:24,185 --> 01:14:28,165
Speaker 2:  is that to my house? Is that to people like me? Is that to

1204
01:14:28,425 --> 01:14:31,405
Speaker 2:  don? Don't know. Are there a million people in the cohort that I'm a part

1205
01:14:31,405 --> 01:14:34,965
Speaker 2:  of? Like how specific is it even sort of useful and

1206
01:14:35,285 --> 01:14:37,485
Speaker 2:  valuable to go as you're thinking about this stuff?

1207
01:14:37,735 --> 01:14:41,445
Speaker 12:  Incredibly individual. Okay, so it's, it's to your profile. So if you've

1208
01:14:41,445 --> 01:14:45,125
Speaker 12:  got multiple profiles set up on your Netflix account, each of those profiles

1209
01:14:45,265 --> 01:14:49,085
Speaker 12:  is, has an individually tailored set of recommendations.

1210
01:14:49,465 --> 01:14:52,845
Speaker 2:  And if you're not doing things like demographics and all that stuff, they

1211
01:14:52,845 --> 01:14:54,925
Speaker 2:  should have essentially nothing to do with each other, right?

1212
01:14:55,385 --> 01:14:59,365
Speaker 12:  All we know about each of those profiles is literally the pattern of

1213
01:14:59,465 --> 01:15:03,365
Speaker 12:  of watching or gameplay. Okay. And that's, that is the, the only input and

1214
01:15:03,365 --> 01:15:07,125
Speaker 12:  the the purest input that we can take to then make the next great

1215
01:15:07,125 --> 01:15:08,365
Speaker 12:  hopefully recommendation for you.

1216
01:15:08,785 --> 01:15:11,805
Speaker 2:  Got it. Okay. So yeah, I mean, and that winds me all the way back to like

1217
01:15:12,185 --> 01:15:15,805
Speaker 2:  how much data is it useful to have part of this? 'cause I think don don't

1218
01:15:15,805 --> 01:15:19,205
Speaker 2:  know, presumably there are things you could know about me as a person that

1219
01:15:19,215 --> 01:15:22,125
Speaker 2:  might make some of it better. But then I guess at the scale you're working

1220
01:15:22,125 --> 01:15:26,085
Speaker 2:  at like that, that eventually becomes untenable to try and

1221
01:15:26,085 --> 01:15:29,685
Speaker 2:  like individually identify every single person based on like their eye color

1222
01:15:29,745 --> 01:15:30,925
Speaker 2:  And, what that might mean. They'd like,

1223
01:15:31,015 --> 01:15:35,005
Speaker 12:  Quite honestly we've, we've got more than we can handle more ideas than

1224
01:15:35,005 --> 01:15:38,765
Speaker 12:  we can handle with just how members are using Netflix today. So just by

1225
01:15:39,155 --> 01:15:42,765
Speaker 12:  revealing their tastes and preferences based on among the recommendations

1226
01:15:42,765 --> 01:15:46,725
Speaker 12:  we show, what do you try, what do you not finish, what do

1227
01:15:46,725 --> 01:15:49,565
Speaker 12:  you finish all the way to completion? What do you finish quickly, as I was

1228
01:15:49,565 --> 01:15:53,005
Speaker 12:  mentioning earlier, if there are ways for us to have a little bit better

1229
01:15:53,005 --> 01:15:56,445
Speaker 12:  sense for what you loved versus you just liked. So one way you could tell

1230
01:15:56,445 --> 01:15:59,725
Speaker 12:  us that would be two thumbs up versus one thumb up and doing that more frequently

1231
01:15:59,725 --> 01:16:03,525
Speaker 12:  for example. But if there might be other ways where we could extract a little

1232
01:16:03,525 --> 01:16:07,445
Speaker 12:  more signal with respect to time, even better spent and time, you're super

1233
01:16:07,885 --> 01:16:10,805
Speaker 12:  thrilled to have spent with Netflix that those would be great ways for us

1234
01:16:10,805 --> 01:16:14,085
Speaker 12:  to continue to enrich the way we improve our recommendations for you.

1235
01:16:14,305 --> 01:16:17,205
Speaker 2:  Got it. Okay. All, right, this is my actual last question. I swear I've said

1236
01:16:17,205 --> 01:16:20,765
Speaker 2:  this three times now. This is my actual last question. Tell me about thumbs

1237
01:16:20,825 --> 01:16:24,205
Speaker 2:  versus stars. I find this totally fascinating and I think you've been at

1238
01:16:24,205 --> 01:16:28,125
Speaker 2:  Netflix long enough to have seen both sides. So, I will just lay on my

1239
01:16:28,125 --> 01:16:31,965
Speaker 2:  cards on the table. I think five star scales are the stupidest thing on the

1240
01:16:32,085 --> 01:16:35,325
Speaker 2:  internet and I think they, they essentially mean nothing. But I'm curious

1241
01:16:35,325 --> 01:16:38,845
Speaker 2:  about how you think about like the one thumb, two thumb thumbs down

1242
01:16:39,215 --> 01:16:42,885
Speaker 2:  thing versus a five star recommendation and why the thumbs works better.

1243
01:16:43,265 --> 01:16:46,605
Speaker 12:  Thumbs is a simple way for you to provide

1244
01:16:47,165 --> 01:16:50,245
Speaker 12:  feedback on whether you like something or didn't like something. The the

1245
01:16:50,245 --> 01:16:52,805
Speaker 12:  trick on stars, and it sounds like you're not in the Stars camp So I don't

1246
01:16:52,805 --> 01:16:56,565
Speaker 12:  have to persuade you. The trick on stars is sometimes you might rate

1247
01:16:56,565 --> 01:16:59,805
Speaker 12:  something very highly on the stars because that's how something you think

1248
01:16:59,805 --> 01:17:03,085
Speaker 12:  something ought to be perceived. So it's critically acclaimed and, and so

1249
01:17:03,085 --> 01:17:06,525
Speaker 12:  you feel like it deserves many stars as opposed to how did you actually

1250
01:17:06,595 --> 01:17:10,205
Speaker 12:  feel about it? And that's what's more meaningful to improve your

1251
01:17:10,205 --> 01:17:14,085
Speaker 12:  recommendations is the reflection of how you actually felt about something

1252
01:17:14,085 --> 01:17:17,845
Speaker 12:  and whether it was good for you. And so thumbs as the benefit of

1253
01:17:18,265 --> 01:17:22,045
Speaker 12:  one being simpler and two, hopefully being a better reflection of

1254
01:17:22,315 --> 01:17:26,085
Speaker 12:  what you actually love or didn't love about what you're watching on Netflix.

1255
01:17:26,425 --> 01:17:26,845
Speaker 12:  That's

1256
01:17:27,005 --> 01:17:30,285
Speaker 2:  Interesting. That's actually a more like emotional answer than I was expecting.

1257
01:17:30,445 --> 01:17:33,645
Speaker 2:  'cause I think to me the problem is always that if I like something, do I

1258
01:17:33,645 --> 01:17:37,485
Speaker 2:  give it five stars or four stars or three stars? Literally no one knows

1259
01:17:37,485 --> 01:17:39,925
Speaker 2:  and everybody has different ideas. So you end up with a totally meaningless

1260
01:17:39,925 --> 01:17:42,445
Speaker 2:  scale. So, I've always liked the thumbs up, thumbs down because did I like

1261
01:17:42,445 --> 01:17:46,125
Speaker 2:  this or not? Is a much easier question to answer I think.

1262
01:17:46,345 --> 01:17:49,085
Speaker 2:  But you're describing something really different where it's like I, we want

1263
01:17:49,085 --> 01:17:53,005
Speaker 2:  you to tell us how you feel not is this good? And that's actually

1264
01:17:53,005 --> 01:17:54,405
Speaker 2:  like a really different thing.

1265
01:17:54,705 --> 01:17:57,725
Speaker 12:  Is it good for you? I mean that's the response that we would like. And so

1266
01:17:58,025 --> 01:18:01,885
Speaker 12:  that's the benefit of the simple two thumbs up, one thumb up and one thumb

1267
01:18:01,885 --> 01:18:05,565
Speaker 12:  down is that it's pretty clear to most people. What does, what does that

1268
01:18:05,565 --> 01:18:05,925
Speaker 12:  mean to you?

1269
01:18:06,445 --> 01:18:09,085
Speaker 2:  I love it. All, right? I promise. That was my last question. So I will let

1270
01:18:09,085 --> 01:18:11,325
Speaker 2:  you go, but thank you for doing this. This was really fun. I really appreciate

1271
01:18:11,325 --> 01:18:15,125
Speaker 12:  It. Very fun David, great to spend the time with you and I look forward

1272
01:18:15,125 --> 01:18:16,045
Speaker 12:  to catching up again soon.

1273
01:18:16,875 --> 01:18:19,885
Speaker 2:  Alright, we gotta take one more break and then we're gonna get to the hotline.

1274
01:18:20,175 --> 01:18:20,845
Speaker 2:  We'll be right back.

1275
01:20:33,475 --> 01:20:36,825
Speaker 2:  We're back. Let's take a question from The Vergecast hotline. As a reminder,

1276
01:20:36,925 --> 01:20:40,705
Speaker 2:  you can always email Vergecast at The Verge dot com or call 8

1277
01:20:40,945 --> 01:20:44,705
Speaker 2:  6 6 Verge one one to reach us. We try and answer at least one question on

1278
01:20:44,705 --> 01:20:48,625
Speaker 2:  the show every Wednesday. Thank you as always. To everybody who calls and

1279
01:20:48,625 --> 01:20:52,065
Speaker 2:  emails, it's so fun. Oh, and speaking of which, we're actually planning to

1280
01:20:52,125 --> 01:20:55,905
Speaker 2:  do an all hotline episode next week all about buying

1281
01:20:56,165 --> 01:20:59,265
Speaker 2:  advice specifically. So if you're trying to figure out what to buy this holiday

1282
01:20:59,265 --> 01:21:03,185
Speaker 2:  season or you're deciding between two things, or you want to talk to me about

1283
01:21:03,185 --> 01:21:06,065
Speaker 2:  monitors, get all your questions in now we're gonna take as many as we can

1284
01:21:06,455 --> 01:21:10,025
Speaker 2:  next week this week though, no buying advice. Instead we have a

1285
01:21:10,475 --> 01:21:14,345
Speaker 2:  super fun, super wonky question that we got in The Vergecast email and I

1286
01:21:14,375 --> 01:21:17,945
Speaker 2:  have the world's two foremost experts here with me to answer it. Helen Havlak

1287
01:21:17,945 --> 01:21:21,665
Speaker 2:  is the verges publisher and Neli Patel is our editor in chief. Between them,

1288
01:21:22,015 --> 01:21:25,025
Speaker 2:  they run everything. Helen Havlak, Welcome To, The Vergecast.

1289
01:21:25,475 --> 01:21:26,825
Speaker 14:  Thank you. Excited to be

1290
01:21:26,825 --> 01:21:30,705
Speaker 2:  Here. Neli Patel is here too. Hi Neli. Hey, how's it going?

1291
01:21:32,045 --> 01:21:35,105
Speaker 2:  You know, I dial up my enthusiasm based on how excited I am for the guest.

1292
01:21:35,415 --> 01:21:38,705
Speaker 2:  Okay, this question is kind of long, so bear with me. But then we have a

1293
01:21:38,705 --> 01:21:41,905
Speaker 2:  bunch of stuff to dive into here. The question comes from Anthony, and here's

1294
01:21:41,905 --> 01:21:45,065
Speaker 2:  what it says. I feel like the effects music streaming has had on income for

1295
01:21:45,065 --> 01:21:48,745
Speaker 2:  artists is fairly well-defined or at least better known, but as an avid reader

1296
01:21:48,765 --> 01:21:52,105
Speaker 2:  of various journalists and publications such as yourselves. I have similar

1297
01:21:52,385 --> 01:21:55,265
Speaker 2:  questions about journalism on the internet, maybe supporting journalism isn't

1298
01:21:55,265 --> 01:21:58,145
Speaker 2:  talked about as much because of the overwhelming rise in news consumption

1299
01:21:58,205 --> 01:22:01,905
Speaker 2:  on social media platforms. But for those of us who try to consume news from

1300
01:22:01,905 --> 01:22:05,145
Speaker 2:  dedicated aggregators like Apple News, Flipboard, et cetera, I find myself

1301
01:22:05,145 --> 01:22:08,705
Speaker 2:  asking what do those platforms do for journalist readership and pay from

1302
01:22:08,705 --> 01:22:11,385
Speaker 2:  a user perspective, it's a good balance between the convenience of a single

1303
01:22:11,385 --> 01:22:14,385
Speaker 2:  source for all my news and interests, but also intentional about seeking

1304
01:22:14,385 --> 01:22:18,225
Speaker 2:  news and not just Instagram filtering my news based on my likes. For example,

1305
01:22:18,525 --> 01:22:21,425
Speaker 2:  is there a significant difference in how well a Verge article does when I

1306
01:22:21,425 --> 01:22:24,465
Speaker 2:  read it from Flipboard? Instead of going to the site directly, some of these

1307
01:22:24,705 --> 01:22:27,585
Speaker 2:  aggregators filter out ads. So that has to have an effect on the money The

1308
01:22:27,665 --> 01:22:31,225
Speaker 2:  Verge makes, right? I also wonder if there's a cost benefit of having articles

1309
01:22:31,225 --> 01:22:34,865
Speaker 2:  available on those aggregators because it expands readership again in an

1310
01:22:34,865 --> 01:22:37,905
Speaker 2:  age where fewer people are seeking out news and just passively consuming

1311
01:22:37,905 --> 01:22:40,825
Speaker 2:  it on social media. So the question if I'm gonna boil this all the way down,

1312
01:22:41,125 --> 01:22:45,105
Speaker 2:  is basically how does a website like The Verge

1313
01:22:45,105 --> 01:22:48,945
Speaker 2:  think about where you read our stuff, And, what that means to

1314
01:22:48,945 --> 01:22:52,865
Speaker 2:  us as a publication? Is that a fair summary of of all of that, would

1315
01:22:52,865 --> 01:22:53,905
Speaker 2:  you say? Yeah, I think

1316
01:22:53,905 --> 01:22:57,545
Speaker 14:  So. And maybe also, how does our publication make money

1317
01:22:57,685 --> 01:22:58,865
Speaker 14:  and support the work we make

1318
01:22:59,215 --> 01:23:03,025
Speaker 2:  True? Two good questions. Okay. So if I understand this correctly, you two

1319
01:23:03,025 --> 01:23:06,965
Speaker 2:  have thought about this and talked about this every day forever for all of

1320
01:23:06,965 --> 01:23:10,645
Speaker 2:  your adult lives. Helen, why don't you start at this from a sort of business

1321
01:23:10,645 --> 01:23:13,925
Speaker 2:  perspective, obviously this is the thing we think about a lot where our stuff

1322
01:23:13,945 --> 01:23:17,685
Speaker 2:  is who we work with, how we distribute things versus people coming to the

1323
01:23:17,685 --> 01:23:21,605
Speaker 2:  site. Is there a good sort of simple rubric of how you think

1324
01:23:21,605 --> 01:23:22,525
Speaker 2:  about all of that?

1325
01:23:22,995 --> 01:23:26,565
Speaker 14:  Yeah, absolutely. I think it helps to start with the basic of how does The

1326
01:23:26,685 --> 01:23:30,085
Speaker 14:  Verge make money? The Verge is a free website, so the single most important

1327
01:23:30,145 --> 01:23:34,045
Speaker 14:  way we make money today is advertising. We also make money from other

1328
01:23:34,045 --> 01:23:37,925
Speaker 14:  things like affiliate commerce on our excellent product reviews. If

1329
01:23:37,925 --> 01:23:41,365
Speaker 14:  people subscribe to our paid newsletters like Command Line and Hotpod. If

1330
01:23:41,365 --> 01:23:45,125
Speaker 14:  people become loyal subscribers to things like this, our podcasts, but a

1331
01:23:45,125 --> 01:23:48,965
Speaker 14:  bit of nuance on that ads, business ads are worth the most if you serve

1332
01:23:48,965 --> 01:23:52,645
Speaker 14:  them inside your own ad technology. We serve many of our ads inside

1333
01:23:52,745 --> 01:23:56,645
Speaker 14:  Vox media's ad technology concert. And I'll also say a loyal reader

1334
01:23:56,745 --> 01:24:00,325
Speaker 14:  who comes back many times is worth a lot more than someone

1335
01:24:00,585 --> 01:24:04,485
Speaker 14:  who just comes by once via search. For example, to

1336
01:24:04,485 --> 01:24:08,165
Speaker 14:  use the music metaphor from this question, someone who consistently

1337
01:24:08,275 --> 01:24:12,165
Speaker 14:  buys your entire album and then lines up for tickets to

1338
01:24:12,165 --> 01:24:15,325
Speaker 14:  your concert and buys your merch, that person is worth a lot more money

1339
01:24:15,345 --> 01:24:19,285
Speaker 14:  to you than someone who listens to your hit single on the radio or a

1340
01:24:19,285 --> 01:24:22,725
Speaker 14:  Spotify playlist. It's kind of the same for a news publisher

1341
01:24:23,015 --> 01:24:26,805
Speaker 14:  where the single most valuable thing to a news publisher is a

1342
01:24:27,135 --> 01:24:31,125
Speaker 14:  loyal reader who comes back over and over again no matter what kind

1343
01:24:31,125 --> 01:24:34,445
Speaker 14:  of business you run. Is it an advertising business, a subscription business?

1344
01:24:34,945 --> 01:24:38,525
Speaker 14:  So the kind of like guiding north star of this

1345
01:24:38,525 --> 01:24:41,885
Speaker 14:  conversation is, okay, to what extent do platforms help us

1346
01:24:42,535 --> 01:24:44,005
Speaker 14:  build that loyal readership?

1347
01:24:44,395 --> 01:24:47,565
Speaker 2:  Yeah, Neli, this is something you and I talk a lot about, right? Like in

1348
01:24:47,565 --> 01:24:51,325
Speaker 2:  just sort of day-to-day coverage. This question of like what's the trade-off

1349
01:24:51,325 --> 01:24:54,645
Speaker 2:  of sort of trying to be everywhere that people are understanding that the

1350
01:24:54,975 --> 01:24:58,725
Speaker 2:  world in which we live is not one where people like spend a lot of time typing

1351
01:24:59,075 --> 01:25:02,965
Speaker 2:  URLs into desktop browser bars and all of that versus like

1352
01:25:03,305 --> 01:25:07,045
Speaker 2:  we want the website to be the thing kind of even more so with this

1353
01:25:07,165 --> 01:25:10,365
Speaker 2:  redesign we did a year ago. Like how do you sort that out in your head at

1354
01:25:10,365 --> 01:25:10,565
Speaker 2:  this point?

1355
01:25:10,945 --> 01:25:13,805
Speaker 15:  So I do think about this all the time. Our entire redesign is basically

1356
01:25:13,885 --> 01:25:17,485
Speaker 15:  a response to this and it's why I lured David

1357
01:25:17,635 --> 01:25:21,045
Speaker 15:  back to The Verge because if you look at most publishers

1358
01:25:22,105 --> 01:25:25,645
Speaker 15:  on the internet, they just give their stuff away all the time.

1359
01:25:25,755 --> 01:25:28,805
Speaker 15:  They're like, here's what we do, people type and then we give their words

1360
01:25:28,835 --> 01:25:32,805
Speaker 15:  away to other people's apps and hopefully they'll pay

1361
01:25:33,085 --> 01:25:36,805
Speaker 15:  us. And that hopefully is a huge problem, right? Because it has just

1362
01:25:36,805 --> 01:25:40,445
Speaker 15:  never come true for anyone. And then you look at their websites, the

1363
01:25:40,445 --> 01:25:44,245
Speaker 15:  products they actually make, and it's just amalgamations of other people's

1364
01:25:44,405 --> 01:25:48,205
Speaker 15:  software, other people's ad software, very commonly Google and Facebook

1365
01:25:48,205 --> 01:25:52,045
Speaker 15:  and other people's ad software, other people's tracking software, very commonly,

1366
01:25:52,085 --> 01:25:56,045
Speaker 15:  other people's video players just glomming up pages and

1367
01:25:56,045 --> 01:25:59,925
Speaker 15:  you're like, why would anybody come back to this? Why would anybody choose

1368
01:25:59,925 --> 01:26:03,525
Speaker 15:  to have this experience? Of course they're gonna go to Flipboard or Apple

1369
01:26:03,525 --> 01:26:06,965
Speaker 15:  News or Google Discover or any of these other platforms where you're giving

1370
01:26:06,965 --> 01:26:10,805
Speaker 15:  your stuff away for pennies on the dollar. And of course that is

1371
01:26:10,845 --> 01:26:14,725
Speaker 15:  a doom loop for the media and the music industry and the

1372
01:26:14,725 --> 01:26:17,805
Speaker 15:  movie industry have figured this out and they figured it out because they

1373
01:26:17,805 --> 01:26:20,645
Speaker 15:  have collective leverage, right? There's only so many big labels, there's

1374
01:26:20,645 --> 01:26:24,405
Speaker 15:  only so many big studios. They figured it out in different ways. The

1375
01:26:24,475 --> 01:26:28,325
Speaker 15:  studios funded Spotify basically, and they have a tremendous

1376
01:26:28,325 --> 01:26:31,925
Speaker 15:  amount of leverage over Spotify. Taylor Swift is writing letters to the

1377
01:26:31,925 --> 01:26:35,325
Speaker 15:  Wall Street Journal about streaming rates. You know, five or six years ago

1378
01:26:35,625 --> 01:26:39,565
Speaker 15:  the studios just built their own apps. They're like, we screw it, we're

1379
01:26:39,565 --> 01:26:42,325
Speaker 15:  going away from Netflix, we're gonna build our own apps. And that pendulum

1380
01:26:42,325 --> 01:26:44,965
Speaker 15:  is swinging back and forth and I'm not sure that they've landed on the right

1381
01:26:45,215 --> 01:26:49,125
Speaker 15:  conclusion. But then you look at the news industry and no one's tried

1382
01:26:49,125 --> 01:26:52,445
Speaker 15:  any of it, right? It's, it's just been giving stuff away left and right.

1383
01:26:52,755 --> 01:26:56,325
Speaker 15:  Very few publishers have stood up and said, we need to make a product that

1384
01:26:56,325 --> 01:26:59,645
Speaker 15:  competes on the merits for user experience to actually capture attention.

1385
01:27:00,265 --> 01:27:04,205
Speaker 15:  The New York Times has done a good job of this and we e everybody recognizes

1386
01:27:04,205 --> 01:27:08,005
Speaker 15:  it, but we cannot live in a world where the New York

1387
01:27:08,035 --> 01:27:11,965
Speaker 15:  Times makes news and everyone else reacts to the New York Times.

1388
01:27:11,965 --> 01:27:15,845
Speaker 15:  I think that is an unhealthy place to be. So Helen and I have spent a lot

1389
01:27:16,455 --> 01:27:20,085
Speaker 15:  of time thinking about one, we do have a loyal audience. The Verge audience

1390
01:27:20,135 --> 01:27:23,485
Speaker 15:  is our great asset. Very few publishers have an audience like we do, okay?

1391
01:27:23,485 --> 01:27:26,885
Speaker 15:  We have to build that audience a product that is worth coming back to several

1392
01:27:26,885 --> 01:27:30,805
Speaker 15:  times a day so that even if you encounter us on all the

1393
01:27:30,805 --> 01:27:34,765
Speaker 15:  other platforms that we distribute, we can make a offer to you that coming

1394
01:27:34,765 --> 01:27:38,645
Speaker 15:  to us directly is a better and more rewarding experience for

1395
01:27:38,645 --> 01:27:42,485
Speaker 15:  you. The consumer of news, not just for us, the collector of revenue.

1396
01:27:43,275 --> 01:27:47,125
Speaker 14:  I'll get a little technical though. We do participate in a lot of news

1397
01:27:47,125 --> 01:27:50,245
Speaker 14:  readers and there's two kinds of news readers and I think it's helpful to

1398
01:27:50,245 --> 01:27:53,605
Speaker 14:  understand the difference between the two in terms of how we think about

1399
01:27:53,605 --> 01:27:57,285
Speaker 14:  them driving our business. So one kind of news reader is basically an

1400
01:27:57,325 --> 01:28:01,125
Speaker 14:  RSS feed. We give them an RSS feed, it runs on their platform.

1401
01:28:01,225 --> 01:28:05,205
Speaker 14:  If someone clicks to read that article, what they get is a Verge page. They

1402
01:28:05,205 --> 01:28:08,805
Speaker 14:  get a VERGE page with VERGE advertising and Verge commerce links and all

1403
01:28:08,805 --> 01:28:12,685
Speaker 14:  of that. And ideally what we're doing with that is either someone is

1404
01:28:12,805 --> 01:28:16,005
Speaker 14:  hitting that page and they're deciding to read more VERGE content in that

1405
01:28:16,005 --> 01:28:19,965
Speaker 14:  news reader. And I think this audience question proves you can have a

1406
01:28:19,965 --> 01:28:23,405
Speaker 14:  loyal Verge reader who primarily reads us somewhere like Flipboard. That

1407
01:28:23,405 --> 01:28:27,045
Speaker 14:  is possible, that's valid, that's still pretty good for business. There

1408
01:28:27,045 --> 01:28:30,565
Speaker 14:  is a second kind of news reader and you know, I think we've talked probably

1409
01:28:30,565 --> 01:28:34,165
Speaker 14:  quite a lot on The Vergecast about Google Amp or the now defunct

1410
01:28:34,405 --> 01:28:38,325
Speaker 14:  Facebook instant articles, which rather than giving people content as

1411
01:28:38,325 --> 01:28:42,085
Speaker 14:  an RSS feed, which serves your own page, you would put your

1412
01:28:42,085 --> 01:28:45,805
Speaker 14:  content in some proprietary code format that then is native

1413
01:28:45,905 --> 01:28:49,725
Speaker 14:  to that platform. And the promise of that was, okay, you're

1414
01:28:50,005 --> 01:28:53,205
Speaker 14:  gonna make less money per article maybe because you don't have your fancy

1415
01:28:53,345 --> 01:28:57,005
Speaker 14:  ad formats all of the rest. But the product that then runs

1416
01:28:57,045 --> 01:29:00,765
Speaker 14:  natively in Facebook is gonna load so fast and it's gonna be such a great

1417
01:29:00,845 --> 01:29:04,765
Speaker 14:  experience that the kind of volume you will get by participating there

1418
01:29:04,995 --> 01:29:08,845
Speaker 14:  will make up for lost revenue. That in particular turned out

1419
01:29:08,945 --> 01:29:12,845
Speaker 14:  not to be a great business to be in. For example, many publishers

1420
01:29:12,985 --> 01:29:16,765
Speaker 14:  got way too dependent on Facebook, call it circa 2016,

1421
01:29:16,865 --> 01:29:20,365
Speaker 14:  the height of Facebook traffic. Everyone was serving instant

1422
01:29:20,365 --> 01:29:24,325
Speaker 14:  articles, everyone was gaming the algorithm. And then Facebook decided

1423
01:29:24,635 --> 01:29:28,565
Speaker 14:  basically to shift the algorithm, prioritize family and friends content

1424
01:29:29,045 --> 01:29:32,805
Speaker 14:  deprioritize, news content, and a lot of publishers straight up died, like

1425
01:29:32,875 --> 01:29:36,645
Speaker 14:  went out of business, died. So that kind of dependence on a

1426
01:29:36,645 --> 01:29:40,485
Speaker 14:  single platform to mediate your audience relationship, that

1427
01:29:40,485 --> 01:29:44,445
Speaker 14:  is super dangerous. And that is part of why as we evaluate,

1428
01:29:44,665 --> 01:29:48,405
Speaker 14:  you know, what readers do we wanna be on, I think a good rubric is

1429
01:29:48,465 --> 01:29:52,205
Speaker 14:  one, does that send people back to our website or let us create a loyal

1430
01:29:52,285 --> 01:29:56,165
Speaker 14:  relationship with that person inside that app. And if not, it better

1431
01:29:56,165 --> 01:29:59,925
Speaker 14:  have some other kind of value For us here we're primarily talking about

1432
01:29:59,925 --> 01:30:03,725
Speaker 14:  like text content, but we also make things like video. I think

1433
01:30:03,745 --> 01:30:07,165
Speaker 14:  TikTok iss a good analogy for the purpose of that. Platform's a little bit

1434
01:30:07,165 --> 01:30:10,965
Speaker 14:  different. You know, I think about TikTok as primarily a marketing

1435
01:30:11,205 --> 01:30:15,005
Speaker 14:  platform. A marketing platform to bring The Verge content and brand to

1436
01:30:15,125 --> 01:30:19,045
Speaker 14:  younger audiences and initiate them to The Verge. And so it is valid

1437
01:30:19,065 --> 01:30:22,925
Speaker 14:  to approach platforms from different perspectives, but I would say

1438
01:30:23,225 --> 01:30:26,765
Speaker 14:  it either better convert on loyalty or it better have a really different

1439
01:30:26,855 --> 01:30:30,525
Speaker 14:  value for us, or it's not gonna be somewhere we're gonna wanna participate.

1440
01:30:30,755 --> 01:30:31,045
Speaker 14:  That

1441
01:30:31,045 --> 01:30:34,645
Speaker 15:  TikTok thing is really interesting because if you have a big TikTok channel

1442
01:30:34,705 --> 01:30:38,245
Speaker 15:  and you're a creator, people come to you and say, Hey, help me sell my product.

1443
01:30:38,245 --> 01:30:41,605
Speaker 15:  Like do some ads for us. If we have a big TikTok channel,

1444
01:30:42,035 --> 01:30:45,325
Speaker 15:  what we should be saying is, Hey, visit our website where we make money

1445
01:30:45,595 --> 01:30:49,205
Speaker 15:  because we can't really do the advertising that creators can do on TikTok

1446
01:30:49,285 --> 01:30:52,685
Speaker 15:  'cause we have this irritating wall between journalists and sales

1447
01:30:53,365 --> 01:30:57,165
Speaker 15:  creators don't. So that whole platform is built on like integrated advertising

1448
01:30:57,195 --> 01:31:00,445
Speaker 15:  with the content and that's fine, right? More power to the people doing

1449
01:31:00,445 --> 01:31:03,325
Speaker 15:  that work. That's not what we do because we are very precious about making

1450
01:31:03,325 --> 01:31:07,285
Speaker 15:  journalism. So our product that we have to sell is our website,

1451
01:31:07,655 --> 01:31:10,485
Speaker 15:  right? You're, you're watching these talks, you like our people come find

1452
01:31:10,765 --> 01:31:14,685
Speaker 15:  us on our, on our platform. Our platform had better be good enough to

1453
01:31:14,685 --> 01:31:18,605
Speaker 15:  convert, right? If our product isn't any good and we're saying come to

1454
01:31:18,605 --> 01:31:22,525
Speaker 15:  our website that is loaded up with junky ads and SEO spam,

1455
01:31:22,745 --> 01:31:25,925
Speaker 15:  the whole premise of doing TikTok falls apart so that I think there's a

1456
01:31:25,925 --> 01:31:29,805
Speaker 15:  forcing function, okay, we're gonna do TikTok and reels and

1457
01:31:29,805 --> 01:31:32,805
Speaker 15:  YouTube and all these other things, but underneath it there had better be

1458
01:31:32,845 --> 01:31:36,765
Speaker 15:  a product that's really worth it that we are marketing the same way that

1459
01:31:36,915 --> 01:31:39,325
Speaker 15:  anybody would go to any other creator and market their product,

1460
01:31:39,575 --> 01:31:42,965
Speaker 2:  Right? Yeah. What, what you're describing in a funny way is not that different

1461
01:31:42,965 --> 01:31:46,445
Speaker 2:  from what a lot of the folks who are building paywalls around

1462
01:31:46,735 --> 01:31:49,925
Speaker 2:  stuff say, right? Which is that essentially it aligns incentives. We want

1463
01:31:49,985 --> 01:31:53,925
Speaker 2:  you to engage with our product and we want you to support

1464
01:31:53,925 --> 01:31:57,805
Speaker 2:  us directly. And what we're saying instead of give us money for a subscription

1465
01:31:57,825 --> 01:32:01,605
Speaker 2:  is like come hang out on our platform. And that is like ultimately

1466
01:32:01,605 --> 01:32:05,445
Speaker 2:  that is how we win and how you win because it'll

1467
01:32:05,445 --> 01:32:09,245
Speaker 2:  makes us give you the best experience. And like that's a good alignment

1468
01:32:09,385 --> 01:32:12,565
Speaker 2:  of incentives. It seems like everybody wins if we get there. But I do. There

1469
01:32:12,565 --> 01:32:15,485
Speaker 2:  is one more thing I wanna talk about, which is the like Netflix for news

1470
01:32:15,915 --> 01:32:19,765
Speaker 2:  kind of thing that has come and gone at various times. Apple News is

1471
01:32:19,925 --> 01:32:23,045
Speaker 2:  probably the most obvious version of that right now, but there are others

1472
01:32:23,045 --> 01:32:26,285
Speaker 2:  where it's like, give us some money, take all the news and we'll figure out

1473
01:32:26,285 --> 01:32:30,005
Speaker 2:  how to split the revenue. Is that a real thing that's gonna work for anybody

1474
01:32:30,135 --> 01:32:31,005
Speaker 2:  Helen? Well,

1475
01:32:31,005 --> 01:32:34,965
Speaker 14:  It's interesting to see what Apple is doing. If you are in Apple News today,

1476
01:32:35,345 --> 01:32:39,165
Speaker 14:  as someone who does not pay for Apple News, plus what will you will

1477
01:32:39,165 --> 01:32:42,885
Speaker 14:  find is that Apple is doing an awful lot of work to promote the Apple News

1478
01:32:42,885 --> 01:32:46,645
Speaker 14:  plus subscription. And that seems to be their primary focus

1479
01:32:46,955 --> 01:32:50,725
Speaker 14:  because historically Apple's not that great at advertising. And so

1480
01:32:51,015 --> 01:32:54,725
Speaker 14:  Apple News is an interesting one because the business model there is a little

1481
01:32:54,725 --> 01:32:58,485
Speaker 14:  bit different than the promise of just ads can make it

1482
01:32:58,785 --> 01:33:02,325
Speaker 14:  And. what they seem to be doing is going after a subscription bundle,

1483
01:33:02,775 --> 01:33:06,285
Speaker 14:  which your Netflix metaphor I think accurately describes.

1484
01:33:06,665 --> 01:33:10,245
Speaker 14:  And then in that, you know, if you as a publisher can have a good piece

1485
01:33:10,245 --> 01:33:13,765
Speaker 14:  of that, that's a good business to be in. It's trickier if you are an ad

1486
01:33:13,765 --> 01:33:17,725
Speaker 14:  supported publisher to figure out how to effectively participate in Apple

1487
01:33:17,725 --> 01:33:18,565
Speaker 14:  News and make that work.

1488
01:33:19,105 --> 01:33:22,885
Speaker 15:  To be clear, I think all these Netflix for news ideas are gonna run into

1489
01:33:22,885 --> 01:33:26,845
Speaker 15:  the same exact trap as the music industry and it maybe this is

1490
01:33:26,845 --> 01:33:29,245
Speaker 15:  a good place then. 'cause we started with a direct comparison to the music

1491
01:33:29,485 --> 01:33:32,805
Speaker 15:  industry. The music labels are doing great. Artists

1492
01:33:33,265 --> 01:33:37,005
Speaker 15:  are not, the music labels have a big share of Spotify. They own a big

1493
01:33:37,005 --> 01:33:40,765
Speaker 15:  percentage of Spotify. They can negotiate rates as collectives. Their

1494
01:33:41,225 --> 01:33:45,125
Speaker 15:  job is to basically churn artists up and out through the

1495
01:33:45,125 --> 01:33:48,605
Speaker 15:  system, right? What is the shelf life of Jack Harlow? Who knows? But they,

1496
01:33:48,905 --> 01:33:52,885
Speaker 15:  the music industry is good at finding the next Jack Harlow and spamming

1497
01:33:52,885 --> 01:33:55,885
Speaker 15:  him onto your feeds. That's great that, I mean that, and that is the history

1498
01:33:55,885 --> 01:33:58,405
Speaker 15:  of music industry. I, I'm not even making a judgment there. That is just

1499
01:33:58,405 --> 01:34:02,085
Speaker 15:  the whole history of the music industry. The news industry

1500
01:34:02,355 --> 01:34:05,325
Speaker 15:  doesn't have any of the protections, doesn't have any of the cultural relevance

1501
01:34:05,325 --> 01:34:08,645
Speaker 15:  of the music industry. If The Verge decided to pull a

1502
01:34:08,805 --> 01:34:12,685
Speaker 15:  Metallica and start suing every TikTok creator that read one of our articles

1503
01:34:12,685 --> 01:34:16,005
Speaker 15:  to camera for copyright infringement, this is a disaster. No one can do

1504
01:34:16,005 --> 01:34:19,925
Speaker 15:  this. So we are just in this less strong

1505
01:34:20,285 --> 01:34:24,085
Speaker 15:  position as people who make text than the music or me. Movies

1506
01:34:24,085 --> 01:34:27,325
Speaker 15:  industries are, there's no content id for text. There's no

1507
01:34:27,935 --> 01:34:31,885
Speaker 15:  sense that reading an article out loud should pay us.

1508
01:34:32,035 --> 01:34:35,725
Speaker 15:  Whereas everybody knows if you make a famous cover of a famous song, the

1509
01:34:35,725 --> 01:34:39,685
Speaker 15:  songwriter should get paid. None of that is there. None of it exists. So

1510
01:34:39,685 --> 01:34:42,605
Speaker 15:  we have to come up with something else. And then on top of it, you add these

1511
01:34:42,965 --> 01:34:46,845
Speaker 15:  aggregators to the mix and it's obvious they're gonna extract more value

1512
01:34:46,845 --> 01:34:50,805
Speaker 15:  than they pay back to the publishers because that's what they have done

1513
01:34:51,185 --> 01:34:54,605
Speaker 15:  in music. That's what they have done in movies. And again, it's the, the

1514
01:34:54,605 --> 01:34:58,325
Speaker 15:  middlemen are great. The, the record labels are doing great and maybe

1515
01:34:58,355 --> 01:35:02,285
Speaker 15:  some of these big holding companies will do great, but the idea that

1516
01:35:02,285 --> 01:35:06,245
Speaker 15:  you're gonna get a famous writer or a famous journalist or a

1517
01:35:06,245 --> 01:35:10,085
Speaker 15:  famous author from an aggregation platform that

1518
01:35:10,085 --> 01:35:13,325
Speaker 15:  is like well compensated and feels like a star, don, don't think that's

1519
01:35:13,805 --> 01:35:16,885
Speaker 15:  remotely possible. I think the economics of that are totally stacked against

1520
01:35:16,885 --> 01:35:20,765
Speaker 15:  the deck. I think all of these platforms would prefer to deal

1521
01:35:20,835 --> 01:35:24,525
Speaker 15:  with an infinite supply of young individuals than

1522
01:35:25,085 --> 01:35:28,845
Speaker 15:  companies that might exert leverage. And I think that alignment mismatch,

1523
01:35:28,845 --> 01:35:32,445
Speaker 15:  like you said, David is so real. Every millennial media

1524
01:35:32,445 --> 01:35:36,365
Speaker 15:  company, let's call them buzzfeed, vice, whatever, our own all

1525
01:35:36,365 --> 01:35:40,005
Speaker 15:  thought that they would become these like institutional

1526
01:35:40,065 --> 01:35:43,645
Speaker 15:  brands and the Facebook's of the world would pay

1527
01:35:44,085 --> 01:35:47,965
Speaker 15:  carriage fees like the cable companies paid ESPN carriage

1528
01:35:48,035 --> 01:35:51,045
Speaker 15:  fees because their brands are so strong and people would want them And.

1529
01:35:51,045 --> 01:35:54,925
Speaker 15:  What the platform figured out is they don't need to do that if there's

1530
01:35:54,925 --> 01:35:58,765
Speaker 15:  always another 22-year-old creator on the, on the come up and you can

1531
01:35:58,765 --> 01:36:02,245
Speaker 15:  pay everyone the, the same rates and all the creators figured out there's

1532
01:36:02,245 --> 01:36:05,365
Speaker 15:  no money in the platforms and they need to go start selling energy drinks

1533
01:36:05,665 --> 01:36:09,605
Speaker 15:  and sneakers, which is exactly what happened. And so like stuck in the middle

1534
01:36:09,605 --> 01:36:13,565
Speaker 15:  of that is like, how do you pay for the news, right? Like maybe we

1535
01:36:13,565 --> 01:36:16,205
Speaker 15:  should tell Parker to start selling energy drinks and sneakers. We've already

1536
01:36:16,205 --> 01:36:20,005
Speaker 15:  got great t-shirts, but like most publishers are not

1537
01:36:20,005 --> 01:36:23,405
Speaker 15:  individual brands like this that can just hawk a product to you and they

1538
01:36:23,565 --> 01:36:27,085
Speaker 15:  probably shouldn't be. So Helen runs the business she has being nicer than

1539
01:36:27,085 --> 01:36:30,845
Speaker 15:  I do about the platforms. I just see this dynamics in a very

1540
01:36:30,855 --> 01:36:34,845
Speaker 15:  clear way for us, which is if we wanna make the journalism, we wanna make,

1541
01:36:35,105 --> 01:36:38,405
Speaker 15:  we wanna hold power to account, we want to do the reporting, we want all

1542
01:36:38,405 --> 01:36:41,685
Speaker 15:  the stuff, we wanna have fun on our website and not write for algorithms,

1543
01:36:41,715 --> 01:36:45,445
Speaker 15:  instead write for our audience. We have to build a business that is independent

1544
01:36:45,445 --> 01:36:48,965
Speaker 15:  of these platforms, especially for, especially we for us because we cover

1545
01:36:48,985 --> 01:36:52,125
Speaker 15:  the platforms. Do you know how weird it would be if we had an existential

1546
01:36:52,125 --> 01:36:55,645
Speaker 15:  financial dependency on Meta? I just think like we have to build something

1547
01:36:55,645 --> 01:36:59,165
Speaker 15:  else over here. And so it's great. You should go read us wherever you want.

1548
01:36:59,165 --> 01:37:02,245
Speaker 15:  The question is like, how do we make money? We're on these places because

1549
01:37:02,245 --> 01:37:05,845
Speaker 15:  we want to find our people there and these algorithms are good at at matching

1550
01:37:05,845 --> 01:37:09,525
Speaker 15:  us with audiences sometimes. But once you're there and if you really like

1551
01:37:09,525 --> 01:37:13,405
Speaker 15:  us, the thing to do to support us right now is come to

1552
01:37:13,405 --> 01:37:16,645
Speaker 15:  our website three times a day. And the thing to do in the future is like

1553
01:37:16,645 --> 01:37:19,565
Speaker 15:  pay for command line and take our survey about what other paid products

1554
01:37:19,635 --> 01:37:22,845
Speaker 15:  because that's gonna help us continue to be independent and honestly

1555
01:37:23,715 --> 01:37:27,285
Speaker 15:  make it easier for us to go report on the platforms without this like

1556
01:37:27,675 --> 01:37:31,205
Speaker 15:  existential dread that we're gonna like piss off Mark Zuckerberg and he's

1557
01:37:31,205 --> 01:37:34,725
Speaker 15:  gonna turn our traffic to zero, which has happened to many publishers

1558
01:37:34,955 --> 01:37:36,565
Speaker 15:  many times over the past few years.

1559
01:37:36,995 --> 01:37:40,925
Speaker 14:  Because I am the money. I will say you do not need to feel guilty

1560
01:37:41,105 --> 01:37:44,885
Speaker 14:  for reading The Verge on Flipboard podcasting. What all of you are

1561
01:37:44,885 --> 01:37:48,125
Speaker 14:  listening to right now, you are listening to in someone else's app that

1562
01:37:48,125 --> 01:37:51,805
Speaker 14:  we happen to distribute to with our own advertising and that's a great business.

1563
01:37:52,185 --> 01:37:56,125
Speaker 14:  So there are a lot of these news readers where we can have loyal

1564
01:37:56,275 --> 01:37:59,925
Speaker 14:  readers who are following The, Verge reading us, reading our page

1565
01:37:59,925 --> 01:38:03,765
Speaker 14:  experience with our advertising. It is a great business to be in. But

1566
01:38:03,905 --> 01:38:07,885
Speaker 14:  as Neli says, the primary place we need to go is

1567
01:38:07,885 --> 01:38:11,645
Speaker 14:  to have that direct audience relationship, not to be too dependent on

1568
01:38:11,785 --> 01:38:15,645
Speaker 14:  any one platform or algorithm and to offer things on our website

1569
01:38:15,645 --> 01:38:19,365
Speaker 14:  that you won't get anywhere else. Notably quick posts, our

1570
01:38:19,755 --> 01:38:23,205
Speaker 14:  live streams, none of that goes to any of these distributed publishers.

1571
01:38:23,225 --> 01:38:26,805
Speaker 14:  So if you wanna hear like Alex Heath and Eli's real time

1572
01:38:26,995 --> 01:38:30,925
Speaker 14:  reporting on OpenAI last week, you wouldn't get that if you were just

1573
01:38:30,925 --> 01:38:34,685
Speaker 14:  reading us in Flipboard. You would only get that if you were on The Verge

1574
01:38:34,745 --> 01:38:38,645
Speaker 14:  dot com looking at our homepage, looking at the story stream about the drama

1575
01:38:38,655 --> 01:38:42,645
Speaker 14:  going down. And so that is a big part of it is, yeah,

1576
01:38:42,645 --> 01:38:45,445
Speaker 14:  what can, what can we offer in the website that you can't get anywhere else?

1577
01:38:46,085 --> 01:38:49,765
Speaker 2:  I like it. So as always the answer is download every episode of The Vergecast

1578
01:38:49,815 --> 01:38:53,645
Speaker 2:  60 or 70 times and everything will be fine. Awesome.

1579
01:38:53,735 --> 01:38:57,205
Speaker 2:  Thank you both. Appreciate it. The Verge dot com. It's a good website. You

1580
01:38:57,205 --> 01:39:00,965
Speaker 2:  should read it. The only website left. Alright, that's it for The

1581
01:39:01,045 --> 01:39:04,325
Speaker 2:  Vergecast today. Thank you to everyone who's on the show and thank you as

1582
01:39:04,325 --> 01:39:07,845
Speaker 2:  always for listening. There is, as always lots more on everything that we

1583
01:39:07,845 --> 01:39:11,085
Speaker 2:  talked about at The Verge dot com. Go watch Planet Earth, we'll put some

1584
01:39:11,085 --> 01:39:13,925
Speaker 2:  links into the show notes and you know, read The Verge dot com. There's a

1585
01:39:13,925 --> 01:39:17,605
Speaker 2:  lot going on even when open AI chaos isn't happening every minute of every

1586
01:39:17,605 --> 01:39:21,405
Speaker 2:  day. And as always, if you have thoughts, questions, feelings,

1587
01:39:21,585 --> 01:39:25,085
Speaker 2:  or just please want to tell me which monitor to buy, you can always email

1588
01:39:25,085 --> 01:39:28,565
Speaker 2:  us at Vergecast at The Verge dot com or keep calling the hotline.

1589
01:39:28,565 --> 01:39:32,325
Speaker 2:  8 6 6 Verge one one. I love hearing from you and we're gonna do

1590
01:39:32,465 --> 01:39:35,685
Speaker 2:  that episode all about buying advice next week. So get your questions in

1591
01:39:35,685 --> 01:39:39,645
Speaker 2:  now. This show is produced by Andrew Moreno and Liam James Vergecast is Verge

1592
01:39:39,645 --> 01:39:42,845
Speaker 2:  production and part of the Vox Media podcast network. Meli Alex and I will

1593
01:39:42,845 --> 01:39:46,765
Speaker 2:  be back on Friday to talk more about what's going on in open AI

1594
01:39:46,765 --> 01:39:50,445
Speaker 2:  because that just won't stop happening. Plus AI sports

1595
01:39:50,585 --> 01:39:52,725
Speaker 2:  reporters, Amazon computers, and lots more. We'll see you then. Rock and

1596
01:39:52,605 --> 01:39:52,725
Speaker 2:  roll

