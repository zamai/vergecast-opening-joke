1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 0341e570-13fc-4e82-a11d-a21232896567
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/8619930506113865002/7830846010305701506/s93290-US-5773s-1758505944.mp3
Description: There’s a lot of gadget news this week! But we begin the show in an unprecedented way: with a bit of Brendan Carr is a Dummy, America’s favorite podcast within a podcast. Nilay pops on the show to discuss what happened to Jimmy Kimmel, why the FCC’s assault on speech is so dangerous, and why a couple of broadcast TV companies matter so much to the story. After that, Jake Kastrenakes and Richard Lawler join to talk about all of Meta’s new smart glasses, including the company’s first pair with a built-in display. Finally, in the lightning round, we talk about Reddit’s new AI deal with Google, Nvidia’s new chip deal with Intel, and Samsung’s terrible plan to put ads on your fridge.




2
00:01:47,355 --> 00:01:47,845
Speaker 4:  Welcome

3
00:01:47,845 --> 00:01:51,805
Speaker 5:  To the Birch Cast flagship podcast of parental leave. Sometimes you

4
00:01:51,805 --> 00:01:55,725
Speaker 5:  take it and then sometimes things happen and suddenly you are

5
00:01:55,725 --> 00:01:59,645
Speaker 5:  no longer taking it. All of which is to say ne patella is here. Honey

6
00:01:59,745 --> 00:01:59,965
Speaker 5:  lie.

7
00:02:00,285 --> 00:02:03,645
Speaker 6:  I would like to say that my default position is to hate and fear the government.

8
00:02:03,905 --> 00:02:07,285
Speaker 6:  And the fact that Brendan Carr has made me return to work early has done

9
00:02:07,285 --> 00:02:10,845
Speaker 6:  nothing but underline and fortify that

10
00:02:11,165 --> 00:02:12,845
Speaker 6:  position, which I hold deep in my soul.

11
00:02:13,205 --> 00:02:17,165
Speaker 5:  I just want to imagine kind of what your last 24 hours have been

12
00:02:17,165 --> 00:02:20,165
Speaker 5:  like emotionally. Can you just, can you, you're, you're In theory

13
00:02:20,915 --> 00:02:24,885
Speaker 5:  sitting on a couch with a, with a young baby, just living your

14
00:02:24,885 --> 00:02:26,405
Speaker 5:  best parenting life.

15
00:02:26,675 --> 00:02:30,645
Speaker 6:  Yeah. Headphone Jack Patel is doing great. He,

16
00:02:30,715 --> 00:02:34,645
Speaker 6:  he's what, nine weeks? He found his thumb. He's doing great. How's your

17
00:02:34,645 --> 00:02:35,085
Speaker 6:  baby? That's

18
00:02:35,205 --> 00:02:39,005
Speaker 5:  Exciting. He's good. Big pacifier fan. Yeah. And

19
00:02:40,175 --> 00:02:43,805
Speaker 5:  we're finally out of the screams for two hours at 6:00 PM for no reason phase.

20
00:02:43,945 --> 00:02:45,285
Speaker 5:  So life is, life is terrific.

21
00:02:45,505 --> 00:02:46,525
Speaker 6:  Our baby is very chill, which

22
00:02:48,835 --> 00:02:52,795
Speaker 6:  it's scary. Like, you know, it's coming like it's all bottled

23
00:02:52,795 --> 00:02:56,055
Speaker 6:  up in there And I, I can feel it. 'cause

24
00:02:56,365 --> 00:02:59,990
Speaker 6:  yesterday we were there was rocking the baby and all this Brennan Carr, Jimmy

25
00:03:00,025 --> 00:03:03,925
Speaker 6:  Kimmel stuff went down. And this, this Porsche Hele just received a

26
00:03:03,925 --> 00:03:07,695
Speaker 6:  full lecture on the FCC, just a full, a

27
00:03:07,695 --> 00:03:11,215
Speaker 6:  full lecture on what is going on with our nation's government. And in

28
00:03:11,215 --> 00:03:14,865
Speaker 6:  particular, the incredible, completely

29
00:03:15,705 --> 00:03:19,345
Speaker 6:  hypocritical Republican desire to control speech from, from the top levels

30
00:03:19,405 --> 00:03:20,065
Speaker 6:  of our government.

31
00:03:20,295 --> 00:03:23,945
Speaker 5:  Yeah. So we're gonna get to most of the show is gonna be Richard

32
00:03:23,945 --> 00:03:26,625
Speaker 5:  Lawler and Jake Kakis. We have a lot of news to talk about. We have a lot

33
00:03:26,625 --> 00:03:29,545
Speaker 5:  of smart glasses stuff. We have a lot of AI things. There's a lot to talk

34
00:03:29,545 --> 00:03:33,185
Speaker 5:  about, but the people demanded America's favorite podcast within a podcast.

35
00:03:33,605 --> 00:03:37,385
Speaker 5:  So we are going to lead The Vergecast with Brendan Carr as a dummy. And

36
00:03:37,415 --> 00:03:41,225
Speaker 5:  from what I understand, Jimmy Kimmel went

37
00:03:41,225 --> 00:03:45,185
Speaker 5:  on his show and said a relatively milk toast

38
00:03:45,275 --> 00:03:45,625
Speaker 5:  thing.

39
00:03:46,645 --> 00:03:50,545
Speaker 7:  We hit some new lows over the weekend with the MAGA gang desperately trying

40
00:03:50,545 --> 00:03:54,465
Speaker 7:  to characterize this kid who murdered Charlie Kirk as anything other than

41
00:03:54,525 --> 00:03:58,305
Speaker 7:  one of them, and doing everything they can to score political points

42
00:03:58,335 --> 00:03:58,825
Speaker 7:  from it.

43
00:03:59,165 --> 00:04:02,945
Speaker 6:  That's it, that's all that happened. And to be clear, we have asked the FCC,

44
00:04:03,535 --> 00:04:06,945
Speaker 6:  what about this is objectionable and they have not told us.

45
00:04:07,475 --> 00:04:11,465
Speaker 6:  Right. Which is, we'll get to it, which is the most dangerous thing of

46
00:04:11,465 --> 00:04:14,665
Speaker 6:  all. If you don't know what the rules for acceptable speech in society are,

47
00:04:14,895 --> 00:04:17,825
Speaker 6:  then no speech is actually acceptable. You can tell that I'm just like amped

48
00:04:17,825 --> 00:04:18,305
Speaker 6:  up. Sorry David.

49
00:04:18,375 --> 00:04:21,865
Speaker 5:  That is very much the point. But, but so, okay. So that happens, and sort

50
00:04:21,865 --> 00:04:25,745
Speaker 5:  of in the background, there has been a, a lot of people on the right who

51
00:04:25,745 --> 00:04:29,305
Speaker 5:  don't like Jimmy Kimmel for one reason or another. Trump has posted many

52
00:04:29,305 --> 00:04:32,945
Speaker 5:  times about not liking Kimmel, that he's, he's just an

53
00:04:32,955 --> 00:04:36,345
Speaker 5:  enemy of that group of people for many reasons. So Brendan Carr

54
00:04:36,975 --> 00:04:40,585
Speaker 5:  then immediately starts making the threats that Brendan Carr

55
00:04:40,765 --> 00:04:44,105
Speaker 5:  as the head of the FCC seems to always make. Which is that like, I don't

56
00:04:44,105 --> 00:04:47,505
Speaker 5:  like that thing you said, wouldn't it be terrible if I took away your broadcast

57
00:04:47,505 --> 00:04:51,425
Speaker 5:  licenses? Jimmy Kimmel show is on a, B, C, which is owned by Disney.

58
00:04:51,605 --> 00:04:54,825
Speaker 5:  Disney has all kinds of, you know, dealings with the government over time.

59
00:04:54,825 --> 00:04:58,305
Speaker 5:  Like basically goes on. And I would say makes a pretty naked threat

60
00:04:58,655 --> 00:05:01,465
Speaker 5:  that if you don't do something about Jimmy Kimmel, I am going to use the

61
00:05:01,465 --> 00:05:04,745
Speaker 5:  force of the government to do something to you.

62
00:05:05,015 --> 00:05:08,265
Speaker 6:  It's not even a naked threat. He went on Benny Johnson's YouTube show and

63
00:05:08,265 --> 00:05:12,105
Speaker 6:  said, we can do this the hard way or the easy way. Right? Right. The,

64
00:05:12,135 --> 00:05:15,895
Speaker 6:  it's not, I mean it's, it's, he's a cartoon. Yeah.

65
00:05:16,085 --> 00:05:19,935
Speaker 6:  Like this is literally what gangsters say in movies. And Brendan,

66
00:05:20,335 --> 00:05:23,015
Speaker 6:  I dunno if you've ever seen a picture of Brendan, he can't do it with like

67
00:05:23,015 --> 00:05:26,775
Speaker 6:  being physically imposing. So he is just saying cartoon gangster

68
00:05:26,785 --> 00:05:27,135
Speaker 6:  stuff.

69
00:05:27,795 --> 00:05:31,575
Speaker 8:  The broadcasters and you've gotten this right, are entirely different

70
00:05:31,885 --> 00:05:35,015
Speaker 8:  than people that use other forms of communication. They have a license

71
00:05:35,565 --> 00:05:39,135
Speaker 8:  granted by us at the FCC and that comes with it, an

72
00:05:39,135 --> 00:05:42,855
Speaker 8:  obligation to operate in the public interest. And we can get into some ways

73
00:05:42,855 --> 00:05:46,135
Speaker 8:  that we've been trying to reinvigorate the public interest and some changes

74
00:05:46,325 --> 00:05:49,895
Speaker 8:  that we've seen. But frankly, when you see stuff like this, I mean, look,

75
00:05:49,895 --> 00:05:53,615
Speaker 8:  we can do this the easy way or the hard way. These companies can find

76
00:05:53,725 --> 00:05:57,405
Speaker 8:  ways to change conduct, to take action, frankly

77
00:05:58,145 --> 00:06:01,645
Speaker 8:  on Kimmel, or, you know, there's gonna be additional work for the FCC

78
00:06:02,015 --> 00:06:02,365
Speaker 8:  ahead.

79
00:06:02,905 --> 00:06:06,885
Speaker 6:  And it's not Disney that has the broadcast licenses. It's a bunch of

80
00:06:06,905 --> 00:06:10,805
Speaker 6:  Disney affiliates in cities and towns across the country

81
00:06:10,995 --> 00:06:14,405
Speaker 6:  that have broadcast licenses. And importantly,

82
00:06:14,985 --> 00:06:18,965
Speaker 6:  two major conglomerates that own a bunch of these local affiliates are

83
00:06:18,965 --> 00:06:22,845
Speaker 6:  trying to merge. So they have business before him. And so when he says, we

84
00:06:22,845 --> 00:06:26,725
Speaker 6:  can do this, the hardware or the easy way, he's putting pressure on a deal,

85
00:06:26,975 --> 00:06:30,605
Speaker 6:  right? Which is just classic Trump administration stuff, right? Yes. And

86
00:06:30,605 --> 00:06:34,125
Speaker 5:  The two companies you're talking about are nexstar and tegna, which would

87
00:06:34,205 --> 00:06:37,845
Speaker 5:  like to merge. And if the deal goes through that

88
00:06:38,365 --> 00:06:41,765
Speaker 5:  combined company would own, I think it was

89
00:06:42,025 --> 00:06:45,965
Speaker 5:  80% of local affiliates around

90
00:06:45,965 --> 00:06:46,085
Speaker 5:  the

91
00:06:46,085 --> 00:06:48,845
Speaker 6:  Country. No, they would reach 80% of US households. Oh,

92
00:06:48,845 --> 00:06:49,885
Speaker 5:  I see. Oh, okay. So

93
00:06:49,885 --> 00:06:53,755
Speaker 6:  There's an underlying framework here, which

94
00:06:53,755 --> 00:06:56,715
Speaker 6:  is important to understand. Back in the day,

95
00:06:57,695 --> 00:07:01,625
Speaker 6:  all media was distributed over radio waves or print

96
00:07:01,625 --> 00:07:05,425
Speaker 6:  newspapers, shout out to print newspapers. But back in the day, broadcast

97
00:07:05,425 --> 00:07:09,065
Speaker 6:  media was literally broadcast from towers in, in cities and towns. There

98
00:07:09,065 --> 00:07:09,185
Speaker 6:  were

99
00:07:09,205 --> 00:07:12,145
Speaker 5:  Big s pointy towers, and that's how you got your television.

100
00:07:12,325 --> 00:07:16,225
Speaker 6:  But those were basically created regional monopolies, right? You're the local

101
00:07:16,385 --> 00:07:19,345
Speaker 6:  NBC affiliate, you own the NBC affiliate the next time over the next time,

102
00:07:19,345 --> 00:07:22,665
Speaker 6:  over the next time over the government did not want you to also own the A

103
00:07:22,665 --> 00:07:26,625
Speaker 6:  BC affiliate, right? It wanted media competition. So it set

104
00:07:26,625 --> 00:07:30,305
Speaker 6:  rules over how many households you could reach as a, as a affiliate

105
00:07:30,585 --> 00:07:34,185
Speaker 6:  conglomerate. And the rule right now is that you can hit 39% of US households

106
00:07:35,165 --> 00:07:38,265
Speaker 6:  for a number of reasons. There's lots of criticism in this rule.

107
00:07:39,355 --> 00:07:43,245
Speaker 6:  Meta hits 100% of households, right? Google hits

108
00:07:43,265 --> 00:07:46,965
Speaker 6:  100% of households. Like the, the media landscape has fully changed the idea

109
00:07:46,965 --> 00:07:50,605
Speaker 6:  that the broadcast owner in your town is a

110
00:07:50,695 --> 00:07:54,445
Speaker 6:  commanding presence in the media landscape, I, I think has fallen by the

111
00:07:54,445 --> 00:07:55,005
Speaker 6:  wayside, right?

112
00:07:55,315 --> 00:07:59,165
Speaker 5:  It's the sort of rule that like the spirit of it made and

113
00:07:59,165 --> 00:08:01,365
Speaker 5:  makes sense, but it is completely

114
00:08:02,905 --> 00:08:05,485
Speaker 5:  voided by the actual existence of the world in which we live

115
00:08:05,485 --> 00:08:07,565
Speaker 6:  Now and there and there. But there are good arguments to still have the rule

116
00:08:07,765 --> 00:08:11,725
Speaker 6:  people make them, right? Lots and lots of people still get

117
00:08:11,885 --> 00:08:15,565
Speaker 6:  a lot of their news from broadcast television, big events like the

118
00:08:15,885 --> 00:08:19,045
Speaker 6:  Olympics and the Emmys, all this stuff happens on broadcast television. There's,

119
00:08:19,045 --> 00:08:22,085
Speaker 6:  there's still a lot of power there. And so one of the reasons you don't want

120
00:08:22,085 --> 00:08:25,645
Speaker 6:  massive consolidation of broadcast stations is then you get control over

121
00:08:25,645 --> 00:08:29,485
Speaker 6:  the information flow, right? So the 39% rule has

122
00:08:29,485 --> 00:08:33,405
Speaker 6:  held for a long time, and in order for Nexstar and Tenet to merge, they

123
00:08:33,405 --> 00:08:37,045
Speaker 6:  have to get a waiver of this rule to hit 80% of US households.

124
00:08:37,345 --> 00:08:41,205
Speaker 6:  So now one company will have enough broadcast stations to

125
00:08:41,295 --> 00:08:44,645
Speaker 6:  reach 80% of US households, which is literally double the limit, right?

126
00:08:44,755 --> 00:08:48,685
Speaker 5:  Yeah. Not only do they need the, the actual

127
00:08:48,825 --> 00:08:52,805
Speaker 5:  merger to be approved, they need the rules to be changed so

128
00:08:52,805 --> 00:08:56,765
Speaker 5:  that the merger can be approved, which is now two points of leverage

129
00:08:56,875 --> 00:09:00,845
Speaker 5:  that our buddy Brendan has over this deal for many billions

130
00:09:00,845 --> 00:09:01,125
Speaker 5:  of dollars.

131
00:09:01,345 --> 00:09:05,245
Speaker 6:  And, and just to stay on the, but Google and Meta hit a hundred

132
00:09:05,245 --> 00:09:09,045
Speaker 6:  percent of the people. Yeah, they, they sure do. And this is the complaint,

133
00:09:09,185 --> 00:09:13,085
Speaker 6:  And I think it's a good one. Like by all the broadcast stations, man,

134
00:09:13,165 --> 00:09:16,165
Speaker 6:  have, have, have fun. You're dead anyway. It does. You know what I mean?

135
00:09:16,165 --> 00:09:19,965
Speaker 6:  Like, that thing is dying. We know it's dying, but in the meantime,

136
00:09:20,315 --> 00:09:23,845
Speaker 6:  they're the ones who make the news. Do you know what? Google and Meta do

137
00:09:23,845 --> 00:09:27,765
Speaker 6:  not pay for the fucking news. That's why all the websites are

138
00:09:27,765 --> 00:09:31,005
Speaker 6:  going outta business because there isn't money from those big distributors

139
00:09:31,345 --> 00:09:35,165
Speaker 6:  to pay for the news. So when you think about NBC's News division,

140
00:09:35,165 --> 00:09:39,085
Speaker 6:  or ABC's News Division, or CBS's News Division, which just got

141
00:09:39,125 --> 00:09:43,085
Speaker 6:  a government monitor because they wanted a deal to go through. Well the,

142
00:09:43,085 --> 00:09:46,005
Speaker 6:  that's where the news comes from. So you can put a lot of pressure on those

143
00:09:46,005 --> 00:09:49,805
Speaker 6:  news organizations. And even if they die, there isn't a

144
00:09:50,085 --> 00:09:53,805
Speaker 6:  parallel structure online for news there. There really isn't. Like,

145
00:09:54,235 --> 00:09:58,165
Speaker 6:  however you feel politically, you cannot look

146
00:09:58,265 --> 00:10:01,765
Speaker 6:  at the digital media landscape and say there is a thing here

147
00:10:02,355 --> 00:10:06,125
Speaker 6:  that has the resources, the history, the depth, and the experience

148
00:10:06,345 --> 00:10:10,325
Speaker 6:  of broadcast news divisions, which just doesn't exist. Yeah, maybe it

149
00:10:10,325 --> 00:10:13,045
Speaker 6:  will one day, but it doesn't right now. So you're just in this transition

150
00:10:13,045 --> 00:10:16,845
Speaker 6:  period, and Brendan Carr knows he has a lot of leverage,

151
00:10:17,225 --> 00:10:19,805
Speaker 6:  is those companies try to thrash their way into the future,

152
00:10:20,135 --> 00:10:23,005
Speaker 5:  Right? So the the first companies that bend to

153
00:10:23,875 --> 00:10:27,325
Speaker 5:  Brendan Carr's threats on Benny Johnson's YouTube channel, like, do you ever

154
00:10:27,325 --> 00:10:30,245
Speaker 5:  say a sentence and you're like, how is this any of this actually, what's

155
00:10:30,245 --> 00:10:31,965
Speaker 5:  going on? That's the thing that happened. These

156
00:10:31,965 --> 00:10:35,045
Speaker 6:  People are all the most terminally online posters in history. Yes. They all

157
00:10:35,065 --> 00:10:38,165
Speaker 6:  run the government now, and they are playing out the most petty

158
00:10:39,015 --> 00:10:42,765
Speaker 6:  forum grievances in particular Brendan Carr. He's just a troll. Yeah.

159
00:10:42,905 --> 00:10:46,685
Speaker 5:  So, but some of these companies, particularly Nexstar and Sinclair, two

160
00:10:46,865 --> 00:10:50,805
Speaker 5:  big broadcasters, they are the first ones

161
00:10:51,675 --> 00:10:55,495
Speaker 5:  to basically bend or cave or bite or whatever you wanna call it,

162
00:10:55,495 --> 00:10:59,295
Speaker 5:  after these threats. And they start to say, we're gonna not show Jimmy

163
00:10:59,295 --> 00:11:02,015
Speaker 5:  Kimmel, essentially we're gonna put on something else instead of Jimmy Kimmel's

164
00:11:02,015 --> 00:11:05,535
Speaker 5:  show. And then that immediately spirals into a, b, c saying,

165
00:11:06,275 --> 00:11:09,975
Speaker 5:  we are going to pull Jimmy Kimmel's show indefinitely.

166
00:11:10,235 --> 00:11:14,175
Speaker 5:  Yep. Which now, like it is, it is one of

167
00:11:14,175 --> 00:11:17,975
Speaker 5:  the more straightforward, like this is what censorship looks like. Brendan

168
00:11:18,045 --> 00:11:21,375
Speaker 5:  Carr kinds of stories we've had in a while, which I think is a, a useful

169
00:11:22,565 --> 00:11:26,295
Speaker 5:  time to bring this particular second. This is just, this is the straightest

170
00:11:26,325 --> 00:11:29,815
Speaker 5:  line between what we have been talking about

171
00:11:30,235 --> 00:11:33,855
Speaker 5:  and free speech disasters that we've had in a pretty long

172
00:11:33,855 --> 00:11:36,455
Speaker 6:  Time. You publish what the government wants, you broadcast what the government

173
00:11:36,455 --> 00:11:39,525
Speaker 6:  wants, or the government will punish you. If you publish something the government

174
00:11:39,525 --> 00:11:43,485
Speaker 6:  doesn't like and you don't take actions to, to remediate it, the

175
00:11:43,485 --> 00:11:46,845
Speaker 6:  government will punish you. That that's what he said. It's not,

176
00:11:47,755 --> 00:11:50,965
Speaker 6:  it's not even shaded. He said, we can do this the hard way or the easy way.

177
00:11:51,695 --> 00:11:55,685
Speaker 6:  There's no dancing around his actual statement. And then the next

178
00:11:55,835 --> 00:11:59,085
Speaker 6:  turn was a bunch of these stations, the, these big

179
00:11:59,085 --> 00:12:03,045
Speaker 6:  conglomerates, these are not little heartland TV stations in the middle

180
00:12:03,045 --> 00:12:06,085
Speaker 6:  of the country that just, you know, we've had a, a really rural audience

181
00:12:06,085 --> 00:12:09,125
Speaker 6:  and they don't like it when No, these are huge conglomerates in the middle

182
00:12:09,185 --> 00:12:13,125
Speaker 6:  of a $6.2 billion merger, right. That

183
00:12:13,125 --> 00:12:16,045
Speaker 6:  are trying to get government approval to change a rule that has existed for

184
00:12:16,045 --> 00:12:19,045
Speaker 6:  years and years and years about how big media companies can be.

185
00:12:20,385 --> 00:12:24,245
Speaker 6:  And there's just, I like politically that is just a

186
00:12:24,245 --> 00:12:26,845
Speaker 6:  total realignment, right? Do you want big companies to get bigger? May maybe

187
00:12:26,845 --> 00:12:30,085
Speaker 6:  you do. Do you want big companies to own a bunch of speech in America?

188
00:12:31,005 --> 00:12:34,845
Speaker 6:  Probably you don't it. And that usually cuts in a bipartisan way.

189
00:12:34,845 --> 00:12:38,485
Speaker 6:  Like what have Republicans yelled about the most over the past

190
00:12:38,675 --> 00:12:42,285
Speaker 6:  half a decade? It's how big the platform companies are and how much control

191
00:12:42,285 --> 00:12:45,805
Speaker 6:  they have over speech. Right? What does Brendan Carr say? I, Ben Smith from

192
00:12:45,905 --> 00:12:49,765
Speaker 6:  SE four interviewed Brendan Carr at an event a couple months ago,

193
00:12:50,225 --> 00:12:53,365
Speaker 6:  and he said, do you agree with me that the biggest threat to speech in America

194
00:12:53,365 --> 00:12:57,085
Speaker 6:  is the government? That's that's the foundation, right? Like most people

195
00:12:57,085 --> 00:12:59,685
Speaker 6:  agree with this. And Brendan Carr said, no, the biggest threat to speech

196
00:12:59,685 --> 00:13:02,645
Speaker 6:  in America is the platform companies. And I, the government will, will take

197
00:13:02,645 --> 00:13:06,445
Speaker 6:  care of it. And it's like, no, that's, that's still wrong, right? When

198
00:13:06,445 --> 00:13:09,885
Speaker 5:  You're also kind of, you're, you're kind of answering your own question while

199
00:13:09,885 --> 00:13:12,405
Speaker 5:  you try to say the other thing, right? Yeah. The government is

200
00:13:12,405 --> 00:13:14,925
Speaker 6:  Gonna stop who has enough power to bring the platform companies in line?

201
00:13:14,995 --> 00:13:17,325
Speaker 6:  It's me, the government. It's like, no, that's why you're not supposed to

202
00:13:17,325 --> 00:13:18,365
Speaker 6:  use that power. Right?

203
00:13:18,365 --> 00:13:20,165
Speaker 5:  That is In fact the problem we're trying to solve

204
00:13:20,165 --> 00:13:24,005
Speaker 6:  Here. And so you just end up in this place where, and And I, you

205
00:13:24,005 --> 00:13:27,805
Speaker 6:  can see this throughout, I think the, the aftermath of

206
00:13:27,905 --> 00:13:29,845
Speaker 6:  the horrific murder of Charlie Kirk,

207
00:13:31,665 --> 00:13:35,595
Speaker 6:  that Republicans are totally happy to abandon

208
00:13:35,765 --> 00:13:39,035
Speaker 6:  everything they said about free speech and free expression on the internet

209
00:13:40,015 --> 00:13:43,025
Speaker 6:  when they are the ones in control of the speech. Yep. And I,

210
00:13:43,805 --> 00:13:47,535
Speaker 6:  this is why, I mean, for years I've come on the show I've hosted on social

211
00:13:47,535 --> 00:13:51,135
Speaker 6:  media, government speech regulations are bad and the pushback is, but we

212
00:13:51,135 --> 00:13:53,135
Speaker 6:  should have some because you don't want racism, you don't want this. You

213
00:13:53,205 --> 00:13:57,055
Speaker 6:  like, and I'm always like, but then the bad guys will be in

214
00:13:57,055 --> 00:13:57,215
Speaker 6:  charge

215
00:13:58,825 --> 00:14:02,765
Speaker 6:  and they will do the things that always happen, which is they will start

216
00:14:02,765 --> 00:14:05,885
Speaker 6:  to put pressure on speech they don't like because you've given them the tools.

217
00:14:05,885 --> 00:14:09,725
Speaker 6:  You've opened the door over and over and over again. We have made this point

218
00:14:09,725 --> 00:14:13,205
Speaker 6:  on The Verge for 15 years. We've made this point on The Verge, Addie turned

219
00:14:13,205 --> 00:14:16,245
Speaker 6:  that story about the Republicans wage war in the First Amendment in like

220
00:14:16,245 --> 00:14:19,565
Speaker 6:  five minutes. Why? Because she And I have written that story 5,000 times.

221
00:14:19,565 --> 00:14:20,245
Speaker 5:  It's just sitting there. Yeah.

222
00:14:20,315 --> 00:14:23,445
Speaker 6:  It's just, and she like, I think that she's just auto completed it on her

223
00:14:23,645 --> 00:14:26,565
Speaker 6:  computer. Like she's got a keyboard macro that's like do the first Amendment

224
00:14:26,565 --> 00:14:29,725
Speaker 6:  story, you know, it comes out Right. Because we've done it so many times.

225
00:14:30,505 --> 00:14:34,125
Speaker 6:  And Brendan in particular does not know

226
00:14:34,435 --> 00:14:38,245
Speaker 6:  he's playing with fire. Like he knows that he has power, but

227
00:14:38,335 --> 00:14:42,015
Speaker 6:  he's a dummy. He, he, he can't see

228
00:14:42,395 --> 00:14:46,295
Speaker 6:  the obvious hypocrisy of all of his positions add up to

229
00:14:46,795 --> 00:14:50,595
Speaker 6:  now I'm the guy who canceled Jimmy Kimmel. And I actually think most

230
00:14:51,125 --> 00:14:54,565
Speaker 6:  Americans look at the government directly censoring speech

231
00:14:55,225 --> 00:14:59,165
Speaker 6:  and say, no, that's too far. That's it. It it, I don't think that's a

232
00:14:59,165 --> 00:15:03,105
Speaker 6:  political situation. I think the government directly

233
00:15:03,105 --> 00:15:06,745
Speaker 6:  saying Get this comedian off the air is like, there

234
00:15:06,855 --> 00:15:10,695
Speaker 6:  isn't a better way to launch Jimmy Kimmel's YouTube career then the

235
00:15:10,695 --> 00:15:14,255
Speaker 6:  government trying to cancel him for not even making a joke, for running a

236
00:15:14,255 --> 00:15:15,095
Speaker 6:  clip of Donald Trump.

237
00:15:15,605 --> 00:15:18,735
Speaker 5:  This is the thing about this that I think is, is so interesting and is so

238
00:15:18,735 --> 00:15:22,695
Speaker 5:  different. And I think the, the thing we've learned obviously

239
00:15:22,745 --> 00:15:26,495
Speaker 5:  since, since Charlie Kirk was things are

240
00:15:26,495 --> 00:15:29,815
Speaker 5:  different now, right? Like, there there are a bunch of confusing,

241
00:15:30,085 --> 00:15:33,895
Speaker 5:  complicated sort of inflection points that seem to be happening after

242
00:15:34,435 --> 00:15:38,415
Speaker 5:  he was murdered. And this one just all,

243
00:15:38,475 --> 00:15:41,775
Speaker 5:  all of this is so wrapped up together. But, but I think your your point is

244
00:15:41,775 --> 00:15:44,815
Speaker 5:  right, that this is such a straight line from

245
00:15:45,955 --> 00:15:49,815
Speaker 5:  the government is telling them to cancel Jimmy Kimmel that I, it it, it

246
00:15:49,815 --> 00:15:52,415
Speaker 5:  seems to have resonated differently for people. And I, I'm curious if it

247
00:15:52,415 --> 00:15:56,135
Speaker 5:  has felt that way even to you. Like you, you track this more closely than

248
00:15:56,135 --> 00:15:59,015
Speaker 5:  most because you're like a specific kind of lunatic. But I think

249
00:16:00,205 --> 00:16:03,775
Speaker 5:  this one just feels so visceral and so clear and there are so few

250
00:16:03,985 --> 00:16:07,455
Speaker 5:  steps in the intimidation and the

251
00:16:07,455 --> 00:16:11,215
Speaker 5:  corruption and the coercion that it is, like, people seem to get it. And

252
00:16:11,215 --> 00:16:14,135
Speaker 5:  I've just even been watching this on social for the last like 18 hours. Like

253
00:16:15,075 --> 00:16:19,015
Speaker 5:  in, in all the ways that Brendan Carr was this sort of like, kind of

254
00:16:19,125 --> 00:16:22,575
Speaker 5:  confusing dictator. Now he's just a very straightforward

255
00:16:22,935 --> 00:16:25,735
Speaker 5:  dictator. And that's actually like a more dangerous thing to be if you're

256
00:16:25,735 --> 00:16:29,175
Speaker 5:  Brendan Carr. Yeah. And people see it differently Now, do you, like, do you

257
00:16:29,175 --> 00:16:33,055
Speaker 5:  think this one is different because it is so a, it's high profile

258
00:16:33,055 --> 00:16:36,975
Speaker 5:  because it's Jimmy Kimmel who's a person everybody knows, but also just because

259
00:16:38,475 --> 00:16:42,135
Speaker 5:  the the wrong thing is so straightforwardly obvious this time. I

260
00:16:42,135 --> 00:16:44,935
Speaker 6:  Mean, we've just done a decade of comedians saying they can't say whatever

261
00:16:44,935 --> 00:16:48,395
Speaker 6:  they want. Right? Like this thing you're saying about being legible,

262
00:16:49,055 --> 00:16:51,995
Speaker 6:  man, I, how much do I run into about Brendan Carr? Like my wife doesn't give

263
00:16:51,995 --> 00:16:55,315
Speaker 6:  a shit. Becky doesn't give a shit. Yeah. Becky loves a comedy podcast. She

264
00:16:55,315 --> 00:16:57,195
Speaker 6:  listens to all of them. They're always on in the background of our house.

265
00:16:57,455 --> 00:17:00,635
Speaker 6:  And I said, Jimmy Kimmel got canceled because of Trump yesterday and her

266
00:17:00,755 --> 00:17:03,835
Speaker 6:  eyes got huge. Mm. And she said, I can't wait to hear everyone has to say

267
00:17:03,955 --> 00:17:07,295
Speaker 6:  tomorrow because if you've done this much

268
00:17:07,915 --> 00:17:11,895
Speaker 6:  cancel culture, I've gotta push back against the woke mob. You

269
00:17:11,895 --> 00:17:15,055
Speaker 6:  can't just say whatever you want for so long, if that is your brand. And

270
00:17:15,235 --> 00:17:18,695
Speaker 6:  boy are there a lot of cultural commentators and comedians who've made that

271
00:17:18,695 --> 00:17:22,255
Speaker 6:  their brand. And then you look at not even a joke,

272
00:17:23,185 --> 00:17:24,565
Speaker 6:  not even a Charlie Kirk show. No.

273
00:17:26,205 --> 00:17:29,825
Speaker 6:  If, if what we're saying is merely saying this man's name

274
00:17:30,565 --> 00:17:33,905
Speaker 6:  is enough for the full force of the government to cancel your show.

275
00:17:35,345 --> 00:17:38,315
Speaker 6:  Well we have a problem. I don't think that's actually very confusing at all.

276
00:17:39,015 --> 00:17:42,885
Speaker 6:  And underneath that is, yeah, there's a whole

277
00:17:42,885 --> 00:17:46,525
Speaker 6:  bunch of business stuff that's happening, right? The the, the, the broadcast

278
00:17:46,525 --> 00:17:49,325
Speaker 6:  television empire is fully in its last days,

279
00:17:50,315 --> 00:17:53,885
Speaker 6:  it's not coming back. Sinclair I think said, we're gonna

280
00:17:53,915 --> 00:17:57,485
Speaker 6:  preempt Kimmel and we're gonna run a special honoring Charlie Kirk instead.

281
00:17:57,485 --> 00:18:00,425
Speaker 6:  Yeah, yeah dude. That's not gonna do ratings.

282
00:18:01,325 --> 00:18:05,015
Speaker 6:  All those people are gonna look at their phones instead. Like, you're not

283
00:18:05,015 --> 00:18:08,855
Speaker 6:  gonna get numbers from that. There's no coming back, there's no bringing

284
00:18:08,875 --> 00:18:11,695
Speaker 6:  the audience back to broadcast television in this way.

285
00:18:12,705 --> 00:18:15,245
Speaker 6:  So I dunno what's gonna happen with Jimmy Kim, I'm assuming he's a lawyer

286
00:18:15,245 --> 00:18:17,845
Speaker 6:  up, he's gonna sue Disney. Everyone's gonna get their money and he is gonna

287
00:18:17,845 --> 00:18:21,045
Speaker 6:  launch a YouTube show and then he is gonna start doing ag one supplement

288
00:18:21,045 --> 00:18:23,165
Speaker 6:  brand integrations. He is gonna make millions of dollars like everyone else

289
00:18:23,165 --> 00:18:26,805
Speaker 6:  does. Yep. Because that is the shape of the modern media. And

290
00:18:26,805 --> 00:18:30,365
Speaker 6:  Brendan will get to preside over his empire of shit, of

291
00:18:30,405 --> 00:18:33,405
Speaker 6:  decaying broadcast networks. 'cause he, that's what he has the statutory

292
00:18:33,405 --> 00:18:37,285
Speaker 6:  power to control until the day he realizes that, oh,

293
00:18:37,285 --> 00:18:40,085
Speaker 6:  that's not any good. And I should censor what Americans say on social media

294
00:18:40,325 --> 00:18:43,405
Speaker 6:  platforms instead. And you can, it's just coming. You, you don't have to

295
00:18:43,695 --> 00:18:47,685
Speaker 6:  guess, do I want to rule over the dead thing or do I want

296
00:18:47,685 --> 00:18:51,085
Speaker 6:  actual control over what Google and Facebook distribute? And it's pretty

297
00:18:51,085 --> 00:18:51,885
Speaker 6:  obvious what he wants.

298
00:18:52,435 --> 00:18:56,405
Speaker 5:  Yeah. I mean, do you think this one comes back on Brendan in

299
00:18:56,405 --> 00:18:59,405
Speaker 5:  a different way because of it? Like, on the one hand, this is entirely internally

300
00:18:59,405 --> 00:19:01,965
Speaker 5:  consistent with everything that Brendan Carr has been doing since he has

301
00:19:01,965 --> 00:19:05,485
Speaker 5:  been in this shop. Yeah. So like the fact that he would play this card,

302
00:19:06,065 --> 00:19:10,045
Speaker 5:  not at all surprising, but I think I, this one seems like

303
00:19:10,065 --> 00:19:12,485
Speaker 5:  it might reflect back on him differently.

304
00:19:13,955 --> 00:19:16,405
Speaker 6:  He's, he's a character now. I mean like what have we done? We've been doing

305
00:19:16,405 --> 00:19:19,365
Speaker 6:  nothing but try to make this guy a character. Yeah. And thank you a huge

306
00:19:19,365 --> 00:19:23,005
Speaker 6:  thank you to our audience who was like, it's neli,

307
00:19:23,585 --> 00:19:26,045
Speaker 6:  the people demanded this. He's scared. We know we've been paying attention

308
00:19:26,045 --> 00:19:29,605
Speaker 6:  to him since the beginning. 'cause this has been his move. Right.

309
00:19:30,225 --> 00:19:33,965
Speaker 6:  And we've been inviting him on the show since the beginning because I think

310
00:19:33,965 --> 00:19:37,725
Speaker 6:  he's too dumb to defend these things in a, from a coherent standpoint.

311
00:19:38,325 --> 00:19:42,205
Speaker 6:  I actually understand them from an exercise of power standpoint. This

312
00:19:42,205 --> 00:19:45,845
Speaker 6:  is what sensors do when given the keys. Yeah. They find leverage.

313
00:19:46,115 --> 00:19:49,685
Speaker 6:  They don't immediately say, I would like you to delete this content. They

314
00:19:49,685 --> 00:19:52,125
Speaker 6:  say things like, we can do this the hard way or the easy way. You can get

315
00:19:52,125 --> 00:19:55,725
Speaker 6:  your $6.2 billion merger or you or you

316
00:19:55,785 --> 00:19:59,765
Speaker 6:  cannot. And to get it, you gotta get Jimmy Kimmel off the air car was on

317
00:19:59,925 --> 00:20:03,005
Speaker 6:  CNBC. And he said, look, these are just local stations making decisions.

318
00:20:03,005 --> 00:20:06,845
Speaker 6:  And it's like, dude, you're trying to run, he's already trying to run, he's

319
00:20:06,845 --> 00:20:09,765
Speaker 6:  already trying to pretend that these are little local TV stations just saying

320
00:20:09,785 --> 00:20:13,245
Speaker 6:  we are, you know, we're, we're upset about what these big Hollywood liberals

321
00:20:13,245 --> 00:20:16,645
Speaker 6:  are saying. No, these are billion dollar companies in the middle of a $6.2 billion

322
00:20:16,645 --> 00:20:19,565
Speaker 6:  merger that will let them reach 80% of American households.

323
00:20:20,555 --> 00:20:24,405
Speaker 6:  This isn't ma and pa with a local a, b, C affiliate. What's that weird Al

324
00:20:24,405 --> 00:20:28,205
Speaker 6:  movie? UHF. That's what I want it to be. It's not that.

325
00:20:28,315 --> 00:20:31,085
Speaker 6:  Sure. These are some of the most evil suits in America. Yeah.

326
00:20:32,245 --> 00:20:36,185
Speaker 6:  And what is their $6.2 billion merger gonna do? It's gonna lay off thousands

327
00:20:36,185 --> 00:20:38,505
Speaker 6:  and thousands of people. That's 'cause it always does. That's an inevitable

328
00:20:38,505 --> 00:20:42,065
Speaker 6:  result of these mergers. Yep. So I, I just, I feel no sympathy for any of

329
00:20:42,065 --> 00:20:45,865
Speaker 6:  these characters, but I know that if Brendan came on this show or he came

330
00:20:45,865 --> 00:20:49,645
Speaker 6:  on decoder or I, and we did a walk and talk in the streets of dc like

331
00:20:49,845 --> 00:20:52,935
Speaker 6:  whatever you wanna do it Brendan, I just know that all of your ideas would

332
00:20:52,935 --> 00:20:56,135
Speaker 6:  fall apart under the slightest scrutiny of are these coherent

333
00:20:57,715 --> 00:21:01,355
Speaker 6:  d Does the way you feel about Twitter moderation and COVID

334
00:21:01,735 --> 00:21:05,555
Speaker 6:  the lineup with the actions you are taking right now when it comes

335
00:21:05,935 --> 00:21:09,675
Speaker 6:  to Jimmy Kimmel? 'cause boy you were pissed

336
00:21:09,675 --> 00:21:13,515
Speaker 6:  about Twitter moderation during COVID, like super pissed about it.

337
00:21:14,015 --> 00:21:17,785
Speaker 6:  And that was just Twitter. But that was like, you know, not

338
00:21:18,105 --> 00:21:21,705
Speaker 6:  everyone in America. Yeah. It was not the force of the government interfering

339
00:21:21,705 --> 00:21:25,645
Speaker 6:  in business deals to get favorable speech. And I, it just doesn't

340
00:21:25,645 --> 00:21:29,605
Speaker 6:  line up. So Brendan as always, I will come back from my leaf early. I'm

341
00:21:29,605 --> 00:21:32,525
Speaker 6:  pretty sure the baby can take you. He's not rational and he is a little bit

342
00:21:32,525 --> 00:21:36,445
Speaker 6:  of a terrorist, but I'm pretty sure he can take you. Yeah. But I'll do it

343
00:21:36,445 --> 00:21:37,405
Speaker 6:  anytime you want, man.

344
00:21:37,735 --> 00:21:40,965
Speaker 5:  There you go. Brendan, you, you heard it here also. This is a useful time

345
00:21:40,965 --> 00:21:44,325
Speaker 5:  to remind people, subscribe to The Verge so that we become

346
00:21:44,525 --> 00:21:48,285
Speaker 5:  ungovernable, subscribe to The Verge so that there is no way anyone

347
00:21:48,305 --> 00:21:50,605
Speaker 5:  can stop us and nothing anybody can do.

348
00:21:50,985 --> 00:21:54,765
Speaker 6:  My joke about a G one, first of all, I I just keep, did you do this when

349
00:21:54,765 --> 00:21:57,725
Speaker 6:  you were on David? I just have a list of stories. Oh yeah. And my desire

350
00:21:57,725 --> 00:22:00,245
Speaker 6:  to ever go to a management meeting again is like basically zero. 'cause I

351
00:22:00,245 --> 00:22:02,165
Speaker 6:  just wanna do my list of stories. Yes. We're gonna have to figure that out.

352
00:22:02,665 --> 00:22:06,645
Speaker 6:  But this thing I'm describing where the money in broadcast media

353
00:22:06,705 --> 00:22:10,085
Speaker 6:  is just rapidly declining and the solution is scale and

354
00:22:10,285 --> 00:22:13,245
Speaker 6:  consolidation because that's what dying industries do. Yep. That's real.

355
00:22:13,745 --> 00:22:16,405
Speaker 6:  So all that attention is going somewhere else and it's going onto platforms.

356
00:22:16,405 --> 00:22:20,365
Speaker 6:  The platforms do not pay enough money to creators. Just

357
00:22:20,635 --> 00:22:24,175
Speaker 6:  they don't, Spotify does not pay enough money to artists.

358
00:22:24,525 --> 00:22:28,375
Speaker 6:  Instagram pays literally no money to in Instagram influencers. It's all

359
00:22:28,375 --> 00:22:32,335
Speaker 6:  brand deals. I think it was Samir from calling in Samir was on CN BBC a

360
00:22:32,335 --> 00:22:35,775
Speaker 6:  few weeks ago and he said literally the platforms don't pay enough money.

361
00:22:35,775 --> 00:22:39,095
Speaker 6:  You have to go be an advertiser. Alex Earl was at Can and said, I'm not an

362
00:22:39,095 --> 00:22:42,895
Speaker 6:  influencer, I'm a marketer. That's, that's the money.

363
00:22:43,035 --> 00:22:46,535
Speaker 6:  Yep. The advertising money has come directly into the content

364
00:22:46,645 --> 00:22:49,575
Speaker 6:  because the platforms themselves do not pay enough money to the people who

365
00:22:49,575 --> 00:22:53,495
Speaker 6:  make the work. That's just true. There's a lot to say about that. I, I

366
00:22:53,495 --> 00:22:57,055
Speaker 6:  don't know if how sustainable that is even over time, that's why I had Hank

367
00:22:57,055 --> 00:23:00,135
Speaker 6:  Green was guest hosting decoder. That's why I really wanted him to talk to

368
00:23:00,135 --> 00:23:04,055
Speaker 6:  Amy Lan, who's the CEO of Digitas, the big ad agency. That that's a, that's

369
00:23:04,055 --> 00:23:07,915
Speaker 6:  a perspective I don't have, I'm not a creator like that. All this is to say

370
00:23:08,775 --> 00:23:12,355
Speaker 6:  we don't do the brand deals. You can't, you can't do a brand integration

371
00:23:12,355 --> 00:23:15,675
Speaker 6:  here. I'm saying this And I know that like the executives of Vox Media are

372
00:23:15,675 --> 00:23:19,515
Speaker 6:  like, why? 'cause they, they want us to, that that's the money they can all

373
00:23:19,515 --> 00:23:23,355
Speaker 6:  see the money we're not making. And the promise that we make them is our

374
00:23:23,635 --> 00:23:27,325
Speaker 6:  audiences will pay, will pay us money and we'll make up the game. So

375
00:23:27,325 --> 00:23:31,165
Speaker 6:  that's how we're gonna keep talking about it. But the, the thing that I don't

376
00:23:31,165 --> 00:23:35,085
Speaker 6:  want to get into is, oh boy, our big Nike

377
00:23:35,255 --> 00:23:38,875
Speaker 6:  brand integration is on the rocks because

378
00:23:40,185 --> 00:23:43,985
Speaker 6:  a bunch of gamer Gators said I said Charlie Kirk's name on our show,

379
00:23:44,225 --> 00:23:47,885
Speaker 5:  Right? Because we invented a podcast called Brenda Car. A dummy. Yeah.

380
00:23:48,185 --> 00:23:51,685
Speaker 6:  You see what I'm saying? And like that is where the next set of pressures

381
00:23:51,685 --> 00:23:55,365
Speaker 6:  is gonna come in the media ecosystem because no one's actually making enough

382
00:23:55,365 --> 00:23:58,325
Speaker 6:  money just making the work. The work has been devalued almost nothing.

383
00:23:59,465 --> 00:24:02,715
Speaker 6:  It's brand integrations. It's literally Ag one supplement reads

384
00:24:03,535 --> 00:24:06,825
Speaker 6:  what you gonna do. That's, I mean, fine everyone go make their money. I'm

385
00:24:06,825 --> 00:24:10,705
Speaker 6:  not Right. The people have solved the problem. I I can just see where the

386
00:24:10,705 --> 00:24:13,825
Speaker 6:  next set of pressure points is. And like David said, I don't like it. Nope.

387
00:24:13,885 --> 00:24:17,785
Speaker 6:  We, I I don't like being told what to do. So yeah, that's, that's

388
00:24:17,785 --> 00:24:19,265
Speaker 6:  my pitch for the subscription. Let's have

389
00:24:19,265 --> 00:24:23,105
Speaker 5:  Fewer things to be used against us. Make

390
00:24:23,215 --> 00:24:26,265
Speaker 5:  Neli more. Ungovernable the first.com

391
00:24:27,065 --> 00:24:30,825
Speaker 5:  subscribe. All right, NELI, you go back to break. We're gonna take a break.

392
00:24:31,005 --> 00:24:33,345
Speaker 5:  I'm gonna be back with Richard and Jake. We're gonna talk through all the

393
00:24:33,345 --> 00:24:36,985
Speaker 5:  rest of the news of the week. You're gonna be back with us for real in a

394
00:24:36,985 --> 00:24:40,225
Speaker 5:  few weeks, but not, not just yet. For now. Go, go Enjoy baby time, but thank

395
00:24:40,225 --> 00:24:41,745
Speaker 5:  you for coming to doing this. Yeah,

396
00:24:42,375 --> 00:24:44,465
Speaker 6:  Yeah. I mean, I'll I'll bring the baby next time. It'd be

397
00:24:44,465 --> 00:24:47,425
Speaker 5:  Great. Yeah, good. And hopefully, hopefully Brendan does not require this

398
00:24:47,425 --> 00:24:48,945
Speaker 5:  again of us until that No, he will.

399
00:24:49,075 --> 00:24:51,985
Speaker 6:  We're yeah, we're, we're coming back and forth. Where Brendan Car Daily is

400
00:24:51,985 --> 00:24:53,465
Speaker 6:  our next podcast. It's gonna be amazing.

401
00:24:54,325 --> 00:24:56,065
Speaker 5:  Oh boy. All right, we gotta take a break. We'll be right back.

402
00:27:56,005 --> 00:27:59,245
Speaker 5:  government for making us do the first 20 minutes of the first cast

403
00:27:59,695 --> 00:28:03,685
Speaker 5:  about this. I will never forgive them, but it was nice to have Neli

404
00:28:03,685 --> 00:28:06,645
Speaker 5:  back. We have released Neli into his baby care and weekend.

405
00:28:07,505 --> 00:28:11,445
Speaker 5:  Now let's get on with the good stuff. Jake Kakis is here. Hi Jake. Hey there.

406
00:28:11,445 --> 00:28:15,405
Speaker 5:  What did Neli do? Neli just came in firing. It was nice

407
00:28:15,405 --> 00:28:17,965
Speaker 5:  to have him back. Richard Lawler's also here. Hi Richard. Hello.

408
00:28:18,095 --> 00:28:20,085
Speaker 11:  Let's talk about sports but not the Packers.

409
00:28:21,225 --> 00:28:24,205
Speaker 5:  Who have you been yelling about the FCC too recently?

410
00:28:25,265 --> 00:28:26,645
Speaker 11:  So, Steve Ballmer, of course.

411
00:28:28,485 --> 00:28:32,205
Speaker 5:  Richard, you And I are gonna do a sports thing because one of the angry feelings

412
00:28:32,205 --> 00:28:35,925
Speaker 5:  I've had this summer is that watching sports is a nightmare. And maybe I

413
00:28:35,925 --> 00:28:38,645
Speaker 5:  just don't like sports anymore. Maybe the the simplest thing to do is just

414
00:28:38,645 --> 00:28:40,645
Speaker 5:  not like sports anymore. So we're gonna come back to that. Do

415
00:28:40,645 --> 00:28:41,205
Speaker 11:  You ever like sports?

416
00:28:41,965 --> 00:28:45,725
Speaker 5:  Listen, not now, Richard. Not now.

417
00:28:47,535 --> 00:28:51,245
Speaker 5:  We're gonna talk about Meta because Meta Connect was this week, big week

418
00:28:51,245 --> 00:28:54,965
Speaker 5:  for Smart Glasses, big week for awkward demos in front of large

419
00:28:55,245 --> 00:28:58,685
Speaker 5:  audiences, full of people big week for Mark Zuckerberg wearing sunglasses

420
00:28:58,835 --> 00:29:02,685
Speaker 5:  that may or may not look very good on his face. We have a lot to talk about.

421
00:29:02,705 --> 00:29:05,445
Speaker 5:  So we're gonna go through Meta Connect, then we have a lightning round full

422
00:29:05,445 --> 00:29:09,285
Speaker 5:  of like a lot of surprisingly huge news. This is like an easy

423
00:29:09,995 --> 00:29:13,645
Speaker 5:  four hour VERGE cast kind of week. But we are gonna do our best not to do

424
00:29:13,645 --> 00:29:17,525
Speaker 5:  that three hours maximum. But let's start

425
00:29:18,235 --> 00:29:22,005
Speaker 5:  with Meta Connect. So the, the top line of the news here

426
00:29:22,385 --> 00:29:25,765
Speaker 5:  is that Meta announced a bunch of new smart glasses. I wanna get into all

427
00:29:25,765 --> 00:29:29,645
Speaker 5:  of them, but basically there is a new product called, And I have to look

428
00:29:29,805 --> 00:29:33,085
Speaker 5:  at these names because they're such horrendous name crimes. There is the

429
00:29:33,085 --> 00:29:36,805
Speaker 5:  Meta Ray Band display, which is smart glasses with a little

430
00:29:36,805 --> 00:29:40,605
Speaker 5:  display that we'll get into V Song who has worn all of these

431
00:29:40,605 --> 00:29:43,725
Speaker 5:  and reviewed all of them said they're the best smart glasses she's ever tried.

432
00:29:43,745 --> 00:29:46,605
Speaker 5:  And that is not a thing V says lightly. I think that's a big deal. There's

433
00:29:46,605 --> 00:29:50,285
Speaker 5:  also the Oakley Meta Vanguard. Sure. And then

434
00:29:50,295 --> 00:29:53,765
Speaker 5:  there is the new Meta Ray band. Smart glasses.

435
00:29:54,255 --> 00:29:57,925
Speaker 12:  Sorry David. That's the RayBan Meta. No, did they? Unless they changed it.

436
00:29:58,105 --> 00:29:58,325
Speaker 12:  Ah,

437
00:29:58,475 --> 00:29:59,845
Speaker 5:  It's so I thought I had it right.

438
00:29:59,845 --> 00:30:02,805
Speaker 12:  This is, this is like super inside baseball, but like the, the original

439
00:30:02,805 --> 00:30:06,205
Speaker 12:  product is the RayBan Metas or RayBan Meta.

440
00:30:06,625 --> 00:30:09,245
Speaker 12:  But like nobody knows that. And we're like, oh, it's the Meta Ray band.

441
00:30:09,585 --> 00:30:12,525
Speaker 12:  And so it's just, it, it like writing about these on our website is just

442
00:30:12,525 --> 00:30:15,885
Speaker 12:  constantly switching the Meta back and forth as we figure out which way

443
00:30:15,985 --> 00:30:19,845
Speaker 12:  it goes. They need, they need better naming. I

444
00:30:20,285 --> 00:30:24,195
Speaker 5:  Absolutely guarantee you that behind all of these names

445
00:30:24,425 --> 00:30:27,995
Speaker 5:  were teams of executives and lawyers sitting in conference rooms

446
00:30:28,355 --> 00:30:32,195
Speaker 5:  debating whose name comes first. It's like, if you ever watch the credits

447
00:30:32,215 --> 00:30:35,755
Speaker 5:  of a movie and, and you wonder there's like, you know, they'll, they'll say

448
00:30:35,755 --> 00:30:39,635
Speaker 5:  a bunch of names and then at the end it'll be like, and you know, Alec

449
00:30:39,635 --> 00:30:43,115
Speaker 5:  Baldwin or like, and also guest starring

450
00:30:44,515 --> 00:30:48,035
Speaker 5:  whatever Peter Gallagher, the order in which those names

451
00:30:48,095 --> 00:30:52,075
Speaker 5:  appear and the the like prepositions that come before them is

452
00:30:52,075 --> 00:30:55,995
Speaker 5:  like endlessly litigated and contracted. And I just, I just want

453
00:30:56,195 --> 00:31:00,035
Speaker 5:  everyone watching and listening to this podcast to imagine the meeting in

454
00:31:00,035 --> 00:31:03,995
Speaker 5:  which they decided which glasses would be the Meta RayBan and which would

455
00:31:03,995 --> 00:31:07,875
Speaker 5:  be the RayBan Meta and be so, so happy that you

456
00:31:07,875 --> 00:31:11,515
Speaker 5:  are not in a life that makes you be inside of that meeting.

457
00:31:12,055 --> 00:31:15,635
Speaker 5:  That's all, that's all I have. Just be glad that whatever choices you have

458
00:31:15,635 --> 00:31:19,155
Speaker 5:  made, you did not have to be in the meeting where you decided which one was

459
00:31:19,155 --> 00:31:20,915
Speaker 5:  the Meta Ray band and which one was the RayBan Meta?

460
00:31:20,945 --> 00:31:24,235
Speaker 12:  They're not even names, they're just a collection of brands

461
00:31:24,615 --> 00:31:25,555
Speaker 12:  listed together.

462
00:31:25,975 --> 00:31:29,755
Speaker 5:  It has such like Mark by Mark Jacobs starring Mark Jacobs energy in a,

463
00:31:29,765 --> 00:31:32,555
Speaker 11:  Sorry, I gotta go the other way on this. You guys are out here disrespecting

464
00:31:32,935 --> 00:31:35,315
Speaker 11:  the Meta Ray band Gen two.

465
00:31:37,535 --> 00:31:38,715
Speaker 11:  My favorite pair of smart glasses.

466
00:31:39,715 --> 00:31:42,155
Speaker 12:  I I get, I mean I know who makes it.

467
00:31:43,885 --> 00:31:44,655
Speaker 5:  It's do you

468
00:31:44,915 --> 00:31:47,415
Speaker 11:  Are you sure have, have you looked at their blog posts? They, they go back

469
00:31:47,415 --> 00:31:51,015
Speaker 11:  and forth between calling the the Meta Ray band. I'm sorry, the RayBan Meta

470
00:31:51,325 --> 00:31:54,975
Speaker 11:  Glasses Gen two. See I I did it myself. I I'm I'm there

471
00:31:55,045 --> 00:31:58,855
Speaker 11:  also and the Ray Band Meta Glasses Gen two. So

472
00:31:58,875 --> 00:32:02,155
Speaker 11:  is Gen two part of the name or is it not? So even,

473
00:32:02,155 --> 00:32:06,075
Speaker 5:  Even the company that wants us to buy these things doesn't

474
00:32:06,075 --> 00:32:09,855
Speaker 5:  know what they're actually called. This is the first time ever I've been

475
00:32:09,855 --> 00:32:13,175
Speaker 5:  like, maybe Sony has it right just by having endless hexa decimal

476
00:32:13,385 --> 00:32:16,815
Speaker 5:  situations every time they want to sell a new phone instead of headphones.

477
00:32:16,855 --> 00:32:20,295
Speaker 11:  I still remember when we had to ask if it's iPod Shuffle or iPod Shuffles

478
00:32:20,295 --> 00:32:21,375
Speaker 11:  or iPods shuffle.

479
00:32:22,155 --> 00:32:26,055
Speaker 5:  Oh God. And Apple's whole thing where you can't put the in front of the

480
00:32:26,055 --> 00:32:28,895
Speaker 5:  name. They don't call it the iPad. It's just iPad. Anyway,

481
00:32:29,915 --> 00:32:32,535
Speaker 5:  if we keep talking about names, I will actually go insane because I could

482
00:32:32,535 --> 00:32:36,295
Speaker 5:  do this forever. Let's start with the display. Well the

483
00:32:36,295 --> 00:32:38,775
Speaker 5:  screen one, as we are going to call it from now on,

484
00:32:40,715 --> 00:32:44,205
Speaker 5:  this is one we've been hearing a lot about for a while. Our, our

485
00:32:44,305 --> 00:32:47,605
Speaker 5:  former colleague and current contributor Alex Heath, has been like scooping

486
00:32:47,605 --> 00:32:51,485
Speaker 5:  this roadmap for years. And we got a demo of

487
00:32:51,775 --> 00:32:55,765
Speaker 5:  Orion, which is, I would say like the, the more impressive version of this

488
00:32:55,795 --> 00:32:59,205
Speaker 5:  idea last year. And then this year

489
00:33:00,025 --> 00:33:03,885
Speaker 5:  it, this is the first sort of relatively

490
00:33:03,975 --> 00:33:07,845
Speaker 5:  mainstream available version of smart glasses with a screen, which

491
00:33:07,845 --> 00:33:11,445
Speaker 5:  we've known Meta is gonna be working on, but now it actually exists.

492
00:33:12,225 --> 00:33:14,405
Speaker 5:  Let me just run through the specs real fast before we get into it. 'cause

493
00:33:14,405 --> 00:33:17,365
Speaker 5:  I'm very curious what you both make of this because I, I have reacted to

494
00:33:17,365 --> 00:33:20,645
Speaker 5:  this in a way that I did not expect. Basically they, they look like sunglasses.

495
00:33:20,645 --> 00:33:24,205
Speaker 5:  They're a little thicker and a little heavier than the, the, even the smart

496
00:33:24,205 --> 00:33:27,725
Speaker 5:  glasses we've seen before. They weigh 69 grams, which if that means nothing

497
00:33:27,725 --> 00:33:31,565
Speaker 5:  to you, it's like double the weight of an AirPods case. So just

498
00:33:31,565 --> 00:33:34,845
Speaker 5:  do without what you will tie two of those to your head and see how it feels.

499
00:33:35,995 --> 00:33:39,765
Speaker 5:  They get about six hours of battery. They have 5,000 knits of

500
00:33:39,765 --> 00:33:43,685
Speaker 5:  brightness on this little screen that sort of shows up in front of

501
00:33:43,685 --> 00:33:46,725
Speaker 5:  your, it looks like your right eye. And it's, it's just a little tiny heads

502
00:33:46,725 --> 00:33:50,485
Speaker 5:  up display. It's not like a full augmented reality thing. It's just a little

503
00:33:50,825 --> 00:33:54,765
Speaker 5:  600 by 600, I think it's 20 degree field of view

504
00:33:55,225 --> 00:33:58,605
Speaker 5:  screen that sits right in front of your eyes and it's very bright

505
00:33:59,065 --> 00:34:02,925
Speaker 5:  and everybody who has m worn it says they're able to see it in,

506
00:34:02,955 --> 00:34:06,845
Speaker 5:  even in bright Light V Song said if you look directly into the sun, you

507
00:34:06,845 --> 00:34:09,685
Speaker 5:  won't be able to see it, but also don't do that. So that's fine. It's just

508
00:34:09,765 --> 00:34:13,285
Speaker 5:  a, it's a pair of smart glasses with a little tiny display that does some

509
00:34:13,285 --> 00:34:17,015
Speaker 5:  stuff. And I think that is like, that's both kind of it

510
00:34:17,275 --> 00:34:21,215
Speaker 5:  and kind of enough to me And I wanna get into the control system in a

511
00:34:21,215 --> 00:34:25,115
Speaker 5:  minute. But the glasses alone I feel like are actually

512
00:34:25,115 --> 00:34:28,555
Speaker 5:  pretty exciting. But I'm curious, Richard, what was your, what was your reaction

513
00:34:28,555 --> 00:34:28,835
Speaker 5:  to these?

514
00:34:29,515 --> 00:34:32,755
Speaker 11:  I still wonder if there may be a little bit too early with these, And I

515
00:34:32,755 --> 00:34:35,835
Speaker 11:  understand they're maybe still planning only on selling limited amounts

516
00:34:35,835 --> 00:34:39,275
Speaker 11:  of these. I I don't know how many they think they will, will move. But one

517
00:34:39,275 --> 00:34:41,995
Speaker 11:  of the things that they mentioned, And I I think we'll get to their conversation

518
00:34:41,995 --> 00:34:45,955
Speaker 11:  with with Alex Heath is that lots of

519
00:34:45,955 --> 00:34:46,795
Speaker 11:  people wear glasses already.

520
00:34:48,495 --> 00:34:52,075
Speaker 11:  And as a person, I don't know David, are you a glasses contacts guy or,

521
00:34:52,375 --> 00:34:53,475
Speaker 5:  I'm not a glasses contacts guy.

522
00:34:53,535 --> 00:34:54,715
Speaker 11:  Oh, you one of those 2020

523
00:34:54,915 --> 00:34:58,315
Speaker 5:  Actually it's better than 2020 vision. Like not to brag it is bragging. I

524
00:34:58,315 --> 00:34:58,595
Speaker 5:  always knew there

525
00:34:58,595 --> 00:34:59,795
Speaker 11:  Was some weird impression. It's fine.

526
00:35:01,355 --> 00:35:03,195
Speaker 5:  I don't have a lot going for me. I've,

527
00:35:03,195 --> 00:35:06,515
Speaker 11:  I've been trading the ability to look a little bit more punchable

528
00:35:07,175 --> 00:35:11,115
Speaker 11:  for being able to see for basically my whole life. And

529
00:35:11,275 --> 00:35:13,915
Speaker 11:  I don't know if I want to wear slightly thicker glasses just to have a screen

530
00:35:13,915 --> 00:35:15,675
Speaker 11:  in 'em and to have to charge 'em all the time.

531
00:35:15,945 --> 00:35:18,555
Speaker 5:  Yeah. So can I just read you the quote that Mark Zuckerberg said about this?

532
00:35:18,675 --> 00:35:20,875
Speaker 5:  'cause I actually thought it was really instructive and interesting about

533
00:35:20,875 --> 00:35:23,995
Speaker 5:  how they were talking about this. So this is an interview with Alex Heath

534
00:35:25,575 --> 00:35:28,995
Speaker 5:  and he said there are between one to 2 billion people who wear glasses on

535
00:35:28,995 --> 00:35:32,595
Speaker 5:  a daily basis today for vision correction. Is there a world where in five

536
00:35:32,595 --> 00:35:35,875
Speaker 5:  or seven years the vast majority of those glasses are AI glasses in some

537
00:35:36,075 --> 00:35:38,565
Speaker 5:  capacity? I think that's kind of like when the iPhone came out and everyone

538
00:35:38,565 --> 00:35:41,405
Speaker 5:  had flip phones. It's just a matter of time before they all become smartphones.

539
00:35:42,085 --> 00:35:45,565
Speaker 5:  I would say the iPhone comparison there doesn't make any sense like that

540
00:35:45,565 --> 00:35:48,765
Speaker 5:  is he, he just described two completely different things where it's not that

541
00:35:48,925 --> 00:35:51,525
Speaker 5:  everyone who had flip phones upgraded to smart like that, that's just none

542
00:35:51,525 --> 00:35:52,165
Speaker 5:  of that is how it worked.

543
00:35:54,195 --> 00:35:57,995
Speaker 5:  I think it's fascinating to hear him say that our target

544
00:35:57,995 --> 00:36:01,475
Speaker 5:  market is people who wear glasses because we've had a lot of conversations

545
00:36:01,535 --> 00:36:05,235
Speaker 5:  on this show and elsewhere, basically asking the question,

546
00:36:05,975 --> 00:36:08,475
Speaker 5:  are any of these companies going to be able to convince people who don't

547
00:36:08,475 --> 00:36:11,595
Speaker 5:  wear glasses to wear glasses? And I think that is a steep, steep, steep,

548
00:36:11,685 --> 00:36:15,555
Speaker 5:  steep hill to climb for all of these companies. But the idea

549
00:36:15,555 --> 00:36:19,395
Speaker 5:  that they're just saying, okay, how do we take the glasses you're already

550
00:36:19,395 --> 00:36:23,275
Speaker 5:  wearing and try to put some intelligence and smarts into them

551
00:36:24,805 --> 00:36:28,745
Speaker 5:  vastly more achievable. Like yes, smaller market, hard for

552
00:36:28,745 --> 00:36:31,185
Speaker 5:  lots of different reasons, people's prescriptions are complicated. Managing

553
00:36:31,185 --> 00:36:33,865
Speaker 5:  this stuff is complicated. These things get expensive really fast, like on

554
00:36:33,865 --> 00:36:37,825
Speaker 5:  and on. But I think thinking about that as the target market is just

555
00:36:37,825 --> 00:36:41,105
Speaker 5:  really interesting to me and not at all what I expected. So like he's, he's

556
00:36:41,105 --> 00:36:44,625
Speaker 5:  after the two of you who wear glasses and he, he is trying to convince you

557
00:36:45,005 --> 00:36:48,145
Speaker 5:  way before he tries to convince me that these things are worth wearing all

558
00:36:48,145 --> 00:36:48,625
Speaker 5:  day every day.

559
00:36:48,895 --> 00:36:52,705
Speaker 12:  Also like to Richard's point, I I'm wearing wire frame

560
00:36:52,705 --> 00:36:56,425
Speaker 12:  glasses right now, like wire frame glasses are, are I, listen,

561
00:36:56,605 --> 00:36:59,345
Speaker 12:  I'm, I'm not gonna put myself out there as like a fashion expert, but I

562
00:36:59,345 --> 00:37:02,905
Speaker 12:  feel like they're much more in than the like super chunky, thick

563
00:37:02,905 --> 00:37:06,825
Speaker 12:  hipster glasses that I think the Meta Ray Ban

564
00:37:06,825 --> 00:37:10,625
Speaker 12:  Display glasses are, are much more in line with they had those

565
00:37:10,625 --> 00:37:14,145
Speaker 12:  15 years ago, oh man, that they would be right on target.

566
00:37:15,355 --> 00:37:17,665
Speaker 12:  These things are cyclical. Maybe they'll come back around, maybe they can

567
00:37:17,825 --> 00:37:21,305
Speaker 12:  convince us. But right now these are, they're, they're thicker than a standard

568
00:37:21,335 --> 00:37:25,315
Speaker 12:  pair of Wayfairs And I

569
00:37:25,535 --> 00:37:29,475
Speaker 12:  I'm not sure that's even the, you know, most popular type right now. So

570
00:37:29,665 --> 00:37:33,275
Speaker 12:  look, these are a fashion product. It has to be fashionable first and foremost.

571
00:37:34,645 --> 00:37:38,305
Speaker 12:  You know, whether the tech can get there is, is a whole other question.

572
00:37:38,405 --> 00:37:41,945
Speaker 12:  So I think they have a, a challenge number one in just like bringing these

573
00:37:42,045 --> 00:37:45,865
Speaker 12:  two different styles of glasses right now it is in one style as far as I

574
00:37:45,865 --> 00:37:49,785
Speaker 12:  can tell, and it is bigger than a standard pair of glasses. They

575
00:37:49,785 --> 00:37:53,025
Speaker 12:  look, they look all right. They're like, it's stylized. It's like heavily

576
00:37:53,265 --> 00:37:53,825
Speaker 12:  stylized.

577
00:37:55,515 --> 00:37:58,415
Speaker 12:  Can they make that work in smaller pairs of glasses? It's gonna take a while.

578
00:37:58,555 --> 00:38:00,215
Speaker 12:  And I think that's like a big part of the

579
00:38:00,215 --> 00:38:04,095
Speaker 5:  Story here. Yeah. And for whatever sort it does seem like Meta is

580
00:38:04,095 --> 00:38:08,055
Speaker 5:  better set up to do that than almost anybody, right? This, this huge

581
00:38:08,245 --> 00:38:12,055
Speaker 5:  partnership they have with Esler Luxottica is a big deal. And

582
00:38:12,055 --> 00:38:15,895
Speaker 5:  that's like, that's the company that makes most people's glasses. And so

583
00:38:16,515 --> 00:38:19,255
Speaker 5:  the the ability to move this stuff through

584
00:38:20,155 --> 00:38:24,055
Speaker 5:  styles and lines and brands over time is there. But

585
00:38:24,095 --> 00:38:27,775
Speaker 5:  I agree like Jake, the gap between what we saw today

586
00:38:28,235 --> 00:38:31,615
Speaker 5:  and your glasses is enormous. Yeah.

587
00:38:31,905 --> 00:38:33,255
Speaker 5:  We're nowhere close. Even

588
00:38:33,255 --> 00:38:34,575
Speaker 12:  Like Richard's glasses,

589
00:38:34,665 --> 00:38:37,845
Speaker 5:  Which have some plastic to them, I don't think we're anywhere,

590
00:38:38,565 --> 00:38:42,365
Speaker 11:  Anywhere close to this. No. It it's, it's massive. And and they are big

591
00:38:42,365 --> 00:38:45,485
Speaker 11:  in a way that when someone sees you wearing them, they, they, they're saying,

592
00:38:45,505 --> 00:38:49,245
Speaker 11:  oh, you've got those on. Yeah. Which as the glasses

593
00:38:49,315 --> 00:38:53,085
Speaker 11:  wear, I can say is not the thing that you want to hear from someone who's

594
00:38:53,085 --> 00:38:53,845
Speaker 11:  noticed that you wear glasses.

595
00:38:54,385 --> 00:38:58,325
Speaker 5:  Oh, you've got those on is is such a real thing that's

596
00:38:58,325 --> 00:39:01,725
Speaker 5:  happening right now in all of these spaces. 'cause I think to me,

597
00:39:02,235 --> 00:39:05,685
Speaker 5:  like I, I wear the, I have the, the original Meta Ray bands

598
00:39:06,435 --> 00:39:10,125
Speaker 5:  that I like a lot And I, I wear them mostly to use as headphones And

599
00:39:11,085 --> 00:39:15,045
Speaker 5:  I ironically, as they've become more popular, people are noticing

600
00:39:15,045 --> 00:39:18,765
Speaker 5:  them more on my face, which is not what I expected. Like you, you, you expect

601
00:39:18,875 --> 00:39:22,805
Speaker 5:  this stuff to sort of blend in as you start to see more

602
00:39:22,805 --> 00:39:25,525
Speaker 5:  people wearing it. You like, like you don't notice somebody wearing AirPods

603
00:39:25,525 --> 00:39:29,285
Speaker 5:  anymore, right? Like you don't clock AirPods as they go by. If I wear these,

604
00:39:30,685 --> 00:39:34,525
Speaker 5:  I get constant notif notices because like you can tell because

605
00:39:34,525 --> 00:39:37,325
Speaker 5:  people inadvertently make eye contact with you because they're looking at

606
00:39:37,325 --> 00:39:40,045
Speaker 5:  your eyes. And so as I'm walking down the street, I'm constantly giving people

607
00:39:40,045 --> 00:39:42,645
Speaker 5:  who are just like sort of giving me these sideways glances as I walk by them.

608
00:39:43,185 --> 00:39:47,005
Speaker 5:  And yeah, I get that is not what anybody is looking for with

609
00:39:47,005 --> 00:39:48,645
Speaker 5:  their pair of glasses. I don't think

610
00:39:49,065 --> 00:39:52,935
Speaker 11:  The screen does seem to be good, right? They they

611
00:39:52,935 --> 00:39:53,215
Speaker 11:  did it.

612
00:39:53,355 --> 00:39:57,295
Speaker 5:  It is, and this is, this is the thing that is like fascinating about this

613
00:39:57,295 --> 00:40:01,285
Speaker 5:  whole road that Meta is on right now is it seems like the screen

614
00:40:01,455 --> 00:40:04,925
Speaker 5:  works. And to me, if you're, if you're gonna get a pair of glasses like this,

615
00:40:05,165 --> 00:40:08,525
Speaker 5:  a screen makes absolute perfect sense, right? A bunch of the stuff that they're

616
00:40:08,675 --> 00:40:12,325
Speaker 5:  talking about doing on this is simple things like

617
00:40:12,495 --> 00:40:16,445
Speaker 5:  being able to, you know, get turn by turn directions in your

618
00:40:16,445 --> 00:40:20,005
Speaker 5:  heads up display, perfect use case for this kind of thing. Live translation

619
00:40:20,105 --> 00:40:23,485
Speaker 5:  in front of your eyes as you're talking to somebody. Perfect use case for

620
00:40:23,485 --> 00:40:26,765
Speaker 5:  this kind of display. Like using your vision

621
00:40:27,345 --> 00:40:31,005
Speaker 5:  to line up a photo that you're taking with the camera in your glasses.

622
00:40:31,005 --> 00:40:34,965
Speaker 5:  Perfect use case for this kind of like, if we're gonna do smart

623
00:40:34,965 --> 00:40:38,885
Speaker 5:  glasses, they need displays. I think we've known that for a while and

624
00:40:38,885 --> 00:40:42,715
Speaker 5:  it seems like if you're Meta you've got it,

625
00:40:43,175 --> 00:40:46,835
Speaker 5:  if not right, then, then largely right. Like it, we will have to see and

626
00:40:46,855 --> 00:40:50,035
Speaker 5:  you know, use the thing and review it properly. But, but I think you're right,

627
00:40:50,035 --> 00:40:53,915
Speaker 5:  it does seem like the early returns on this thing are that

628
00:40:54,185 --> 00:40:57,995
Speaker 5:  Meta kind of got it right. The question is just even more so

629
00:40:58,135 --> 00:41:01,715
Speaker 5:  is this a thing that I want? I don't know. And I think the thing that I'm

630
00:41:01,715 --> 00:41:05,395
Speaker 5:  so struck by with this one in particular is there is

631
00:41:05,425 --> 00:41:09,355
Speaker 5:  this weird kind of distant look you get

632
00:41:09,355 --> 00:41:13,115
Speaker 5:  in your eyes when you're looking at a heads up display that is just

633
00:41:13,345 --> 00:41:17,235
Speaker 5:  awkward in life. And, and a lot of our coverage pointed

634
00:41:17,235 --> 00:41:20,555
Speaker 5:  this out And I think it's, it's just a strange thing that like, no, you're

635
00:41:20,555 --> 00:41:24,395
Speaker 5:  not gonna be able to see my screen if I'm wearing these glasses, right?

636
00:41:24,395 --> 00:41:26,395
Speaker 5:  Like if you And I are just sitting here looking at each other and we're both

637
00:41:26,395 --> 00:41:29,795
Speaker 5:  wearing glasses, you're not gonna be able to see that my screen is on, but

638
00:41:29,795 --> 00:41:33,325
Speaker 5:  you're gonna be able to see that I'm focusing my eyes kind of up

639
00:41:33,635 --> 00:41:37,525
Speaker 5:  here and not on you. And it, like a lot of the pictures I've seen

640
00:41:37,525 --> 00:41:41,485
Speaker 5:  kind of make it look like people are just sort of staring

641
00:41:41,545 --> 00:41:44,245
Speaker 5:  at nothing and it's, it's just this weird

642
00:41:45,245 --> 00:41:49,125
Speaker 5:  distracted thing that's happening. And at the same time, the not knowing

643
00:41:50,065 --> 00:41:53,445
Speaker 5:  is just as big a problem to me. Like, we went through this with

644
00:41:53,735 --> 00:41:57,085
Speaker 5:  glass holes and this question of like, are you recording is a problem?

645
00:41:57,585 --> 00:42:01,205
Speaker 5:  And so not only are you, are you recording, but are you

646
00:42:01,205 --> 00:42:04,125
Speaker 5:  listening to me? Are you paying attention to me? Can you, are you looking

647
00:42:04,125 --> 00:42:07,925
Speaker 5:  at me? Is like, there's so many like social cues that

648
00:42:08,405 --> 00:42:12,325
Speaker 5:  a pair of glasses like this totally destroys. And I just, I don't

649
00:42:12,325 --> 00:42:13,245
Speaker 5:  know how we figure that out.

650
00:42:13,885 --> 00:42:17,755
Speaker 12:  I I sorta worry that we are completely

651
00:42:17,785 --> 00:42:21,755
Speaker 12:  past that, right? You think, oh yes, because Google Glass came

652
00:42:22,145 --> 00:42:25,715
Speaker 12:  very early smartphone era, right? People were not used to

653
00:42:26,145 --> 00:42:29,915
Speaker 12:  screens and cameras being everywhere yet. You know, 10,

654
00:42:29,915 --> 00:42:33,595
Speaker 12:  15 years on, you can strap 10 cameras to your face and

655
00:42:33,755 --> 00:42:37,235
Speaker 12:  somebody's just like, yo, what's up? Like, that's nor right, like the, the

656
00:42:37,235 --> 00:42:41,075
Speaker 12:  other pair of glasses, they make their headphones and cameras on your

657
00:42:41,075 --> 00:42:42,635
Speaker 12:  face. Nobody cares. Right?

658
00:42:42,775 --> 00:42:45,355
Speaker 5:  But that's, that's kind of the point, right? Like I think if I have a, if

659
00:42:45,355 --> 00:42:49,275
Speaker 5:  I put a GoPro on my face, you, you, you know the answers to all of

660
00:42:49,275 --> 00:42:52,435
Speaker 5:  your questions already, right? Like, I'm wearing a GoPro on my face. Yes.

661
00:42:52,475 --> 00:42:56,355
Speaker 5:  I have a camera on that is recording you. If I'm just wearing a pair

662
00:42:56,355 --> 00:43:00,195
Speaker 5:  of glasses that has a camera in them, like the, the subtlety

663
00:43:00,195 --> 00:43:04,115
Speaker 5:  is actually the problem. In a strange way, if this thing just had a big

664
00:43:04,255 --> 00:43:08,155
Speaker 5:  ass screen that like came out of the glasses and folded down and

665
00:43:08,155 --> 00:43:09,315
Speaker 5:  you just saw it right here,

666
00:43:11,065 --> 00:43:15,035
Speaker 5:  that would be worse in some ways, but better as a, in, in

667
00:43:15,035 --> 00:43:18,875
Speaker 5:  a, in a like human interaction kind of way because then at least I know what's

668
00:43:18,875 --> 00:43:22,635
Speaker 5:  going on. Whereas my read of you as a person is

669
00:43:22,695 --> 00:43:26,195
Speaker 5:  now totally incongruous with reality. It's like the transparency mode in

670
00:43:26,195 --> 00:43:29,915
Speaker 5:  AirPods, which I think this has borne out in a lot of interesting ways. Like

671
00:43:29,915 --> 00:43:33,715
Speaker 5:  when, if you guys are wearing headphones and you go into a store, what do

672
00:43:33,715 --> 00:43:35,915
Speaker 5:  you do if you're gonna, you're, you're like, you're, you're up at the counter

673
00:43:35,935 --> 00:43:39,395
Speaker 5:  at the coffee shop, you have both headphones in. Do you take one out? Do

674
00:43:39,395 --> 00:43:41,115
Speaker 5:  you just pause your music and talk through your headphones? Like what do

675
00:43:41,115 --> 00:43:42,235
Speaker 5:  you, what do you do? I

676
00:43:42,305 --> 00:43:44,195
Speaker 11:  Usually just pause the music and talk.

677
00:43:44,745 --> 00:43:46,815
Speaker 5:  Okay, Jake, what

678
00:43:46,815 --> 00:43:50,055
Speaker 12:  Do you do? Oh yeah, I'm, I'm I'm taking them out. Yeah, I, it's like, it's

679
00:43:50,055 --> 00:43:53,175
Speaker 12:  in the way, I mean, it's like the same thing if, if I, if I go into the

680
00:43:53,175 --> 00:43:56,255
Speaker 12:  store And I'm wearing sunglasses, like I'm gonna take them off to talk to

681
00:43:56,455 --> 00:43:56,575
Speaker 12:  somebody,

682
00:43:57,705 --> 00:44:00,825
Speaker 5:  I will always like performatively take out one of my headphones to be like,

683
00:44:00,975 --> 00:44:04,345
Speaker 5:  like as I'm walking up, just to make it very clear that like, yes, I'm listening

684
00:44:04,345 --> 00:44:07,345
Speaker 5:  to you. Like, 'cause I think it, it communicates something right? And there's

685
00:44:07,345 --> 00:44:10,905
Speaker 5:  like, you can see sometimes when somebody is

686
00:44:10,905 --> 00:44:14,385
Speaker 5:  talking to you and you're wearing headphones, they don't know if you can

687
00:44:14,385 --> 00:44:17,305
Speaker 5:  hear them. And there's just like, there's just a million things like this

688
00:44:17,405 --> 00:44:20,585
Speaker 5:  in, in modern life and smart glasses exacerbate every single one of them.

689
00:44:21,445 --> 00:44:24,705
Speaker 5:  And Jake, you're, you're probably right that if we're not over that yet,

690
00:44:24,765 --> 00:44:26,385
Speaker 5:  we will get there quickly. And

691
00:44:27,425 --> 00:44:28,185
Speaker 12:  I, I'm not saying we should

692
00:44:28,245 --> 00:44:31,655
Speaker 5:  Or we'll get used to it or whatever, but it's just, just, I don't know, this

693
00:44:31,655 --> 00:44:34,015
Speaker 5:  is just a thing I keep thinking about. And even looking at pictures, it's

694
00:44:34,015 --> 00:44:37,375
Speaker 5:  like there's something uncanny about

695
00:44:38,045 --> 00:44:40,975
Speaker 5:  some of the pictures we took even a v where she's looking at the camera,

696
00:44:41,075 --> 00:44:44,735
Speaker 5:  but she's not looking at the camera and you can feel it and it's strange.

697
00:44:46,715 --> 00:44:48,715
Speaker 5:  I don't know. That said, these glasses seem awesome.

698
00:44:49,555 --> 00:44:50,635
Speaker 12:  I, I mean I'm

699
00:44:50,785 --> 00:44:51,635
Speaker 5:  Torn on, well

700
00:44:51,785 --> 00:44:55,275
Speaker 12:  This is the thing, like they've been building toward this for

701
00:44:55,825 --> 00:44:58,595
Speaker 12:  many years now and they've been pretty public about the fact that they're

702
00:44:58,675 --> 00:45:02,275
Speaker 12:  building toward this and they're one of many companies, right? Snap has

703
00:45:02,275 --> 00:45:05,595
Speaker 12:  also been racing toward this and it's, I don't know, it, it hasn't been

704
00:45:05,595 --> 00:45:09,235
Speaker 12:  clear to me that we were going to get to a

705
00:45:09,635 --> 00:45:13,395
Speaker 12:  consumer product version this quickly. And obviously we still

706
00:45:13,395 --> 00:45:17,355
Speaker 12:  have to test them, but you know, in these, in these initial

707
00:45:17,445 --> 00:45:21,195
Speaker 12:  demos, it seems like they have built a reasonably functional product

708
00:45:21,255 --> 00:45:25,195
Speaker 12:  and a reasonably functional form factor. A little thick, a little chunky,

709
00:45:26,255 --> 00:45:30,235
Speaker 12:  but you know, that's, that's farther than I think anybody expected. Meta

710
00:45:30,415 --> 00:45:33,995
Speaker 12:  the company that makes Facebook to get with a hardware product, let alone

711
00:45:33,995 --> 00:45:35,315
Speaker 12:  to, to be leaders in the field.

712
00:45:35,665 --> 00:45:39,595
Speaker 5:  Totally. Yeah. I I think that's exactly right. And I think this

713
00:45:39,595 --> 00:45:42,515
Speaker 5:  is probably where we should also talk about the neural band, which is a,

714
00:45:42,595 --> 00:45:46,315
Speaker 5:  a thing that Meta is doing differently from a lot of these other

715
00:45:46,515 --> 00:45:50,355
Speaker 5:  companies that I happen to think is maybe the

716
00:45:50,635 --> 00:45:54,475
Speaker 5:  smartest single decision that Meta has made. So the way that

717
00:45:54,475 --> 00:45:58,355
Speaker 5:  you control a lot of the stuff on these smart glasses is not with

718
00:45:58,355 --> 00:46:02,195
Speaker 5:  like eye tracking or wacky, you know, camera hand tracking

719
00:46:02,195 --> 00:46:05,555
Speaker 5:  stuff. You wear this thing on your arm

720
00:46:05,945 --> 00:46:09,475
Speaker 5:  that actually measures and responds to your motor

721
00:46:09,795 --> 00:46:13,515
Speaker 5:  movements and it uses the, the term it's called electromyography,

722
00:46:13,645 --> 00:46:16,595
Speaker 5:  which is a thing that I know a lot about. So if you'd like to talk about

723
00:46:16,595 --> 00:46:19,515
Speaker 5:  it, we, we please can, but basically you, like you, you put this thing on

724
00:46:19,515 --> 00:46:22,275
Speaker 5:  and then you don't have to have your hands up in view of your glasses, you

725
00:46:22,275 --> 00:46:24,795
Speaker 5:  don't have to have your hands anywhere. You can just, you can just sort of

726
00:46:24,815 --> 00:46:28,355
Speaker 5:  sit here with your hands in your lap and you, you, I think you pinch to

727
00:46:28,455 --> 00:46:32,155
Speaker 5:  select or to go back depending contextually on where you are, you double

728
00:46:32,155 --> 00:46:35,515
Speaker 5:  pinch your fingers to get the display up or

729
00:46:35,665 --> 00:46:39,475
Speaker 5:  dismiss it. You like make a fist and sort of joystick swipe on it to do

730
00:46:39,565 --> 00:46:43,395
Speaker 5:  other stuff. You, you pinch and rotate to, to

731
00:46:43,415 --> 00:46:47,115
Speaker 5:  do zoom in photos or to change the volume. It is like

732
00:46:47,255 --> 00:46:51,195
Speaker 5:  the closest thing we've done yet to the Minority Report interface. It's just

733
00:46:51,195 --> 00:46:54,675
Speaker 5:  like a smaller, more subtle version of Tom Cruise, like moving all the windows

734
00:46:54,675 --> 00:46:58,635
Speaker 5:  around with his hands. And again, this is another thing that

735
00:46:58,635 --> 00:47:02,435
Speaker 5:  like all the demos say it works. Everybody says it is vastly more natural

736
00:47:03,025 --> 00:47:06,195
Speaker 5:  than what you have to do with a lot of these other devices, which is like

737
00:47:06,195 --> 00:47:10,035
Speaker 5:  in the Vision Pro, you have to get used to really carefully

738
00:47:10,395 --> 00:47:12,795
Speaker 5:  focusing on every single thing you wanna do, which is just like, not how

739
00:47:12,795 --> 00:47:16,395
Speaker 5:  people exist in the world and on a lot of these other devices,

740
00:47:16,815 --> 00:47:20,595
Speaker 5:  you spend your time like putting your hands up in front of you

741
00:47:20,935 --> 00:47:23,715
Speaker 5:  in order to take actions and that's awkward. And so I think

742
00:47:24,735 --> 00:47:28,515
Speaker 5:  the idea of it being a separate accessory is probably not

743
00:47:28,525 --> 00:47:32,205
Speaker 5:  ideal in the long run, but is to me

744
00:47:32,885 --> 00:47:36,445
Speaker 5:  a way better system of controlling this kind of thing than basically anything

745
00:47:36,445 --> 00:47:38,515
Speaker 5:  else we've seen before. Am I crazy?

746
00:47:39,175 --> 00:47:42,835
Speaker 12:  It it's subtle too. It like, it, it looks like a wristband and, and like

747
00:47:42,835 --> 00:47:45,195
Speaker 12:  my immediate, the immediate thought is like they, they're gonna put a watch

748
00:47:45,195 --> 00:47:46,275
Speaker 12:  on this thing, right? Like,

749
00:47:46,695 --> 00:47:48,315
Speaker 5:  Ooh, that's a good call.

750
00:47:48,745 --> 00:47:52,595
Speaker 12:  Like th this feels like it becomes something. It's, it seems

751
00:47:52,595 --> 00:47:54,675
Speaker 12:  like it's cool tech on its own regardless of the glasses.

752
00:47:54,675 --> 00:47:58,555
Speaker 5:  Oh man. If this was just, if it was like this but also a Fitbit, like yes.

753
00:47:58,665 --> 00:47:58,955
Speaker 5:  Yeah.

754
00:47:59,275 --> 00:47:59,475
Speaker 12:  I mean

755
00:47:59,815 --> 00:48:00,035
Speaker 5:  I'm

756
00:48:00,035 --> 00:48:00,235
Speaker 12:  So in

757
00:48:00,245 --> 00:48:02,515
Speaker 5:  Makes sense it, I don't even need the screen stuff. Like I got all the screen

758
00:48:02,515 --> 00:48:06,235
Speaker 5:  up here. Just, just give me like step and

759
00:48:06,275 --> 00:48:09,595
Speaker 5:  sleep tracking And I'll wear that thing all the time. Done. That's a great

760
00:48:09,595 --> 00:48:13,545
Speaker 5:  idea. Mark, get at us. I

761
00:48:13,545 --> 00:48:14,545
Speaker 5:  dunno. Richard, what do you think?

762
00:48:14,865 --> 00:48:17,585
Speaker 11:  I think that's definitely the right decision. We've, we've shown this is

763
00:48:17,585 --> 00:48:20,145
Speaker 11:  how controls work. Have you ever played a video game?

764
00:48:21,655 --> 00:48:25,565
Speaker 11:  Like have you ever used a computer? We we've had,

765
00:48:25,565 --> 00:48:29,485
Speaker 11:  we've had this battle. Yeah, like being able to use your, your hands to

766
00:48:29,485 --> 00:48:33,445
Speaker 11:  control something is, is just better than voice or eye tracking or

767
00:48:33,515 --> 00:48:37,445
Speaker 11:  like head or trying to, to wave in front of you at virtual

768
00:48:37,445 --> 00:48:40,685
Speaker 11:  things. Like, like even if you're not holding something, it's just, it,

769
00:48:40,715 --> 00:48:42,285
Speaker 11:  it's just a correct way. Yeah,

770
00:48:42,725 --> 00:48:46,645
Speaker 5:  I agree. And I think making it like a core part of this

771
00:48:46,645 --> 00:48:46,925
Speaker 5:  system

772
00:48:48,485 --> 00:48:52,365
Speaker 5:  probably again alienates some people. 'cause again, it's like if the goal

773
00:48:52,385 --> 00:48:55,885
Speaker 5:  is just to get people who wear glasses

774
00:48:56,225 --> 00:48:59,965
Speaker 5:  to wear these different glasses, you've now asked me to do even more stuff.

775
00:49:00,075 --> 00:49:03,685
Speaker 5:  Yeah, right. I'm spending more money on bigger glasses

776
00:49:03,835 --> 00:49:07,525
Speaker 5:  with a different style And I have to wear this other thing. But for like

777
00:49:07,825 --> 00:49:11,765
Speaker 5:  if, if you sort of back your way down from what the technology can do,

778
00:49:12,035 --> 00:49:14,885
Speaker 5:  this feels like exactly the right road to be going down.

779
00:49:16,405 --> 00:49:18,765
Speaker 5:  Yeah. I just think, I think these are very cool And I'm very curious to see

780
00:49:19,585 --> 00:49:20,725
Speaker 5:  how they do. I think,

781
00:49:22,605 --> 00:49:26,325
Speaker 5:  I think it was Andrew Bosworth, one of the Meta executives told Alex Heath

782
00:49:26,325 --> 00:49:29,125
Speaker 5:  that they're only planning to make a couple hundred thousand of them, which

783
00:49:29,125 --> 00:49:32,165
Speaker 5:  suggests that these are not supposed to be like a huge

784
00:49:32,695 --> 00:49:36,565
Speaker 5:  mainstream product. Even the, the RayBan metas we've been hearing single

785
00:49:36,575 --> 00:49:39,405
Speaker 5:  digit millions for what they've sold, which is like a

786
00:49:39,915 --> 00:49:43,845
Speaker 5:  hilariously different term, single digit millions can mean an awful

787
00:49:44,145 --> 00:49:45,285
Speaker 5:  lot of different numbers.

788
00:49:47,385 --> 00:49:51,125
Speaker 5:  But even that compared to, you know, a couple hundred thousand makes

789
00:49:51,125 --> 00:49:55,045
Speaker 5:  clear really kind of what they're going for here. Which brings

790
00:49:55,045 --> 00:49:58,885
Speaker 5:  us to the next one, which I think I have come to think might be

791
00:49:58,885 --> 00:50:02,725
Speaker 5:  sneakily the coolest thing Meta launched this week, which is

792
00:50:02,725 --> 00:50:05,885
Speaker 5:  the Oakley Meta Vanguard, which are some deeply

793
00:50:06,505 --> 00:50:09,765
Speaker 5:  baller ass wraparound Oakley sunglasses

794
00:50:10,795 --> 00:50:14,045
Speaker 5:  with a camera in the nose bridge, like essentially the way I've come to think

795
00:50:14,045 --> 00:50:17,725
Speaker 5:  about these things, it is, it's a GoPro on your sunglasses. And

796
00:50:18,555 --> 00:50:22,245
Speaker 5:  that strikes me as maybe exactly

797
00:50:22,385 --> 00:50:25,805
Speaker 5:  the correct thing to have done here. Jake, you wear

798
00:50:25,835 --> 00:50:28,925
Speaker 5:  wraparounds to and from work every day if, if memory serves.

799
00:50:28,925 --> 00:50:32,405
Speaker 12:  Yeah. As you can tell, I'm big into extreme sports,

800
00:50:34,025 --> 00:50:34,605
Speaker 12:  so no, I,

801
00:50:34,925 --> 00:50:37,605
Speaker 5:  Whenever Jake is not on The Vergecast, I want you to picture him bass fishing.

802
00:50:38,405 --> 00:50:39,885
Speaker 5:  Yeah, that's, that's important to me. Yeah.

803
00:50:40,165 --> 00:50:43,725
Speaker 12:  IE even what's the opposite of extreme sports? Like

804
00:50:44,045 --> 00:50:47,645
Speaker 12:  I animal don't ask you much. For me, these

805
00:50:47,755 --> 00:50:51,455
Speaker 12:  look outrageous and kind of amazing. And

806
00:50:52,435 --> 00:50:55,775
Speaker 12:  the, the, the thing is there really is just like a big

807
00:50:56,275 --> 00:51:00,095
Speaker 12:  chunky camera right above your nose and it looks a little goofy,

808
00:51:00,595 --> 00:51:03,975
Speaker 12:  but also the, the entire like

809
00:51:04,365 --> 00:51:08,335
Speaker 12:  vibe of these oakleys is like boom in your face. It

810
00:51:08,335 --> 00:51:12,295
Speaker 12:  kind of works. And for like that, for, for what you're trying

811
00:51:12,295 --> 00:51:14,135
Speaker 12:  to film. Oh, that's perfect. Well,

812
00:51:14,155 --> 00:51:16,655
Speaker 11:  So they do fitness tracking too and the camera bit.

813
00:51:16,845 --> 00:51:20,815
Speaker 5:  Yeah, they'll do, they have a heart rate monitor. They do the, the camera

814
00:51:20,985 --> 00:51:24,855
Speaker 5:  stuff and it has like a bunch of

815
00:51:25,095 --> 00:51:28,735
Speaker 5:  partnerships with Strava and Garmin and it, you can do,

816
00:51:29,675 --> 00:51:32,335
Speaker 5:  you, you can use the LED that I think is supposed to show you heart rate

817
00:51:32,335 --> 00:51:35,775
Speaker 5:  stuff also to give you like pacing information as you're going for runs.

818
00:51:35,955 --> 00:51:39,815
Speaker 5:  So there's, there's a lot of like knowledge about who is actually

819
00:51:39,815 --> 00:51:43,415
Speaker 5:  buying sunglasses that look like this anyway. Like, again, it's, it's the

820
00:51:43,415 --> 00:51:45,655
Speaker 5:  same sort of thing we were talking about where it's like we want to take

821
00:51:45,655 --> 00:51:49,415
Speaker 5:  people who might buy something that look like this anyway and give them all

822
00:51:49,415 --> 00:51:52,695
Speaker 5:  these new things to do for this price, but instead of everyone who wears

823
00:51:52,695 --> 00:51:56,175
Speaker 5:  glasses, it's people who buy glasses that look like this. And that to me

824
00:51:56,175 --> 00:51:59,015
Speaker 5:  is such a smart way of thinking about this, right? We're like,

825
00:52:00,525 --> 00:52:04,055
Speaker 5:  wayfarers are, are a choice you make if what you want is sort of the

826
00:52:04,545 --> 00:52:08,255
Speaker 5:  least offensive thing that looks good on the most

827
00:52:08,255 --> 00:52:12,175
Speaker 5:  people kind of glasses. This is the opposite. It's like here is a slice

828
00:52:12,195 --> 00:52:15,335
Speaker 5:  of people and it is a very specific place of people who are going to wear

829
00:52:16,435 --> 00:52:19,975
Speaker 5:  tinted rainbow colored cool ass

830
00:52:20,005 --> 00:52:23,965
Speaker 5:  wraparounds and we're just gonna give them things that those people might

831
00:52:23,965 --> 00:52:27,805
Speaker 5:  want. And that is a completely different way of thinking about what smart

832
00:52:27,805 --> 00:52:31,485
Speaker 5:  glasses might be. But to me is like, if you wanna make one that works right

833
00:52:31,485 --> 00:52:32,765
Speaker 5:  now for people, that's how you do it.

834
00:52:33,165 --> 00:52:37,045
Speaker 12:  I also like, I think there's a really interesting distinction there. The,

835
00:52:37,505 --> 00:52:41,285
Speaker 12:  the Meta Ray band displays the display smart, those

836
00:52:41,305 --> 00:52:45,005
Speaker 12:  are smart glasses. They're glasses with a screen that show you stuff.

837
00:52:46,145 --> 00:52:50,125
Speaker 12:  The all of these other ones, they're fancy headphones in the shape of

838
00:52:50,125 --> 00:52:54,005
Speaker 12:  a pair of glasses, right? Yes. Like, well the air pods now do heart

839
00:52:54,005 --> 00:52:57,925
Speaker 12:  rate tracking. These are just AirPods that also like block

840
00:52:57,925 --> 00:53:01,565
Speaker 12:  the sun, right? That that is a thing people want and buy,

841
00:53:01,575 --> 00:53:05,285
Speaker 12:  right? People like fitness tracking people like headphones, people like

842
00:53:05,285 --> 00:53:08,845
Speaker 12:  sunglasses. Combining all three makes a ton of sense.

843
00:53:09,585 --> 00:53:13,045
Speaker 12:  And being good at one doesn't necessarily mean you're gonna be good at making

844
00:53:13,315 --> 00:53:17,245
Speaker 12:  true smart glasses. So I, I think like there's still

845
00:53:17,285 --> 00:53:21,165
Speaker 12:  a lot they have to prove out with that idea, but were they early

846
00:53:21,345 --> 00:53:25,245
Speaker 12:  to this let's stuff headphones into a glasses form factor and

847
00:53:25,245 --> 00:53:29,085
Speaker 12:  let's start making that, you know, even more useful and more valuable.

848
00:53:29,685 --> 00:53:33,525
Speaker 12:  Absolutely. And the, the vanguard like as kind of ludicrous of a product

849
00:53:33,585 --> 00:53:37,405
Speaker 12:  as it seems. Oh, they're just putting more and more like useful

850
00:53:37,405 --> 00:53:41,005
Speaker 12:  things that people already buy and want into a pair of sunglasses. Which

851
00:53:41,295 --> 00:53:44,125
Speaker 12:  again, to your point, David, there's already a market for these sunglasses

852
00:53:44,175 --> 00:53:45,445
Speaker 12:  right now. They're just making them better.

853
00:53:45,755 --> 00:53:48,845
Speaker 5:  It's cool, right? Yeah. And, and it's like, I think if, if that's, if you're

854
00:53:48,845 --> 00:53:52,045
Speaker 5:  a Meta and you want this stuff to be useful to people, that's the way to

855
00:53:52,045 --> 00:53:55,645
Speaker 5:  do it. Find sunglasses, people are already buying and give,

856
00:53:55,945 --> 00:53:58,845
Speaker 5:  put the things that people are doing when they wear those sunglasses into

857
00:53:58,845 --> 00:54:02,765
Speaker 5:  the sunglasses. And one of those things is like bass fishing

858
00:54:02,875 --> 00:54:06,165
Speaker 5:  with a GoPro on. And, and again, there there are like a bunch of features

859
00:54:06,265 --> 00:54:10,125
Speaker 5:  on this that suggest that who this is for

860
00:54:10,135 --> 00:54:13,565
Speaker 5:  again, right? The, the battery's even longer. It's nine hours of battery,

861
00:54:14,515 --> 00:54:17,925
Speaker 5:  like, like you said, Jake, they're pretty chunky and thick. But again, that's,

862
00:54:17,925 --> 00:54:20,725
Speaker 5:  that's to get a pretty big camera in here.

863
00:54:21,745 --> 00:54:25,685
Speaker 5:  It does up to three K and up to 120 frames per second of video, but not at

864
00:54:25,685 --> 00:54:29,045
Speaker 5:  the same time. The more frame rate you get, the less resolution you're gonna

865
00:54:29,045 --> 00:54:31,765
Speaker 5:  get because otherwise you would essentially let your face on fire. I think

866
00:54:31,815 --> 00:54:34,405
Speaker 5:  these things would get so hot, but yeah, they had, they have the heart rate

867
00:54:34,405 --> 00:54:38,205
Speaker 5:  monitor. It's like, it is so distinctly obvious who these glasses are for

868
00:54:40,025 --> 00:54:43,885
Speaker 5:  And I I just think that's very smart. They are a total name crime again

869
00:54:43,885 --> 00:54:47,845
Speaker 5:  because they're the Oakley Meta Vanguards, which is just a, just a bad name.

870
00:54:48,465 --> 00:54:52,405
Speaker 5:  But the other ones were, were just called HSTN the last time Oakley and

871
00:54:52,405 --> 00:54:55,405
Speaker 5:  Meta did one together and it's like the Houston, Houston whatever glasses.

872
00:54:56,375 --> 00:54:59,445
Speaker 5:  Those were dumb. This is better. That's my take.

873
00:55:00,205 --> 00:55:03,485
Speaker 12:  I agree. And the and the the Oakley of it all is so essential to it, right?

874
00:55:03,515 --> 00:55:07,285
Speaker 12:  Like again, this literally is a product. People are already buying,

875
00:55:07,385 --> 00:55:11,005
Speaker 12:  people already want these specific sunglasses from Oakley. Yeah. Now you're

876
00:55:11,005 --> 00:55:12,005
Speaker 12:  just giving them an upgrade version.

877
00:55:12,585 --> 00:55:15,115
Speaker 5:  Richard, I feel like you'd look cool in wraparounds. What are your thoughts?

878
00:55:16,655 --> 00:55:18,925
Speaker 11:  Never tried it, but maybe

879
00:55:19,525 --> 00:55:23,325
Speaker 5:  I think The Verge cast fashion show in which you try them on no one

880
00:55:23,325 --> 00:55:27,205
Speaker 5:  can see and we talk about it. Fabulous idea. Podcast fashion

881
00:55:27,235 --> 00:55:30,805
Speaker 5:  show is a, is a thing we're gonna pioneer here on this show. It's gonna be

882
00:55:30,805 --> 00:55:34,085
Speaker 5:  amazing. So the other device that Meta

883
00:55:34,275 --> 00:55:37,725
Speaker 5:  announced is the more like main Streamy

884
00:55:38,585 --> 00:55:42,485
Speaker 5:  RayBan Smart Glasses. This is like the new version of the ones

885
00:55:42,485 --> 00:55:45,925
Speaker 5:  that have been out there for a while. And like you said, Jake, they are headphones,

886
00:55:46,285 --> 00:55:50,165
Speaker 5:  they're functionally they are like I I I compare these to

887
00:55:50,165 --> 00:55:54,045
Speaker 5:  like Alexa devices a lot where there are

888
00:55:54,045 --> 00:55:58,005
Speaker 5:  technically lots of things that they can do and are for everybody does the

889
00:55:58,005 --> 00:56:01,965
Speaker 5:  same two things and, and on on Echo devices, people play music and

890
00:56:01,965 --> 00:56:04,925
Speaker 5:  they set timers and then there's a long list of other things that almost

891
00:56:04,925 --> 00:56:08,685
Speaker 5:  nobody does on, on these glasses. You can listen to music

892
00:56:08,745 --> 00:56:12,365
Speaker 5:  and you can take pictures and there's a long list of stuff that people can

893
00:56:12,365 --> 00:56:16,275
Speaker 5:  do. You can do the live ai, lots of interesting ideas about what you

894
00:56:16,275 --> 00:56:19,835
Speaker 5:  might do with a pair of smart glasses. They are sunglasses with speakers

895
00:56:19,895 --> 00:56:23,405
Speaker 5:  and a camera. That's it. That's the whole pitch. And so if that's your whole

896
00:56:23,405 --> 00:56:27,045
Speaker 5:  pitch doing what Meta did here I think is,

897
00:56:27,465 --> 00:56:30,925
Speaker 5:  is correct. The new model is

898
00:56:31,955 --> 00:56:35,445
Speaker 5:  it's more expensive, which is a bummer, but pricing is

899
00:56:36,015 --> 00:56:39,725
Speaker 5:  goofy. Tariffs and inflation and everything has made the cost of everything

900
00:56:39,825 --> 00:56:43,765
Speaker 5:  insane. So like do with the $80 price increase, what

901
00:56:43,765 --> 00:56:46,325
Speaker 5:  you will, it's 379 $9 instead of 2 99,

902
00:56:47,705 --> 00:56:51,685
Speaker 5:  but it has double the rated battery life eight hours on a

903
00:56:51,685 --> 00:56:54,885
Speaker 5:  charge, which is a big deal. The difference between getting four hours of

904
00:56:54,885 --> 00:56:58,165
Speaker 5:  battery on your sunglasses and getting eight is actually the difference between

905
00:56:58,165 --> 00:57:01,325
Speaker 5:  like the battery being annoying and the battery not being annoying. I think

906
00:57:01,325 --> 00:57:04,405
Speaker 5:  in most cases, especially if you have the charging case, which puts it up

907
00:57:04,405 --> 00:57:07,525
Speaker 5:  to, I think it was 48 hours of total battery life.

908
00:57:08,225 --> 00:57:11,085
Speaker 5:  So this is like a, you're charging your sunglasses once a week kind of thing,

909
00:57:11,085 --> 00:57:14,085
Speaker 5:  and that's a pretty solid setup. They also have a bunch of the camera improvements.

910
00:57:14,085 --> 00:57:17,205
Speaker 5:  So you can do up to three K video and up to 60 frames per second, but not

911
00:57:17,205 --> 00:57:18,125
Speaker 5:  at the same time,

912
00:57:19,705 --> 00:57:23,485
Speaker 5:  all four up to three minutes at a time. Again, to keep your face from lighting

913
00:57:23,485 --> 00:57:27,445
Speaker 5:  on fire with the heat of your sunglasses. That would be a

914
00:57:27,445 --> 00:57:29,685
Speaker 5:  tough way to go to the hospital by the way. They're like, what happened to

915
00:57:29,685 --> 00:57:32,165
Speaker 5:  you? What, what are these third degree burns all over your face? And you're

916
00:57:32,165 --> 00:57:36,025
Speaker 5:  like, well I was taking some sweet beach picks

917
00:57:37,165 --> 00:57:40,465
Speaker 5:  and here we are. But anyway, this is like

918
00:57:41,385 --> 00:57:44,645
Speaker 5:  the mainstream version of this thing And I think it continues to be

919
00:57:45,575 --> 00:57:48,985
Speaker 5:  good and interesting and, and kind of more compelling than anybody else who

920
00:57:48,985 --> 00:57:51,505
Speaker 5:  is doing this sort of thing. This

921
00:57:51,505 --> 00:57:55,225
Speaker 12:  Is a tricky upgrade. Like on one hand, double the battery, great. They did

922
00:57:55,225 --> 00:57:59,105
Speaker 12:  the exact thing they should do perfect eight hours is

923
00:57:59,765 --> 00:58:03,625
Speaker 12:  in the ballpark of where you should be. On the other hand, you know, to,

924
00:58:03,645 --> 00:58:06,905
Speaker 12:  to keep repeating my argument, these are headphones and

925
00:58:07,175 --> 00:58:11,025
Speaker 12:  they're now three $79 pair of AirPods Pro three

926
00:58:11,245 --> 00:58:15,065
Speaker 12:  are $250. Those things are gonna be on sale for, for lower

927
00:58:15,265 --> 00:58:19,105
Speaker 12:  than that in a couple of months. So I don't know, this gets tricky.

928
00:58:19,175 --> 00:58:22,665
Speaker 12:  Like I feel like when the old model, which I guess is still available for

929
00:58:22,725 --> 00:58:26,585
Speaker 12:  2 99, but you know, those were when they were available at that price, I

930
00:58:26,585 --> 00:58:29,745
Speaker 12:  think that's closer in price to what you might pay for a pair of wireless

931
00:58:29,745 --> 00:58:33,465
Speaker 12:  headphones. Anyway. Thi this seems like it's

932
00:58:33,465 --> 00:58:37,345
Speaker 12:  getting a little up there. Maybe a little tricky if you're a big fan of

933
00:58:37,345 --> 00:58:40,705
Speaker 12:  these already. Maybe this, this makes sense. I do wonder if this is gonna

934
00:58:40,705 --> 00:58:44,545
Speaker 12:  make it harder for them to get sort of that impulse buy that maybe

935
00:58:45,095 --> 00:58:48,185
Speaker 12:  they were banking on for the original model where people were kind of just

936
00:58:48,185 --> 00:58:52,105
Speaker 12:  like, wow, I can't believe I can get a pair of sunglasses that do that.

937
00:58:53,015 --> 00:58:56,305
Speaker 5:  Yeah, I think I, if you're at a point where it's like a a hundred dollars

938
00:58:56,445 --> 00:59:00,305
Speaker 5:  markup to get all this stuff in it, you, you, you start to have a, an

939
00:59:00,305 --> 00:59:03,545
Speaker 5:  easier case to make, but when it's like double the price and

940
00:59:04,285 --> 00:59:07,705
Speaker 5:  now it'll play music when you already own a pair of headphones. I do agree

941
00:59:07,705 --> 00:59:11,465
Speaker 5:  that's it's a different set of things that Meta

942
00:59:11,525 --> 00:59:15,265
Speaker 5:  is trying to get you to be into here. Yeah, and it really depends on the,

943
00:59:15,265 --> 00:59:18,985
Speaker 5:  the AI being good and my experience

944
00:59:18,985 --> 00:59:22,725
Speaker 5:  with Meta's live AI and frankly all of these live AI

945
00:59:22,725 --> 00:59:26,005
Speaker 5:  systems is that they're not very good. Sometimes they're good, sometimes

946
00:59:26,005 --> 00:59:29,885
Speaker 5:  they're trash. And actually, wait, can I, can I play you a

947
00:59:29,885 --> 00:59:33,845
Speaker 5:  clip from Meta Connect, which was, I would say we, we've

948
00:59:33,845 --> 00:59:37,205
Speaker 5:  all been to a lot of these events. We've covered a lot of these events. We,

949
00:59:37,425 --> 00:59:41,005
Speaker 5:  we have more sympathy than most for the

950
00:59:41,155 --> 00:59:45,045
Speaker 5:  cringey demo fails. But in the, in the annals of cringey

951
00:59:45,045 --> 00:59:48,965
Speaker 5:  demo fails, Meta Connect was a tough one this year. So let me,

952
00:59:48,965 --> 00:59:52,205
Speaker 5:  let me just set this up for you and then I'm gonna play you the full 53 seconds

953
00:59:52,205 --> 00:59:55,925
Speaker 5:  of this clip. Oh no. Because you need to experience every second of it. So

954
00:59:56,265 --> 01:00:00,245
Speaker 5:  in, in a, in an effort to test the live AI stuff on the smart glasses,

955
01:00:00,705 --> 01:00:04,405
Speaker 5:  we have a chef standing up on stage or he's standing up

956
01:00:04,405 --> 01:00:08,085
Speaker 5:  somewhere in front of a table with a bunch of ingredients on it. And the

957
01:00:08,085 --> 01:00:11,605
Speaker 5:  idea is he's gonna use the live AI with the,

958
01:00:12,195 --> 01:00:15,365
Speaker 5:  with the camera and all of the different systems, the the whole multimodal

959
01:00:15,545 --> 01:00:18,605
Speaker 5:  AI setup to make some food.

960
01:00:20,015 --> 01:00:20,755
Speaker 5:  Here's what happens.

961
01:00:21,695 --> 01:00:24,955
Speaker 13:  You can make a Korean inspired steak sauce using soy sauce,

962
01:00:25,515 --> 01:00:26,235
Speaker 13:  sesame oil. What

963
01:00:26,235 --> 01:00:26,835
Speaker 14:  Do I do first French,

964
01:00:31,905 --> 01:00:32,675
Speaker 14:  what do I do first?

965
01:00:34,415 --> 01:00:38,315
Speaker 13:  You've already combined the base ingredients. So now create a pear

966
01:00:38,315 --> 01:00:39,155
Speaker 13:  to add to the sauce.

967
01:00:43,025 --> 01:00:43,875
Speaker 14:  What do I do first?

968
01:00:46,015 --> 01:00:49,755
Speaker 13:  You've already combined the base ingredients, so now grate the pear and

969
01:00:49,755 --> 01:00:51,595
Speaker 13:  gently combine it with the base sauce.

970
01:00:51,975 --> 01:00:55,075
Speaker 14:  All right. I think the wifi might be messed up. Sorry, back to you, mark.

971
01:00:55,425 --> 01:00:57,675
Speaker 14:  It's all good. You know what,

972
01:00:59,265 --> 01:00:59,915
Speaker 14:  it's all good.

973
01:01:02,425 --> 01:01:06,115
Speaker 14:  It's the irony of the whole thing is that you spend

974
01:01:06,125 --> 01:01:09,835
Speaker 14:  years making technology and then the wifi at the day kind of

975
01:01:10,625 --> 01:01:12,115
Speaker 14:  catches you. Alright?

976
01:01:14,015 --> 01:01:17,915
Speaker 5:  Can we just say, first of all, that was obviously not a wifi problem.

977
01:01:18,155 --> 01:01:18,275
Speaker 5:  Nope.

978
01:01:19,585 --> 01:01:20,835
Speaker 12:  Like extremely

979
01:01:21,055 --> 01:01:22,115
Speaker 5:  Not a wifi problem

980
01:01:23,865 --> 01:01:27,805
Speaker 12:  And, and not the only time that happened. Yeah, that it was, well that was

981
01:01:27,805 --> 01:01:29,325
Speaker 12:  the start of the demo fails of the

982
01:01:29,325 --> 01:01:32,445
Speaker 5:  Day. Yeah, it was tough. Yeah. But it, it's like that to me was so

983
01:01:32,565 --> 01:01:35,765
Speaker 5:  illustrative of like the whole AI experience. Like imagine

984
01:01:36,975 --> 01:01:40,325
Speaker 5:  being in front of lots of people doing this demo

985
01:01:40,985 --> 01:01:44,725
Speaker 5:  and even just in your own kitchen trying to talk

986
01:01:45,065 --> 01:01:48,365
Speaker 5:  to the ai and it is like you've put all the base ingredients together and

987
01:01:48,605 --> 01:01:50,925
Speaker 5:  actually what's happening is you're standing in front of an empty bowl and

988
01:01:50,925 --> 01:01:54,565
Speaker 5:  you've done nothing. That experience is so awful

989
01:01:55,345 --> 01:01:58,485
Speaker 5:  and, and because it's ai, because it's voice, because it's, it's sort of

990
01:01:58,485 --> 01:02:02,405
Speaker 5:  directionless like this, it's not clear where to go. It's not clear how

991
01:02:02,405 --> 01:02:04,445
Speaker 5:  to go back. It's not clear how to fix things. It's not clear how to start

992
01:02:04,445 --> 01:02:08,165
Speaker 5:  over. Like the UI of this is so unfinished

993
01:02:08,785 --> 01:02:12,605
Speaker 5:  and the quality of it is so intermittent. I've been stuck in this thing

994
01:02:12,625 --> 01:02:15,925
Speaker 5:  so many times too, where it's like you're just trying to ask a simple question,

995
01:02:16,625 --> 01:02:18,965
Speaker 5:  but you need the answer before you can do something. But because you're doing

996
01:02:19,005 --> 01:02:22,925
Speaker 5:  with ai, you've gone down some insane impossible rabbit hole.

997
01:02:23,185 --> 01:02:27,125
Speaker 5:  And the idea that I'm going to like trust my ongoing

998
01:02:27,125 --> 01:02:31,005
Speaker 5:  day-to-day life to this thing that I can chat with is like

999
01:02:31,005 --> 01:02:34,725
Speaker 5:  that's, you can just see why it breaks all the time and it's not because

1000
01:02:34,725 --> 01:02:36,795
Speaker 5:  of the wifi, it's just not

1001
01:02:38,105 --> 01:02:41,285
Speaker 12:  So, okay. I I'm curious, are you guys

1002
01:02:42,105 --> 01:02:45,445
Speaker 12:  pro these live demos, like, do you think that

1003
01:02:47,005 --> 01:02:50,565
Speaker 12:  companies should still do these despite the very obvious

1004
01:02:50,565 --> 01:02:54,165
Speaker 12:  possibility of failure embarrassment like this, right? Because like the

1005
01:02:54,165 --> 01:02:57,485
Speaker 12:  obvious thing is that then everybody makes fun of you, right? It's just

1006
01:02:57,485 --> 01:02:59,925
Speaker 12:  very easy for 'em to not do these and to script these.

1007
01:03:00,905 --> 01:03:04,815
Speaker 5:  Yes. I mean, I I have spent years

1008
01:03:04,885 --> 01:03:08,655
Speaker 5:  wondering how valuable these events are at all for these companies,

1009
01:03:09,915 --> 01:03:13,655
Speaker 5:  but also like I, I love live demos And I think the the

1010
01:03:14,245 --> 01:03:17,975
Speaker 5:  flip side is when these live demos work

1011
01:03:18,035 --> 01:03:22,015
Speaker 5:  and are cool, it's really impressive. What we've seen is a lot

1012
01:03:22,015 --> 01:03:25,575
Speaker 5:  of even quote unquote live demos are not live. So even the ones that seem

1013
01:03:25,575 --> 01:03:29,415
Speaker 5:  live, you should take with a real grain of salt at this point. These things

1014
01:03:29,415 --> 01:03:33,135
Speaker 5:  are so on rails and like I think about the, the

1015
01:03:33,705 --> 01:03:37,535
Speaker 5:  truck demo where the, the so-called self-driving truck was just

1016
01:03:37,535 --> 01:03:41,495
Speaker 5:  rolling down the hill. Like it's, it's, some of this isn't, is

1017
01:03:41,495 --> 01:03:45,375
Speaker 5:  not real, but I I I genuinely applaud Meta for trying to do this

1018
01:03:45,375 --> 01:03:48,855
Speaker 5:  stuff live on stage and Google sometimes tries to do it live on stage. Although

1019
01:03:48,855 --> 01:03:51,615
Speaker 5:  ev even it is going more towards some of these canned demos. Like

1020
01:03:52,845 --> 01:03:56,615
Speaker 5:  it's just, you should be able to do this in front of people if you're gonna

1021
01:03:56,735 --> 01:04:00,655
Speaker 5:  ship it to the world, right? Like if you, if the demo fails, maybe your

1022
01:04:00,655 --> 01:04:03,135
Speaker 5:  product's not done, I think is is kind of where I land.

1023
01:04:03,565 --> 01:04:06,055
Speaker 11:  Yeah. I mean if you're telling me it's gonna work at my house, you know,

1024
01:04:06,055 --> 01:04:09,895
Speaker 11:  sometimes the wifi is bad, sometimes a step has been missed

1025
01:04:09,955 --> 01:04:13,375
Speaker 11:  or the AI just doesn't catch something the right way.

1026
01:04:14,115 --> 01:04:17,655
Speaker 11:  If, if it can't recover, then that, that kind of is the question that is

1027
01:04:17,655 --> 01:04:21,255
Speaker 11:  the whole sales pitch and, and you should make it. And I think largely that

1028
01:04:21,485 --> 01:04:24,815
Speaker 11:  when these failures happen, if the product is good when it comes out, people

1029
01:04:24,815 --> 01:04:25,655
Speaker 11:  forget about it very quickly.

1030
01:04:26,045 --> 01:04:29,495
Speaker 5:  Yeah. But then when it, when it sucks, everybody goes back to these launches

1031
01:04:29,675 --> 01:04:33,535
Speaker 5:  and it was like, oh right, it sucked. What what they really did is they

1032
01:04:33,535 --> 01:04:37,415
Speaker 5:  should have taught this poor chef how to actually use the glasses. Like

1033
01:04:37,645 --> 01:04:41,415
Speaker 5:  this is such a a, like, he was given a set of things

1034
01:04:41,435 --> 01:04:44,775
Speaker 5:  to say, knowing the responses he was gonna get, and they just put the whole

1035
01:04:44,775 --> 01:04:47,455
Speaker 5:  demo on rails and it's like, what, what actually needs to happen if you wanna

1036
01:04:47,455 --> 01:04:50,935
Speaker 5:  use one of these systems, is you need to learn how to use it. Like if, if

1037
01:04:50,935 --> 01:04:54,815
Speaker 5:  you want to be good at ai, you need to learn how to do

1038
01:04:54,845 --> 01:04:57,935
Speaker 5:  good prompting and you need to learn how to engage with the thing and you

1039
01:04:57,935 --> 01:05:00,095
Speaker 5:  need to learn how to back it up and you need to learn how to start over.

1040
01:05:00,125 --> 01:05:04,055
Speaker 5:  Like they're going to fail. And actually we, we've seen some of

1041
01:05:04,055 --> 01:05:07,295
Speaker 5:  these moss open AI has actually done this a lot in, in some of its product

1042
01:05:07,295 --> 01:05:11,215
Speaker 5:  launches where it is people who are clearly like conversant

1043
01:05:11,355 --> 01:05:14,815
Speaker 5:  in speaking with an AI system. And you see the difference where it's like

1044
01:05:14,815 --> 01:05:17,805
Speaker 5:  even when stuff fails, they're able to sort of redirect and they understand

1045
01:05:17,805 --> 01:05:20,685
Speaker 5:  how the system works and they're able to back up and start over and try new

1046
01:05:20,685 --> 01:05:24,605
Speaker 5:  things. And that ends up actually seeming more impressive

1047
01:05:24,665 --> 01:05:28,645
Speaker 5:  in a lot of cases because it's like, oh, this is this imperfect thing

1048
01:05:28,645 --> 01:05:32,565
Speaker 5:  that you are interacting with, but you understand how to bend it to your

1049
01:05:32,565 --> 01:05:36,405
Speaker 5:  will. And it's like, if this AI stuff is gonna work, that's the bar for

1050
01:05:36,405 --> 01:05:37,925
Speaker 5:  all of us. We all have

1051
01:08:59,505 --> 01:09:03,285
Speaker 5:  I'm sure Facebook is gonna sell me ads based on what we've been talking about

1052
01:09:03,285 --> 01:09:06,445
Speaker 5:  here. But let's, let's just run through some stuff. There's actually like

1053
01:09:06,445 --> 01:09:09,205
Speaker 5:  a surprising amount of news this week, so we're gonna try to plow through

1054
01:09:09,205 --> 01:09:12,445
Speaker 5:  a bunch of it as quickly as we can. Richard, why don't you go first? What

1055
01:09:12,445 --> 01:09:12,645
Speaker 5:  do you have

1056
01:09:13,945 --> 01:09:17,565
Speaker 11:  Reddit, if we haven't talked about enough AI already, let's talk about what

1057
01:09:17,565 --> 01:09:21,365
Speaker 11:  really powers ai. You posters people who post on the internet

1058
01:09:21,365 --> 01:09:24,845
Speaker 11:  who say have their opinions about things. Something that, And I, And I think

1059
01:09:24,845 --> 01:09:27,885
Speaker 11:  Josh Je had had an article that we published a while ago about how

1060
01:09:28,745 --> 01:09:32,445
Speaker 11:  humans really power these AI tools that you see. And

1061
01:09:32,625 --> 01:09:35,725
Speaker 11:  Reddit has been profiting from that. They have a deal with Google that they've

1062
01:09:35,725 --> 01:09:38,445
Speaker 11:  had for a while and Bloomberg reported this week that they're trying to

1063
01:09:38,565 --> 01:09:42,485
Speaker 11:  renegotiate. And part of it seems to be that they want not only to

1064
01:09:42,485 --> 01:09:46,085
Speaker 11:  provide results and data for Google and other companies to

1065
01:09:46,275 --> 01:09:49,965
Speaker 11:  process, to use for, for ai, for AI training, but

1066
01:09:49,995 --> 01:09:53,965
Speaker 11:  also for Google and whoever else to do things that feed back

1067
01:09:53,995 --> 01:09:57,765
Speaker 11:  into making people post on Reddit more, which would improve those

1068
01:09:57,765 --> 01:10:01,245
Speaker 11:  tools because they would've more data to be sourced from. And you kind of

1069
01:10:01,245 --> 01:10:04,915
Speaker 11:  see how there's this very interesting thing where we think about how

1070
01:10:05,085 --> 01:10:08,555
Speaker 11:  generative AI works and oh, it's just these computers doing things, but

1071
01:10:08,555 --> 01:10:12,515
Speaker 11:  really it's people, and in this case it's posters. We, we broke down

1072
01:10:13,215 --> 01:10:16,755
Speaker 11:  the type of guy who posts and you sir are very

1073
01:10:17,075 --> 01:10:17,235
Speaker 11:  valuable.

1074
01:10:18,865 --> 01:10:21,995
Speaker 5:  This is, to me it's like this is just Reddit saying the quiet part loud,

1075
01:10:21,995 --> 01:10:25,675
Speaker 5:  right? Which is like, we made this deal with Google.

1076
01:10:26,335 --> 01:10:29,515
Speaker 5:  The the open web is, is just falling into complete chaos.

1077
01:10:30,125 --> 01:10:33,715
Speaker 5:  There are no good websites left except The Verge dot com subscribe to The

1078
01:10:33,795 --> 01:10:37,195
Speaker 5:  Verge. And without

1079
01:10:37,495 --> 01:10:41,395
Speaker 5:  Reddit results, Google is effectively useless, which is more and more true

1080
01:10:41,805 --> 01:10:45,795
Speaker 5:  every single day. Like it, it is, at least in my own day-to-day

1081
01:10:45,795 --> 01:10:49,755
Speaker 5:  experience, it is wild how often I

1082
01:10:49,755 --> 01:10:52,955
Speaker 5:  end up on Reddit after doing a Google search. Like more and more all the

1083
01:10:52,955 --> 01:10:55,355
Speaker 5:  time. It feels like that's where people land. And so Reddit is like, okay,

1084
01:10:55,355 --> 01:10:59,075
Speaker 5:  well you've now hitched your wagon to us because we're the only thing left

1085
01:10:59,075 --> 01:10:59,435
Speaker 5:  on the web

1086
01:11:01,015 --> 01:11:04,875
Speaker 5:  payout. Like this is, this is how, this is how you make it

1087
01:11:04,875 --> 01:11:07,635
Speaker 5:  more valuable for all of us. You're gonna give us, you're gonna give us money

1088
01:11:07,635 --> 01:11:10,355
Speaker 5:  and you're gonna give us users and in exchange we're gonna keep this whole

1089
01:11:10,355 --> 01:11:14,245
Speaker 5:  flywheel going for you. And I wonder if Google

1090
01:11:14,385 --> 01:11:17,485
Speaker 5:  is already starting to regret the extent to which it is

1091
01:11:18,235 --> 01:11:21,925
Speaker 5:  relying on Reddit because it's actually Google specifically

1092
01:11:22,385 --> 01:11:26,045
Speaker 5:  is making Reddit very, very, very powerful. And I think that's so

1093
01:11:26,405 --> 01:11:30,005
Speaker 5:  fascinating. And this company that could for years couldn't figure out how

1094
01:11:30,005 --> 01:11:33,685
Speaker 5:  to be effectively run or rub two nickels together is all of a sudden

1095
01:11:33,715 --> 01:11:37,365
Speaker 5:  like the last bastion of the web. And

1096
01:11:37,625 --> 01:11:41,165
Speaker 5:  boy would I not have predicted this a couple of years ago, but it is now

1097
01:11:41,165 --> 01:11:43,925
Speaker 5:  and now it's in a position where like Reddit's really powerful because you're

1098
01:11:43,925 --> 01:11:47,485
Speaker 5:  right Richard, like it is, it is the most valuable

1099
01:11:47,855 --> 01:11:51,645
Speaker 5:  consistent resource of humans on the internet

1100
01:11:51,645 --> 01:11:54,965
Speaker 5:  right now for so, so many different things. Yeah. And

1101
01:11:54,965 --> 01:11:57,565
Speaker 11:  Part of the reason why it's so valuable and so consistent is because it's

1102
01:11:57,565 --> 01:12:01,245
Speaker 11:  moderated and so many other areas aren't. Yeah. But that's really the difference.

1103
01:12:01,505 --> 01:12:04,365
Speaker 5:  And because Reddit is willing to then structure and sell all of the data,

1104
01:12:04,725 --> 01:12:08,485
Speaker 5:  which is like, and that's, that's the flywheel and, And I think it seems

1105
01:12:08,725 --> 01:12:12,565
Speaker 5:  to have decided that it's fine and users will not

1106
01:12:12,805 --> 01:12:16,605
Speaker 5:  revolt and it will be okay and now it's just gonna,

1107
01:12:16,635 --> 01:12:18,245
Speaker 5:  it's just gonna milk that for all it's worth.

1108
01:12:18,395 --> 01:12:21,965
Speaker 12:  This is such a power play from Reddit. Like we talked about this last week,

1109
01:12:22,015 --> 01:12:25,925
Speaker 12:  right? Like every change they're making is is built around the

1110
01:12:25,925 --> 01:12:29,765
Speaker 12:  fact that they know at this moment in time, they have a huge

1111
01:12:29,825 --> 01:12:33,645
Speaker 12:  influx of traffic from Google and they have the leverage, they have

1112
01:12:33,645 --> 01:12:37,365
Speaker 12:  no idea how long it's gonna last, right? And so as they're going back,

1113
01:12:37,365 --> 01:12:40,885
Speaker 12:  they're just being really blunt about it. Give us our users,

1114
01:12:41,365 --> 01:12:44,845
Speaker 12:  right? Because they know long term this deal may maybe doesn't work out

1115
01:12:44,845 --> 01:12:48,565
Speaker 12:  for them, but right now Reddit just is Google

1116
01:12:48,585 --> 01:12:52,005
Speaker 12:  search. Google is just giving you Reddit results, which is

1117
01:12:53,115 --> 01:12:54,085
Speaker 12:  bewildering. But

1118
01:12:55,675 --> 01:12:59,045
Speaker 12:  yeah, this makes complete sense. Like they're just trying to move Google's

1119
01:12:59,045 --> 01:13:02,645
Speaker 12:  users over to being their users before Google takes cuts that fire hose

1120
01:13:02,645 --> 01:13:06,165
Speaker 5:  Off. Well, and you would think, and we talked a little bit about this last

1121
01:13:06,165 --> 01:13:10,005
Speaker 5:  week too, so we shouldn't spend too long on it, but the, there's

1122
01:13:10,005 --> 01:13:12,885
Speaker 5:  one way to look at this that is like Reddit is in this incredibly precarious

1123
01:13:13,085 --> 01:13:17,045
Speaker 5:  position, right? Because as soon as Google turns down the algorithm,

1124
01:13:17,215 --> 01:13:20,165
Speaker 5:  it'll, it'll die, right? So there's like, is a, is Reddit trying to like

1125
01:13:20,665 --> 01:13:24,165
Speaker 5:  get while the Gettin's good, but then the reporting we've been reading particularly

1126
01:13:24,165 --> 01:13:26,605
Speaker 5:  from Bloomberg, suggests that actually Reddit is trying to get a lot more

1127
01:13:26,605 --> 01:13:30,405
Speaker 5:  money out of Google, which, which really makes

1128
01:13:30,425 --> 01:13:34,375
Speaker 5:  it seem like Reddit knows Google has nowhere

1129
01:13:34,375 --> 01:13:38,015
Speaker 5:  else to go. Like, yeah, it, it is genuinely possible

1130
01:13:38,485 --> 01:13:41,855
Speaker 5:  that Reddit is the last thing, keeping plain

1131
01:13:42,165 --> 01:13:46,015
Speaker 5:  vanilla Google search from being useless for lots and lots of things because

1132
01:13:46,075 --> 01:13:49,935
Speaker 5:  it it, it's being totally overrun by AI slop and nonsense.

1133
01:13:50,475 --> 01:13:54,255
Speaker 5:  And so, so for Reddit to come in and say not just like, we need

1134
01:13:54,535 --> 01:13:56,935
Speaker 5:  guarantees that you're gonna keep sending us traffic, but we want more money

1135
01:13:57,595 --> 01:14:01,095
Speaker 5:  is such an interesting, like, inversion of power from the way that

1136
01:14:01,435 --> 01:14:04,775
Speaker 5:  any other website that relies on Google for traffic is able to negotiate

1137
01:14:04,775 --> 01:14:08,765
Speaker 5:  with Google. It's just nuts. Alright, Jake, you're up. What do you got?

1138
01:14:09,115 --> 01:14:12,060
Speaker 12:  Okay, this has been going on for a while. We're finally coming to the end

1139
01:14:12,060 --> 01:14:16,005
Speaker 12:  of the saga. Allegedly the US and China may finally have come to a

1140
01:14:16,005 --> 01:14:19,805
Speaker 12:  deal on TikTok. TikTok was supposed to get banned earlier this year.

1141
01:14:19,805 --> 01:14:21,485
Speaker 12:  There's like a federal law about this.

1142
01:14:23,705 --> 01:14:27,405
Speaker 12:  The, the, I don't know what is held it up. I do not know exactly what the

1143
01:14:27,405 --> 01:14:28,005
Speaker 12:  problem is.

1144
01:14:28,185 --> 01:14:32,165
Speaker 5:  Yes, you do. Yeah, I corruption and chaos. Like we, we can just say

1145
01:14:32,165 --> 01:14:33,685
Speaker 5:  what it is. Yeah. Like that

1146
01:14:34,675 --> 01:14:38,205
Speaker 12:  That is, that is correct. So apparently maybe

1147
01:14:38,645 --> 01:14:42,085
Speaker 12:  possibly this week or this month or soon, who really knows where these things,

1148
01:14:42,795 --> 01:14:45,685
Speaker 12:  there's some forward motion, it sounds like they have buyers, da da da da.

1149
01:14:45,745 --> 01:14:48,245
Speaker 12:  The thing that has interesting to me, and this has been coming out with

1150
01:14:48,245 --> 01:14:52,085
Speaker 12:  the past like several weeks or maybe months, but there's apparently

1151
01:14:52,085 --> 01:14:55,885
Speaker 12:  still a point of the current deal is that

1152
01:14:56,385 --> 01:15:00,365
Speaker 12:  TikTok has built a new version of its app just for the

1153
01:15:00,425 --> 01:15:04,325
Speaker 12:  US and once this deal goes through, everyone in the US is going to have

1154
01:15:04,325 --> 01:15:07,985
Speaker 12:  to stop using the current version of TikTok and go download this new version

1155
01:15:07,985 --> 01:15:11,905
Speaker 12:  of TikTok. And I amm curious if you guys think that that

1156
01:15:11,905 --> 01:15:15,065
Speaker 12:  is going to be a disaster for them or if everybody just gonna be like, okay,

1157
01:15:15,125 --> 01:15:18,385
Speaker 12:  new TikTok, whatever, like that seems that's a lot to ask of people.

1158
01:15:19,065 --> 01:15:22,225
Speaker 5:  I think disaster. I think like on the one hand,

1159
01:15:23,045 --> 01:15:26,905
Speaker 5:  my general belief is that most

1160
01:15:26,905 --> 01:15:28,305
Speaker 5:  people don't wanna download apps.

1161
01:15:29,825 --> 01:15:33,425
Speaker 5:  I also think TikTok is very important to society Yeah.

1162
01:15:33,765 --> 01:15:37,585
Speaker 5:  At this moment in time. So like if, if anybody could bully

1163
01:15:37,705 --> 01:15:40,385
Speaker 5:  a hundred million people into downloading an apple on the same day, it's

1164
01:15:40,585 --> 01:15:41,145
Speaker 5:  probably TikTok,

1165
01:15:42,965 --> 01:15:45,785
Speaker 5:  but the, it just feels like

1166
01:15:46,965 --> 01:15:50,845
Speaker 5:  a mess. Like it, there's just no way this

1167
01:15:50,845 --> 01:15:54,805
Speaker 5:  transition goes any kind of smoothly. The report

1168
01:15:54,805 --> 01:15:58,325
Speaker 5:  has been that basically Andreessen Horowitz, silver Lake and

1169
01:15:58,665 --> 01:16:01,685
Speaker 5:  Oracle are gonna be the major owners, which is like it's own

1170
01:16:02,795 --> 01:16:06,685
Speaker 5:  mess. And like what's less cool than Oracle owning

1171
01:16:06,685 --> 01:16:10,565
Speaker 5:  TikTok. Like I, I literally couldn't think of a less cool owner for

1172
01:16:10,585 --> 01:16:14,525
Speaker 5:  TikTok in the United States. But yeah, to me it's the new app

1173
01:16:14,525 --> 01:16:18,245
Speaker 5:  thing is like if anybody can do it is it's TikTok, but I kind of doubt

1174
01:16:18,245 --> 01:16:19,005
Speaker 5:  anybody can do it

1175
01:16:19,355 --> 01:16:23,285
Speaker 11:  Well to, so your last point David, I wonder if one, one of the questions

1176
01:16:23,285 --> 01:16:27,165
Speaker 11:  I have is who do you trust less with your data? The Chinese government or

1177
01:16:27,495 --> 01:16:31,365
Speaker 11:  Larry Ellison and Anderson Horowitz. And I'm not sure

1178
01:16:31,365 --> 01:16:34,805
Speaker 11:  what the answer to that question is. Terrific. It's kind of where, where

1179
01:16:34,805 --> 01:16:38,285
Speaker 11:  we are, but I I I think they might be able to pull it off

1180
01:16:39,165 --> 01:16:42,345
Speaker 11:  if they have enough support. Is it even gonna be noticeable? Like is it

1181
01:16:42,345 --> 01:16:46,265
Speaker 11:  gonna be something where it just happens on your device, you had an app

1182
01:16:46,325 --> 01:16:49,425
Speaker 11:  and now it has been replaced in the app store by another app, you don't

1183
01:16:49,425 --> 01:16:53,185
Speaker 11:  even have to sign in again and you never know. Is it still good? Is the

1184
01:16:53,185 --> 01:16:57,025
Speaker 11:  algorithm suddenly putting some very political videos in your feed

1185
01:16:57,405 --> 01:17:01,385
Speaker 11:  all the time? Or is it the same as it was? I feel like now even sometimes,

1186
01:17:01,385 --> 01:17:05,185
Speaker 11:  like the TikTok algorithm can vary wildly from from se

1187
01:17:05,205 --> 01:17:08,985
Speaker 11:  one session to another. But if it's still the same TikTok and if it's

1188
01:17:09,130 --> 01:17:12,085
Speaker 11:  not too much of a lift, I mean this is the app where people were learning

1189
01:17:12,085 --> 01:17:15,245
Speaker 11:  Chinese and downloading red notes. So yeah, they need their TikTok.

1190
01:17:15,505 --> 01:17:19,045
Speaker 5:  That's real. Yeah, I mean we've seen a little bit of what it looks like when

1191
01:17:19,425 --> 01:17:23,165
Speaker 5:  you have to get to a new app to do TikTok things. I

1192
01:17:23,395 --> 01:17:27,245
Speaker 5:  deleted TikTok off my phone for the summer because I was like on leave

1193
01:17:27,445 --> 01:17:30,365
Speaker 5:  and just wanted fewer reasons to look at my phone. And what that actually

1194
01:17:30,365 --> 01:17:32,765
Speaker 5:  meant is I just ended up looking at YouTube shorts a lot all summer

1195
01:17:33,955 --> 01:17:37,365
Speaker 5:  YouTube shorts. Not good. Not good. Don't do that. It's

1196
01:17:37,365 --> 01:17:40,285
Speaker 11:  Amazing how something with 20 years of data on what videos I like is so

1197
01:17:40,285 --> 01:17:40,485
Speaker 11:  bad,

1198
01:17:41,005 --> 01:17:44,925
Speaker 5:  Right? I I feel the same way. It's like YouTube does

1199
01:17:45,065 --> 01:17:48,725
Speaker 5:  the thing that Instagram used to do that would always drive me crazy, where

1200
01:17:48,725 --> 01:17:52,005
Speaker 5:  it's like if you watch one short about something

1201
01:17:52,785 --> 01:17:56,005
Speaker 5:  and you watch it for like 45 seconds, something in the YouTube algorithm

1202
01:17:56,075 --> 01:17:59,935
Speaker 5:  goes, oh, that's the stuff. And then it shows me 600

1203
01:18:00,005 --> 01:18:03,855
Speaker 5:  consecutive videos of that thing again until I'm like, I

1204
01:18:03,855 --> 01:18:07,575
Speaker 5:  never wanna see this again as long as I live. And now the whole

1205
01:18:07,575 --> 01:18:10,095
Speaker 5:  shorts algorithm has been ruined for me because there's no way to start over,

1206
01:18:10,145 --> 01:18:13,815
Speaker 5:  which is like the thing that TikTok has gotten so good at is the way that

1207
01:18:13,815 --> 01:18:17,775
Speaker 5:  it, it it explores and it bounces around and it changes and it moves. Like

1208
01:18:19,225 --> 01:18:23,065
Speaker 5:  I, there is something still different about what TikTok is

1209
01:18:23,385 --> 01:18:26,825
Speaker 5:  doing that no, even all the ones that ever tried to copy it have not

1210
01:18:26,825 --> 01:18:29,825
Speaker 5:  successfully copied it. So we'll see. I just wanna say before we move on,

1211
01:18:29,865 --> 01:18:32,945
Speaker 5:  I call bullshit on all of this. I don't think any of this is real. I don't

1212
01:18:32,945 --> 01:18:35,505
Speaker 5:  think the deal's gonna happen. I don't think TikTok is gonna get banned.

1213
01:18:35,545 --> 01:18:38,585
Speaker 5:  I think we are just going to live in this limbo state forever. If I'm wrong,

1214
01:18:38,585 --> 01:18:41,825
Speaker 5:  please play me this clip of me being wrong because I will be thrilled to

1215
01:18:41,825 --> 01:18:45,425
Speaker 5:  never talk about this again. But I think all of this is nonsense.

1216
01:18:45,785 --> 01:18:47,065
Speaker 12:  I think that's a reasonable prediction.

1217
01:18:47,535 --> 01:18:50,985
Speaker 5:  Yeah. Alright, I have, I have two that we're gonna just talk about very quickly.

1218
01:18:51,245 --> 01:18:54,985
Speaker 5:  One is I would just briefly like to yell at Qualcomm

1219
01:18:56,045 --> 01:18:59,585
Speaker 5:  for its name Crime of the Week, which is that it took

1220
01:19:00,045 --> 01:19:02,625
Speaker 5:  the Snapdragon eight Elite

1221
01:19:04,105 --> 01:19:07,405
Speaker 5:  and updated it to the Snapdragon eight Elite Gen five.

1222
01:19:08,755 --> 01:19:11,215
Speaker 5:  And if you're saying, David, what about gens two, three and four?

1223
01:19:12,975 --> 01:19:16,255
Speaker 5:  I don't know. They, they don't exist. And here is

1224
01:19:16,535 --> 01:19:20,495
Speaker 5:  Qualcomm's blog post explaining this stupid naming decision. It says it might

1225
01:19:20,735 --> 01:19:23,655
Speaker 5:  look like we skip generations, but the truth is simpler and more powerful.

1226
01:19:24,065 --> 01:19:27,415
Speaker 5:  Snapdragon eight Elite Gen five marks the fifth generation of our premium

1227
01:19:27,425 --> 01:19:30,535
Speaker 5:  eight series platform since we introduced our new single digit naming and

1228
01:19:30,535 --> 01:19:33,775
Speaker 5:  visual identity. So while the naming may look new, it's actually a continuation

1229
01:19:33,775 --> 01:19:37,375
Speaker 5:  of our established framework that says nothing means nothing. And

1230
01:19:37,645 --> 01:19:39,295
Speaker 5:  this is a bad name. I

1231
01:19:39,295 --> 01:19:42,935
Speaker 12:  Don't understand. Every couple of years they have to just like fully change

1232
01:19:42,935 --> 01:19:45,775
Speaker 12:  up the naming scheme and the thing, I'm not saying their earlier naming

1233
01:19:45,775 --> 01:19:49,695
Speaker 12:  scheme was good, it was like only tech obsessives could

1234
01:19:49,695 --> 01:19:53,295
Speaker 12:  follow what what what it was 800. It was 800

1235
01:19:53,295 --> 01:19:57,135
Speaker 12:  series. I don't know what numbers they were at, but they incremented them.

1236
01:19:57,195 --> 01:20:01,095
Speaker 12:  It was fine. I could say the eight whatever was higher than the eight other

1237
01:20:01,095 --> 01:20:04,495
Speaker 12:  thing. Now I don't know what they're doing, they're just adding more words.

1238
01:20:05,035 --> 01:20:08,685
Speaker 5:  So just, I just wanna read you the, the names in order. Okay. There was the

1239
01:20:08,685 --> 01:20:12,445
Speaker 5:  Snapdragon eight gen one, Snapdragon eight, gen two, Snapdragon eight,

1240
01:20:12,505 --> 01:20:16,485
Speaker 5:  gen three, Snapdragon eight Elite, and Snapdragon eight Elite

1241
01:20:16,585 --> 01:20:17,805
Speaker 5:  Gen five. Good.

1242
01:20:17,805 --> 01:20:21,725
Speaker 12:  Good. Very good. Well well done marketing team. I'm glad you

1243
01:20:21,725 --> 01:20:22,605
Speaker 12:  were all earning salaries.

1244
01:20:22,845 --> 01:20:26,485
Speaker 5:  You're all fired. The next thing is a brief follow up to last week

1245
01:20:27,185 --> 01:20:31,125
Speaker 5:  we, we had seen some info on the new nothing year three

1246
01:20:31,395 --> 01:20:35,045
Speaker 5:  earbuds. We got the full reveal this week and as it turns out, we

1247
01:20:35,155 --> 01:20:39,085
Speaker 5:  predicted what the talk button on the side of the charging case was

1248
01:20:39,085 --> 01:20:42,685
Speaker 5:  gonna be. Almost exactly. It is primarily meant to be

1249
01:20:43,515 --> 01:20:46,525
Speaker 5:  used when you have your headphones paired to your phone and it's essentially

1250
01:20:46,525 --> 01:20:49,885
Speaker 5:  just an external microphone. You can hold it to your mouth to make phone

1251
01:20:49,885 --> 01:20:53,645
Speaker 5:  calls, which should sound better. You can do voice notes, you can do memos

1252
01:20:53,835 --> 01:20:57,645
Speaker 5:  into the essential space AI app, which we also predicted like we,

1253
01:20:57,705 --> 01:21:01,525
Speaker 5:  we crushed it. And I just think good job. Us. I also think this is a very

1254
01:21:01,925 --> 01:21:05,645
Speaker 5:  good idea that this idea, I, I had this thought

1255
01:21:05,915 --> 01:21:09,885
Speaker 5:  when I saw somebody out the other day EarPods in or AirPods

1256
01:21:09,885 --> 01:21:13,725
Speaker 5:  in holding their phone up to their mouth, talking into their

1257
01:21:13,725 --> 01:21:17,325
Speaker 5:  phone. And I had the unbelievable urge to be like, that's not how it works.

1258
01:21:19,395 --> 01:21:23,045
Speaker 5:  Your phone is accomplishing nothing with you holding it like this right now.

1259
01:21:23,985 --> 01:21:27,965
Speaker 5:  But it is true that when you have a microphone closer to your mouth,

1260
01:21:27,985 --> 01:21:31,045
Speaker 5:  it is going to sound better. Like one way to sound better on a phone call

1261
01:21:31,045 --> 01:21:34,925
Speaker 5:  is to put the microphone closer to your mouth and something like this,

1262
01:21:35,035 --> 01:21:38,685
Speaker 5:  when, when you want to sound good, whether you're like on a

1263
01:21:38,835 --> 01:21:42,605
Speaker 5:  Zoom call out in the world or you're making content or

1264
01:21:42,885 --> 01:21:46,805
Speaker 5:  whatever, having a a thing that is like attached to the device that you're

1265
01:21:46,805 --> 01:21:50,685
Speaker 5:  already using that is just a sort of always on immediate external

1266
01:21:50,685 --> 01:21:54,365
Speaker 5:  microphone, I think is very clever And I think people will use this. So kudos

1267
01:21:54,365 --> 01:21:57,965
Speaker 5:  to nothing and also to us for getting it exactly right. I second that,

1268
01:22:00,075 --> 01:22:01,405
Speaker 5:  Richard, what's your second one?

1269
01:22:01,585 --> 01:22:05,445
Speaker 11:  My second one, yes. YouTube this week they had their big made

1270
01:22:05,445 --> 01:22:07,885
Speaker 11:  on YouTube event that they have pretty much every year, but for this time

1271
01:22:07,995 --> 01:22:11,205
Speaker 11:  it's been 20 years. They were talking about the next 20 years and one of

1272
01:22:11,205 --> 01:22:13,285
Speaker 11:  the things they were talking about is what might actually get the lightning

1273
01:22:13,285 --> 01:22:17,205
Speaker 11:  round to sponsor. If we get a sponsor later, we can use AI to

1274
01:22:17,205 --> 01:22:21,125
Speaker 11:  dynamically insert the ads. So it'll just, oh my suddenly appear with

1275
01:22:21,125 --> 01:22:23,845
Speaker 11:  new ads. And I, and it's one of those things that's a little change, but

1276
01:22:23,845 --> 01:22:26,685
Speaker 11:  also kind of changes things in a big way because we've seen how creators

1277
01:22:26,685 --> 01:22:30,165
Speaker 11:  have gotten used to saying, oh, and my sponsor for this video is blah, blah,

1278
01:22:30,165 --> 01:22:33,605
Speaker 11:  blah, blah. But they don't have to do that if they can just change it

1279
01:22:34,355 --> 01:22:38,085
Speaker 11:  like next week or next year when they get a different sponsor. And the way

1280
01:22:38,085 --> 01:22:41,925
Speaker 11:  that you make money on YouTube is getting some pretty big revamps the way

1281
01:22:41,925 --> 01:22:45,445
Speaker 11:  that people use AI to do different things on YouTube to

1282
01:22:45,745 --> 01:22:48,845
Speaker 11:  enable shopping. But one of the things that it seems like is that YouTube

1283
01:22:49,505 --> 01:22:53,205
Speaker 11:  is in a, a pretty significant way becoming a shopping

1284
01:22:53,205 --> 01:22:53,525
Speaker 11:  channel.

1285
01:22:54,025 --> 01:22:57,685
Speaker 5:  Yes. This seems to be every video platform's

1286
01:22:57,915 --> 01:23:01,405
Speaker 5:  best idea about how to make money is like, what if we just let you buy the

1287
01:23:01,405 --> 01:23:05,125
Speaker 5:  products shown on screen and, and I'm, I'm not saying that's a, a

1288
01:23:05,425 --> 01:23:09,405
Speaker 5:  bad idea or the wrong one or won't work, it's just the only idea

1289
01:23:09,435 --> 01:23:13,365
Speaker 5:  anybody has is like ads and also click

1290
01:23:13,385 --> 01:23:17,245
Speaker 5:  to buy the cool wraparound sunglasses that somebody is

1291
01:23:17,245 --> 01:23:21,045
Speaker 5:  wearing. Like that's it. That's all, that's all we're doing here. But I agree

1292
01:23:21,045 --> 01:23:24,925
Speaker 5:  with you that I think the dynamic ads thing is a big deal. It's

1293
01:23:24,925 --> 01:23:28,365
Speaker 5:  gonna mean a lot of deals shift

1294
01:23:28,745 --> 01:23:32,605
Speaker 5:  for creators away from like basically

1295
01:23:32,825 --> 01:23:36,485
Speaker 5:  making sponsored videos to like, if you can get to the point where you just

1296
01:23:36,485 --> 01:23:39,845
Speaker 5:  make a lot of videos that get a lot of views, that's gonna be much easier

1297
01:23:39,845 --> 01:23:41,925
Speaker 5:  to monetize than it has been in the past. Or if

1298
01:23:42,165 --> 01:23:44,925
Speaker 11:  You have an old video that suddenly becomes popular now you can sell a new

1299
01:23:44,925 --> 01:23:45,805
Speaker 11:  sponsorship on it,

1300
01:23:45,855 --> 01:23:48,365
Speaker 5:  Right? And you're gonna, yeah, you're gonna be able to make brand deals across

1301
01:23:48,365 --> 01:23:51,725
Speaker 5:  your whole channel all at once. And that's like, there's just a lot of ways

1302
01:23:51,745 --> 01:23:52,085
Speaker 5:  in which

1303
01:23:53,795 --> 01:23:57,685
Speaker 5:  YouTubers only get to make a specific kind of deal. And now this

1304
01:23:57,685 --> 01:24:01,605
Speaker 5:  is a different new kind of deal that I think might make

1305
01:24:01,805 --> 01:24:03,565
Speaker 5:  everyone's viewing experience much worse

1306
01:24:05,205 --> 01:24:08,685
Speaker 11:  Probably. But what we've seen from YouTubers is that they respond very quickly

1307
01:24:08,985 --> 01:24:12,605
Speaker 11:  And I think in, in maybe ways that we didn't expect to change in the way

1308
01:24:12,605 --> 01:24:16,085
Speaker 11:  that you make money. Why does everyone make 20 minute videos now? You know,

1309
01:24:16,245 --> 01:24:17,365
Speaker 11:  a lot of the different things that you see

1310
01:24:17,675 --> 01:24:18,605
Speaker 5:  Take it midrolls when

1311
01:24:18,605 --> 01:24:20,765
Speaker 11:  When the incentives change, they, their actions change.

1312
01:24:20,765 --> 01:24:24,645
Speaker 5:  Totally. And this is like yet another push from YouTube into just

1313
01:24:24,645 --> 01:24:28,205
Speaker 5:  being live television, right? Like there's a reason

1314
01:24:28,815 --> 01:24:32,725
Speaker 5:  every 30 minute comedy is structured the way that it is and it's because

1315
01:24:32,725 --> 01:24:36,405
Speaker 5:  of ad breaks and there's like every, everything is tuned

1316
01:24:36,585 --> 01:24:39,965
Speaker 5:  to, you know, every, every x number of minutes there's gonna be an ad break

1317
01:24:39,965 --> 01:24:42,365
Speaker 5:  and we don't have control of what's there. We don't, we're we're not sort

1318
01:24:42,365 --> 01:24:45,245
Speaker 5:  of seamlessly integrating it in, we just have to stop the thing. But make

1319
01:24:45,245 --> 01:24:48,285
Speaker 5:  sure you come back and, and like you said, I suspect we're gonna start to

1320
01:24:48,285 --> 01:24:52,125
Speaker 5:  get a lot of, like, there's gonna be cliffhangers six minutes into every

1321
01:24:52,125 --> 01:24:55,925
Speaker 5:  YouTube video so that you keep watching after like all of this stuff is

1322
01:24:55,925 --> 01:24:59,885
Speaker 5:  going to happen. And you're exactly right that the, the people

1323
01:25:00,065 --> 01:25:03,325
Speaker 5:  making this stuff have absorbed and

1324
01:25:03,875 --> 01:25:07,485
Speaker 5:  morphed to what the platform wants and especially how the platform

1325
01:25:07,555 --> 01:25:10,885
Speaker 5:  monetizes really fast. And so I think you're gonna start to see this super

1326
01:25:10,885 --> 01:25:14,525
Speaker 5:  quickly all over YouTube. Like the, the era of the

1327
01:25:14,685 --> 01:25:18,605
Speaker 5:  30 minute multi-camera comedy on YouTube legitimately

1328
01:25:18,605 --> 01:25:21,925
Speaker 5:  might have just begun. Like it's gonna be fascinating.

1329
01:25:23,315 --> 01:25:27,205
Speaker 5:  There's also a, a thing that you can do now with side by

1330
01:25:27,205 --> 01:25:31,125
Speaker 5:  side ads in live streams, which I hate in principle and

1331
01:25:31,275 --> 01:25:33,805
Speaker 5:  hope no one ever uses, but I'm confident that they will.

1332
01:25:35,265 --> 01:25:38,565
Speaker 5:  I'm gonna go next because Jake, I want you to go last. Okay, my next one

1333
01:25:38,705 --> 01:25:42,005
Speaker 5:  is a fascinating bit of weird

1334
01:25:42,915 --> 01:25:46,245
Speaker 5:  chip machinations, which is that Nvidia just invested

1335
01:25:46,275 --> 01:25:50,205
Speaker 5:  $5 billion into Intel essentially just by

1336
01:25:50,205 --> 01:25:53,525
Speaker 5:  buying a bunch of Intel stock, but they have a plan between the two companies

1337
01:25:53,545 --> 01:25:57,485
Speaker 5:  to jointly develop chips both for PCs

1338
01:25:57,485 --> 01:26:01,445
Speaker 5:  and for data centers using a lot of NVIDIA's technology. So I think

1339
01:26:01,445 --> 01:26:05,205
Speaker 5:  the, the idea is essentially like Intel CPU,

1340
01:26:05,785 --> 01:26:08,685
Speaker 5:  Nvidia, GPU in chips together.

1341
01:26:10,195 --> 01:26:13,925
Speaker 5:  It's weird times for both of these companies. Intel

1342
01:26:14,515 --> 01:26:18,485
Speaker 5:  just sold part of itself to the government and part of it itself to

1343
01:26:18,645 --> 01:26:22,165
Speaker 5:  SoftBank, Nvidia made weird revenue

1344
01:26:22,165 --> 01:26:25,205
Speaker 5:  sharing deals with the government. Like all these companies are just like

1345
01:26:25,235 --> 01:26:28,205
Speaker 5:  tied up with each other in really bizarre ways.

1346
01:26:29,225 --> 01:26:32,965
Speaker 5:  But there's just a fascinating thing here where like I think Richard, you're,

1347
01:26:32,985 --> 01:26:36,845
Speaker 5:  you're more, I would say up on the PC chip game

1348
01:26:36,845 --> 01:26:40,365
Speaker 5:  than I am, but my impression recently has been that a MD

1349
01:26:40,945 --> 01:26:44,925
Speaker 5:  is like a real threat in the mirror of both Intel and Nvidia.

1350
01:26:45,425 --> 01:26:49,365
Speaker 5:  And this is a way for them to combine, to try and push back.

1351
01:26:49,425 --> 01:26:50,685
Speaker 5:  Is that, is that a fair way to look at

1352
01:26:50,685 --> 01:26:53,805
Speaker 11:  This? I think it really is. It's, it's something where Intel has been behind

1353
01:26:53,825 --> 01:26:57,485
Speaker 11:  and Nvidia has at least in certain ways been ahead, but by combining,

1354
01:26:57,595 --> 01:27:01,125
Speaker 11:  they do some of the things that a MD has been doing where they, they can

1355
01:27:01,125 --> 01:27:04,805
Speaker 11:  do both the CPU and the GPU side of it that is so crucial to these

1356
01:27:04,905 --> 01:27:08,725
Speaker 11:  AI applications and, and having that, that integration

1357
01:27:08,785 --> 01:27:11,845
Speaker 11:  and also kind of on a personal computing level, gaming,

1358
01:27:13,025 --> 01:27:16,365
Speaker 11:  if you can have a system where you're buying suddenly an Nvidia

1359
01:27:17,185 --> 01:27:21,085
Speaker 11:  GPU slash GPU that's quite different than what we've seen before

1360
01:27:21,425 --> 01:27:23,725
Speaker 5:  And feels like, I mean, again, we'll we'll have to see how this actually

1361
01:27:23,725 --> 01:27:26,525
Speaker 5:  nets out, but the idea of being able to buy like Nvidia integrated graphics

1362
01:27:26,745 --> 01:27:30,325
Speaker 5:  in your, your high-end laptop seems like potentially a very exciting

1363
01:27:30,635 --> 01:27:34,205
Speaker 5:  idea. Yeah. Also, poor intel is just like this

1364
01:27:34,605 --> 01:27:38,205
Speaker 5:  pathetic little company that no one wants to let die, but maybe you should

1365
01:27:38,205 --> 01:27:41,845
Speaker 5:  just die and ev like if this company

1366
01:27:41,855 --> 01:27:45,325
Speaker 5:  can't figure out how to turn it around now with the, the support of

1367
01:27:45,795 --> 01:27:49,685
Speaker 5:  everybody trying to keep it alive no matter what the cost,

1368
01:27:50,685 --> 01:27:51,965
Speaker 5:  I don't know. I don't know what we do here.

1369
01:27:52,315 --> 01:27:56,285
Speaker 12:  This does feel related to that, right? Like one of the problems Intel and

1370
01:27:56,305 --> 01:28:00,125
Speaker 12:  its foundries have had is customers are like, I dunno if you're gonna

1371
01:28:00,125 --> 01:28:04,045
Speaker 12:  be here, like should I make a deal with you if you, and you

1372
01:28:04,045 --> 01:28:07,965
Speaker 12:  know, I say what you will about the, the US government

1373
01:28:07,965 --> 01:28:11,925
Speaker 12:  taking a stake in it for money that Intel was already being given,

1374
01:28:13,465 --> 01:28:17,445
Speaker 12:  but some of that was meant to I think send a signal like, hey Intel,

1375
01:28:17,555 --> 01:28:21,325
Speaker 12:  they're gonna be here. And I think Nvidia doing the same thing

1376
01:28:21,345 --> 01:28:25,285
Speaker 12:  is kind of in the same ballpark, right? Nvidia is saying like,

1377
01:28:25,285 --> 01:28:27,805
Speaker 12:  Hey, we have some faith in Intel. Not only do we have faith in Intel, we

1378
01:28:27,805 --> 01:28:31,525
Speaker 12:  have skin in the game now. So thi this is like, feels

1379
01:28:31,525 --> 01:28:35,085
Speaker 12:  pretty meaningful for Intel in terms of their ability to turn around. They

1380
01:28:35,085 --> 01:28:38,405
Speaker 12:  still have to do it, they still have to do the thing and make good products,

1381
01:28:38,405 --> 01:28:40,885
Speaker 12:  which apparently has been a challenge for them. Yeah,

1382
01:28:41,275 --> 01:28:41,565
Speaker 5:  It's

1383
01:28:41,565 --> 01:28:45,245
Speaker 12:  Hard work, but they just got a bunch of money and they've got,

1384
01:28:45,665 --> 01:28:49,485
Speaker 12:  you know, NVIDIA's expertise so that, that certainly, certainly would,

1385
01:28:49,485 --> 01:28:50,045
Speaker 12:  should help.

1386
01:28:50,275 --> 01:28:53,565
Speaker 5:  Yeah, it was funny. There was like a huge stock rally after this because

1387
01:28:53,595 --> 01:28:57,565
Speaker 5:  like just rubbing elbows with Nvidia instantly makes

1388
01:28:57,565 --> 01:29:01,485
Speaker 5:  your company exciting to a lot of people. Like this one's gonna be fascinating

1389
01:29:01,485 --> 01:29:05,325
Speaker 5:  to watch shakeout Jake end us with some

1390
01:29:05,615 --> 01:29:07,005
Speaker 5:  sheer abject rage.

1391
01:29:07,275 --> 01:29:10,765
Speaker 12:  Yeah, I mean I know you guys are always saying like, man, the screen on

1392
01:29:10,765 --> 01:29:13,925
Speaker 12:  my refrigerator is not big enough. The, the screen on my refrigerator is

1393
01:29:13,925 --> 01:29:17,485
Speaker 12:  one of the most valuable useful screens in my house. I wish you could do

1394
01:29:17,515 --> 01:29:21,325
Speaker 12:  more things. I love gaming on it. I love being productive on it.

1395
01:29:22,275 --> 01:29:26,165
Speaker 12:  Samsung loves that screen too. And in good

1396
01:29:26,165 --> 01:29:29,205
Speaker 12:  news for everyone everywhere, but specifically in the US where this is happening,

1397
01:29:29,285 --> 01:29:33,085
Speaker 12:  there're now going to be advertisements displayed on the screen

1398
01:29:33,265 --> 01:29:36,635
Speaker 12:  of your Samsung Smart Fridge. Okay.

1399
01:29:37,235 --> 01:29:41,035
Speaker 12:  Like that how that, that's actually like I I'm like,

1400
01:29:41,035 --> 01:29:44,355
Speaker 12:  this is galling, this is like really bad, right? They sold you a product,

1401
01:29:44,625 --> 01:29:47,875
Speaker 12:  this is a product that lives in a major room of your house

1402
01:29:48,845 --> 01:29:52,185
Speaker 12:  and now they are changing the product. They sold you to put ads in your

1403
01:29:52,185 --> 01:29:55,705
Speaker 12:  face like this. This should not be allowed. Number one,

1404
01:29:56,095 --> 01:29:59,465
Speaker 12:  this is like a terrible product feature. Number two,

1405
01:30:00,335 --> 01:30:02,865
Speaker 12:  stop putting screens on fridges number three. That's all I got.

1406
01:30:03,865 --> 01:30:06,435
Speaker 5:  Okay. Allow me to make the other case. Oh

1407
01:30:06,465 --> 01:30:07,435
Speaker 12:  Alright, alright.

1408
01:30:07,495 --> 01:30:07,835
Speaker 5:  I'm just kidding.

1409
01:30:08,695 --> 01:30:12,275
Speaker 12:  No, not subsidize the fridge. Go the tele route. Ooh.

1410
01:30:12,825 --> 01:30:16,195
Speaker 12:  Zero cost fridge. But it's always showing advertisements.

1411
01:30:16,465 --> 01:30:19,195
Speaker 5:  It's always showing advertisements, but okay, here's how you do the advertisements

1412
01:30:19,195 --> 01:30:22,675
Speaker 5:  on my fridge. You make it, you you you use the camera on my Samsung fridge

1413
01:30:22,675 --> 01:30:26,395
Speaker 5:  to take a picture of the inside of my fridge. Yeah. And then you fill it

1414
01:30:26,785 --> 01:30:28,635
Speaker 5:  with sponsored products.

1415
01:30:28,735 --> 01:30:29,795
Speaker 12:  Oh my God. And you're

1416
01:30:29,795 --> 01:30:32,475
Speaker 5:  Like, wouldn't it be great if you had all this stuff in your fridge? Yeah,

1417
01:30:32,475 --> 01:30:36,035
Speaker 5:  yeah, yeah. And I can just be like, boop, boop boop, give me those and it

1418
01:30:36,035 --> 01:30:38,875
Speaker 5:  immediately instacarts them to my house that

1419
01:30:40,205 --> 01:30:40,815
Speaker 12:  Just fill it with

1420
01:30:40,815 --> 01:30:42,775
Speaker 5:  A perfect advertising scheme that I would fall prey

1421
01:30:42,775 --> 01:30:44,775
Speaker 12:  To prime energy drinks. Yeah.

1422
01:30:44,775 --> 01:30:48,735
Speaker 5:  You're just like, oh dope. I have some chocolate Haagen-Dazs in my freezer.

1423
01:30:48,795 --> 01:30:50,335
Speaker 5:  And it's like, no you don't, but you could

1424
01:30:51,285 --> 01:30:51,575
Speaker 12:  What

1425
01:30:52,165 --> 01:30:55,535
Speaker 5:  They would get me. But no, I think, I think this is a total disaster. And

1426
01:30:55,535 --> 01:30:57,175
Speaker 5:  I also think in April,

1427
01:30:58,835 --> 01:31:02,815
Speaker 5:  Jen Tuey asked Samsung executives if there were

1428
01:31:02,815 --> 01:31:06,695
Speaker 5:  going to be ads because like the smart person that she is, she

1429
01:31:06,695 --> 01:31:09,215
Speaker 5:  looked at an enormous screen and a prominent place in your house and said,

1430
01:31:09,215 --> 01:31:12,975
Speaker 5:  I bet they're gonna sell ads on that. And the quote

1431
01:31:13,085 --> 01:31:16,975
Speaker 5:  said they don't currently have ads and quote no plans

1432
01:31:16,975 --> 01:31:20,655
Speaker 5:  regarding the inclusion of advertisements on AI home screens, which we took

1433
01:31:20,805 --> 01:31:24,255
Speaker 5:  back then as like, oh thank goodness they're not gonna do ads. Now what I'm

1434
01:31:24,255 --> 01:31:27,495
Speaker 5:  hearing is we still haven't figured it out, but we're gonna do it for sure.

1435
01:31:28,275 --> 01:31:32,255
Speaker 5:  We just, we don't have our plan yet is what they meant. Plans

1436
01:31:32,255 --> 01:31:35,575
Speaker 5:  is not no correct, no plans is not no

1437
01:31:36,075 --> 01:31:38,735
Speaker 5:  is a useful, useful thing. This is like

1438
01:31:40,535 --> 01:31:44,225
Speaker 5:  genuinely like throw out your fridge and get a new one. Possibilities

1439
01:31:44,415 --> 01:31:47,985
Speaker 5:  here. If, if they're doing this ad in the wrong, like if you play an autoplay

1440
01:31:48,595 --> 01:31:52,305
Speaker 5:  video ad on my fridge screen, I'm just

1441
01:31:52,405 --> 01:31:56,065
Speaker 5:  un I like that thing is going either off of network or

1442
01:31:56,455 --> 01:32:00,325
Speaker 5:  into the for sale section of my Nextdoor app

1443
01:32:00,795 --> 01:32:01,365
Speaker 5:  very quickly.

1444
01:32:01,905 --> 01:32:05,165
Speaker 11:  You, you don't want going to the fridge for a snack to be like pumping gas

1445
01:32:05,345 --> 01:32:06,885
Speaker 11:  now that that's, that's not what you love.

1446
01:32:07,145 --> 01:32:09,925
Speaker 5:  Wow. So all the podcasts that I've been listening to recently have been

1447
01:32:10,885 --> 01:32:14,645
Speaker 5:  advertising for Jordan Peel's new movie, which is about

1448
01:32:15,245 --> 01:32:19,125
Speaker 5:  football players. And it's this very like creepy low voice.

1449
01:32:19,145 --> 01:32:22,045
Speaker 5:  He kind of sounds like Harrison Ford talking about. And I'm just imagining

1450
01:32:22,045 --> 01:32:24,605
Speaker 5:  every time I walk into my kitchen, it's like coming this fall,

1451
01:32:25,745 --> 01:32:25,965
Speaker 12:  I'm

1452
01:32:25,965 --> 01:32:28,445
Speaker 5:  Just like, I'm gonna, I'm gonna walk into my fridge at two o'clock in the

1453
01:32:28,445 --> 01:32:32,405
Speaker 5:  morning and there's just gonna be some scary person on my fridge to promote

1454
01:32:32,405 --> 01:32:34,965
Speaker 5:  Jordan Peel's new movie. And I'm gonna, I'm gonna throw my fridge through

1455
01:32:35,045 --> 01:32:38,905
Speaker 5:  a window. The end. This is the worst idea of all time.

1456
01:32:38,965 --> 01:32:42,905
Speaker 5:  And I hope Samsung just immediately walks it back because it

1457
01:32:42,905 --> 01:32:45,915
Speaker 5:  should. Jake, you're not mad enough about this.

1458
01:32:46,495 --> 01:32:50,355
Speaker 12:  You're, I I know I've, I've just been so pro fridge

1459
01:32:50,415 --> 01:32:54,235
Speaker 12:  ads just all this time. I'd be like, the money they're leaving

1460
01:32:54,235 --> 01:32:57,915
Speaker 12:  on the table, they put a screen in everybody's kitchen.

1461
01:32:59,805 --> 01:33:01,105
Speaker 12:  No. Yeah, they, this

1462
01:33:01,105 --> 01:33:02,705
Speaker 5:  Is, it's really on us for not seeing this coming.

1463
01:33:03,305 --> 01:33:07,065
Speaker 12:  I mean, I, to be clear, I don't think we've been all that pro

1464
01:33:07,725 --> 01:33:10,705
Speaker 12:  fridge screen. I know there are people out there, they have screens in their

1465
01:33:10,705 --> 01:33:14,465
Speaker 12:  fridges. I don't know how they got their, is anyone using them?

1466
01:33:14,765 --> 01:33:18,105
Speaker 12:  Are they, are they valuable to you? I don't have a, a screen on my fridge,

1467
01:33:18,685 --> 01:33:18,905
Speaker 12:  but

1468
01:33:20,805 --> 01:33:24,295
Speaker 12:  yeah, I think don't trust Samsung with that. I if

1469
01:33:24,715 --> 01:33:25,855
Speaker 12:  is the lesson. Yeah,

1470
01:33:26,005 --> 01:33:29,775
Speaker 5:  That said, if you work for telly and you decide to go ahead with your refrigerator,

1471
01:33:30,645 --> 01:33:34,615
Speaker 5:  Jake would like some credit. Alright, we have gone way over. There's

1472
01:33:34,615 --> 01:33:38,135
Speaker 5:  too much happening. If everybody could just stop for like a, like a minute

1473
01:33:38,275 --> 01:33:42,095
Speaker 5:  and not do all of your news in September, it'd be great. We would be very

1474
01:33:42,335 --> 01:33:45,575
Speaker 5:  grateful. There's more coming. By the way, there's a, an Amazon event scheduled

1475
01:33:45,575 --> 01:33:49,535
Speaker 5:  for September 30th. So in two weeks we think we're gonna see the next

1476
01:33:49,545 --> 01:33:53,375
Speaker 5:  generation of echo stuff now that Alexa plus exists and now that

1477
01:33:53,535 --> 01:33:57,015
Speaker 5:  Anos pane who used to run windows and hardware at Microsoft is running the

1478
01:33:57,015 --> 01:33:59,415
Speaker 5:  stuff over there. That should be interesting. There's some more Google stuff

1479
01:33:59,415 --> 01:34:02,975
Speaker 5:  coming. There's just a lot going on this fall. So we'll be here a lot, but

1480
01:34:02,975 --> 01:34:06,175
Speaker 5:  also if everybody could stop, that'd be great. But for now

1481
01:34:06,755 --> 01:34:09,375
Speaker 5:  we should get outta here. Richard, Jake, thank you for being here with me.

1482
01:34:09,375 --> 01:34:13,015
Speaker 5:  This was a delight. Mila is off doing. God only knows what. We'll see him

1483
01:34:13,605 --> 01:34:17,575
Speaker 5:  next time. There are speech crimes, so presumably very soon. If

1484
01:34:17,575 --> 01:34:20,135
Speaker 5:  you have questions about any of this or other things you want us to talk

1485
01:34:20,135 --> 01:34:22,935
Speaker 5:  about or feelings about whatever is going on in the world, you can always

1486
01:34:22,945 --> 01:34:26,735
Speaker 5:  email us at Vergecast at The Verge dot com. You can call us eight six six

1487
01:34:26,735 --> 01:34:30,575
Speaker 5:  Virgin one. One is the hotline. There are an increasing number of

1488
01:34:30,575 --> 01:34:34,015
Speaker 5:  people who want to get in the Slack room that automatically pulls in all

1489
01:34:34,015 --> 01:34:37,935
Speaker 5:  the voicemails we get on the hotline. So keep 'em coming. We love

1490
01:34:37,935 --> 01:34:41,175
Speaker 5:  the hotline. The Vergecast is VERGE Production and part of the Vox Media

1491
01:34:41,175 --> 01:34:44,655
Speaker 5:  podcast network. It's produced by Travis Lara, Brandon Kiefer and Eric Gomez.

1492
01:34:45,555 --> 01:34:49,495
Speaker 5:  We will be back next Tuesday. We're gonna talk about YouTube. We're

1493
01:34:49,495 --> 01:34:53,295
Speaker 5:  gonna do some more takes. I have feelings I need to get out and we're gonna

1494
01:34:53,295 --> 01:34:55,295
Speaker 5:  talk about them. See you then. Rock and roll,

