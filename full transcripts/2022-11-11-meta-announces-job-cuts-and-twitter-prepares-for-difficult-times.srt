1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 4507ce40-63c5-11ed-a47b-fd2bca75ad72
Status: Done
Stage: Done
Title: Meta announces job cuts and Twitter prepares for difficult times
Audio URL: https://jfe93e.s3.amazonaws.com/-1134901488950748107/2300059821430801362/s93290-US-4911s-1668393361.mp3
Description: The Verge's Nilay Patel, David Pierce, Alex Cranz, and Alex Heath discuss week two of Elon Musk as CEO of Twitter and Meta announcing job cuts.
Later in the show: What's next for Binance and FTX, a stretchable screen by LG Display, and the Surface Pro 9 review.

2
00:00:00,240 --> 00:00:03,240
Speaker 1:  Before we get to the show, I have a really quick favor to ask. What makes

3
00:00:03,240 --> 00:00:07,200
Speaker 1:  this show special, as you know, is you, it's the listeners, it's the people

4
00:00:07,200 --> 00:00:10,760
Speaker 1:  we get to hang out with every week and talk about tech, and that's why we'd

5
00:00:10,760 --> 00:00:14,360
Speaker 1:  like your help. Planning for our future, the future of the Vergecast. All

6
00:00:14,360 --> 00:00:18,040
Speaker 1:  we need you to do is fill out a short survey. You can go to the link in the

7
00:00:18,040 --> 00:00:21,960
Speaker 1:  show notes or directly to vox.com/pod survey. Take

8
00:00:21,960 --> 00:00:25,280
Speaker 1:  couple of questions. Super easy. Tell us about the vergecast, say main things

9
00:00:25,280 --> 00:00:29,120
Speaker 1:  about Eli. We would absolutely love to get your feedback to help

10
00:00:29,120 --> 00:00:33,000
Speaker 1:  us understand who's listening, what kinds of things you want

11
00:00:33,000 --> 00:00:36,800
Speaker 1:  us to talk more about and do. And hopefully how we

12
00:00:36,800 --> 00:00:40,480
Speaker 1:  can convince everyone you know, all of your friends and neighbors and

13
00:00:40,760 --> 00:00:44,680
Speaker 1:  coworkers and random people you encounter on the street can come to be part

14
00:00:44,680 --> 00:00:48,200
Speaker 1:  of our awesome Vergecast community. That's it. Fill out the survey. Thank

15
00:00:48,200 --> 00:00:48,640
Speaker 1:  you so much.

16
00:01:27,780 --> 00:01:31,770
Speaker 4:  It is the season of giving and the season of stressing Shop

17
00:01:31,800 --> 00:01:35,730
Speaker 4:  Amazon this holiday for decompressing Save on

18
00:01:35,730 --> 00:01:39,250
Speaker 4:  Silk Road and bound there refreshing when your parents in

19
00:01:39,320 --> 00:01:42,770
Speaker 4:  Inlaws just aren't really meshing or when your kid brother

20
00:01:42,850 --> 00:01:46,290
Speaker 4:  won't pass the red dressing and the thought of dry Turkey

21
00:01:46,400 --> 00:01:48,130
Speaker 4:  gets way too distressing.

22
00:01:51,960 --> 00:01:55,690
Speaker 4:  Whatever's holidays are depressing,

23
00:01:56,430 --> 00:01:57,010
Speaker 4:  I'm fine.

24
00:02:08,540 --> 00:02:12,300
Speaker 5:  Hello and welcome to the Verge Cast, the flagship podcast of

25
00:02:12,410 --> 00:02:16,100
Speaker 5:  verified users on Twitter. I'm your host Eli Patel.

26
00:02:16,120 --> 00:02:17,460
Speaker 6:  See, this is the problem

27
00:02:19,790 --> 00:02:21,540
Speaker 6:  no one would've known. That wasn't me.

28
00:02:21,950 --> 00:02:22,460
Speaker 5:  No one

29
00:02:22,630 --> 00:02:26,540
Speaker 6:  If not for this dastardly blue check that Alex has purchased

30
00:02:26,540 --> 00:02:26,660
Speaker 6:  for

31
00:02:26,660 --> 00:02:28,700
Speaker 5:  Herself. We sound exactly the same.

32
00:02:29,920 --> 00:02:31,700
Speaker 6:  How can anyone know who anyone is?

33
00:02:31,700 --> 00:02:33,940
Speaker 5:  Our audio engineer is like, I can't tell 'em apart.

34
00:02:34,070 --> 00:02:37,100
Speaker 6:  Do do have you? Have you seen? There's like a really good TikTok where they

35
00:02:37,100 --> 00:02:39,900
Speaker 6:  speed up Sam Smith's voice and they slow down Adele's voice and then they

36
00:02:39,900 --> 00:02:43,420
Speaker 6:  have the same voice. That's Twitter Blue. That's for

37
00:02:43,420 --> 00:02:47,060
Speaker 6:  $8 a month. You can speed up Bedell's voice and slow down Sam Smith's voice.

38
00:02:47,160 --> 00:02:48,420
Speaker 6:  You can't tell 'em apart

39
00:02:48,550 --> 00:02:50,980
Speaker 5:  If you can't tell other Eli Patel is here.

40
00:02:51,150 --> 00:02:55,100
Speaker 6:  Hi, I'm your friend Eli. That's Alex Kranz. That's me. David Pierce

41
00:02:55,100 --> 00:02:55,820
Speaker 6:  is here. Oh yeah,

42
00:02:56,130 --> 00:02:58,580
Speaker 5:  I thought I was Eli. Oh my god. David Pierce

43
00:02:58,580 --> 00:03:02,040
Speaker 1:  Is here. There. There are several ne Elis on this podcast. No one can confirm

44
00:03:02,040 --> 00:03:04,800
Speaker 1:  which ne Eli is, which Neli, only that there are many.

45
00:03:04,800 --> 00:03:07,720
Speaker 6:  Truly the real problem on the show is that there's two Alex, so Kranz is

46
00:03:07,720 --> 00:03:09,520
Speaker 6:  here and then Alex Heath is joining us. Hey Alex.

47
00:03:09,660 --> 00:03:11,680
Speaker 7:  Hey Rust And peace carries from Chicago.

48
00:03:12,680 --> 00:03:13,440
Speaker 6:  We'll get into

49
00:03:13,440 --> 00:03:14,800
Speaker 7:  That, get that on the way up front.

50
00:03:14,800 --> 00:03:18,480
Speaker 6:  It's a huge week of news. Yeah, so obviously

51
00:03:18,590 --> 00:03:22,360
Speaker 6:  Elon and Twitter, Alex, I don't think you've slept, you've been breaking

52
00:03:22,360 --> 00:03:25,560
Speaker 6:  story after story. They all seem to happen at two in the morning, which is

53
00:03:25,560 --> 00:03:29,400
Speaker 6:  a real problem for you. Yes, Meta had massive layoffs this week.

54
00:03:29,400 --> 00:03:33,280
Speaker 6:  11,000 people. Zuck wrote a very nice note, real contrast in

55
00:03:33,280 --> 00:03:36,960
Speaker 6:  leadership styles between our nation's social media CEOs this week, I would

56
00:03:36,960 --> 00:03:40,760
Speaker 6:  say including Gary from Chicago, who, Alex and David made

57
00:03:40,760 --> 00:03:44,000
Speaker 6:  famous in a feature earlier this year. And then

58
00:03:44,660 --> 00:03:48,440
Speaker 6:  ftx, the huge crypto exchange I'm pretty sure just

59
00:03:48,440 --> 00:03:52,080
Speaker 6:  ruined Tom Brady and Giselle's marriage. I'm, yeah, I don't, I can't make

60
00:03:52,080 --> 00:03:55,400
Speaker 6:  the causal connection. I don't have any evidence of it, but it seems obvious

61
00:03:55,550 --> 00:03:57,360
Speaker 6:  what's happening there a hundred percent. So

62
00:03:57,360 --> 00:04:00,680
Speaker 1:  We gotta, and that is the main consequence of everything going on with ftx.

63
00:04:00,680 --> 00:04:03,640
Speaker 1:  If you stop listening to this podcast right now, just know the only thing

64
00:04:03,640 --> 00:04:07,080
Speaker 1:  you need to know about FTX is that it ruins Tom Brady's relationship. That's

65
00:04:07,080 --> 00:04:07,480
Speaker 1:  very important.

66
00:04:07,480 --> 00:04:11,280
Speaker 6:  Yeah. Tom Brady nows to play football until he is 85 years old to just

67
00:04:11,280 --> 00:04:14,720
Speaker 6:  crawl out of the hold at crypto Doug for him. So we gotta talk about all

68
00:04:14,720 --> 00:04:18,560
Speaker 6:  that stuff. We obviously have to start with Twitter, which is a minute to

69
00:04:18,840 --> 00:04:22,480
Speaker 6:  minute, moment by moment just out of

70
00:04:22,480 --> 00:04:26,240
Speaker 6:  control, car crash hurdling towards yet another car crash,

71
00:04:26,240 --> 00:04:30,000
Speaker 6:  which itself is hurdling into the sun. Like,

72
00:04:30,000 --> 00:04:33,480
Speaker 6:  I dunno how to describe the current state of Twitter. People are quitting.

73
00:04:33,640 --> 00:04:36,360
Speaker 6:  Heath, tell us what you know so far. Well,

74
00:04:36,360 --> 00:04:39,160
Speaker 1:  We should say just real quick before we, before we get too far in, we should

75
00:04:39,320 --> 00:04:43,200
Speaker 1:  just say it's four 11 Eastern time on Thursday. Wow. If

76
00:04:43,200 --> 00:04:46,520
Speaker 1:  all of Twitter is different by the time you listen to this, which there's

77
00:04:46,520 --> 00:04:50,400
Speaker 1:  like a 60% chance it will be, just know that it is as of

78
00:04:50,400 --> 00:04:54,040
Speaker 1:  this moment, here is what we know, everything subject to change at all times.

79
00:04:54,040 --> 00:04:55,520
Speaker 1:  We'll just dub in whatever change is.

80
00:04:55,520 --> 00:04:58,360
Speaker 6:  Just to be clear about how real that is. We are in a product meeting today

81
00:04:58,360 --> 00:05:01,000
Speaker 6:  about our redesign and what's coming next and all this stuff we wanna do.

82
00:05:01,020 --> 00:05:05,000
Speaker 6:  And someone very casually, like a V Media product person was like, Oh,

83
00:05:05,000 --> 00:05:07,920
Speaker 6:  then we gotta think about Twitter, like Twitter integration. It's like, and

84
00:05:07,920 --> 00:05:11,720
Speaker 6:  then there was like a beat and then everyone was like, will

85
00:05:11,720 --> 00:05:14,960
Speaker 6:  Twitter still be around when the ships? And we were just like

86
00:05:15,030 --> 00:05:18,920
Speaker 6:  crossing off the list because no one knows the answer.

87
00:05:19,030 --> 00:05:22,800
Speaker 6:  Hold off on that one. Yeah. Anyways, Alex, tell us what you know.

88
00:05:23,360 --> 00:05:27,040
Speaker 7:  Well as we are recording this, Musk is addressing Twitter

89
00:05:27,440 --> 00:05:31,400
Speaker 7:  employees for the very first time in a meeting that he scheduled 15 minutes

90
00:05:31,400 --> 00:05:35,080
Speaker 7:  before and showed up about 10 minutes late too. Feels right. And

91
00:05:35,080 --> 00:05:39,040
Speaker 7:  we will have a read out of that hopefully after this podcast. He is

92
00:05:39,040 --> 00:05:42,760
Speaker 7:  literally addressing them over, you know, video for the first

93
00:05:42,760 --> 00:05:46,400
Speaker 7:  time since he took over. He sent a very terse email at

94
00:05:46,400 --> 00:05:50,160
Speaker 7:  almost midnight the other day, basically saying, Get ready for

95
00:05:50,160 --> 00:05:54,000
Speaker 7:  pain. He said he is not sure that

96
00:05:54,000 --> 00:05:57,840
Speaker 7:  Twitter will survive the coming recession, which is like a very, you know,

97
00:05:57,840 --> 00:06:01,720
Speaker 7:  heartwarming message to get from your new ceo. And then I guess my

98
00:06:01,840 --> 00:06:05,520
Speaker 7:  favorite part was he just sent a quick follow up email, like less than five

99
00:06:05,520 --> 00:06:09,360
Speaker 7:  minutes after, which was just one sentence and it was like, by the way, our

100
00:06:09,360 --> 00:06:12,720
Speaker 7:  top priority is fighting spam and bots and trolls.

101
00:06:13,210 --> 00:06:17,200
Speaker 7:  So very erratic inside Twitter right now. And

102
00:06:17,550 --> 00:06:21,120
Speaker 7:  I think all of that had a very fine bow put on it

103
00:06:21,560 --> 00:06:25,160
Speaker 7:  with this story we published today. So the day before this podcast

104
00:06:25,160 --> 00:06:29,000
Speaker 7:  comes out that a Twitter lawyer posted a Slack message

105
00:06:29,370 --> 00:06:33,080
Speaker 7:  to the whole company, basically encouraging them to seek whistleblower

106
00:06:33,080 --> 00:06:36,880
Speaker 7:  protection. So totally normal things happening inside Twitter right

107
00:06:36,880 --> 00:06:40,480
Speaker 6:  Now. So let's try to walk through the week

108
00:06:40,530 --> 00:06:44,280
Speaker 6:  of things. I'm not, There are many ways to tell a story. Welcome to the

109
00:06:44,280 --> 00:06:47,240
Speaker 6:  Verest. There are many ways to tell a story. You can start with the most

110
00:06:47,240 --> 00:06:50,560
Speaker 6:  important thing for us. You could lead with a conflict. Sometimes you're

111
00:06:50,560 --> 00:06:53,840
Speaker 6:  just beaten in the submission and the only proper way to tell a story is

112
00:06:53,840 --> 00:06:54,880
Speaker 6:  chronological order.

113
00:06:55,110 --> 00:06:56,480
Speaker 5:  I can do it. You want me to do it?

114
00:06:56,480 --> 00:06:57,440
Speaker 6:  Let's go it. Let's see if

115
00:06:57,440 --> 00:07:00,880
Speaker 5:  He can pull up. Okay, last week Elon said, I'm going to

116
00:07:01,190 --> 00:07:04,680
Speaker 5:  revamp Twitter blue and we're gonna start charging people

117
00:07:04,910 --> 00:07:08,720
Speaker 5:  more money and they're gonna get a blue check mark. So I immediately went

118
00:07:08,720 --> 00:07:10,520
Speaker 5:  out and I reserved Reckless Patel.

119
00:07:10,520 --> 00:07:11,440
Speaker 6:  That's how you're telling the

120
00:07:11,440 --> 00:07:14,200
Speaker 5:  Story. That's how I'm telling the story. Okay. And I immediately went out

121
00:07:14,200 --> 00:07:17,760
Speaker 5:  and I reserved Reckless Patel as a handle because I knew

122
00:07:17,850 --> 00:07:20,600
Speaker 5:  exactly what I was gonna do. This

123
00:07:20,600 --> 00:07:23,080
Speaker 6:  Is the story. This is just self-congratulation

124
00:07:23,740 --> 00:07:27,080
Speaker 5:  Exa. Hundred percent, a hundred percent Go Cowboys.

125
00:07:27,590 --> 00:07:31,440
Speaker 5:  Anyway, over the weekend they, they released a new version of

126
00:07:31,440 --> 00:07:35,400
Speaker 5:  I of the Twitter app on iOS and said, Okay, Twitter blues here,

127
00:07:35,500 --> 00:07:37,960
Speaker 5:  but it wasn't here. Right. That was all lies.

128
00:07:37,960 --> 00:07:41,040
Speaker 6:  Well, because they made a last minute determination that they should not

129
00:07:41,040 --> 00:07:44,960
Speaker 6:  roll out verification that is easily gamed to

130
00:07:44,960 --> 00:07:47,360
Speaker 6:  interate people right before the

131
00:07:47,560 --> 00:07:50,280
Speaker 5:  Election. Right. They realized, oh no, we should not do

132
00:07:50,280 --> 00:07:54,080
Speaker 6:  That. So game time decision to not ruin America's

133
00:07:54,080 --> 00:07:55,000
Speaker 6:  democracy with Twitter.

134
00:07:55,070 --> 00:07:58,960
Speaker 5:  Yeah. So they, they released this new version, it

135
00:07:58,960 --> 00:08:02,560
Speaker 5:  did absolutely nothing. People were very confused and then they all

136
00:08:02,560 --> 00:08:05,400
Speaker 5:  stopped caring for at least two days. Then there was a whole

137
00:08:05,680 --> 00:08:09,120
Speaker 6:  Election. There was an election. I will say, by the way, if you, I don't

138
00:08:09,120 --> 00:08:11,560
Speaker 6:  believe this is true, but if you are one of the many people who believe that

139
00:08:11,670 --> 00:08:15,440
Speaker 6:  Elon Musk bought Twitter to push his right wing agenda

140
00:08:15,440 --> 00:08:15,960
Speaker 6:  didn't

141
00:08:15,960 --> 00:08:16,080
Speaker 5:  Work,

142
00:08:16,590 --> 00:08:20,520
Speaker 6:  Just 44 billion to send the least effective political

143
00:08:20,530 --> 00:08:23,600
Speaker 6:  message of all time. He was like, I think you should vote for Republicans.

144
00:08:23,600 --> 00:08:26,960
Speaker 6:  And America was like, Not as much as you want us to. And then they didn't

145
00:08:26,960 --> 00:08:28,840
Speaker 6:  do it. Yeah. So I just

146
00:08:29,060 --> 00:08:29,720
Speaker 5:  Red trickle,

147
00:08:29,720 --> 00:08:33,280
Speaker 6:  Red trickle my thesis was Seehan is going to destroy his reputation

148
00:08:33,700 --> 00:08:36,600
Speaker 6:  and potentially cause grievous damage to his other companies.

149
00:08:37,150 --> 00:08:38,880
Speaker 5:  That's, that's happening. And

150
00:08:39,040 --> 00:08:42,520
Speaker 6:  The first one appears to be happening. Anyway, continue your story about,

151
00:08:42,630 --> 00:08:43,920
Speaker 5:  Okay. And then

152
00:08:43,990 --> 00:08:45,880
Speaker 6:  Flagrantly breaking Twitter's rules.

153
00:08:46,150 --> 00:08:50,120
Speaker 5:  Then yesterday Richard Lawler hit me up and he said, Alex, they

154
00:08:50,120 --> 00:08:53,320
Speaker 5:  did it blue. This is how I learned. By the way, Richard Lawler, our news

155
00:08:53,320 --> 00:08:56,800
Speaker 5:  editor, you've all heard him on the Verge cast, He's amazing, slacked me.

156
00:08:56,800 --> 00:09:00,200
Speaker 5:  And he said, They've rolled out Twitter blue, it's finally here, What are

157
00:09:00,200 --> 00:09:03,000
Speaker 5:  we gonna do? And I was like, eating a banana. And I was like, I don't know,

158
00:09:03,000 --> 00:09:05,400
Speaker 5:  what are we gonna do? And then I remembered that I, did

159
00:09:05,400 --> 00:09:06,440
Speaker 6:  You remember that you,

160
00:09:06,990 --> 00:09:10,480
Speaker 5:  I had reserved Reckless Patel and so I immediately went

161
00:09:10,660 --> 00:09:14,120
Speaker 5:  and I had to log out of my Twitter account on my phone because it only works

162
00:09:14,120 --> 00:09:16,240
Speaker 5:  on your phone. Only iOS.

163
00:09:16,240 --> 00:09:18,920
Speaker 6:  Right. So by the way, they, they're only rolling this out and Elon said this,

164
00:09:18,920 --> 00:09:22,840
Speaker 6:  he said at a financial conference, right, that they're piggybacking on

165
00:09:22,840 --> 00:09:26,200
Speaker 6:  Apple's user verification and credit card Yes. Security.

166
00:09:26,420 --> 00:09:30,280
Speaker 5:  Yes. So it only works on iOS. Yeah. And you

167
00:09:30,280 --> 00:09:33,800
Speaker 5:  have to have a Twitter account that was reserved before November

168
00:09:33,960 --> 00:09:37,480
Speaker 5:  9th. Yeah. So I, I was ready to go. I

169
00:09:37,480 --> 00:09:41,440
Speaker 5:  immediately reserved it using my, my Verge email and

170
00:09:41,440 --> 00:09:45,240
Speaker 5:  my account that very clearly does not say Eli Patel anywhere in

171
00:09:46,020 --> 00:09:47,360
Speaker 5:  it. And I had a blue check mark

172
00:09:47,500 --> 00:09:50,080
Speaker 6:  And now she's just running around impersonating me. And, and here's what

173
00:09:50,080 --> 00:09:52,840
Speaker 6:  I'll tell you. Alex has gotten herself up to 200 followers. Yes.

174
00:09:52,910 --> 00:09:53,840
Speaker 5:  Over 200

175
00:09:53,840 --> 00:09:57,640
Speaker 6:  Dier just sent me a text message noting that the fake account

176
00:09:57,640 --> 00:10:01,520
Speaker 6:  now auto completes when you search for my name, it's being

177
00:10:01,520 --> 00:10:04,880
Speaker 6:  that account was recommended to me and my should follow

178
00:10:04,960 --> 00:10:08,920
Speaker 6:  today. It's great's great. It's, it's, it's amazing. It's

179
00:10:08,920 --> 00:10:12,760
Speaker 6:  everything that you've ever wanted from identity verification system that

180
00:10:12,760 --> 00:10:16,320
Speaker 6:  basically comes down to do you have $8? Yeah. So that, the reason I brought

181
00:10:16,320 --> 00:10:20,240
Speaker 6:  up the piggybacking is right, Elon's, like the $8 will deter spammers, it

182
00:10:20,240 --> 00:10:24,080
Speaker 6:  will make spam too expensive. And also the credit card payment

183
00:10:24,080 --> 00:10:27,840
Speaker 6:  processors and apples iOS protections are additional layers of

184
00:10:28,040 --> 00:10:31,160
Speaker 6:  security. This thesis has proven to be about as false

185
00:10:31,570 --> 00:10:32,800
Speaker 5:  As it can be, Right?

186
00:10:32,800 --> 00:10:36,040
Speaker 6:  Like there is, there's just spam all over the plat. Like Mario is flipping

187
00:10:36,040 --> 00:10:39,680
Speaker 6:  you off from an account that looks like the Nintendo account. It's it's still

188
00:10:39,680 --> 00:10:43,560
Speaker 6:  going. There's a fake Eli Lilly account that has been promising

189
00:10:43,560 --> 00:10:47,440
Speaker 6:  free insulin for a day. Which is, I mean, maybe they should just

190
00:10:47,440 --> 00:10:50,960
Speaker 6:  do it just like that's a good idea, but it's a good policy. He's completely

191
00:10:50,960 --> 00:10:53,280
Speaker 6:  lost control over the platform. Yeah,

192
00:10:53,590 --> 00:10:54,880
Speaker 5:  A hundred percent. This,

193
00:10:54,880 --> 00:10:58,440
Speaker 1:  This seems like a useful time to note that this is what

194
00:10:58,610 --> 00:11:02,240
Speaker 1:  he wanted. Like this is, this is the whole thing.

195
00:11:02,700 --> 00:11:06,080
Speaker 1:  And like this is, this is the guy who said comedy is back on the platform

196
00:11:06,080 --> 00:11:09,840
Speaker 1:  and then said actually if you impersonate somebody, you'll get suspended

197
00:11:09,840 --> 00:11:13,200
Speaker 1:  from Twitter and then forced a bunch of comedians to do that and get suspended

198
00:11:13,200 --> 00:11:16,720
Speaker 1:  from Twitter. Like Crans. You get to do kind of a victory lap on this after

199
00:11:16,720 --> 00:11:20,520
Speaker 1:  last week because this was never, ever, ever actually about verifying

200
00:11:20,520 --> 00:11:24,440
Speaker 1:  users. Right. And anyone who thought it was, it was wrong. Yeah.

201
00:11:24,440 --> 00:11:27,960
Speaker 1:  What this is about is getting people to pay $8 to feel fancy

202
00:11:28,460 --> 00:11:32,320
Speaker 1:  and you get, you get to be up ranked in people's search results and algorithms

203
00:11:32,320 --> 00:11:35,720
Speaker 1:  and you get to have a check mark. And even that has now been like completely

204
00:11:35,720 --> 00:11:39,120
Speaker 1:  undermined by the explanation. That's like some people are verified

205
00:11:39,130 --> 00:11:42,000
Speaker 1:  because they're important and some people are verified because they paid

206
00:11:42,000 --> 00:11:45,880
Speaker 1:  and like instantly being verified because you paid has become like the thirstiest

207
00:11:45,880 --> 00:11:49,480
Speaker 1:  dumbest thing to possibly do. It's just this whole thing has gone so

208
00:11:49,630 --> 00:11:53,360
Speaker 1:  horribly awry in so many ways. But the thing that is like

209
00:11:53,360 --> 00:11:56,440
Speaker 1:  useful is the idea that like, the idea that this was ever actually about

210
00:11:56,440 --> 00:11:59,840
Speaker 1:  verifying Twitter users on Twitter, we can just, we can just put that to

211
00:11:59,840 --> 00:12:01,120
Speaker 1:  bed. Cause that's not what's happening. It's

212
00:12:01,120 --> 00:12:01,800
Speaker 5:  Total Well and the

213
00:12:01,800 --> 00:12:04,560
Speaker 6:  Rest Heath went, Heath is just like cracking up what's going on.

214
00:12:04,570 --> 00:12:07,120
Speaker 7:  We haven't even talked about the other check mark yet.

215
00:12:08,510 --> 00:12:12,400
Speaker 6:  I know. All right. He explained the other check mark which came and went

216
00:12:12,610 --> 00:12:14,600
Speaker 6:  in a, like a frenetic burst defense.

217
00:12:14,600 --> 00:12:17,360
Speaker 5:  Sandra O was so important for 30 minutes

218
00:12:17,550 --> 00:12:20,840
Speaker 1:  I think all thanks to marque Brownlee. Like it seems like Marque Brownlee

219
00:12:20,840 --> 00:12:23,200
Speaker 1:  killed the other check mark. But Heath you should explain.

220
00:12:24,450 --> 00:12:28,200
Speaker 7:  No. So Marque did not kill it. What actually happened is,

221
00:12:28,710 --> 00:12:29,480
Speaker 7:  well first you

222
00:12:29,480 --> 00:12:30,440
Speaker 6:  Have to explain what it is.

223
00:12:30,770 --> 00:12:34,440
Speaker 7:  So basically as they were rolling out blue, someone inside Twitter

224
00:12:34,840 --> 00:12:38,360
Speaker 7:  realized, oh shit, what do we do about all these government

225
00:12:38,760 --> 00:12:42,240
Speaker 7:  agencies that are not going to pay us $8 to have a check mark

226
00:12:42,750 --> 00:12:46,680
Speaker 7:  NGOs, et cetera. So they roll out this gray check mark

227
00:12:46,870 --> 00:12:50,240
Speaker 7:  that's a second verification check mark that is

228
00:12:50,540 --> 00:12:54,400
Speaker 7:  the same as the old check mark in that it's literally managed

229
00:12:54,400 --> 00:12:58,160
Speaker 7:  in a spreadsheet inside Twitter. And it's like people

230
00:12:58,160 --> 00:13:02,000
Speaker 7:  from different parts of the company submitting names and

231
00:13:02,000 --> 00:13:05,680
Speaker 7:  Twitter accounts to be verified. Right. Which is how it used to work. That

232
00:13:05,680 --> 00:13:08,360
Speaker 7:  goes on for what? What? I don't even know. Was it, this is like an hour?

233
00:13:08,590 --> 00:13:11,920
Speaker 7:  Yeah, it was like a half a day. Okay. You could've told me half a day. You

234
00:13:11,920 --> 00:13:15,880
Speaker 7:  could've told me an hour, whatever. Then Elon tweets, I just killed this.

235
00:13:16,230 --> 00:13:19,400
Speaker 7:  I think it was maybe to Marques. Yeah, yeah. When everyone just got confused

236
00:13:19,400 --> 00:13:22,440
Speaker 7:  and they're like, wait, why do, why do some people have two check marks?

237
00:13:22,440 --> 00:13:26,320
Speaker 7:  What is this great check mark? And his whole thing was like Lords and

238
00:13:26,320 --> 00:13:29,600
Speaker 7:  peasants. Right? He was like, the original way verification works was bullshit,

239
00:13:29,600 --> 00:13:33,440
Speaker 7:  you know, power to the people, everyone gets it for $8 and then that wasn't

240
00:13:33,720 --> 00:13:37,520
Speaker 7:  the case the day it rolled out. And so then he

241
00:13:37,520 --> 00:13:41,080
Speaker 7:  cancels it and I think they may actually bring it back guys.

242
00:13:41,310 --> 00:13:44,840
Speaker 7:  I think there's like, right now the problem is, is that

243
00:13:45,550 --> 00:13:49,400
Speaker 7:  a bunch of Twitter people frantically started trying to add names to

244
00:13:49,400 --> 00:13:52,720
Speaker 7:  this great check mark list because they wanted their respective partners,

245
00:13:53,120 --> 00:13:54,640
Speaker 7:  agencies, et cetera to have it

246
00:13:54,640 --> 00:13:55,280
Speaker 5:  Right. So that's why

247
00:13:55,280 --> 00:13:58,480
Speaker 7:  Sandra sit out and was like, No, like this is too much

248
00:13:58,900 --> 00:14:01,840
Speaker 7:  and shut it down temporarily. But I think they're gonna bring it back. So

249
00:14:01,840 --> 00:14:05,600
Speaker 7:  I think there's gonna be this still two-tier verification system

250
00:14:05,900 --> 00:14:09,040
Speaker 7:  and it's just check marks all the way down. You know, it's just,

251
00:14:09,250 --> 00:14:12,960
Speaker 5:  It wouldn't be two tier, it would be technically three tier because there'd

252
00:14:12,960 --> 00:14:16,840
Speaker 5:  be the gray check mark for people. Then the blue

253
00:14:16,890 --> 00:14:20,320
Speaker 5:  if you click on it says this is an important person check mark.

254
00:14:20,500 --> 00:14:23,720
Speaker 5:  And then finally the blue if you click on it, This is Reckless Patel?

255
00:14:23,890 --> 00:14:27,560
Speaker 7:  No, the mid, the mid blue one is going

256
00:14:27,560 --> 00:14:31,360
Speaker 7:  away. The mid-tier blue check mark, that's the legacy one will go

257
00:14:31,360 --> 00:14:34,960
Speaker 7:  away. Okay. But Right. I for now there's going to be three.

258
00:14:35,570 --> 00:14:39,480
Speaker 5:  So are they gonna change who gets the gray

259
00:14:39,480 --> 00:14:42,920
Speaker 5:  check mark? Like is if you're currently have the blue check mark without

260
00:14:42,920 --> 00:14:46,240
Speaker 5:  paying, will you move to the gray or are they gonna like audit that and be

261
00:14:46,240 --> 00:14:50,000
Speaker 5:  like, Sandra O can keep it Alex Kranz? Absolutely not. Which I would

262
00:14:50,000 --> 00:14:50,320
Speaker 5:  respect

263
00:14:50,640 --> 00:14:54,520
Speaker 6:  Kranz. Only Elon knows. Okay. Only Elon knows.

264
00:14:54,520 --> 00:14:58,240
Speaker 1:  No, I, I would pause it that even Elon doesn't know that literally no one

265
00:14:58,240 --> 00:14:59,720
Speaker 1:  on this earth knows how that

266
00:14:59,720 --> 00:15:03,280
Speaker 6:  Is. Wait, I just wanna put this out there. We are at the point with all of

267
00:15:03,280 --> 00:15:06,800
Speaker 6:  this chaos, Did I receive notes from like two or three people

268
00:15:07,460 --> 00:15:11,280
Speaker 6:  who are like tech company operators just floating the

269
00:15:11,280 --> 00:15:15,000
Speaker 6:  idea that he's trying to destroy the company on purpose. Like it's the,

270
00:15:15,000 --> 00:15:18,920
Speaker 6:  the amount of chaos is so Yeah. Like irresponsible

271
00:15:19,470 --> 00:15:23,320
Speaker 6:  that like smart people are like, you should look into whether he's

272
00:15:23,320 --> 00:15:25,000
Speaker 6:  doing this on purpose to destroy Twitter.

273
00:15:25,170 --> 00:15:25,760
Speaker 5:  No, he's just

274
00:15:25,760 --> 00:15:28,720
Speaker 6:  Risked. We haven't even gotten to the FTC violations yet. Yeah. We haven't

275
00:15:28,720 --> 00:15:32,160
Speaker 6:  even gotten to like the other, the looming shadow of the government. There's

276
00:15:32,160 --> 00:15:35,360
Speaker 6:  like random people are like, you should look. I'm like, I don't, That seems

277
00:15:35,360 --> 00:15:38,840
Speaker 6:  like he wouldn't just light 44 billion on fire.

278
00:15:38,990 --> 00:15:40,720
Speaker 5:  Yeah. Especially like he's

279
00:15:40,720 --> 00:15:44,640
Speaker 6:  Had to, he's, he's definitely the point with the whiplash decisions and

280
00:15:44,640 --> 00:15:48,480
Speaker 6:  the sort of just, I don't know, disregard for the

281
00:15:48,480 --> 00:15:52,440
Speaker 6:  reality of running a company at Twitter scale that other smart people

282
00:15:52,440 --> 00:15:56,360
Speaker 6:  are like, there's an actual method here and the goal is to destroy the company,

283
00:15:56,360 --> 00:15:58,840
Speaker 6:  which I think is a, a remarkable place to

284
00:15:58,840 --> 00:16:02,520
Speaker 1:  Be. I've had multiple people over the last several days use the phrase,

285
00:16:02,880 --> 00:16:06,800
Speaker 1:  never ascribe anything to malice that can be explained by incompetence.

286
00:16:07,160 --> 00:16:10,640
Speaker 1:  Yeah. Like, like that exact phrase over and over. And it's like, it's because

287
00:16:10,640 --> 00:16:13,120
Speaker 1:  of that thing. It's like you look at it and it's like, okay, the simplest

288
00:16:13,120 --> 00:16:16,360
Speaker 1:  explanation here is that Elon Musk is systematically trying to ruin Twitter.

289
00:16:16,600 --> 00:16:17,000
Speaker 1:  Like that's

290
00:16:17,000 --> 00:16:17,400
Speaker 6:  The only

291
00:16:17,710 --> 00:16:20,920
Speaker 1:  Simple explanation for what's going on here. But it's like, then you look

292
00:16:20,920 --> 00:16:24,600
Speaker 1:  around and it's like, okay, it's, it's Elon Musk who has no idea how to run

293
00:16:24,600 --> 00:16:27,680
Speaker 1:  a company like this who brought in a bunch of people who have no idea how

294
00:16:27,680 --> 00:16:31,480
Speaker 1:  to run a company like this. Tried to change it all in 15 minutes, fired half

295
00:16:31,480 --> 00:16:35,160
Speaker 1:  the staff. And it's like, of course this is gonna be a disaster. Like you

296
00:16:35,160 --> 00:16:38,360
Speaker 1:  could, you could do all those things and try your absolute hardest and it

297
00:16:38,360 --> 00:16:41,720
Speaker 1:  would go exactly like this. Like it's craziness.

298
00:16:41,720 --> 00:16:45,640
Speaker 5:  This is the guy who beta tests, self-driving cars on

299
00:16:45,640 --> 00:16:49,520
Speaker 5:  public roads where anybody could theoretically be hit by it. Of course he's

300
00:16:49,520 --> 00:16:52,240
Speaker 6:  Gonna like the, There's a real difference there. And I i's

301
00:16:52,240 --> 00:16:52,400
Speaker 5:  Is that

302
00:16:52,400 --> 00:16:56,280
Speaker 6:  Okay? And I, I've been thinking about this a lot. Okay. Elon does not

303
00:16:56,280 --> 00:16:59,760
Speaker 6:  have absolute disdain for the people who work at Tesla

304
00:16:59,900 --> 00:17:03,800
Speaker 6:  and buy Tesla's. Yeah. And his open disdain for the

305
00:17:03,800 --> 00:17:07,680
Speaker 6:  people who make Twitter is so obvious and it's

306
00:17:07,680 --> 00:17:11,080
Speaker 6:  like, dude, you're addicted to Twitter. The thing they made is your

307
00:17:11,600 --> 00:17:15,120
Speaker 6:  favorite thing. This is like if you walked into the Oreo factory

308
00:17:15,380 --> 00:17:19,240
Speaker 6:  and you were like, who are the people who made Oreos? Fuck them. Get

309
00:17:19,330 --> 00:17:23,320
Speaker 6:  in the, here I'm doing Oreos my way and then you ruined Oreos.

310
00:17:23,640 --> 00:17:27,600
Speaker 6:  Like it's, it's absolutely bizarre. And I get that

311
00:17:27,600 --> 00:17:30,560
Speaker 6:  maybe the company was burning too much money and it, I think we have to say

312
00:17:30,560 --> 00:17:34,480
Speaker 6:  this every week criticizing Elon's tenure, Twitter is

313
00:17:34,480 --> 00:17:38,400
Speaker 6:  a no way. Praise for the previous disaster chief executives

314
00:17:38,400 --> 00:17:41,680
Speaker 6:  of Twitter. They did a bad job running the company. I mean Prague

315
00:17:41,680 --> 00:17:42,360
Speaker 5:  Yes. Made

316
00:17:42,360 --> 00:17:45,640
Speaker 6:  Bank the operation of the, Actually he hasn't made bank yet, right? He's

317
00:17:45,640 --> 00:17:49,040
Speaker 6:  he's gonna have to, He's he didn't, he got fired for cause Oh, and the cause,

318
00:17:49,080 --> 00:17:53,000
Speaker 6:  cause was you made me look bad and forced me to buy Twitter. So

319
00:17:53,000 --> 00:17:56,880
Speaker 6:  like I just, it's just crazy to me that he doesn't, if you are,

320
00:17:56,880 --> 00:18:00,280
Speaker 6:  if you think you can do a better job managing an organization

321
00:18:00,390 --> 00:18:03,680
Speaker 6:  just by making slightly different decisions and not actually like changing

322
00:18:03,680 --> 00:18:07,440
Speaker 6:  how the organization works, like you're in for a bad time and here

323
00:18:07,720 --> 00:18:11,400
Speaker 6:  with verification all this stuff, there's like really good reasons

324
00:18:11,400 --> 00:18:14,840
Speaker 6:  that smart people made rigorous decisions to get where they landed. Right.

325
00:18:14,840 --> 00:18:17,440
Speaker 6:  And he's not taking them into account. Okay.

326
00:18:17,440 --> 00:18:17,720
Speaker 7:  Which

327
00:18:17,720 --> 00:18:19,520
Speaker 6:  Leads us, You guys want some Alex to the ftc?

328
00:18:19,790 --> 00:18:23,280
Speaker 7:  Yeah. Yeah. Well before that I was just gonna say, to kind of add to what

329
00:18:23,280 --> 00:18:27,080
Speaker 7:  you were saying, this is live kind of updates from the all hands. That

330
00:18:27,080 --> 00:18:30,840
Speaker 7:  was just, and that he told employees that bankruptcy

331
00:18:30,840 --> 00:18:34,520
Speaker 7:  is not out of the question and that he expects Twitter to have

332
00:18:34,800 --> 00:18:38,640
Speaker 7:  negative cash flow of several billion next year. So yeah,

333
00:18:38,790 --> 00:18:42,560
Speaker 7:  your theory that he may actually be just setting it on fire

334
00:18:42,570 --> 00:18:44,640
Speaker 7:  is, is definitely not unfounded.

335
00:18:44,790 --> 00:18:47,800
Speaker 6:  Yeah. But then like how are you gonna do all the things you want do? Like

336
00:18:47,910 --> 00:18:51,520
Speaker 6:  he's filed paperwork to start a payment service and like building everything

337
00:18:51,520 --> 00:18:51,920
Speaker 6:  out. What

338
00:18:51,920 --> 00:18:54,600
Speaker 5:  If he just bought it for the tech stack?

339
00:18:55,010 --> 00:18:57,280
Speaker 6:  There's not, I mean it's like a, it's fine.

340
00:18:57,580 --> 00:19:01,440
Speaker 7:  I'm just, I'm kind of speechless with all this. I mean this is certainly

341
00:19:01,440 --> 00:19:04,600
Speaker 7:  the wildest story I've ever recovered. Do you wanna talk about the FTC thing?

342
00:19:04,750 --> 00:19:05,240
Speaker 7:  Yeah.

343
00:19:05,240 --> 00:19:07,480
Speaker 6:  This is the big scoop that you had this morning. Oh my

344
00:19:07,480 --> 00:19:11,320
Speaker 7:  God. Well props to Casey for skipping me on

345
00:19:11,320 --> 00:19:14,800
Speaker 7:  Twitter. But yeah, we have this full memo

346
00:19:15,190 --> 00:19:19,120
Speaker 7:  that a company lawyer, a senior counsel on the privacy team

347
00:19:19,390 --> 00:19:23,320
Speaker 7:  sent us kind of like a falling on your sword. I mean she clearly is

348
00:19:23,320 --> 00:19:26,320
Speaker 7:  expecting to be fired after this. Basically saying that

349
00:19:26,870 --> 00:19:30,400
Speaker 7:  Elon is pushing the company to violate this

350
00:19:30,540 --> 00:19:34,360
Speaker 7:  FTC consent decree, which has very, you know, stringent rules

351
00:19:34,360 --> 00:19:37,800
Speaker 7:  about certifying how data is used and you know, privacy

352
00:19:37,800 --> 00:19:41,760
Speaker 7:  review that Twitter has been caught violating before and that the

353
00:19:41,760 --> 00:19:44,920
Speaker 7:  company is standing to face billions of dollars

354
00:19:45,410 --> 00:19:48,880
Speaker 7:  in fines. And that the most alarming thing I think was that

355
00:19:49,320 --> 00:19:52,320
Speaker 7:  engineers, individual engineers are now being asked to

356
00:19:52,340 --> 00:19:56,160
Speaker 7:  self-certify their, their code under this

357
00:19:56,160 --> 00:20:00,000
Speaker 7:  consent decree. And the three executives who were actually in

358
00:20:00,000 --> 00:20:03,680
Speaker 7:  charge of enforcing this internally all resigned the same.

359
00:20:03,680 --> 00:20:07,480
Speaker 7:  Well the evening before this memo went out. And this is a company in-house

360
00:20:07,480 --> 00:20:11,320
Speaker 7:  lawyer ending a message saying, By the way, here's how

361
00:20:11,320 --> 00:20:13,360
Speaker 7:  you can contact the FTC to whistle

362
00:20:13,360 --> 00:20:13,720
Speaker 6:  Blow.

363
00:20:15,140 --> 00:20:19,120
Speaker 7:  I'm gonna take PTO now. Salute emoji. Which is the emoji they're all giving

364
00:20:19,120 --> 00:20:19,680
Speaker 7:  when they get

365
00:20:19,680 --> 00:20:20,680
Speaker 6:  Laid off. Amazing.

366
00:20:21,010 --> 00:20:24,800
Speaker 7:  So just like a truly incredible thing to,

367
00:20:24,800 --> 00:20:27,680
Speaker 7:  to have sent inside a company by one of your own lawyers.

368
00:20:27,870 --> 00:20:28,360
Speaker 6:  What

369
00:20:28,360 --> 00:20:29,760
Speaker 5:  Is the self certifying?

370
00:20:30,350 --> 00:20:33,840
Speaker 6:  Well throw this back up, up. We can explain kinda the mechanics here. Okay,

371
00:20:33,970 --> 00:20:37,920
Speaker 6:  so in 2011, right, Twitter got in trouble because they were

372
00:20:37,920 --> 00:20:41,520
Speaker 6:  using personal information to target ads. Okay. So you'd sign up for Twitter,

373
00:20:41,520 --> 00:20:44,880
Speaker 6:  you'd tell 'em your email address, your phone number, your whatever pii it's

374
00:20:44,880 --> 00:20:48,800
Speaker 6:  called personal identify information. And they were using it to target ads.

375
00:20:48,800 --> 00:20:51,840
Speaker 6:  Okay. The FFC got mad at them, made them sign a consent decree saying you're

376
00:20:51,840 --> 00:20:55,200
Speaker 6:  not gonna do this May of 2022, Twitter pays fine.

377
00:20:55,200 --> 00:20:58,920
Speaker 6:  150 million. Cuz guess what they did? They used your personal information.

378
00:20:58,920 --> 00:21:02,440
Speaker 6:  Target the ads. No, So re-up the consent decree. Modified order.

379
00:21:02,710 --> 00:21:06,160
Speaker 6:  This requires them to have a group of

380
00:21:06,930 --> 00:21:09,720
Speaker 6:  people. We don't know who that group of people is that is accountable to

381
00:21:09,740 --> 00:21:10,160
Speaker 6:  the ftc.

382
00:21:10,570 --> 00:21:14,040
Speaker 7:  Oh, it's the people who resigned eli. Yeah, yeah, yeah. It's the chief privacy

383
00:21:14,040 --> 00:21:18,000
Speaker 7:  officer, Chief compliance officer and chief security

384
00:21:18,000 --> 00:21:21,560
Speaker 7:  information officer. All three of whom resigned together. Right.

385
00:21:21,560 --> 00:21:23,760
Speaker 6:  Okay. So we didn't, I didn't think we had this when we wrote the story, but,

386
00:21:23,760 --> 00:21:27,400
Speaker 6:  so Alex has now confirmed it, the people responsible to the

387
00:21:27,460 --> 00:21:31,280
Speaker 6:  FTC for filing compliance reports, keeping Twitter

388
00:21:31,280 --> 00:21:33,120
Speaker 6:  and compliance with this FTC order not

389
00:21:33,120 --> 00:21:33,600
Speaker 5:  Getting fined

390
00:21:33,600 --> 00:21:37,160
Speaker 6:  Again, but for, Well no, but they're accountable to the ftc. So if they're

391
00:21:37,160 --> 00:21:39,640
Speaker 6:  on the hook, Twitter's on the hook for billions dollars in fines. They're

392
00:21:39,640 --> 00:21:41,440
Speaker 6:  on the hook personally. Right.

393
00:21:42,220 --> 00:21:44,480
Speaker 7:  And we should say like, yeah, going to jail,

394
00:21:44,590 --> 00:21:48,560
Speaker 6:  They can go to jail. So one of the clauses

395
00:21:48,560 --> 00:21:52,440
Speaker 6:  in this consent decree is 14 days after a change in ownership or

396
00:21:52,440 --> 00:21:56,200
Speaker 6:  control of the company Twitter, these people have to file a

397
00:21:56,200 --> 00:21:59,520
Speaker 6:  compliance report. So if anything happens to the company, company changes

398
00:21:59,520 --> 00:22:03,360
Speaker 6:  control. 14 days later the FTC wants a document saying data practice is still

399
00:22:03,360 --> 00:22:03,480
Speaker 6:  good.

400
00:22:06,190 --> 00:22:06,680
Speaker 7:  They

401
00:22:06,680 --> 00:22:09,960
Speaker 6:  All quit yesterday. They don't wanna be in the hook,

402
00:22:10,390 --> 00:22:14,280
Speaker 6:  they don't wanna go to jail for Elon's. Crazy. Right?

403
00:22:14,280 --> 00:22:17,840
Speaker 6:  And the FTC has owed this thing, the FTC had a statement, they gave it to

404
00:22:17,840 --> 00:22:21,160
Speaker 6:  us, they're watching this very closely, they're alarmed. In the meantime,

405
00:22:21,160 --> 00:22:24,840
Speaker 6:  Elon's rushing out features that take your credit card number

406
00:22:25,100 --> 00:22:28,960
Speaker 6:  and purport to identify you without going

407
00:22:28,960 --> 00:22:31,880
Speaker 6:  through as Alex reported all the necessary reviews, including

408
00:22:32,060 --> 00:22:36,000
Speaker 6:  hilariously the red team review, which is like, here's all the

409
00:22:36,000 --> 00:22:36,840
Speaker 6:  things that could go wrong.

410
00:22:39,110 --> 00:22:42,160
Speaker 6:  They didn't take any of the recommendations. Nothing. All of the things immediately

411
00:22:42,160 --> 00:22:44,480
Speaker 6:  went wrong. Exactly the way that you would expect them to. Right.

412
00:22:44,480 --> 00:22:48,080
Speaker 7:  To be clear. So there was an emergency red team review

413
00:22:48,140 --> 00:22:51,280
Speaker 7:  the night before Blue launched the night before.

414
00:22:51,820 --> 00:22:55,200
Speaker 7:  And all of the things that we were just talking about with impersonation,

415
00:22:55,670 --> 00:22:59,480
Speaker 7:  this was all raised, I'm told internally as like, hey, we should be

416
00:22:59,480 --> 00:23:02,680
Speaker 7:  thinking about this. This is gonna happen immediately. Obviously none of

417
00:23:02,680 --> 00:23:06,280
Speaker 7:  it was implemented. And yeah, so that's just a sign of how

418
00:23:06,280 --> 00:23:10,120
Speaker 7:  breakneck the company is operating. And I mean this lawyer in this

419
00:23:10,120 --> 00:23:13,520
Speaker 7:  note says we're on one to two week from product

420
00:23:13,520 --> 00:23:17,360
Speaker 7:  inception to release sprints and how in the world are we supposed to get

421
00:23:17,360 --> 00:23:20,760
Speaker 7:  that through R FTC requirements? And

422
00:23:21,110 --> 00:23:24,880
Speaker 7:  I mean I just like, I know I already said like this is like a

423
00:23:24,880 --> 00:23:28,640
Speaker 7:  remarkable thing for someone to write, but this is, this is a

424
00:23:28,880 --> 00:23:32,680
Speaker 7:  company lawyer literally saying like people are gonna go to jail basically.

425
00:23:32,680 --> 00:23:36,560
Speaker 7:  Right. And this person was still on the payroll when they sent it, so

426
00:23:37,320 --> 00:23:40,040
Speaker 7:  obviously unclear what's gonna happen. But yeah, that's the state of things.

427
00:23:40,320 --> 00:23:44,120
Speaker 5:  Could Elon go to jail? Could he Yeah. Buy

428
00:23:44,120 --> 00:23:45,600
Speaker 5:  Twitter and get sent to

429
00:23:45,600 --> 00:23:48,600
Speaker 6:  Jail? I mean I don't, I don't think that causality is that direct, but

430
00:23:48,600 --> 00:23:50,280
Speaker 5:  Yes, my head, it will always be

431
00:23:50,540 --> 00:23:54,320
Speaker 7:  His personal attorney Alex Burrow, who is also Twitter's acting

432
00:23:54,320 --> 00:23:57,720
Speaker 7:  head of legal told the, the person who wrote this memo

433
00:23:58,240 --> 00:24:02,040
Speaker 7:  that I reported, Elon puts rockets into space. He's not

434
00:24:02,040 --> 00:24:05,280
Speaker 7:  afraid of the ftc. So that's

435
00:24:05,280 --> 00:24:05,480
Speaker 6:  Good.

436
00:24:05,480 --> 00:24:06,440
Speaker 5:  Yeah. Wow.

437
00:24:06,870 --> 00:24:08,240
Speaker 6:  I mean it's a good line.

438
00:24:08,240 --> 00:24:09,800
Speaker 5:  Yeah, it's a very good line. I

439
00:24:09,800 --> 00:24:10,120
Speaker 6:  Would say the

440
00:24:10,120 --> 00:24:11,600
Speaker 5:  Threats that gets you sent to jail,

441
00:24:11,620 --> 00:24:15,480
Speaker 6:  The threats from space conceptually. Yeah. And

442
00:24:15,480 --> 00:24:19,280
Speaker 6:  government lawyers are different in form, which is one of those things like

443
00:24:19,570 --> 00:24:21,840
Speaker 6:  if you're good at one thing, you're not always good at the other thing. Like

444
00:24:21,840 --> 00:24:22,120
Speaker 6:  yeah

445
00:24:22,580 --> 00:24:23,600
Speaker 5:  One is going

446
00:24:23,600 --> 00:24:27,400
Speaker 6:  Up, i, I type really well. I'm not afraid of playing NFL football. It's like

447
00:24:27,710 --> 00:24:30,960
Speaker 6:  that's, it's the same form of argument, you know. But

448
00:24:31,590 --> 00:24:35,040
Speaker 6:  that to me is this is the ultimately

449
00:24:35,310 --> 00:24:39,080
Speaker 6:  what, what I think Elon has failed to grasp

450
00:24:39,130 --> 00:24:43,040
Speaker 6:  is that Twitter is a deeply complicated company and

451
00:24:43,040 --> 00:24:46,600
Speaker 6:  a lot of it's dysfunction is because of the, the

452
00:24:47,280 --> 00:24:50,640
Speaker 6:  conflicting pressures it's under from all directions at all times.

453
00:24:50,790 --> 00:24:54,400
Speaker 6:  Some of which is self-inflicted. Right. The FTC consent decree, Twitter

454
00:24:54,400 --> 00:24:58,160
Speaker 6:  should not have used data in a way that Twitter

455
00:24:58,160 --> 00:25:00,560
Speaker 6:  should not have used your personal information in a way that violated people's

456
00:25:00,560 --> 00:25:04,320
Speaker 6:  privacy. Right. And so now they have to be extra careful or some

457
00:25:04,320 --> 00:25:05,360
Speaker 6:  officers of the company go to

458
00:25:05,360 --> 00:25:09,000
Speaker 7:  Jail. Well I was just gonna say, it's worth noting too that in this Twitter

459
00:25:09,000 --> 00:25:12,800
Speaker 7:  spaces that Elon hosted with advertisers the other day, he

460
00:25:12,800 --> 00:25:16,280
Speaker 7:  talked about merging Twitter's tech stacks and he's done this internally

461
00:25:16,280 --> 00:25:19,560
Speaker 7:  already in terms of like he's created a new central engineering organization

462
00:25:19,560 --> 00:25:23,280
Speaker 7:  Twitter used to have its advertising stack and its

463
00:25:23,280 --> 00:25:26,880
Speaker 7:  tweet kind of relevant stack for consumers separate.

464
00:25:27,140 --> 00:25:30,920
Speaker 7:  And he's talked about frantically trying to merge all of it together.

465
00:25:30,920 --> 00:25:33,920
Speaker 7:  And I think his quote was like, we need to be adventuresome or something.

466
00:25:34,220 --> 00:25:38,040
Speaker 7:  But he wants the same technology that powers ads to power

467
00:25:38,040 --> 00:25:41,920
Speaker 7:  tweet relevance. And this gets it at the heart of this FTC thing,

468
00:25:41,920 --> 00:25:45,760
Speaker 7:  which is like you cannot just merge data sets without going

469
00:25:45,760 --> 00:25:49,560
Speaker 7:  through us. And he literally said that on a call with a hundred thousand

470
00:25:49,560 --> 00:25:50,880
Speaker 7:  people listening a couple

471
00:25:50,880 --> 00:25:51,240
Speaker 6:  Days ago.

472
00:25:52,030 --> 00:25:55,400
Speaker 1:  Yeah. I mean this is like straightforwardly, the thing Twitter has gotten

473
00:25:55,400 --> 00:25:58,840
Speaker 1:  in trouble for in the past is promising to use people's data one way and

474
00:25:58,840 --> 00:26:02,760
Speaker 1:  then using it another, which would be a huge issue in

475
00:26:02,780 --> 00:26:05,960
Speaker 1:  for any other company and a particularly huge one for Twitter, which has

476
00:26:05,960 --> 00:26:09,880
Speaker 1:  basically signed a thing saying you, you were allowed to destroy us if

477
00:26:09,880 --> 00:26:13,680
Speaker 1:  we do this again. And yet I get, I just keep coming

478
00:26:13,680 --> 00:26:15,880
Speaker 1:  back to this thing that we talk about a lot on this show, which is that Elon

479
00:26:15,880 --> 00:26:18,440
Speaker 1:  Musk believes the rules don't apply to him. Yeah. And has a fair amount of

480
00:26:18,600 --> 00:26:22,080
Speaker 1:  evidence that says that they don't and like the SCC has not stopped him from

481
00:26:22,080 --> 00:26:25,040
Speaker 1:  tweeting whatever the hell he wants overall this time. So like if I'm Elon,

482
00:26:25,040 --> 00:26:28,160
Speaker 1:  I have a lot of evidence that says these government agencies are gonna yell

483
00:26:28,160 --> 00:26:29,840
Speaker 1:  and yell and yell and then I'm gonna get my way.

484
00:26:29,840 --> 00:26:33,680
Speaker 7:  And maybe he thinks that because he took it private, like it

485
00:26:33,680 --> 00:26:37,240
Speaker 7:  doesn't matter. I don't know. Like I'm, I mean

486
00:26:38,060 --> 00:26:41,840
Speaker 7:  I'm just like, is it, is it cuz it's the his like his toy

487
00:26:41,840 --> 00:26:44,960
Speaker 7:  now that he can do whatever he wants with it. I mean I really, I don't get

488
00:26:44,960 --> 00:26:45,120
Speaker 7:  it.

489
00:26:45,470 --> 00:26:49,360
Speaker 5:  What's the over under on his personal lawyer who is clearly

490
00:26:49,360 --> 00:26:53,200
Speaker 5:  calling a lot of like the legal shots, having any knowledge of

491
00:26:53,200 --> 00:26:55,080
Speaker 5:  how an FTC consent decree works.

492
00:26:55,980 --> 00:26:57,240
Speaker 6:  Who knows? Right? Like,

493
00:26:57,240 --> 00:27:00,880
Speaker 5:  Like this is not, but this is not like, you know, usually you have lawyer,

494
00:27:00,880 --> 00:27:03,960
Speaker 5:  like this lawyer sounds like you specialized lawyers. Yeah. Specialized lawyers

495
00:27:03,960 --> 00:27:05,680
Speaker 5:  and this guy's not that and

496
00:27:05,680 --> 00:27:07,160
Speaker 7:  Well they all quit. Yeah.

497
00:27:07,190 --> 00:27:07,680
Speaker 5:  Well

498
00:27:07,810 --> 00:27:11,400
Speaker 7:  So it's interesting his, his lawyer Alex Spiro is also

499
00:27:11,430 --> 00:27:15,320
Speaker 7:  this week representing Megan the stallion in a

500
00:27:15,320 --> 00:27:19,280
Speaker 7:  feud with Drake according to tmz. So he might be busy

501
00:27:19,560 --> 00:27:19,640
Speaker 7:  actually

502
00:27:19,640 --> 00:27:20,440
Speaker 5:  Little busy.

503
00:27:22,280 --> 00:27:25,960
Speaker 6:  He was also just on an NBA podcast about crisis communication. So

504
00:27:25,970 --> 00:27:29,520
Speaker 6:  it was good. I I, you know, I listened to it. Here's my big question about

505
00:27:29,520 --> 00:27:33,040
Speaker 6:  all of this, right? He's not in a fight with the FTC yet. He,

506
00:27:33,430 --> 00:27:37,120
Speaker 6:  I don't know if he's pissed off Twitter users with the blue stuff. I dunno

507
00:27:37,120 --> 00:27:40,080
Speaker 6:  if he's ruin the experience. He's keeps claiming by the way that the numbers

508
00:27:40,080 --> 00:27:43,320
Speaker 6:  are way up. Which is hilarious because he tweeting

509
00:27:44,080 --> 00:27:48,000
Speaker 6:  MDO charts the same charts he said were full of bots when he tried to get

510
00:27:48,000 --> 00:27:51,120
Speaker 6:  out of the deal. So who knows, maybe more bots have been added to Twitter.

511
00:27:51,160 --> 00:27:54,480
Speaker 6:  Can't tell. But he says the numbers are up, usages up. He has driven away

512
00:27:54,480 --> 00:27:57,400
Speaker 6:  a bunch of advertisers. They don't appear likely to come back. Especially

513
00:27:57,400 --> 00:28:00,880
Speaker 6:  if reckless patellas out there just like given Nintendo the bird.

514
00:28:00,950 --> 00:28:03,600
Speaker 6:  Yeah. Seems unlikely that advertisers wanna

515
00:28:03,600 --> 00:28:06,520
Speaker 5:  Be tweeting at Mariah all

516
00:28:06,520 --> 00:28:09,760
Speaker 6:  Day. I mean I would just do that Mariah, if you're out there, that's very

517
00:28:09,760 --> 00:28:11,680
Speaker 6:  awkward Mariah, if you're out there,

518
00:28:13,290 --> 00:28:17,240
Speaker 6:  in fact you would understand. I think she's a verge cast listener. Do you

519
00:28:17,240 --> 00:28:19,640
Speaker 6:  know Mariah really cares about charging standards? Does

520
00:28:19,640 --> 00:28:22,720
Speaker 5:  She? Yeah, I feel, I believe it. I believe it. This is, this is how you guys

521
00:28:22,720 --> 00:28:24,840
Speaker 5:  are gonna meet. This is, this is the connection.

522
00:28:24,840 --> 00:28:28,360
Speaker 6:  She's like USB three gen tube version one. What is that bullshit?

523
00:28:29,200 --> 00:28:30,400
Speaker 6:  She's up this

524
00:28:30,400 --> 00:28:34,040
Speaker 1:  Year. All I want for Christmas is Mariah Carey sneaking up on you in spatial

525
00:28:34,040 --> 00:28:34,280
Speaker 1:  audio.

526
00:28:34,910 --> 00:28:37,560
Speaker 6:  That's all I want in the world. That's the only use for spatial audio. That's

527
00:28:37,560 --> 00:28:40,880
Speaker 6:  Mariah Carey. Anyhow, the advertiser seem extremely wary they're not going

528
00:28:40,880 --> 00:28:44,760
Speaker 6:  back. My question is, Elon's companies are

529
00:28:44,780 --> 00:28:48,520
Speaker 6:  effectively monopolies in their spaces. Like SpaceX

530
00:28:48,520 --> 00:28:52,440
Speaker 6:  in particular, the United States has no other way of going

531
00:28:52,440 --> 00:28:56,040
Speaker 6:  to space. It's SpaceX or the Russian government,

532
00:28:56,140 --> 00:29:00,120
Speaker 6:  the SLS was on the launchpad, a hurricane came by and

533
00:29:00,120 --> 00:29:01,960
Speaker 5:  They're like, Nope, nevermind, nevermind, nevermind.

534
00:29:02,230 --> 00:29:03,560
Speaker 6:  Like it's a permanently

535
00:29:04,200 --> 00:29:06,120
Speaker 5:  Can't get all the way like

536
00:29:06,180 --> 00:29:09,680
Speaker 6:  The, the blue origin rocket lends itself to the most incredible jokes about

537
00:29:09,680 --> 00:29:12,920
Speaker 6:  not being able to go all the way to space. We just gotta set those aside.

538
00:29:12,920 --> 00:29:16,280
Speaker 6:  Yeah. Is SpaceX is the vendor for the United States government. One of the

539
00:29:16,280 --> 00:29:19,040
Speaker 6:  reasons Elon gets away with everything is cuz they got no other

540
00:29:19,760 --> 00:29:23,600
Speaker 6:  choices. Tesla for years only viable electric car

541
00:29:23,600 --> 00:29:27,520
Speaker 6:  company. Right. And you know, people really like the cars and the software

542
00:29:27,520 --> 00:29:28,760
Speaker 6:  experience is great and there's all of that.

543
00:29:28,760 --> 00:29:30,400
Speaker 5:  It's changed the automotive industry.

544
00:29:30,400 --> 00:29:33,800
Speaker 6:  Yeah. Like huge congratulations to the Tesla team. You made this thing happen.

545
00:29:33,940 --> 00:29:37,880
Speaker 6:  But he's in markets where he's the only player next

546
00:29:37,880 --> 00:29:41,720
Speaker 6:  year. You know, I've heard from auto advertisers in particular who are

547
00:29:41,720 --> 00:29:45,560
Speaker 6:  like, well why would we go back to Twitter? Like why would we

548
00:29:45,560 --> 00:29:48,680
Speaker 6:  put our marketing plans on Twitter? Alex was mentioning this last week, I

549
00:29:48,680 --> 00:29:51,800
Speaker 6:  talked to some folks this week. Like that's their vibe. They think Tesla's

550
00:29:51,800 --> 00:29:55,080
Speaker 6:  gonna have to compete against all of these cars that are coming out the next

551
00:29:55,080 --> 00:29:58,560
Speaker 6:  year if they ever come out. Right. But if the auto industry succeeds in actually

552
00:29:58,720 --> 00:30:01,680
Speaker 6:  shipping cars next year, Tesla's in a competitive environment. Yeah. Might

553
00:30:01,680 --> 00:30:05,240
Speaker 6:  have to advertise. Twitter is the only business Elon runs

554
00:30:05,670 --> 00:30:09,320
Speaker 6:  that is not just like a full monopoly. Right. Where

555
00:30:09,340 --> 00:30:13,320
Speaker 6:  his actions might have consequences in a way that he, they can't over

556
00:30:13,320 --> 00:30:16,000
Speaker 6:  can't be overcome because there's no other choices. Yeah.

557
00:30:16,000 --> 00:30:19,560
Speaker 5:  I mean historically he's bought into these companies when they're still

558
00:30:19,920 --> 00:30:23,280
Speaker 5:  barely companies. There are these tiny little things. This is the first time

559
00:30:23,280 --> 00:30:27,000
Speaker 5:  he's like, I'm gonna buy in and own this company that's been chugging along

560
00:30:27,170 --> 00:30:30,760
Speaker 5:  in the public realm for years. And now like

561
00:30:31,030 --> 00:30:34,240
Speaker 5:  I think he's learning some lessons, although I don't think he necessarily

562
00:30:34,240 --> 00:30:35,080
Speaker 5:  wants to admit it.

563
00:30:35,310 --> 00:30:39,240
Speaker 6:  Yeah. I just, there's just a piece of, I mean am I ranting about competition

564
00:30:39,240 --> 00:30:42,240
Speaker 6:  on the vercast? I ranting about competition on the ver chest? There's just

565
00:30:42,240 --> 00:30:45,240
Speaker 6:  a piece of me that says he gets away with it all the time goes, what are

566
00:30:45,240 --> 00:30:48,320
Speaker 6:  you gonna do if you want electric car, not buy a Tesla? What are you gonna

567
00:30:48,320 --> 00:30:51,720
Speaker 6:  do if you wanna put a satellite in the space, not sign up with SpaceX,

568
00:30:51,980 --> 00:30:53,520
Speaker 5:  Get the guys back from space.

569
00:30:53,920 --> 00:30:57,000
Speaker 6:  Like what, what are you gonna do if you want the astronauts back from the

570
00:30:57,000 --> 00:31:00,320
Speaker 6:  space station in your fighting a proxy war with Russia?

571
00:31:00,510 --> 00:31:04,320
Speaker 6:  Well it's one choice. Yeah. So here

572
00:31:04,320 --> 00:31:06,560
Speaker 6:  it's like what are you gonna do if you don't wanna spend money on Twitter

573
00:31:06,610 --> 00:31:10,520
Speaker 6:  in your general Mills? It's like, oh I can just spend money anywhere else.

574
00:31:10,840 --> 00:31:14,560
Speaker 6:  Anywhere. Alex, I wanna, I wanna recapitulate a conversation that you and

575
00:31:14,560 --> 00:31:18,360
Speaker 6:  I have been having like all week. Cause I've been saying if I'm Mark

576
00:31:18,360 --> 00:31:22,320
Speaker 6:  Zuckerberg famously ultra competitive Mark Zuckerberg,

577
00:31:22,500 --> 00:31:24,800
Speaker 6:  I'm like I could just kill Twitter tomorrow,

578
00:31:24,800 --> 00:31:25,160
Speaker 5:  Just

579
00:31:25,160 --> 00:31:28,600
Speaker 6:  Body it. I can just take all those advertising dollars and put them on my

580
00:31:28,720 --> 00:31:32,200
Speaker 6:  platform in some way. And you have been pointing out that that's actually

581
00:31:32,200 --> 00:31:33,120
Speaker 6:  not a huge incentive.

582
00:31:33,230 --> 00:31:37,200
Speaker 7:  Yeah. I mean we'll get into this but like the, the, the people

583
00:31:37,200 --> 00:31:41,160
Speaker 7:  that Zuckerberg laid off, you know, he's probably gonna save Twitter's

584
00:31:41,160 --> 00:31:45,000
Speaker 7:  annual revenue and just like the people he laid off, like we're talking

585
00:31:45,000 --> 00:31:48,280
Speaker 7:  about a scale that is just so much larger

586
00:31:49,940 --> 00:31:53,760
Speaker 7:  and the dollars that are spent on Twitter are the kind of

587
00:31:53,760 --> 00:31:57,640
Speaker 7:  dollars that would flow more to like billboards than

588
00:31:57,640 --> 00:32:01,400
Speaker 7:  they would meta. Right. They're not performance advertisers. Elon even

589
00:32:01,400 --> 00:32:05,160
Speaker 7:  said this in a memo to employees that we reported on the Twitter's

590
00:32:05,360 --> 00:32:09,280
Speaker 7:  advertising base is 70% brand, which is, you

591
00:32:09,280 --> 00:32:12,960
Speaker 7:  know, code for large big brands doing campaigns without a

592
00:32:12,960 --> 00:32:16,520
Speaker 7:  verifiable kind of outcome. Right. Just to spread brand awareness. Those

593
00:32:16,520 --> 00:32:20,360
Speaker 7:  dollars they go other places. They don't necessarily go to search or

594
00:32:20,360 --> 00:32:20,560
Speaker 7:  meta.

595
00:32:20,670 --> 00:32:24,040
Speaker 6:  Wait can we just, I just wanna clarify for the listener what you mean by

596
00:32:24,040 --> 00:32:27,960
Speaker 6:  performance and brand. We, this is our world, right? Versus is like an advertising

597
00:32:27,960 --> 00:32:31,840
Speaker 6:  supported publication. Performance advertising or direct advertising

598
00:32:31,840 --> 00:32:35,160
Speaker 6:  is like search ads. Like you search for a thing, you search for a flight

599
00:32:35,160 --> 00:32:39,120
Speaker 6:  and United Airline shows you a price and you click the button and

600
00:32:39,320 --> 00:32:42,880
Speaker 6:  you're like all the way at the bottom of the advertising funnel where you

601
00:32:42,880 --> 00:32:45,840
Speaker 6:  have like expressed intent to buy something. Yeah. And then they can track

602
00:32:45,840 --> 00:32:49,200
Speaker 6:  that you bought something And the reason it's called performance is cuz that

603
00:32:49,200 --> 00:32:52,040
Speaker 6:  you, the advertising performs, brand advertising is all the way at the other

604
00:32:52,040 --> 00:32:55,720
Speaker 6:  end where you're just, you're just aware that United Airlines

605
00:32:55,720 --> 00:32:56,680
Speaker 6:  exists. Yeah.

606
00:32:56,990 --> 00:32:59,680
Speaker 1:  It's just Matt Damon saying crypto is good. Yeah.

607
00:32:59,880 --> 00:33:03,680
Speaker 6:  Basically that's brand. So all those AWS ads on football or

608
00:33:03,680 --> 00:33:07,600
Speaker 6:  all the weird IT solution vendors ads at the airport. Like when

609
00:33:07,600 --> 00:33:11,440
Speaker 6:  you push on like why they exist. Like is anybody watching an NFL

610
00:33:11,640 --> 00:33:15,440
Speaker 6:  football game? Like I should sign up for aws. Like that's

611
00:33:15,440 --> 00:33:19,400
Speaker 6:  all brand advertising And the reason they all do it is so that when they,

612
00:33:19,550 --> 00:33:23,440
Speaker 6:  when people go to their CIOs or their vendors, there's like a

613
00:33:23,680 --> 00:33:27,480
Speaker 6:  baseline level of familiarity Right. That makes you more inclined

614
00:33:27,480 --> 00:33:29,880
Speaker 6:  to, to do a thing as opposed to being like, I've never heard of ADA

615
00:33:29,880 --> 00:33:33,760
Speaker 5:  And that's why he's concerned about it right now. Yeah. Because we

616
00:33:33,760 --> 00:33:37,200
Speaker 5:  are in a weird economic space and one of the first things to go is, well,

617
00:33:37,200 --> 00:33:40,920
Speaker 5:  do we really need people to be that aware of aws? We're

618
00:33:41,040 --> 00:33:44,760
Speaker 5:  probably good. We can probably cut that budget. Yeah. And I thought that

619
00:33:44,760 --> 00:33:48,520
Speaker 5:  was really interesting that in that letter he sent or that email, whatever

620
00:33:48,520 --> 00:33:52,160
Speaker 5:  it was he sent, he was like, we're getting 50% of it here. We need

621
00:33:52,160 --> 00:33:56,120
Speaker 5:  50% or more of our revenue from Twitter,

622
00:33:56,190 --> 00:33:57,520
Speaker 5:  blue subscriptions,

623
00:33:57,520 --> 00:33:58,200
Speaker 6:  Subscriptions.

624
00:33:58,420 --> 00:34:01,840
Speaker 5:  You need to make billions of dollars on Twitter. Blue

625
00:34:01,840 --> 00:34:03,800
Speaker 5:  subscriptions is basically what he's saying.

626
00:34:04,050 --> 00:34:06,960
Speaker 6:  Oh, so you think they're, they're close to making Twitter bank's what, four

627
00:34:06,960 --> 00:34:10,840
Speaker 6:  or 5 billion a year? Are they gonna make two and a half billion in

628
00:34:10,840 --> 00:34:11,880
Speaker 6:  $8 Twitter blue subscriptions

629
00:34:12,010 --> 00:34:15,880
Speaker 7:  If they up the price to what Musk originally wanted before Stephen King

630
00:34:16,120 --> 00:34:20,000
Speaker 7:  got involved maybe I will note it. I

631
00:34:20,000 --> 00:34:23,880
Speaker 7:  will note that the $8 a month is labeled as an introductory price.

632
00:34:23,880 --> 00:34:25,440
Speaker 7:  I do think he has every intention to raise

633
00:34:25,440 --> 00:34:26,360
Speaker 6:  The price. Yeah.

634
00:34:26,430 --> 00:34:26,920
Speaker 5:  Next

635
00:34:26,920 --> 00:34:29,280
Speaker 1:  Week. I noticed that too. I thought that was interesting. But I would just

636
00:34:29,280 --> 00:34:32,240
Speaker 1:  say one more thought on the, the meta thing. Like let's not forget that Mark

637
00:34:32,240 --> 00:34:35,880
Speaker 1:  Zuckerberg literally rebranded his company because he wanted to get away

638
00:34:35,880 --> 00:34:38,920
Speaker 1:  from dealing with all of the nonsense that comes with running a social network.

639
00:34:38,920 --> 00:34:42,880
Speaker 1:  Like nobody knows better the perils of running Twitter than Mark Zuckerberg.

640
00:34:43,160 --> 00:34:47,080
Speaker 1:  And he and he like dude decided he wanted no part of it and he doesn't

641
00:34:47,080 --> 00:34:49,720
Speaker 1:  talk about it anymore. He doesn't answer questions about it anymore. He's

642
00:34:49,720 --> 00:34:53,320
Speaker 1:  like, have you heard about legs? Yeah. And avatars. Let's talk about that.

643
00:34:53,380 --> 00:34:56,960
Speaker 1:  And it's like, even if Facebook could and thought it was interesting

644
00:34:57,070 --> 00:35:00,160
Speaker 1:  monetarily to kill Twitter, which it obviously doesn't. It's just

645
00:35:01,040 --> 00:35:04,240
Speaker 1:  everyone who has been through this has discovered the gigantic headache that

646
00:35:04,240 --> 00:35:07,320
Speaker 1:  it is trying to do this. This is why nobody bought Twitter in the past because

647
00:35:07,320 --> 00:35:10,720
Speaker 1:  people kept kicking the tires and kept going, Oh this is a shit show. We

648
00:35:10,720 --> 00:35:14,560
Speaker 1:  want no part of this. And and it took Elon Musk like putting

649
00:35:14,560 --> 00:35:17,720
Speaker 1:  his hand on the stove to figure out that oh actually everybody was right

650
00:35:17,720 --> 00:35:18,080
Speaker 1:  the whole time.

651
00:35:18,250 --> 00:35:21,880
Speaker 7:  Oh and guys, since we are just, you know, we're doing this in real time,

652
00:35:22,030 --> 00:35:25,920
Speaker 7:  it's Twitter, everything is changing at all times. I'm now getting pings

653
00:35:25,920 --> 00:35:29,880
Speaker 7:  that UL Roth Twitter's head of trust and safety that Elon has

654
00:35:29,880 --> 00:35:33,760
Speaker 7:  elevated in the last couple weeks is on the way out. Unclear if

655
00:35:33,760 --> 00:35:37,680
Speaker 7:  it was because he was forced out or voluntarily resigned.

656
00:35:37,680 --> 00:35:40,800
Speaker 7:  This is the guy that was on the call with advertisers. The on his set is

657
00:35:40,800 --> 00:35:44,640
Speaker 7:  the one he trusts to implement his content moderation policies.

658
00:35:45,440 --> 00:35:46,240
Speaker 7:  And UL is now,

659
00:35:46,410 --> 00:35:50,280
Speaker 6:  He was the face, he was the one sent out to say the content policies

660
00:35:50,280 --> 00:35:54,040
Speaker 6:  haven't changed. I've decreased hate speech on the platform. He's

661
00:35:54,040 --> 00:35:57,560
Speaker 6:  tweeting charts the charts by the way. He's like here's charts of hates school

662
00:35:57,560 --> 00:36:00,960
Speaker 6:  speech. And it's like that's a chart of people tweeting the N-word. I just

663
00:36:00,960 --> 00:36:04,720
Speaker 6:  want be clear when you say this is a chart of tweets with slurs

664
00:36:04,810 --> 00:36:08,200
Speaker 6:  in it, this is how often people tweet the n Oh

665
00:36:08,200 --> 00:36:12,120
Speaker 7:  My god. Oh my god. Yeah. I'm sorry. The head of I just, we

666
00:36:12,120 --> 00:36:15,560
Speaker 7:  gotta just have this in the pod cuz it's all gonna be out by the time Robin

667
00:36:15,560 --> 00:36:19,440
Speaker 7:  Wheeler, the head of advertising has also left who was on the call with Elon

668
00:36:19,440 --> 00:36:23,360
Speaker 7:  the other day talking to advertisers. Yeah. That he just made, he just put

669
00:36:23,360 --> 00:36:27,000
Speaker 7:  her in charge of all ads and marketing and she's also

670
00:36:27,000 --> 00:36:27,360
Speaker 7:  leaving

671
00:36:27,360 --> 00:36:30,120
Speaker 1:  With you all. So that, just to put a point on this, there was a Bloomberg

672
00:36:30,120 --> 00:36:33,960
Speaker 1:  story this morning that named those two people as two of the three

673
00:36:33,960 --> 00:36:37,440
Speaker 1:  most important people at Twitter who he had decided were like his inner circle

674
00:36:37,440 --> 00:36:41,000
Speaker 1:  who were ascending to be leaders of the company. That's two of the three

675
00:36:41,000 --> 00:36:44,520
Speaker 6:  Names. This is the danger, the people who know how Twitter works, who have

676
00:36:44,520 --> 00:36:48,480
Speaker 6:  the relationships with the customers who understand the complexity

677
00:36:48,480 --> 00:36:51,840
Speaker 6:  of content moderation, they're all looking at this and saying this isn't

678
00:36:51,840 --> 00:36:52,240
Speaker 6:  worth it.

679
00:36:52,550 --> 00:36:53,040
Speaker 5:  Yeah.

680
00:36:53,330 --> 00:36:57,080
Speaker 6:  There's a part of me that feels bad for

681
00:36:57,320 --> 00:37:01,200
Speaker 6:  Elon Musk. Like he wakes up every day and this is

682
00:37:01,200 --> 00:37:05,000
Speaker 6:  the loneliest place you can be. And his only release

683
00:37:05,370 --> 00:37:09,080
Speaker 6:  is tweeting clown emojis at Tom Warren. With Tom Warren

684
00:37:09,210 --> 00:37:12,960
Speaker 6:  is like, look at how bad Twitter verification is going. Like

685
00:37:13,740 --> 00:37:17,600
Speaker 6:  I'm not, it's not a lot of pity. Yeah. But like

686
00:37:17,800 --> 00:37:19,880
Speaker 6:  the walls are just closing in. Well

687
00:37:19,880 --> 00:37:22,720
Speaker 5:  I wonder if he recognizes that because we were also seeing him this week

688
00:37:22,720 --> 00:37:26,360
Speaker 5:  tweet like yeah, our our our average user base is growing.

689
00:37:26,360 --> 00:37:29,640
Speaker 5:  Right? So like maybe in his head it's like well, you know,

690
00:37:30,010 --> 00:37:33,800
Speaker 5:  at least one important number still go up. We still good. Yeah.

691
00:37:33,800 --> 00:37:37,680
Speaker 1:  He's been saying this a lot that like, you know, it's, it's messy but

692
00:37:37,680 --> 00:37:41,440
Speaker 1:  it's at least it's interesting and it's like, okay, that's all well and

693
00:37:41,440 --> 00:37:44,400
Speaker 1:  good Elon and and it is certainly interesting like

694
00:37:45,330 --> 00:37:48,680
Speaker 1:  it is our audience is interested in it, we're interested in it. The internet

695
00:37:48,680 --> 00:37:52,520
Speaker 1:  is interested in it. Like I, I was at, I was at a doctor's appointment this

696
00:37:52,520 --> 00:37:55,240
Speaker 1:  morning and we talked about what Elon Musk is doing to Twitter. Like this

697
00:37:55,240 --> 00:37:58,880
Speaker 1:  is, this is a captivating thing. But then there comes a minute

698
00:37:58,880 --> 00:38:01,800
Speaker 1:  where Elon Musk has to pay a billion dollar interest payment

699
00:38:02,530 --> 00:38:06,360
Speaker 1:  to make this money work and it's just not

700
00:38:06,800 --> 00:38:09,960
Speaker 1:  interesting. Doesn't eventually pay the bills here and it, it looks like

701
00:38:09,960 --> 00:38:13,480
Speaker 1:  all the money is walking away even if the thing is more interesting from

702
00:38:13,480 --> 00:38:14,120
Speaker 1:  day to day.

703
00:38:14,350 --> 00:38:18,000
Speaker 6:  Here's the thing that's gonna really get Elon in trouble. A fake Taylor Swift

704
00:38:18,000 --> 00:38:21,120
Speaker 6:  account just tweeted that her tour is canceled and it has 5,000

705
00:38:21,120 --> 00:38:25,040
Speaker 5:  Likes and oh God, she pissed off the BTS

706
00:38:25,040 --> 00:38:25,280
Speaker 5:  fans.

707
00:38:25,910 --> 00:38:26,840
Speaker 6:  It's all over

708
00:38:26,840 --> 00:38:30,240
Speaker 5:  Man. The BTS army is mad now you got the swifties mad.

709
00:38:30,530 --> 00:38:34,240
Speaker 5:  We gotta get the, I believe they're called the lamb blaze. That's your people

710
00:38:34,580 --> 00:38:38,520
Speaker 5:  Eli. Hmm. The lambs. That's what, that's what Mariah calls her

711
00:38:38,520 --> 00:38:38,720
Speaker 5:  fans.

712
00:38:38,900 --> 00:38:39,960
Speaker 6:  The lamb blaze

713
00:38:40,020 --> 00:38:42,640
Speaker 5:  The lamb like family but lambs

714
00:38:42,800 --> 00:38:46,600
Speaker 6:  Right. There's a limit to my Mariah fandom and it really ended with,

715
00:38:47,330 --> 00:38:49,880
Speaker 6:  we found how very single I was when I was a teenager.

716
00:38:51,530 --> 00:38:54,320
Speaker 6:  There's a little box right? My just like fandom.

717
00:38:54,590 --> 00:38:56,040
Speaker 5:  I don't know this and I don't

718
00:38:56,040 --> 00:38:58,640
Speaker 6:  Want to again and end with the heartbreaker video. That's all I'm saying.

719
00:38:59,600 --> 00:39:02,440
Speaker 1:  Yeah, that sounds right. But like this has been happening like there was

720
00:39:02,440 --> 00:39:06,240
Speaker 1:  a fake LeBron James who tweeted requesting a trade that that

721
00:39:06,240 --> 00:39:09,280
Speaker 1:  became a whole thing. Like this is just, this is gonna happen over and over

722
00:39:09,280 --> 00:39:12,560
Speaker 1:  and over again. And it sounds like basically there are somewhere between

723
00:39:12,830 --> 00:39:16,600
Speaker 1:  zero and four people at Twitter who are just like manually chasing this

724
00:39:16,600 --> 00:39:19,880
Speaker 1:  around the platform trying to delete stuff as it goes and it's like this

725
00:39:19,880 --> 00:39:23,600
Speaker 1:  just isn't gonna work. Yeah. And it's gonna get so much worse

726
00:39:23,770 --> 00:39:24,400
Speaker 1:  so quickly

727
00:39:24,790 --> 00:39:28,600
Speaker 5:  You're seeing other companies dunk on it. I think both Tumblr

728
00:39:28,780 --> 00:39:32,720
Speaker 5:  and Sub Stack, neither company doing terrifically well have both

729
00:39:32,720 --> 00:39:35,920
Speaker 5:  announced that they're now doing Blue Check marks Tumblr's offering you two

730
00:39:35,920 --> 00:39:36,840
Speaker 5:  for the price of one.

731
00:39:37,010 --> 00:39:40,640
Speaker 1:  We, we should not put those two in the same category because sub stack is

732
00:39:40,640 --> 00:39:44,120
Speaker 1:  like doing this very earnest thing where they're like, Twitter sucks, we

733
00:39:44,120 --> 00:39:48,080
Speaker 1:  are your great home and our check marks represent actual writer success

734
00:39:48,080 --> 00:39:50,720
Speaker 1:  on the platform and Tumblr just like give us eight bucks, we'll give you

735
00:39:50,720 --> 00:39:52,880
Speaker 1:  two check marks. They don't mean anywhere. It's very good. Fuck you. And

736
00:39:52,880 --> 00:39:53,040
Speaker 1:  it's

737
00:39:53,040 --> 00:39:56,880
Speaker 6:  Amazing. It's very good. Sorry I'm also catching up on the

738
00:39:56,880 --> 00:40:00,840
Speaker 6:  you off news. I mean it is crazy. I'm just gonna read

739
00:40:00,840 --> 00:40:03,200
Speaker 6:  this tweet from Casey and then we gotta take a break because we can't keep

740
00:40:03,200 --> 00:40:06,200
Speaker 6:  talking about Twitter in this moment of flux. Like

741
00:40:06,780 --> 00:40:10,160
Speaker 6:  I'm just gonna read this tweet Casey right now the timeline kind of feels

742
00:40:10,160 --> 00:40:14,000
Speaker 6:  like the day the Lamas escaped except this time the LLAs are loose at

743
00:40:14,000 --> 00:40:16,720
Speaker 6:  Twitter headquarters and are trying to shut the company down.

744
00:40:17,630 --> 00:40:21,320
Speaker 6:  That's it is incredible how much all of this platform

745
00:40:21,320 --> 00:40:25,200
Speaker 6:  has turned its gaze inwards and it's just washing the company

746
00:40:25,600 --> 00:40:28,680
Speaker 6:  collapse. Yep. I don't know what's going to happen next. Heath. I don't think

747
00:40:28,680 --> 00:40:30,640
Speaker 6:  you know what's gonna, Do you know what's gonna happen next? Cuz it would

748
00:40:30,640 --> 00:40:31,000
Speaker 6:  be really helpful

749
00:40:31,250 --> 00:40:34,960
Speaker 7:  To say it. I, I don't know. I mean this FTC thing may

750
00:40:34,960 --> 00:40:38,920
Speaker 7:  sink the company because my understanding is the people who are being

751
00:40:38,920 --> 00:40:42,880
Speaker 7:  asked to self-certify product launches and code at

752
00:40:42,880 --> 00:40:46,760
Speaker 7:  the risk of facing possible jail time are all quitting. So everyone on like

753
00:40:46,760 --> 00:40:50,520
Speaker 7:  the security and privacy team under the executives who who left

754
00:40:50,520 --> 00:40:54,160
Speaker 7:  are all kind of quitting together. And so I don't know what

755
00:40:54,180 --> 00:40:57,760
Speaker 7:  how much of a company he's gonna have left next week, to be perfectly honest.

756
00:40:58,150 --> 00:40:59,040
Speaker 5:  Even tomorrow.

757
00:40:59,550 --> 00:41:00,040
Speaker 6:  Yeah.

758
00:41:00,040 --> 00:41:00,840
Speaker 7:  Or tomorrow. And

759
00:41:00,860 --> 00:41:04,440
Speaker 6:  And we should say we have not talked about the technology of Twitter very

760
00:41:04,440 --> 00:41:08,240
Speaker 6:  much on our tech podcast. Twitter is starting to subtly break in weird

761
00:41:08,240 --> 00:41:12,080
Speaker 6:  ways like follower accounts have gone up. The retweet button was

762
00:41:12,080 --> 00:41:13,320
Speaker 6:  doing manual retreats for a

763
00:41:13,320 --> 00:41:17,160
Speaker 7:  While. I should note because this happened because Twitter had a code

764
00:41:17,160 --> 00:41:20,440
Speaker 7:  freeze in place until the day after the midterms when they launched Blue

765
00:41:20,440 --> 00:41:23,480
Speaker 7:  where basically you couldn't push anything through production unless you

766
00:41:23,480 --> 00:41:27,360
Speaker 7:  got VP approval. And that lifted Wednesday evening and I'm

767
00:41:27,360 --> 00:41:30,800
Speaker 7:  told that once that lifted, it was kind of like all hell broke loose and

768
00:41:30,800 --> 00:41:34,560
Speaker 7:  now that the site can be changed, you're seeing all this dramatic stuff

769
00:41:34,560 --> 00:41:38,000
Speaker 7:  with what the lawyer sent and all these resignations because everyone's realizing

770
00:41:38,000 --> 00:41:41,840
Speaker 7:  like, oh when Elon actually has the keys and can make changes, this

771
00:41:41,840 --> 00:41:42,440
Speaker 7:  is what happens.

772
00:41:42,730 --> 00:41:45,680
Speaker 6:  Oh boy. All right. We gotta stop talking about Twitter because literally

773
00:41:45,680 --> 00:41:49,520
Speaker 6:  the more we talk about it, the more we summon chaos. Yeah.

774
00:41:49,520 --> 00:41:53,000
Speaker 6:  More people are leaving invalidates everything we just said. We'll see what

775
00:41:53,160 --> 00:41:55,040
Speaker 6:  happened. We're obviously gonna talk about next week, we gotta take a break,

776
00:41:55,310 --> 00:41:58,480
Speaker 6:  come back. Heath is gonna walk us through what's going on at Meow, which

777
00:41:58,480 --> 00:42:02,280
Speaker 6:  is going through equal chaos. But I would say in a

778
00:42:02,280 --> 00:42:05,200
Speaker 6:  more controlled way. Yeah, we'll be right back.

779
00:44:35,570 --> 00:44:39,540
Speaker 6:  Okay, we're back. I've struggled to keep all these stories apart in

780
00:44:39,540 --> 00:44:43,500
Speaker 6:  my head. Like Twitter, chaos, meta chaos, ftx, chaos, collapse,

781
00:44:43,500 --> 00:44:46,780
Speaker 6:  chaos. Just across the board. Let's talk about meta though.

782
00:44:47,050 --> 00:44:50,700
Speaker 6:  11,000 people let go. A very different tone from Mark

783
00:44:50,700 --> 00:44:54,140
Speaker 6:  Zuckerberg and letting those folks go. Very generous terms. He wasn't like

784
00:44:54,140 --> 00:44:57,380
Speaker 6:  your all audience by the way, we should note that in the all hands that Elon

785
00:44:57,380 --> 00:45:00,740
Speaker 6:  just had. He said that even after the 50% layoffs, Twitter still

786
00:45:00,740 --> 00:45:04,460
Speaker 6:  overstaffed, which just cannot be motivating for the people who

787
00:45:04,460 --> 00:45:06,060
Speaker 6:  remain meta in a very different place.

788
00:45:06,330 --> 00:45:09,260
Speaker 1:  Elon also said if you're physically able to come to the office and you don't

789
00:45:09,260 --> 00:45:13,060
Speaker 1:  resignation accepted, which is a pretty bull

790
00:45:13,060 --> 00:45:16,940
Speaker 1:  like I think starting like today was the, he told me yesterday and it was

791
00:45:16,940 --> 00:45:20,860
Speaker 1:  starting today was the end of their remote work policy. So yeah,

792
00:45:20,860 --> 00:45:24,780
Speaker 1:  I would say Mark Zuckerberg handled this significantly more gracefully is

793
00:45:24,940 --> 00:45:25,700
Speaker 1:  probably the word I would use.

794
00:45:25,700 --> 00:45:28,940
Speaker 6:  And strange to me in the timeline where Mark Zuckerberg is the revered older

795
00:45:28,940 --> 00:45:32,540
Speaker 6:  statesman of tech. But here we we're, right? Alex walk, What's going on with

796
00:45:32,540 --> 00:45:32,860
Speaker 6:  Meow?

797
00:45:32,890 --> 00:45:36,380
Speaker 7:  Sure. Let's contrast this quickly at the top. So Twitter

798
00:45:36,380 --> 00:45:40,140
Speaker 7:  layoffs were unsigned emails, no message from Elon, very

799
00:45:40,140 --> 00:45:44,020
Speaker 7:  terse also like potentially violating the war Act TBD on that

800
00:45:44,220 --> 00:45:48,060
Speaker 7:  about minimum severance you could offer. And meow by

801
00:45:48,340 --> 00:45:52,140
Speaker 7:  contrast, it's a lot of people. So this is the largest tech

802
00:45:52,140 --> 00:45:55,860
Speaker 7:  company layoff to date. One of the largest I think ever. It actually may

803
00:45:55,860 --> 00:45:59,380
Speaker 7:  be the largest ever. It's 13% of the company, over

804
00:45:59,380 --> 00:46:03,340
Speaker 7:  11,000 people. And the way this happened was Mark gathered all the

805
00:46:03,460 --> 00:46:07,180
Speaker 7:  directors and VPs the day before on a call where I'm told he was very

806
00:46:07,740 --> 00:46:11,460
Speaker 7:  remorseful looking like kind of hazy eyed and took responsibility.

807
00:46:11,620 --> 00:46:15,460
Speaker 7:  Which you know you can laugh at that, right? Cuz it's like billionaire

808
00:46:15,460 --> 00:46:18,860
Speaker 7:  Co takes responsibility. What does that actually look like? But said like

809
00:46:18,860 --> 00:46:22,820
Speaker 7:  this was my fault. I thought that the trends we saw during Covid where

810
00:46:22,820 --> 00:46:26,140
Speaker 7:  there was a pull forward as all these tech executives were talking about

811
00:46:26,230 --> 00:46:30,100
Speaker 7:  in people's online activity, commerce, et cetera, people thought

812
00:46:30,100 --> 00:46:33,940
Speaker 7:  this was going to, and I kept hearing this at the time too, I'm sure Eli

813
00:46:33,940 --> 00:46:37,100
Speaker 7:  and others did too. All these tech executives were saying during Covid like

814
00:46:37,100 --> 00:46:40,780
Speaker 7:  this has pulled forward 10 years of growth in a matter of

815
00:46:40,980 --> 00:46:43,940
Speaker 7:  18 months. And Zuckerberg said on this call with kind of management that

816
00:46:43,940 --> 00:46:47,740
Speaker 7:  he expected that growth to sustain and to not you know, retreat.

817
00:46:47,760 --> 00:46:51,740
Speaker 7:  And certainly I guess no one expected J Powell to just raise rates

818
00:46:51,740 --> 00:46:55,500
Speaker 7:  the way he did and that certainly affected everyone. And then the

819
00:46:55,500 --> 00:46:59,460
Speaker 7:  following day, you know, emails start going out and Mark actually gets on

820
00:46:59,460 --> 00:47:03,380
Speaker 7:  a call with everyone who was laid off kind of reiterates again there was

821
00:47:03,380 --> 00:47:06,940
Speaker 7:  video of this that leaked. Looks like he's basically tearing up, said thank

822
00:47:06,940 --> 00:47:10,500
Speaker 7:  you guys so much. He's giving everyone four months of severance and

823
00:47:10,850 --> 00:47:14,780
Speaker 7:  it's just couldn't be handled, you know, differently. But in terms of

824
00:47:14,780 --> 00:47:18,620
Speaker 7:  like the impact to meta, I think what's been interesting based on my

825
00:47:18,620 --> 00:47:21,700
Speaker 7:  conversations with employees and including some who were laid off, is that

826
00:47:21,860 --> 00:47:25,100
Speaker 7:  everyone was kind of shocked at how sporadic these cuts were because over

827
00:47:25,100 --> 00:47:28,780
Speaker 7:  the summer Meta has been doing quiet layoffs. Essentially they asked

828
00:47:28,960 --> 00:47:32,360
Speaker 7:  managers to build lists of bottom performers, about

829
00:47:32,360 --> 00:47:36,240
Speaker 7:  10%, 10 to 15% of their team, which matches the layoffs that they

830
00:47:36,240 --> 00:47:39,800
Speaker 7:  just did that need support. And they were also, they had frozen

831
00:47:40,280 --> 00:47:43,720
Speaker 7:  internal transfers, they had frozen external hiring. There had been a real

832
00:47:43,720 --> 00:47:47,400
Speaker 7:  ramp up in attrition and everyone thought that these layoffs would just hit

833
00:47:47,400 --> 00:47:51,280
Speaker 7:  those people on that need support list. And instead I'm hearing about

834
00:47:51,640 --> 00:47:54,640
Speaker 7:  directors and AI people working on the AR glasses

835
00:47:55,280 --> 00:47:58,840
Speaker 7:  areas that you wouldn't necessarily expect that are still key bets.

836
00:47:58,840 --> 00:48:02,560
Speaker 7:  Obviously some stuff that that you would expect. Like meta had like almost

837
00:48:02,560 --> 00:48:05,520
Speaker 7:  7,000 recruiters. So that word got

838
00:48:05,840 --> 00:48:09,440
Speaker 7:  decimated. And also in marketing and some of those other areas,

839
00:48:09,920 --> 00:48:13,640
Speaker 7:  comms pretty hit hard but it wasn't like really

840
00:48:13,640 --> 00:48:17,480
Speaker 7:  focused on I would say reality labs with the metaverse division

841
00:48:17,480 --> 00:48:21,080
Speaker 7:  that everyone's saying he needs to be cutting on as much as it was kind of

842
00:48:21,080 --> 00:48:24,960
Speaker 7:  spread randomly throughout hitting senior and low level people. And what

843
00:48:24,960 --> 00:48:28,640
Speaker 7:  I heard was they didn't wanna focus it on one org because they didn't

844
00:48:28,830 --> 00:48:32,760
Speaker 7:  want their that to breed resentment in the company. Oh my god. Or

845
00:48:32,760 --> 00:48:36,240
Speaker 7:  getting hit more than the other, even though Reality Labs everyone

846
00:48:36,240 --> 00:48:39,640
Speaker 7:  acknowledges internally is very bloated, it has over

847
00:48:39,640 --> 00:48:43,280
Speaker 7:  25,000 people. This is the part of the company that makes Horizon,

848
00:48:43,480 --> 00:48:47,440
Speaker 7:  which I wrote the VP is having a hard time even getting the people building

849
00:48:47,440 --> 00:48:51,120
Speaker 7:  it to use and Horizon has a thousand people on it

850
00:48:51,260 --> 00:48:54,840
Speaker 7:  and this isn't a product that has like maybe 150,000

851
00:48:54,840 --> 00:48:55,680
Speaker 7:  users. Well

852
00:48:55,680 --> 00:48:58,360
Speaker 6:  We should wait, we should talk about that for one minute cuz we haven't published

853
00:48:58,360 --> 00:49:01,960
Speaker 6:  our Quest Pro review yet. We will just,

854
00:49:02,350 --> 00:49:05,600
Speaker 6:  it's been a very busy week but Addie's working on that review, it's going

855
00:49:05,600 --> 00:49:08,720
Speaker 6:  up. We're working on the video. Alex, you have a Quest Pro. I have a Quest

856
00:49:08,720 --> 00:49:12,000
Speaker 6:  Pro. A Quest Pro. We've tried now several times to hang out in both Horizon

857
00:49:12,000 --> 00:49:15,200
Speaker 6:  work rooms, which is the Metaverse conference room

858
00:49:15,280 --> 00:49:19,120
Speaker 6:  situation and Horizon Worlds, which is the

859
00:49:19,900 --> 00:49:23,720
Speaker 6:  the fun one. It's bad. And I'm just gonna offer

860
00:49:23,720 --> 00:49:27,560
Speaker 6:  you this one snippet of a moment not to totally tease this from you.

861
00:49:27,560 --> 00:49:31,520
Speaker 6:  I don't wanna spoil it. Too bad. You, you should probably tell from the tone

862
00:49:31,520 --> 00:49:32,000
Speaker 6:  of my voice,

863
00:49:32,130 --> 00:49:32,880
Speaker 5:  Oh I'm ready.

864
00:49:33,810 --> 00:49:37,480
Speaker 6:  We, we, Alex was, Alex Heath was trying to join me

865
00:49:37,480 --> 00:49:40,760
Speaker 6:  and Addie in work rooms and he couldn't get on it just like didn't work.

866
00:49:40,760 --> 00:49:44,400
Speaker 6:  So then he invited us into his world in

867
00:49:44,400 --> 00:49:46,720
Speaker 6:  Horizon worlds and so he beam in there,

868
00:49:47,330 --> 00:49:47,880
Speaker 5:  No legs

869
00:49:47,980 --> 00:49:51,280
Speaker 6:  And no legs and suddenly we are

870
00:49:51,600 --> 00:49:55,480
Speaker 6:  surrounded by the sound of teen boys saying there's a

871
00:49:55,480 --> 00:49:58,400
Speaker 6:  girl on the server. Oh boy, there's a girl here.

872
00:49:58,530 --> 00:49:59,200
Speaker 5:  Oh no.

873
00:49:59,780 --> 00:50:02,640
Speaker 6:  And then they said ask her if she's over 18.

874
00:50:03,580 --> 00:50:06,920
Speaker 6:  And then dozens of avatars ran across.

875
00:50:07,130 --> 00:50:09,320
Speaker 5:  So just Xbox in 2002.

876
00:50:10,410 --> 00:50:14,400
Speaker 6:  It was like terrifying. And the funniest part about this was we

877
00:50:14,400 --> 00:50:18,200
Speaker 6:  don't even know if that was Addie, cause Addie, you hear

878
00:50:18,200 --> 00:50:20,040
Speaker 6:  her clearly talking to someone else.

879
00:50:20,450 --> 00:50:23,840
Speaker 7:  It was pure chaos And it's just like imagine, you know,

880
00:50:23,840 --> 00:50:27,600
Speaker 7:  scrolling through Twitter but in 3D where you're embodied and

881
00:50:27,600 --> 00:50:28,320
Speaker 7:  it's a bunch of people

882
00:50:28,320 --> 00:50:31,920
Speaker 5:  Yelling, I don't want that. Is there a girl on the platform?

883
00:50:32,450 --> 00:50:33,720
Speaker 5:  Is she over aging? I

884
00:50:33,720 --> 00:50:37,600
Speaker 6:  Mean it was, it was like instance after we like I hit the button to

885
00:50:37,600 --> 00:50:41,560
Speaker 6:  Beam to where Alex was just like dozens of of boys,

886
00:50:41,710 --> 00:50:45,560
Speaker 6:  like teen boy voices being like there's a girl, she's the only

887
00:50:45,760 --> 00:50:46,760
Speaker 6:  girl on the server.

888
00:50:46,940 --> 00:50:50,600
Speaker 5:  You don't see that as often as you used to cuz like early internet days you'd

889
00:50:50,600 --> 00:50:54,400
Speaker 5:  be like, I'm a girl. And oh no, it was those

890
00:50:54,500 --> 00:50:57,640
Speaker 5:  AOL chat rooms got spicy for this 12 year old girl,

891
00:50:58,500 --> 00:51:02,400
Speaker 5:  but but like you don't see it as often now, so it's like woo.

892
00:51:02,670 --> 00:51:04,320
Speaker 5:  Yeah, that's, that's something.

893
00:51:04,350 --> 00:51:07,280
Speaker 6:  Yeah, there's no, I don't think there's a button in the metaverse that lets

894
00:51:07,280 --> 00:51:11,080
Speaker 6:  you type asl, but that's, it was very much that vibe.

895
00:51:11,080 --> 00:51:14,800
Speaker 6:  So I won't give away the whole thing, but like it's a lot of money going

896
00:51:14,800 --> 00:51:18,080
Speaker 6:  towards an experience that I would say is not very good at this point in

897
00:51:18,080 --> 00:51:21,320
Speaker 6:  time. Yeah, but Alex you're saying they didn't cut reality labs

898
00:51:21,450 --> 00:51:25,240
Speaker 6:  because they didn't want the reality labs people to be resentful

899
00:51:25,240 --> 00:51:26,440
Speaker 6:  of Instagram or

900
00:51:26,760 --> 00:51:30,480
Speaker 7:  Whatever? No, I just, I'm saying throughout the company the

901
00:51:30,480 --> 00:51:34,400
Speaker 7:  cuts were relatively spread because they

902
00:51:34,400 --> 00:51:37,560
Speaker 7:  didn't want certain teams and there were, to be clear, there were some product

903
00:51:37,560 --> 00:51:41,440
Speaker 7:  teams that got hit a lot harder. There was actually still a remnant

904
00:51:41,440 --> 00:51:44,680
Speaker 7:  of a consumer smartwatch team trying to figure out if their meadow was gonna

905
00:51:44,680 --> 00:51:45,720
Speaker 7:  do a consumer smartwatch,

906
00:51:47,520 --> 00:51:50,600
Speaker 7:  which I didn't even know. Are they still, there was still, No, that team

907
00:51:50,600 --> 00:51:54,520
Speaker 7:  got really sacked, so Oh, there were some teams that got hit

908
00:51:54,520 --> 00:51:58,320
Speaker 7:  hard, but in terms of where the cuts were spread throughout all of

909
00:51:58,320 --> 00:52:01,800
Speaker 7:  meta, it was fairly distributed and that was on purpose to not breed

910
00:52:01,800 --> 00:52:02,360
Speaker 7:  resentment.

911
00:52:02,590 --> 00:52:03,080
Speaker 6:  Yeah.

912
00:52:03,270 --> 00:52:07,080
Speaker 1:  Well and I also think it's, it's kind of emblematic of this

913
00:52:07,280 --> 00:52:11,160
Speaker 1:  impossible position that meta is in and that Mark Zuckerberg continues

914
00:52:11,160 --> 00:52:15,120
Speaker 1:  to put himself in, which is that everybody wants him to pull

915
00:52:15,120 --> 00:52:18,200
Speaker 1:  back on the metaverse bets and start investing in the stuff that actually

916
00:52:18,200 --> 00:52:21,960
Speaker 1:  makes the company money. But he is now so all in pot

917
00:52:21,960 --> 00:52:24,520
Speaker 1:  committed to the idea that the metaverse is the future of the company. That

918
00:52:24,520 --> 00:52:27,600
Speaker 1:  he almost can't afford to like retrench on that and be like, Okay, actually

919
00:52:27,600 --> 00:52:30,240
Speaker 1:  we need to focus on the stuff that makes us the money. We'll worry about

920
00:52:30,240 --> 00:52:32,680
Speaker 1:  that someday in the future. Like then you inspire a whole different kind

921
00:52:32,680 --> 00:52:36,600
Speaker 1:  of panic. Like he has to project confidence in this idea

922
00:52:36,600 --> 00:52:40,560
Speaker 1:  that he has sort of loudly bet the company on even as it

923
00:52:40,560 --> 00:52:44,200
Speaker 1:  sort of systematically destroys the company. Yeah, yeah. And it's, I don't

924
00:52:44,200 --> 00:52:45,360
Speaker 1:  know how you navigate that.

925
00:52:45,550 --> 00:52:49,480
Speaker 7:  Well, I just wanna be careful that yeah this is super precarious for

926
00:52:49,480 --> 00:52:52,320
Speaker 7:  him. Obviously, like they're losing a lot of money and investors don't believe

927
00:52:52,320 --> 00:52:56,160
Speaker 7:  in this mission at the same time. Like this is not Twitter, like meta

928
00:52:56,170 --> 00:52:59,840
Speaker 7:  is wildly profitable. They did like 5 billion in profit last

929
00:53:00,050 --> 00:53:03,640
Speaker 7:  quarter. So it's a very, this last quarter different situation that

930
00:53:04,390 --> 00:53:08,200
Speaker 7:  said, I think the cuts put meta back to where it was like less than a year

931
00:53:08,200 --> 00:53:12,000
Speaker 7:  ago. Like this company has hired so much that was that

932
00:53:12,120 --> 00:53:15,920
Speaker 7:  feature featuring Gary from Chicago, you know, rest in peace salute

933
00:53:15,920 --> 00:53:19,440
Speaker 7:  that David, you and I wrote over the summer where

934
00:53:19,540 --> 00:53:23,480
Speaker 7:  like men have hired like 40% headcount growth

935
00:53:23,480 --> 00:53:27,320
Speaker 7:  during the pandemic all remotely. So they went from like 30 ish

936
00:53:27,560 --> 00:53:31,240
Speaker 7:  thousand pre pandemic to like 87,000 now

937
00:53:31,240 --> 00:53:34,920
Speaker 7:  and the offices are empty, you know, so it's like people are still working

938
00:53:34,920 --> 00:53:38,520
Speaker 7:  remote and it's just, it's this, I think bigger story

939
00:53:38,520 --> 00:53:42,360
Speaker 7:  that's, we've seen across tech of these companies thought that the

940
00:53:43,040 --> 00:53:46,600
Speaker 7:  punch bowl that they were giving during Covid would never be taken away.

941
00:53:46,700 --> 00:53:50,560
Speaker 7:  And they're all realizing very forcefully and frighteningly

942
00:53:50,560 --> 00:53:54,360
Speaker 7:  at the same time that it's totally gone and they're left out, you know? But

943
00:53:54,360 --> 00:53:58,040
Speaker 7:  what does Buffet say? Like if, if when the tide come comes back in, you get

944
00:53:58,040 --> 00:54:00,480
Speaker 7:  to see who's swimming naked. So that's like what's happening right now.

945
00:54:00,990 --> 00:54:04,520
Speaker 1:  I was just gonna say, this is a thing I've heard from a bunch of people over

946
00:54:04,520 --> 00:54:06,800
Speaker 1:  time and it's been really interesting to track this over the last like six

947
00:54:06,800 --> 00:54:09,440
Speaker 1:  months cuz there was like we've been talking about, there was this moment

948
00:54:09,440 --> 00:54:12,320
Speaker 1:  where basically for two years everybody was like, okay, we have essentially

949
00:54:12,320 --> 00:54:16,160
Speaker 1:  fast forwarded a decade into the future. Yeah. And that growth is gonna keep

950
00:54:16,160 --> 00:54:19,160
Speaker 1:  going. This stuff is never going back. We're all gonna order groceries and

951
00:54:19,160 --> 00:54:22,240
Speaker 1:  have them delivered. We're all gonna hang out in the metaverse, Zoom is the

952
00:54:22,240 --> 00:54:25,880
Speaker 1:  future, all this stuff. And then there was this period after that where everybody

953
00:54:25,880 --> 00:54:28,800
Speaker 1:  was like, okay, we've made all these changes but maybe the pace from here

954
00:54:28,800 --> 00:54:32,280
Speaker 1:  isn't gonna be quite as fast as we thought. So everybody sort of slowed down

955
00:54:32,280 --> 00:54:35,720
Speaker 1:  a little bit. And more recently I've started talking to people who are like,

956
00:54:35,720 --> 00:54:39,400
Speaker 1:  Oh my God, we're just going back to 2019. Yes. Like all of the stuff that

957
00:54:39,560 --> 00:54:43,120
Speaker 1:  happened is now being sort of systematically undone as people go back to

958
00:54:43,120 --> 00:54:46,240
Speaker 1:  work and back to the ways that they were doing things before now that they

959
00:54:46,240 --> 00:54:49,240
Speaker 1:  could. And so like not only are we not moving forward as fast, we're actually

960
00:54:49,240 --> 00:54:52,680
Speaker 1:  going backwards. And to me that's one of the things that has really like

961
00:54:52,680 --> 00:54:55,800
Speaker 1:  combined that with all the macroeconomic stuff and all of these companies

962
00:54:55,800 --> 00:54:59,600
Speaker 1:  have gone like, Oh my God, we are no longer anywhere near

963
00:55:00,160 --> 00:55:03,160
Speaker 1:  actually set up to be the kind of company we need to be to succeed right

964
00:55:03,160 --> 00:55:06,440
Speaker 1:  now. And it's just, it, everybody is sort of feeling that crunch

965
00:55:06,840 --> 00:55:08,680
Speaker 1:  simultaneously, which has been really interesting to hear about.

966
00:55:08,680 --> 00:55:12,480
Speaker 6:  Yeah, I think we, we talked about this a lot on the vergecast, which is there

967
00:55:12,480 --> 00:55:15,680
Speaker 6:  the first order pandemic effects in like the second order ones.

968
00:55:16,180 --> 00:55:19,880
Speaker 6:  And like my favorite second order effect is everyone cares more about their

969
00:55:19,880 --> 00:55:23,800
Speaker 6:  webcams. Like does Maca West continuity cam and that little be

970
00:55:23,800 --> 00:55:27,480
Speaker 6:  mount exist if not for the global Covid pandemic? No,

971
00:55:27,480 --> 00:55:30,720
Speaker 6:  definitely not. Right? Like, no, everyone had to care about it. So we care

972
00:55:30,720 --> 00:55:34,160
Speaker 6:  about it and now there's like an entire category of of AI powered webcams

973
00:55:34,160 --> 00:55:36,960
Speaker 6:  that exist and that's like a hilarious second order effect. The problem is

974
00:55:37,160 --> 00:55:40,720
Speaker 6:  everyone overestimated the first order effects. Yeah. And the way that like

975
00:55:40,720 --> 00:55:44,520
Speaker 6:  tech people, computer people often do, which is, oh my gosh, you've moved

976
00:55:44,520 --> 00:55:48,440
Speaker 6:  all of your stuff to this computer platform, it's so much faster and

977
00:55:48,440 --> 00:55:52,320
Speaker 6:  more efficient. Why would you ever go back to the old way? And it turns out

978
00:55:52,320 --> 00:55:55,920
Speaker 6:  the old way of doing lots of things has benefits as well.

979
00:55:55,990 --> 00:55:58,080
Speaker 6:  Like, like I, it's, it's not

980
00:55:58,080 --> 00:56:01,720
Speaker 1:  Well the answer is cuz schools are open again, right? Like that's, they,

981
00:56:01,720 --> 00:56:02,800
Speaker 1:  they let us go back to school.

982
00:56:03,080 --> 00:56:06,320
Speaker 6:  I was on CNBC the other day and we were talking about the gaming companies

983
00:56:06,320 --> 00:56:08,680
Speaker 6:  and their earnings and the way that you do on cnbc and they sent me a bunch

984
00:56:08,680 --> 00:56:12,360
Speaker 6:  of research to prepare and one of them was a note from Jeff's about Roblox

985
00:56:12,360 --> 00:56:16,320
Speaker 6:  earnings and the analyst note was we expect Roblox to be soft at

986
00:56:16,320 --> 00:56:20,240
Speaker 6:  the end of the year because the kids are in school and it was just like dead

987
00:56:20,240 --> 00:56:21,240
Speaker 1:  Ahead. Literally. That's like

988
00:56:21,260 --> 00:56:25,200
Speaker 6:  The kids are in school and when they're in the classroom they cannot be

989
00:56:25,200 --> 00:56:29,040
Speaker 6:  playing Roblox. Right. And it turns out that for two years kids at

990
00:56:29,040 --> 00:56:32,080
Speaker 6:  school, at home were kind of playing Roblox on the side

991
00:56:32,700 --> 00:56:35,640
Speaker 6:  and like that's just reality for so many of these companies. And I think

992
00:56:35,640 --> 00:56:39,280
Speaker 6:  it's, the thing with Meta though is they didn't

993
00:56:39,280 --> 00:56:42,840
Speaker 6:  launch a bunch of pandemic products. They

994
00:56:42,840 --> 00:56:46,120
Speaker 6:  hired a lot of people for coming shifts and I think

995
00:56:46,120 --> 00:56:50,000
Speaker 6:  Zuckerberg's view was, everyone's at home on their computer now this

996
00:56:50,000 --> 00:56:53,760
Speaker 6:  is the right time to make a face computer. So your whole life is the computer

997
00:56:53,760 --> 00:56:57,560
Speaker 6:  all the time. Yeah. Because I think he was running head first into

998
00:56:57,560 --> 00:57:01,320
Speaker 6:  app tracking transparency and 30% platform

999
00:57:01,320 --> 00:57:05,160
Speaker 6:  fees and all this other stuff and he was like, I have to make a new platform

1000
00:57:05,540 --> 00:57:09,520
Speaker 6:  for the coming change and the new platform. Again, not to spoil

1001
00:57:09,520 --> 00:57:13,040
Speaker 6:  our review, I think they probably should have just kept that one on the shelf.

1002
00:57:13,110 --> 00:57:17,080
Speaker 6:  Yeah, it's really bad. I mean it's, it's, I think

1003
00:57:17,080 --> 00:57:20,760
Speaker 6:  Addie said that Addie said Horizon is like the worst software

1004
00:57:20,760 --> 00:57:24,560
Speaker 6:  experience she's ever had, like ever. Which, yeah,

1005
00:57:24,590 --> 00:57:28,040
Speaker 6:  I mean I, I mean I do think the hardware

1006
00:57:28,570 --> 00:57:32,520
Speaker 6:  is, you can see the quality, you can see the, the design and that

1007
00:57:32,520 --> 00:57:36,160
Speaker 6:  they clearly have a lot of X apple people there and they,

1008
00:57:36,160 --> 00:57:39,760
Speaker 6:  they, I think they did an okay job with the hardware. It's just the software

1009
00:57:39,970 --> 00:57:43,920
Speaker 6:  is so atrocious on this thing. And yes, there were Meta

1010
00:57:43,920 --> 00:57:47,840
Speaker 6:  Quest Pro employees and engineers laid off like this

1011
00:57:47,840 --> 00:57:51,720
Speaker 6:  is a product that just shipped and I think just goes to show like kind of

1012
00:57:51,720 --> 00:57:55,680
Speaker 6:  how in disarray this whole strategy is. Yeah. So we'll see.

1013
00:57:55,710 --> 00:57:59,440
Speaker 6:  I mean, again, I don't think that there has been a really

1014
00:57:59,440 --> 00:58:02,680
Speaker 6:  definitive review of the Quest Pro yet. There's a reason we're taking a lot

1015
00:58:02,680 --> 00:58:05,960
Speaker 6:  of time with ours, I think to make some of the claims you're gonna make,

1016
00:58:05,960 --> 00:58:08,960
Speaker 6:  you gotta take a lot of time. Yep. That review will come out. But I think

1017
00:58:09,290 --> 00:58:13,200
Speaker 6:  it will put a pin, I think on this era of meta in a way that the layoffs

1018
00:58:13,380 --> 00:58:17,040
Speaker 6:  are putting a pin on this era of meta and really this era of tech. Like

1019
00:58:17,050 --> 00:58:20,200
Speaker 6:  Apple's doing a hiring freeze. I would expect Google to be doing some sort

1020
00:58:20,200 --> 00:58:23,760
Speaker 6:  of changes soon. We were just seeing it across the tech industry. Right.

1021
00:58:23,760 --> 00:58:26,120
Speaker 6:  We gotta take a break. We're gonna come back. We're gonna talk about one

1022
00:58:26,120 --> 00:58:30,080
Speaker 6:  more disaster. Alex, I think you're, you're not second with us, right?

1023
00:58:30,190 --> 00:58:33,840
Speaker 6:  I think you gotta, you gotta go do some reporting. I, All

1024
00:58:35,640 --> 00:58:38,680
Speaker 6:  right. Alex is gonna go and figure out what's going on with Twitter. We'll

1025
00:58:38,680 --> 00:58:40,720
Speaker 6:  be back. David's gonna take us through ftx. We'll be right back.

1026
00:58:46,280 --> 00:58:49,620
Speaker 9:  Hey, it's Kenny man. This is a promotion of Haman. The Kenny Mane talks to

1027
00:58:49,620 --> 00:58:53,580
Speaker 9:  famous people podcast. We got lots of famous people, Dan Patrick and

1028
00:58:53,580 --> 00:58:56,260
Speaker 9:  Keith Overman. We gotta work 99% of what we

1029
00:58:56,260 --> 00:59:00,220
Speaker 10:  Tried to do. I'm mad at him because I know that he'll regret it, but I

1030
00:59:00,220 --> 00:59:01,340
Speaker 10:  know that he has to leave.

1031
00:59:01,680 --> 00:59:05,340
Speaker 9:  Sue Bird is involved. Re's Chapman, Dan Levard, Katie

1032
00:59:05,500 --> 00:59:09,380
Speaker 9:  Nolan, Allison Becker, Sorry for all the others I interviewed who I

1033
00:59:09,380 --> 00:59:12,660
Speaker 9:  left out. Oh yeah, Solo O'Brien. She was good. Get it on the Odyssey app

1034
00:59:12,910 --> 00:59:14,300
Speaker 9:  or wherever you get your podcast.

1035
00:59:16,310 --> 00:59:20,180
Speaker 11:  Support for this episode comes from brx, the corporate card and

1036
00:59:20,180 --> 00:59:24,040
Speaker 11:  spend management software teams actually love. If you're a CFO

1037
00:59:24,170 --> 00:59:27,480
Speaker 11:  or finance leader today, you know we are operating in

1038
00:59:27,480 --> 00:59:31,320
Speaker 11:  transformational times. It can be hard getting people all in the same

1039
00:59:31,320 --> 00:59:35,280
Speaker 11:  place and not over another Zoom call now more than

1040
00:59:35,280 --> 00:59:38,760
Speaker 11:  ever before. You need to help build a connection with not only your team

1041
00:59:38,860 --> 00:59:42,240
Speaker 11:  but with your clientele in real life. Thankfully

1042
00:59:42,580 --> 00:59:46,400
Speaker 11:  brx can help. BR is an integrated solution of corporate cards

1043
00:59:46,400 --> 00:59:50,120
Speaker 11:  and span management software that drives 100% compliance

1044
00:59:50,120 --> 00:59:53,920
Speaker 11:  and zero receipt chasing in over 100 countries. Brx

1045
00:59:53,920 --> 00:59:57,760
Speaker 11:  is easy to set up and easy to use with dedicated implementation

1046
00:59:58,080 --> 01:00:01,960
Speaker 11:  software and intuitive consumer great design and the brx mobile

1047
01:00:01,960 --> 01:00:05,840
Speaker 11:  app. And if you ever need support, you can always reach out by phone

1048
01:00:05,860 --> 01:00:09,840
Speaker 11:  app or chat twenty four seven. It's that simple.

1049
01:00:09,840 --> 01:00:13,760
Speaker 11:  Brx makes it easy to manage every aspect of spending from the

1050
01:00:13,810 --> 01:00:17,560
Speaker 11:  smallest purchases to the biggest procurements. No matter where your team

1051
01:00:17,560 --> 01:00:21,480
Speaker 11:  works, they help empower employees to do the right thing and

1052
01:00:21,500 --> 01:00:25,400
Speaker 11:  spend responsibly and compliance is built in. So with everything

1053
01:00:25,400 --> 01:00:28,920
Speaker 11:  from restaurants to retail stores to your work platform, all going

1054
01:00:29,200 --> 01:00:33,000
Speaker 11:  cloud based, isn't it time for your company to use a spend management solution

1055
01:00:33,000 --> 01:00:36,240
Speaker 11:  for modern times? Learn more at brx.com/podcast.

1056
01:00:40,940 --> 01:00:43,840
Speaker 6:  All right, we're back. Let's see if we can do this quickly. David,

1057
01:00:44,400 --> 01:00:48,280
Speaker 6:  alongside all of the social media disasters, there's a giant

1058
01:00:48,280 --> 01:00:50,000
Speaker 6:  crypto exchange called ftx.

1059
01:00:50,420 --> 01:00:50,840
Speaker 1:  Yes.

1060
01:00:50,840 --> 01:00:54,640
Speaker 6:  Which just ate itself this week. What, what happened?

1061
01:00:55,790 --> 01:00:59,560
Speaker 1:  That's, it's a pretty solid description actually. So, okay. The, the piece

1062
01:00:59,560 --> 01:01:03,520
Speaker 1:  of context that is useful to understand here is that Sam Bankman Freed,

1063
01:01:03,520 --> 01:01:07,280
Speaker 1:  who is the CEO of ftx, which is one of the biggest crypto exchanges and

1064
01:01:07,290 --> 01:01:10,480
Speaker 1:  there's ftx.com and there's ftx.us,

1065
01:01:10,920 --> 01:01:14,840
Speaker 1:  ftx.us is a separate thing that is also potentially falling apart. But

1066
01:01:14,840 --> 01:01:17,840
Speaker 1:  for the purposes of this, we are not going to be talking about ftx us. Is

1067
01:01:17,840 --> 01:01:18,360
Speaker 11:  It also an

1068
01:01:18,520 --> 01:01:18,680
Speaker 6:  Exchange?

1069
01:01:18,850 --> 01:01:21,840
Speaker 1:  It is also an exchange and that is the one the people in the US actually

1070
01:01:21,840 --> 01:01:25,600
Speaker 1:  use. But basically because a lot of people are confused

1071
01:01:25,780 --> 01:01:29,320
Speaker 1:  and or mad at crypto rules, a lot of people run their crypto stuff

1072
01:01:29,680 --> 01:01:32,040
Speaker 1:  offshore. Okay. So that is a thing that has been happening and that is what

1073
01:01:32,040 --> 01:01:35,800
Speaker 1:  ftx.com is Sam Banque free, the CEO of FTX has been,

1074
01:01:36,110 --> 01:01:39,680
Speaker 1:  I would, I think beefing is like a fair way to describe it with

1075
01:01:39,960 --> 01:01:43,520
Speaker 1:  Cheang, the CEO of Binance, which is the largest crypto exchange.

1076
01:01:43,650 --> 01:01:47,280
Speaker 1:  So they've been fighting for various reasons over time.

1077
01:01:47,300 --> 01:01:51,040
Speaker 1:  And FTX has been on this crazy run during the crypto downturn of

1078
01:01:51,040 --> 01:01:54,840
Speaker 1:  basically just buying everything it could find, right? Like they

1079
01:01:54,840 --> 01:01:57,480
Speaker 1:  definitely seem to sort of sense that this was a moment to gain market share

1080
01:01:57,480 --> 01:02:01,160
Speaker 1:  and win in a big way. But all of this is to say basically this week bin

1081
01:02:02,560 --> 01:02:05,840
Speaker 1:  specifically started a huge run on

1082
01:02:06,140 --> 01:02:09,520
Speaker 1:  the token that FTX gives out, which is called ftt.

1083
01:02:09,560 --> 01:02:13,200
Speaker 1:  Basically they, they decided they didn't want own any of it anymore and sold

1084
01:02:13,200 --> 01:02:16,360
Speaker 1:  a gigantic amount of it all at once. Very publicly, very loudly announced

1085
01:02:16,360 --> 01:02:20,320
Speaker 1:  that they were doing this. And when somebody like the CEO of Binance decides

1086
01:02:20,320 --> 01:02:24,120
Speaker 1:  to do this and when they sell this much, the price goes down. So

1087
01:02:24,120 --> 01:02:26,360
Speaker 1:  the price goes down, which means more people wanna withdraw, which means

1088
01:02:26,360 --> 01:02:29,080
Speaker 1:  the price goes down further, which means more people wanna withdraw. This

1089
01:02:29,080 --> 01:02:32,360
Speaker 1:  is what they call a run on the bank. Yes. So this now becomes a gigantic

1090
01:02:32,680 --> 01:02:36,520
Speaker 1:  disaster. And then it turns out that FTX didn't have the money to

1091
01:02:36,520 --> 01:02:39,800
Speaker 1:  pay all the people who wanted to get their money out, which

1092
01:02:40,170 --> 01:02:43,880
Speaker 1:  is a problem for a lot of very complicated reasons. But if you don't have

1093
01:02:43,880 --> 01:02:47,400
Speaker 1:  people's money to give them, that's generally considered to be a problem.

1094
01:02:47,930 --> 01:02:51,720
Speaker 1:  So there was a minute where FTX was going

1095
01:02:51,720 --> 01:02:55,680
Speaker 1:  to be sold to Binance and Binance was gonna essentially take it over

1096
01:02:55,680 --> 01:02:59,560
Speaker 1:  in an effort to give customers their money back and sort of make all of

1097
01:02:59,560 --> 01:03:03,360
Speaker 1:  them whole while swallowing ftx.com Binance,

1098
01:03:03,790 --> 01:03:07,720
Speaker 1:  from what we can tell, basically did like six minutes of due diligence went,

1099
01:03:07,720 --> 01:03:11,560
Speaker 1:  Oh my God, this is so much worse than we thought. Nevermind, we're at,

1100
01:03:11,560 --> 01:03:14,040
Speaker 1:  we're out, we're not doing this. And again, announces this very publicly

1101
01:03:14,040 --> 01:03:17,800
Speaker 1:  makes a statement about how essentially saying like, FTX sucks so bad, we

1102
01:03:17,800 --> 01:03:21,320
Speaker 1:  don't even want to buy it for $1. Like we're out.

1103
01:03:21,460 --> 01:03:24,640
Speaker 1:  And then over the course of the last 24 hours, it has come out that basically

1104
01:03:25,100 --> 01:03:28,920
Speaker 1:  the most egregiously wrong thing that FTX did

1105
01:03:28,920 --> 01:03:32,400
Speaker 1:  was use the money that people had invested to fund its own trading

1106
01:03:32,670 --> 01:03:36,560
Speaker 1:  with this separate firm called Alameda that was basically

1107
01:03:36,560 --> 01:03:40,440
Speaker 1:  a hedge fund using FTX assets. So now

1108
01:03:40,440 --> 01:03:43,560
Speaker 1:  it has come out that FTX was using customer money to do its own trading.

1109
01:03:43,750 --> 01:03:47,480
Speaker 1:  Crypto goes down, that trading doesn't work, so you don't have the money

1110
01:03:47,480 --> 01:03:51,080
Speaker 1:  to give back to people, it just spins outta control, right? Like money, money

1111
01:03:51,080 --> 01:03:54,800
Speaker 1:  goes down, everything falls apart. And so now what it basically looks like

1112
01:03:54,800 --> 01:03:58,680
Speaker 1:  is sandbank free, the CEO is out trying to get somewhere in the

1113
01:03:58,680 --> 01:04:02,560
Speaker 1:  range of nine and a half billion just to like

1114
01:04:02,560 --> 01:04:05,560
Speaker 1:  make customers whole and make this work. And And

1115
01:04:05,560 --> 01:04:09,360
Speaker 5:  By work you mean pay all those people because no one wants to invest in

1116
01:04:09,360 --> 01:04:09,560
Speaker 5:  that

1117
01:04:09,560 --> 01:04:13,280
Speaker 1:  Now. Yeah. So essentially what I mean I think if he can't make

1118
01:04:13,520 --> 01:04:17,040
Speaker 1:  customers whole and then shut his company down, it's gonna get much worse

1119
01:04:17,040 --> 01:04:20,360
Speaker 1:  for him. Yeah, right. There's like, this gets very ugly when people can't

1120
01:04:20,360 --> 01:04:23,200
Speaker 1:  get their money out and right now those people can't get their money out

1121
01:04:23,200 --> 01:04:26,920
Speaker 1:  because it literally doesn't exist. And so he, he has explored a bunch of

1122
01:04:26,920 --> 01:04:30,640
Speaker 1:  different avenues. There are other crypto people who are like, oh, turn your

1123
01:04:30,640 --> 01:04:34,600
Speaker 1:  crypto into our crypto for very expensive exchanges and that's

1124
01:04:34,600 --> 01:04:38,520
Speaker 1:  a disaster. So it's like scams on top of scams on top of scams and it,

1125
01:04:38,520 --> 01:04:42,160
Speaker 1:  it seems like at the end of this FTX and Sam Freed was like

1126
01:04:42,660 --> 01:04:46,280
Speaker 1:  the crypto guy. Yeah. Right. Like he's on billboards in San Francisco. He's

1127
01:04:46,280 --> 01:04:48,760
Speaker 1:  like, he is the face of crypto in a very real way. He was a

1128
01:04:48,760 --> 01:04:50,480
Speaker 6:  Cover of Forbes or Fortune.

1129
01:04:50,550 --> 01:04:53,240
Speaker 1:  Yeah. Like recently. And this is, this is all

1130
01:04:53,750 --> 01:04:57,640
Speaker 1:  absolutely just crashing around him and I

1131
01:04:57,640 --> 01:05:01,320
Speaker 1:  don't know exactly how it's gonna end, but it seems very unlikely that

1132
01:05:01,380 --> 01:05:04,680
Speaker 1:  FTX continues to be a thing for much longer after this.

1133
01:05:05,110 --> 01:05:08,800
Speaker 5:  Does this just kind of like prove that

1134
01:05:08,870 --> 01:05:12,120
Speaker 5:  a lot of crypto not the, the underlying technology blockchain is cool?

1135
01:05:13,850 --> 01:05:16,720
Speaker 5:  Is it Blockchain is like the technology has,

1136
01:05:16,960 --> 01:05:20,160
Speaker 1:  Blockchain is a thing that exists. It's a thing that's like the most I'm

1137
01:05:20,160 --> 01:05:20,760
Speaker 1:  willing to give you for

1138
01:05:20,760 --> 01:05:24,400
Speaker 5:  Sure. And I feel like it could be cool when not used in a

1139
01:05:24,940 --> 01:05:27,560
Speaker 5:  multibillion dollar pyramid scheme,

1140
01:05:28,840 --> 01:05:31,520
Speaker 5:  which is like, that's what this is. Like everything you're saying, I'm like,

1141
01:05:31,520 --> 01:05:35,400
Speaker 5:  that's just like the time it's, I gave money to get an Xbox to

1142
01:05:35,680 --> 01:05:39,160
Speaker 5:  someone online. I didn't get my Xbox, I lost

1143
01:05:39,160 --> 01:05:40,640
Speaker 5:  $40. It's

1144
01:05:40,640 --> 01:05:44,160
Speaker 1:  Less pyramid scheme and more Ponzi scheme. Okay. In the sense that I'm gonna

1145
01:05:44,160 --> 01:05:47,800
Speaker 1:  take your money and I'm gonna do some stuff with it and then I'm gonna take

1146
01:05:47,800 --> 01:05:51,080
Speaker 1:  someone else's money and give it to you while I'm still doing the stuff.

1147
01:05:51,080 --> 01:05:53,800
Speaker 1:  And then at the end all of us are gonna be so rich that you're not even gonna

1148
01:05:53,800 --> 01:05:56,840
Speaker 1:  be worried about it. Except then crypto goes down.

1149
01:05:56,840 --> 01:05:58,440
Speaker 5:  So real Bernie Madoff energy.

1150
01:05:58,440 --> 01:05:58,600
Speaker 6:  Yeah.

1151
01:05:59,120 --> 01:06:03,000
Speaker 1:  Super Bernie Madoff energy, unintentional Bernie Madoff thing is like, is

1152
01:06:03,000 --> 01:06:04,360
Speaker 1:  that a thing? Can you like accidentally,

1153
01:06:04,770 --> 01:06:08,400
Speaker 6:  He just lied to everyone. He was very intentionally doing this. So Sam

1154
01:06:08,400 --> 01:06:12,200
Speaker 6:  Bankman freed Sbf as people know, like the profiles are

1155
01:06:12,200 --> 01:06:15,480
Speaker 6:  glowing and he was the one in like the halls of Congress

1156
01:06:16,150 --> 01:06:20,080
Speaker 6:  pitching the regulation. So you gotta change the laws to the

1157
01:06:20,080 --> 01:06:23,840
Speaker 6:  reason there's FTX and ftx US is cuz Fdx does riskier

1158
01:06:23,840 --> 01:06:27,440
Speaker 6:  trades than are allowed in the United States. There's a real thing. Yeah.

1159
01:06:27,440 --> 01:06:31,040
Speaker 6:  Yeah. So he's like running around saying they should be crypto regulation

1160
01:06:31,040 --> 01:06:34,240
Speaker 6:  and he should allow me to do these kinds of trades. And the crypto industry

1161
01:06:34,240 --> 01:06:34,520
Speaker 6:  has a

1162
01:06:36,280 --> 01:06:39,560
Speaker 6:  pretty conflicted relationship with him. They didn't like the bills he was

1163
01:06:39,730 --> 01:06:43,320
Speaker 6:  proposing. There's, there's like a medium chance he just got taken down

1164
01:06:43,320 --> 01:06:45,120
Speaker 6:  for proposing crypto regulations that would've,

1165
01:06:45,300 --> 01:06:45,880
Speaker 5:  But also

1166
01:06:45,880 --> 01:06:47,200
Speaker 6:  Because his own position

1167
01:06:47,330 --> 01:06:48,640
Speaker 5:  He was doing a Ponzi

1168
01:06:48,640 --> 01:06:50,400
Speaker 6:  But also the, I mean there's that element for

1169
01:06:50,400 --> 01:06:51,400
Speaker 5:  Sure. Yeah, yeah. Well

1170
01:06:51,400 --> 01:06:54,520
Speaker 1:  But also the, the this, this is why I bring up the beefing that's been going

1171
01:06:54,520 --> 01:06:58,320
Speaker 1:  on between Sam and Angia, the CEO of Binance. Like Sam

1172
01:06:58,320 --> 01:07:01,960
Speaker 1:  did this whole long tweet thread basically apologizing for

1173
01:07:02,320 --> 01:07:06,240
Speaker 1:  being horrible and making a lot of horrendously bad decisions and

1174
01:07:06,240 --> 01:07:09,640
Speaker 1:  like to some extent took, you know, acknowledged all the stuff that he did

1175
01:07:09,640 --> 01:07:12,560
Speaker 1:  wrong and the mistakes that they made and all this stuff. But then at the

1176
01:07:12,560 --> 01:07:15,800
Speaker 1:  very end was basically like, you know, I don't wanna, I don't wanna pick

1177
01:07:15,800 --> 01:07:19,720
Speaker 1:  fights but like I think the last thing was like you did it, You

1178
01:07:19,720 --> 01:07:23,280
Speaker 1:  won. Which is like very clearly directed at

1179
01:07:24,280 --> 01:07:28,240
Speaker 1:  who just like cemented his own place and bins power

1180
01:07:28,240 --> 01:07:31,400
Speaker 1:  in this industry by sort of systematically destroying a competitor.

1181
01:07:31,400 --> 01:07:34,960
Speaker 5:  Yeah, I think he said, I think he said, and I don't wanna like name any names

1182
01:07:34,960 --> 01:07:38,760
Speaker 5:  here, but you won and everybody's like, okay it's it's finance. It's obvious

1183
01:07:38,760 --> 01:07:41,440
Speaker 6:  Though it's not this and let's talk about the most important part. FTX ran

1184
01:07:41,440 --> 01:07:43,680
Speaker 6:  a lot of ads. They ran a Superbowl ad,

1185
01:07:44,070 --> 01:07:45,280
Speaker 5:  They own a stadium,

1186
01:07:45,280 --> 01:07:46,640
Speaker 6:  They own a stadium, they

1187
01:07:46,640 --> 01:07:50,360
Speaker 1:  Own a bunch of stadiums, like hundreds of millions of dollars of right steals

1188
01:07:50,360 --> 01:07:53,520
Speaker 1:  that FTX has has paid for some of them I think in crypto.

1189
01:07:53,520 --> 01:07:57,480
Speaker 6:  Can we just skip to the important part of this, which is the FTX did a

1190
01:07:57,480 --> 01:08:01,400
Speaker 6:  lot of advertising. Yeah. Like a lot of advertising they

1191
01:08:01,400 --> 01:08:03,840
Speaker 6:  owned I think that Miami Heat Play and FTX Arena,

1192
01:08:03,840 --> 01:08:06,160
Speaker 5:  Right? They got a lot of arenas. Tons.

1193
01:08:06,350 --> 01:08:10,320
Speaker 6:  They did a super ad. It's like the super A is like just Tom Brady

1194
01:08:10,320 --> 01:08:13,040
Speaker 6:  calling people and being like, are you in? And it's like an escalating series

1195
01:08:13,040 --> 01:08:14,000
Speaker 6:  of famous people. You know,

1196
01:08:14,810 --> 01:08:18,520
Speaker 1:  My favorite is that Major League baseball umpires wear an FTX logo

1197
01:08:18,730 --> 01:08:20,960
Speaker 1:  on their uniform. Sure.

1198
01:08:21,810 --> 01:08:24,680
Speaker 6:  So Tom Brady and Giselle have an equity deal,

1199
01:08:25,590 --> 01:08:29,000
Speaker 6:  they own a huge chunk of FTX and they poured like some significant

1200
01:08:29,190 --> 01:08:32,480
Speaker 6:  amount of their net worth into it. We don't know how much, but they were

1201
01:08:32,480 --> 01:08:35,320
Speaker 6:  like on the record being like, we're bit big on ftx.

1202
01:08:35,320 --> 01:08:38,680
Speaker 5:  Well they just, they just finalized their divorce and I wonder if part of

1203
01:08:38,680 --> 01:08:41,440
Speaker 5:  it was Giselle was like, you take all the crypto holdings

1204
01:08:42,070 --> 01:08:42,560
Speaker 1:  Cash,

1205
01:08:42,560 --> 01:08:45,720
Speaker 5:  You're taking the crypto. So she's just sitting there being like, Wow man,

1206
01:08:45,720 --> 01:08:46,600
Speaker 5:  suck to be you.

1207
01:08:46,940 --> 01:08:50,080
Speaker 6:  Let me just read from this press release a seven times Super Bowl champion

1208
01:08:50,080 --> 01:08:53,480
Speaker 6:  and one of the greatest athletes of all time. Tom is a natural fit in his

1209
01:08:53,480 --> 01:08:57,120
Speaker 6:  new role as ambassador for ftx. Given that the platform has quickly

1210
01:08:57,120 --> 01:09:00,800
Speaker 6:  risen to be one of the leading exchanges worldwide. The first part of that

1211
01:09:00,960 --> 01:09:03,600
Speaker 6:  sentence and the second part of that sentence have nothing to do with each

1212
01:09:03,600 --> 01:09:07,360
Speaker 6:  other. Nothing being the greatest athlete

1213
01:09:07,360 --> 01:09:08,880
Speaker 6:  in the world. That's nothing. I'm

1214
01:09:08,880 --> 01:09:10,480
Speaker 5:  A great writer. That means I'll play football.

1215
01:09:11,210 --> 01:09:13,520
Speaker 6:  There's a lot of that on the Verge cast this week.

1216
01:09:14,500 --> 01:09:18,360
Speaker 1:  Can we rec con deflate gate to be about the lowering

1217
01:09:18,360 --> 01:09:21,240
Speaker 1:  price of crypto instead of about footballs? Do you think we can

1218
01:09:21,240 --> 01:09:25,000
Speaker 6:  Do that somehow? Giselle was named the environmental and Social

1219
01:09:25,000 --> 01:09:28,320
Speaker 6:  Initiatives advisor to the Crypto Exchange. Oh

1220
01:09:28,320 --> 01:09:28,600
Speaker 5:  Wow.

1221
01:09:29,060 --> 01:09:32,320
Speaker 6:  And she talks about how much she cares about the environment in the context

1222
01:09:32,320 --> 01:09:36,280
Speaker 6:  for crypto investment. I'm fairly convinced and there's like a lot

1223
01:09:36,280 --> 01:09:38,720
Speaker 6:  of Tom Brady noise. He's gotta play football for the rest of his life now

1224
01:09:38,720 --> 01:09:40,640
Speaker 5:  Forever. That's he, he can never

1225
01:09:40,670 --> 01:09:44,280
Speaker 6:  Stop. He's he's gonna be hustling Gatorade and like whatever

1226
01:09:44,280 --> 01:09:45,160
Speaker 6:  forever. Now

1227
01:09:45,160 --> 01:09:47,920
Speaker 5:  People are like not gonna tackle him at some point cuz they're like I don't

1228
01:09:47,920 --> 01:09:48,720
Speaker 5:  wanna break his bones.

1229
01:09:48,910 --> 01:09:49,960
Speaker 6:  Yeah. We just,

1230
01:09:50,270 --> 01:09:54,040
Speaker 1:  It's also, this is perfect proof of the long

1231
01:09:54,040 --> 01:09:57,920
Speaker 1:  running thesis that as soon as a company puts its

1232
01:09:57,920 --> 01:10:00,920
Speaker 1:  name on a sports stadium, you can assume that that company is about to fall

1233
01:10:00,920 --> 01:10:04,800
Speaker 1:  apart. Yes. Yeah. Like it just, it it is, it has never not been

1234
01:10:04,800 --> 01:10:08,760
Speaker 1:  true and like blessings to fdx it. It continues to be true.

1235
01:10:08,840 --> 01:10:09,760
Speaker 1:  Kudos to everybody.

1236
01:10:09,920 --> 01:10:13,720
Speaker 6:  We'll just see what happens with this. But this is like the weirdest fallout

1237
01:10:13,720 --> 01:10:17,320
Speaker 6:  of all this crypto noise is the number of celebrities and

1238
01:10:17,320 --> 01:10:21,120
Speaker 6:  athletes who bet huge on crypto in the middle of the pandemic.

1239
01:10:21,460 --> 01:10:25,360
Speaker 6:  And now that's all getting wiped out. Aaron Rogers, she points out and that's

1240
01:10:25,360 --> 01:10:29,240
Speaker 6:  the deal where he was gonna get paid in Bitcoin, which is a

1241
01:10:29,240 --> 01:10:31,360
Speaker 6:  horrible deal now. Like that dude just took care of cut on.

1242
01:10:31,910 --> 01:10:32,200
Speaker 5:  I

1243
01:10:32,200 --> 01:10:35,280
Speaker 6:  Love it. And there's like lots of athletes who, who took deals like this

1244
01:10:35,280 --> 01:10:39,080
Speaker 6:  to, to promote and he did it by the way, with our friend Jack Dorsey and

1245
01:10:39,080 --> 01:10:42,920
Speaker 6:  Cash app. Okay. Jack Dorsey, you know, the extremely

1246
01:10:42,920 --> 01:10:43,760
Speaker 6:  good CEO Jack Dorsey,

1247
01:10:43,810 --> 01:10:45,000
Speaker 5:  He knows how to run a company.

1248
01:10:45,170 --> 01:10:47,520
Speaker 6:  So just a lot of chaos in tech this week.

1249
01:10:47,710 --> 01:10:51,240
Speaker 1:  Yeah. Well and FTX was supposed to be one of the like

1250
01:10:51,240 --> 01:10:55,200
Speaker 1:  responsible future of crypto companies that it was like a lot

1251
01:10:55,200 --> 01:10:58,440
Speaker 1:  of people bet on it because it was like, okay, when all of the noise

1252
01:10:58,830 --> 01:11:02,680
Speaker 1:  goes away there's gonna be a handful of sort of good stewards of crypto

1253
01:11:02,680 --> 01:11:05,760
Speaker 1:  left and FTX is gonna be one of them. And now you have people like

1254
01:11:05,760 --> 01:11:09,720
Speaker 1:  Brian Armstrong, the CEO of Coinbase, who like could not

1255
01:11:09,720 --> 01:11:13,480
Speaker 1:  have reacted quicker to distance Coinbase from FTX. And

1256
01:11:13,480 --> 01:11:17,200
Speaker 1:  even he was like, we looked at it and oh boy, it's bad news. Meanwhile

1257
01:11:17,200 --> 01:11:20,680
Speaker 1:  Coinbase is, doc is down like 80% this year. Like it's, it's been a disaster

1258
01:11:20,680 --> 01:11:23,960
Speaker 1:  for everybody. And even he is coming out being like, Oh I, I wouldn't touch

1259
01:11:23,960 --> 01:11:26,040
Speaker 1:  that with a 10 foot pole. Yeah, it's

1260
01:11:26,040 --> 01:11:28,880
Speaker 6:  Rough. I would imagine now that the midterms over the politics are down

1261
01:11:29,640 --> 01:11:33,200
Speaker 6:  well down the, Yeah we're down to a low boil

1262
01:11:33,290 --> 01:11:37,040
Speaker 6:  of American democracy. Not a full rolling boil. Yeah, it's still

1263
01:11:37,230 --> 01:11:38,240
Speaker 6:  hotter than you'd like

1264
01:11:38,240 --> 01:11:41,160
Speaker 5:  Supreme Court announced a case soon we'll be back at it.

1265
01:11:41,340 --> 01:11:44,760
Speaker 6:  But you imagine that a crypto regulation is gonna pick up in Congress cuz

1266
01:11:44,760 --> 01:11:48,360
Speaker 6:  a lot of famous people just got wrecked by some shady crypto

1267
01:11:48,360 --> 01:11:52,040
Speaker 6:  dealings that is gonna require some regulation people from doing. How

1268
01:11:52,360 --> 01:11:54,120
Speaker 5:  Many politicians do you think got

1269
01:11:54,120 --> 01:11:57,920
Speaker 6:  Wrecked? That's the story. Yeah. If you're a politician and you got

1270
01:11:57,920 --> 01:11:58,800
Speaker 6:  wrecked by ftx,

1271
01:11:59,430 --> 01:12:00,360
Speaker 5:  Send us your bill.

1272
01:12:00,360 --> 01:12:03,680
Speaker 6:  Yes. Just let us know. We'd love to write about it. We should end on some

1273
01:12:03,680 --> 01:12:06,960
Speaker 6:  GAD news end on a high note also. We gotta check Twitter to see if anything

1274
01:12:06,960 --> 01:12:10,080
Speaker 6:  else changed in Twitter in the last five minutes. The answer is yes, but

1275
01:12:10,080 --> 01:12:13,960
Speaker 6:  you'll have to check the ver.com to see what happened. We should with some

1276
01:12:13,960 --> 01:12:17,800
Speaker 6:  GA stuff. Yeah. Monica reviewed the service Pro nine. I would say that

1277
01:12:18,280 --> 01:12:21,040
Speaker 6:  Microsoft's attempt to put an arm ship in a service laptop cause once again

1278
01:12:21,110 --> 01:12:25,000
Speaker 6:  been fell and Monica says you should just buy the Intel one. Great.

1279
01:12:25,130 --> 01:12:28,600
Speaker 6:  It was very pretty. She had, we're in the office, we saw I got to play with

1280
01:12:28,600 --> 01:12:31,920
Speaker 6:  it for half a second yesterday when she was in a meeting with me. It's beautiful.

1281
01:12:31,920 --> 01:12:34,400
Speaker 6:  You just get that laptop or you should get the surface on.

1282
01:12:34,470 --> 01:12:38,120
Speaker 1:  Yeah, Microsoft has like done everything with the surface that you would

1283
01:12:38,120 --> 01:12:42,080
Speaker 1:  want it to do except make like that next leap to this next

1284
01:12:42,080 --> 01:12:45,160
Speaker 1:  magical place of great battery life and perfect connectivity. But in terms

1285
01:12:45,160 --> 01:12:49,020
Speaker 1:  of like regular old surface things, it's like they, they continue

1286
01:12:49,020 --> 01:12:51,980
Speaker 1:  to be very good. Seems nice. If you wanna surface by this surface it's very

1287
01:12:51,980 --> 01:12:53,540
Speaker 1:  good. Yeah. Like that's all you can ask for.

1288
01:12:53,670 --> 01:12:55,500
Speaker 6:  LG has a stretchable display now.

1289
01:12:55,670 --> 01:12:56,900
Speaker 5:  LG display.

1290
01:12:56,900 --> 01:12:59,100
Speaker 6:  Oh not lg. Lg. LG display.

1291
01:12:59,430 --> 01:13:02,900
Speaker 5:  LG display. They have very different PR companies and they get really,

1292
01:13:03,660 --> 01:13:07,420
Speaker 5:  they're fine actually if you confuse them but they cannot help you. But yeah,

1293
01:13:07,430 --> 01:13:11,420
Speaker 5:  LG display has a stretchable prototype that hopefully

1294
01:13:11,420 --> 01:13:15,180
Speaker 5:  we'll be seeing at ces. Hopefully that will be one of the things LG display

1295
01:13:15,180 --> 01:13:18,460
Speaker 5:  shows off and it's different because you know, they've done rollable and

1296
01:13:18,460 --> 01:13:22,420
Speaker 5:  they've done like foldable and this is more like you could

1297
01:13:22,560 --> 01:13:26,420
Speaker 5:  theoretically put this on clothes or furniture. I,

1298
01:13:26,420 --> 01:13:28,580
Speaker 5:  I think that's a ways off. Yeah.

1299
01:13:28,600 --> 01:13:32,180
Speaker 6:  But would the furniture be like those vinyl covers that like grandma's used

1300
01:13:32,180 --> 01:13:33,540
Speaker 5:  To have? I think so. I think it would be like,

1301
01:13:33,890 --> 01:13:36,660
Speaker 6:  Yeah, like, like animated florals on the

1302
01:13:36,660 --> 01:13:40,180
Speaker 5:  Couch. Just like a mouth opening as you go to sit down. Absolutely

1303
01:13:40,180 --> 01:13:44,060
Speaker 6:  Not. That's pretty good. Monica also review the HQ affiliate plus 14. I just

1304
01:13:44,060 --> 01:13:47,540
Speaker 6:  like OED laptops and I will read any review of an OED laptop. Just something,

1305
01:13:47,540 --> 01:13:50,460
Speaker 6:  I just want one. I'm like, and this is not the one apparently it's, she said

1306
01:13:50,460 --> 01:13:53,300
Speaker 6:  it was very confusing but shouldn't, shouldn't we just be at a place where

1307
01:13:53,500 --> 01:13:55,820
Speaker 6:  Ed's and laptops sort of thing like all the time.

1308
01:13:55,820 --> 01:13:59,660
Speaker 1:  Well I just, I like this one cuz it, it got the o led part right. And the

1309
01:13:59,660 --> 01:14:03,340
Speaker 1:  laptop part wrong. Like what if the screen was really

1310
01:14:03,340 --> 01:14:07,260
Speaker 1:  good but the laptop felt like it was gonna break every time you

1311
01:14:07,260 --> 01:14:10,780
Speaker 1:  picked it up or touched it. It's like well yeah, we've, we've done,

1312
01:14:11,080 --> 01:14:14,760
Speaker 1:  we've done the hard part. Right, but you kind of forgot about the easy part.

1313
01:14:14,870 --> 01:14:16,880
Speaker 1:  Yeah. But the screen does look really nice.

1314
01:14:17,040 --> 01:14:20,920
Speaker 6:  Pixel watch already bug and how it counts calories

1315
01:14:21,570 --> 01:14:22,240
Speaker 6:  amazing.

1316
01:14:22,660 --> 01:14:26,000
Speaker 5:  Wow. Shocking. Just shocking.

1317
01:14:26,310 --> 01:14:29,320
Speaker 6:  Yeah. All that AI and they're like, we know we're bad at counting. Yeah,

1318
01:14:29,440 --> 01:14:29,920
Speaker 6:  that's good.

1319
01:14:30,350 --> 01:14:33,040
Speaker 5:  A very expensive controller is coming from this is where

1320
01:14:33,140 --> 01:14:34,200
Speaker 6:  End. Yeah. Tell

1321
01:14:34,200 --> 01:14:37,080
Speaker 5:  Tell me about this. Yeah, I'm, I'm a little excited about this cuz for years

1322
01:14:37,460 --> 01:14:41,240
Speaker 5:  you could not get a really customizable controller for, for Sony

1323
01:14:41,240 --> 01:14:45,080
Speaker 5:  products. You had to go to SC SCUFF was basically it and they would

1324
01:14:45,080 --> 01:14:49,000
Speaker 5:  modify them themselves. But we started to see more of these and this is

1325
01:14:49,000 --> 01:14:52,560
Speaker 5:  kind of like the Microsoft Xbox controller

1326
01:14:52,560 --> 01:14:56,280
Speaker 5:  Elite I believe is the name, the elite controller. And

1327
01:14:56,280 --> 01:14:59,600
Speaker 5:  this is the Wolverine version two pro.

1328
01:15:00,030 --> 01:15:03,920
Speaker 5:  I think that's what the V stands for. It's the Wolverine V2

1329
01:15:03,920 --> 01:15:07,840
Speaker 5:  Pro $250 and

1330
01:15:07,840 --> 01:15:11,760
Speaker 5:  still more expensive than Sony's own first party super

1331
01:15:11,760 --> 01:15:13,480
Speaker 5:  fancy customizable controller.

1332
01:15:13,480 --> 01:15:15,920
Speaker 6:  Yeah, this thing looks like a chunk. It

1333
01:15:15,920 --> 01:15:16,880
Speaker 5:  Looks like a big boy.

1334
01:15:16,950 --> 01:15:20,720
Speaker 1:  Yeah. I immediately think of Kirby, the

1335
01:15:20,720 --> 01:15:23,880
Speaker 1:  entire character. Every single time I look at this, it's just, it's it's

1336
01:15:23,880 --> 01:15:27,200
Speaker 1:  a Kirby controller. I love this thing and I love what Razor is doing where

1337
01:15:27,200 --> 01:15:30,400
Speaker 1:  they're like, oh there's a lot of gaming stuff out there. What if we made

1338
01:15:30,640 --> 01:15:34,280
Speaker 1:  something that was so much more aggressive than

1339
01:15:34,520 --> 01:15:36,680
Speaker 1:  anything else you've ever had? Is that something you'd be interested in?

1340
01:15:36,680 --> 01:15:40,040
Speaker 1:  And it turns out the answer is yes. Yes. And this is like, this is what Razor

1341
01:15:40,140 --> 01:15:44,040
Speaker 1:  has always done well. They're just like, here's some like deeply

1342
01:15:44,150 --> 01:15:47,320
Speaker 1:  like capital E, extra gaming gear.

1343
01:15:47,600 --> 01:15:49,600
Speaker 1:  Would you like that? And I'm like, yes, I would.

1344
01:15:49,600 --> 01:15:52,720
Speaker 5:  Thank you. I do have one concern about it cuz it looks like the, the handles

1345
01:15:52,720 --> 01:15:53,720
Speaker 5:  on the side, it's called

1346
01:15:53,720 --> 01:15:56,000
Speaker 1:  The Wolverine might be what's, what's there to be The

1347
01:15:56,000 --> 01:15:59,560
Speaker 5:  Last Wolverine was great. The last Wolverine was wonderful. The buttons were

1348
01:15:59,560 --> 01:16:02,880
Speaker 5:  really nice. Some of the best buttons in these kind of controllers. But this

1349
01:16:02,880 --> 01:16:06,280
Speaker 5:  one looks like it might have a different texture on the sides. And I'm not

1350
01:16:06,280 --> 01:16:09,440
Speaker 5:  about that. I want like the smooth, sweaty plastic texture

1351
01:16:09,990 --> 01:16:12,760
Speaker 5:  everywhere. Gross. I don't want, I don't want like

1352
01:16:12,860 --> 01:16:15,680
Speaker 1:  I'm actually with Alex on this. If it's not like slipping out of my hands

1353
01:16:15,680 --> 01:16:16,560
Speaker 1:  all the time, I'm not

1354
01:16:16,560 --> 01:16:19,080
Speaker 5:  Interested. Yeah, yeah. I don't want sticky controllers.

1355
01:16:19,250 --> 01:16:21,920
Speaker 6:  Oh, I see what you mean. Yeah. This is But this looks like a textured

1356
01:16:21,920 --> 01:16:25,480
Speaker 5:  Plastic. Yeah, I'm hoping that's what it is. It's got a lot of lights on

1357
01:16:25,480 --> 01:16:29,040
Speaker 5:  it. You can expect the buttons to be pretty good. The triggers on the back

1358
01:16:29,220 --> 01:16:32,320
Speaker 5:  are different. A lot of people do these like flipper style triggers, but

1359
01:16:32,320 --> 01:16:32,640
Speaker 5:  there's

1360
01:16:32,640 --> 01:16:32,840
Speaker 1:  Four

1361
01:16:32,840 --> 01:16:34,320
Speaker 5:  Triggers. Oh yeah, four triggers.

1362
01:16:34,320 --> 01:16:36,120
Speaker 1:  I'm looking at this picture, it looks like there's four

1363
01:16:36,120 --> 01:16:37,080
Speaker 5:  Triggers. Oh yeah.

1364
01:16:37,310 --> 01:16:38,480
Speaker 1:  Hell yeah. Dude.

1365
01:16:38,480 --> 01:16:41,920
Speaker 5:  They're all programmable. So you should be able to like be like, I wanna

1366
01:16:41,920 --> 01:16:45,400
Speaker 5:  jump by just using my middle finger on the back of the controller and do

1367
01:16:45,400 --> 01:16:48,560
Speaker 5:  it. But then you have to like train your body to remember that. That's why

1368
01:16:48,560 --> 01:16:51,480
Speaker 5:  I never can use them because I always forget. And then I'm like, why am I

1369
01:16:51,480 --> 01:16:54,680
Speaker 5:  jumping so much? And I'm like, oh it's, I've just been holding this trigger

1370
01:16:54,680 --> 01:16:55,280
Speaker 5:  on my back.

1371
01:16:55,500 --> 01:16:59,480
Speaker 1:  I'm gonna buy this just to play skateboarding games on Apple arcade and it's

1372
01:16:59,480 --> 01:17:02,400
Speaker 1:  gonna be absolutely glorious. Just ripping it. I have zero regrets.

1373
01:17:02,780 --> 01:17:04,640
Speaker 5:  $250. All

1374
01:17:04,640 --> 01:17:07,360
Speaker 1:  Right. The most overkill possible move. I'm all in. I

1375
01:17:07,360 --> 01:17:11,200
Speaker 6:  Love it. We should end there on overkill controllers with RGB

1376
01:17:11,200 --> 01:17:13,920
Speaker 6:  lights. I'm so excited. We gotta end on a high note. Yeah, there's like other

1377
01:17:13,920 --> 01:17:15,280
Speaker 6:  stuff to talk about, but we gotta,

1378
01:17:15,500 --> 01:17:19,080
Speaker 5:  The thing that's not collapsing is customizable

1379
01:17:19,080 --> 01:17:20,240
Speaker 5:  controllers for your PS

1380
01:17:20,240 --> 01:17:23,800
Speaker 6:  Five gamer lights are the one thing you can rely on in 2022. America

1381
01:17:23,800 --> 01:17:27,280
Speaker 6:  invest, you get in, buy high,

1382
01:17:27,560 --> 01:17:28,440
Speaker 6:  don't sell

1383
01:17:28,670 --> 01:17:29,840
Speaker 5:  Hold gamer

1384
01:17:29,840 --> 01:17:33,600
Speaker 6:  Lights. All right. That's it. That's a verge cast. Somehow

1385
01:17:33,600 --> 01:17:37,240
Speaker 6:  we've gone over but we're still right on time. Yes. That's what that feels

1386
01:17:37,240 --> 01:17:41,160
Speaker 6:  like to me. Nailed it. We got right to where we need to be. We're gonna just

1387
01:17:41,160 --> 01:17:44,800
Speaker 6:  have Twitter coverage. Look, we made our entire site look like Twitter,

1388
01:17:45,000 --> 01:17:48,800
Speaker 6:  right? Because we wanted to move faster. Prettier close.

1389
01:17:48,800 --> 01:17:52,600
Speaker 6:  Little did we know that the perfect use for our new product would be

1390
01:17:52,600 --> 01:17:56,400
Speaker 6:  covering Twitter. It's not what I expected, but it's working

1391
01:17:56,400 --> 01:18:00,320
Speaker 6:  out. The site's a lot of fun. It's every minute of

1392
01:18:00,320 --> 01:18:03,920
Speaker 6:  every day. Also first little tweak to the redesign and come in next week.

1393
01:18:04,220 --> 01:18:06,360
Speaker 6:  Ooh. I think people, I think people are gonna like,

1394
01:18:06,510 --> 01:18:07,240
Speaker 5:  I think so too.

1395
01:18:07,240 --> 01:18:10,680
Speaker 6:  We're we're gonna bring back some, We're gonna bring back some old flows.

1396
01:18:10,680 --> 01:18:13,240
Speaker 6:  You're gonna, you're gonna like it, but we're still have the new flow. Yeah.

1397
01:18:13,390 --> 01:18:14,360
Speaker 5:  It's gonna be sick.

1398
01:18:14,430 --> 01:18:18,280
Speaker 6:  Yeah, it's, you're gonna like it, but just check out cause

1399
01:18:18,280 --> 01:18:21,040
Speaker 6:  it's every minute, every minute of every day. Something's crazy happening.

1400
01:18:21,040 --> 01:18:24,880
Speaker 6:  And who knows how long Twitter will stay around. What's your over under

1401
01:18:24,880 --> 01:18:25,320
Speaker 6:  90 days?

1402
01:18:25,910 --> 01:18:26,680
Speaker 5:  120.

1403
01:18:26,910 --> 01:18:29,760
Speaker 6:  120. So one more month. Okay. What do you got?

1404
01:18:29,950 --> 01:18:33,280
Speaker 1:  It's, it's not going anywhere. I'll take, I'll take any over. You give me,

1405
01:18:33,340 --> 01:18:36,480
Speaker 1:  but will I be there in 120 days? No.

1406
01:18:36,990 --> 01:18:37,600
Speaker 6:  Just like

1407
01:18:37,600 --> 01:18:40,880
Speaker 1:  I've already drafted the like, you know what everybody does the like, here

1408
01:18:40,880 --> 01:18:44,640
Speaker 1:  are all the other ways you can reach me. Not on Twitter tweet. I have drafted

1409
01:18:44,640 --> 01:18:47,520
Speaker 1:  that like three or four times already in the last week. And then every time

1410
01:18:47,520 --> 01:18:50,080
Speaker 1:  I type it on, then I'm like, who am I kidding? I'm not done with Twitter.

1411
01:18:50,360 --> 01:18:52,600
Speaker 1:  Yeah. But one of these days I'm gonna send that tweet and be done with Twitter.

1412
01:18:52,600 --> 01:18:56,560
Speaker 6:  And the place you're gonna find us is the Verge Doc. We're gonna add comments

1413
01:18:56,650 --> 01:18:57,800
Speaker 6:  to the quick posts,

1414
01:18:57,800 --> 01:19:00,960
Speaker 5:  But Reckless Patel will be there, Reckless Patel until the end.

1415
01:19:01,000 --> 01:19:04,960
Speaker 6:  Right? We gotta wrap this up. Here's my last, if any of you know Mariah

1416
01:19:04,960 --> 01:19:05,280
Speaker 6:  care,

1417
01:19:07,500 --> 01:19:11,440
Speaker 6:  you know, like I hadn't thought about it a long time, but if,

1418
01:19:11,440 --> 01:19:12,600
Speaker 6:  you know, just let me know.

1419
01:19:12,720 --> 01:19:14,200
Speaker 5:  Slide into those dms.

1420
01:19:16,590 --> 01:19:18,440
Speaker 6:  It's Christmas time. That's all I'm say

1421
01:19:18,510 --> 01:19:22,440
Speaker 1:  This is, no one should underestimate this NE's

1422
01:19:22,440 --> 01:19:26,320
Speaker 1:  entire profile and career success has built to the moment where

1423
01:19:26,320 --> 01:19:29,960
Speaker 1:  he can ask a lot of people to get him in touch with Mariah Care. This is

1424
01:19:29,960 --> 01:19:31,360
Speaker 1:  that moment. Do not let him

1425
01:19:31,360 --> 01:19:32,880
Speaker 5:  Cheer for me. Let him shoot his shot.

1426
01:19:33,110 --> 01:19:35,880
Speaker 6:  Yeah. I think actually like the funniest thing about this, like I think Becky

1427
01:19:35,880 --> 01:19:37,560
Speaker 6:  like would like to be in the room

1428
01:19:39,280 --> 01:19:42,680
Speaker 5:  Shoot phone just slowly come up record.

1429
01:19:42,840 --> 01:19:46,720
Speaker 6:  She'd be like, I know what this is, but I wanna watch a good down. I've known

1430
01:19:46,720 --> 01:19:49,760
Speaker 6:  her since I was 18 years old. She's gonna be like, I want be in that room.

1431
01:19:50,300 --> 01:19:54,240
Speaker 6:  All right. That's it. That's the ver again, if you know Mariah, just

1432
01:19:54,240 --> 01:19:58,040
Speaker 6:  let it be known. She's a business. She can come on to go

1433
01:19:59,140 --> 01:20:00,960
Speaker 5:  Hit him up at at Red,

1434
01:20:00,960 --> 01:20:04,560
Speaker 6:  That's, that's a Verge chest rock and roll. And also the sweet DT sounds

1435
01:20:04,560 --> 01:20:04,840
Speaker 6:  of Mariah.

1436
01:20:10,420 --> 01:20:14,040
Speaker 12:  And that's a wrap for Vergecast this week. Thanks for listening. If you

1437
01:20:14,040 --> 01:20:17,440
Speaker 12:  enjoy the show, subscribe in the podcast app of your choice or tell a friend,

1438
01:20:17,580 --> 01:20:21,440
Speaker 12:  you can send us feedback at vergecast@theverge.com. This show is

1439
01:20:21,640 --> 01:20:25,120
Speaker 12:  produced by me, Liam James, and our senior audio director, Andrew Marino.

1440
01:20:25,150 --> 01:20:29,120
Speaker 12:  This episode was edited and mixed by Amanda Rose

1441
01:20:29,120 --> 01:20:32,960
Speaker 12:  Smith. Our editorial director is Brooke Miners and our executive producer

1442
01:20:32,960 --> 01:20:36,680
Speaker 12:  is Eleanor Donovan. The Verge Cast is a production of the Verge and

1443
01:20:36,680 --> 01:20:39,680
Speaker 12:  Box Media podcast network. And that's it. We'll see you next week.

