1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 969b12cd-7163-4628-87a7-108374280d89
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-2700198998721048203/9169285102658635801/s93290-US-7053s-1718581354.mp3
Description: The Verge's Nilay Patel, Alex Cranz, Allison Johnson, and David Pierce discuss all the announcements from Apple's WWDC event.

2
00:01:15,985 --> 00:01:16,665
Speaker 3:  I picked

3
00:01:56,665 --> 00:02:00,465
Speaker 3:  announcements, Apple Intelligence, which is the company's approach to

4
00:02:00,645 --> 00:02:04,625
Speaker 3:  ai, which has many, many, many components including all the way

5
00:02:04,625 --> 00:02:08,185
Speaker 3:  at the end. A little, little chat. GPT-4. Oh yeah, just a little.

6
00:02:08,435 --> 00:02:12,345
Speaker 3:  There it is. Just shut up. Wall Street. That's pretty much what

7
00:02:12,345 --> 00:02:12,945
Speaker 3:  it was. Yeah.

8
00:02:13,005 --> 00:02:15,825
Speaker 4:  You want us to have a chat GPT strategy. Here it is. It's

9
00:02:15,825 --> 00:02:18,265
Speaker 3:  Just chat GPT. So David and I were walking around the event, we're walking

10
00:02:18,265 --> 00:02:21,945
Speaker 3:  to Apple Park. The vibe was very much like, what is GPT doing

11
00:02:22,135 --> 00:02:25,145
Speaker 3:  here? Like they were excited about it. They were talking about it,

12
00:02:25,965 --> 00:02:29,545
Speaker 3:  but they were kept on talking about all the stuff they had built. Yeah. In

13
00:02:29,545 --> 00:02:32,465
Speaker 3:  the keynote, their principles for how to build it, how they're gonna protect

14
00:02:32,465 --> 00:02:35,945
Speaker 3:  user privacy. There was a second on the record

15
00:02:36,395 --> 00:02:40,105
Speaker 3:  event where I, Justine interviewed John Jean Andrea,

16
00:02:40,105 --> 00:02:43,585
Speaker 3:  who's their head of ai and Craig Federighi, they re recapitulated the keynote

17
00:02:43,645 --> 00:02:47,145
Speaker 3:  and said the principles and values again. And then they kept being, and then

18
00:02:47,145 --> 00:02:50,745
Speaker 3:  some people are gonna want to use chat bt. Right. And it was just like,

19
00:02:51,385 --> 00:02:53,825
Speaker 3:  I think all the lead up was about are they gonna pick Google? Are they gonna

20
00:02:53,825 --> 00:02:57,545
Speaker 3:  pick open ai? They're behind, they gotta catch up. These

21
00:02:57,545 --> 00:03:01,365
Speaker 3:  models will power this stuff. And David, I it just felt like

22
00:03:01,835 --> 00:03:03,045
Speaker 3:  they could have done without it.

23
00:03:03,275 --> 00:03:06,765
Speaker 4:  Well there was the assumption going in that if they were gonna sign a deal

24
00:03:06,765 --> 00:03:10,565
Speaker 4:  like this, it was gonna be to sort of underpin all of this stuff.

25
00:03:10,565 --> 00:03:13,605
Speaker 4:  Right. That like in the sense that when you go to Safari and you do a search,

26
00:03:13,605 --> 00:03:17,285
Speaker 4:  you get Google, right? You don't get like a mishmash of Apple and Google

27
00:03:17,285 --> 00:03:20,925
Speaker 4:  when it's useful. Like it's just Google because that's the one that Apple

28
00:03:20,925 --> 00:03:24,645
Speaker 4:  picked. And also billions of dollars is fun. But the assumption

29
00:03:24,675 --> 00:03:28,405
Speaker 4:  then was like, okay, this will be a Siri based on Gemini.

30
00:03:28,405 --> 00:03:32,165
Speaker 4:  Apple doesn't have the technology yet. Apple hasn't been able to compete

31
00:03:32,165 --> 00:03:35,285
Speaker 4:  with OpenAI and others. So they're gonna build on top of this infrastructure,

32
00:03:35,895 --> 00:03:39,405
Speaker 4:  which as we've talked about, has all kinds of like weird privacy implications,

33
00:03:39,405 --> 00:03:40,685
Speaker 4:  but in a certain way kinda makes sense.

34
00:03:42,395 --> 00:03:46,365
Speaker 4:  Instead it's just like a weird thing off to the side where

35
00:03:46,455 --> 00:03:49,245
Speaker 4:  Apple made a huge deal out of all the stuff that it has built. It says it

36
00:03:49,245 --> 00:03:52,245
Speaker 4:  can do a ton. It's built this incredibly vertically integrated system that

37
00:03:52,245 --> 00:03:55,285
Speaker 4:  it says preserve your privacy and knows what's on the screen. And then like

38
00:03:55,285 --> 00:03:58,405
Speaker 4:  you said, oh, and also chat GPT. Yeah. And so it's, it feels like

39
00:03:59,115 --> 00:04:03,045
Speaker 4:  just a, an afterthought because it's a really good brand

40
00:04:03,045 --> 00:04:04,085
Speaker 4:  that people know. Well

41
00:04:04,085 --> 00:04:07,805
Speaker 5:  It it, it does actually feel like the Google thing because it

42
00:04:07,865 --> 00:04:11,325
Speaker 5:  in that it's only being used for search, right. Like that that was, that

43
00:04:11,325 --> 00:04:12,125
Speaker 5:  was my understanding.

44
00:04:12,125 --> 00:04:15,725
Speaker 3:  It's not even used for search in that way. It's, it it would

45
00:04:15,725 --> 00:04:19,405
Speaker 4:  Be like if you only took Google images. Yeah.

46
00:04:19,405 --> 00:04:23,245
Speaker 4:  Everything else was Apple except Google images and you it. And

47
00:04:23,625 --> 00:04:26,485
Speaker 4:  so if you do a search for a picture, you get Google and everything else is

48
00:04:26,485 --> 00:04:28,965
Speaker 4:  Apple. And you'd be like, what? This doesn't make any sense because the

49
00:04:28,965 --> 00:04:32,725
Speaker 5:  Integration is like you just, you ask and then if it

50
00:04:32,755 --> 00:04:36,365
Speaker 5:  decides that it doesn't want to do it and it wants chat GPT to do it.

51
00:04:36,715 --> 00:04:39,805
Speaker 3:  Well no, sorry. We should step through it. Yeah. Like walk, the big headline

52
00:04:39,805 --> 00:04:43,485
Speaker 3:  feature we should talk about is Apple. Intelligence. Yep. The way the keynote

53
00:04:43,625 --> 00:04:47,165
Speaker 3:  was structured was to put all of that stuff at the end. It was the grand

54
00:04:47,265 --> 00:04:48,085
Speaker 3:  finale of

55
00:04:48,345 --> 00:04:49,125
Speaker 4:  It was the one more thing

56
00:04:49,125 --> 00:04:49,925
Speaker 3:  Almost WWDC

57
00:04:50,025 --> 00:04:53,045
Speaker 4:  Me. I turned to me at one point during the live blog as they, they hit like

58
00:04:53,085 --> 00:04:56,205
Speaker 4:  a wrap up moment. Yeah. Before they did the Apple Intelligence stuff. And

59
00:04:56,205 --> 00:04:58,725
Speaker 4:  Neil, I just turned to me and goes, is that it? Yeah. Like are

60
00:04:58,725 --> 00:05:01,885
Speaker 3:  We, because they ran through all the oss. Yeah. Which, which we'll get to

61
00:05:01,885 --> 00:05:04,885
Speaker 3:  later. But they ran through all the oss and like here's the new grid of icons

62
00:05:04,885 --> 00:05:07,685
Speaker 3:  on the home screen. Look, you could put the icons everywhere. Here's TV os

63
00:05:08,305 --> 00:05:12,205
Speaker 3:  we didn't do anything. And then they, they came to like a

64
00:05:12,205 --> 00:05:15,165
Speaker 3:  natural wrap point. Yeah. And then Tim Cook came back and he is like, power

65
00:05:15,165 --> 00:05:18,925
Speaker 3:  of generative intelligence, blah blah, blah. Here's all the stuff we're doing.

66
00:05:19,625 --> 00:05:22,805
Speaker 3:  And they laid out a bunch of principles. It has to be powerful, it has to

67
00:05:22,805 --> 00:05:26,645
Speaker 3:  be useful, it has to be private. They've built this extraordinarily

68
00:05:26,755 --> 00:05:30,725
Speaker 3:  complicated system where your device decides

69
00:05:30,725 --> 00:05:34,605
Speaker 3:  whether it can do some of the things that you might want it to do or

70
00:05:34,605 --> 00:05:38,485
Speaker 3:  it has to go to Apple's private cloud compute nodes, which we should definitely

71
00:05:38,485 --> 00:05:42,045
Speaker 3:  talk about. Lots of privacy claims there. And then it's not,

72
00:05:42,465 --> 00:05:45,445
Speaker 3:  and then it goes to chat. GPT. Okay. It's,

73
00:05:46,205 --> 00:05:49,725
Speaker 3:  that's Apple. Intelligence. And the heart of almost all these announcements

74
00:05:50,265 --> 00:05:53,965
Speaker 3:  are like, here's some stuff you can do on your phone or your Mac. Here's

75
00:05:53,965 --> 00:05:57,885
Speaker 3:  some stuff that we built this very complicated system to do in

76
00:05:57,885 --> 00:06:01,765
Speaker 3:  the cloud securely. And then also there's a button

77
00:06:01,765 --> 00:06:05,205
Speaker 3:  here where if you want to take a picture of your fridge and ask it to make

78
00:06:05,205 --> 00:06:09,085
Speaker 3:  up a recipe, you can send a photo to chat GPT if you'd like. Also,

79
00:06:09,175 --> 00:06:12,485
Speaker 3:  we're gonna ask you if you ever wanna do that and every time you do it, we're

80
00:06:12,485 --> 00:06:15,965
Speaker 3:  gonna say, do you want to send this photo to chat GBT? You know what?

81
00:06:16,305 --> 00:06:18,565
Speaker 3:  So there's no, there's almost no integration. Oh

82
00:06:18,565 --> 00:06:19,845
Speaker 5:  That is like, yeah, that's

83
00:06:20,705 --> 00:06:23,285
Speaker 4:  The opposite. I had, I had not thought about this until just now. I think

84
00:06:23,285 --> 00:06:26,525
Speaker 4:  that's on purpose. I think that's like extremely on purpose. Yeah. Because

85
00:06:27,035 --> 00:06:30,565
Speaker 4:  what Apple is trying to do is like abstract all of the AI ness away.

86
00:06:30,895 --> 00:06:34,885
Speaker 4:  Right. That like you as a user shouldn't have to care or notice what's

87
00:06:34,885 --> 00:06:36,925
Speaker 4:  going to the cloud and what's happening on device. They want it to all be

88
00:06:36,925 --> 00:06:40,805
Speaker 4:  secure. It should all work the same. Like fine Apple wants it to

89
00:06:40,825 --> 00:06:44,685
Speaker 4:  be damn clear when you are using chat GPT. Yep. Because chat

90
00:06:44,805 --> 00:06:47,485
Speaker 4:  GPT is going to make mistakes. It's going to do a lot of weird stuff and

91
00:06:47,485 --> 00:06:49,925
Speaker 4:  Apple would very much like to be like, Hey, remember when you hit a button

92
00:06:49,925 --> 00:06:52,845
Speaker 4:  that said chat GPT, like this is no longer our problem.

93
00:06:53,035 --> 00:06:55,445
Speaker 5:  Even the prompt is like, sometimes we'll make errors.

94
00:06:55,515 --> 00:06:59,325
Speaker 3:  Yeah. At the bottom of every result it says check important info. Brutal.

95
00:06:59,415 --> 00:07:02,645
Speaker 3:  Which is just chat G's reputation now. Yeah. This thing lies to you. It's

96
00:07:02,645 --> 00:07:02,725
Speaker 3:  even

97
00:07:02,745 --> 00:07:05,525
Speaker 4:  That's even crueler than like Chad GT's typical,

98
00:07:06,495 --> 00:07:08,645
Speaker 4:  which is just like, sometimes it makes mistakes. Apple

99
00:07:08,645 --> 00:07:12,325
Speaker 3:  Is like straight up check this. Right? Yeah. So, but there's a real line

100
00:07:12,325 --> 00:07:16,125
Speaker 3:  there. And that's what I'm saying. It felt like the vibe was we did all this

101
00:07:16,125 --> 00:07:19,525
Speaker 3:  stuff also this is here so don't ask us about it. Right. Like yeah. They

102
00:07:19,525 --> 00:07:21,365
Speaker 3:  said Craig Federighi at the,

103
00:07:22,925 --> 00:07:25,085
Speaker 3:  I don't even know what you would call this, it was an interview, but it was

104
00:07:25,085 --> 00:07:26,725
Speaker 3:  like interview, it was very stage little

105
00:07:26,725 --> 00:07:27,245
Speaker 5:  Coffee side.

106
00:07:29,625 --> 00:07:32,965
Speaker 3:  He said that Gemini would be an example of another

107
00:07:34,045 --> 00:07:37,725
Speaker 3:  LLM they could bring into this. And he said there will be others. We heard

108
00:07:37,725 --> 00:07:41,285
Speaker 3:  people talk about like, what if you're a doctor and there's a medical

109
00:07:41,585 --> 00:07:45,285
Speaker 3:  AI system that you want to plug into your Mac in this way the

110
00:07:45,335 --> 00:07:48,925
Speaker 3:  hooks are being built so that you'll have multiple models you can pick from.

111
00:07:49,185 --> 00:07:52,045
Speaker 3:  So chat GBT is just the one they're starting with today because they kept

112
00:07:52,045 --> 00:07:55,285
Speaker 3:  saying it's the market leader. They think it's the best one of these things

113
00:07:55,555 --> 00:07:59,365
Speaker 3:  they can integrate in all these places. Over time it's obvious

114
00:07:59,365 --> 00:08:02,645
Speaker 3:  that Apple Intelligence this much more private system is gonna get better

115
00:08:02,665 --> 00:08:06,285
Speaker 3:  and maybe push one out or there's gonna be like competition

116
00:08:06,625 --> 00:08:08,125
Speaker 3:  and you get to pick whatever model you want.

117
00:08:08,345 --> 00:08:11,405
Speaker 5:  So is it effectively just advertisement for the API then

118
00:08:13,285 --> 00:08:17,205
Speaker 3:  I think, I suspect I do not know that

119
00:08:17,205 --> 00:08:20,765
Speaker 3:  Apple is paying open AI to have this built into

120
00:08:21,375 --> 00:08:24,685
Speaker 3:  their operating systems. I don't know how they're getting paid. I dunno if

121
00:08:24,685 --> 00:08:26,765
Speaker 3:  it's per use. I dunno if it's a bulk rate, whatever.

122
00:08:28,645 --> 00:08:30,805
Speaker 3:  I know that OpenAI doesn't make any money.

123
00:08:32,525 --> 00:08:36,365
Speaker 3:  Famously they have not yet made any money. Microsoft owns

124
00:08:36,365 --> 00:08:39,525
Speaker 3:  49% of OpenAI. It would be very funny if

125
00:08:40,205 --> 00:08:44,045
Speaker 3:  Microsoft was putting money into OpenAI and OpenAI was paying Apple

126
00:08:44,785 --> 00:08:47,725
Speaker 3:  for the privilege of being an Apple's operating, like that would be almost

127
00:08:47,725 --> 00:08:51,525
Speaker 3:  backwards. So the, you know, the, the logical

128
00:08:51,525 --> 00:08:55,445
Speaker 3:  assumption is that Apple is paying to have this be part

129
00:08:55,445 --> 00:08:58,005
Speaker 3:  of their operating system and maybe they'll pay other companies over time.

130
00:08:58,065 --> 00:09:00,165
Speaker 3:  What's weird about that or there will be some other kind of arrangement you

131
00:09:00,165 --> 00:09:03,725
Speaker 3:  can have. You can log in. If you have a subscriber to chat GPT, you can log

132
00:09:03,725 --> 00:09:07,085
Speaker 3:  into your account, you get more features. Yeah. It will remember you for

133
00:09:07,085 --> 00:09:11,045
Speaker 3:  example. Whereas if you don't have a chat GPT account or you're not paying

134
00:09:11,145 --> 00:09:11,605
Speaker 3:  for premium,

135
00:09:13,265 --> 00:09:16,045
Speaker 3:  it doesn't remember anything about you, it's free.

136
00:09:17,005 --> 00:09:20,605
Speaker 3:  It's free to use on your iPhone. It has no memory and it's, it throws everything

137
00:09:20,605 --> 00:09:24,445
Speaker 3:  out about you. So they have built this like very firewalled version of chat

138
00:09:24,605 --> 00:09:28,565
Speaker 3:  GBT that's just around. Yeah. But all of the action is Apple

139
00:09:28,565 --> 00:09:30,725
Speaker 3:  Intelligence, which is totally controlled by Apple.

140
00:09:31,155 --> 00:09:35,005
Speaker 5:  That makes a hundred. Like that just makes sense. Apple was never gonna

141
00:09:35,005 --> 00:09:36,645
Speaker 5:  let anybody that tightly integrate

142
00:09:36,645 --> 00:09:38,205
Speaker 3:  Into this. But this, these are not the rumors, right?

143
00:09:38,625 --> 00:09:41,885
Speaker 4:  No. Well and it also makes the chat GPT piece of it make less sense to me,

144
00:09:41,885 --> 00:09:45,765
Speaker 4:  right? Yeah. 'cause if, if OpenAI is paying Apple, that I understand, right?

145
00:09:45,765 --> 00:09:48,885
Speaker 4:  Like I get that for OpenAI. They say, okay, this is going to make people

146
00:09:48,905 --> 00:09:52,405
Speaker 4:  use our product more, which is gonna make more people subscribe. That's,

147
00:09:52,405 --> 00:09:55,285
Speaker 4:  that's the path we get. User data, whatever. But

148
00:09:55,985 --> 00:09:59,965
Speaker 4:  OpenAI in the way that it's set up now seems to

149
00:09:59,965 --> 00:10:03,885
Speaker 4:  be getting most of the upside. And all Apple gets is just like a weird way

150
00:10:03,885 --> 00:10:06,765
Speaker 4:  to offload you to another system for some questions that you have. It's

151
00:10:06,765 --> 00:10:10,525
Speaker 3:  Very much like to do the good fun stuff. It has to be not private. And that's

152
00:10:10,525 --> 00:10:14,285
Speaker 3:  Sam Alton's problem. We're gonna, we're gonna have this. So the

153
00:10:14,345 --> 00:10:15,325
Speaker 3:  the architecture.

154
00:10:15,325 --> 00:10:18,405
Speaker 4:  So you think the risk then is that if, if it's, if you don't have that, all

155
00:10:18,405 --> 00:10:22,285
Speaker 4:  you get is kind of a like not fully baked AI system that people don't use

156
00:10:22,305 --> 00:10:24,365
Speaker 4:  and so you're sort of lost at from the beginning. Yeah.

157
00:10:24,385 --> 00:10:28,245
Speaker 3:  And I think one of the really interesting pieces of the puzzle here is

158
00:10:28,665 --> 00:10:32,565
Speaker 3:  we don't know how much of these features will arrive with iOS

159
00:10:32,685 --> 00:10:35,085
Speaker 3:  18 at the beginning. Right. We don't know how many are coming towards the

160
00:10:35,085 --> 00:10:36,965
Speaker 3:  end. Every time they talked about Siri,

161
00:10:38,485 --> 00:10:42,285
Speaker 3:  I kept noticing that they, they insisted, they used like often

162
00:10:42,305 --> 00:10:46,245
Speaker 3:  the distance verb tenses. Yeah. Siri is going to be able to do

163
00:10:46,285 --> 00:10:50,085
Speaker 3:  this. And it's like, when is Siri going to be able to do this? The

164
00:10:50,085 --> 00:10:53,445
Speaker 3:  answer appears to be within the window of iOS 18.

165
00:10:54,305 --> 00:10:57,925
Speaker 3:  So Siri will be able to do a bunch of the stuff they demoed before iOS 19

166
00:10:57,925 --> 00:10:58,365
Speaker 3:  comes out,

167
00:10:59,305 --> 00:11:00,325
Speaker 5:  But not necessarily

168
00:11:00,765 --> 00:11:04,485
Speaker 3:  A long time from now. Yeah, yeah. Like that's, that's September, 2025 is

169
00:11:04,485 --> 00:11:07,405
Speaker 3:  the release date of iOS 19. So there's a long way to go

170
00:11:08,385 --> 00:11:11,485
Speaker 3:  before they have to ship all these features. But the fundamental architecture

171
00:11:11,485 --> 00:11:15,085
Speaker 3:  of Apple Intelligence is really interesting because they have,

172
00:11:15,195 --> 00:11:18,765
Speaker 3:  they are claiming very much that the on-device

173
00:11:19,045 --> 00:11:22,405
Speaker 3:  intelligence that they've built, they said there are already 200 models running

174
00:11:22,405 --> 00:11:25,525
Speaker 3:  air phone before we ever do any of this generative stuff for things like

175
00:11:25,525 --> 00:11:29,285
Speaker 3:  car crash detection and photo editing and all photos in general on an

176
00:11:29,285 --> 00:11:32,925
Speaker 3:  iPhone. Tons of ai. And then now they're adding some of these other models.

177
00:11:33,715 --> 00:11:37,445
Speaker 3:  It's only gonna run on The iPhone 15 Pro and

178
00:11:37,445 --> 00:11:41,285
Speaker 3:  presumably the next one and then Max with an M1 chip or

179
00:11:41,405 --> 00:11:44,485
Speaker 3:  above. So that's interesting. 'cause the M1

180
00:11:45,805 --> 00:11:49,685
Speaker 3:  I think is more similar to some of the previous I iPhone ships. Yeah.

181
00:11:49,785 --> 00:11:53,365
Speaker 3:  But they are gating it. So it's the 15 pro and above and M1 and above

182
00:11:53,555 --> 00:11:56,165
Speaker 3:  obviously running the new versions of the operating system and it's gonna

183
00:11:56,165 --> 00:12:00,125
Speaker 3:  add more models that let you do more stuff on the phone. So you will be

184
00:12:00,125 --> 00:12:03,965
Speaker 3:  able to generate horrifying images on the phone

185
00:12:04,255 --> 00:12:07,725
Speaker 3:  based on I'm So what's happening, your photos that you'll be able to

186
00:12:08,385 --> 00:12:11,845
Speaker 3:  ask Siri for certain things using App intent, which we talked about a bunch

187
00:12:11,845 --> 00:12:12,805
Speaker 3:  last week, but

188
00:12:12,805 --> 00:12:14,965
Speaker 5:  It's only using the data on your device. Right.

189
00:12:15,035 --> 00:12:16,765
Speaker 3:  Only using the data on your device. Which

190
00:12:16,765 --> 00:12:20,445
Speaker 5:  Is why all of the images from the image playground that we saw

191
00:12:20,625 --> 00:12:22,485
Speaker 5:  in the keynote were horrible.

192
00:12:23,075 --> 00:12:23,845
Speaker 4:  They were so bad.

193
00:12:23,875 --> 00:12:26,885
Speaker 5:  They were like, it was like, do you remember how when you're, when you're

194
00:12:27,045 --> 00:12:30,125
Speaker 5:  downloading app and it's like, do you wanna download any of these other games

195
00:12:30,435 --> 00:12:34,005
Speaker 5:  that you've never heard of and are probably gonna steal your data? They it

196
00:12:34,005 --> 00:12:35,685
Speaker 5:  like all the art looked like those apps.

197
00:12:36,235 --> 00:12:38,685
Speaker 3:  Yeah. So it's Image Playground, which is all local

198
00:12:40,345 --> 00:12:43,885
Speaker 3:  and yeah, it looks bad. It looks real bad. But Image playground is a, a thing

199
00:12:43,885 --> 00:12:47,405
Speaker 3:  you can just integrate into apps now. So you can draw sketch and notes and

200
00:12:47,405 --> 00:12:50,165
Speaker 3:  circle it and then it'll make the AI bubble and then it'll turn your sketch

201
00:12:50,165 --> 00:12:50,685
Speaker 3:  into a thing.

202
00:12:51,225 --> 00:12:52,645
Speaker 4:  Is that anything

203
00:12:53,875 --> 00:12:54,165
Speaker 3:  Like,

204
00:12:54,785 --> 00:12:56,365
Speaker 4:  I'm sort of serious, like I think

205
00:12:56,765 --> 00:12:57,205
Speaker 3:  I have been,

206
00:12:57,525 --> 00:13:00,525
Speaker 4:  I have been thinking about this so much the last few weeks about like how

207
00:13:00,525 --> 00:13:04,485
Speaker 4:  what in AI is a real thing that people will do and what is going to be a

208
00:13:04,485 --> 00:13:07,205
Speaker 4:  tech demo that no one in the world ever actually does. And I've been thinking

209
00:13:07,205 --> 00:13:10,885
Speaker 4:  about this actually ever since Rabbit did the demo where he drew a spreadsheet

210
00:13:10,905 --> 00:13:14,845
Speaker 4:  on a piece of paper and then pointed his rabbit to it and was

211
00:13:14,845 --> 00:13:18,405
Speaker 4:  like, transposed the rows and columns and send this to my email and it did

212
00:13:18,405 --> 00:13:22,205
Speaker 4:  it. And it was like, oh neat unusable feature for anyone who exists

213
00:13:22,205 --> 00:13:25,085
Speaker 4:  in the world. Like why on earth would you do this? And I wonder with this

214
00:13:25,085 --> 00:13:28,165
Speaker 4:  thing where he's like, there was a moment in the keynote where he was in

215
00:13:28,165 --> 00:13:32,045
Speaker 4:  notes and he just did a circle in a note

216
00:13:32,105 --> 00:13:36,085
Speaker 4:  in an open part of the note and it made a picture of the stuff that was

217
00:13:36,085 --> 00:13:39,765
Speaker 4:  in his note. And it's like a technically neat thing.

218
00:13:40,025 --> 00:13:44,005
Speaker 4:  It made a thing. Why? What is this for?

219
00:13:44,545 --> 00:13:47,325
Speaker 5:  No, I figured it out. It's when, you know how when you have to send a deck

220
00:13:47,465 --> 00:13:51,205
Speaker 5:  and you don't wanna go look for art to send that deck to like all your other

221
00:13:51,405 --> 00:13:54,045
Speaker 5:  coworkers to be like, this is why we're gonna do this new policy or whatever.

222
00:13:54,435 --> 00:13:55,645
Speaker 4:  Okay. That's actually, that's actually

223
00:13:55,745 --> 00:13:57,725
Speaker 3:  It. You really tell that Alex used to be the managing editor. Yeah.

224
00:13:57,725 --> 00:13:57,965
Speaker 5:  Right? Oh

225
00:13:57,965 --> 00:13:59,005
Speaker 3:  Yeah. She had to explain a lot of policy.

226
00:13:59,205 --> 00:14:01,885
Speaker 4:  I don't, I think I don't make enough decks to like be Yeah, yeah.

227
00:14:02,715 --> 00:14:04,645
Speaker 4:  Steward of the world. I need to make more texts.

228
00:14:04,755 --> 00:14:07,365
Speaker 3:  Yeah. We, you make me an installer deck using an entire,

229
00:14:08,605 --> 00:14:10,685
Speaker 3:  But there's other stuff that you, that will happen locally on the phone,

230
00:14:10,685 --> 00:14:14,565
Speaker 3:  like the new iOS that you get AI powered summaries of

231
00:14:14,565 --> 00:14:18,445
Speaker 3:  your notifications and they previewed this with a very like,

232
00:14:19,315 --> 00:14:22,885
Speaker 3:  like the stock thing that everyone previews everything with, which is like

233
00:14:22,915 --> 00:14:26,365
Speaker 3:  your friends are planning a trip in a group text and it's like, so and so

234
00:14:26,365 --> 00:14:28,725
Speaker 3:  booked a house, so the first date is this and so and so is gonna be late.

235
00:14:28,825 --> 00:14:31,805
Speaker 3:  I'm like, none of my friends are this transactional, they do not communicate

236
00:14:31,805 --> 00:14:34,805
Speaker 3:  this way. It's gonna be like your law school friends are shit posting. Again,

237
00:14:35,115 --> 00:14:38,405
Speaker 3:  some of these images are not safe for work. Right. And it's like, what will

238
00:14:38,405 --> 00:14:41,965
Speaker 3:  we have do this? So like there's a real,

239
00:14:42,325 --> 00:14:45,925
Speaker 3:  I think just gap between sort of these demos, like these ideas of what you

240
00:14:45,925 --> 00:14:49,405
Speaker 3:  can do on the phone, the reality of how powerful your phone might have to

241
00:14:49,405 --> 00:14:53,325
Speaker 3:  be and then like what actually is happening on people's phones. And

242
00:14:53,325 --> 00:14:57,285
Speaker 3:  then at some point, and we don't really know when the phone's gonna say,

243
00:14:57,485 --> 00:15:01,085
Speaker 3:  I don't have the horsepower to do this, or my battery life will be too compromised,

244
00:15:01,105 --> 00:15:04,845
Speaker 3:  or the thermals are outta whack and it will create a secure connection

245
00:15:05,305 --> 00:15:09,085
Speaker 3:  to Apple's secure private compute cloud

246
00:15:09,205 --> 00:15:12,325
Speaker 3:  service that is running apple silicon somewhere.

247
00:15:13,745 --> 00:15:17,405
Speaker 3:  And that whole mechanism is Apple's innovation.

248
00:15:17,475 --> 00:15:20,965
Speaker 3:  Like at the end of the day, apple running a bunch of tiny models on device

249
00:15:21,145 --> 00:15:24,325
Speaker 3:  and a bunch of bigger models in the cloud is what everyone is doing. Yep.

250
00:15:24,515 --> 00:15:28,485
Speaker 3:  Some of the user experiences they are delivering are exactly

251
00:15:28,585 --> 00:15:31,965
Speaker 3:  the same ones as we've seen demoed by other companies.

252
00:15:32,155 --> 00:15:35,965
Speaker 3:  Apple's much better at telling you a compelling story about those user

253
00:15:36,035 --> 00:15:39,485
Speaker 3:  interface ideas, but it's the same stuff. We're gonna read all your email

254
00:15:39,505 --> 00:15:43,485
Speaker 3:  and make you a list of flights like Yeah, we saw that at io, right? That's

255
00:15:43,965 --> 00:15:47,845
Speaker 3:  Microsoft is demoing, but the the big innovation is they're saying

256
00:15:47,895 --> 00:15:50,765
Speaker 3:  we're doing this all on your device as much as we can. And when we have to

257
00:15:50,765 --> 00:15:54,045
Speaker 3:  go up to the cloud, we've built this whole system

258
00:15:54,745 --> 00:15:58,565
Speaker 3:  to keep that secure and then importantly throw your data away on the cloud

259
00:15:58,565 --> 00:16:02,005
Speaker 3:  when we're done. So there's no chance of being compromised. Right. That

260
00:16:02,005 --> 00:16:05,805
Speaker 4:  Whole chain is supposed to be exactly as secure as just doing it on your

261
00:16:05,805 --> 00:16:09,445
Speaker 4:  device. Yeah. Which just instinctively I don't believe. Yeah. Because that's

262
00:16:09,445 --> 00:16:12,125
Speaker 4:  not a thing. You've just, you've taken a thing that was on my device and

263
00:16:12,125 --> 00:16:14,725
Speaker 4:  you've put it somewhere else. And so now by definition it's less secure,

264
00:16:14,945 --> 00:16:18,885
Speaker 4:  but at least to apple's credit, it does seem like it has done just about

265
00:16:18,885 --> 00:16:21,645
Speaker 4:  everything you can do to mitigate that. Yeah.

266
00:16:21,645 --> 00:16:24,885
Speaker 5:  It's gone to like, it seems to be just as secure

267
00:16:25,945 --> 00:16:29,605
Speaker 5:  as possible with still acknow but refusing to acknowledge

268
00:16:29,755 --> 00:16:33,125
Speaker 5:  that it is still way less secure than everything just being on your device.

269
00:16:33,615 --> 00:16:37,125
Speaker 5:  Right. Because it's like, yeah, this is probably one of the most secure ways

270
00:16:37,125 --> 00:16:40,645
Speaker 5:  you can transfer this information. You are still transferring this information

271
00:16:40,645 --> 00:16:43,605
Speaker 5:  and that means you open yourself up to other people

272
00:16:44,665 --> 00:16:45,715
Speaker 5:  inserting themselves in.

273
00:16:45,845 --> 00:16:49,835
Speaker 4:  Right. And there's all kinds of potential for weirdness if you have network

274
00:16:49,995 --> 00:16:53,795
Speaker 4:  problems or again, like it turns out sending a bunch of data to the web

275
00:16:54,095 --> 00:16:57,315
Speaker 4:  and the cloud is also taxing on your battery life. Yeah. And thermal, it's

276
00:16:57,315 --> 00:17:00,795
Speaker 4:  like, yeah, this stuff is hard. And I think doing all of this super

277
00:17:01,155 --> 00:17:03,915
Speaker 4:  seamlessly, if Apple can pull it off, is going to be like the true magic

278
00:17:03,915 --> 00:17:05,075
Speaker 4:  trick of this whole system.

279
00:17:05,305 --> 00:17:08,755
Speaker 3:  Yeah. So the the basics are complicated. They just released a white paper

280
00:17:08,765 --> 00:17:12,235
Speaker 3:  about how it all works. It is very dry.

281
00:17:12,615 --> 00:17:15,275
Speaker 3:  Oh my god. Alex, I believe your read on it was they don't want people to

282
00:17:15,275 --> 00:17:16,115
Speaker 3:  read this. No,

283
00:17:17,095 --> 00:17:18,035
Speaker 5:  You sure don't.

284
00:17:19,495 --> 00:17:23,035
Speaker 3:  But some interesting pieces of it. Right. Craig

285
00:17:23,105 --> 00:17:26,915
Speaker 3:  Federer described one part of the system as blockchain ish. Yeah. Which is

286
00:17:27,075 --> 00:17:31,035
Speaker 3:  actually a great description. So your phone

287
00:17:31,065 --> 00:17:34,675
Speaker 3:  when it goes to talk to one of these servers, if they have not published

288
00:17:35,015 --> 00:17:38,835
Speaker 3:  the code for researchers to verify the security of the

289
00:17:38,835 --> 00:17:42,275
Speaker 3:  code to an append only cryptographically signed database

290
00:17:42,325 --> 00:17:46,275
Speaker 3:  blockchain ish that your phone can check, it just won't

291
00:17:46,275 --> 00:17:50,125
Speaker 3:  talk to that server. Right. So like your, your man in the middle attack

292
00:17:50,125 --> 00:17:52,885
Speaker 3:  there, like they're trying to cut that down. There's a line in the white

293
00:17:52,885 --> 00:17:56,565
Speaker 3:  paper that says we do not want there to be targetability. So

294
00:17:57,475 --> 00:18:01,445
Speaker 3:  it's not like you have a Mac in the cloud. Yeah. There's a huge

295
00:18:01,495 --> 00:18:05,045
Speaker 3:  array of devices in the cloud and they don't want any one of those to be

296
00:18:05,045 --> 00:18:09,005
Speaker 3:  associated with you. So your device, when it asks for a server to run

297
00:18:09,005 --> 00:18:12,845
Speaker 3:  some these workloads on, it actually will only ever get a group and it won't

298
00:18:12,845 --> 00:18:16,805
Speaker 3:  know which one is in the end. And then that load balancer is also like hardened.

299
00:18:17,425 --> 00:18:21,365
Speaker 3:  So you like you can't attack it. Right. So No, no. Like attacker

300
00:18:21,365 --> 00:18:23,605
Speaker 3:  can be like, okay, they always get that one and it's not sending all the

301
00:18:23,605 --> 00:18:27,325
Speaker 3:  data in plain text, but it's not storing a database of everything you've

302
00:18:27,325 --> 00:18:29,525
Speaker 3:  ever done on your computer in plain text. Yeah. Good. Like windows those

303
00:18:30,025 --> 00:18:32,485
Speaker 3:  recall. It's good. Yeah. Although Microsoft did say they were gonna fix it.

304
00:18:33,645 --> 00:18:36,165
Speaker 3:  This is like, there's just a bunch of stuff like that. One of the more interesting

305
00:18:36,165 --> 00:18:40,045
Speaker 3:  pieces the servers run a custom operating system that

306
00:18:40,045 --> 00:18:43,365
Speaker 3:  Apple says in the white paper is a combination of Mac OS and iOS

307
00:18:44,635 --> 00:18:47,525
Speaker 3:  that is designed just for inference loads. They've cut down all the other

308
00:18:47,525 --> 00:18:51,485
Speaker 3:  attack surfaces and then they, the hardware itself, in

309
00:18:51,685 --> 00:18:55,525
Speaker 3:  addition to all their usual like security measures, they

310
00:18:55,525 --> 00:18:59,205
Speaker 3:  have additional layers of security when they make the hardware

311
00:18:59,765 --> 00:19:02,085
Speaker 3:  ship it to the data center and validate it for installation.

312
00:19:03,425 --> 00:19:06,725
Speaker 4:  And also there's a large man with a gun just standing next to each one

313
00:19:07,075 --> 00:19:10,445
Speaker 3:  Just in case. Well I think, I think some of that stuff is in this white paper.

314
00:19:10,445 --> 00:19:13,525
Speaker 3:  They talk about it, it's in this blog post because if you are recall, there

315
00:19:13,525 --> 00:19:16,605
Speaker 3:  was a huge Bloomberg story about Apple's data centers

316
00:19:17,255 --> 00:19:20,645
Speaker 3:  being attacked at the supply chain level. And I think they're like, yeah,

317
00:19:21,415 --> 00:19:25,125
Speaker 3:  we're not, that's not even a possibility here. Yeah. So they're, they're

318
00:19:25,125 --> 00:19:28,485
Speaker 3:  saying all of these things about how the system will work. I think the most

319
00:19:28,485 --> 00:19:31,965
Speaker 3:  important thing they're saying is we want researchers to come in and validate

320
00:19:31,965 --> 00:19:35,325
Speaker 3:  this stuff over and over and over again. Yeah. The firmware for these devices,

321
00:19:35,325 --> 00:19:37,885
Speaker 3:  they're gonna publish it in plain text and like look at it.

322
00:19:39,145 --> 00:19:43,125
Speaker 3:  So I think there's this level of we want, we want to take the pressure

323
00:19:43,145 --> 00:19:46,405
Speaker 3:  on the system. At the same time, the pressure is not

324
00:19:46,835 --> 00:19:50,645
Speaker 3:  necessarily technical. The pressure is legal and

325
00:19:50,645 --> 00:19:54,325
Speaker 3:  political. Like the Chinese government doesn't give a shit.

326
00:19:55,195 --> 00:19:58,045
Speaker 3:  They're just gonna say, if you want to keep selling iPhones in China, you're

327
00:19:58,045 --> 00:20:01,005
Speaker 3:  gonna have to let us see everything. Right. What are gonna do about that?

328
00:20:01,185 --> 00:20:05,085
Speaker 3:  The Indian government is probably not gonna give a shit. Like they just

329
00:20:05,875 --> 00:20:09,365
Speaker 3:  want to see things. They just had some elections. It's a little softener

330
00:20:09,365 --> 00:20:12,565
Speaker 3:  over there, but like, who knows? Right? Like that's the pressure on the world.

331
00:20:12,625 --> 00:20:15,925
Speaker 3:  Our FBI here in the United States has repeatedly tried to pressure Apple

332
00:20:16,355 --> 00:20:20,325
Speaker 3:  into turning over encryption keys to iMessage and iCloud. This is a

333
00:20:20,325 --> 00:20:24,245
Speaker 3:  new vector of attack to say, okay, you're moving personal device off of

334
00:20:24,245 --> 00:20:28,085
Speaker 3:  people's phones into the cloud. There is something called the third

335
00:20:28,085 --> 00:20:31,405
Speaker 3:  party doctrine in this country that says if you anything touches your telecom

336
00:20:31,605 --> 00:20:34,365
Speaker 3:  provider or a cloud service, you had no longer have a reason why expectation

337
00:20:34,365 --> 00:20:37,245
Speaker 3:  of privacy. 'cause a third party has seen it and now the government can see

338
00:20:37,245 --> 00:20:41,045
Speaker 3:  it too. Apple's answer to this is we're gonna throw it all away as soon as

339
00:20:41,045 --> 00:20:43,605
Speaker 3:  we're done processing in the cloud and we send you a result back. And so

340
00:20:43,605 --> 00:20:47,005
Speaker 3:  we don't even have it to turn it over, but the pressure is gonna keep coming.

341
00:20:47,425 --> 00:20:50,445
Speaker 3:  So it's interesting that the, the technical side, they've tried to button

342
00:20:50,445 --> 00:20:53,405
Speaker 3:  it up as much as they can. The legal and political side.

343
00:20:55,195 --> 00:20:58,285
Speaker 3:  They, they want to keep selling phones in China. Yeah. They're,

344
00:20:58,475 --> 00:21:00,245
Speaker 5:  It's just a big We'll see. Yeah.

345
00:21:00,515 --> 00:21:02,525
Speaker 3:  It's like we're, we're just gonna see how Well also

346
00:21:02,555 --> 00:21:06,445
Speaker 4:  That problem, that problem doesn't cease to exist even if you don't have

347
00:21:06,445 --> 00:21:09,525
Speaker 4:  this system for Apple. Right. Like this is just, this is just the price of

348
00:21:09,525 --> 00:21:13,365
Speaker 4:  doing business in Apples or in China. Yeah. So fundamentally like Apple

349
00:21:13,915 --> 00:21:17,365
Speaker 4:  made that decision a very long time ago. Yeah. And this is just another version

350
00:21:17,365 --> 00:21:20,645
Speaker 4:  of that same decision. What it seems like here is Apple is trying to

351
00:21:21,395 --> 00:21:25,365
Speaker 4:  give itself an out for the rest of the world's versions of

352
00:21:25,365 --> 00:21:28,365
Speaker 4:  those legal and political problems where it can just be like, sorry, we don't,

353
00:21:28,365 --> 00:21:30,245
Speaker 4:  we don't have it to give you like, I don't know what you want. Right. They,

354
00:21:30,355 --> 00:21:33,565
Speaker 3:  They've sort of engineered a technical solution to a legal problem. Right.

355
00:21:33,565 --> 00:21:37,165
Speaker 4:  Right. Well this is the thing you hear a lot now from people who are building

356
00:21:37,345 --> 00:21:40,845
Speaker 4:  web services is like the main thing you should do is make sure you don't

357
00:21:40,845 --> 00:21:44,645
Speaker 4:  have one shred of data that you don't absolutely need. Because if you

358
00:21:44,965 --> 00:21:47,845
Speaker 4:  accidentally store a bunch of people's credit card numbers, somebody's gonna

359
00:21:47,845 --> 00:21:50,005
Speaker 4:  hack it and they're gonna get it. And that's gonna suck real bad for you.

360
00:21:50,005 --> 00:21:53,765
Speaker 4:  Yep. If you have a bunch of people's email addresses and passwords for accounts

361
00:21:53,765 --> 00:21:56,885
Speaker 4:  that don't really matter to you, same thing's gonna happen. Like all this

362
00:21:56,885 --> 00:22:00,685
Speaker 4:  stuff. And so these data minimization practices are not just like good

363
00:22:00,745 --> 00:22:04,005
Speaker 4:  for the world, even though I think they are, but it's just good business

364
00:22:04,245 --> 00:22:07,845
Speaker 4:  practice. And so it's like for Apple, if they're sincerely not

365
00:22:08,155 --> 00:22:10,965
Speaker 4:  turning around and training more models on that data or selling that data,

366
00:22:10,965 --> 00:22:14,925
Speaker 4:  both of which they say they're not. And I think, I believe them keeping that

367
00:22:14,925 --> 00:22:18,565
Speaker 4:  data is just a liability. Yeah. And so it's actually, it's smart for so many

368
00:22:18,565 --> 00:22:21,645
Speaker 4:  reasons to be like, the minute you're done with it, it's just shredded and

369
00:22:21,645 --> 00:22:23,485
Speaker 4:  gone. We can get back if you want it. I mean, I

370
00:22:23,485 --> 00:22:27,365
Speaker 5:  Think Apple's ideal is that everything will eventually be on the phone. The

371
00:22:27,365 --> 00:22:29,965
Speaker 5:  processors will be fast enough that they don't have to send anything to the

372
00:22:29,965 --> 00:22:30,685
Speaker 5:  cloud. Right? Yeah.

373
00:22:30,835 --> 00:22:34,645
Speaker 4:  Yeah. I I I think very clearly Apple's goal is to do more and more on

374
00:22:34,645 --> 00:22:35,285
Speaker 4:  device over time.

375
00:22:36,565 --> 00:22:40,485
Speaker 3:  I disagree. Really? Yeah. But not in like a meaningful way.

376
00:22:42,525 --> 00:22:45,565
Speaker 3:  I shouldn't, I I think when you say Apple's goal is to get it all on your

377
00:22:45,565 --> 00:22:49,245
Speaker 3:  phone, I think, I think it, it's gone. The horses

378
00:22:49,315 --> 00:22:53,005
Speaker 3:  left the station. It's been a long day. Horses, you keep horses in the station,

379
00:22:53,005 --> 00:22:55,765
Speaker 3:  right? And Yeah. Yeah. Yeah. The horses left the barn. The train is

380
00:22:55,825 --> 00:22:56,725
Speaker 5:  Has left station, the train has the

381
00:22:56,725 --> 00:23:00,605
Speaker 3:  Station, station train has left. The The iPhone workload has left your phone.

382
00:23:02,625 --> 00:23:04,845
Speaker 3:  And I think what's gonna happen is the phone will get more and more powerful.

383
00:23:04,845 --> 00:23:08,005
Speaker 3:  It'll take more workloads onto the phone. Sure. Mm. But then you're gonna

384
00:23:08,005 --> 00:23:10,765
Speaker 3:  invent more stuff you wanna do, and now you've built this incredibly powerful

385
00:23:11,585 --> 00:23:15,085
Speaker 3:  secure cloud, blah, blah, blah, and you're gonna do all the stuff you,

386
00:23:15,285 --> 00:23:17,965
Speaker 3:  there will always be some level of stuff you can't do on the phone that now

387
00:23:17,965 --> 00:23:18,565
Speaker 3:  you can do up there.

388
00:23:19,005 --> 00:23:21,965
Speaker 4:  I think both of those things can be simultaneously true. Right. Like the,

389
00:23:22,185 --> 00:23:26,085
Speaker 4:  the private cloud compute is how you get rid of chat

390
00:23:26,245 --> 00:23:30,125
Speaker 4:  GPT and like ultimately at some point, if we go far enough down this

391
00:23:30,125 --> 00:23:33,565
Speaker 4:  road open AI and Apple will be naked competitors in this space. Like that's

392
00:23:33,565 --> 00:23:37,205
Speaker 4:  just where we're headed and that's how you get rid of chat

393
00:23:37,325 --> 00:23:41,165
Speaker 4:  GPT needing to do all this stuff. Right. I think every time

394
00:23:41,255 --> 00:23:45,045
Speaker 4:  Apple sends something out of Apple Intelligence and into chat GPTT,

395
00:23:45,235 --> 00:23:48,285
Speaker 4:  that is going to look like failure to Apple. Yeah. For a whole variety of

396
00:23:48,285 --> 00:23:48,445
Speaker 4:  reasons.

397
00:23:50,305 --> 00:23:54,045
Speaker 4:  But it's still true. I think that as the set of workloads gets

398
00:23:54,045 --> 00:23:56,765
Speaker 4:  larger, apple is going to want to do more and more of them on your device

399
00:23:56,765 --> 00:24:00,245
Speaker 4:  because it's gonna save them computing. Apple talked a bunch about the environmental

400
00:24:00,245 --> 00:24:02,725
Speaker 4:  impact of all of this stuff and they make a big deal about the fact that

401
00:24:02,725 --> 00:24:05,805
Speaker 4:  the more you can do on your device, the less they have to send anywhere,

402
00:24:05,805 --> 00:24:09,685
Speaker 4:  which is computationally expensive costs electricity. Like it's just

403
00:24:09,685 --> 00:24:12,245
Speaker 4:  more efficient to do it on the device. So I think the push to do that's of

404
00:24:12,245 --> 00:24:15,965
Speaker 4:  locally is going to be real. It probably won't ever be the whole answer though.

405
00:24:16,045 --> 00:24:18,805
Speaker 4:  I think you're like, and the bleeding edge stuff can happen in the compute

406
00:24:18,805 --> 00:24:22,565
Speaker 4:  cloud so that it doesn't have to happen in Azure. Yeah. Which is a

407
00:24:22,645 --> 00:24:23,445
Speaker 4:  bummer if you're Apple.

408
00:24:23,835 --> 00:24:26,125
Speaker 3:  Yeah. I mean I, that's what, that's kinda what I'm getting at. It's, I I

409
00:24:26,245 --> 00:24:28,565
Speaker 3:  disagree with you, but not in like some huge sense. I just think there will

410
00:24:28,565 --> 00:24:32,365
Speaker 3:  always be some set of ideas that is too big for the phone. Yeah. And once

411
00:24:32,785 --> 00:24:36,765
Speaker 3:  you've opened the door to Apple saying we've

412
00:24:36,765 --> 00:24:40,605
Speaker 3:  built a system that allows us to take some stuff away

413
00:24:40,605 --> 00:24:43,245
Speaker 3:  from your phone and up into the cloud, which they're very proud of that all

414
00:24:43,245 --> 00:24:46,325
Speaker 3:  of their data centers run on a hundred percent renewable energy and Apple

415
00:24:46,325 --> 00:24:49,925
Speaker 3:  silicon is already high performance per watt. And like

416
00:24:50,035 --> 00:24:53,725
Speaker 3:  they can do all this stuff where maybe they can solve some of those efficiency

417
00:24:53,725 --> 00:24:54,925
Speaker 3:  problems, right? Like Yeah.

418
00:24:54,925 --> 00:24:55,485
Speaker 4:  Fair. Yeah.

419
00:24:55,875 --> 00:24:58,285
Speaker 3:  There's just gonna be some set of stuff that they can do in the cloud. So

420
00:24:58,285 --> 00:25:01,765
Speaker 3:  like I, this is like, this is today's the change

421
00:25:02,265 --> 00:25:05,725
Speaker 3:  and like a year from now or two years from now, it'll just be part of the

422
00:25:05,725 --> 00:25:09,045
Speaker 3:  way The iPhone works is you have access to private compute cloud

423
00:25:09,795 --> 00:25:12,165
Speaker 3:  that no dumb Android phone comes. Right.

424
00:25:13,115 --> 00:25:13,605
Speaker 4:  Whereas

425
00:25:13,605 --> 00:25:16,125
Speaker 3:  Like with Android, you gotta send everything to Google, which is like training

426
00:25:16,125 --> 00:25:19,765
Speaker 3:  on your emails, like whatever thing Apple's gonna say. So I just think this

427
00:25:19,765 --> 00:25:22,805
Speaker 3:  is the beginning of a change and that's really how they framed it all day

428
00:25:22,805 --> 00:25:26,525
Speaker 3:  long. Yeah. Was this is the beginning of a change. Like this is the next

429
00:25:26,525 --> 00:25:30,005
Speaker 3:  generation of these devices. This is the next generation of how we use these

430
00:25:30,005 --> 00:25:33,445
Speaker 3:  apps. David, at one point he said, you can, you can

431
00:25:33,845 --> 00:25:37,125
Speaker 3:  squint and you can see the end of the app era here. And the way that they're

432
00:25:37,125 --> 00:25:40,965
Speaker 3:  talking about Siri, there's just excitement in a way that I would, for example,

433
00:25:41,925 --> 00:25:45,605
Speaker 3:  contrast with the Vision Pro. Yeah. Which received 45 seconds

434
00:25:46,185 --> 00:25:48,765
Speaker 3:  of like, now you can look at your keyboard in immersive mode,

435
00:25:49,575 --> 00:25:51,685
Speaker 5:  Ultra wide displays. Thank you.

436
00:25:52,865 --> 00:25:56,405
Speaker 3:  But you know, the way, the way they talked about that product four months

437
00:25:56,425 --> 00:26:00,365
Speaker 3:  ago was like, we have to pretend this is the thing and the way they

438
00:26:00,365 --> 00:26:03,205
Speaker 3:  talked about Apple Intelligence today, but was like, this is the thing that

439
00:26:03,205 --> 00:26:04,805
Speaker 3:  changes your experience with this phone forever.

440
00:26:05,315 --> 00:26:08,765
Speaker 5:  What is the cool stuff here? Because I, I mean I obviously see there

441
00:26:09,505 --> 00:26:13,365
Speaker 5:  or wasn't there, I watched it here at this beautiful house, the image

442
00:26:13,365 --> 00:26:17,165
Speaker 5:  playground I was really excited about, but I can just like do that right

443
00:26:17,225 --> 00:26:20,845
Speaker 5:  now with most online image generators. What are the other like

444
00:26:21,505 --> 00:26:22,645
Speaker 3:  At high, at higher quality?

445
00:26:22,915 --> 00:26:25,965
Speaker 5:  Yeah. Yeah. Right. They will look better. Yeah. My, my shit post will be

446
00:26:25,965 --> 00:26:29,925
Speaker 5:  infinitely better with something else. What, what is cool? Like we

447
00:26:29,925 --> 00:26:33,605
Speaker 5:  got chat GPT integration, we got image playground, we got emojis,

448
00:26:34,015 --> 00:26:37,245
Speaker 5:  which is like make your own emojis. That's cool. That rules.

449
00:26:37,945 --> 00:26:41,925
Speaker 5:  What's the other AI stuff? Like what is this for? Oh, we, the the math notes

450
00:26:41,925 --> 00:26:43,325
Speaker 5:  where we'll like calculate the math.

451
00:26:43,485 --> 00:26:46,365
Speaker 3:  I think that's from everything. I don't think I, that's like ai but it's

452
00:26:46,365 --> 00:26:47,365
Speaker 3:  the old kinda, it's

453
00:26:47,365 --> 00:26:47,925
Speaker 5:  The old AI

454
00:26:47,925 --> 00:26:50,325
Speaker 4:  That's, this is, I mean this is the weirdest thing about all of the Apple

455
00:26:50,325 --> 00:26:54,125
Speaker 4:  Intelligence stuff is like, you and I kept accidentally disagreeing with

456
00:26:54,125 --> 00:26:57,485
Speaker 4:  each other on the live blog, which I really enjoyed. You kept saying so weird.

457
00:26:57,495 --> 00:27:00,925
Speaker 4:  We're 45 minutes in and there's been no ai. And I kept saying, all they're

458
00:27:00,925 --> 00:27:04,485
Speaker 4:  talking about is AI because like every single one of these features, it's

459
00:27:04,485 --> 00:27:08,165
Speaker 4:  just AI underneath. Yeah. It's not the AI they're talking about. And there

460
00:27:08,165 --> 00:27:11,925
Speaker 4:  is this like long spectrum of what is just software

461
00:27:12,025 --> 00:27:15,765
Speaker 4:  and what is AI and what is like new and it's, it's all

462
00:27:16,315 --> 00:27:17,685
Speaker 4:  sort of compressing together.

463
00:27:17,895 --> 00:27:19,885
Speaker 5:  Fuzzy as AI's definition is right now

464
00:27:20,485 --> 00:27:24,125
Speaker 4:  For sure. But like the, the everything on the iPad pure ai

465
00:27:24,305 --> 00:27:27,925
Speaker 4:  and they didn't talk about it as AI at all. They in fact pulled it out of

466
00:27:27,925 --> 00:27:31,045
Speaker 4:  the thing where they talked about AI and talked about it separately. But

467
00:27:31,085 --> 00:27:34,485
Speaker 4:  I think all the intelligence stuff to me felt like

468
00:27:35,565 --> 00:27:39,325
Speaker 4:  a sort of developer demo in a very real way. Right? Yeah. Like this is a

469
00:27:39,325 --> 00:27:43,205
Speaker 4:  developer conference and I think it, it, it made me think of the Vision

470
00:27:43,265 --> 00:27:46,045
Speaker 4:  Pro thing actually because to some extent, like what Apple is doing with

471
00:27:46,045 --> 00:27:48,645
Speaker 4:  all of this is saying, look, we built a bunch of really cool technology,

472
00:27:49,195 --> 00:27:52,565
Speaker 4:  here it is. Please go do something interesting with it. And

473
00:27:53,385 --> 00:27:57,365
Speaker 4:  so far, the Vision Pro, not so much we'll get to that later, but I

474
00:27:57,445 --> 00:28:01,045
Speaker 4:  I was kind of struck by the same thing of like, this is a lot of talk about

475
00:28:01,665 --> 00:28:05,525
Speaker 4:  the logistics of a compute cloud and not a lot of talk about

476
00:28:05,885 --> 00:28:08,525
Speaker 4:  features that people can use. Yeah. And there's a bunch of Siri stuff and

477
00:28:08,525 --> 00:28:12,405
Speaker 4:  I think we, we can talk about what's coming to Siri, but this idea,

478
00:28:12,645 --> 00:28:16,605
Speaker 4:  I think especially of the sort of Siri app intense thing where you

479
00:28:16,605 --> 00:28:20,525
Speaker 4:  can talk to your phone and it can do stuff on your device for you. That's

480
00:28:20,525 --> 00:28:24,125
Speaker 4:  the whole thing. Yeah. And, and I feel like Apple didn't weirdly sort of

481
00:28:24,125 --> 00:28:27,405
Speaker 4:  connect those dots today because they have this big idea of what Apple Intelligence

482
00:28:27,425 --> 00:28:30,325
Speaker 4:  can be. They have to convince everybody that this is going to be humongous

483
00:28:30,625 --> 00:28:34,605
Speaker 4:  and like the size of, you know, The iPhone as an industry. That's how you

484
00:28:34,605 --> 00:28:37,365
Speaker 4:  keep growing. If you're Apple, this whole thing I just could not stop thinking

485
00:28:37,365 --> 00:28:41,045
Speaker 4:  was like Apple executives talking to investors like in a very real way. Yes.

486
00:28:41,045 --> 00:28:44,965
Speaker 4:  Yes. With them being like, please we, we have a growth plan. We're gonna

487
00:28:44,965 --> 00:28:48,685
Speaker 4:  be so successful. Don't let us be the third most valuable company

488
00:28:48,685 --> 00:28:50,125
Speaker 4:  anymore. Like give it back to us.

489
00:28:50,125 --> 00:28:54,005
Speaker 3:  Well, I'll just give you the, the clearest, the clearest evidence of this

490
00:28:54,005 --> 00:28:57,685
Speaker 3:  that I can offer you. The keynote ended and we did not go to look at any

491
00:28:57,735 --> 00:29:01,685
Speaker 3:  demos. Yeah. We went to we we had lunch. Yeah. How was it? It was

492
00:29:01,685 --> 00:29:05,285
Speaker 3:  fine. I I I eat the, I ate the corporate food with an immense amount of guilt.

493
00:29:06,225 --> 00:29:08,885
Speaker 3:  So it was, it was fine. It was, you know, apple, they have a good chef at

494
00:29:08,885 --> 00:29:12,485
Speaker 3:  Cafe Maxx or whatever, but, but there were no, there was not like a thing

495
00:29:12,485 --> 00:29:15,405
Speaker 3:  where we like ran around playing with a bunch of AI stuff afterwards. Right.

496
00:29:15,845 --> 00:29:19,685
Speaker 3:  And I even think to some extent that OpenAI partnership is so that no one

497
00:29:19,685 --> 00:29:21,485
Speaker 3:  is comparing Apple to OpenAI. Oh.

498
00:29:21,565 --> 00:29:25,045
Speaker 5:  A hundred. I like, I think the AI OpenAI partnership is almost

499
00:29:25,075 --> 00:29:27,765
Speaker 5:  exclusively for investors rather than actual people.

500
00:29:28,035 --> 00:29:31,805
Speaker 3:  Well see, we, we have to get the stuff and like Ba Craig said,

501
00:29:31,865 --> 00:29:34,885
Speaker 3:  any place you see a blinking text cursor is a place where you can use this

502
00:29:34,885 --> 00:29:37,765
Speaker 3:  integration Yeah. In the system. That's pretty interesting. Yeah. Well

503
00:29:37,885 --> 00:29:41,125
Speaker 5:  A lot of it also felt like very windowy.

504
00:29:41,995 --> 00:29:45,085
Speaker 5:  Like a lot of the big, the biggest tools, the coolest stuff was like, oh,

505
00:29:45,305 --> 00:29:49,085
Speaker 5:  that's also stuff Microsoft announced. Oh yeah. Like, like, oh are

506
00:29:49,265 --> 00:29:50,405
Speaker 5:  we can convince an email.

507
00:29:50,795 --> 00:29:54,085
Speaker 4:  Yeah. Yeah. Cool. Yeah, it's really, it's, it's like

508
00:29:54,355 --> 00:29:57,325
Speaker 4:  genuinely insane to me how similar

509
00:29:57,875 --> 00:30:01,685
Speaker 4:  everybody is doing ai. Like, God help me if

510
00:30:01,705 --> 00:30:04,285
Speaker 4:  one more company is like, we have an idea for how to summarize your emails

511
00:30:04,345 --> 00:30:07,725
Speaker 4:  so that you can read them faster. Like, I'm good. Yeah. We have solved that

512
00:30:07,725 --> 00:30:09,405
Speaker 4:  problem. That I don't think was a real problem.

513
00:30:09,425 --> 00:30:12,205
Speaker 3:  Did you, did you see the fake email that they made? Nicer? It was actually

514
00:30:12,205 --> 00:30:12,685
Speaker 3:  very good.

515
00:30:12,825 --> 00:30:13,685
Speaker 4:  Was it? You

516
00:30:13,685 --> 00:30:16,405
Speaker 3:  Should get the screen cap of this from the keynote, but they're like, you

517
00:30:16,405 --> 00:30:18,685
Speaker 3:  know, sometimes you're write an email at work and it's a little too spicy.

518
00:30:18,705 --> 00:30:21,645
Speaker 3:  You need to make it nicer. And then there was like, they flashed up a mean

519
00:30:21,645 --> 00:30:24,965
Speaker 3:  email and it was like, guys, we have to stop doing this bullshit.

520
00:30:26,145 --> 00:30:28,045
Speaker 3:  And you're like, oh that's, that's how Craig emails.

521
00:30:29,565 --> 00:30:32,405
Speaker 3:  I must insist that you like blah blah blah. And they made it nicer and it

522
00:30:32,405 --> 00:30:36,285
Speaker 3:  was like, gentlemen, I must once again ask that you stop

523
00:30:36,485 --> 00:30:37,085
Speaker 3:  fucking it up.

524
00:30:38,465 --> 00:30:41,725
Speaker 4:  Is it Jeff Bezos who was famous for forwarding customer emails to people

525
00:30:41,725 --> 00:30:44,205
Speaker 4:  with just a question mark. It's very good. I'm imagining now you take that

526
00:30:44,205 --> 00:30:46,245
Speaker 4:  you can really and high the question mark and you're like, make this nice

527
00:30:46,505 --> 00:30:49,725
Speaker 4:  and it's just like, hello everyone. Yeah. I received this email from a customer.

528
00:30:50,025 --> 00:30:50,325
Speaker 4:  Can you,

529
00:30:50,325 --> 00:30:53,445
Speaker 3:  There's a real part of this to you point about features in the only the six

530
00:30:53,445 --> 00:30:56,685
Speaker 3:  ideas they are playing a little bit of catch, right? Yeah. Like

531
00:30:57,205 --> 00:31:00,645
Speaker 3:  Microsoft's been out there making Google dance this whole time. Like it's

532
00:31:00,645 --> 00:31:04,365
Speaker 3:  hard to demo features and say like, we made it more personal until

533
00:31:05,265 --> 00:31:08,685
Speaker 3:  you get to Siri and all the stuff they think Siri can do.

534
00:31:09,055 --> 00:31:12,765
Speaker 3:  Which is you just ask Siri, what time do I have to leave? So you get to my

535
00:31:12,845 --> 00:31:16,165
Speaker 3:  daughter's to answer settle, this is the example they used 50 times. And

536
00:31:16,165 --> 00:31:19,805
Speaker 3:  then Siri has to know that you have a daughter and where she is and where

537
00:31:19,805 --> 00:31:23,085
Speaker 3:  that dance recital is and what your schedule is. I think

538
00:31:23,555 --> 00:31:26,605
Speaker 3:  Federer you pointed out like it has to know if you like using Uber or Lyft.

539
00:31:26,605 --> 00:31:30,045
Speaker 3:  Like you just, you go down the list of things you do on your phone and you

540
00:31:30,045 --> 00:31:34,005
Speaker 3:  need all what they call personal context to make it work. And right now

541
00:31:34,355 --> 00:31:38,245
Speaker 3:  none of the other compute models we've seen pull this off. Yeah. Maybe

542
00:31:38,585 --> 00:31:42,285
Speaker 3:  Google will get there on Android. They're less good

543
00:31:43,305 --> 00:31:46,405
Speaker 3:  at making the people who work at Google talk to each other than Apple.

544
00:31:46,505 --> 00:31:48,405
Speaker 4:  But those are the only two companies that even can't, they're

545
00:31:48,405 --> 00:31:51,085
Speaker 3:  Only two companies that come close. Yeah. And like Google to some extent

546
00:31:51,385 --> 00:31:55,245
Speaker 3:  was trying to show these ideas right. In a less sort of like focused way.

547
00:31:55,455 --> 00:31:57,565
Speaker 3:  Apple was straight up like, here's what you're gonna do. You're gonna pick

548
00:31:57,565 --> 00:32:00,405
Speaker 3:  up Siri, you're gonna say I gotta get to this dance recital, make it happen.

549
00:32:00,665 --> 00:32:04,045
Speaker 3:  And then Siri is gonna run off and tie into all the app intents on your phone.

550
00:32:04,075 --> 00:32:06,645
Speaker 3:  It's gonna book a thing, it's gonna move a meeting, it's gonna call it today.

551
00:32:06,645 --> 00:32:08,685
Speaker 3:  And you're gonna get in the car, you're gonna look at the dance recital.

552
00:32:08,785 --> 00:32:12,045
Speaker 3:  You're gonna say edit me a video. It was a fishing trip. That was the demo.

553
00:32:12,285 --> 00:32:15,725
Speaker 3:  I think that's like, I went fishing, make me a video of this fishing trip

554
00:32:15,785 --> 00:32:19,605
Speaker 3:  of my son learning to fish and Siri is just gonna talk to whatever

555
00:32:19,605 --> 00:32:22,965
Speaker 3:  video editing app is on your phone that you've chosen. It's gonna like read

556
00:32:22,965 --> 00:32:25,805
Speaker 3:  all the videos for you. It's gonna make a thing. It's gonna pick a song about

557
00:32:25,805 --> 00:32:28,845
Speaker 3:  fishing from Apple Music. Here you go. Bob's your uncle, you're all done.

558
00:32:28,895 --> 00:32:32,845
Speaker 3:  Right. And like this thing, those are the features. They

559
00:32:32,845 --> 00:32:36,805
Speaker 3:  need a bunch of developers to expose all the hooks. Right. So

560
00:32:36,805 --> 00:32:40,325
Speaker 3:  that Siri can actually do it. I, I think it is very interesting that they're

561
00:32:40,325 --> 00:32:44,125
Speaker 3:  going to app intense. They're not doing the the stuff that we thought they

562
00:32:44,125 --> 00:32:48,085
Speaker 3:  might do, which is like screen reading your phone and clicking

563
00:32:48,085 --> 00:32:51,525
Speaker 3:  around for you. I think everyone has realized like that idea sounds great

564
00:32:51,585 --> 00:32:55,165
Speaker 3:  but is ultimately not trustworthy. I think it would also break Apple's

565
00:32:55,165 --> 00:32:56,485
Speaker 3:  relationships with its developers.

566
00:32:56,595 --> 00:33:00,405
Speaker 4:  Yeah. It's also unnecessary if you have a gigantic developer ecosystem

567
00:33:00,425 --> 00:33:02,965
Speaker 4:  of people who are very happy to build stuff for your platform.

568
00:33:03,225 --> 00:33:05,325
Speaker 5:  But that means they have to be happy to build stuff

569
00:33:05,585 --> 00:33:08,205
Speaker 4:  For this platform. Right. Which is super debatable right now I feel

570
00:33:08,205 --> 00:33:11,605
Speaker 5:  Like. Right? Yeah. Because this would also your, your example that means

571
00:33:11,605 --> 00:33:15,205
Speaker 5:  okay I'm not checking Outlook to, to find the email for when the recital

572
00:33:15,205 --> 00:33:18,765
Speaker 5:  is, I'm not checking Outlook to move this. You can tell I use Outlook to

573
00:33:18,765 --> 00:33:22,645
Speaker 5:  use to, to move my calendar around. I'm not going to Uber into the Uber app

574
00:33:22,645 --> 00:33:26,605
Speaker 5:  myself or the Lyft app. It's gonna auto choose all of that. Like

575
00:33:26,605 --> 00:33:29,885
Speaker 5:  that suddenly that's lost revenue for a lot of different people. Right. Just

576
00:33:29,885 --> 00:33:30,885
Speaker 5:  to make my experience. Yeah.

577
00:33:30,885 --> 00:33:34,125
Speaker 3:  Uber CEO is like, all right, when do I upsell you to Uber Plus or whatever,

578
00:33:34,285 --> 00:33:34,605
Speaker 3:  right.

579
00:33:34,885 --> 00:33:38,565
Speaker 4:  Nonsense. Right. What this means is the subscription

580
00:33:38,565 --> 00:33:42,525
Speaker 4:  economy in apps goes through the roof because all of a sudden I just

581
00:33:42,525 --> 00:33:45,765
Speaker 4:  need you to sign up for my thing. Right. Like if I'm Uber, I don't actually

582
00:33:45,765 --> 00:33:47,885
Speaker 4:  care if you're in the Uber app for the most part, as long as you're using

583
00:33:47,885 --> 00:33:51,045
Speaker 4:  Uber because I make money when you use Uber. So actually making it easy for

584
00:33:51,045 --> 00:33:51,645
Speaker 4:  you to use Uber

585
00:33:53,365 --> 00:33:57,245
Speaker 4:  benefits me to some extent. Right. Whereas if I run Yelp and

586
00:33:57,265 --> 00:34:01,085
Speaker 4:  I'm an ad-based system, I have exactly zero

587
00:34:01,085 --> 00:34:04,245
Speaker 4:  incentive to be part of this because all I'm doing is giving you the information

588
00:34:04,245 --> 00:34:07,365
Speaker 4:  that you want without you having to come look at my ads. So like the end

589
00:34:07,365 --> 00:34:10,925
Speaker 4:  of this is, and I think this is true with a lot of AI, is you look at a lot

590
00:34:10,925 --> 00:34:13,965
Speaker 4:  fewer things but you pay a lot more subscriptions. Yeah. And that,

591
00:34:14,885 --> 00:34:15,005
Speaker 3:  I

592
00:34:15,005 --> 00:34:16,445
Speaker 4:  Hate that. Dunno how I feel about that. Yeah.

593
00:34:16,645 --> 00:34:19,885
Speaker 5:  I, I can say I hate that. I don't wanna spend more money. Yeah.

594
00:34:19,995 --> 00:34:20,285
Speaker 4:  Yeah.

595
00:34:20,305 --> 00:34:23,125
Speaker 3:  But they did say they have something called onscreen awareness, which is

596
00:34:23,355 --> 00:34:25,925
Speaker 3:  they will know the state of your phone as you're using it. They'll able like

597
00:34:25,925 --> 00:34:29,405
Speaker 3:  help you. Again, this is Google apps

598
00:34:29,405 --> 00:34:30,445
Speaker 4:  Google maybe

599
00:34:30,885 --> 00:34:33,765
Speaker 3:  A million years ago. We have an entire feature about Google Nile from like

600
00:34:33,765 --> 00:34:34,365
Speaker 3:  10 years ago.

601
00:34:36,075 --> 00:34:39,125
Speaker 3:  Like these ideas have been floating around for a while and I think it's been

602
00:34:39,125 --> 00:34:42,805
Speaker 3:  very hard for Apple to make them see do in this context. 'cause we just

603
00:34:42,955 --> 00:34:46,125
Speaker 3:  came, we're in developer conference season, this is the end of it. And the

604
00:34:46,125 --> 00:34:49,205
Speaker 3:  same ideas have been demoed over and over again. The one that struck me as

605
00:34:49,205 --> 00:34:52,645
Speaker 3:  particularly interesting is type to Siri.

606
00:34:53,205 --> 00:34:55,605
Speaker 3:  'cause they kept saying it's, you know, chatbots are not this, we actually

607
00:34:55,605 --> 00:34:59,085
Speaker 3:  keep people safe by not letting them just do chat bot stuff. That's how you

608
00:34:59,085 --> 00:35:01,925
Speaker 3:  break this stuff and find its weaknesses and make it do evil stuff. Also

609
00:35:01,925 --> 00:35:05,845
Speaker 3:  you can now type to Siri. Yeah. And it's like first of all, they should

610
00:35:05,845 --> 00:35:08,925
Speaker 3:  have had type to Siri from the very beginning of Siri. I think Paul Miller

611
00:35:08,945 --> 00:35:12,605
Speaker 3:  on this show is like, it is a crime that you can't just like type

612
00:35:12,715 --> 00:35:14,605
Speaker 3:  Siri a command that you have to talk to it. Yeah.

613
00:35:14,835 --> 00:35:16,605
Speaker 5:  It's like an accessibility nightmare.

614
00:35:16,635 --> 00:35:17,165
Speaker 3:  Yeah. But this

615
00:35:17,165 --> 00:35:20,165
Speaker 4:  Is, well it does exist but you have to pick, which is ridiculous. Yeah.

616
00:35:20,275 --> 00:35:23,125
Speaker 3:  Like I'll just remind everybody that Siri launched, like the year The Verge

617
00:35:23,285 --> 00:35:26,205
Speaker 3:  launched. Like that's how old this thing is. Like

618
00:35:26,425 --> 00:35:27,365
Speaker 4:  Who do you think has done better?

619
00:35:29,785 --> 00:35:32,645
Speaker 3:  We are told that it's like a billion and a half request of Syria Day. Yeah.

620
00:35:32,675 --> 00:35:36,445
Speaker 3:  Just slightly behind the vch. Yeah. People command us to do set timers

621
00:35:36,465 --> 00:35:39,365
Speaker 3:  all day long. The Vergecast hotline is just like five minutes.

622
00:35:42,545 --> 00:35:44,885
Speaker 3:  But they should have had it from all long and now they do. So you can type

623
00:35:44,885 --> 00:35:48,485
Speaker 3:  to Siri whether that feels like a chat bot to people or just commands

624
00:35:49,185 --> 00:35:52,205
Speaker 3:  who, who knows. Yeah. One of the coolest features by the way they added to

625
00:35:52,515 --> 00:35:56,165
Speaker 3:  AirPods for Siri is now when it asks you if you wanna do something, you can

626
00:35:56,165 --> 00:35:57,405
Speaker 3:  just nod Yes. Or shake. No,

627
00:35:57,945 --> 00:35:58,845
Speaker 5:  I'm very excited about

628
00:35:58,845 --> 00:36:02,165
Speaker 3:  That. Very cool. So they're just kinda making Siri more natural and more

629
00:36:02,165 --> 00:36:06,045
Speaker 3:  like available to you and then increasing it set of capabilities. None

630
00:36:06,045 --> 00:36:09,005
Speaker 3:  of that is coming in the betas of iOS they're gonna be at Nope. That is just

631
00:36:09,005 --> 00:36:12,805
Speaker 3:  gonna slowly increase over the course of now until

632
00:36:12,805 --> 00:36:16,485
Speaker 3:  the end of iOS 18 and then we'll see what makes it, what gets pushed to iOS

633
00:36:16,605 --> 00:36:19,845
Speaker 3:  19, whatever. But they're basically saying like, we're starting now.

634
00:36:20,615 --> 00:36:23,285
Speaker 3:  We're, we're going, yeah. Siri's gonna become this thing. That's what we

635
00:36:23,285 --> 00:36:24,005
Speaker 3:  want it to be. And

636
00:36:24,005 --> 00:36:27,285
Speaker 5:  It and they're severely limiting what phones it will work on. Right,

637
00:36:27,815 --> 00:36:31,645
Speaker 3:  Right. And it's, you know, it's unclear whether that's because they want

638
00:36:31,645 --> 00:36:35,285
Speaker 3:  everybody to buy a new phone. They probably want everybody to buy a new phone.

639
00:36:35,405 --> 00:36:35,525
Speaker 3:  I

640
00:36:35,525 --> 00:36:37,165
Speaker 4:  Was gonna say, you don't think that's clear? I think

641
00:36:37,165 --> 00:36:39,325
Speaker 3:  That's fair. Clear. Well it, it's, I, I think I need to like spend more time

642
00:36:39,325 --> 00:36:42,885
Speaker 3:  thinking about the, the differences between the M1 and sort of like

643
00:36:43,325 --> 00:36:46,205
Speaker 3:  whatever the A series The, iPhone, The, iPhone 15 Pro. Like

644
00:36:46,995 --> 00:36:50,285
Speaker 3:  there's some stuff there that's different but yeah, they probably just want

645
00:36:50,285 --> 00:36:53,765
Speaker 3:  everybody to buy a new phone and you're not gonna get some like M1 MacBook

646
00:36:53,765 --> 00:36:54,965
Speaker 3:  error on two. Like I'm doing this. What

647
00:36:54,965 --> 00:36:58,685
Speaker 4:  We get in theory, if this cloud computing thing works as well as Apple

648
00:36:58,715 --> 00:37:02,605
Speaker 4:  says, you should actually be able to fail it pretty gracefully down and just

649
00:37:02,605 --> 00:37:04,965
Speaker 4:  do more and more in the cloud as you get to older and older phones. Well

650
00:37:04,965 --> 00:37:05,045
Speaker 4:  you

651
00:37:05,045 --> 00:37:07,565
Speaker 3:  Want, yeah, you want the older phones With the older cell radios pushing

652
00:37:07,565 --> 00:37:08,245
Speaker 3:  more and more of

653
00:37:08,315 --> 00:37:09,925
Speaker 4:  Hell yeah dude, let's go.

654
00:37:10,735 --> 00:37:14,605
Speaker 5:  Maybe the cell radios is it? Huh? Like maybe the cell radio is why

655
00:37:14,995 --> 00:37:17,725
Speaker 3:  Yeah. Who doess Or they just wanna sell a bunch of phones. I dunno if you

656
00:37:17,725 --> 00:37:20,685
Speaker 3:  looked at their last of earnings. Probably they're desperate for an upgrade

657
00:37:20,685 --> 00:37:21,365
Speaker 3:  cycle. Probably a mix.

658
00:37:21,365 --> 00:37:21,645
Speaker 5:  Yeah.

659
00:37:21,785 --> 00:37:25,485
Speaker 4:  But I do think this is an unusually developer dependent feature. Not only

660
00:37:25,485 --> 00:37:29,245
Speaker 4:  to plug into the intents, but like one of the things Apple did a lot of

661
00:37:29,375 --> 00:37:33,205
Speaker 4:  today, and we should get into it, like we have a lot of oss to get to,

662
00:37:34,465 --> 00:37:38,445
Speaker 4:  but they opened up a lot of new APIs

663
00:37:38,585 --> 00:37:41,765
Speaker 4:  and things people can tap into and gave them access to new stuff that's going

664
00:37:41,765 --> 00:37:45,725
Speaker 4:  on in the system. And like they're both giving users

665
00:37:45,955 --> 00:37:49,365
Speaker 4:  more stuff they can noodle around with. But also developers feel like they're

666
00:37:49,365 --> 00:37:52,805
Speaker 4:  getting way more access to like the underlying stuff

667
00:37:52,805 --> 00:37:56,525
Speaker 4:  happening on the device than they have in the past. And I feel like if you're

668
00:37:56,525 --> 00:37:59,005
Speaker 4:  Apple and you wanna like make things work across the device, you have to

669
00:37:59,005 --> 00:38:01,805
Speaker 4:  do that. But it also feels like this is Apple being like, okay, we are sort

670
00:38:01,805 --> 00:38:05,765
Speaker 4:  of throwing open The iPhone in a new way. Please come

671
00:38:06,345 --> 00:38:09,765
Speaker 4:  do cool things with it. Please. We need it so bad, please

672
00:38:09,765 --> 00:38:13,685
Speaker 5:  Come. Yeah. Which is like wild for them to be doing right now

673
00:38:13,685 --> 00:38:16,605
Speaker 5:  when probably their relationship with the developers has never been more

674
00:38:16,805 --> 00:38:17,045
Speaker 5:  fraught.

675
00:38:17,995 --> 00:38:21,565
Speaker 4:  Yeah. Yeah. I spend a lot of time trying to decide how big a deal I think

676
00:38:21,565 --> 00:38:24,805
Speaker 4:  that is because on the one hand, where the hell are you gonna go? Yeah. Yeah.

677
00:38:24,835 --> 00:38:27,365
Speaker 4:  Like what other moves do you have at this point? A hundred percent. And for

678
00:38:27,365 --> 00:38:31,045
Speaker 4:  Apple, this is another chance to shore that up because if this increases

679
00:38:31,045 --> 00:38:34,245
Speaker 4:  Apple's market share, it starts to fight against some of these other AI systems.

680
00:38:34,315 --> 00:38:38,085
Speaker 4:  Everybody who's like, oh, open AI is gonna break the paradigm of the smartphone.

681
00:38:38,085 --> 00:38:42,005
Speaker 4:  Apple can just sit here and be like, gotcha. We win and come make apps

682
00:38:42,005 --> 00:38:43,365
Speaker 4:  for us again. Yeah. But at the same

683
00:38:43,835 --> 00:38:44,285
Speaker 3:  Your rabbit.

684
00:38:44,575 --> 00:38:48,525
Speaker 4:  Right? Right. But at the same time it is, it is true that there are a lot

685
00:38:48,525 --> 00:38:52,245
Speaker 4:  of developers who do not believe Apple has their best interest at heart right

686
00:38:52,245 --> 00:38:52,325
Speaker 4:  now.

687
00:38:52,905 --> 00:38:56,645
Speaker 3:  And especially at the point of the all this stuff is to obviate the app.

688
00:38:56,645 --> 00:38:57,005
Speaker 3:  Right? Like

689
00:38:58,765 --> 00:39:02,685
Speaker 3:  I think, I think like fundamentally it's very interesting to look at

690
00:39:02,685 --> 00:39:05,365
Speaker 3:  Apple under a little bit of competitive pressure. Like, where are you gonna

691
00:39:05,365 --> 00:39:08,685
Speaker 3:  go? Is like, that's the monopoly. Where are you gonna go? Like we, they have

692
00:39:08,685 --> 00:39:12,485
Speaker 3:  all the customers. No one right now is like running

693
00:39:12,545 --> 00:39:16,325
Speaker 3:  off by an AI powered Surface Book. Feder again today

694
00:39:16,325 --> 00:39:19,805
Speaker 3:  said, technically we've been shipping AI PC since 2020.

695
00:39:19,875 --> 00:39:23,445
Speaker 3:  Alright. And some people wanna call that a category now. And it's like they

696
00:39:23,445 --> 00:39:27,165
Speaker 3:  are feeling pressure. It's good. Yeah. Like I, it's good for all of

697
00:39:27,165 --> 00:39:30,165
Speaker 3:  technology when these companies are ferociously competitive and this stuff

698
00:39:30,165 --> 00:39:33,085
Speaker 3:  has made them ferociously competitive. They all have the same idea.

699
00:39:34,075 --> 00:39:37,805
Speaker 3:  It's all the same stuff. We make this email 10% nicer. Yeah.

700
00:39:38,175 --> 00:39:40,165
Speaker 4:  Email summarization wars, baby, let's go.

701
00:39:40,435 --> 00:39:42,725
Speaker 3:  There's just a part of, but there's a part of this where at the end of it,

702
00:39:42,725 --> 00:39:46,445
Speaker 3:  it's just like, I'm sending David a robot email. It's his robot's

703
00:39:46,685 --> 00:39:50,285
Speaker 3:  summarizing it. He's sending me some weird mutant Jen

704
00:39:50,335 --> 00:39:53,045
Speaker 3:  Moshe response. It's like, what have we accomplished

705
00:39:53,155 --> 00:39:57,045
Speaker 5:  Here? I I love how it's just abstracting all communication. Like

706
00:39:57,045 --> 00:40:00,485
Speaker 5:  that's all AI does now. Is it just abstracts everything we say. Yeah.

707
00:40:00,485 --> 00:40:04,365
Speaker 4:  You'll send the first email and then it'll just be AI forever. Yeah.

708
00:40:04,365 --> 00:40:07,125
Speaker 4:  Yeah. And then something will end up in your calendar. Yeah. And that'll

709
00:40:07,125 --> 00:40:07,365
Speaker 4:  be great.

710
00:40:07,755 --> 00:40:11,725
Speaker 3:  Some stuff that they did not announce, which I was curious if

711
00:40:11,725 --> 00:40:15,645
Speaker 3:  they would, they announced AI image removal in the background of photos,

712
00:40:16,265 --> 00:40:20,045
Speaker 3:  but not anything beyond that. Right. So basically Smart Eraser,

713
00:40:20,045 --> 00:40:22,845
Speaker 3:  which like Google Photos has had forever and Lightroom now has,

714
00:40:23,705 --> 00:40:26,485
Speaker 3:  that's really interesting. They're gonna add this to more with our products.

715
00:40:26,785 --> 00:40:29,525
Speaker 3:  But you could go even farther and be like, you can just take people out of

716
00:40:29,525 --> 00:40:33,325
Speaker 3:  these photos and like, they didn't demo that. Right? Yeah. So Apple is clearly

717
00:40:33,395 --> 00:40:37,165
Speaker 3:  operating within some set of constraints. They did a lot of safety

718
00:40:37,485 --> 00:40:41,405
Speaker 3:  checking around the gen, their generative AI tool, which again produces just

719
00:40:41,405 --> 00:40:45,045
Speaker 3:  like horrific cartoons. I'm, I'm so excited. It's not nearly as photo realistic

720
00:40:45,205 --> 00:40:48,325
Speaker 3:  as the other stuff that we see on the market. Like Meta's AI tool is just

721
00:40:48,325 --> 00:40:51,485
Speaker 3:  like, just a weird spaghetti Jesus day and night. Right? Yeah.

722
00:40:52,775 --> 00:40:55,405
Speaker 3:  Apple can't make anything of that quality. 'cause it's running everything

723
00:40:55,405 --> 00:40:55,645
Speaker 3:  locally.

724
00:40:57,155 --> 00:40:59,725
Speaker 5:  Well it's using all of like your images to train on it,

725
00:41:00,495 --> 00:41:03,325
Speaker 3:  Right? No, it's not. It's no, there's no training. There's, so

726
00:41:03,325 --> 00:41:04,205
Speaker 5:  Where is it training? How's it

727
00:41:04,245 --> 00:41:06,445
Speaker 3:  Training? It just has a model. It's pre-trained model. It's running on your

728
00:41:06,445 --> 00:41:06,565
Speaker 3:  phone.

729
00:41:06,565 --> 00:41:08,245
Speaker 5:  Okay. So a pre-trained garbage model.

730
00:41:08,765 --> 00:41:11,645
Speaker 3:  Yeah. And they were very clear, actually David brought this up, the apple,

731
00:41:11,645 --> 00:41:14,805
Speaker 3:  just like everybody else. Like Yeah. We, we trained on the public web for

732
00:41:14,805 --> 00:41:17,605
Speaker 3:  its text models. Yep. Yeah. Just like Yeah, like you do. Like Yeah. And they're

733
00:41:17,605 --> 00:41:21,005
Speaker 3:  like, publishers could have opted out and it's like what publisher is like,

734
00:41:21,025 --> 00:41:24,965
Speaker 3:  get to make sure Apple Bot isn't scraping us. Maybe they were, I mean

735
00:41:25,125 --> 00:41:26,285
Speaker 3:  everyone freaked out about chat v Weren.

736
00:41:26,285 --> 00:41:27,565
Speaker 5:  There's one person was like,

737
00:41:27,565 --> 00:41:30,045
Speaker 3:  I don't even know if we block it disclosure, we have a robot's file.

738
00:41:30,555 --> 00:41:31,045
Speaker 4:  Someone

739
00:41:31,045 --> 00:41:32,045
Speaker 3:  Else is in charge of it.

740
00:41:35,105 --> 00:41:39,005
Speaker 3:  But like they said, they trained their image model on a bunch of Apple

741
00:41:39,015 --> 00:41:42,405
Speaker 3:  owned images in order to maintain safety.

742
00:41:43,155 --> 00:41:46,125
Speaker 3:  They selected the data they were training with, they licensed a bunch of

743
00:41:46,125 --> 00:41:49,325
Speaker 3:  books and news archives and stuff. So all that stuff is sitting on the, on

744
00:41:49,325 --> 00:41:53,245
Speaker 3:  the phone, which is why it's as limited as it is. It's not trained

745
00:41:53,245 --> 00:41:53,965
Speaker 3:  on your data.

746
00:41:54,805 --> 00:41:55,245
Speaker 5:  I was really

747
00:41:55,725 --> 00:41:58,245
Speaker 3:  Training, training a model on even just the amount of photos in like a normal

748
00:41:58,245 --> 00:42:00,005
Speaker 3:  phone. Like your phone would explode. Yeah.

749
00:42:00,075 --> 00:42:02,005
Speaker 5:  Yeah. Also just horrible.

750
00:42:02,835 --> 00:42:03,605
Speaker 3:  Yeah. I don't wanna, I

751
00:42:03,605 --> 00:42:06,085
Speaker 5:  Don't wanna, I don't wanna see anything. No, you, it, it does there.

752
00:42:06,315 --> 00:42:09,405
Speaker 3:  That that's why, that's why you need to go from 35 to 38 tops.

753
00:42:12,715 --> 00:42:14,245
Speaker 3:  Good comments on YouTube last week.

754
00:42:16,025 --> 00:42:18,805
Speaker 3:  But like that last piece where like, how will we keep it safe? How will we

755
00:42:18,805 --> 00:42:22,525
Speaker 3:  keep it from doing the weird stuff the other models have done. The weirdest

756
00:42:22,525 --> 00:42:26,325
Speaker 3:  part about this is on your own phone code, running locally

757
00:42:26,545 --> 00:42:29,925
Speaker 3:  on the phone you purchased with the operating system you're on, there's stuff

758
00:42:29,925 --> 00:42:33,765
Speaker 3:  Apple will not let you do in a way that right now Apple doesn't sit between

759
00:42:33,765 --> 00:42:36,725
Speaker 3:  you and what you type into pages. It doesn't sit between you and what you

760
00:42:36,725 --> 00:42:39,845
Speaker 3:  can record with the camera. It doesn't sit with between you and what you

761
00:42:39,845 --> 00:42:43,365
Speaker 3:  can edit and iMovie, but you open image playground and you're like, make

762
00:42:43,365 --> 00:42:46,245
Speaker 3:  me some horrific stuff. And Apple's just gonna say no because

763
00:42:46,255 --> 00:42:50,085
Speaker 5:  Apple doesn't want to run into what every single other company runs

764
00:42:50,085 --> 00:42:52,085
Speaker 5:  into where it's like, oh no, you did a racism.

765
00:42:52,865 --> 00:42:56,685
Speaker 3:  But that, so the difference is all that stuff is happening on a website controlled

766
00:42:56,685 --> 00:43:00,485
Speaker 3:  by a company, on someone else's server. There's a lot of precedent

767
00:43:00,545 --> 00:43:03,805
Speaker 3:  for, you know, once you're using cloud service, other people get to say what

768
00:43:03,805 --> 00:43:07,725
Speaker 3:  you do with it. There's not a lot of precedent for, you are running code

769
00:43:07,725 --> 00:43:09,605
Speaker 3:  locally on your computer company. If you can do,

770
00:43:09,745 --> 00:43:12,005
Speaker 4:  Do it in airplane mode, should there be any

771
00:43:12,005 --> 00:43:15,365
Speaker 3:  Rules. Right. And the one that I think of all the time, I've asked a bunch

772
00:43:15,365 --> 00:43:18,205
Speaker 3:  of people about this, the one that comes to mind right now is Adobe Photoshop

773
00:43:18,205 --> 00:43:21,845
Speaker 3:  will not let you print out a dollar bill. You really

774
00:43:21,915 --> 00:43:24,805
Speaker 3:  scan a dollar into Photoshop and try to print it. I'll be like, no, it's

775
00:43:24,805 --> 00:43:28,205
Speaker 3:  a dollar. We're not gonna let you do counterfeiting. The government has asked

776
00:43:28,205 --> 00:43:31,365
Speaker 3:  us very politely to not enable counterfeiting and just like won't do it.

777
00:43:32,315 --> 00:43:35,045
Speaker 3:  Okay. Like we've just, I I think everyone has sort of like accepted over

778
00:43:35,045 --> 00:43:38,965
Speaker 3:  time. Yeah. You, you know, fine. Like don't do counterfeiting

779
00:43:38,965 --> 00:43:39,525
Speaker 3:  in Photoshop.

780
00:43:39,875 --> 00:43:43,685
Speaker 5:  Yeah. But that's very different than like, what, just reading the paper and,

781
00:43:43,685 --> 00:43:47,005
Speaker 5:  and what kind of Apple tested on and what they're trying to get rid of. Yeah.

782
00:43:47,675 --> 00:43:51,045
Speaker 5:  It's like, it's just all the shit posting, it's, it's all the stuff like

783
00:43:51,045 --> 00:43:53,445
Speaker 5:  Yeah. Sometimes you do wanna send something absolutely horrible to your phone.

784
00:43:53,445 --> 00:43:53,645
Speaker 5:  Yeah.

785
00:43:53,645 --> 00:43:56,205
Speaker 4:  Like I bet Photoshop will let you print out like a bunch of butts.

786
00:43:56,395 --> 00:43:58,045
Speaker 3:  Yeah. Yeah. The Photoshop will absolutely,

787
00:43:58,345 --> 00:43:59,405
Speaker 5:  In fact, and

788
00:43:59,405 --> 00:44:00,285
Speaker 4:  I, the Apple will not let you,

789
00:44:00,405 --> 00:44:04,325
Speaker 3:  I don't know if Fireies is ready for like, make a bunch of butts, but Firefly

790
00:44:04,325 --> 00:44:06,965
Speaker 3:  runs in the cloud, right? Yeah. So we've accepted this thing where it's like

791
00:44:06,965 --> 00:44:10,925
Speaker 3:  you're using someone else's computer, particularly for free and they

792
00:44:10,925 --> 00:44:13,005
Speaker 3:  have to say, well, it's good or bad. Yeah. And we have some expectations

793
00:44:13,005 --> 00:44:16,125
Speaker 3:  about what they will allow. You're using your own computer. There are no,

794
00:44:16,125 --> 00:44:19,285
Speaker 3:  there we do not usually allow these things to have rules. Right. You

795
00:44:19,285 --> 00:44:20,685
Speaker 4:  Can make all the butts you want. Right.

796
00:44:20,685 --> 00:44:21,965
Speaker 3:  If you pick an open source,

797
00:44:24,045 --> 00:44:25,365
Speaker 5:  I mean, that is the use

798
00:44:25,365 --> 00:44:28,245
Speaker 3:  Case. Finally, finally, a way to sell Chromebooks at scale.

799
00:44:30,565 --> 00:44:33,845
Speaker 3:  I PC is from Microsoft. All the butts you want.

800
00:44:35,665 --> 00:44:39,245
Speaker 3:  But yeah, if you take an open source model and like run it on some PC today,

801
00:44:39,595 --> 00:44:42,725
Speaker 3:  nothing's stopping you. Right. And there's not really a way to stop you unless

802
00:44:42,885 --> 00:44:46,685
Speaker 3:  I know the chip makers prevented. Like that's just not gonna happen. Right.

803
00:44:47,595 --> 00:44:51,205
Speaker 3:  Like I've asked Lisa Sue this question, I've asked Qualcomm this question,

804
00:44:51,845 --> 00:44:54,285
Speaker 3:  they're like, yeah, if the government tells us not to allow stuff, we do

805
00:44:54,285 --> 00:44:57,925
Speaker 3:  it anyhow. The point of this is I think people are gonna get this, they're

806
00:44:57,925 --> 00:45:00,925
Speaker 3:  gonna assume it's their computer and the thing that it will not be is a hundred

807
00:45:00,925 --> 00:45:01,805
Speaker 3:  percent their computer anymore.

808
00:45:02,145 --> 00:45:05,485
Speaker 5:  No. It, and I, I kind find, kind of find that a little gross.

809
00:45:06,805 --> 00:45:10,445
Speaker 5:  I mean it's, it's, I think if, if it was an just a straight up app, if it

810
00:45:10,445 --> 00:45:14,045
Speaker 5:  wasn't like integrated into a whole bunch of other apps, I wouldn't feel

811
00:45:14,045 --> 00:45:17,205
Speaker 5:  as gross about it. If it was just like, oh yeah, that's the app full image

812
00:45:17,205 --> 00:45:20,125
Speaker 5:  generator app. It won't let you make butts. I'd be like, okay, that's fair.

813
00:45:20,665 --> 00:45:24,565
Speaker 5:  But like, okay. If you wanna make butts in any of these other tools, I

814
00:45:24,565 --> 00:45:25,245
Speaker 5:  should be allowed to,

815
00:45:25,955 --> 00:45:27,605
Speaker 3:  Well, I think we're, have our first test.

816
00:45:28,145 --> 00:45:29,125
Speaker 5:  I'm so excited. Apple,

817
00:45:29,135 --> 00:45:32,525
Speaker 3:  Apple, apple. The, again, the vibe at WC is like, we know people are gonna

818
00:45:32,525 --> 00:45:35,685
Speaker 3:  do weird stuff with our thing. We'll take it down when we need to. They,

819
00:45:35,835 --> 00:45:39,125
Speaker 3:  they very much know that the systems will hallucinate and there's gonna be

820
00:45:39,125 --> 00:45:42,445
Speaker 3:  some weird outcomes. They're just like, ready for it. Yeah. But it, I just

821
00:45:42,445 --> 00:45:45,085
Speaker 3:  like, and then I think we should take a break and actually talk about all

822
00:45:45,085 --> 00:45:48,925
Speaker 3:  the OSS after this. But like the one piece of this that like philosophically

823
00:45:48,925 --> 00:45:52,085
Speaker 3:  I'm thinking about is like, this is the first time an operating system is

824
00:45:52,085 --> 00:45:54,365
Speaker 3:  gonna be straight up. Like no, no,

825
00:45:54,925 --> 00:45:55,205
Speaker 5:  I, yeah.

826
00:45:55,205 --> 00:45:57,845
Speaker 3:  We're just not gonna let you do it. And Apple's approach to it is like, we

827
00:45:57,845 --> 00:45:59,565
Speaker 3:  are the ones generating it, so we're gonna set the rules.

828
00:46:00,585 --> 00:46:02,845
Speaker 5:  That's just, that feels weird to me. It's

829
00:46:02,845 --> 00:46:03,645
Speaker 3:  Weird. It's gonna be weird.

830
00:46:03,645 --> 00:46:04,365
Speaker 5:  Yeah, I don't like that.

831
00:46:05,225 --> 00:46:07,805
Speaker 3:  And all the other ones are on the cloud, so you can't like roll up to Google

832
00:46:07,805 --> 00:46:09,605
Speaker 3:  and be like, here's what I wanna do with your data center today.

833
00:46:09,805 --> 00:46:12,965
Speaker 5:  I think I just wanna say free the buts. Like, we gotta free, we gotta

834
00:46:12,965 --> 00:46:13,245
Speaker 3:  Take a

835
00:46:13,245 --> 00:46:15,925
Speaker 5:  Break. So we're taking a break. We'll take a break. We'll

836
00:46:15,925 --> 00:46:17,965
Speaker 3:  Fine. Every, everybody think about what you, whatever you need to think about

837
00:46:18,035 --> 00:46:18,605
Speaker 3:  what we run.

838
00:46:18,635 --> 00:46:19,645
Speaker 5:  Free the buts. Free

839
00:46:19,645 --> 00:46:20,765
Speaker 3:  The buts. Well, we're right back.

840
00:49:46,265 --> 00:49:47,825
Speaker 4:  I feel like the first one we should start with is

841
00:50:35,925 --> 00:50:39,645
Speaker 8:  customizable. You can like resize the tiles and you can move things around

842
00:50:40,825 --> 00:50:44,765
Speaker 8:  and then that kind of feeds into the lock screen

843
00:50:45,055 --> 00:50:48,485
Speaker 8:  where you can change the shortcuts. The like,

844
00:50:48,835 --> 00:50:50,365
Speaker 8:  what is it? Flashlight in camera?

845
00:50:50,675 --> 00:50:53,405
Speaker 4:  Yeah, flashlight. Bottom, left camera, bottom right. Yeah. Right.

846
00:50:54,015 --> 00:50:57,045
Speaker 8:  Which for some reason I have trouble hitting those things, but you can change

847
00:50:57,285 --> 00:51:00,485
Speaker 8:  'em and you can make them pretty much anything that's in the control center

848
00:51:00,485 --> 00:51:01,165
Speaker 8:  options. I think

849
00:51:01,905 --> 00:51:04,965
Speaker 3:  The Haylight folks are very excited because you can just put Hali in

850
00:51:05,295 --> 00:51:06,525
Speaker 4:  Video keynote. True.

851
00:51:06,575 --> 00:51:10,525
Speaker 3:  Right on watch watch screen. Yeah. Which is wild. Like do I

852
00:51:10,525 --> 00:51:13,285
Speaker 3:  want to blame this on EU regulatory pressure? I would like to blame,

853
00:51:15,505 --> 00:51:16,965
Speaker 5:  But it's rules. I think it's

854
00:51:16,965 --> 00:51:19,365
Speaker 3:  Great. It's cool. It's just like what everybody wants is to be able to reprogram

855
00:51:19,365 --> 00:51:21,245
Speaker 3:  a bunch of these buttons to different kinds apps. Yeah. It's,

856
00:51:21,245 --> 00:51:25,045
Speaker 5:  It's, I mean it's something that Android's been doing what, since it

857
00:51:25,045 --> 00:51:25,285
Speaker 5:  started

858
00:51:26,285 --> 00:51:27,485
Speaker 8:  A long time. I would

859
00:51:27,485 --> 00:51:27,685
Speaker 3:  Say

860
00:51:28,705 --> 00:51:32,685
Speaker 4:  It is so funny watching Craig Rigi stand on stage and be like, look, I

861
00:51:32,685 --> 00:51:36,325
Speaker 4:  have an app icon. I can put it anywhere I want. Yeah. And it's like, oh my

862
00:51:36,325 --> 00:51:36,645
Speaker 4:  God, Craig

863
00:51:36,785 --> 00:51:37,605
Speaker 3:  By the way, I just wanna put

864
00:51:38,465 --> 00:51:40,925
Speaker 4:  You, you can't put No, you can't. No thank you.

865
00:51:41,145 --> 00:51:42,285
Speaker 3:  No, it's still a grid.

866
00:51:42,525 --> 00:51:45,285
Speaker 4:  I compared to the stage manager in the live blog and a bunch of people gave

867
00:51:45,285 --> 00:51:48,325
Speaker 4:  me shit for it. And I'm Right. It's stage manager. It's

868
00:51:48,325 --> 00:51:52,085
Speaker 3:  Not like a preform, you can't get to like desktop levels of

869
00:51:52,085 --> 00:51:56,005
Speaker 3:  crazy. Yeah, it's a grid. Yeah. And you can put some stuff on

870
00:51:56,005 --> 00:51:58,005
Speaker 3:  one side or the bottom, honestly,

871
00:51:58,225 --> 00:52:02,085
Speaker 5:  Moving out of the grid and making you be like, allowing you to put wherever

872
00:52:02,085 --> 00:52:05,005
Speaker 5:  you want would be good security for them. 'cause if you get somebody's phone,

873
00:52:05,005 --> 00:52:07,125
Speaker 5:  you're like, ah, I don't fucking know where any of these apps are.

874
00:52:07,635 --> 00:52:07,925
Speaker 8:  It's

875
00:52:07,925 --> 00:52:09,765
Speaker 3:  Just a pile. It's just a pile.

876
00:52:10,225 --> 00:52:11,645
Speaker 5:  Oh God. Like done.

877
00:52:11,915 --> 00:52:15,565
Speaker 3:  They also announced what I, I think should just be known as the Grinder feature.

878
00:52:15,945 --> 00:52:19,885
Speaker 3:  Oh, the Ashley Madison if you will. Yeah. Where you can have a folder

879
00:52:19,885 --> 00:52:21,165
Speaker 3:  full of hidden apps that are locked.

880
00:52:21,365 --> 00:52:24,365
Speaker 5:  I was like, oh, what are those hidden apps? Oh, well if you're married, I

881
00:52:24,365 --> 00:52:26,645
Speaker 5:  know what those hidden apps are. So

882
00:52:27,285 --> 00:52:28,005
Speaker 8:  Sensitive information.

883
00:52:28,225 --> 00:52:29,925
Speaker 5:  I'm gonna be suspicious of all of y'all's phones.

884
00:52:30,485 --> 00:52:33,725
Speaker 4:  Oh, that's where I put the, the notes for things. I'm gonna buy my wife because

885
00:52:34,045 --> 00:52:35,285
Speaker 4:  I just don't want her to know ahead

886
00:52:35,285 --> 00:52:36,245
Speaker 3:  Of time. You're real sweet.

887
00:52:36,645 --> 00:52:38,045
Speaker 5:  A whole app just for that.

888
00:52:39,745 --> 00:52:43,045
Speaker 4:  No, but so I'm very excited about the, the apps on the home screen thing.

889
00:52:43,045 --> 00:52:46,685
Speaker 4:  Like that rules. Just the thing where you can put a row of them on the side

890
00:52:46,785 --> 00:52:50,725
Speaker 4:  and nowhere else. Wonderful. Yeah. Like that's where icons

891
00:52:50,725 --> 00:52:53,205
Speaker 4:  should go. Like if you've ever tried to use your phone in one hand, it's

892
00:52:53,205 --> 00:52:57,085
Speaker 4:  stupid that there are icons everywhere. Anyway. The thing that I think

893
00:52:57,085 --> 00:53:00,805
Speaker 4:  is bad is the, the color themeing that Apple is trying to do. No,

894
00:53:00,805 --> 00:53:04,125
Speaker 4:  I've seen a bunch of screenshots of this. So in theory you can, like apps

895
00:53:04,125 --> 00:53:07,805
Speaker 4:  will be able to theme their own apps, so you'll be, or their own icons. So

896
00:53:07,805 --> 00:53:09,485
Speaker 4:  you'll be able to do lots of different things with it. But you can also,

897
00:53:09,485 --> 00:53:13,445
Speaker 4:  it seems like just brute force a color across the whole home screen.

898
00:53:14,015 --> 00:53:17,845
Speaker 4:  Every single screenshot I've seen of it from Dev so far looks like

899
00:53:17,845 --> 00:53:18,085
Speaker 4:  trash.

900
00:53:18,145 --> 00:53:21,085
Speaker 5:  That's because they haven't done it. Right. It's gotta be that really horrible

901
00:53:21,135 --> 00:53:24,565
Speaker 5:  green and you've gotta have like the matrix background on your phone

902
00:53:25,065 --> 00:53:27,005
Speaker 5:  and then it's gonna be sick. I

903
00:53:27,005 --> 00:53:27,645
Speaker 8:  Don't believe that.

904
00:53:28,725 --> 00:53:32,045
Speaker 3:  I don't think so. I dunno if anyone has ever seen Kranz Slack theme

905
00:53:33,365 --> 00:53:35,445
Speaker 3:  Unusable. Yeah. An unusable.

906
00:53:35,845 --> 00:53:38,685
Speaker 5:  I it's, it's a beautiful security measure. No one's gonna be like looking

907
00:53:38,685 --> 00:53:40,725
Speaker 5:  over my shoulder at Slack because they're gonna be like, Nope. Mm.

908
00:53:40,945 --> 00:53:43,885
Speaker 4:  It screws, you know, you have to look at it. Right? Like, that's, that's

909
00:53:43,885 --> 00:53:44,565
Speaker 4:  the, the

910
00:53:44,565 --> 00:53:46,885
Speaker 5:  Challenge there. Yeah. But you like, you just harden yourself.

911
00:53:46,915 --> 00:53:49,885
Speaker 4:  This explains a lot of why sometimes I'll Slack you and like eight days later

912
00:53:49,885 --> 00:53:50,685
Speaker 4:  you're like, oh hey.

913
00:53:52,715 --> 00:53:55,645
Speaker 5:  Yeah, I don't like it. But no, I, I thought, I thought that was like both

914
00:53:55,665 --> 00:53:59,485
Speaker 5:  the dumbest thing and also my favorite thing. 'cause like if

915
00:53:59,515 --> 00:54:03,005
Speaker 5:  there's the potential to make it look really pretty, you could

916
00:54:03,005 --> 00:54:06,325
Speaker 5:  theoretically, but every example they had on there was like

917
00:54:07,005 --> 00:54:07,725
Speaker 5:  horrible. Yeah. Like

918
00:54:07,725 --> 00:54:10,845
Speaker 4:  What Google has done with Material UI think is is great. And they've done

919
00:54:10,845 --> 00:54:14,005
Speaker 4:  a good job of making it match with backgrounds. And that's some of what Apple

920
00:54:14,025 --> 00:54:17,805
Speaker 4:  is trying to do here, it seems like. But I don't know, it's just like a weird

921
00:54:17,935 --> 00:54:19,605
Speaker 4:  brute force thing that I'm, I'm not into

922
00:54:19,835 --> 00:54:23,085
Speaker 5:  Even the sample he did where he is like, it's like the dog and then there's

923
00:54:23,085 --> 00:54:25,525
Speaker 5:  bunch of tennis balls and he was like, yeah, I can choose a color from here

924
00:54:25,525 --> 00:54:29,005
Speaker 5:  and immediately chose the tennis ball color. So like that was like, that

925
00:54:29,005 --> 00:54:31,885
Speaker 5:  was in the demo. Yeah. He made it look like garbage in the demo.

926
00:54:32,075 --> 00:54:35,685
Speaker 3:  Yeah. Yeah. I You got, you choose all of, you underestimate the power of

927
00:54:35,855 --> 00:54:39,485
Speaker 3:  teens to theme their phones. Like this is for

928
00:54:39,715 --> 00:54:43,285
Speaker 3:  some huge percentage of people. This is the reason they have been jailbreaking

929
00:54:43,285 --> 00:54:44,205
Speaker 3:  their phones. Oh,

930
00:54:44,205 --> 00:54:46,805
Speaker 5:  Totally. No, no. There's gonna be so many purple and pink

931
00:54:47,915 --> 00:54:51,005
Speaker 5:  very, very soon with like the comic sands font. Yeah.

932
00:54:51,305 --> 00:54:53,845
Speaker 3:  That's gonna be amazing. I'm very excited for the, the teenagers to ruin

933
00:54:53,845 --> 00:54:57,805
Speaker 3:  their phones. Yeah. But this is like table stakes stuff. Yeah. Apple

934
00:54:58,085 --> 00:55:00,885
Speaker 3:  has not had forever and now they're like, okay, you can like customize your

935
00:55:00,885 --> 00:55:04,005
Speaker 3:  on screen even more. And the reason they never had it before was because

936
00:55:04,325 --> 00:55:07,805
Speaker 3:  Steve Jobs and maybe only Steve Jobs had the, the,

937
00:55:08,345 --> 00:55:11,285
Speaker 3:  the conviction to say, most of you have bad taste and I don't want you to

938
00:55:11,285 --> 00:55:13,925
Speaker 3:  make my phone ugly. And now they're outta those guys. Yeah.

939
00:55:14,065 --> 00:55:15,005
Speaker 5:  Jo Joni left.

940
00:55:15,275 --> 00:55:16,605
Speaker 3:  He's gone. Yeah. What's he gonna do?

941
00:55:16,995 --> 00:55:19,965
Speaker 5:  Yeah. He was like, they like, and with him all good taste went too.

942
00:55:20,345 --> 00:55:23,125
Speaker 3:  All the rest of the designers left. They're gonna throw up some other designers.

943
00:55:23,515 --> 00:55:27,485
Speaker 3:  Like here's this guy. He made the fabric band on the Vision Pro.

944
00:55:27,585 --> 00:55:28,765
Speaker 3:  He thinks we have horrible taste.

945
00:55:30,085 --> 00:55:33,605
Speaker 8:  I feel like every year for the past few years we've been allowed to make

946
00:55:33,625 --> 00:55:36,805
Speaker 8:  our phones a little bit uglier. Yeah, yeah. Like, we're just given a little

947
00:55:36,805 --> 00:55:37,205
Speaker 8:  bit more

948
00:55:37,505 --> 00:55:40,325
Speaker 5:  And, and we should be allowed to make them as ugly as possible. If I want

949
00:55:40,865 --> 00:55:42,965
Speaker 5:  in MySpace. Let me,

950
00:55:43,435 --> 00:55:46,085
Speaker 3:  It's, it's fair. It's so obviously coming. Just give it,

951
00:55:46,585 --> 00:55:47,125
Speaker 5:  I'm so excited.

952
00:55:48,045 --> 00:55:50,605
Speaker 3:  Even though even the control center stuff is really fascinating that there,

953
00:55:51,145 --> 00:55:52,205
Speaker 3:  it now has pages.

954
00:55:53,765 --> 00:55:57,485
Speaker 3:  I think Ford, CEO, Jim Farley was out there posting on threads about

955
00:55:57,945 --> 00:56:01,725
Speaker 3:  how excited he is for the Ford Pass integration with

956
00:56:01,725 --> 00:56:02,365
Speaker 3:  control center.

957
00:56:02,665 --> 00:56:04,565
Speaker 5:  The Mach e got like a little cameo Yeah.

958
00:56:04,705 --> 00:56:07,405
Speaker 3:  On the phone. You can, you can super unlock your doors from control center

959
00:56:07,425 --> 00:56:08,445
Speaker 3:  now. Great.

960
00:56:08,485 --> 00:56:10,925
Speaker 5:  I think they even unlocked the doors. I think they just turned on the air

961
00:56:10,925 --> 00:56:11,845
Speaker 5:  conditioning in the car.

962
00:56:12,405 --> 00:56:15,485
Speaker 3:  That was the demo during the keynote. But the, the integration has, you can

963
00:56:15,485 --> 00:56:18,725
Speaker 3:  unlock the doors from your luxury. Awesome. It's just what everybody wanted

964
00:56:19,225 --> 00:56:23,005
Speaker 3:  was to not have to use the FordPass app, but it's like, even that

965
00:56:23,185 --> 00:56:27,005
Speaker 3:  is just, it's a little bit more, just let anything happen here. Yeah.

966
00:56:27,275 --> 00:56:30,925
Speaker 3:  Like control center I think is a successful product

967
00:56:31,065 --> 00:56:34,325
Speaker 3:  for Apple. I think. So it does the thing that everybody wants it to do. Yeah.

968
00:56:34,345 --> 00:56:36,725
Speaker 3:  And now it's just another surface to muddy up.

969
00:56:37,125 --> 00:56:40,245
Speaker 5:  I did like, well 'cause Jim and I have talked about this a lot where we talk

970
00:56:40,245 --> 00:56:43,485
Speaker 5:  about the smart home stuff. And the smart home controls in the control center

971
00:56:43,755 --> 00:56:45,245
Speaker 5:  were pretty terrible.

972
00:56:45,915 --> 00:56:49,725
Speaker 3:  They weren't great. Yeah. Because they kept on, they moved them around,

973
00:56:50,055 --> 00:56:52,005
Speaker 3:  which is exactly what you don't want to Yeah.

974
00:56:52,005 --> 00:56:54,765
Speaker 5:  You're like, I wanna turn off my light. Oh cool. You decided I never need

975
00:56:54,765 --> 00:56:55,445
Speaker 5:  to turn off my light.

976
00:56:56,075 --> 00:56:56,565
Speaker 4:  Yeah, there's

977
00:56:56,565 --> 00:56:59,765
Speaker 3:  The button. Because the, the four that they do, they auto-populate based

978
00:56:59,765 --> 00:57:02,845
Speaker 3:  on what you've used last. Horrible. So if you're like, I wanna turn off this

979
00:57:02,845 --> 00:57:06,165
Speaker 3:  light, you gotta, you end up all the way in the home app. Yeah. Whereas the

980
00:57:06,165 --> 00:57:09,725
Speaker 3:  light you turned on yesterday is like, here I am ready to turn me on again.

981
00:57:10,145 --> 00:57:14,045
Speaker 5:  No, I never go in that room. Leave me alone. Yeah. So, so I think the

982
00:57:14,045 --> 00:57:17,365
Speaker 5:  fact that you can customize the home stuff more, that that was like, I was

983
00:57:17,365 --> 00:57:20,445
Speaker 5:  like, okay. 'cause that gives me, that's like I think about how many swipes

984
00:57:20,445 --> 00:57:23,125
Speaker 5:  it takes me to like turn off a light in my house. Right? Yeah. And right

985
00:57:23,125 --> 00:57:26,125
Speaker 5:  now it's like, okay, I gotta go into the home app. I gotta find the look

986
00:57:26,125 --> 00:57:28,765
Speaker 5:  for it. If it's not on that front page, I gotta go to the thing and now be

987
00:57:28,765 --> 00:57:31,485
Speaker 5:  like swipe, swipe to the home section

988
00:57:32,185 --> 00:57:34,685
Speaker 3:  And soon you're able to just be like, Siri dark. Yeah. I

989
00:57:34,685 --> 00:57:38,405
Speaker 4:  Was just gonna to say, there's now like a lot of ways to do everything on

990
00:57:38,405 --> 00:57:42,045
Speaker 4:  your phone. Yes. Because to some extent your home screen now has

991
00:57:42,045 --> 00:57:45,245
Speaker 4:  widgets, your lock screen now has widgets. There's still the weird old like

992
00:57:45,255 --> 00:57:48,765
Speaker 4:  today screen to the left of your home screen. Oh yeah. The, you can put stuff

993
00:57:48,985 --> 00:57:52,365
Speaker 4:  in apps, you can long press on an app icon to do stuff. You can now, one

994
00:57:52,365 --> 00:57:55,045
Speaker 4:  cool thing that I saw, you can long press on an app icon to turn it into

995
00:57:55,045 --> 00:57:58,365
Speaker 4:  a widget in place on the home screen, which looks very cool. It's neat.

996
00:57:58,915 --> 00:58:02,045
Speaker 4:  They like breezed through this stuff to get to the ai and there's actually

997
00:58:02,085 --> 00:58:04,925
Speaker 4:  a lot of like little design details in I 18 that look really great.

998
00:58:05,985 --> 00:58:09,405
Speaker 3:  The new settings for flashlight in the flashlight widget are awesome. Yeah.

999
00:58:09,405 --> 00:58:12,165
Speaker 3:  You can set the width of the beam of the flashlight. It's awesome. Beautiful.

1000
00:58:12,165 --> 00:58:16,045
Speaker 3:  They should have spent an hour on this. That's, I've like, yo,

1001
00:58:16,565 --> 00:58:20,485
Speaker 4:  I honestly believe like in any other year where Apple didn't feel like

1002
00:58:20,485 --> 00:58:23,405
Speaker 4:  it either had to or had an AI story to tell,

1003
00:58:25,025 --> 00:58:28,205
Speaker 4:  we would've spent like an hour talking about little tiny design details and

1004
00:58:28,205 --> 00:58:31,285
Speaker 4:  there would've been long videos about, like, I just saw one thing on Twitter

1005
00:58:31,555 --> 00:58:34,765
Speaker 4:  that now when you press the volume button, the bezel

1006
00:58:35,115 --> 00:58:38,645
Speaker 4:  indents slightly on the screen so you can see the button being pressed. Just

1007
00:58:38,645 --> 00:58:40,925
Speaker 4:  this like tiny little affordance that it looks like it's being pressed from

1008
00:58:40,925 --> 00:58:43,285
Speaker 4:  the side. Oh, that's beautiful. Love it. But also,

1009
00:58:43,625 --> 00:58:45,885
Speaker 3:  No, no, I know, I know what they're doing with that. You know what they're

1010
00:58:45,885 --> 00:58:47,565
Speaker 3:  doing with that. We all know what they're doing with that. They're getting

1011
00:58:47,565 --> 00:58:49,005
Speaker 3:  ready, ready to take the buttons away.

1012
00:58:49,505 --> 00:58:51,725
Speaker 4:  No, that was my next thought. Oh, that's interesting. Yeah.

1013
00:58:51,725 --> 00:58:53,965
Speaker 5:  I hate both of you for ushering that into existence.

1014
00:58:54,185 --> 00:58:57,285
Speaker 3:  Oh no. I mean the second I saw them be like, the screen will dink, I'm like,

1015
00:58:57,285 --> 00:58:58,005
Speaker 3:  oh, I know what you're doing.

1016
00:58:59,555 --> 00:59:03,445
Speaker 4:  It's true. You don't make my screen dink. But we, we have paired the lead

1017
00:59:03,445 --> 00:59:05,845
Speaker 4:  long enough. We got our RCS. It's RCS time. Yeah.

1018
00:59:06,285 --> 00:59:08,205
Speaker 3:  If you I screened loud.

1019
00:59:09,005 --> 00:59:11,605
Speaker 3:  IIII did a welp

1020
00:59:15,085 --> 00:59:18,845
Speaker 3:  I wish I had thought about it sooner. So at

1021
00:59:19,465 --> 00:59:23,405
Speaker 3:  io when they mention RCS, like the crowd goes wild. Like

1022
00:59:23,405 --> 00:59:24,245
Speaker 3:  Dieter rips the shirt

1023
00:59:25,985 --> 00:59:29,525
Speaker 3:  at the Apple event when their RCS shows up and he says it for one second.

1024
00:59:29,525 --> 00:59:32,325
Speaker 3:  And I don't remember RCS thing dead silence except for me.

1025
00:59:33,305 --> 00:59:34,965
Speaker 3:  And I believe Alison also cheered. Yeah.

1026
00:59:35,275 --> 00:59:37,965
Speaker 8:  When I realized you were Yeah. I was like, oh, I can do a cheer.

1027
00:59:38,485 --> 00:59:41,725
Speaker 3:  I should have just screamed Tee. Yeah. Just like that would've gotten the

1028
00:59:41,725 --> 00:59:44,845
Speaker 3:  laugh. I think other than that there was no, there were no sounds it no sound,

1029
00:59:44,845 --> 00:59:45,365
Speaker 3:  no other sounds

1030
00:59:45,365 --> 00:59:48,805
Speaker 4:  Were made. I bet you could hear you somewhere in the livestream if you, if

1031
00:59:48,805 --> 00:59:51,885
Speaker 4:  you do send it to us, vergecast The Verge dot com send us Neli screaming

1032
00:59:51,885 --> 00:59:52,685
Speaker 4:  about RCS.

1033
00:59:52,715 --> 00:59:56,085
Speaker 3:  There's a very famous bootleg of Jeff Tweedy from Loco playing in Madison

1034
00:59:56,225 --> 00:59:59,605
Speaker 3:  and I'm, it forced him to play the song Gun by Uncle Tupelo. And like it

1035
00:59:59,605 --> 01:00:02,485
Speaker 3:  goes out there and it's just me going gun. And he's like, really?

1036
01:00:03,395 --> 01:00:06,485
Speaker 3:  It's out there. You can find it. It's, it's not a legal recording. You know,

1037
01:00:06,485 --> 01:00:06,605
Speaker 3:  I,

1038
01:00:06,705 --> 01:00:10,685
Speaker 4:  The RCS, so we talked last week and we were debating like our,

1039
01:00:10,785 --> 01:00:13,125
Speaker 4:  how big a deal are they gonna make out of RCS? And I think where we landed,

1040
01:00:13,145 --> 01:00:17,085
Speaker 4:  if I'm not mistaken, was it'll be in the, the Bento box at the end that shows

1041
01:00:17,085 --> 01:00:21,005
Speaker 4:  all the features but they won't name it. And I would say we almost got that

1042
01:00:21,145 --> 01:00:24,885
Speaker 4:  he did say the letters Yeah. RCS out loud on stage as

1043
01:00:24,885 --> 01:00:26,045
Speaker 5:  The Bento box appeared.

1044
01:00:26,355 --> 01:00:29,845
Speaker 4:  Yeah, yeah. Right. It was like a brief, I was kind of like, oh, there's RCS

1045
01:00:29,845 --> 01:00:33,285
Speaker 4:  and then he said, and now we have RCS and then just breezed past it. Dead

1046
01:00:33,285 --> 01:00:33,525
Speaker 4:  silence.

1047
01:00:33,765 --> 01:00:34,885
Speaker 3:  They spent more, they did not like this.

1048
01:00:35,115 --> 01:00:39,085
Speaker 8:  They spent more time on the satellite messaging. Like you are

1049
01:00:39,085 --> 01:00:42,725
Speaker 8:  in the woods, you can now thumbs up emoji. Yeah. You know your friend.

1050
01:00:43,185 --> 01:00:44,645
Speaker 8:  And then we have RCS. Yeah.

1051
01:00:45,065 --> 01:00:48,445
Speaker 4:  And the fact that you can now do text formatting, you can do like a Oh that

1052
01:00:48,445 --> 01:00:51,765
Speaker 4:  rules breakthrough in your messages now. Yeah. Which is definitely not gonna

1053
01:00:51,765 --> 01:00:53,845
Speaker 4:  work over rrc SI can tell you that with great

1054
01:00:53,845 --> 01:00:57,005
Speaker 3:  Content. Yeah. They asked a bunch of features on are Im message only so that

1055
01:00:57,005 --> 01:00:59,805
Speaker 3:  they could be like, now we have RCS by the way, SMS works over a satellite.

1056
01:00:59,805 --> 01:01:03,405
Speaker 3:  It's but not RCS. Yeah. I did that s message work the

1057
01:01:03,565 --> 01:01:07,525
Speaker 3:  satellites but not Rrc SI did think it was incredible

1058
01:01:07,915 --> 01:01:11,845
Speaker 3:  that in 2024 we went to a keynote

1059
01:01:12,585 --> 01:01:14,605
Speaker 3:  by the third richest company in the world

1060
01:01:16,105 --> 01:01:19,085
Speaker 3:  state-of-the-art computing company. And they're like, you can underline this

1061
01:01:19,085 --> 01:01:22,965
Speaker 3:  text. And then they're like, and you can also bold it and italicize it. And

1062
01:01:22,965 --> 01:01:23,485
Speaker 3:  people were like,

1063
01:01:24,755 --> 01:01:27,165
Speaker 4:  Well, and there was a moment in Sir one where he was like, now you can find

1064
01:01:27,645 --> 01:01:29,765
Speaker 4:  documents. And they're like, oh my god. Documents

1065
01:01:30,125 --> 01:01:32,645
Speaker 3:  Amazing. In the iPad where it was like, we've made file browsing easier.

1066
01:01:32,915 --> 01:01:36,885
Speaker 3:  It's like, dude, this problem is super solved. Like you just

1067
01:01:36,885 --> 01:01:40,405
Speaker 3:  refuse to solve it. Yeah. A lot of those moments where you just

1068
01:01:40,645 --> 01:01:44,605
Speaker 3:  re-contextualize old solutions into new places. Like you can't italicize

1069
01:01:44,605 --> 01:01:48,365
Speaker 3:  text and messages. Yeah. Yeah. I, I understand why it was just like

1070
01:01:48,765 --> 01:01:52,285
Speaker 3:  really it's the, it's the eye button that's been in every word

1071
01:01:52,285 --> 01:01:55,445
Speaker 3:  processor I've ever used a little slanty eye. You could just push it,

1072
01:01:55,785 --> 01:01:58,365
Speaker 5:  You could just anywhere. You can do it on Twitter or you

1073
01:01:58,365 --> 01:01:59,485
Speaker 3:  Could you ize. Nah.

1074
01:01:59,485 --> 01:02:02,285
Speaker 5:  Yeah. But you had to like, it was like weird. You had to like think about

1075
01:02:02,285 --> 01:02:02,405
Speaker 5:  it.

1076
01:02:02,555 --> 01:02:05,845
Speaker 3:  Yeah. Well now I can do it in messages. It's very exciting message. Also

1077
01:02:05,845 --> 01:02:08,885
Speaker 3:  got any emojis now a tap back in, in messages

1078
01:02:09,035 --> 01:02:09,805
Speaker 4:  That actually think is very

1079
01:02:09,885 --> 01:02:13,365
Speaker 3:  Exciting. People are super stoked about that. You can make your words

1080
01:02:13,565 --> 01:02:16,405
Speaker 3:  jitter and shake and explode. Right. Things the other, do

1081
01:02:16,405 --> 01:02:20,245
Speaker 4:  You guys use that stuff? Like do you I find I use the tap backs all the time

1082
01:02:20,625 --> 01:02:24,485
Speaker 4:  and that's about the only kind of wacky iMessage feature I

1083
01:02:24,485 --> 01:02:26,885
Speaker 4:  use consistently. I'm very excited. Except the birthday balloons. I love

1084
01:02:26,885 --> 01:02:29,205
Speaker 4:  the birthday. I rock the birthday balloons every time

1085
01:02:29,445 --> 01:02:31,885
Speaker 8:  I forget about them and I see 'em. They're very good. Oh that was nice.

1086
01:02:32,125 --> 01:02:35,165
Speaker 5:  I always forget about them until I'm like, oh congratulations. Oh I get fired

1087
01:02:35,165 --> 01:02:35,325
Speaker 5:  up.

1088
01:02:36,255 --> 01:02:40,005
Speaker 3:  Right. I am very excited about the ability to use any emoji as a tap pack.

1089
01:02:40,235 --> 01:02:40,525
Speaker 3:  Yeah.

1090
01:02:40,765 --> 01:02:41,125
Speaker 4:  I think that's gonna

1091
01:02:41,315 --> 01:02:44,965
Speaker 3:  Effectively it just now you just have emoji responses which

1092
01:02:44,975 --> 01:02:48,965
Speaker 3:  every other platform supports. Whereas being like, haha, just like

1093
01:02:49,275 --> 01:02:50,485
Speaker 3:  this is too sarcastic.

1094
01:02:50,485 --> 01:02:54,045
Speaker 4:  Yeah, yeah. Right. It's like the, I use the thumbs up and the the bang bang

1095
01:02:54,225 --> 01:02:55,245
Speaker 4:  for way too many things.

1096
01:02:55,765 --> 01:02:59,645
Speaker 5:  I mean I use the haha when like I'm not truly engaged Yeah. In

1097
01:02:59,645 --> 01:03:02,645
Speaker 5:  conversation. That's what I mean. But I'm like, oh but that was funny point.

1098
01:03:02,995 --> 01:03:05,725
Speaker 3:  It's it's, it's the, you tried of emoji reactions. It's

1099
01:03:05,725 --> 01:03:07,405
Speaker 5:  Like I don't have any more energy for this. Yeah.

1100
01:03:08,165 --> 01:03:11,005
Speaker 3:  I got nothing. It it makes you a dick whether or not you want be one. Like

1101
01:03:11,005 --> 01:03:14,965
Speaker 3:  it's not. So I'm very excited to expand the range. Blood tears

1102
01:03:15,065 --> 01:03:18,845
Speaker 3:  is my favorite. Yeah. Oh you're not gonna be able to get custom emojis. I

1103
01:03:18,845 --> 01:03:22,485
Speaker 3:  think blood tears might be a custom emoji just in our Slack instance. If

1104
01:03:22,485 --> 01:03:25,045
Speaker 3:  you wanna know what it's like working at The Verge often I reply with a picture

1105
01:03:25,105 --> 01:03:26,565
Speaker 3:  of a smiley face crying blood.

1106
01:03:27,275 --> 01:03:27,565
Speaker 4:  It's

1107
01:03:27,565 --> 01:03:29,045
Speaker 5:  True. It's super useful.

1108
01:03:30,045 --> 01:03:32,685
Speaker 3:  Externalism, it expresses so much about what we do here.

1109
01:03:33,075 --> 01:03:33,965
Speaker 5:  More than haha.

1110
01:03:34,395 --> 01:03:34,805
Speaker 3:  More than

1111
01:03:34,805 --> 01:03:36,085
Speaker 5:  Ha. Just way more than

1112
01:03:36,155 --> 01:03:39,405
Speaker 3:  Haha. What if, okay. Starting today. Haha means blood tears.

1113
01:03:40,995 --> 01:03:42,485
Speaker 4:  Tell everybody, just make it happen.

1114
01:03:42,555 --> 01:03:42,845
Speaker 3:  Tell

1115
01:03:42,845 --> 01:03:43,725
Speaker 5:  Your friends, tell

1116
01:03:43,725 --> 01:03:44,325
Speaker 3:  Your, tell your

1117
01:03:44,535 --> 01:03:46,205
Speaker 5:  We're just gonna make this a thing now. Yeah.

1118
01:03:46,205 --> 01:03:47,885
Speaker 3:  You see these words? It means I'm crying blood.

1119
01:03:50,285 --> 01:03:53,005
Speaker 5:  I mean sometimes the jokes. Yeah, that's, that is a feeling. Yeah.

1120
01:03:53,005 --> 01:03:55,685
Speaker 4:  Yeah. Alright, let's keep moving. We got more platforms to do here.

1121
01:03:56,305 --> 01:03:57,645
Speaker 3:  Oh, you're talking about game mode. Yeah.

1122
01:03:57,665 --> 01:03:58,805
Speaker 5:  What's some game mode

1123
01:03:58,895 --> 01:04:02,645
Speaker 4:  There? You just did. That's welcome to game mode. You can now play

1124
01:04:02,835 --> 01:04:06,725
Speaker 4:  5-year-old video games poorly on your computer and there's a

1125
01:04:06,725 --> 01:04:07,765
Speaker 4:  new assassin. It's

1126
01:04:07,765 --> 01:04:07,885
Speaker 3:  On the

1127
01:04:09,165 --> 01:04:09,245
Speaker 4:  Whatever

1128
01:04:09,305 --> 01:04:10,645
Speaker 5:  The new assassin screens coming today.

1129
01:04:10,875 --> 01:04:13,445
Speaker 3:  Your phone on computer now about, we're gonna talk about Apple announces

1130
01:04:13,445 --> 01:04:17,325
Speaker 3:  and games from 2017. We're gonna get to the Mac. Sorry. Game mode prioritizes

1131
01:04:17,725 --> 01:04:19,845
Speaker 3:  wireless performance of controllers on your iPhone. Okay.

1132
01:04:19,935 --> 01:04:23,365
Speaker 4:  There. Done. Great. Congratulations to all of your wireless controllers.

1133
01:04:23,495 --> 01:04:24,085
Speaker 4:  Let's move on.

1134
01:04:25,705 --> 01:04:28,925
Speaker 4:  The next platform, and this is not technically a platform by Apple's definition

1135
01:04:28,925 --> 01:04:32,765
Speaker 4:  but I think we should talk about it, is photos. Because photos is like

1136
01:04:33,565 --> 01:04:37,125
Speaker 4:  a hugely used app and they announced a bunch of stuff including a giant

1137
01:04:37,365 --> 01:04:40,925
Speaker 4:  redesign that I would argue is not a particularly giant redesign.

1138
01:04:41,315 --> 01:04:44,285
Speaker 4:  It's just that they put a bunch of new

1139
01:04:45,385 --> 01:04:49,045
Speaker 4:  albums in your photos app that I am suspicious of their usefulness.

1140
01:04:49,745 --> 01:04:50,965
Speaker 4:  But now they exist. Yeah.

1141
01:04:50,995 --> 01:04:54,925
Speaker 8:  It's very like memories forward. Like it seems like

1142
01:04:55,385 --> 01:04:59,245
Speaker 8:  the actual photos you're going to look for are just right up there with

1143
01:04:59,245 --> 01:05:03,045
Speaker 8:  like, remember this time and here was this thing that happened.

1144
01:05:03,315 --> 01:05:07,165
Speaker 5:  Look at all your dead pets. Yeah. Yeah. Really, really enjoy

1145
01:05:07,405 --> 01:05:07,485
Speaker 5:  'em.

1146
01:05:08,125 --> 01:05:11,405
Speaker 4:  I just remember them. There was years ago at an iPad event, I think it was

1147
01:05:11,405 --> 01:05:15,285
Speaker 4:  the iPad event they did in New York. They put up this marketing image that

1148
01:05:15,285 --> 01:05:18,645
Speaker 4:  was a guy sitting like in a, in the crook

1149
01:05:19,185 --> 01:05:23,085
Speaker 4:  of one of the supports on the Brooklyn Bridge doodling on

1150
01:05:23,085 --> 01:05:25,885
Speaker 4:  his iPad. Sure. And it's like, sure. This is like a normal thing a person

1151
01:05:25,885 --> 01:05:29,725
Speaker 4:  does on their device. And every time Apple shows new photos features, I think

1152
01:05:29,725 --> 01:05:32,645
Speaker 4:  of that guy sitting on the Brooklyn Bridge because it's like this thing where

1153
01:05:32,645 --> 01:05:36,325
Speaker 4:  there is a whole album of just all your awesome pictures from

1154
01:05:36,325 --> 01:05:39,885
Speaker 4:  yesterday. It's like, no, I don't have any awesome pictures from yesterday.

1155
01:05:40,395 --> 01:05:44,365
Speaker 4:  Like I have a bunch of accidental screenshots, I have receipts

1156
01:05:44,365 --> 01:05:48,325
Speaker 4:  from the plane and I have a picture of my toddler that is the same

1157
01:05:48,325 --> 01:05:51,045
Speaker 4:  picture that I take of my toddler that's blurry and weird every single day.

1158
01:05:51,115 --> 01:05:55,045
Speaker 4:  Like I don't need this apple. And all of these things are made for like

1159
01:05:55,555 --> 01:05:59,445
Speaker 4:  extremely interesting worldly beautiful people who take

1160
01:05:59,685 --> 01:06:02,205
Speaker 4:  thousands of photos of themselves every day. Yeah. And I think none of those

1161
01:06:02,205 --> 01:06:05,125
Speaker 4:  people exist in the actual world. It makes me crazy. Yeah.

1162
01:06:05,125 --> 01:06:07,765
Speaker 5:  They exist on Instagram. All my friends friends on Instagram

1163
01:06:08,625 --> 01:06:12,495
Speaker 3:  But they tap, they try. Yeah. Right. Like most people just using their

1164
01:06:12,495 --> 01:06:16,255
Speaker 3:  phones to take photos. But I do think the idea that that the app is not

1165
01:06:16,255 --> 01:06:19,575
Speaker 3:  memory forward is fascinating.

1166
01:06:20,135 --> 01:06:22,575
Speaker 3:  'cause it does imply you're taking more photos and videos than ever and it's

1167
01:06:22,575 --> 01:06:25,375
Speaker 3:  hard to find them. And the device should like sort them for you.

1168
01:06:25,545 --> 01:06:27,895
Speaker 4:  Which I buy in theory. Like it's good logic. Yeah.

1169
01:06:27,935 --> 01:06:31,775
Speaker 3:  I mean I don't use Google Photos as my camera roll. Do you? I mean like on

1170
01:06:31,775 --> 01:06:32,455
Speaker 3:  The iPhone?

1171
01:06:32,455 --> 01:06:33,335
Speaker 5:  No I use the the photos app.

1172
01:06:33,585 --> 01:06:37,295
Speaker 3:  Right. And I think the sort of conflation of the photos app with the camera

1173
01:06:37,325 --> 01:06:41,015
Speaker 3:  roll is like fighting against Apple's goals here, which is to compete with

1174
01:06:41,515 --> 01:06:45,015
Speaker 3:  Google photos and other apps like Google Photos. And so it's just like at

1175
01:06:45,015 --> 01:06:47,775
Speaker 3:  some point it's, I just need to see all the photos I took I in a list

1176
01:06:49,195 --> 01:06:52,135
Speaker 3:  Google Photos right now actually it's the most infuriating feature is it

1177
01:06:52,135 --> 01:06:53,735
Speaker 3:  insists on stacking your photos for you.

1178
01:06:53,875 --> 01:06:54,735
Speaker 5:  Oh I hate that.

1179
01:06:55,035 --> 01:06:57,935
Speaker 3:  And it's like you took five of these frames and it's like, yeah, I, I know.

1180
01:06:58,055 --> 01:06:58,935
Speaker 4:  I would like to see all photos.

1181
01:06:59,095 --> 01:07:02,815
Speaker 3:  I would like to see them. Yeah. I don't want you to pick one. And I think

1182
01:07:02,815 --> 01:07:05,295
Speaker 3:  it gets weird when you think of the photos app is actually your camera roll

1183
01:07:05,295 --> 01:07:07,375
Speaker 3:  and not this like memory playground.

1184
01:07:07,765 --> 01:07:11,455
Speaker 5:  Yeah. Well I wonder also how much of this is the fact that we all review

1185
01:07:11,455 --> 01:07:11,815
Speaker 5:  devices?

1186
01:07:12,935 --> 01:07:13,545
Speaker 4:  What do you mean?

1187
01:07:14,295 --> 01:07:16,505
Speaker 5:  Like do most people take screenshots?

1188
01:07:16,965 --> 01:07:18,465
Speaker 3:  Yes. Okay. All the time.

1189
01:07:19,085 --> 01:07:21,345
Speaker 5:  On purpose. All the time. I take a lot

1190
01:07:21,345 --> 01:07:24,385
Speaker 4:  Of accidental screenshots. Yeah. That's real. Yeah. But I also take a lot

1191
01:07:24,385 --> 01:07:24,825
Speaker 4:  of purpose.

1192
01:07:25,105 --> 01:07:28,305
Speaker 3:  I know people have 10,000 screenshots and they're just like things,

1193
01:07:28,305 --> 01:07:31,305
Speaker 3:  conversations disappearing, messages,

1194
01:07:32,345 --> 01:07:36,065
Speaker 3:  Snapchats like all the stuff, like anything that happens on your phone. The

1195
01:07:36,065 --> 01:07:39,305
Speaker 3:  way the easiest, fastest way to capture is screenshot. Yeah. So you can actually

1196
01:07:39,305 --> 01:07:42,345
Speaker 3:  do some segmenting and making that stuff searchable and filterable from the

1197
01:07:42,345 --> 01:07:46,265
Speaker 3:  rest. Like there's a lot of good intent in this app and I think the

1198
01:07:46,265 --> 01:07:50,225
Speaker 3:  way it looks is like ever, it's

1199
01:07:50,225 --> 01:07:51,945
Speaker 3:  even more complicated than it's ever been before.

1200
01:07:52,205 --> 01:07:56,105
Speaker 5:  But I also think it is prettier than it's ever been. Like if you

1201
01:07:56,105 --> 01:07:58,985
Speaker 5:  think of where we started with eye photos to now

1202
01:08:00,835 --> 01:08:02,115
Speaker 5:  gorgeous app compared to eye photos. Right?

1203
01:08:02,945 --> 01:08:03,235
Speaker 3:  Sure.

1204
01:08:03,905 --> 01:08:05,715
Speaker 5:  Yeah. That's, I care about that. No,

1205
01:08:05,755 --> 01:08:09,715
Speaker 4:  I agree. It has gotten a lot better and I think as a like management

1206
01:08:09,815 --> 01:08:13,795
Speaker 4:  system, it makes sense that this is kind of what they're trying to do. It

1207
01:08:13,795 --> 01:08:16,845
Speaker 4:  just seems like this idea of we are going to constantly repackage your photos

1208
01:08:16,865 --> 01:08:20,845
Speaker 4:  and shove them at you. Feels like the wrong answer to me.

1209
01:08:20,875 --> 01:08:23,805
Speaker 4:  Yeah. But I do think some of the stuff they're doing, like they, I think

1210
01:08:23,805 --> 01:08:27,685
Speaker 4:  said the exact same. You can find your driver's license or your license

1211
01:08:27,695 --> 01:08:31,285
Speaker 4:  plate in your photos. The like the identical demo to Google,

1212
01:08:31,615 --> 01:08:33,165
Speaker 4:  which is just like, this is everybody's

1213
01:08:33,245 --> 01:08:33,965
Speaker 3:  I idea your driver's license

1214
01:08:34,145 --> 01:08:36,245
Speaker 4:  Was your driver's license. Okay. Google's was your license plate. Right.

1215
01:08:36,245 --> 01:08:39,125
Speaker 3:  Right. So you're Yeah it was what, what is my license? Slightly different.

1216
01:08:39,125 --> 01:08:40,285
Speaker 4:  Totally features

1217
01:08:40,785 --> 01:08:42,285
Speaker 9:  Two phones in order to

1218
01:08:42,285 --> 01:08:44,965
Speaker 4:  Get all your information. Right. And then I'll know everything about my particular

1219
01:08:44,965 --> 01:08:48,885
Speaker 3:  Well the demo of the, they're slightly different. They were, were so

1220
01:08:49,005 --> 01:08:52,765
Speaker 3:  slightly different. Google was, you just asked it, you just like asked

1221
01:08:52,765 --> 01:08:55,565
Speaker 3:  Google photos what my license plate number was. Right. And like told you

1222
01:08:55,565 --> 01:08:59,205
Speaker 3:  the answer. This one was you were in a web form and said enter your driver's

1223
01:08:59,205 --> 01:09:03,005
Speaker 3:  license number and like the Apple Intelligence

1224
01:09:03,005 --> 01:09:05,485
Speaker 3:  would go and get it. Oh. And like enter it for you.

1225
01:09:06,065 --> 01:09:06,605
Speaker 4:  That's cool.

1226
01:09:07,045 --> 01:09:10,845
Speaker 3:  Slightly different demo. Sure. Same exact result. Correct. You filled out

1227
01:09:11,085 --> 01:09:14,045
Speaker 3:  a meaningless number of form. Fine.

1228
01:09:14,595 --> 01:09:18,485
Speaker 4:  Welcome to the AI future. It's just a bunch of weird UI affords.

1229
01:09:18,945 --> 01:09:21,965
Speaker 3:  You're gonna row robots at the DMV until the DMV submits. Yeah.

1230
01:09:23,465 --> 01:09:24,805
Speaker 3:  My tax is paid for the shit.

1231
01:09:27,925 --> 01:09:31,845
Speaker 4:  Yeah, it's perfect. So that's photos iPad, which

1232
01:09:31,965 --> 01:09:34,765
Speaker 4:  I think was a weird one in that it was both incredibly disappointing and

1233
01:09:34,765 --> 01:09:37,125
Speaker 4:  also the single coolest demo of the day by a pretty wide margin.

1234
01:09:37,365 --> 01:09:40,205
Speaker 3:  I ended the iPad session with all Lifelog by saying I'm sorry.

1235
01:09:41,395 --> 01:09:44,485
Speaker 3:  That was overwhelmingly what I felt at the end of that. It was Why did you

1236
01:09:44,485 --> 01:09:45,885
Speaker 3:  think that was cool? The math.

1237
01:09:46,065 --> 01:09:47,165
Speaker 4:  The math thing was awesome.

1238
01:09:47,475 --> 01:09:48,365
Speaker 3:  Just the calculator. Right?

1239
01:09:48,395 --> 01:09:52,125
Speaker 4:  Just the single Just in terms of like Holy god this is cool technology.

1240
01:09:52,155 --> 01:09:55,125
Speaker 4:  Just the thing where he's writing down an equation and notes and he writes

1241
01:09:55,125 --> 01:09:58,045
Speaker 4:  the equal sign and it just does it. Yep. In his handwriting that ripped.

1242
01:09:58,265 --> 01:10:01,365
Speaker 4:  And then another one that I'm like, does it, does this help anyone with anything

1243
01:10:01,365 --> 01:10:03,845
Speaker 4:  in reality that exists? Yeah. I don't know where

1244
01:10:03,845 --> 01:10:07,445
Speaker 3:  Where they did the table tennis algebra and then he was like make a graph

1245
01:10:07,445 --> 01:10:10,045
Speaker 3:  of velocities. Yeah. No distance over velocity

1246
01:10:10,495 --> 01:10:14,405
Speaker 4:  Rules. They're just doing stuff on Chromebooks now. Like it's fine. But it

1247
01:10:14,405 --> 01:10:17,725
Speaker 4:  was awesome technology and yet I think, and I'm curious if this was your

1248
01:10:17,745 --> 01:10:18,925
Speaker 3:  It just the calculator app.

1249
01:10:19,745 --> 01:10:20,685
Speaker 4:  Listen, it was awesome.

1250
01:10:21,115 --> 01:10:23,805
Speaker 9:  Look, they spent 14 years to

1251
01:10:23,805 --> 01:10:24,885
Speaker 4:  Make the best

1252
01:10:24,945 --> 01:10:28,485
Speaker 3:  Him. People walked into this thinking iPads were gonna come outta wwc running

1253
01:10:28,745 --> 01:10:31,405
Speaker 3:  Mac os a thing. And you're like the calculator app

1254
01:10:31,665 --> 01:10:35,405
Speaker 4:  Did a thing that is important to say is that the

1255
01:10:35,405 --> 01:10:38,925
Speaker 4:  biggest cheer by a wide margin at this year's.

1256
01:10:39,185 --> 01:10:43,045
Speaker 4:  Www C was for the calculator app for iPad do with that. Which you will.

1257
01:10:43,265 --> 01:10:44,765
Speaker 4:  But it was not close. People

1258
01:10:44,785 --> 01:10:47,365
Speaker 3:  Saw algebra being done by a computer and they're like finally.

1259
01:10:48,635 --> 01:10:49,365
Speaker 3:  Yeah. But

1260
01:10:49,365 --> 01:10:53,285
Speaker 4:  I found this one so fascinating because it was like we got the new iPad Pro

1261
01:10:53,425 --> 01:10:57,205
Speaker 4:  and the new iPads. What like a month ago, two months ago. Time is

1262
01:10:57,565 --> 01:11:00,805
Speaker 4:  whatever. Everybody was like, okay, this is a device

1263
01:11:01,275 --> 01:11:05,165
Speaker 4:  waiting for amazing software and like WWDC

1264
01:11:05,165 --> 01:11:08,525
Speaker 4:  is coming, this is gonna be the one. And we just super duper didn't get it.

1265
01:11:08,525 --> 01:11:12,485
Speaker 4:  Yeah, yeah. Like just not even a little bit at all. And I don't

1266
01:11:12,485 --> 01:11:16,245
Speaker 4:  know if you guys felt this way being in there, but the energy

1267
01:11:16,345 --> 01:11:20,245
Speaker 4:  in the room was the lowest as he was describing like

1268
01:11:20,375 --> 01:11:22,405
Speaker 4:  share play improvements on the iPad.

1269
01:11:22,405 --> 01:11:26,325
Speaker 3:  Right. When he got to, we've added some UI improvements to the iPad and everyone

1270
01:11:26,325 --> 01:11:29,805
Speaker 3:  thought it would be like a window in system. Right. And he is like floating

1271
01:11:29,905 --> 01:11:33,685
Speaker 3:  tab bar. And then he said the word morph five times in row

1272
01:11:34,275 --> 01:11:36,365
Speaker 3:  just seamlessly morphs into the sidebar.

1273
01:11:38,005 --> 01:11:41,845
Speaker 3:  I don't know if you've seen anything morph. Famously the robot and

1274
01:11:41,845 --> 01:11:45,645
Speaker 3:  Terminator two morphs the video for Michael Jackson's black and white.

1275
01:11:45,785 --> 01:11:49,325
Speaker 3:  So the first morphing, good morphing ever done, he turns into a tiger.

1276
01:11:49,915 --> 01:11:53,485
Speaker 3:  Nothing about this hit on the level of Michael Jackson

1277
01:11:53,485 --> 01:11:56,925
Speaker 3:  turning into a tiger in the video for black and white. This

1278
01:11:56,925 --> 01:11:57,565
Speaker 5:  Was no two one

1279
01:11:57,565 --> 01:12:00,805
Speaker 3:  Houses like absolute zero zero response to this morphing.

1280
01:12:01,745 --> 01:12:02,485
Speaker 5:  It was, it

1281
01:12:02,485 --> 01:12:05,885
Speaker 3:  Was the mighty more from Power Rangers. I think emotional reactions from

1282
01:12:05,885 --> 01:12:09,805
Speaker 3:  everybody in that room, nothing on this hit the level of the

1283
01:12:09,805 --> 01:12:11,525
Speaker 3:  white ranger coming back. You know what I'm saying?

1284
01:12:12,515 --> 01:12:14,885
Speaker 4:  It's an impossible bar. Yeah. Impossible bar.

1285
01:12:16,555 --> 01:12:19,005
Speaker 5:  It's nobody else. I'm just surprised you know that much about the white ranger.

1286
01:12:19,005 --> 01:12:19,125
Speaker 5:  I

1287
01:12:19,445 --> 01:12:20,005
Speaker 4:  I have morphing.

1288
01:12:21,185 --> 01:12:21,605
Speaker 5:  That's

1289
01:12:21,605 --> 01:12:21,885
Speaker 4:  A lot. I

1290
01:12:21,885 --> 01:12:23,005
Speaker 3:  Grew up in a time of morphing.

1291
01:12:24,415 --> 01:12:24,765
Speaker 5:  These

1292
01:12:24,785 --> 01:12:26,645
Speaker 3:  Are core childhood memories.

1293
01:12:27,045 --> 01:12:28,845
Speaker 5:  Morphing was very popular in

1294
01:12:28,845 --> 01:12:32,565
Speaker 3:  The nineties. It was a big deal. Like a lot of late nineties, early two thousands.

1295
01:12:32,565 --> 01:12:35,885
Speaker 3:  Culture really revolved around morphing if you ever, I'm just saying the

1296
01:12:35,885 --> 01:12:39,405
Speaker 3:  guy, he said, we watch the tab or seamlessly morph into the sidebar. I was

1297
01:12:39,405 --> 01:12:39,485
Speaker 3:  like,

1298
01:12:39,705 --> 01:12:39,925
Speaker 5:  No.

1299
01:12:40,435 --> 01:12:42,285
Speaker 3:  Yeah, it is baby morphing.

1300
01:12:44,425 --> 01:12:47,005
Speaker 4:  We should move on. But I just wanna say, if you ever write like a Soufan

1301
01:12:47,005 --> 01:12:50,805
Speaker 4:  Steven style album, I grew up in a time of morphing. Is this title of your

1302
01:12:50,805 --> 01:12:51,005
Speaker 4:  single?

1303
01:12:51,195 --> 01:12:54,445
Speaker 3:  It's just, it was oddly prevalent. Alison's with me. She knows

1304
01:12:54,445 --> 01:12:57,805
Speaker 5:  There there wa Yeah. There was a lot of morphing. There was morphing.

1305
01:12:57,955 --> 01:12:59,805
Speaker 3:  They were, they were mighty and they were power.

1306
01:13:00,365 --> 01:13:00,645
Speaker 5:  They

1307
01:13:00,645 --> 01:13:02,565
Speaker 3:  Were only, only one verb in there.

1308
01:13:06,515 --> 01:13:09,605
Speaker 4:  Yeah. All right, let's move on. That's enough for the iPad. The iPad

1309
01:13:10,335 --> 01:13:12,005
Speaker 4:  still disappointing now with the calculator.

1310
01:13:13,645 --> 01:13:16,765
Speaker 4:  I put watchOS next but it's really a tie between,

1311
01:13:16,765 --> 01:13:19,005
Speaker 3:  Wait, can we say two things on the iPad? Sure. There are two things. One,

1312
01:13:19,075 --> 01:13:22,765
Speaker 3:  they announced the most important feature of all for anyone who has a parent

1313
01:13:22,765 --> 01:13:26,645
Speaker 3:  with an iPad. You can now take over their screen. Oh I missed that. So

1314
01:13:26,645 --> 01:13:29,005
Speaker 3:  when you're FaceTiming with them, you can share play and they're like, what

1315
01:13:29,005 --> 01:13:32,285
Speaker 3:  am I doing? You can draw on their screen to call their attention to something

1316
01:13:32,285 --> 01:13:34,125
Speaker 3:  you want them to do or you can just do

1317
01:13:34,125 --> 01:13:36,285
Speaker 4:  It. That's cool. Killer feature. Yeah. That's a good feature.

1318
01:13:36,605 --> 01:13:39,885
Speaker 3:  Absolutely. Killer feature. And then the weird dynamic

1319
01:13:39,995 --> 01:13:43,965
Speaker 3:  handwriting font thing, they're doing smart script. Oh. Or you draw it and

1320
01:13:43,965 --> 01:13:46,525
Speaker 3:  it smooths out your handwriting but then also sort of creates handwriting

1321
01:13:46,545 --> 01:13:50,125
Speaker 3:  for you. It's unclear whether there's like a system wide

1322
01:13:50,245 --> 01:13:53,685
Speaker 3:  typeface or it just has a model of your handwriting that you can now copy

1323
01:13:53,745 --> 01:13:57,285
Speaker 3:  and paste. You can paste, you can copy text from somewhere else. Paste it

1324
01:13:57,355 --> 01:13:59,085
Speaker 3:  into a document. Your handwriting. In

1325
01:13:59,085 --> 01:14:00,605
Speaker 4:  Your handwriting. That's pretty awesome. Couldn't

1326
01:14:00,605 --> 01:14:04,285
Speaker 5:  You do that on like a surface device five years ago? Yeah.

1327
01:14:05,665 --> 01:14:06,285
Speaker 5:  But now it's on the

1328
01:14:06,355 --> 01:14:10,165
Speaker 3:  IPad. Yeah. Look, they didn't head windows. They added a

1329
01:14:10,165 --> 01:14:13,445
Speaker 3:  morphing tab bar, task bar. And you get smart. They

1330
01:14:13,445 --> 01:14:14,765
Speaker 5:  Were like, we're gonna set the bar real

1331
01:14:14,765 --> 01:14:16,005
Speaker 3:  Low. It's very low. And

1332
01:14:16,005 --> 01:14:16,685
Speaker 5:  Then we're gonna go

1333
01:14:16,965 --> 01:14:19,765
Speaker 3:  Slightly. People thought they were gonna run Mac os on their iPads coming

1334
01:14:19,765 --> 01:14:21,845
Speaker 3:  outta this event. Smart script people

1335
01:14:22,035 --> 01:14:22,485
Speaker 4:  Were not.

1336
01:14:22,485 --> 01:14:25,405
Speaker 3:  Correct. And David got a calculator. You know what's ironic? All the algebra

1337
01:14:25,405 --> 01:14:26,285
Speaker 3:  you do at work. This

1338
01:14:26,285 --> 01:14:28,805
Speaker 4:  Is actually, this is a good segue into the next one. Let's do Mac os next

1339
01:14:28,805 --> 01:14:31,765
Speaker 4:  because what we actually got is much closer to the exact opposite

1340
01:14:34,465 --> 01:14:38,005
Speaker 4:  of getting Mac Os on your iPad. We got iPhones on your Mac.

1341
01:14:38,185 --> 01:14:38,405
Speaker 3:  Yes.

1342
01:14:39,385 --> 01:14:41,325
Speaker 4:  Mac os Sequoia. How do you feel about Sequoia?

1343
01:14:42,325 --> 01:14:43,295
Speaker 5:  It's like a, A name.

1344
01:14:43,685 --> 01:14:45,175
Speaker 4:  It's fine. It's a name. I, I've

1345
01:14:45,175 --> 01:14:48,775
Speaker 3:  Lo, I've lo live logged a W for like 10 years, 15 years now.

1346
01:14:49,075 --> 01:14:51,815
Speaker 3:  And when Craig does the bit about the name, I literally just like take a

1347
01:14:51,815 --> 01:14:55,135
Speaker 3:  break and like Yeah. Crack my knuckles. I'm like, you're gonna, it's a name.

1348
01:14:55,165 --> 01:14:56,415
Speaker 3:  It's gonna be a mountain. Yeah.

1349
01:14:56,505 --> 01:14:59,855
Speaker 4:  We're good. They did or didn't get high. It's fine. Yeah. But yeah, the big

1350
01:14:59,855 --> 01:15:02,615
Speaker 4:  things we should talk about iPhone mirroring because this is one of those

1351
01:15:02,615 --> 01:15:06,495
Speaker 4:  things that I think this is the big thing. Apple probably didn't expect to

1352
01:15:06,495 --> 01:15:10,415
Speaker 4:  be as exciting to people as it was, but is very exciting. And I think is

1353
01:15:10,515 --> 01:15:12,055
Speaker 4:  is like gonna be a huge deal.

1354
01:15:13,185 --> 01:15:16,275
Speaker 3:  Yeah. I mean they're, they're missing a key

1355
01:15:16,905 --> 01:15:18,835
Speaker 3:  interface element.

1356
01:15:19,935 --> 01:15:20,795
Speaker 4:  You mean a digital crown?

1357
01:15:22,255 --> 01:15:26,115
Speaker 3:  It took the World bunch too. It's right up there. It's the click

1358
01:15:26,115 --> 01:15:29,635
Speaker 3:  wheel, it's Digital Crown, it's the track path. Three most important devices.

1359
01:15:30,735 --> 01:15:34,395
Speaker 3:  No, they don't have a touchscreen. It's like bananas. I can mirror a phone

1360
01:15:34,395 --> 01:15:38,275
Speaker 3:  onto your Mac without a touchscreen. But I think that the basic

1361
01:15:38,385 --> 01:15:41,715
Speaker 3:  idea that people wanna use their phone. There's a bunch of apps in your phone

1362
01:15:42,105 --> 01:15:45,795
Speaker 3:  that did not sign up for the Mac app store. When the Mac went to Apple Silicon,

1363
01:15:45,845 --> 01:15:49,275
Speaker 3:  which they really thought would happen. It did not happen. Yep. How are you

1364
01:15:49,275 --> 01:15:52,235
Speaker 3:  gonna get the Instagram app on your Mac? How are you gonna do it? It

1365
01:15:52,235 --> 01:15:53,635
Speaker 4:  Was a catalyst that was supposed to bring all that stuff

1366
01:15:53,635 --> 01:15:57,315
Speaker 3:  Across. Catalyst was iPad apps being remapped into Mac apps. Okay.

1367
01:15:57,455 --> 01:16:01,315
Speaker 3:  But now you can just run iOS apps on Apple, Silicon Mac

1368
01:16:01,515 --> 01:16:05,435
Speaker 3:  straight up, no porting. The Bluetooth lights in the

1369
01:16:05,435 --> 01:16:09,355
Speaker 3:  studio at my house have a horrible iPhone app. And it's the only, it's

1370
01:16:09,355 --> 01:16:12,195
Speaker 3:  the only app that has ever, I've been like, I wonder if that's here and it's

1371
01:16:12,195 --> 01:16:15,315
Speaker 3:  there. Sure. 'cause they don't care. Yeah. Instagram is like, no, we're not

1372
01:16:15,315 --> 01:16:17,195
Speaker 3:  letting you do this. Right. TikTok is like, we're not letting you do this.

1373
01:16:17,195 --> 01:16:18,355
Speaker 3:  We're not making you a Mac app.

1374
01:16:19,985 --> 01:16:23,715
Speaker 3:  Yeah. You just mirror your iPhone and I, it's just the most

1375
01:16:23,885 --> 01:16:27,795
Speaker 3:  brute force. Like we're just horse powering your this screen

1376
01:16:27,795 --> 01:16:31,035
Speaker 3:  onto that screen. Solve the problem. The app's still running on the phone.

1377
01:16:31,705 --> 01:16:34,355
Speaker 3:  It's very cool. I think it will work. I think people are gonna use it all

1378
01:16:34,355 --> 01:16:37,955
Speaker 3:  the time. The coolest part, I dunno if you guys saw this. The notifications

1379
01:16:37,975 --> 01:16:41,915
Speaker 3:  get remapped that, so your notifications show up on your Mac and you click,

1380
01:16:41,915 --> 01:16:45,035
Speaker 3:  it has Mac notifications, it has Mac notifications and you click 'em and

1381
01:16:45,035 --> 01:16:48,635
Speaker 3:  it'll pop up in The iPhone mirroring and drop you into The iPhone. I

1382
01:16:48,635 --> 01:16:52,395
Speaker 8:  Mean I'm nervous about that. Yeah. But I already don't like how many

1383
01:16:52,545 --> 01:16:56,115
Speaker 8:  notifications I get on my iPhone. I'm like, are they gonna be on my computer

1384
01:16:56,335 --> 01:16:56,755
Speaker 8:  now too?

1385
01:16:57,065 --> 01:17:00,835
Speaker 5:  Yeah. So you like AP News loves to push a breaking notification

1386
01:17:00,855 --> 01:17:04,395
Speaker 5:  for everything. Yeah. Is that gonna pop up on my, my Mac?

1387
01:17:04,545 --> 01:17:07,835
Speaker 4:  Well supposedly now thanks to the magic of ai,

1388
01:17:08,335 --> 01:17:11,765
Speaker 4:  all of your notifications are going to be sorted by priority. Which couldn't

1389
01:17:11,925 --> 01:17:15,645
Speaker 4:  possibly go wrong or be gamed by any systems because Apple has historically

1390
01:17:15,645 --> 01:17:17,405
Speaker 4:  done such a good job of managing notifications

1391
01:17:18,075 --> 01:17:20,165
Speaker 5:  Roll back. Like that's, that's all you gotta do.

1392
01:17:20,945 --> 01:17:21,965
Speaker 3:  No, they sherlocked the hell outta

1393
01:17:22,065 --> 01:17:25,405
Speaker 5:  Grs. I know they sherlocked it, but like they didn't make anything better.

1394
01:17:25,785 --> 01:17:26,165
Speaker 5:  No, that's,

1395
01:17:26,195 --> 01:17:28,325
Speaker 3:  They just made it worse. That's not what you do when you use your dominant

1396
01:17:28,685 --> 01:17:31,325
Speaker 3:  monopoly to kill your competition. Makes me so matter. It's not a choice

1397
01:17:31,325 --> 01:17:31,685
Speaker 3:  you're making.

1398
01:17:32,145 --> 01:17:36,125
Speaker 5:  But I am, I am excited about like the The iPhone thing just because I'll

1399
01:17:36,125 --> 01:17:39,805
Speaker 5:  be able to never have to get off my couch again when I need to like log

1400
01:17:39,915 --> 01:17:41,925
Speaker 5:  into something that needs two-factor authentication.

1401
01:17:42,585 --> 01:17:43,805
Speaker 3:  That's why you got an Apple watch.

1402
01:17:44,025 --> 01:17:44,685
Speaker 4:  Oh, that's a good one.

1403
01:17:45,425 --> 01:17:48,325
Speaker 3:  You all think the Apple Watch is a health and fitness device. I think of

1404
01:17:48,325 --> 01:17:51,325
Speaker 3:  this as a two factor dongle. Does it have like, that shames me from, does

1405
01:17:51,325 --> 01:17:51,405
Speaker 3:  it

1406
01:17:51,405 --> 01:17:52,405
Speaker 5:  Have the authenticators on it?

1407
01:17:52,545 --> 01:17:53,165
Speaker 3:  Oh yeah. Yeah.

1408
01:17:54,365 --> 01:17:56,965
Speaker 4:  I use, I use Okta Verify and Authe on it. Well I'm

1409
01:17:57,265 --> 01:17:57,685
Speaker 5:  Thanks

1410
01:17:57,685 --> 01:18:00,525
Speaker 4:  To you actually because you have been proselytizing this for years.

1411
01:18:00,665 --> 01:18:04,365
Speaker 3:  We don't use any of those services. We use other ones. This was not a security

1412
01:18:04,365 --> 01:18:04,645
Speaker 3:  hole.

1413
01:18:07,325 --> 01:18:08,565
Speaker 5:  I don't have any of those on my watch.

1414
01:18:09,465 --> 01:18:09,685
Speaker 3:  We

1415
01:18:09,685 --> 01:18:10,805
Speaker 4:  Use the new Apple password that I'm

1416
01:18:10,885 --> 01:18:13,605
Speaker 3:  Downloading 'em right now. This is a, this is a two factor dongle that will

1417
01:18:13,765 --> 01:18:16,565
Speaker 3:  occasionally shame you for not standing up. And it's fine. It works. Yeah.

1418
01:18:16,725 --> 01:18:19,845
Speaker 3:  That's great. But I, but that thing where they added more iPhone to the Mac

1419
01:18:20,265 --> 01:18:24,245
Speaker 3:  Deeply, deeply funny. Oh yeah. They also, we talked

1420
01:18:24,245 --> 01:18:27,005
Speaker 3:  a lot about Siri in the AI section. They changed the way Siri looks and works

1421
01:18:27,025 --> 01:18:30,165
Speaker 3:  on the Mac to make it more powerful to give it more of these text inputs.

1422
01:18:30,545 --> 01:18:33,605
Speaker 3:  But like it's, they didn't change much. The big other feature they got a

1423
01:18:33,605 --> 01:18:37,325
Speaker 3:  lot of cheers in the Mac section was automatic window tiling, which Windows

1424
01:18:37,425 --> 01:18:38,925
Speaker 3:  has had for 100 years.

1425
01:18:39,765 --> 01:18:43,685
Speaker 5:  I have used it so much on Windows. And I have an app on my computer that

1426
01:18:43,685 --> 01:18:46,165
Speaker 5:  I like. When they announced it, I was like, but I thought we already had

1427
01:18:46,165 --> 01:18:46,325
Speaker 5:  that.

1428
01:18:46,755 --> 01:18:50,725
Speaker 4:  Yeah. It's it's one of those features that it is truly bonkers. It didn't

1429
01:18:50,725 --> 01:18:54,365
Speaker 4:  have already. Yeah. And there are a million apps out there that are free

1430
01:18:54,425 --> 01:18:57,765
Speaker 4:  and great for window tiling and will do it better than Sequoia I'm sure.

1431
01:18:58,825 --> 01:19:01,885
Speaker 4:  So go use those Magnet. I use one called Rectangle. It's very good. Highly.

1432
01:19:02,105 --> 01:19:03,405
Speaker 3:  That's a good name for an app. It

1433
01:19:03,405 --> 01:19:05,925
Speaker 4:  Is. It's very good. Very good. It's very good. And it's free and it's wonderful

1434
01:19:05,925 --> 01:19:09,845
Speaker 4:  and everybody should use it. But this, it's, yeah, there's so many

1435
01:19:09,845 --> 01:19:13,165
Speaker 4:  things in here that are just like Apple sort of slowly checking off boxes

1436
01:19:13,305 --> 01:19:16,725
Speaker 4:  of like features. It's insane that have not been here for a decade. Yeah.

1437
01:19:17,465 --> 01:19:18,565
Speaker 4:  And that's fine. I'll take

1438
01:19:18,565 --> 01:19:20,605
Speaker 3:  It. A lot of people have asked me

1439
01:19:22,185 --> 01:19:25,845
Speaker 3:  how to feel. I guess I, I don't know about Sari, how to describe this about

1440
01:19:25,965 --> 01:19:28,885
Speaker 3:  Safari. Yeah. Yeah. And the fact that it has AI summaries built into it now,

1441
01:19:28,885 --> 01:19:32,325
Speaker 3:  which is, I know you two love Arc, but a lot of people have feelings about

1442
01:19:32,385 --> 01:19:35,445
Speaker 3:  Arc doing that in different ways. Feelings about perplexity doing that in

1443
01:19:35,445 --> 01:19:38,925
Speaker 3:  different ways. This one feels much more innocuous.

1444
01:19:39,645 --> 01:19:43,045
Speaker 3:  'cause you're browsing the web and it is loading the webpages.

1445
01:19:43,485 --> 01:19:46,525
Speaker 5:  I mean, I have it turned off in Arc. I always forget that it's, it's there

1446
01:19:46,525 --> 01:19:47,645
Speaker 3:  Though. You just like Arc.

1447
01:19:47,715 --> 01:19:48,885
Speaker 5:  Yeah. I just love Arc.

1448
01:19:48,945 --> 01:19:51,125
Speaker 4:  But that, that distinction you made I think is actually really important.

1449
01:19:51,145 --> 01:19:54,405
Speaker 4:  And as the whole thing, right? Like Apple's way of doing this is you go to

1450
01:19:54,525 --> 01:19:58,325
Speaker 4:  a webpage and then AI can do things to that webpage. Yeah.

1451
01:19:59,145 --> 01:20:01,645
Speaker 4:  And like a bunch of it is really clever. Right? It's like there, if you're

1452
01:20:01,645 --> 01:20:04,325
Speaker 4:  looking for important information on a webpage, it will help you surface

1453
01:20:04,345 --> 01:20:07,725
Speaker 4:  it. Like Yep. If you ever go to like a restaurant website and you look for

1454
01:20:07,725 --> 01:20:11,565
Speaker 4:  the phone number, impossible. And this is like, it will just find you the

1455
01:20:11,565 --> 01:20:15,085
Speaker 4:  phone number. Like that's good. But you're already on the website, right?

1456
01:20:15,085 --> 01:20:17,925
Speaker 4:  Yeah. And so now, now all you're doing is you're solving for awful web design,

1457
01:20:17,935 --> 01:20:21,885
Speaker 4:  which I'm fully in favor of. Like, hey, I should destroy bad web design.

1458
01:20:23,025 --> 01:20:26,845
Speaker 4:  But it, it flips the equation of the thing. Like it's not going to the webpage

1459
01:20:26,945 --> 01:20:30,885
Speaker 4:  and then returning information on my behalf. I am going to the webpage. Yeah.

1460
01:20:30,885 --> 01:20:32,245
Speaker 4:  And then asking it for information.

1461
01:20:32,305 --> 01:20:36,245
Speaker 3:  To be clear, we have not used this to any great extent. Like no, we've seen

1462
01:20:36,245 --> 01:20:39,245
Speaker 3:  some demos. We people have the private betas and they're publishing about

1463
01:20:39,245 --> 01:20:42,605
Speaker 3:  it. So like people are talking about it. But I think there's gonna be a lot

1464
01:20:42,605 --> 01:20:46,245
Speaker 3:  of back and forth between, hey, this web browser is now doing a lot of summary.

1465
01:20:46,665 --> 01:20:50,365
Speaker 3:  You have a big partner with OpenAI, which not everyone is so happy with.

1466
01:20:50,605 --> 01:20:53,565
Speaker 3:  I have a disclosure. Our company has a content deal with OpenAI.

1467
01:20:54,955 --> 01:20:55,245
Speaker 3:  Cool.

1468
01:20:57,125 --> 01:20:58,325
Speaker 3:  I dunno if we have one with anyone else,

1469
01:20:59,985 --> 01:21:03,965
Speaker 3:  but like, I, I think a lot of, a lot of the Safari work,

1470
01:21:04,105 --> 01:21:07,525
Speaker 3:  at one point the person who's presenting Safari was like, if you haven't

1471
01:21:07,525 --> 01:21:11,405
Speaker 3:  used it, you should try it. It got pretty good. Yeah. It's like, oh boy,

1472
01:21:11,405 --> 01:21:14,045
Speaker 3:  you need to get this back. Yeah. You gotta get this back on track. So they're

1473
01:21:14,045 --> 01:21:17,045
Speaker 3:  adding some features to it because as David has been covering an installer,

1474
01:21:17,395 --> 01:21:20,725
Speaker 3:  like Browser Wars are back, there's like a bunch of very interesting browsers

1475
01:21:20,875 --> 01:21:24,525
Speaker 3:  because of AI features. And so I think Apple needs to capture some of that.

1476
01:21:24,995 --> 01:21:28,965
Speaker 4:  Yeah. And the, like, the reader mode updates that it got

1477
01:21:29,065 --> 01:21:31,205
Speaker 4:  was cool reader's another one that it's like nobody's mad at reader mode

1478
01:21:31,205 --> 01:21:33,805
Speaker 4:  even though it strips everything out because you have to load the webpage,

1479
01:21:33,805 --> 01:21:36,645
Speaker 4:  you have to load the webpage. Like it's, that's just the whole thing. And

1480
01:21:37,105 --> 01:21:40,045
Speaker 4:  the, there's now the, what's it called? They call it the viewer mode where

1481
01:21:40,045 --> 01:21:42,685
Speaker 4:  it'll just pop up a video that's on the page if you wanna watch the video

1482
01:21:42,685 --> 01:21:45,565
Speaker 4:  and give you like native picture and picture and viewing controls. That's

1483
01:21:45,565 --> 01:21:48,365
Speaker 4:  very good. Awesome. Love it. Yeah. Incredible. It's making that websites

1484
01:21:48,365 --> 01:21:52,325
Speaker 4:  better. Unbelievable. Yeah. Huge fan. Make me go to the website.

1485
01:21:53,295 --> 01:21:56,405
Speaker 3:  Right. The the problem with all the other browser is like, you'll stop browsing

1486
01:21:56,405 --> 01:21:59,525
Speaker 3:  the web. Right. And then there's no more incentive to make web And I think

1487
01:21:59,555 --> 01:22:00,805
Speaker 3:  Apple's trying to walk the line here.

1488
01:22:00,835 --> 01:22:04,525
Speaker 4:  Yeah, yeah. But I'm, I'm again, yeah, there's a lot of questions, but I'm

1489
01:22:04,525 --> 01:22:08,165
Speaker 4:  kind of in favor. Is does anyone sitting here use Safari with any

1490
01:22:08,165 --> 01:22:10,725
Speaker 4:  regularity? I, I do. Do you like on purpose?

1491
01:22:11,235 --> 01:22:15,045
Speaker 5:  Yeah. For, for until I'm switched to Arc, I would do like Edge is my work

1492
01:22:15,045 --> 01:22:17,725
Speaker 5:  browser and Safari was my personal browser.

1493
01:22:19,015 --> 01:22:20,255
Speaker 5:  I tried to keep the work separate.

1494
01:22:23,435 --> 01:22:26,255
Speaker 4:  So what I've learned about you in this podcast so far, you are a

1495
01:22:27,045 --> 01:22:30,095
Speaker 4:  devoted Mac user who loves Outlook and Edge,

1496
01:22:31,885 --> 01:22:34,415
Speaker 5:  Make better mail and web browser,

1497
01:22:34,795 --> 01:22:36,255
Speaker 4:  Use other devices. Yeah.

1498
01:22:36,255 --> 01:22:40,175
Speaker 3:  Yeah. Have you heard about these? IPCs? Yeah. You love being watched surface

1499
01:22:40,235 --> 01:22:43,135
Speaker 4:  By big corporations. Surface tight. Dude, you were also on this podcast not

1500
01:22:43,135 --> 01:22:46,135
Speaker 4:  long ago being like, oh, what Apple wants to do is build a surface. You can

1501
01:22:46,135 --> 01:22:46,575
Speaker 4:  just have one.

1502
01:22:47,335 --> 01:22:51,295
Speaker 5:  I know, but I don't want it. I I want, I want Apple to do what I want it

1503
01:22:51,295 --> 01:22:51,615
Speaker 5:  to. You

1504
01:22:51,615 --> 01:22:52,655
Speaker 4:  Just want U up your iPhone.

1505
01:22:54,245 --> 01:22:57,895
Speaker 3:  This is like, people in America are so confused about competition. Yeah.

1506
01:22:57,895 --> 01:23:00,455
Speaker 3:  They're like, I'll just yell at Apple until it makes me the product I want.

1507
01:23:00,575 --> 01:23:04,015
Speaker 3:  I won't just buy the product that exists. Exactly. The party is the thing

1508
01:23:04,015 --> 01:23:04,255
Speaker 3:  I want.

1509
01:23:04,275 --> 01:23:06,965
Speaker 5:  That's, that's why I'm in the job I'm in. So I can, that's very yell everywhere.

1510
01:23:06,965 --> 01:23:07,205
Speaker 5:  Very.

1511
01:23:07,905 --> 01:23:11,125
Speaker 3:  Can we spend two seconds talking about gaming and then talk about passwords?

1512
01:23:11,675 --> 01:23:13,125
Speaker 4:  Literally two seconds. Okay.

1513
01:23:13,335 --> 01:23:14,485
Speaker 3:  Apple announced a bunch of,

1514
01:23:14,585 --> 01:23:15,245
Speaker 4:  That's it. Sorry.

1515
01:23:16,885 --> 01:23:19,725
Speaker 3:  I just wanna announce they they were like, you can now play Death Stranding

1516
01:23:19,725 --> 01:23:23,445
Speaker 3:  on the Mac that came, came out in 2019. That Assassin Creed

1517
01:23:23,605 --> 01:23:26,805
Speaker 3:  game. The one that is coming out. That's true. But another one came out in

1518
01:23:26,805 --> 01:23:30,765
Speaker 3:  2019 and then the big finale was Control Now with Ray Tracing

1519
01:23:31,035 --> 01:23:34,365
Speaker 3:  Control was the game of the year in like

1520
01:23:34,365 --> 01:23:35,085
Speaker 3:  2017.

1521
01:23:35,905 --> 01:23:39,125
Speaker 5:  It, yeah, it, the control is a game that everybody just uses to show off

1522
01:23:39,185 --> 01:23:42,485
Speaker 5:  Ray tracing. 'cause it has really good ray tracing. Like Yeah. That's kind

1523
01:23:42,485 --> 01:23:44,565
Speaker 5:  of why it exists in most people's computers now. I It's

1524
01:23:44,565 --> 01:23:46,965
Speaker 3:  Good game like Control is at the point where it's like, if you open the PlayStation

1525
01:23:46,965 --> 01:23:50,125
Speaker 3:  store on the right day, it's like, do you just want control? Yeah. Like you

1526
01:23:50,125 --> 01:23:52,845
Speaker 3:  should have it is like really good, you know, like you should try it out.

1527
01:23:53,465 --> 01:23:56,525
Speaker 5:  But the Ubisoft stuff was interesting. It did feel like Apple is trying to

1528
01:23:56,525 --> 01:24:00,085
Speaker 5:  kind of brute force its way back into the gaming conversation.

1529
01:24:00,525 --> 01:24:04,365
Speaker 5:  I mean, it's been doing it for the last three or four years, but having the

1530
01:24:04,525 --> 01:24:08,325
Speaker 5:  Ubisoft like guy on stage, having the new

1531
01:24:08,325 --> 01:24:11,885
Speaker 5:  games come out on the iPad. On the Mac like day and date. That

1532
01:24:11,945 --> 01:24:13,605
Speaker 5:  that's, that's not nothing.

1533
01:24:13,915 --> 01:24:17,725
Speaker 3:  Wait, I got this wrong. Control is a Game of the Year contender

1534
01:24:17,725 --> 01:24:21,605
Speaker 3:  in 2019. The Assassin's Creed game came out in 2017. I'm sorry Zoe.

1535
01:24:21,605 --> 01:24:22,525
Speaker 3:  Apologies to

1536
01:24:22,685 --> 01:24:25,885
Speaker 5:  Everyone. Yeah, it's, they're all old. But

1537
01:24:25,885 --> 01:24:26,725
Speaker 4:  Also this, they're

1538
01:24:26,725 --> 01:24:30,085
Speaker 3:  Old game. This does, I was a different person. This was before the pandemic.

1539
01:24:30,365 --> 01:24:30,605
Speaker 3:  I was

1540
01:24:30,605 --> 01:24:31,885
Speaker 5:  Like, it's pre Covid. It's

1541
01:24:31,885 --> 01:24:33,925
Speaker 3:  Old. I used to, I was breathing on people every day.

1542
01:24:35,995 --> 01:24:39,885
Speaker 4:  This does continue Assassin's Creed's Perfect streak of being available on

1543
01:24:39,885 --> 01:24:41,125
Speaker 4:  every platform invented by

1544
01:24:41,125 --> 01:24:43,685
Speaker 3:  Anyone. If you add a computer and you're like, can I fucking stab someone

1545
01:24:43,705 --> 01:24:45,485
Speaker 3:  on this computer? Ubisoft is there.

1546
01:24:45,725 --> 01:24:47,805
Speaker 5:  They're like, yes. In a little French accent.

1547
01:24:50,505 --> 01:24:52,285
Speaker 3:  The new one is Infu Japan. All

1548
01:24:52,285 --> 01:24:56,125
Speaker 4:  Right. That's, that's too much Game mode talk. Let's talk about watchOS

1549
01:24:56,205 --> 01:24:59,645
Speaker 4:  briefly. This is the one I am perhaps least qualified to talk about because

1550
01:24:59,725 --> 01:25:03,645
Speaker 4:  I just went in and turned off all of the fitness notifications. Yeah. On

1551
01:25:03,645 --> 01:25:07,005
Speaker 4:  my Apple watch because they were making me sad. Now they like, do you wanna

1552
01:25:07,005 --> 01:25:10,245
Speaker 4:  stand up? And I was like, no, I'm on a call. Leave me alone Apple. But there's

1553
01:25:10,245 --> 01:25:13,365
Speaker 4:  like, if you're a fitness person and Allison, you're wearing a watch and

1554
01:25:13,365 --> 01:25:17,085
Speaker 4:  seem like a fitness person. There's a lot of new stuff here. This thing is

1555
01:25:17,085 --> 01:25:20,605
Speaker 4:  like a super intense health and fitness device. Now. It's getting serious.

1556
01:25:21,325 --> 01:25:25,125
Speaker 8:  I, I will say, and we'll give this shout out for Colleague V Song

1557
01:25:25,275 --> 01:25:28,805
Speaker 8:  that you can now finally tell Apple you're taking a rest day

1558
01:25:29,345 --> 01:25:33,325
Speaker 8:  and or like you're sick. You are not gonna go do your little jog or

1559
01:25:33,445 --> 01:25:34,605
Speaker 5:  Whatever. I think he's soft. Yeah,

1560
01:25:34,925 --> 01:25:38,405
Speaker 8:  Probably. I like, I could feel it. I could feel her, you know,

1561
01:25:38,585 --> 01:25:39,005
Speaker 8:  energy.

1562
01:25:39,425 --> 01:25:42,565
Speaker 4:  He was typing in our Slack when this got launched and was typing in all caps

1563
01:25:42,665 --> 01:25:45,125
Speaker 4:  so fast. She was just making thousands of typos. Yeah.

1564
01:25:45,195 --> 01:25:45,485
Speaker 5:  Just

1565
01:25:45,895 --> 01:25:49,765
Speaker 4:  Happy your joy. Yeah. Yeah. But yeah, so there's, you can now take rest

1566
01:25:49,765 --> 01:25:53,445
Speaker 4:  days. You can also change your goals day to day throughout the week.

1567
01:25:53,725 --> 01:25:57,405
Speaker 4:  Which I think is very clever. There's a new vitals app that'll track new

1568
01:25:57,405 --> 01:26:01,045
Speaker 4:  stuff on your body. If I explain it more than that, I will immediately

1569
01:26:01,055 --> 01:26:05,045
Speaker 4:  sound as dumb as I am about all of this. You can rate like

1570
01:26:05,065 --> 01:26:08,845
Speaker 4:  the effort of a workout. It's basically like, this is all just health

1571
01:26:09,065 --> 01:26:11,485
Speaker 4:  inputs and outputs, right? Yeah. Like that is what this device is. Now

1572
01:26:11,555 --> 01:26:14,565
Speaker 5:  They, it felt like they added a bunch of stuff that other folks have been

1573
01:26:14,565 --> 01:26:18,245
Speaker 5:  doing. Like Aura Ring has been doing and Garment has been doing it. Especially

1574
01:26:18,245 --> 01:26:21,605
Speaker 5:  the health stuff. Like Aura has been all over that. Yeah. And it was like,

1575
01:26:21,605 --> 01:26:25,165
Speaker 5:  oh we, we, we've got all those sensors. We've in fact got better sensors.

1576
01:26:25,225 --> 01:26:28,725
Speaker 5:  We could probably do that. And Apple has just been really weird about it

1577
01:26:28,785 --> 01:26:29,885
Speaker 5:  before now and

1578
01:26:29,885 --> 01:26:33,805
Speaker 3:  Well they've been in a pretty healthy lawsuit. The company event. That's

1579
01:26:33,845 --> 01:26:35,005
Speaker 4:  Probably, yeah. That's

1580
01:26:35,125 --> 01:26:39,045
Speaker 5:  Probably why. But so, so it's, it's nice to see that. Yeah. You'll be able

1581
01:26:39,125 --> 01:26:42,165
Speaker 5:  I, the rest days is the big one though. I think. I think that was what the

1582
01:26:42,165 --> 01:26:44,365
Speaker 5:  one like I was seeing on threads even everybody was just like

1583
01:26:44,835 --> 01:26:47,405
Speaker 3:  Rest. Yeah that was the one the people ask that forever.

1584
01:26:47,635 --> 01:26:51,045
Speaker 5:  Yeah because it's, yeah, sometimes you feel like garbage and your watch is

1585
01:26:51,045 --> 01:26:53,605
Speaker 5:  like, you haven't moved at all today. You piece of shit. Yeah. And you're

1586
01:26:53,605 --> 01:26:56,565
Speaker 5:  like, because I feel like garbage. Thanks mom. Like leave me alone.

1587
01:26:57,305 --> 01:27:00,605
Speaker 4:  And it seems to get like meaner and meaner as time goes on. Like if you get

1588
01:27:00,605 --> 01:27:04,085
Speaker 4:  to like day three of not closing all your rings,

1589
01:27:04,875 --> 01:27:08,045
Speaker 4:  your watch is just so disappointed in you. Yeah. It's like, it's like you

1590
01:27:08,045 --> 01:27:10,645
Speaker 4:  get Yeah you get the message. It's like you didn't close any rings yesterday.

1591
01:27:10,965 --> 01:27:14,805
Speaker 4:  Like let's just try for one today. I'm like, I'm sorry, what's the bare minimum

1592
01:27:15,105 --> 01:27:18,445
Speaker 4:  you can get me? What you did anything today. I'm like I didn't even have

1593
01:27:18,445 --> 01:27:20,005
Speaker 4:  my watch on yesterday. Leave me alone.

1594
01:27:20,375 --> 01:27:22,925
Speaker 3:  Stand ring. We're gonna go for stand ring once

1595
01:27:22,945 --> 01:27:23,845
Speaker 4:  An hour. Yeah,

1596
01:27:24,035 --> 01:27:24,845
Speaker 3:  Just stand.

1597
01:27:25,305 --> 01:27:28,125
Speaker 4:  I'm gonna put my goal to three hours today. Let's go Apple.

1598
01:27:28,505 --> 01:27:29,085
Speaker 3:  That's good.

1599
01:27:29,925 --> 01:27:32,805
Speaker 4:  Alright, let's burn through the last ones then we can take a break. AirPods,

1600
01:27:32,985 --> 01:27:36,125
Speaker 4:  we talked a little bit about the AirPods. You not head shake. Oh yeah, nod.

1601
01:27:36,125 --> 01:27:39,885
Speaker 4:  Very good. That good. Unbelievably unconvinced that that

1602
01:27:39,885 --> 01:27:43,845
Speaker 4:  works. But if it does, I'm very excited. There are a lot of people out there

1603
01:27:44,105 --> 01:27:48,085
Speaker 4:  who are trying to make that stuff work. Turns out you move your

1604
01:27:48,085 --> 01:27:51,005
Speaker 4:  head a lot. I don't know if you've noticed, but like in just being a person

1605
01:27:51,005 --> 01:27:54,925
Speaker 4:  in the world, you move ahead your head a lot. And so figuring those

1606
01:27:54,925 --> 01:27:55,805
Speaker 4:  gestures out. I

1607
01:27:55,805 --> 01:27:58,525
Speaker 5:  Complic, I hope it's the same way. Like when you talk to your computer or

1608
01:27:58,525 --> 01:28:01,725
Speaker 5:  you use a voice, you have like your computer voice. I hope you have to like

1609
01:28:01,795 --> 01:28:03,525
Speaker 5:  have a computer head nod dramatically.

1610
01:28:03,715 --> 01:28:04,245
Speaker 4:  Head nod.

1611
01:28:04,245 --> 01:28:07,405
Speaker 5:  Exactly. So you're just like walking down the street doing these really dramatic

1612
01:28:07,405 --> 01:28:08,525
Speaker 5:  head nods. That would be ideal.

1613
01:28:08,575 --> 01:28:11,725
Speaker 4:  Which is definitely better than talking to yourself. Yeah, yeah, yeah. Not,

1614
01:28:11,905 --> 01:28:14,245
Speaker 4:  not weird to just constantly be walking those spaces. In both

1615
01:28:14,245 --> 01:28:16,205
Speaker 5:  Cases you'll probably get the car to yourself on the subway.

1616
01:28:17,525 --> 01:28:20,805
Speaker 3:  I was walking down the street in Philadelphia the other day and a woman rode

1617
01:28:20,805 --> 01:28:24,725
Speaker 3:  by on her bike and she just goes, Hey Siri, really loud, you have a

1618
01:28:24,725 --> 01:28:28,005
Speaker 3:  pods in. And I was like, literally like a lot of people stopped because that

1619
01:28:28,005 --> 01:28:31,445
Speaker 3:  was just a weird thing to happen. And I said out loud to the person I was

1620
01:28:31,445 --> 01:28:33,645
Speaker 3:  walking with, I've never seen anyone do that in the wild before. Yeah. And

1621
01:28:33,645 --> 01:28:37,205
Speaker 3:  they're like, that was special. And that we had like, everyone's like the

1622
01:28:37,205 --> 01:28:40,525
Speaker 3:  whole street had a moment. 'cause she was like, I'm gonna talk to Siri while

1623
01:28:40,525 --> 01:28:41,885
Speaker 3:  I'm just biking. It's

1624
01:28:41,885 --> 01:28:44,645
Speaker 5:  Hard to do in public 'cause you're like, I'm always like, Hey Siri,

1625
01:28:44,645 --> 01:28:47,965
Speaker 3:  How are you? Yeah, no, she, I you gotta, no, she just Philly man with

1626
01:28:47,965 --> 01:28:50,885
Speaker 5:  Her whole chest. The whole, I love that point. Philly,

1627
01:28:51,025 --> 01:28:54,165
Speaker 3:  That's where, that's where you can just do it. Yeah. There are some towns

1628
01:28:54,165 --> 01:28:56,605
Speaker 3:  in America where you can just address Voice assistant. Yeah.

1629
01:28:56,985 --> 01:29:00,245
Speaker 5:  The AirPods Pros, they're getting better like phone calls to

1630
01:29:00,255 --> 01:29:02,645
Speaker 3:  Microphone voice isolation. Yeah. Yeah. Which

1631
01:29:02,645 --> 01:29:06,445
Speaker 4:  Is a feature that has existed for a long time and is deeply buried

1632
01:29:06,465 --> 01:29:09,525
Speaker 4:  in settings on all of your devices. This is like a thing you can do on phone

1633
01:29:09,525 --> 01:29:13,005
Speaker 4:  calls now and it makes you sound so much better. Yeah. And it has always

1634
01:29:13,005 --> 01:29:15,685
Speaker 4:  driven me crazy that Apple doesn't just turn it on by default. But it's a

1635
01:29:15,685 --> 01:29:18,445
Speaker 4:  thing that exists on the Mac. It's a thing that exists on The iPhone, but

1636
01:29:18,445 --> 01:29:21,645
Speaker 4:  you have to turn it on for every single call like in the middle of the call.

1637
01:29:21,825 --> 01:29:24,925
Speaker 4:  And that's very stupid. And so the fact that it's just on now, there's also

1638
01:29:24,925 --> 01:29:28,605
Speaker 4:  the personalized spatial audio, which, you know, NE's favorite feature so

1639
01:29:28,605 --> 01:29:30,845
Speaker 4:  that everyone can sneak up on you during your phone calls. Yeah.

1640
01:29:30,845 --> 01:29:31,445
Speaker 3:  That's what you want.

1641
01:29:33,105 --> 01:29:35,045
Speaker 4:  But no, I'm, I'm into it. The AirPods,

1642
01:29:35,435 --> 01:29:36,365
Speaker 3:  They did it. Yeah.

1643
01:29:36,515 --> 01:29:39,685
Speaker 4:  They're still AirPods. No more Air AirPods Maxes. I really thought

1644
01:29:40,275 --> 01:29:44,085
Speaker 4:  that we were gonna get AirPods today. Either it was gonna be a home pod or

1645
01:29:44,085 --> 01:29:47,285
Speaker 4:  a new AirPods maxes and they were gonna like make a whole series story out

1646
01:29:47,285 --> 01:29:48,005
Speaker 4:  of it. Nothing.

1647
01:29:48,565 --> 01:29:51,725
Speaker 3:  Whatever in thought was that they were gonna add Macs, the iPod and the AirPods

1648
01:29:51,725 --> 01:29:54,885
Speaker 3:  would be the focus of all the AI efforts. And all of you people were disappointed.

1649
01:29:55,225 --> 01:29:55,445
Speaker 3:  So

1650
01:29:55,445 --> 01:29:57,605
Speaker 4:  We got a calculator app and it was sick.

1651
01:29:59,325 --> 01:30:02,645
Speaker 4:  TVOS we have covered several times. We'll just move on from there.

1652
01:30:03,215 --> 01:30:05,365
Speaker 4:  It'll now we're getting a new season.

1653
01:30:05,465 --> 01:30:09,445
Speaker 3:  The added 21 9 projector support to TVOS. Okay. This is the next hour

1654
01:30:09,445 --> 01:30:12,245
Speaker 3:  of the George Cast. I'm moving on excited

1655
01:30:12,245 --> 01:30:15,565
Speaker 4:  About this to speaking of the next hour of The Vergecast vision os

1656
01:30:16,725 --> 01:30:20,645
Speaker 3:  I will not name names, but a friend of ours, friend of

1657
01:30:20,645 --> 01:30:24,525
Speaker 3:  the show came up to us and they're like, so they're just giving up on the

1658
01:30:24,525 --> 01:30:27,315
Speaker 3:  Vision Pro and they, they, this person looked

1659
01:30:28,335 --> 01:30:30,675
Speaker 3:  bereft. Aw, bereft.

1660
01:30:31,015 --> 01:30:31,675
Speaker 5:  That's sad.

1661
01:30:32,355 --> 01:30:34,915
Speaker 3:  And I was like, no, I think they just, they announced four months ago. I

1662
01:30:34,915 --> 01:30:37,795
Speaker 3:  don't think they had anything left in the tank.

1663
01:30:38,695 --> 01:30:40,035
Speaker 3:  And like they're giving up on it. Well,

1664
01:30:40,215 --> 01:30:44,115
Speaker 5:  Wes Davis was going through all of the updates and he's like, oh, what

1665
01:30:44,115 --> 01:30:47,915
Speaker 5:  they didn't say on stage was that they're fixing a ton of bugs and

1666
01:30:47,915 --> 01:30:50,875
Speaker 5:  issues he's had with it. 'cause he's like the one PE person upset. He loves

1667
01:30:50,875 --> 01:30:53,835
Speaker 5:  it. He loves it. God bless him. He's always like, you wanna FaceTime? I'm

1668
01:30:53,835 --> 01:30:54,755
Speaker 5:  like, absolutely not.

1669
01:30:56,335 --> 01:31:00,195
Speaker 5:  Put that in the fire. But, but yeah. So he's apparently there's doing a bunch

1670
01:31:00,195 --> 01:31:02,915
Speaker 5:  of updates to it, but they just didn't talk about any of that.

1671
01:31:02,985 --> 01:31:06,915
Speaker 3:  They did not. Because I think you have to know what is broken about

1672
01:31:06,915 --> 01:31:10,395
Speaker 3:  the Vision Pro in order to appreciate the fixes. Yeah. And most people don't

1673
01:31:10,395 --> 01:31:11,475
Speaker 3:  know anything about the vision program

1674
01:31:11,475 --> 01:31:12,835
Speaker 5:  And they're like, we're not spending time on that. This

1675
01:31:12,835 --> 01:31:14,875
Speaker 3:  David is fond of reminding us it costs $3,500.

1676
01:31:15,125 --> 01:31:17,715
Speaker 4:  Seven outta 10 baby. Here we go.

1677
01:31:19,315 --> 01:31:22,875
Speaker 3:  I, I stand by my review now more than ever. Actually not the score, but the

1678
01:31:22,875 --> 01:31:23,155
Speaker 3:  review.

1679
01:31:23,755 --> 01:31:26,875
Speaker 4:  Yeah. No, I, I think it's right. And I think we, we have, we have continued

1680
01:31:26,875 --> 01:31:29,395
Speaker 4:  to find what is that? It's better out here than in there.

1681
01:31:30,495 --> 01:31:33,235
Speaker 3:  But they did add, they're adding more immersive videos. They're gonna release

1682
01:31:33,235 --> 01:31:35,675
Speaker 3:  more stuff. They're releasing it more countries, which actually got a huge

1683
01:31:35,675 --> 01:31:39,635
Speaker 3:  cheer that expands the market. Canons making a special

1684
01:31:39,665 --> 01:31:42,835
Speaker 3:  lens just for the R nine. Which Allison, I'm curious to you read on this.

1685
01:31:43,095 --> 01:31:43,475
Speaker 3:  Oh my

1686
01:31:43,475 --> 01:31:47,275
Speaker 8:  God, I totally like blanked that out. It looked like,

1687
01:31:47,655 --> 01:31:51,475
Speaker 8:  wasn't there a moment where some company was making a 3D lens for the camera?

1688
01:31:51,785 --> 01:31:55,475
Speaker 8:  Yeah. Like Fuji Film I think did the, like, you know, when

1689
01:31:55,475 --> 01:31:59,205
Speaker 8:  3D was gonna be the next thing, they're like, here's a camera lens that will

1690
01:31:59,205 --> 01:32:02,925
Speaker 8:  shoot 3D photos for you. And I was like, we're doing it

1691
01:32:02,925 --> 01:32:03,605
Speaker 8:  again. Yeah.

1692
01:32:03,605 --> 01:32:07,445
Speaker 3:  Oh know, I can't tell if the, the EOS R nine, it was specifically the

1693
01:32:07,445 --> 01:32:10,925
Speaker 3:  camera they called out has a sensor or a

1694
01:32:11,095 --> 01:32:14,965
Speaker 3:  processing system that can take the split image. Right.

1695
01:32:15,085 --> 01:32:17,165
Speaker 3:  'cause what they're doing is they're making a right and left image and then

1696
01:32:17,715 --> 01:32:20,685
Speaker 3:  combining it somewhere. So I'm wondering if the camera has some setting but

1697
01:32:20,685 --> 01:32:24,365
Speaker 3:  it, it, the Canon's making a lens for one camera. It's not just

1698
01:32:24,805 --> 01:32:28,325
Speaker 3:  a canon lens like you would expect. It's for this one camera. So now you

1699
01:32:28,325 --> 01:32:29,805
Speaker 3:  can shoot Apple immersive with this one camera.

1700
01:32:30,065 --> 01:32:31,285
Speaker 5:  Is it the R nine or the R seven?

1701
01:32:32,085 --> 01:32:32,825
Speaker 3:  Was it the R seven

1702
01:32:34,435 --> 01:32:37,625
Speaker 3:  urine? Says it was the R seven urine's already bought the lens.

1703
01:32:39,605 --> 01:32:42,465
Speaker 8:  No. Oh my gosh. Live fact checking.

1704
01:32:44,255 --> 01:32:45,925
Speaker 3:  Maybe I just typed it wrong in the Lifelog.

1705
01:32:47,825 --> 01:32:48,365
Speaker 3:  Now I'm checking.

1706
01:32:48,795 --> 01:32:52,245
Speaker 4:  Yeah. Again, I would say this is indicative of how important this actually

1707
01:32:52,785 --> 01:32:53,125
Speaker 4:  to the world.

1708
01:32:53,235 --> 01:32:55,685
Speaker 3:  It's zero seven actually. But I think this is really wild. 'cause there's

1709
01:32:55,685 --> 01:32:59,005
Speaker 3:  not enough content for this headset. Right. So that they spend a lot of time

1710
01:32:59,005 --> 01:33:02,205
Speaker 3:  talking about just like how they're building out the content pipelines for

1711
01:33:02,205 --> 01:33:04,325
Speaker 3:  the Canon EOS R seven. Thank

1712
01:33:04,325 --> 01:33:04,365
Speaker 8:  You.

1713
01:33:05,075 --> 01:33:08,925
Speaker 4:  Yeah, no it's true. It's very clear that Apple thinks content is

1714
01:33:08,925 --> 01:33:12,645
Speaker 4:  the thing. Yep. And they, they announced like new environments, new

1715
01:33:12,795 --> 01:33:16,205
Speaker 4:  ways to look at the spatial photos, like new, new tools for showing this

1716
01:33:16,205 --> 01:33:19,845
Speaker 4:  stuff. It's very obvious to me that the two things they're seeing people

1717
01:33:19,845 --> 01:33:22,725
Speaker 4:  do in this are used it as a monitor, which is why they announced the new

1718
01:33:22,735 --> 01:33:26,325
Speaker 4:  ultra wide monitor, which looked awesome. I'm confident will not look like

1719
01:33:26,325 --> 01:33:29,485
Speaker 4:  that in actual use. But the idea of having one

1720
01:33:30,505 --> 01:33:34,325
Speaker 4:  wi giant like wall sized monitor in front of you kicks

1721
01:33:34,345 --> 01:33:35,165
Speaker 4:  ass. And I want it very badly.

1722
01:33:35,385 --> 01:33:38,645
Speaker 3:  I'm very excited to see if that means Mac OS will now support

1723
01:33:39,295 --> 01:33:43,045
Speaker 3:  ultra wides. Curved ultra wides more natively. Oh, that's interesting. So

1724
01:33:43,045 --> 01:33:45,485
Speaker 3:  right now if you get one of the crazy Samsungs, they just like don't work

1725
01:33:45,485 --> 01:33:46,085
Speaker 3:  very well. Right.

1726
01:33:46,505 --> 01:33:49,045
Speaker 5:  It would be hysterical if it only works with the Vision Pro.

1727
01:33:49,465 --> 01:33:53,165
Speaker 3:  It would be perfectly un brand. Yeah. If you could get a giant curve culture

1728
01:33:53,195 --> 01:33:57,045
Speaker 3:  wide in the $35 headset, but that same resolution could not be

1729
01:33:57,045 --> 01:34:00,125
Speaker 3:  displayed in an actual monitor. Just beautiful. Yeah. Notice, we'll see.

1730
01:34:00,145 --> 01:34:02,805
Speaker 3:  But I, people did cheer for that. It is the thing they're using it for.

1731
01:34:04,105 --> 01:34:07,685
Speaker 3:  But yeah, I, I I think that just means they're adding more display resolutions

1732
01:34:07,685 --> 01:34:11,605
Speaker 3:  to the Mac. Which would be good. 'cause there's a class of honors that

1733
01:34:11,605 --> 01:34:13,125
Speaker 3:  you really can't use very well with Mac right now.

1734
01:34:13,515 --> 01:34:15,925
Speaker 4:  Yeah. Well and with that, that's the last we're gonna hear of the Vision

1735
01:34:15,945 --> 01:34:17,405
Speaker 4:  Pro for a pretty long time, I think.

1736
01:34:17,865 --> 01:34:21,285
Speaker 3:  But wait, can I, in my continuing quest to describe the, what is a photo

1737
01:34:21,285 --> 01:34:25,245
Speaker 3:  apocalypse? They added a feature right now you can shoot spatial audio

1738
01:34:25,415 --> 01:34:29,245
Speaker 3:  right now. You can shoot spatial video and photos with

1739
01:34:29,245 --> 01:34:32,925
Speaker 3:  your iPhone. I don't think you should do it. 'cause it actually really reduces

1740
01:34:32,925 --> 01:34:36,325
Speaker 3:  the quality of, especially in low light. So they and the

1741
01:34:36,325 --> 01:34:37,485
Speaker 4:  Files are monstrous.

1742
01:34:37,555 --> 01:34:41,525
Speaker 3:  Yeah. And you can only look at them in headset. Yeah. Just like not

1743
01:34:41,525 --> 01:34:45,085
Speaker 3:  worth it right now. But they are adding a feature where it can

1744
01:34:45,085 --> 01:34:48,885
Speaker 3:  spatialize your regular photos, which means it is

1745
01:34:49,205 --> 01:34:52,885
Speaker 3:  creating a bunch of synthetic data for your eyes to look at out of one photo.

1746
01:34:53,025 --> 01:34:56,045
Speaker 3:  Yep. So you've got a left eye vision and it's gonna make a right eye or you've

1747
01:34:56,045 --> 01:34:58,485
Speaker 3:  got a right eye or whatever, whatever it's doing. It's just gonna create

1748
01:34:58,565 --> 01:35:02,325
Speaker 3:  a little bit of a depth map and it's gonna just

1749
01:35:02,325 --> 01:35:06,085
Speaker 3:  synthesize some information that super wasn't there in the photo.

1750
01:35:06,675 --> 01:35:10,285
Speaker 3:  That doesn't upset me. Is this the greatest? What is a photo crime? No, it

1751
01:35:10,285 --> 01:35:13,245
Speaker 3:  is not. Is it super weird that we're all just

1752
01:35:13,865 --> 01:35:17,805
Speaker 3:  racing ahead long into the future of synthetic imagery and being

1753
01:35:17,805 --> 01:35:18,525
Speaker 3:  like, oh that's fun.

1754
01:35:18,675 --> 01:35:22,445
Speaker 5:  Yeah. But that's stuff they've been doing in like TVs for ages right?

1755
01:35:22,475 --> 01:35:25,605
Speaker 5:  When they do the auto upscaling and stuff. Isn't that the same thing where

1756
01:35:25,605 --> 01:35:28,005
Speaker 5:  they're just adding pixels where

1757
01:35:28,115 --> 01:35:31,565
Speaker 3:  Well no. So auto upscaling is, you know, you take like a a seven 20 image

1758
01:35:31,625 --> 01:35:35,165
Speaker 3:  and you just like make it bigger. Yeah. And, but I mean shows and you get

1759
01:35:35,165 --> 01:35:39,145
Speaker 3:  a bunch of AI stuff in there shows this is and like

1760
01:35:39,145 --> 01:35:41,625
Speaker 3:  that's still right. You're right that that's happening. But you're adding

1761
01:35:41,685 --> 01:35:45,425
Speaker 3:  pixels like in a 2D plane. Yeah, this is, they're gonna

1762
01:35:45,525 --> 01:35:49,505
Speaker 3:  add a 3D image. So you're gonna get another angle from like

1763
01:35:49,505 --> 01:35:52,145
Speaker 3:  if, assume the picture again as your left eye. You're gonna get another angle

1764
01:35:52,165 --> 01:35:55,425
Speaker 3:  on the same image and you're gonna see like a little bit of the side of someone's

1765
01:35:55,425 --> 01:35:55,585
Speaker 3:  head.

1766
01:35:56,575 --> 01:35:59,015
Speaker 5:  I cannot wait to look at a little bit of the side of Allison's head.

1767
01:35:59,615 --> 01:36:01,455
Speaker 3:  I but an AI Allison's head,

1768
01:36:02,145 --> 01:36:05,615
Speaker 5:  Right? Synthetic. Yeah. You're just gonna have like four ears. Yeah.

1769
01:36:06,225 --> 01:36:06,575
Speaker 5:  It'll

1770
01:36:06,575 --> 01:36:08,495
Speaker 3:  Be great. I'm just saying it's just like one of those things where you're

1771
01:36:08,495 --> 01:36:12,095
Speaker 3:  like, oh, huh, they're just doing that. They're gonna totally synthesize

1772
01:36:12,095 --> 01:36:14,815
Speaker 3:  another image for you to look at to create a 3D effect.

1773
01:36:16,005 --> 01:36:19,935
Speaker 3:  That image never existed. Nope. It, it, it did not happen. You did not

1774
01:36:19,935 --> 01:36:22,615
Speaker 3:  capture it. This computer's just gonna confidently tell you this is what

1775
01:36:22,615 --> 01:36:25,055
Speaker 3:  your other eye would've seen and you're gonna be like, huh. That's weird.

1776
01:36:25,565 --> 01:36:29,375
Speaker 3:  It's a weird thing that's happening. I will say I know people, Liam is always

1777
01:36:29,395 --> 01:36:33,015
Speaker 3:  on me for endlessly going on about what is a photo. I ruthlessly use the

1778
01:36:33,015 --> 01:36:36,775
Speaker 3:  generative racer in my room the other day to take people outta the background

1779
01:36:36,775 --> 01:36:39,935
Speaker 3:  of a photo of my daughter. I'm as conflicted as you are. I am, but a man.

1780
01:36:40,005 --> 01:36:40,655
Speaker 3:  Okay. How

1781
01:36:40,655 --> 01:36:43,295
Speaker 4:  Did it make you feel? Huh? Do do you look at that photo differently now?

1782
01:36:43,295 --> 01:36:43,615
Speaker 4:  Awesome.

1783
01:36:44,095 --> 01:36:47,375
Speaker 3:  I do look at the photo differently 'cause I know what I did. But I don't

1784
01:36:47,375 --> 01:36:51,175
Speaker 3:  know that most people have a feeling of shame when they're done using Lightroom.

1785
01:36:51,865 --> 01:36:53,895
Speaker 4:  Generative shame is a whole thing we're not even

1786
01:36:53,895 --> 01:36:55,255
Speaker 3:  Ready for. They should mark it as shame.

1787
01:36:57,935 --> 01:37:00,495
Speaker 3:  We're about to, by the way, have a big story just weather about is working

1788
01:37:00,495 --> 01:37:03,855
Speaker 3:  on it. Regular photographers are now running into the reality that

1789
01:37:04,275 --> 01:37:08,255
Speaker 3:  any use of AI tools depends on watermark. Which then Instagram

1790
01:37:08,255 --> 01:37:11,735
Speaker 3:  will just like say made with AI and people have real feelings about that

1791
01:37:11,735 --> 01:37:11,975
Speaker 3:  label.

1792
01:37:13,525 --> 01:37:16,095
Speaker 3:  It's the vers for story that exists, but Justin working on it.

1793
01:37:16,165 --> 01:37:19,735
Speaker 4:  Yeah. Yeah. Alright, well that's all the platforms. There's a lot we didn't

1794
01:37:19,735 --> 01:37:22,695
Speaker 4:  get to. I suspect we will talk a lot more about this both like on Friday

1795
01:37:22,795 --> 01:37:25,455
Speaker 4:  and for the rest of our lives.

1796
01:37:26,675 --> 01:37:29,615
Speaker 4:  But it was a lot like it was a big, it was a lot. This was a big day. Yeah.

1797
01:37:29,835 --> 01:37:33,095
Speaker 4:  And I think in it was a funny one 'cause in another world

1798
01:37:34,165 --> 01:37:36,535
Speaker 4:  just that run of platforms would've been a two hour.

1799
01:37:36,595 --> 01:37:38,735
Speaker 3:  That's why at the end of it I was like, are they done? Yeah.

1800
01:37:39,035 --> 01:37:41,855
Speaker 4:  And as it was, they just blew through it. Like I think one of the things

1801
01:37:41,855 --> 01:37:44,015
Speaker 4:  we're gonna see over the next few days, because the developer Raiders are

1802
01:37:44,015 --> 01:37:47,895
Speaker 4:  out, we're gonna learn about so many things that didn't even come up or

1803
01:37:47,895 --> 01:37:50,655
Speaker 4:  get mentioned. They're not in blog posts, they weren't on the bentos. Like

1804
01:37:50,655 --> 01:37:52,775
Speaker 4:  there's a lot of stuff in these platforms. Talk bentos

1805
01:37:52,775 --> 01:37:54,335
Speaker 3:  Are getting surprisingly less

1806
01:37:54,335 --> 01:37:55,845
Speaker 4:  Dense. Yeah, they're very spar now.

1807
01:37:56,405 --> 01:37:59,125
Speaker 3:  I think Apple should repack those with information. They're

1808
01:38:00,005 --> 01:38:03,205
Speaker 4:  I think just like a plain text screen. Here's list.

1809
01:38:03,955 --> 01:38:07,445
Speaker 4:  Yeah. Yeah. Just full change log. That's, that's it. We should, we should

1810
01:38:07,445 --> 01:38:07,805
Speaker 4:  take a break.

1811
01:38:08,625 --> 01:38:10,285
Speaker 3:  You don't wanna talk about games some more? No,

1812
01:38:12,885 --> 01:38:16,565
Speaker 4:  I don't wanna play Assassin's Creed on any of my Apple devices. Please be

1813
01:38:16,565 --> 01:38:17,245
Speaker 4:  alone about it.

1814
01:38:19,065 --> 01:38:19,885
Speaker 3:  All right, we'll be right back.

1815
01:41:07,035 --> 01:41:07,525
Speaker 3:  Alright,

1816
01:42:06,365 --> 01:42:10,225
Speaker 5:  am have no artistic ability and the ability to make a horse with 12

1817
01:42:10,355 --> 01:42:12,785
Speaker 5:  butts just sounds weird. I wanna see what happens.

1818
01:42:13,055 --> 01:42:16,785
Speaker 4:  It's a really interesting, no artistic ability and terrible person. Yeah.

1819
01:42:16,905 --> 01:42:18,705
Speaker 4:  It's like a really fascinating combination.

1820
01:42:18,705 --> 01:42:21,425
Speaker 3:  Yeah, it's but somehow but also wildly creative. Yeah.

1821
01:42:23,415 --> 01:42:26,385
Speaker 3:  Yeah. Like if you were like, I have no artistic ability, I'm a bad person,

1822
01:42:26,525 --> 01:42:30,105
Speaker 3:  but I couldn't imagine a horse with 12. But like it's fine. Go about your

1823
01:42:30,395 --> 01:42:33,425
Speaker 3:  right crazy's like I got ideas. Yeah. I go, I wanna see,

1824
01:42:33,625 --> 01:42:37,385
Speaker 5:  I wanna see what happens. So I am, I am super excited

1825
01:42:37,385 --> 01:42:41,065
Speaker 5:  about that. We'll see how long I'm allowed to be excited about it before

1826
01:42:41,065 --> 01:42:42,185
Speaker 5:  Apple just shuts me off.

1827
01:42:42,365 --> 01:42:45,825
Speaker 3:  Who shut you down at the server level? Like we got the kill switch in iOS

1828
01:42:46,295 --> 01:42:46,585
Speaker 3:  Fire.

1829
01:42:47,415 --> 01:42:51,385
Speaker 5:  Soon as I log in they're like, Nope, that's not for you. Execute, but

1830
01:42:51,695 --> 01:42:55,625
Speaker 5:  it's gonna be sick. And then my other one I've talked about already is the,

1831
01:42:55,625 --> 01:42:56,745
Speaker 5:  the ugly dark mode apps.

1832
01:42:57,055 --> 01:42:58,025
Speaker 4:  Crayons. Oh my God.

1833
01:42:58,215 --> 01:42:59,225
Speaker 3:  It's bad. You've

1834
01:42:59,225 --> 01:43:02,785
Speaker 5:  Seen that. My Slack now. You know, I just, I want

1835
01:43:02,945 --> 01:43:06,545
Speaker 5:  everything. I want all of my devices when I turn them on for you to go.

1836
01:43:07,575 --> 01:43:10,905
Speaker 3:  Okay. Again, why don't you use Windows and Android? Which

1837
01:43:11,295 --> 01:43:14,825
Speaker 3:  from the like the base levels of the operating system, it's too easy, are

1838
01:43:14,985 --> 01:43:17,705
Speaker 3:  designed to be this ugly. It's too easy. Oh, I see. You're

1839
01:43:17,705 --> 01:43:19,425
Speaker 5:  Not a hacker if you're not hacking

1840
01:43:20,645 --> 01:43:24,385
Speaker 3:  By using the system level being controls added

1841
01:43:24,445 --> 01:43:25,465
Speaker 3:  to the operating system.

1842
01:43:25,965 --> 01:43:28,025
Speaker 5:  It feels like hacking when it's on iOS.

1843
01:43:29,535 --> 01:43:31,385
Speaker 3:  Alright, Kranz, everybody.

1844
01:43:33,075 --> 01:43:34,145
Speaker 3:  David, what are you?

1845
01:43:35,765 --> 01:43:39,065
Speaker 4:  My two I, I changed it because I wanna talk about two things You changed.

1846
01:43:39,775 --> 01:43:42,545
Speaker 4:  Yeah. But who can remember what my last one was? Now it's, it's been too

1847
01:43:42,545 --> 01:43:46,385
Speaker 4:  long. There were rules. This I changed show not

1848
01:43:46,385 --> 01:43:49,505
Speaker 4:  during the break, so it was fine. I changed it while you were talking about

1849
01:43:49,505 --> 01:43:52,805
Speaker 4:  something or other theme mode. Yeah, probably.

1850
01:43:53,315 --> 01:43:56,565
Speaker 4:  Yeah. You were like, oh, Assassin's Creed. And I just started typing, you

1851
01:43:56,565 --> 01:43:59,005
Speaker 3:  Know, I shot control in 2017. My first one,

1852
01:44:01,905 --> 01:44:05,365
Speaker 4:  My first one is weirdly just like a throw in at the end of

1853
01:44:05,825 --> 01:44:08,765
Speaker 4:  wwc, which I actually, that was very exciting. It's transcription and AI

1854
01:44:08,965 --> 01:44:10,325
Speaker 4:  summarization in the voice memos app

1855
01:44:10,385 --> 01:44:11,685
Speaker 3:  And also the phone app. And

1856
01:44:11,685 --> 01:44:15,445
Speaker 4:  Also the phone app. Yeah. So exciting. Which is like, this is the kind of

1857
01:44:15,445 --> 01:44:19,005
Speaker 4:  thing that like if you're a reporter is life changing and if you're a real

1858
01:44:19,005 --> 01:44:22,885
Speaker 4:  person is just like sort of whatever. But for me, like I spend a lot of time

1859
01:44:23,515 --> 01:44:27,205
Speaker 4:  talking into things and being talked at on those same things

1860
01:44:27,465 --> 01:44:31,085
Speaker 4:  and having a decent recorder is amazing. Like you use the pixel

1861
01:44:31,365 --> 01:44:34,125
Speaker 4:  recorder, Allison, I know I have a pixel because that is a magical little

1862
01:44:34,125 --> 01:44:37,285
Speaker 4:  piece of software Yeah. At all times. And this feels like it might do the

1863
01:44:37,285 --> 01:44:40,405
Speaker 4:  same thing. And I'm very excited about that fact. Yeah. So that's awesome.

1864
01:44:40,675 --> 01:44:44,405
Speaker 4:  Also, maybe the thing that AI is the most consistently good at is transcription

1865
01:44:44,425 --> 01:44:47,285
Speaker 4:  and summarization. So like sold. Love it. I'll take it.

1866
01:44:48,225 --> 01:44:52,125
Speaker 4:  The other one is all of the organization stuff in mail,

1867
01:44:52,495 --> 01:44:55,965
Speaker 4:  which I am more excited about as time goes on because

1868
01:44:56,865 --> 01:44:58,965
Speaker 4:  NE is making a face at me, which is fair.

1869
01:44:59,795 --> 01:45:03,085
Speaker 3:  He's just thinking mime screen is, I'm just, I'm like, this man has to run

1870
01:45:03,085 --> 01:45:05,165
Speaker 3:  installer and he has to pretend all software is

1871
01:45:05,365 --> 01:45:08,805
Speaker 4:  Interesting. So no, it's that all

1872
01:45:09,215 --> 01:45:13,125
Speaker 4:  email apps for iPhone are bad. Yeah. Which is just a

1873
01:45:13,275 --> 01:45:16,605
Speaker 4:  fact of the world solve problem on the Mac mime stream is excellent. Yeah.

1874
01:45:16,605 --> 01:45:20,445
Speaker 4:  Everybody should use Mime Stream. Love it to death. There are no

1875
01:45:20,445 --> 01:45:24,405
Speaker 4:  good email apps for The. iPhone. And before you hear this or see this

1876
01:45:24,405 --> 01:45:27,805
Speaker 4:  and send me one, don't. I've tried it. It sucks. They're all bad.

1877
01:45:29,305 --> 01:45:32,285
Speaker 4:  But this thing that Apple did, which is basically just launched Gmail. Yeah.

1878
01:45:32,435 --> 01:45:32,725
Speaker 4:  They

1879
01:45:32,725 --> 01:45:34,885
Speaker 3:  Were just like, they have an updates tab, like the whole thing. Yeah. Yeah.

1880
01:45:34,915 --> 01:45:38,845
Speaker 4:  They, they do the categorization. They're doing some AI summarization.

1881
01:45:38,985 --> 01:45:42,485
Speaker 4:  You can use the tools to rewrite your emails like we were talking about earlier.

1882
01:45:43,625 --> 01:45:47,325
Speaker 4:  I'm gonna go back to using Apple Mail again because it is like

1883
01:45:47,545 --> 01:45:50,365
Speaker 4:  useful. The problem with Apple Mail has always been that search sucks, which

1884
01:45:50,445 --> 01:45:54,205
Speaker 4:  I assume is still the case. And it doesn't have the

1885
01:45:54,205 --> 01:45:57,485
Speaker 4:  split inboxes in Gmail, which I've actually now come to rely on. They're

1886
01:45:57,485 --> 01:46:00,165
Speaker 4:  not very good, but they're better than just dumping everything into your

1887
01:46:00,165 --> 01:46:03,605
Speaker 4:  one inbox. And at least when I go to promotions, it's like mostly

1888
01:46:04,255 --> 01:46:07,325
Speaker 4:  stuff I don't want. And when I go to updates, it's like mostly newsletters

1889
01:46:07,325 --> 01:46:11,125
Speaker 4:  and receipts. Again, not perfect, but pretty good. And if Apple can do that

1890
01:46:11,125 --> 01:46:14,485
Speaker 4:  stuff, even that well, it immediately becomes the best email app on The.

1891
01:46:14,485 --> 01:46:17,925
Speaker 4:  iPhone like by a mile. And so I'm cautiously

1892
01:46:17,975 --> 01:46:21,005
Speaker 4:  optimistic. I just, the Gmail app is so bad. I

1893
01:46:21,005 --> 01:46:23,885
Speaker 3:  Want to believe for you, it's so bad. It's not good. Yeah. That's why you

1894
01:46:23,885 --> 01:46:24,565
Speaker 3:  gotta use Outlook.

1895
01:46:25,225 --> 01:46:25,445
Speaker 4:  No,

1896
01:46:27,215 --> 01:46:28,125
Speaker 4:  sucks about Outlook.

1897
01:46:28,575 --> 01:46:28,925
Speaker 3:  Every

1898
01:46:29,145 --> 01:46:33,085
Speaker 4:  Is, well, A, everything B it's very slow. But C, when you open an email,

1899
01:46:33,465 --> 01:46:36,805
Speaker 4:  the archive button, which is the only button that matters on an email app,

1900
01:46:36,805 --> 01:46:39,965
Speaker 4:  is all the way at the top right of the screen where it's completely unreachable

1901
01:46:39,965 --> 01:46:42,885
Speaker 4:  no matter how hold you hold your phone. Ridiculous. You

1902
01:46:42,885 --> 01:46:43,565
Speaker 3:  Archive them.

1903
01:46:44,805 --> 01:46:48,665
Speaker 4:  Do you just leave them? Oh, you're, oh crap. Oh no, I'm discovering

1904
01:46:48,785 --> 01:46:49,925
Speaker 4:  I hate you in this episode.

1905
01:46:50,305 --> 01:46:50,765
Speaker 3:  Oh no,

1906
01:46:51,135 --> 01:46:53,725
Speaker 8:  Don't, don't worry about my little numbers. You don't. Don't worry about

1907
01:46:53,725 --> 01:46:56,045
Speaker 8:  it. Thousand don't you? It's fine.

1908
01:46:56,225 --> 01:46:59,205
Speaker 4:  You just, you read it then mark it, it unread for the chaos and then go about

1909
01:46:59,205 --> 01:46:59,965
Speaker 4:  your business, don't you?

1910
01:46:59,965 --> 01:47:02,445
Speaker 5:  Yeah. Like sometimes I'll be like, oh, that's spam. I'll leave it unread.

1911
01:47:02,505 --> 01:47:03,405
Speaker 5:  So I for one day,

1912
01:47:04,625 --> 01:47:04,845
Speaker 4:  No

1913
01:47:05,985 --> 01:47:09,405
Speaker 3:  One, oh, that hurt my soul. Soul. That's way to do it. Say second. The Gmail

1914
01:47:09,545 --> 01:47:13,325
Speaker 3:  app has actually solved this by way of a, a, a bug that is still not fixed.

1915
01:47:13,695 --> 01:47:17,605
Speaker 3:  Which is sometimes when you open an email from the notification on the

1916
01:47:17,605 --> 01:47:20,005
Speaker 3:  Gmail app for iOS, it just deletes the email.

1917
01:47:21,795 --> 01:47:22,085
Speaker 5:  I've

1918
01:47:22,085 --> 01:47:22,885
Speaker 4:  Noticed that. And it's

1919
01:47:22,885 --> 01:47:26,725
Speaker 3:  Just like, how do you get here? How did, how

1920
01:47:26,725 --> 01:47:30,525
Speaker 3:  did you arrive at the state? Google, I mean all that ai. Like I

1921
01:47:30,525 --> 01:47:33,965
Speaker 3:  bet what you wanted to do was immediately delete this email that you actually

1922
01:47:33,965 --> 01:47:37,925
Speaker 3:  chose to take an action on. Then action was delete. And that's

1923
01:47:37,925 --> 01:47:40,285
Speaker 3:  how I hit inbox zero. Congratulations.

1924
01:47:40,285 --> 01:47:40,685
Speaker 8:  That's

1925
01:47:40,685 --> 01:47:43,365
Speaker 4:  Really exciting. Yeah. Reading it is not important to get into inbox Zero.

1926
01:47:43,505 --> 01:47:43,805
Speaker 4:  No longer

1927
01:47:43,895 --> 01:47:47,205
Speaker 3:  Steps the robots summarize the email. Yeah. I can't believe you picked fucking

1928
01:47:47,205 --> 01:47:47,685
Speaker 3:  mail out.

1929
01:47:47,965 --> 01:47:51,925
Speaker 4:  I honestly, the more I think about it, the more excited I, but also

1930
01:47:51,925 --> 01:47:55,445
Speaker 4:  the thing where you can now group by sender. So I'm like the one time you

1931
01:47:55,445 --> 01:47:58,205
Speaker 4:  go to a restaurant and then they send you an email every day for the rest

1932
01:47:58,205 --> 01:48:02,005
Speaker 4:  of your life. Going and clicking the unsubscribe button. Too much work Doing

1933
01:48:02,005 --> 01:48:05,205
Speaker 4:  it in Gmail. Yeah. Doesn't work. That's just a lie that they tell you.

1934
01:48:06,025 --> 01:48:09,365
Speaker 4:  But now you can group them and just delete them all at once. Yeah. I I like

1935
01:48:09,365 --> 01:48:09,525
Speaker 4:  that.

1936
01:48:09,865 --> 01:48:13,285
Speaker 3:  I'm excited. I'm excited for their, the same AI idea everyone else has, which

1937
01:48:13,285 --> 01:48:16,725
Speaker 3:  is like, you're planning a trip and all the emails from your trip are gonna

1938
01:48:16,725 --> 01:48:20,485
Speaker 3:  be a little diagnosed of trip emails. Love it. Great. I'm super excited

1939
01:48:20,585 --> 01:48:22,325
Speaker 3:  for you in Mail Act. Thank you.

1940
01:48:22,715 --> 01:48:26,365
Speaker 4:  It's gonna be an awesome like six days. Yeah. And then somebody will

1941
01:48:26,385 --> 01:48:30,205
Speaker 4:  update their app again and I'll be like, maybe they fixed it and they

1942
01:48:30,205 --> 01:48:31,925
Speaker 4:  didn't. Yeah. But I'll try it again. You've

1943
01:48:31,925 --> 01:48:34,045
Speaker 3:  Got a problem and it's fine because it keeps you writing in

1944
01:48:34,045 --> 01:48:35,165
Speaker 4:  Star. I do it for work now Alison.

1945
01:48:35,955 --> 01:48:39,645
Speaker 3:  What it some saying? Yeah. All right. What are yours,

1946
01:48:39,805 --> 01:48:39,965
Speaker 3:  Allison?

1947
01:48:41,035 --> 01:48:44,445
Speaker 8:  Mine messaging related. Ooh, I am,

1948
01:48:44,555 --> 01:48:48,445
Speaker 8:  because I test a lot of Android phones. I'm usually the person on Android

1949
01:48:49,105 --> 01:48:51,285
Speaker 8:  in the group chat. So

1950
01:48:51,285 --> 01:48:54,605
Speaker 4:  Do you turn iMessage on when you test an iPhone and then off when you stop?

1951
01:48:54,635 --> 01:48:57,245
Speaker 4:  Yeah. Does it ruin your life every time you do that?

1952
01:48:57,435 --> 01:49:00,885
Speaker 8:  Kind of like possibly. I have missed out on

1953
01:49:00,915 --> 01:49:04,885
Speaker 8:  friendships, you know, things happening. I

1954
01:49:04,885 --> 01:49:05,725
Speaker 8:  don't know. When

1955
01:49:05,725 --> 01:49:09,605
Speaker 4:  You deen enroll from, from iMessage, you miss messages. Like for days. Yeah.

1956
01:49:09,605 --> 01:49:09,805
Speaker 8:  Yeah.

1957
01:49:10,275 --> 01:49:10,805
Speaker 4:  It's insane.

1958
01:49:11,325 --> 01:49:12,925
Speaker 8:  I think there's people I just don't talk to anymore

1959
01:49:14,195 --> 01:49:14,685
Speaker 5:  Because

1960
01:49:14,685 --> 01:49:18,565
Speaker 8:  They probably try to Yeah. Message me. No, I do this, I do it with

1961
01:49:18,725 --> 01:49:22,685
Speaker 8:  RCS. So like, yeah. RCS and iMessage is

1962
01:49:22,685 --> 01:49:25,525
Speaker 8:  gonna Yeah. Fix everything for me. I feel really good

1963
01:49:25,525 --> 01:49:28,365
Speaker 3:  About my, oh man, that's even more optimistic than David picking nail out.

1964
01:49:29,845 --> 01:49:30,285
Speaker 8:  I love this.

1965
01:49:30,435 --> 01:49:33,325
Speaker 4:  Well, you can send high resolution it's photos. Now is

1966
01:49:33,325 --> 01:49:37,285
Speaker 8:  The photos. 'cause like right now when in the group chat we're

1967
01:49:37,285 --> 01:49:41,165
Speaker 8:  sharing photos of our kids doing cute things and I have to be

1968
01:49:41,165 --> 01:49:45,005
Speaker 8:  like, I'm sorry, I'm screwing up the, the

1969
01:49:45,275 --> 01:49:49,045
Speaker 8:  high, you know, the quality of the images here. Can you just send them to

1970
01:49:49,045 --> 01:49:52,445
Speaker 8:  my husband or can we put 'em in a Google? There's so many Google photos

1971
01:49:52,825 --> 01:49:53,725
Speaker 8:  albums. It's

1972
01:49:53,725 --> 01:49:55,125
Speaker 3:  Like, oh God. Yeah. How are you

1973
01:49:55,125 --> 01:49:56,685
Speaker 8:  On any group chats in

1974
01:49:56,685 --> 01:49:58,165
Speaker 4:  Text? It's so I

1975
01:49:58,305 --> 01:49:58,725
Speaker 8:  Really,

1976
01:49:58,765 --> 01:50:01,485
Speaker 4:  I love the idea of everybody sending photos back and forth and then you just

1977
01:50:01,485 --> 01:50:03,125
Speaker 4:  sending Google photos, links, it's

1978
01:50:03,385 --> 01:50:07,005
Speaker 8:  Oh my God. Yeah. Check out my cool photos. And

1979
01:50:07,425 --> 01:50:11,165
Speaker 8:  you have really good friends. I know. They are so patient with me.

1980
01:50:11,165 --> 01:50:14,765
Speaker 8:  Those are some like rock solid. But you know what, there was one Android

1981
01:50:15,305 --> 01:50:19,285
Speaker 8:  guy and he just switched to iPhone too. I was like, that's tough. Now it's

1982
01:50:19,285 --> 01:50:23,165
Speaker 8:  just me. Yeah. So that's it. RCS is gonna fix everything for me.

1983
01:50:23,405 --> 01:50:24,205
Speaker 8:  I feel good about it.

1984
01:50:24,355 --> 01:50:25,085
Speaker 4:  That is a good one.

1985
01:50:25,155 --> 01:50:28,165
Speaker 8:  Yeah. And scheduling messages.

1986
01:50:28,385 --> 01:50:29,365
Speaker 3:  Yes. That's a clut one.

1987
01:50:29,845 --> 01:50:30,845
Speaker 8:  I message only.

1988
01:50:31,505 --> 01:50:34,365
Speaker 3:  I'm gonna schedule so many messages for like seven minutes from now,

1989
01:50:36,035 --> 01:50:39,965
Speaker 3:  just so it's not like immediately thirsty, but like within 10 is too much.

1990
01:50:40,555 --> 01:50:43,365
Speaker 3:  Yeah. Right. Yeah. Send seven minutes from That's

1991
01:50:43,365 --> 01:50:46,765
Speaker 8:  So that true. It fixes the like, oh, you just texted me and I'm gonna text

1992
01:50:46,765 --> 01:50:50,045
Speaker 8:  you right back. But that like, seems weird. Yep. And then I'm gonna forget

1993
01:50:50,045 --> 01:50:51,445
Speaker 8:  about it and then never text you back.

1994
01:50:51,465 --> 01:50:53,645
Speaker 3:  Yep. Those are the only two options that exist. Yes. Right.

1995
01:50:53,675 --> 01:50:57,485
Speaker 4:  Yeah. I'm honestly, I'm so glad you both just said that because this is my

1996
01:50:57,485 --> 01:51:01,245
Speaker 4:  main problem as a person because I'll read your message and if I

1997
01:51:01,245 --> 01:51:05,165
Speaker 4:  respond, if I am in the right head space to respond to it, I'm very responsive,

1998
01:51:05,185 --> 01:51:09,125
Speaker 4:  I'm ready. But if I do the thing where I put my phone down, we're done.

1999
01:51:09,155 --> 01:51:12,805
Speaker 4:  It's, I'm gone. Never, ever getting back to it. And I will just feel an increasing

2000
01:51:12,815 --> 01:51:16,125
Speaker 4:  sense of guilt. Like I could name you right now, off the top of my head,

2001
01:51:16,125 --> 01:51:20,005
Speaker 4:  15 people I owe text messages to who are never getting text messages from.

2002
01:51:20,345 --> 01:51:21,285
Speaker 4:  Do you, do you read

2003
01:51:21,285 --> 01:51:24,325
Speaker 3:  Them? Name them. Now I've, I've, this will be the greatest TikTok in

2004
01:51:24,795 --> 01:51:28,525
Speaker 3:  history. Name the 15 people you know that you are

2005
01:51:28,725 --> 01:51:30,565
Speaker 3:  supposed to text under no circumstances.

2006
01:51:31,265 --> 01:51:33,565
Speaker 4:  But all of them know who they are, which is the beauty of it.

2007
01:51:35,145 --> 01:51:36,285
Speaker 4:  And I'm just, it's seven

2008
01:51:36,285 --> 01:51:39,005
Speaker 3:  Minutes around. They should just add it as a default button. Send in seven

2009
01:51:39,005 --> 01:51:40,525
Speaker 3:  minutes. Yeah. Right. Yeah, yeah, yeah.

2010
01:51:40,915 --> 01:51:41,925
Speaker 4:  Tell send. But be cool.

2011
01:51:42,625 --> 01:51:43,285
Speaker 3:  Be cool about it.

2012
01:51:43,975 --> 01:51:44,765
Speaker 8:  Chill. Yeah.

2013
01:51:44,995 --> 01:51:45,605
Speaker 4:  Yeah. That's,

2014
01:51:45,605 --> 01:51:48,765
Speaker 3:  That's a really good one. This is like the swingers button. All right. It's,

2015
01:51:48,925 --> 01:51:50,325
Speaker 3:  I can't believe I picked this two. Hey.

2016
01:51:50,325 --> 01:51:52,205
Speaker 8:  Hey Neli. What, what are yours? What are

2017
01:51:52,205 --> 01:51:56,005
Speaker 3:  Your picks? I picked one that I, I I stand by, which is

2018
01:51:56,015 --> 01:51:59,725
Speaker 3:  phone mirror. Phone mirroring. Yep. Yes. And remote iOS

2019
01:51:59,725 --> 01:52:03,445
Speaker 3:  access for grandparent tech support. That's huge. Game changers.

2020
01:52:03,915 --> 01:52:06,445
Speaker 3:  Game changers all the way around. And that's it. Those are two.

2021
01:52:06,625 --> 01:52:08,325
Speaker 8:  Two. I picked it. Yeah. No, if you had one more. What was

2022
01:52:08,325 --> 01:52:11,725
Speaker 3:  It at the time? I did not know what we were picking.

2023
01:52:12,365 --> 01:52:16,245
Speaker 3:  I thought we were just picking some cool features. I did not know that

2024
01:52:16,285 --> 01:52:19,925
Speaker 3:  I would create false conflict with David in the iPad segment

2025
01:52:20,465 --> 01:52:22,325
Speaker 3:  and I picked the calculator app. Okay.

2026
01:52:22,705 --> 01:52:25,365
Speaker 4:  Eli, I would like you, I would like you to do the following. I would like

2027
01:52:25,365 --> 01:52:29,165
Speaker 4:  you to right now make the case that the calculator app is

2028
01:52:29,185 --> 01:52:32,725
Speaker 4:  the missing thing on the iPad. And the iPad is now perfect and complete.

2029
01:52:32,765 --> 01:52:34,285
Speaker 4:  I would like you to make that case right now.

2030
01:52:35,345 --> 01:52:39,165
Speaker 3:  The problem with the iPad for the past 13 years has been its

2031
01:52:39,165 --> 01:52:40,685
Speaker 3:  inability to do simple mathematics,

2032
01:52:42,485 --> 01:52:43,485
Speaker 3:  I think as we've all known.

2033
01:52:46,405 --> 01:52:47,665
Speaker 3:  And now you can,

2034
01:52:51,415 --> 01:52:55,265
Speaker 4:  That was it. I do wanna say quickly, just to pour one out

2035
01:52:55,285 --> 01:52:58,225
Speaker 4:  for the app called Solver. Yeah. Which is an awesome,

2036
01:52:59,055 --> 01:53:02,945
Speaker 4:  very cool, very clever app where you can just like type out the math

2037
01:53:02,945 --> 01:53:06,665
Speaker 4:  you're trying to do. You're just like, the bill is $65, there's four of us.

2038
01:53:06,725 --> 01:53:09,785
Speaker 4:  How much does everybody owe with a 20% tip? And it just answers your math

2039
01:53:09,985 --> 01:53:12,825
Speaker 4:  questions like that Apple just full Sherlock that app today.

2040
01:53:13,205 --> 01:53:17,185
Speaker 3:  No. 'cause you would have to get out your iPad and start writing with

2041
01:53:17,185 --> 01:53:20,865
Speaker 3:  a pencil at dinner. And I just don't, I don't think that's what's happening

2042
01:53:20,865 --> 01:53:21,105
Speaker 3:  here.

2043
01:53:22,445 --> 01:53:24,705
Speaker 4:  You're like, oh, do you wanna sign the check? And you're like, not yet. Hold

2044
01:53:24,705 --> 01:53:24,865
Speaker 4:  on.

2045
01:53:25,855 --> 01:53:26,985
Speaker 3:  I've got a draw dinner.

2046
01:53:29,005 --> 01:53:30,865
Speaker 3:  How much, how much of the apps did you have?

2047
01:53:33,145 --> 01:53:37,045
Speaker 3:  I agree that they took a lot of those ideas, but yeah, I don't, I think

2048
01:53:37,045 --> 01:53:39,565
Speaker 3:  solver's one. 'cause that's not kind of an app, right? Yeah, yeah.

2049
01:53:39,795 --> 01:53:40,845
Speaker 4:  It's very good on the iPad.

2050
01:53:41,115 --> 01:53:43,765
Speaker 3:  It's unbelievable. They're not adding any of these calculator features to

2051
01:53:43,765 --> 01:53:46,965
Speaker 3:  The iPhone. It's like The iPhone and the iPad will never have the same calculator

2052
01:53:46,965 --> 01:53:47,525
Speaker 3:  experience.

2053
01:53:47,785 --> 01:53:51,485
Speaker 4:  The the epiphany that I had during the live blog today was that everybody

2054
01:53:51,485 --> 01:53:55,445
Speaker 4:  desperately wants the iPad to become a Mac. And what it actually is,

2055
01:53:55,445 --> 01:53:57,045
Speaker 4:  is an iPhone with a stylist. Yes.

2056
01:53:59,025 --> 01:54:02,005
Speaker 4:  And to the extent that that changes what you can do on it, apple is like

2057
01:54:02,005 --> 01:54:05,365
Speaker 4:  pushing really hard on that idea that like, because there's a stylist, you

2058
01:54:05,365 --> 01:54:09,005
Speaker 4:  can do new things. That's, that's the whole bent of the iPad right now when

2059
01:54:09,005 --> 01:54:12,085
Speaker 8:  We get the folding fold. Yeah, exactly. It's gonna be sick when it folds.

2060
01:54:12,235 --> 01:54:16,085
Speaker 4:  Yeah. It may well be all over, but it is, is further and further away

2061
01:54:16,085 --> 01:54:17,285
Speaker 4:  from being a Mac all the time.

2062
01:54:17,505 --> 01:54:21,325
Speaker 8:  And then you can use your folding iPad on your

2063
01:54:21,765 --> 01:54:25,205
Speaker 8:  computer because it will do iPhone mirroring.

2064
01:54:25,545 --> 01:54:25,765
Speaker 8:  Oh.

2065
01:54:26,345 --> 01:54:29,565
Speaker 4:  And then you plug in your vision pro and you get a giant ass monitor. Yeah.

2066
01:54:29,925 --> 01:54:31,005
Speaker 4:  Bringing it all together. We fixed it.

2067
01:54:31,645 --> 01:54:35,445
Speaker 3:  I think I've never been more depressed about computers after that entire

2068
01:54:35,765 --> 01:54:37,165
Speaker 3:  sequence. What

2069
01:54:39,565 --> 01:54:43,485
Speaker 3:  I, I actually think we saw a lot from Apple today,

2070
01:54:43,485 --> 01:54:47,165
Speaker 3:  which indicates this company can actually like, have new ideas, which is

2071
01:54:47,165 --> 01:54:51,045
Speaker 3:  sort of not been the case for a minute. Right? Like they're like,

2072
01:54:51,045 --> 01:54:54,885
Speaker 3:  we had a themeing to iOS for Krantz. Great. Yeah. Thank you. Stuff that other

2073
01:54:55,125 --> 01:54:58,165
Speaker 3:  platforms had forever. Even at the, all these AI features are kind of the

2074
01:54:58,165 --> 01:55:01,885
Speaker 3:  same like as everybody else. They've integrated 'em into the operating system

2075
01:55:01,885 --> 01:55:04,845
Speaker 3:  in better ways. They have a better story to tell. Like here's why it's useful

2076
01:55:05,185 --> 01:55:08,965
Speaker 3:  as opposed to like, here's just the raw amount of compute that we can throw

2077
01:55:08,965 --> 01:55:12,805
Speaker 3:  at a problem. Which is basically how Google handles things. But

2078
01:55:12,885 --> 01:55:16,165
Speaker 3:  I come back to this thing about the iPad and it's like they still don't know

2079
01:55:16,165 --> 01:55:19,165
Speaker 3:  why they make this thing. They just don't know.

2080
01:55:19,235 --> 01:55:22,645
Speaker 4:  Yeah. It gets increasingly cool without ever getting

2081
01:55:23,115 --> 01:55:26,045
Speaker 4:  Yeah. More itself in any

2082
01:55:26,045 --> 01:55:28,685
Speaker 3:  Way. Yeah. I think they, they make it 'cause they sell 'em. Yeah. And that,

2083
01:55:28,685 --> 01:55:32,405
Speaker 3:  and that's kind of, and it's like they're, they need to kickstart that somehow

2084
01:55:33,105 --> 01:55:33,525
Speaker 8:  Or do

2085
01:56:13,175 --> 01:56:13,665
Speaker 4:  Today's

2086
01:56:42,305 --> 01:56:43,065
Speaker 4:  week. All

2087
01:56:43,065 --> 01:56:45,465
Speaker 3:  Right. That's it. Thank you for listening. Thank you Allison for joining

2088
01:56:45,465 --> 01:56:48,785
Speaker 3:  us. We'll be back on Friday with more of this,

2089
01:56:49,235 --> 01:56:52,865
Speaker 3:  which you love and all the platforms you love the most. Well that's it. That's

2090
01:56:52,865 --> 01:56:52,985
Speaker 3:  where

