1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: b4109e3b-4a29-4066-94c4-490e623a90e0
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/2443249629892064772/-6898166201993161420/s93290-US-6282s-1757901445.mp3
Description: One thing you should know about the iPhone launch is that there’s... not usually a lot of other tech news around the iPhone launch. So David and Jake start this episode with some more information about the iPhone launch, including some controversial details we missed about the AirPods Pro 3 and the argument in favor of the crossbody strap. After that, with David back on the mic, it’s time for a round of AI-focused hot takes with The Verge’s Hayden Field. The gang talks ChatGPT, Claude, money, more money, and what counts as a real friend. (And money.) Finally, in the lightning round — yes, once again the LIGHTNING ROUND — the three co-hosts talk about Canon’s confusing new camera, the future of Reddit, Claude’s spreadsheet-y future, and much more.




2
00:01:50,625 --> 00:01:54,345
Speaker 5:  with our lives. I'm your friend, David Pierce. Jake Kakis is here. Hi, Jake.

3
00:01:54,555 --> 00:01:55,665
Speaker 6:  Hello. Good to see you again.

4
00:01:55,855 --> 00:01:59,825
Speaker 5:  It's been a couple months. I, I feel weird being back. I have to be

5
00:01:59,825 --> 00:02:03,625
Speaker 5:  honest with you. This is, this is strange. I'm, I'm not like

6
00:02:03,625 --> 00:02:06,745
Speaker 5:  used to sitting here and looking into cameras anymore. I've forgotten how

7
00:02:06,905 --> 00:02:10,785
Speaker 5:  tiring it is to like sit on video meetings all day. We all just do

8
00:02:10,865 --> 00:02:11,825
Speaker 5:  this. It's, it's a lot.

9
00:02:12,205 --> 00:02:16,185
Speaker 6:  It isn't fun just staring at, at zoom all day long

10
00:02:16,845 --> 00:02:20,385
Speaker 6:  hoping that your meeting shows up on time and

11
00:02:20,775 --> 00:02:24,065
Speaker 6:  ends on time and somebody's taking notes. And the AI isn't saying the wrong

12
00:02:24,065 --> 00:02:24,265
Speaker 6:  thing.

13
00:02:24,705 --> 00:02:28,385
Speaker 5:  I think we've all like forgotten how weird it is to stare at our own

14
00:02:28,435 --> 00:02:32,305
Speaker 5:  faces as much as we stare at our own faces in the era of video chat. And

15
00:02:32,305 --> 00:02:36,185
Speaker 5:  when you don't do it for a long time, it is glorious.

16
00:02:36,685 --> 00:02:38,945
Speaker 5:  And then you start staring at your own face again and you're like, oh God,

17
00:02:38,945 --> 00:02:41,785
Speaker 5:  is that what I look like? Like it's not, it's not great. I don't recommend

18
00:02:41,785 --> 00:02:45,505
Speaker 5:  it. You have done a terrific job this summer. I just wanna say this now in

19
00:02:45,505 --> 00:02:49,385
Speaker 5:  front of God and everybody, you did a great job. It was very fun to listen

20
00:02:49,405 --> 00:02:53,385
Speaker 5:  to this show all summer and have absolutely no input over any of

21
00:02:53,385 --> 00:02:57,345
Speaker 5:  it. You did a really good job. So we have a lot to get to today. We're

22
00:02:57,345 --> 00:03:01,105
Speaker 5:  gonna do some gadget news up top here. We have a lightning round

23
00:03:01,205 --> 00:03:01,665
Speaker 5:  at the end,

24
00:03:03,565 --> 00:03:07,375
Speaker 5:  just yes, you heard it correctly. What? We'll come back to that, David.

25
00:03:07,665 --> 00:03:09,975
Speaker 5:  We're gonna have a lightning round in which we fight about the lightning

26
00:03:09,975 --> 00:03:11,775
Speaker 5:  round, and then we're gonna have a lightning round. And I'm very excited

27
00:03:11,775 --> 00:03:15,455
Speaker 5:  about it. And in the middle we have, we have a segment I'm calling

28
00:03:15,515 --> 00:03:18,575
Speaker 5:  Summer Takes, which is just, I have a lot of things I need to get off my

29
00:03:18,575 --> 00:03:20,855
Speaker 5:  chest And I need to know if I'm insane. So we're gonna talk about all of

30
00:03:20,855 --> 00:03:24,735
Speaker 5:  that. But first, it's still Apple Week. Like this is, this is

31
00:03:24,735 --> 00:03:27,735
Speaker 5:  the week where nobody else does anything because it's mostly Apple News.

32
00:03:28,755 --> 00:03:31,975
Speaker 5:  So let's cover off on some of the Apple stuff we didn't really touch on on

33
00:03:31,975 --> 00:03:34,055
Speaker 5:  Wednesday show. We talked about all the gadgets. If you haven't listened

34
00:03:34,055 --> 00:03:37,975
Speaker 5:  to Wednesday show, we, we talked about all the iPhones, the watches, the

35
00:03:38,005 --> 00:03:41,975
Speaker 5:  AirPods, the cross body straps, everything. We ran through all of that.

36
00:03:42,435 --> 00:03:46,375
Speaker 5:  Go listen to that episode. But there are a few details we should touch on

37
00:03:47,475 --> 00:03:51,305
Speaker 5:  before we get outta here. And the first one is the charging

38
00:03:51,315 --> 00:03:54,985
Speaker 5:  cable. This, this has been like a, a, a mild kerfuffle on the

39
00:03:55,345 --> 00:03:58,985
Speaker 5:  internet since it became revealed that the AirPods Pro three

40
00:03:59,485 --> 00:04:01,505
Speaker 5:  do not ship with a charging cable.

41
00:04:01,685 --> 00:04:03,185
Speaker 6:  Are people upset about this? People

42
00:04:03,185 --> 00:04:03,945
Speaker 5:  Are upset about this.

43
00:04:04,015 --> 00:04:07,865
Speaker 6:  Okay, so back a few years ago when this, when I think

44
00:04:07,865 --> 00:04:10,505
Speaker 6:  every company stopped, including the charging brick, I was like, this is

45
00:04:10,505 --> 00:04:14,425
Speaker 6:  cheap. You're all cheapen out on us. The cables

46
00:04:14,585 --> 00:04:18,505
Speaker 6:  I have so many cables are, so I had to get a

47
00:04:18,505 --> 00:04:22,385
Speaker 6:  new laptop at work recently 'cause my old one broke. And our IT

48
00:04:22,415 --> 00:04:25,425
Speaker 6:  team was like, here's the laptop and here's the charger and here's the cable.

49
00:04:25,485 --> 00:04:28,425
Speaker 6:  And I'm like, please keep this. And they're like, no, no, no. We insist it's

50
00:04:28,425 --> 00:04:32,385
Speaker 6:  great cable, it's a great charger. And I'm like, please do not burden me

51
00:04:32,385 --> 00:04:36,305
Speaker 6:  with this chart. I have so many, I have so many of

52
00:04:36,305 --> 00:04:37,225
Speaker 6:  them. The other thing,

53
00:04:38,825 --> 00:04:42,555
Speaker 6:  there's just, we all, we're all we're, we're full up. We're full up.

54
00:04:42,615 --> 00:04:44,395
Speaker 6:  We don't need this. Do you feel the same way?

55
00:04:44,875 --> 00:04:48,795
Speaker 5:  I do. So I'm, I'm torn. I think the, I

56
00:04:49,115 --> 00:04:52,475
Speaker 5:  honestly, I, I swear to God, if you gave me five minutes, I could find you

57
00:04:52,555 --> 00:04:56,355
Speaker 5:  a hundred USBC cables in, in like within arm's reach of me. I'm not

58
00:04:56,385 --> 00:04:57,115
Speaker 5:  like, like

59
00:04:58,625 --> 00:05:00,515
Speaker 5:  that just right there. I just, that's, I

60
00:05:00,515 --> 00:05:03,475
Speaker 6:  Can confirm that's my arms. David is holding like 19 cables.

61
00:05:03,475 --> 00:05:06,795
Speaker 5:  Like it's, that was one reach into one drawer like this. Most people are

62
00:05:06,795 --> 00:05:10,755
Speaker 5:  not like us, right? Like this is not a normal situation

63
00:05:11,175 --> 00:05:14,955
Speaker 5:  for humanity. And I think there is something to,

64
00:05:15,705 --> 00:05:19,355
Speaker 5:  like, you should have a charging cable with your phone, right? Like that

65
00:05:19,355 --> 00:05:22,755
Speaker 5:  is, that is the device that I think if you own nothing else, you probably

66
00:05:22,755 --> 00:05:26,075
Speaker 5:  own that. And if you own nothing else, that's the one that should come with

67
00:05:26,195 --> 00:05:29,435
Speaker 5:  a charger. So I think I, I'm actually, I have more feelings about it on that

68
00:05:29,435 --> 00:05:32,275
Speaker 5:  one. If you're paying $250 for a pair of AirPods pros,

69
00:05:33,655 --> 00:05:37,035
Speaker 5:  the, the overlap of the Venn diagram between those people and people who

70
00:05:37,035 --> 00:05:40,995
Speaker 5:  don't have USBC cables to spare is non-existent. So like, this to me is

71
00:05:40,995 --> 00:05:44,675
Speaker 5:  such a non-issue. Except if you're like a person who cares about the

72
00:05:44,675 --> 00:05:46,515
Speaker 5:  principle of I should have charging cables. I

73
00:05:46,515 --> 00:05:49,635
Speaker 6:  Also distinctly think of wireless

74
00:05:50,145 --> 00:05:53,895
Speaker 6:  earbuds as devices that should be wirelessly charged.

75
00:05:54,455 --> 00:05:58,265
Speaker 6:  I have never plugged any of my pairs of wireless

76
00:05:58,415 --> 00:06:02,345
Speaker 6:  earbuds into a charging cable. Now, that's particularly true for the AirPods

77
00:06:02,345 --> 00:06:06,145
Speaker 6:  that I have. 'cause I have the lightning port AirPods, and I'm not

78
00:06:06,145 --> 00:06:09,905
Speaker 6:  messing with that. I, somebody recently asked me for an

79
00:06:09,905 --> 00:06:13,825
Speaker 6:  iPhone charger. I'm like, which one you mean man in the middle

80
00:06:13,825 --> 00:06:17,385
Speaker 6:  lightning cord? Ugh, I, I had to tear my house apart.

81
00:06:17,705 --> 00:06:21,265
Speaker 6:  'cause I've done everything I can to rid myself of lightning cables. And

82
00:06:21,265 --> 00:06:25,185
Speaker 6:  it's like, I've got a, a nest of them somewhere. But it's like in some

83
00:06:25,445 --> 00:06:29,105
Speaker 6:  old cabinet, the, the, the AirPods,

84
00:06:29,155 --> 00:06:32,465
Speaker 6:  these new ones, they ha they have wireless charging. You don't need it. It's

85
00:06:32,495 --> 00:06:35,785
Speaker 6:  fine. That's not the device I'm, I'm plugging in all the time.

86
00:06:36,365 --> 00:06:39,545
Speaker 6:  And surely if you're gonna charge them, just use the same cord you're using

87
00:06:39,545 --> 00:06:41,825
Speaker 6:  for your, for your, for your iPhone, it's fine. Yeah. You're gonna

88
00:06:41,825 --> 00:06:44,625
Speaker 5:  Be all right. On this note, can I tell you about a gadget upgrade I made

89
00:06:44,625 --> 00:06:47,945
Speaker 5:  this summer that I so incredibly highly recommend to everybody? Oh yeah.

90
00:06:48,205 --> 00:06:52,105
Speaker 5:  So every company now that makes accessories, makes a version of this. But

91
00:06:52,265 --> 00:06:54,665
Speaker 5:  it's basically the like all in one

92
00:06:56,465 --> 00:06:59,305
Speaker 5:  wireless charger, right? So like, mine is maybe this company called 12 South.

93
00:06:59,325 --> 00:07:03,305
Speaker 5:  And basically it's, it's, it's a little stand and on the sort

94
00:07:03,305 --> 00:07:07,185
Speaker 5:  of sloping front, it's a mag safe charger for a phone, usually an

95
00:07:07,185 --> 00:07:10,385
Speaker 5:  iPhone. But also the, the Pixel 10, which I have upstairs also fits on it.

96
00:07:10,385 --> 00:07:13,905
Speaker 5:  There's a little thing on the back where you put the Apple watch and there's

97
00:07:13,905 --> 00:07:16,825
Speaker 5:  a little pad down on the bottom where you can charge AirPods.

98
00:07:18,305 --> 00:07:21,905
Speaker 5:  I bought one of those And I used to have it here sitting at my desk. But

99
00:07:21,905 --> 00:07:25,865
Speaker 5:  where I actually put it this summer was next to the place.

100
00:07:25,865 --> 00:07:28,385
Speaker 5:  Everybody has the place. They put their things when they walk inside, right?

101
00:07:28,385 --> 00:07:31,625
Speaker 5:  Like it's where you put your keys or whatever. I put it there

102
00:07:32,485 --> 00:07:36,225
Speaker 5:  and it has been incredible. That is now just like, it's the place

103
00:07:36,325 --> 00:07:39,905
Speaker 5:  my devices live. And especially to your point about the AirPods, I now

104
00:07:40,195 --> 00:07:43,585
Speaker 5:  never, ever think about charging my AirPods because when I come inside,

105
00:07:43,965 --> 00:07:45,545
Speaker 5:  that's just where I put them down. Oh,

106
00:07:45,545 --> 00:07:45,905
Speaker 6:  That's pretty good.

107
00:07:46,045 --> 00:07:49,065
Speaker 5:  Is on the wire. I cannot recommend this enough. It's been the best. Okay.

108
00:07:49,225 --> 00:07:52,305
Speaker 6:  I, I see photos of these things all the time. They look amazing online, but

109
00:07:52,305 --> 00:07:55,985
Speaker 6:  I've always thought that in practice they're like the equivalent of putting

110
00:07:56,205 --> 00:08:00,185
Speaker 6:  all of your spices into the same jar. Or like, and I'm like it,

111
00:08:00,185 --> 00:08:03,585
Speaker 6:  like it looks very pretty on the internet. Does this really make sense? Is

112
00:08:03,585 --> 00:08:07,185
Speaker 6:  it really gonna make my life better? Am I really use this thing is

113
00:08:07,415 --> 00:08:11,305
Speaker 5:  Very slow when I'm trying to charge all of them simultaneously. Mm. But again,

114
00:08:11,305 --> 00:08:14,825
Speaker 5:  this is like not a, oh no, I need to charge my AirPods thing. It's a I am

115
00:08:14,825 --> 00:08:17,665
Speaker 5:  home. Where do my AirPods go? Yes. I just stick it on the thing. Yeah, I

116
00:08:17,665 --> 00:08:21,545
Speaker 5:  charge my phone there less because I usually just like have my phone in my

117
00:08:21,545 --> 00:08:24,425
Speaker 5:  pocket all day. But where, and it's like you come home and you like empty

118
00:08:24,425 --> 00:08:28,025
Speaker 5:  the bag or empty your pockets having a charger

119
00:08:28,245 --> 00:08:29,545
Speaker 5:  be a couple of those spots.

120
00:08:30,385 --> 00:08:33,665
Speaker 6:  Fabulous. Yeah, I mean at, at, at home I just have a wireless charger on,

121
00:08:33,725 --> 00:08:37,205
Speaker 6:  on my work desk. My AirPods just live there. Like,

122
00:08:38,065 --> 00:08:41,485
Speaker 6:  yes. Does that probably hurt their battery over time? Doesn't matter. They

123
00:08:41,485 --> 00:08:43,525
Speaker 6:  live on the charger. They're gonna have power.

124
00:08:44,155 --> 00:08:47,485
Speaker 5:  This might be a messed up place to have landed, but I have, I have fully

125
00:08:47,485 --> 00:08:51,365
Speaker 5:  landed on, I am going to lose or destroy these things long before their parts

126
00:08:51,365 --> 00:08:54,885
Speaker 5:  start to fall apart. Oh. So I'm just, yeah. I'm so brutal

127
00:08:55,425 --> 00:08:56,485
Speaker 5:  on AirPods for

128
00:08:56,485 --> 00:08:58,445
Speaker 6:  That. It's going down a sewer great one day. Yeah.

129
00:08:58,475 --> 00:09:01,965
Speaker 5:  Like it's a, it's a, I've had these, I still have the, the last regular

130
00:09:01,965 --> 00:09:05,085
Speaker 5:  lightning AirPods that they made. And it is a full miracle that I still have

131
00:09:05,085 --> 00:09:08,975
Speaker 5:  these anyway, charging cables.

132
00:09:08,975 --> 00:09:12,775
Speaker 5:  If you need one, just call me. I have thousands of them. It'll be fine. The

133
00:09:12,775 --> 00:09:16,495
Speaker 5:  next Apple thing mostly. I just wanna shout out a piece that Jess

134
00:09:16,495 --> 00:09:20,375
Speaker 5:  weathered wrote for us about the cross body strap. You And I talked

135
00:09:20,375 --> 00:09:23,855
Speaker 5:  about this on Wednesday's show, and we got a couple of emails from people

136
00:09:23,875 --> 00:09:26,815
Speaker 5:  who were like, you know that thing Jake said about 30 something men being

137
00:09:26,815 --> 00:09:29,095
Speaker 5:  the wrong people to talk about this? You are exactly correct. You guys are

138
00:09:29,095 --> 00:09:32,975
Speaker 5:  idiots. Shut up. I'm paraphrasing. But that was more or less the

139
00:09:32,975 --> 00:09:36,375
Speaker 5:  vibe. And that's also more or less the vibe of Jess's piece, which makes

140
00:09:36,415 --> 00:09:40,335
Speaker 5:  a series of very good points about how people, particularly women's

141
00:09:40,335 --> 00:09:44,255
Speaker 5:  clothes that don't typically have pockets or people in other countries, these

142
00:09:44,255 --> 00:09:47,335
Speaker 5:  are already a thing. And that actually what Apple is doing here is leaning

143
00:09:47,335 --> 00:09:51,175
Speaker 5:  into a very useful trend. I still would argue that just having

144
00:09:51,175 --> 00:09:53,935
Speaker 5:  your phone sort of banging around on your hip is a weird choice.

145
00:09:54,965 --> 00:09:58,575
Speaker 6:  It's funny because, you know, when I take my camera out,

146
00:09:59,445 --> 00:10:03,295
Speaker 6:  it's on a strap, it's around my body, right? It's just banging

147
00:10:03,295 --> 00:10:06,815
Speaker 6:  around. There's a very functional purpose for that, right? It, it's, I don't

148
00:10:06,815 --> 00:10:09,775
Speaker 6:  need it all the time. I wanna be able to quickly pull it up. You can, you

149
00:10:09,775 --> 00:10:13,495
Speaker 6:  can make that argument about a phone, I guess, which you also do use for

150
00:10:13,835 --> 00:10:17,775
Speaker 6:  photos. Maybe the thing that feels off about it to me

151
00:10:18,435 --> 00:10:22,335
Speaker 6:  is, you know, a camera, it sort of has like a, a very specific

152
00:10:22,335 --> 00:10:25,815
Speaker 6:  purpose, right? It's either off or I'm taking a photo. If I'm taking a photo,

153
00:10:25,955 --> 00:10:29,935
Speaker 6:  I'm, I'm doing some sort of socially constructed,

154
00:10:31,375 --> 00:10:35,195
Speaker 6:  you know, action, right? Hmm. People know I'm taking the photo, I'm taking

155
00:10:35,315 --> 00:10:39,105
Speaker 6:  a photo of an object. There's a limited period of time with the phone.

156
00:10:39,265 --> 00:10:42,305
Speaker 6:  I think having it banging around all the time sort of indicates like, Hey

157
00:10:42,305 --> 00:10:45,905
Speaker 6:  man, I could whip this out at any second. I'm gonna be on this thing a lot.

158
00:10:46,705 --> 00:10:50,385
Speaker 6:  Might be watching TikTok videos. I'm gonna be in line. I'm gonna be talking

159
00:10:50,385 --> 00:10:54,225
Speaker 6:  to you. And it might, right? And I think, you know, the

160
00:10:54,225 --> 00:10:57,745
Speaker 6:  norms are a little different there for some

161
00:10:58,115 --> 00:10:58,945
Speaker 6:  folks than others.

162
00:11:00,745 --> 00:11:04,665
Speaker 6:  I, I think, like for me, you know, I want to have

163
00:11:04,725 --> 00:11:08,545
Speaker 6:  my phone away and out of sight. If somebody else's phone was like right

164
00:11:08,605 --> 00:11:12,225
Speaker 6:  beside them, buzzing up, lighting up all the time, I, I think that would,

165
00:11:12,235 --> 00:11:16,185
Speaker 6:  would feel a little weird in conversation with me. But

166
00:11:16,185 --> 00:11:20,065
Speaker 6:  I see it, right? Phones are a little big. People like them to be

167
00:11:20,105 --> 00:11:22,965
Speaker 6:  a little too big. That's convenient. Yeah.

168
00:11:23,185 --> 00:11:26,925
Speaker 5:  And I think I, I sort of love this because, and, and Jess's piece is very

169
00:11:26,925 --> 00:11:29,965
Speaker 5:  good molding to it in the show notes, but she, she argues that

170
00:11:30,675 --> 00:11:34,565
Speaker 5:  this is sort of a perfectly appley product in that like, if this is

171
00:11:34,625 --> 00:11:38,285
Speaker 5:  for you, apple really thought it all the way through, right? It has, it has

172
00:11:38,355 --> 00:11:41,845
Speaker 5:  magnets for easy attaching, you can, you can color coordinate it to your

173
00:11:41,845 --> 00:11:45,325
Speaker 5:  clothes because it's easy to take the, the lanyard on and off. You can

174
00:11:46,155 --> 00:11:49,965
Speaker 5:  just quickly adjust the size of the strap so that you can use it more

175
00:11:49,965 --> 00:11:53,765
Speaker 5:  easily and ha attach it to things like, if you're gonna

176
00:11:53,875 --> 00:11:57,805
Speaker 5:  make a cross body strap, this is the way to do it. And I just think,

177
00:11:58,025 --> 00:12:01,845
Speaker 5:  to me, the whole existence of this is a trend. It, it gets at

178
00:12:01,845 --> 00:12:05,525
Speaker 5:  exactly what you're talking about. Where it's like, this is a tool you

179
00:12:05,745 --> 00:12:09,005
Speaker 5:  use to do stuff all the time. And I think especially in places like

180
00:12:09,665 --> 00:12:13,605
Speaker 5:  Europe and Asia where things like transit tickets are like

181
00:12:14,305 --> 00:12:18,205
Speaker 5:  all done on mobile and, and the sort of NFC culture is just

182
00:12:18,445 --> 00:12:20,925
Speaker 5:  absolutely everywhere. This idea of like having a thing that I can just reach

183
00:12:20,925 --> 00:12:23,685
Speaker 5:  out and tap all the time instead of actually, even for me having to dig it

184
00:12:23,685 --> 00:12:27,365
Speaker 5:  outta my pocket over and over makes a lot of sense. And it's just like, I

185
00:12:27,365 --> 00:12:31,245
Speaker 5:  just so don't use my phone this way. Right. Where it is like constantly sort

186
00:12:31,245 --> 00:12:34,005
Speaker 5:  of up and down. I'm actually trying to do that less with my phone. Yes, yes.

187
00:12:34,005 --> 00:12:37,685
Speaker 5:  And I want my phone to be less near me. But it,

188
00:12:37,715 --> 00:12:40,885
Speaker 5:  it's just an interesting way to like think about your phone in the world.

189
00:12:41,185 --> 00:12:45,045
Speaker 5:  So I am suitably wrong and as penance, I will wear one of these around

190
00:12:45,065 --> 00:12:48,365
Speaker 5:  for a week And I will tell everybody about it. And I'm very much looking

191
00:12:48,365 --> 00:12:48,805
Speaker 5:  forward to that.

192
00:12:48,805 --> 00:12:49,765
Speaker 6:  What color are you gonna choose?

193
00:12:50,565 --> 00:12:52,045
Speaker 5:  I, I don't know. That's,

194
00:12:52,185 --> 00:12:52,885
Speaker 6:  That's what matters

195
00:12:52,885 --> 00:12:56,765
Speaker 5:  Most. Every, every hour that goes by, I get a little closer to

196
00:12:57,965 --> 00:13:01,885
Speaker 5:  throwing away this blue iPhone 16 that I love dearly and absolutely do not

197
00:13:01,885 --> 00:13:05,165
Speaker 5:  need to upgrade. And just going full orange, just, just

198
00:13:05,625 --> 00:13:09,405
Speaker 5:  orange iPhone, orange case, orange, cross body strap.

199
00:13:09,555 --> 00:13:13,005
Speaker 5:  Just, just be that guy. I do. You can't do both at once. Lifestyle

200
00:13:13,845 --> 00:13:15,495
Speaker 6:  Blue on one side, orange on the other.

201
00:13:16,335 --> 00:13:16,775
Speaker 5:  I like that.

202
00:13:17,005 --> 00:13:18,775
Speaker 6:  Yeah. Now you're talking do Carey.

203
00:13:20,435 --> 00:13:23,235
Speaker 5:  So yeah, go read that piece. It's good stuff. Couple more little things.

204
00:13:23,845 --> 00:13:27,675
Speaker 5:  There was a really interesting paper slash

205
00:13:27,675 --> 00:13:30,515
Speaker 5:  press release that Apple put out around the iPhone 17 that we didn't really

206
00:13:30,515 --> 00:13:34,395
Speaker 5:  talk about, about a security upgrade that it comes with, which Apple calls

207
00:13:34,395 --> 00:13:38,275
Speaker 5:  memory integrity enforcement. And basically

208
00:13:38,275 --> 00:13:42,115
Speaker 5:  this is a very complicated system designed to stop one specific kind of

209
00:13:42,225 --> 00:13:46,075
Speaker 5:  intrusion on iPhones, which is the thing that we hear about

210
00:13:46,075 --> 00:13:50,035
Speaker 5:  and talk about usually during criminal activity of one kind or

211
00:13:50,035 --> 00:13:52,795
Speaker 5:  another. When like law enforcement wants to get into an iPhone,

212
00:13:54,165 --> 00:13:57,755
Speaker 5:  apple typically does not help. And there are an

213
00:13:57,755 --> 00:14:01,515
Speaker 5:  increasingly large number of tools for getting into iPhones.

214
00:14:02,095 --> 00:14:05,715
Speaker 5:  And there's also like, there, there's a whole sort of

215
00:14:05,915 --> 00:14:08,435
Speaker 5:  spyware industry around this. There's, there's like a lot of way, and Apple

216
00:14:08,825 --> 00:14:12,675
Speaker 5:  went way out of its way to be like, we are, we have spent,

217
00:14:12,755 --> 00:14:16,515
Speaker 5:  I think they said a half a decade trying to stop this. And we have figured

218
00:14:16,515 --> 00:14:20,155
Speaker 5:  out how to stop this. And I just think this is fascinating. Like this,

219
00:14:20,425 --> 00:14:24,375
Speaker 5:  this ongoing privacy versus

220
00:14:25,415 --> 00:14:29,255
Speaker 5:  openness versus who is actually responsible for the data

221
00:14:29,275 --> 00:14:33,265
Speaker 5:  on your device and who owns it and who gets to have it. Apple

222
00:14:33,625 --> 00:14:35,745
Speaker 5:  continues to make it stance there. Very clear. And I just think that's really

223
00:14:35,945 --> 00:14:36,105
Speaker 5:  interesting.

224
00:14:36,465 --> 00:14:39,345
Speaker 6:  I mean this is so fascinating, particularly because it's not like they went,

225
00:14:39,485 --> 00:14:43,145
Speaker 6:  Hey, we fixed some really common issue with

226
00:14:43,375 --> 00:14:47,265
Speaker 6:  Java that could have destroyed millions of iPhones. Right?

227
00:14:47,395 --> 00:14:50,465
Speaker 6:  Right. This is the kind of thing that a specific

228
00:14:51,205 --> 00:14:54,765
Speaker 6:  spyware developer is going to sell to one, you know,

229
00:14:54,975 --> 00:14:58,925
Speaker 6:  state sponsored hacker for millions of dollars Yep. With the

230
00:14:59,075 --> 00:15:03,045
Speaker 6:  goal of invading a single target's phone

231
00:15:03,625 --> 00:15:07,525
Speaker 6:  and tracking them. Right? Yeah. But it's gonna be really, really, really

232
00:15:07,625 --> 00:15:11,565
Speaker 6:  bad when that happens. Yeah. Like that's the kind of stuff that Apple is

233
00:15:11,565 --> 00:15:15,405
Speaker 6:  dealing with now. And you know, to their credit, they, they do go

234
00:15:15,405 --> 00:15:18,605
Speaker 6:  out of their way to lock that stuff down and to notify people when they figure

235
00:15:18,665 --> 00:15:22,565
Speaker 6:  out that somebody's been targeted. And so I will confess

236
00:15:23,005 --> 00:15:26,365
Speaker 6:  I do not understand what they did here at all, but

237
00:15:26,925 --> 00:15:29,645
Speaker 6:  I do appreciate, like this is the kind of thing that we see from them pretty

238
00:15:29,645 --> 00:15:30,205
Speaker 6:  regularly.

239
00:15:30,395 --> 00:15:34,205
Speaker 5:  Yeah. Apple calls this kind of software mercenary spyware, which is just

240
00:15:34,365 --> 00:15:38,285
Speaker 5:  a truly terrific phrase. Like mercenary spyware is like

241
00:15:38,325 --> 00:15:42,245
Speaker 5:  a, a series of Netflix spy thrillers that I would watch without one second

242
00:15:42,245 --> 00:15:46,205
Speaker 5:  of thought. Like Mr. Robot, two mercenary spyware is like, I'm in, oh yeah,

243
00:15:46,205 --> 00:15:49,365
Speaker 5:  let's do this. I love this very much. All right, a couple more things.

244
00:15:50,545 --> 00:15:52,365
Speaker 5:  In, in all of the headphone stuff,

245
00:15:54,015 --> 00:15:57,165
Speaker 5:  there are, there was a, a Beats earbuds leak

246
00:15:58,035 --> 00:16:01,325
Speaker 5:  that I just wanna briefly mention because whenever we talk about Apple headphones,

247
00:16:01,685 --> 00:16:04,405
Speaker 5:  I hear from people who are like, you're talking about the wrong Apple headphones

248
00:16:04,405 --> 00:16:08,165
Speaker 5:  because the beat stuff is all better and they

249
00:16:08,165 --> 00:16:12,005
Speaker 5:  haven't been officially announced yet, but the, the new

250
00:16:12,005 --> 00:16:15,285
Speaker 5:  version of the Powerbeats fit may be coming soon. So if you're somebody who

251
00:16:15,285 --> 00:16:18,765
Speaker 5:  likes the Wing Tips, I like the Wing tips. Maybe hold off in the AirPods

252
00:16:18,765 --> 00:16:19,085
Speaker 5:  Pro three.

253
00:16:19,975 --> 00:16:23,825
Speaker 6:  It's funny, beats even beat them to the heart rate sensor. Right.

254
00:16:24,515 --> 00:16:27,825
Speaker 6:  Beats had a pair of earbuds earlier this year that, that did that. I

255
00:16:28,825 --> 00:16:32,585
Speaker 6:  I do not understand the relationship between Apple and Beats at this point

256
00:16:32,585 --> 00:16:36,305
Speaker 6:  in time. And I'm not convinced that Apple does either. But

257
00:16:36,515 --> 00:16:40,025
Speaker 6:  Beats is putting out some nice looking headphones like they, they look good.

258
00:16:40,605 --> 00:16:44,305
Speaker 6:  People still like 'em, the colors are nice. They know about colors.

259
00:16:44,685 --> 00:16:45,705
Speaker 6:  That's good stuff.

260
00:16:45,705 --> 00:16:49,545
Speaker 5:  They do. Beets also looks like they're gonna be an orange. Just

261
00:16:49,545 --> 00:16:52,785
Speaker 5:  saying like, if you're going full aesthetic this year,

262
00:16:54,255 --> 00:16:55,035
Speaker 5:  you want the beets.

263
00:16:55,305 --> 00:16:58,915
Speaker 6:  It's the way this, oh this orange I'm, we'll we'll see. This feels like it's

264
00:16:58,915 --> 00:17:02,835
Speaker 6:  gonna be hot for Halloween. And then everybody's gonna be like, I

265
00:17:02,955 --> 00:17:06,795
Speaker 6:  I have regrets. That's, that's my early prediction on Orange.

266
00:17:07,115 --> 00:17:09,595
Speaker 5:  Interesting. Speaking of the colors, by the way, I don't know if you've noticed

267
00:17:09,595 --> 00:17:12,195
Speaker 5:  this, but in addition to the excitement about the orange, there has been

268
00:17:12,195 --> 00:17:16,155
Speaker 5:  some consternation that there is no black option on the iPhone pros this

269
00:17:16,155 --> 00:17:19,355
Speaker 5:  year, which I had, I didn't even really process until people started being

270
00:17:19,355 --> 00:17:22,715
Speaker 5:  mad about it. Like there kind of isn't a default,

271
00:17:23,975 --> 00:17:27,705
Speaker 5:  like no excitement choice for the iPhone

272
00:17:28,105 --> 00:17:28,865
Speaker 5:  17 pro this year.

273
00:17:29,205 --> 00:17:32,145
Speaker 6:  The the dark blue is good if you're, if you're a dark phone person, like

274
00:17:32,145 --> 00:17:35,345
Speaker 6:  the dark blue is is very nice. Yes, it is a color, but it's nice. It's nice.

275
00:17:35,345 --> 00:17:38,625
Speaker 6:  There's also, what is it white or is it like kind of cream? I can't remember

276
00:17:38,625 --> 00:17:42,145
Speaker 6:  because there's like a creamy one for the the iPhone air. Yeah.

277
00:17:42,365 --> 00:17:45,425
Speaker 5:  The, the pro, again, I haven't seen it in person. You have, but it's, it's

278
00:17:45,425 --> 00:17:48,705
Speaker 5:  more, it's like silver, pretty straight silver. It's like, it kind of looks

279
00:17:48,705 --> 00:17:49,860
Speaker 5:  like MacBook silver to

280
00:17:49,860 --> 00:17:52,845
Speaker 6:  Right, right, right. Yeah. I've, I've never loved the Silvers.

281
00:17:53,715 --> 00:17:57,605
Speaker 6:  Yeah. But yeah, I, it, I think that's weird, right?

282
00:17:57,685 --> 00:18:01,245
Speaker 6:  I i it has there been a year before where there hasn't, sorry, maybe since.

283
00:18:01,955 --> 00:18:04,565
Speaker 6:  Yeah. Has there ever not been a black iPhone? I

284
00:18:04,565 --> 00:18:08,245
Speaker 5:  Would not swear to it, but I certainly cannot recall there not being a black

285
00:18:08,245 --> 00:18:12,085
Speaker 5:  iPhone or something very like it. Like they'll call it, you know, space gray

286
00:18:12,085 --> 00:18:15,245
Speaker 5:  or whatever, but something that is functionally a black phone.

287
00:18:16,205 --> 00:18:17,285
Speaker 5:  I don't remember the last time.

288
00:18:17,755 --> 00:18:18,485
Speaker 6:  Yeah. Me, me either.

289
00:18:18,665 --> 00:18:21,245
Speaker 5:  If you do Vergecast of The Verge dot com tell us when it was and tell us

290
00:18:21,245 --> 00:18:25,165
Speaker 5:  what color you bought. I wanna know. But yeah, I think, I think you're

291
00:18:25,245 --> 00:18:28,765
Speaker 5:  probably right that the blue becomes that thing, but it is

292
00:18:29,065 --> 00:18:33,005
Speaker 5:  the, the sort of ongoing thesis of a lot of

293
00:18:33,475 --> 00:18:37,325
Speaker 5:  this year's phones is that they're sort of more different than

294
00:18:37,325 --> 00:18:39,925
Speaker 5:  ever. And that actually what Apple is doing is pushing more and more people

295
00:18:39,945 --> 00:18:43,405
Speaker 5:  toward the 17. Like I think the, the

296
00:18:43,955 --> 00:18:47,925
Speaker 5:  base pro and the base iPhone

297
00:18:48,315 --> 00:18:52,245
Speaker 5:  have always been the ones that like regular people would decide to buy. And

298
00:18:52,245 --> 00:18:54,445
Speaker 5:  it was always like, do you want the slightly better camera and the slightly

299
00:18:54,445 --> 00:18:58,045
Speaker 5:  better battery life and like you might upgrade even if you don't want the

300
00:18:58,045 --> 00:19:00,885
Speaker 5:  sort of highest of the high end features. I don't see that this time. I think

301
00:19:00,885 --> 00:19:04,725
Speaker 5:  if you don't want the the if, if you don't know what pro

302
00:19:04,885 --> 00:19:07,365
Speaker 5:  res is, you probably don't need an iPhone pro.

303
00:19:07,475 --> 00:19:10,885
Speaker 6:  Yeah. I'll say the air maybe complicates things a bit, but

304
00:19:11,685 --> 00:19:12,245
Speaker 6:  I feel

305
00:19:12,245 --> 00:19:14,685
Speaker 5:  It's easy 'cause it's the pretty one. It's like the iPad maybe is Yeah. You

306
00:19:14,685 --> 00:19:15,365
Speaker 5:  either want it or you don't.

307
00:19:15,365 --> 00:19:16,565
Speaker 6:  Yeah, that's, I think that's fair.

308
00:19:16,785 --> 00:19:19,525
Speaker 5:  And I think we, we try to sort of ham fist it into the lineup, but it is,

309
00:19:19,875 --> 00:19:23,125
Speaker 5:  it's gonna be such a visceral thing for people where like either you want

310
00:19:23,125 --> 00:19:25,365
Speaker 5:  the air or you don't. Yeah. And I think most people already know the answer

311
00:19:25,365 --> 00:19:25,565
Speaker 5:  to that.

312
00:19:25,565 --> 00:19:28,245
Speaker 6:  That tracks that tracks. Yeah. You're you're looking for something

313
00:19:28,245 --> 00:19:30,765
Speaker 5:  Flashy, which is also really upsetting because I increasingly want the air.

314
00:19:31,105 --> 00:19:32,205
Speaker 6:  Oh, I hate that

315
00:19:32,205 --> 00:19:33,805
Speaker 5:  I am this person. It's, but I like,

316
00:19:34,275 --> 00:19:37,365
Speaker 6:  It's cool. It's cool. It looks nice. I know. Yeah. And

317
00:19:37,365 --> 00:19:41,285
Speaker 5:  I'm, I'm trying to stop upgrading my phone every year like I do in part because

318
00:19:41,585 --> 00:19:45,325
Speaker 5:  we do this for a living and in part because I'm like a lunatic in this specific

319
00:19:45,345 --> 00:19:49,285
Speaker 5:  way, but I'm, I'm trying to be more

320
00:19:49,285 --> 00:19:50,365
Speaker 5:  responsible in my gadget

321
00:19:50,485 --> 00:19:53,085
Speaker 6:  Purchases. Now is this really the year to give it up, David?

322
00:19:53,305 --> 00:19:55,165
Speaker 5:  No, it's not. I've decided this is, this is where I've landed.

323
00:19:55,585 --> 00:19:57,445
Speaker 6:  I'm sorry. I'm I'm sorry to do it. You. Yeah, it's

324
00:19:57,445 --> 00:19:57,805
Speaker 5:  Fraternal.

325
00:19:57,915 --> 00:20:01,645
Speaker 6:  That blue is just so old. I, I can't believe you're still

326
00:20:01,695 --> 00:20:02,645
Speaker 6:  still using that thing.

327
00:20:04,445 --> 00:20:07,205
Speaker 5:  Alright, let's, let's talk about some other gadget news before we need to

328
00:20:07,205 --> 00:20:07,845
Speaker 5:  take a break here. Yes.

329
00:20:09,525 --> 00:20:13,495
Speaker 5:  This is like a half a gadget news so far. So nothing, which I think

330
00:20:13,495 --> 00:20:16,855
Speaker 5:  is like one of the most interesting hardware companies still.

331
00:20:17,645 --> 00:20:21,335
Speaker 5:  They have a new set of their own earbuds coming out the year three

332
00:20:21,795 --> 00:20:25,615
Speaker 5:  coming out next week. So we're gonna get all the details next week.

333
00:20:26,275 --> 00:20:30,095
Speaker 5:  But what we've learned this week is that in

334
00:20:30,235 --> 00:20:33,215
Speaker 5:  the, the headphones look roughly the same as they have before. They have

335
00:20:33,215 --> 00:20:36,815
Speaker 5:  that kind of transparent design. They look very cool. Nothing is very good

336
00:20:36,815 --> 00:20:39,055
Speaker 5:  at designing these kinds of gadgets. I really like the way that it looks.

337
00:20:40,235 --> 00:20:44,175
Speaker 5:  But there's a, there's a microphone and a talk button on the

338
00:20:44,295 --> 00:20:48,145
Speaker 5:  charging case itself. We don't know what it's for. We don't know how

339
00:20:48,145 --> 00:20:50,705
Speaker 5:  it's gonna work. We just know that it's there.

340
00:20:51,325 --> 00:20:54,945
Speaker 6:  You know, I don't understand what it is, but it's cool. I think it's cool

341
00:20:54,945 --> 00:20:58,545
Speaker 6:  that there's a button and it says talk I nothing loves a gimmick, but like

342
00:20:58,545 --> 00:21:02,225
Speaker 6:  this might, it's maybe this is a good gimmick, right? Because I think that

343
00:21:02,225 --> 00:21:05,505
Speaker 6:  the conspiracy theory, tell me if I'm wrong here. I think the conspiracy

344
00:21:05,505 --> 00:21:08,945
Speaker 6:  theory is that this is going to actually double as a wireless microphone.

345
00:21:09,855 --> 00:21:13,265
Speaker 5:  Yeah. That's the only thing I can think of is that, that that ha that it

346
00:21:13,265 --> 00:21:17,185
Speaker 5:  is, it will, if you press the button take over as

347
00:21:17,205 --> 00:21:17,825
Speaker 5:  the microphone,

348
00:21:19,005 --> 00:21:22,265
Speaker 6:  It is weird because obviously the headphones have mics built in,

349
00:21:22,885 --> 00:21:26,265
Speaker 6:  But that doesn't matter 'cause you're on TikTok and you wanna be holding

350
00:21:26,265 --> 00:21:28,985
Speaker 6:  something, you wanna be holding like a, a thing that is a microphone but

351
00:21:28,985 --> 00:21:30,025
Speaker 6:  doesn't look like a microphone.

352
00:21:31,415 --> 00:21:35,345
Speaker 5:  Right? That is true. So my, my initial take for this

353
00:21:35,345 --> 00:21:38,345
Speaker 5:  was like, okay, the, the sort of handheld microphones are everywhere now

354
00:21:38,485 --> 00:21:42,185
Speaker 5:  and people love the little lavaliers in DJI is selling stuff. And so the

355
00:21:42,185 --> 00:21:45,265
Speaker 5:  idea of like, let's let's repurpose the case into something that A

356
00:21:46,045 --> 00:21:49,785
Speaker 5:  is usable and b puts our brand in front of everybody

357
00:21:49,785 --> 00:21:52,665
Speaker 5:  every time you make a video makes a lot of sense to me.

358
00:21:54,735 --> 00:21:58,595
Speaker 5:  But it, it might just look stupid. It might just

359
00:21:58,595 --> 00:22:00,435
Speaker 5:  look like you're talking into your headphones case.

360
00:22:01,345 --> 00:22:05,195
Speaker 6:  Yeah. Yeah. But it's, it's a cool looking headphones case, right? Like,

361
00:22:05,615 --> 00:22:09,555
Speaker 6:  you know, I'll give him that. I mean, is it, is it stupider than a very,

362
00:22:09,665 --> 00:22:11,915
Speaker 6:  very, very, very tiny microphone?

363
00:22:13,385 --> 00:22:17,275
Speaker 6:  Like I I don't think that, I don't know what cool is anymore. I

364
00:22:17,345 --> 00:22:20,235
Speaker 6:  like everyone has lost the plot here. Oh,

365
00:22:20,235 --> 00:22:20,835
Speaker 5:  That's so true.

366
00:22:21,495 --> 00:22:25,355
Speaker 6:  You just need to be holding an object that looks slightly wrong. I

367
00:22:25,355 --> 00:22:28,875
Speaker 6:  think that's what the goal is here. And so I I I actually think this works.

368
00:22:29,635 --> 00:22:32,755
Speaker 5:  I that's a phenomenal argument. I actually have no comeback for that. It

369
00:22:32,755 --> 00:22:35,155
Speaker 5:  is going to look slightly stupid in the way it is probably supposed to look

370
00:22:35,355 --> 00:22:39,275
Speaker 5:  slightly stupid. I think is is probably exactly right. One

371
00:22:39,275 --> 00:22:43,075
Speaker 5:  other theory I will give you is that so nothing has been doing

372
00:22:44,225 --> 00:22:47,355
Speaker 5:  some really interesting AI stuff. They have this thing on their newest phones

373
00:22:47,355 --> 00:22:50,675
Speaker 5:  called Essential Space, which is sort of like the pixel

374
00:22:50,675 --> 00:22:53,995
Speaker 5:  screenshots feature, like blown out. You, you put a bunch of notes in, you

375
00:22:53,995 --> 00:22:57,675
Speaker 5:  take screenshots, you add files, whatever else, and then it sort of,

376
00:22:58,095 --> 00:23:00,915
Speaker 5:  AI is its way into trying to organize it for you and make it accessible.

377
00:23:01,535 --> 00:23:03,125
Speaker 5:  Great idea. I think it's super useful.

378
00:23:04,745 --> 00:23:08,605
Speaker 5:  The idea of this as like a dedicated voice input to that

379
00:23:08,995 --> 00:23:12,805
Speaker 5:  strikes me as kind of interesting I think because if

380
00:23:12,805 --> 00:23:16,605
Speaker 5:  you're, if you're nothing, what you don't have access to is

381
00:23:16,985 --> 00:23:20,645
Speaker 5:  the like built in assistant stuff in the same way. So for nothing to just

382
00:23:20,645 --> 00:23:23,205
Speaker 5:  be like, oh well we'll we're also shipping a little voice recorder that just

383
00:23:23,205 --> 00:23:24,685
Speaker 5:  pipes stuff into your phone.

384
00:23:26,845 --> 00:23:29,575
Speaker 5:  Some wonky bluetoothy stuff that would have to do to make that work. Yeah.

385
00:23:29,795 --> 00:23:33,375
Speaker 5:  But I think there is potentially, it's, it's just an input device that I

386
00:23:33,375 --> 00:23:36,215
Speaker 5:  think could be interesting. We're seeing these like AI voice recorders

387
00:23:37,185 --> 00:23:41,095
Speaker 5:  everywhere and they're not hard to build. They're pretty easy to like

388
00:23:41,125 --> 00:23:45,015
Speaker 5:  make semi-functional. And so I, I could totally see a world in

389
00:23:45,100 --> 00:23:47,005
Speaker 5:  which that's what this thing also is.

390
00:23:47,265 --> 00:23:51,205
Speaker 6:  And it's also every single product designer is trying to figure

391
00:23:51,225 --> 00:23:55,165
Speaker 6:  out how they can add AI to their spec sheet. So like it's it's there's

392
00:23:55,165 --> 00:23:57,125
Speaker 6:  a real chance. There's a real chance it goes that direction.

393
00:23:57,235 --> 00:24:00,845
Speaker 5:  Yeah. The nothing ear three AI headphones is like a thing I Oh yeah. I hate

394
00:24:00,845 --> 00:24:01,325
Speaker 6:  Already,

395
00:24:01,905 --> 00:24:05,245
Speaker 5:  But it's is definitely coming. Speaking of ai,

396
00:24:06,715 --> 00:24:10,535
Speaker 5:  Google, you may have heard of it, released this thing called the Daily

397
00:24:10,715 --> 00:24:14,615
Speaker 5:  Hub with the Pixel 10. One of the like big features

398
00:24:15,195 --> 00:24:18,935
Speaker 5:  of the new Pixel supposed to do AI to like bring all of your stuff together.

399
00:24:19,815 --> 00:24:23,655
Speaker 5:  Calendar events. Like it's basically like the just Google Discover feed

400
00:24:24,785 --> 00:24:28,695
Speaker 5:  times 10, I would say. Except it turns out it didn't work and Google pulled

401
00:24:28,695 --> 00:24:29,095
Speaker 5:  it already.

402
00:24:30,245 --> 00:24:33,655
Speaker 6:  Okay. On one hand I think this is, this feature

403
00:24:34,115 --> 00:24:37,855
Speaker 6:  is totally inconsequential and doesn't matter. And on the other hand I think

404
00:24:37,855 --> 00:24:41,535
Speaker 6:  this is completely galling, right? This is a

405
00:24:41,535 --> 00:24:44,695
Speaker 6:  brand new feature that they sold the phone with, right.

406
00:24:45,415 --> 00:24:49,135
Speaker 6:  A feature of your brand new phone was just removed. Yep.

407
00:24:49,475 --> 00:24:53,255
Speaker 6:  And I think particularly for the pixel line where, and it's

408
00:24:53,255 --> 00:24:56,335
Speaker 6:  particularly this year, the software is really all that's new.

409
00:24:57,535 --> 00:25:01,275
Speaker 6:  The That's wild. That's what now listen, zero people bought the phone

410
00:25:01,415 --> 00:25:04,675
Speaker 6:  for Daily Hub. Sure. Did Google even advertise this thing? I was trying to

411
00:25:04,675 --> 00:25:08,195
Speaker 6:  find more information on this and it's, it just isn't available 'cause no

412
00:25:08,195 --> 00:25:08,955
Speaker 6:  one cares about it.

413
00:25:09,095 --> 00:25:12,995
Speaker 5:  But there is the, the, it's part of a bigger pitch to me, which is like,

414
00:25:13,275 --> 00:25:16,235
Speaker 5:  I I, to me I think we need to hold Google's feet to the fire for this because

415
00:25:16,235 --> 00:25:18,995
Speaker 5:  we held Apple's feet to the fire fort, right? Oh yeah. And what Google is

416
00:25:18,995 --> 00:25:22,835
Speaker 5:  doing here is not as egregious as what Apple did, which is promise a

417
00:25:22,835 --> 00:25:26,115
Speaker 5:  version of Siri that not only doesn't exist but like actively sucks.

418
00:25:26,745 --> 00:25:29,595
Speaker 5:  This is just Google being like, actually what we're gonna do with AI is we

419
00:25:29,595 --> 00:25:32,275
Speaker 5:  are going to fundamentally transform the way that you interact with your

420
00:25:32,275 --> 00:25:36,155
Speaker 5:  phone. And instead of just having like a, a sequence of apps that

421
00:25:36,155 --> 00:25:39,395
Speaker 5:  you open in order to do different kinds of things, you wanna look at your

422
00:25:39,555 --> 00:25:41,275
Speaker 5:  calendar, you open the calendar, you wanna look at your email, you open your

423
00:25:41,275 --> 00:25:44,595
Speaker 5:  email. Like it actually doesn't have to be that way. And the idea that you

424
00:25:44,595 --> 00:25:47,755
Speaker 5:  could use AI to just be like, here's what matters to you. We have done the

425
00:25:47,755 --> 00:25:51,395
Speaker 5:  work of going into your apps and making sense of your phone for you. Like

426
00:25:51,455 --> 00:25:55,435
Speaker 5:  that's the pitch. That is what everyone is trying to do. And for

427
00:25:55,435 --> 00:25:58,715
Speaker 5:  Google to be like, we did it. Here it is, it's a cool feature of this new

428
00:25:58,715 --> 00:26:01,915
Speaker 5:  phone that you should totally buy and then just mothball it outta nowhere

429
00:26:02,535 --> 00:26:06,435
Speaker 5:  is like, I don't think it's like consumer hostile for basically the

430
00:26:06,435 --> 00:26:08,595
Speaker 5:  reason you're describing. Like, I don't know that anybody bought this phone

431
00:26:08,595 --> 00:26:12,555
Speaker 5:  for that reason anyway, but it's a bad look and this suggests that Google

432
00:26:12,735 --> 00:26:14,235
Speaker 5:  is not just

433
00:26:16,385 --> 00:26:18,195
Speaker 5:  able to get this stuff right.

434
00:26:18,385 --> 00:26:21,955
Speaker 6:  Well I agree. And it's like a feature of your phone that you potentially

435
00:26:21,955 --> 00:26:25,715
Speaker 6:  bought the phone for has now been removed. That, that feels just

436
00:26:25,715 --> 00:26:29,035
Speaker 6:  fundamentally wrong to me. Right. You still paid the same amount of money

437
00:26:29,035 --> 00:26:32,755
Speaker 6:  for the phone, you just can't use some of it anymore. Yeah. Now

438
00:26:32,955 --> 00:26:36,835
Speaker 6:  I I I am very curious to know what was going so horrendously wrong

439
00:26:37,105 --> 00:26:40,555
Speaker 6:  with this feature that was basically just a glorified calendar

440
00:26:41,065 --> 00:26:44,645
Speaker 6:  that that had been LL md like what, what happened

441
00:26:45,075 --> 00:26:46,765
Speaker 6:  that they had to pull this entire thing?

442
00:26:47,185 --> 00:26:50,405
Speaker 5:  So Alison Johnson who, who reviewed the phone and got to use it, lemme just

443
00:26:50,405 --> 00:26:53,805
Speaker 5:  read you a little bit of the, the thing that she

444
00:26:54,115 --> 00:26:58,085
Speaker 5:  described with Daily Hub. So she, she basically,

445
00:26:58,145 --> 00:27:01,365
Speaker 5:  she used it, she got the calendar, she compared it to the now brief

446
00:27:02,105 --> 00:27:05,365
Speaker 5:  on Samsung's S 25 phones, which is just like, pull some information about

447
00:27:05,365 --> 00:27:08,925
Speaker 5:  your day. And then she says, but it also misconstrued some of my recent Google

448
00:27:08,925 --> 00:27:11,805
Speaker 5:  search history in puzzling in hilarious ways. I looked up the schedule for

449
00:27:11,805 --> 00:27:14,645
Speaker 5:  our recycling service provided by Waste Management. And it took that to mean

450
00:27:14,665 --> 00:27:17,765
Speaker 5:  I'm interested in learning more about waste management generally. Not quite

451
00:27:18,195 --> 00:27:21,725
Speaker 5:  this. If you, if you want a perfect microcosm of the ways

452
00:27:22,025 --> 00:27:25,885
Speaker 5:  AI could be great and fall spectacularly short there, it's right. Like

453
00:27:25,965 --> 00:27:29,085
Speaker 5:  Google's ability to be like, oh, here are all the things you Googled yesterday.

454
00:27:29,385 --> 00:27:32,325
Speaker 5:  Here's some new information about that. Why don't we put it into your feed?

455
00:27:32,465 --> 00:27:35,565
Speaker 5:  Oh, you wanted to see who won the Warriors game? Well the Warriors game is

456
00:27:35,565 --> 00:27:37,725
Speaker 5:  over. We'll we'll we'll give you the score 'cause we know you

457
00:32:30,965 --> 00:32:34,325
Speaker 5:  feelings about the news and tech industry and the world,

458
00:32:35,665 --> 00:32:39,525
Speaker 5:  And I have brought you both here basically to tell me how wrong

459
00:32:39,605 --> 00:32:43,245
Speaker 5:  I am about everything. So I don't know, do, do you guys know Subway takes?

460
00:32:44,065 --> 00:32:44,285
Speaker 11:  Yes.

461
00:32:44,665 --> 00:32:45,085
Speaker 6:  Oh yeah.

462
00:32:45,195 --> 00:32:48,365
Speaker 5:  Okay. So Subway takes basically the, the shtick is they're sitting on the

463
00:32:48,365 --> 00:32:52,285
Speaker 5:  subway. He sits down, he says, so what's your take? The person delivers the

464
00:32:52,285 --> 00:32:55,285
Speaker 5:  take and, and Kareem the host, either a hundred percent agrees or a hundred

465
00:32:55,285 --> 00:32:59,205
Speaker 5:  percent disagrees. So this is, I'm, we're just gonna rip that

466
00:32:59,205 --> 00:33:02,685
Speaker 5:  format entirely. I'm going to offer you a take and you are going to either

467
00:33:02,855 --> 00:33:06,325
Speaker 5:  there, there, there are no middle grounds here. You are either in or you

468
00:33:06,325 --> 00:33:10,005
Speaker 5:  are out. But I will offer you a a third option, which is

469
00:33:10,005 --> 00:33:13,525
Speaker 5:  essentially like David is just annihilating his own career in front of me

470
00:33:13,525 --> 00:33:16,885
Speaker 5:  right now. So I'm just going to abstain from this and be quiet. That's allowed,

471
00:33:17,185 --> 00:33:18,085
Speaker 5:  if you listen to see

472
00:33:18,085 --> 00:33:21,925
Speaker 6:  That. Oh boy, I'm have a lot of questions about where

473
00:33:21,925 --> 00:33:22,885
Speaker 6:  these takes are going. Yeah,

474
00:33:22,885 --> 00:33:23,765
Speaker 11:  I can't wait to hear these.

475
00:33:24,055 --> 00:33:27,165
Speaker 5:  We're either in a word out and, and, and this is just what we're doing here.

476
00:33:27,305 --> 00:33:27,525
Speaker 5:  Can

477
00:33:27,525 --> 00:33:29,885
Speaker 6:  I say something? I'm a hundred percent in. I have five

478
00:33:29,885 --> 00:33:33,365
Speaker 5:  Takes for you. We, we can discuss as much as you would like. These are all

479
00:33:33,365 --> 00:33:36,965
Speaker 5:  about ai. Hayden, I've brought you here because it turns out most of my takes

480
00:33:36,965 --> 00:33:37,685
Speaker 5:  are about ai.

481
00:33:38,255 --> 00:33:39,845
Speaker 11:  We're gonna talk. That's common. So I love it.

482
00:33:40,315 --> 00:33:43,125
Speaker 5:  Does this sound good? Everybody? Everybody feel good? Any questions? Would

483
00:33:43,125 --> 00:33:44,605
Speaker 5:  you like to leave before we even start?

484
00:33:45,215 --> 00:33:47,605
Speaker 11:  We're all at, we're 100% in and as you said, so,

485
00:33:47,755 --> 00:33:51,625
Speaker 5:  Okay, take number one. Open AI

486
00:33:51,625 --> 00:33:55,065
Speaker 5:  is a total house of cards and it is all going to collapse like any minute

487
00:33:55,065 --> 00:33:57,025
Speaker 5:  now. And it might just bring America down with it.

488
00:33:59,135 --> 00:33:59,355
Speaker 11:  Man,

489
00:33:59,355 --> 00:34:01,235
Speaker 6:  That's a, that's a lot for a quick reaction.

490
00:34:02,575 --> 00:34:05,705
Speaker 11:  Yeah, this is one I would definitely love to have a middle ground on, but

491
00:34:05,705 --> 00:34:07,025
Speaker 11:  okay, if I have to choose, you're

492
00:34:07,025 --> 00:34:07,305
Speaker 5:  In or you're out.

493
00:34:07,765 --> 00:34:11,745
Speaker 11:  If I have to choose one or the other to the dismay of some, I'll say

494
00:34:12,345 --> 00:34:15,625
Speaker 11:  I will disagree. I think that, you know,

495
00:34:16,255 --> 00:34:19,985
Speaker 11:  valuation is crazy. We won't even talk about profit. But you know,

496
00:34:20,015 --> 00:34:23,305
Speaker 11:  they have a product that a lot of people are using every single day and

497
00:34:23,815 --> 00:34:26,705
Speaker 11:  it's coming up when I go to the bar, it's coming up when I go to the club,

498
00:34:26,705 --> 00:34:29,785
Speaker 11:  when I'm walking my dog, my super is talking to me about it. So I mean,

499
00:34:29,785 --> 00:34:33,465
Speaker 11:  it is a consumer tool that everyone is using, it seems like, and they're

500
00:34:33,465 --> 00:34:37,265
Speaker 11:  using it a lot for a ton of different things in their life. And

501
00:34:37,405 --> 00:34:41,345
Speaker 11:  now they have government partnerships and they're working with like, you

502
00:34:41,345 --> 00:34:45,145
Speaker 11:  know, companies all through the Fortune 500. So I think for better or

503
00:34:45,145 --> 00:34:48,805
Speaker 11:  worse, I'll say that for better or worse, I disagree. And I don't think

504
00:34:48,805 --> 00:34:50,965
Speaker 11:  it's a house of cards that's gonna fall anytime soon.

505
00:34:51,875 --> 00:34:55,005
Speaker 6:  Yeah. I'm, I'm, I'm with Hayden here. Damn. I disagree. Listen, they're a

506
00:34:55,005 --> 00:34:58,845
Speaker 6:  product. It's a, it's a reasonably good product. Listen, there's a lot we

507
00:34:58,845 --> 00:35:02,525
Speaker 6:  can argue about there, but every, it is a product that I think

508
00:35:03,225 --> 00:35:07,165
Speaker 6:  any tech company would, would trade most of what they sell to have that product.

509
00:35:07,775 --> 00:35:11,685
Speaker 6:  There is a lot of money tied up in it, questionable amounts of money tied

510
00:35:11,685 --> 00:35:15,325
Speaker 6:  up in it. Right? If there's one thing I've learned about Silicon Valley and

511
00:35:15,385 --> 00:35:18,805
Speaker 6:  listen, I I'll admit that, that this may not be an expert opinion, but

512
00:35:19,005 --> 00:35:22,045
Speaker 6:  there's one thing I've learned, money is a little bit fake over there. Right?

513
00:35:22,675 --> 00:35:26,405
Speaker 6:  They, they're gonna figure this out if they have to and they have to because

514
00:35:27,425 --> 00:35:30,245
Speaker 6:  way too many people have way too much money on the line.

515
00:35:30,745 --> 00:35:34,525
Speaker 5:  So you, you just said the thing that is the hardest for me to

516
00:35:35,025 --> 00:35:38,885
Speaker 5:  combat, which is that there is now so much riding on it working

517
00:35:39,555 --> 00:35:43,485
Speaker 5:  that like OpenAI might be Bitcoin in the sense that it, it it is

518
00:35:43,485 --> 00:35:47,085
Speaker 5:  just, it is, there's too much money in it and the people who are in it

519
00:35:47,195 --> 00:35:49,125
Speaker 5:  have too much invested in it to let it fall apart.

520
00:35:49,405 --> 00:35:50,885
Speaker 11:  I actually think that's a great analogy.

521
00:35:51,395 --> 00:35:54,925
Speaker 6:  Wait, can I a hundred percent disagree on the Bitcoin analogy?

522
00:35:55,385 --> 00:35:56,845
Speaker 5:  You don't like the Bitcoin analogy? No,

523
00:35:56,845 --> 00:35:58,205
Speaker 11:  Because we're doing a meta disagreement

524
00:35:58,425 --> 00:36:02,085
Speaker 6:  Bi Bitcoin if I can. Okay. Bitcoin has a bunch of

525
00:36:02,645 --> 00:36:06,445
Speaker 6:  nonsense investors, right? Like there, there are real

526
00:36:06,885 --> 00:36:10,845
Speaker 6:  companies, they're like institutions that are invested in

527
00:36:10,845 --> 00:36:14,285
Speaker 6:  open ai, Bitcoin. I think that one can fall apart.

528
00:36:15,725 --> 00:36:16,345
Speaker 6:  So, but

529
00:36:16,775 --> 00:36:17,065
Speaker 5:  Much

530
00:36:17,065 --> 00:36:18,585
Speaker 6:  Bunch of internet randos. We just

531
00:36:18,585 --> 00:36:19,665
Speaker 5:  Had some crazy bunch violent,

532
00:36:20,205 --> 00:36:23,665
Speaker 6:  I'm really, I'm really like sidetracking us here in, in New York. One metaphor.

533
00:36:23,665 --> 00:36:24,105
Speaker 6:  But so

534
00:36:24,165 --> 00:36:27,505
Speaker 11:  You saw the violent crimes tied to Bitcoin recently, like people will do

535
00:36:27,505 --> 00:36:29,065
Speaker 11:  a lot to make it succeed or get it.

536
00:36:30,105 --> 00:36:34,025
Speaker 5:  I that is, that is fair. And I think yeah, we'll we'll leave the

537
00:36:34,025 --> 00:36:37,665
Speaker 5:  Bitcoin thing to the side. That's a whole nother take. That I Fair enough,

538
00:36:37,665 --> 00:36:39,025
Speaker 5:  fair enough. I'm not even ready for that. I'm

539
00:36:39,135 --> 00:36:40,305
Speaker 11:  Time. We'll do that next time. Yeah.

540
00:36:40,955 --> 00:36:44,145
Speaker 5:  Allow me to just briefly make the case that OpenAI is a total disaster and

541
00:36:44,145 --> 00:36:48,065
Speaker 5:  about to fall apart. Let's hear it. Thing number one, OpenAI. The,

542
00:36:48,065 --> 00:36:51,425
Speaker 5:  according to the, the reporting from the information last week is going to

543
00:36:51,455 --> 00:36:55,225
Speaker 5:  burn through $115 billion between now and

544
00:36:55,225 --> 00:36:59,105
Speaker 5:  2029. Yes. Money is fake. Yes. Sam Altman appears to be

545
00:36:59,105 --> 00:37:01,305
Speaker 5:  able to raise as much money as he wants at any given time.

546
00:37:01,705 --> 00:37:05,665
Speaker 5:  $115 billion is a lot of

547
00:37:05,665 --> 00:37:09,505
Speaker 5:  money. And, and at some point it actually doesn't take all that

548
00:37:09,505 --> 00:37:12,785
Speaker 5:  much for somebody to say, oh, all that money we're giving to you we're just

549
00:37:12,785 --> 00:37:16,505
Speaker 5:  gonna put over there. And it like, when it goes, it goes quickly. And

550
00:37:16,585 --> 00:37:20,185
Speaker 5:  $115 billion until

551
00:37:20,185 --> 00:37:24,145
Speaker 5:  2029 is, is a lot to ask of people, especially in a moment where some

552
00:37:24,145 --> 00:37:26,305
Speaker 5:  of the hype on this is starting to die. Like the only way you get there is

553
00:37:26,305 --> 00:37:30,225
Speaker 5:  to convince everybody that by 2029 you will have invented God. And

554
00:37:30,225 --> 00:37:33,465
Speaker 5:  I think we're getting away from that pretty quickly. And so the idea of why

555
00:37:33,465 --> 00:37:37,185
Speaker 5:  am I going to let you lose $115 billion by 2029

556
00:37:38,295 --> 00:37:41,705
Speaker 5:  just gets a little harder. That's one Think number two,

557
00:37:42,325 --> 00:37:45,625
Speaker 5:  Claude is a better product than chat GPT And I think people are starting

558
00:37:45,625 --> 00:37:48,945
Speaker 5:  to realize it. I think Anthropic is shipping circles

559
00:37:49,285 --> 00:37:52,665
Speaker 5:  around OpenAI and OpenAI had a very good big

560
00:37:52,955 --> 00:37:56,745
Speaker 5:  first mover advantage that I think it is losing really, really, really fast.

561
00:37:57,165 --> 00:38:00,545
Speaker 5:  And, and Anthropic also just raised money at a crazy valuation. Google is

562
00:38:00,545 --> 00:38:04,265
Speaker 5:  out here doing stuff like I think OpenAI is still in the lead, but I think

563
00:38:04,265 --> 00:38:07,825
Speaker 5:  it deserves that lead a little bit less every single day. And I think, again,

564
00:38:08,535 --> 00:38:12,185
Speaker 5:  this is what I mean by a house of cards. Like all this stuff only works if

565
00:38:12,185 --> 00:38:15,745
Speaker 5:  it's all working in tandem and as soon as one leg of it comes out, the whole

566
00:38:15,745 --> 00:38:19,665
Speaker 5:  thing collapses because it's $115 billion. You have

567
00:38:19,665 --> 00:38:22,925
Speaker 5:  to be willing to stomach. And I just don't know why people would be,

568
00:38:23,185 --> 00:38:26,805
Speaker 6:  You know, I don't think they have to have invented God though. Right? What

569
00:38:26,805 --> 00:38:30,635
Speaker 6:  if they have just merely invented Google, right? That is still a

570
00:38:30,635 --> 00:38:34,195
Speaker 6:  very big company. I'm not sure that OpenAI is going to be the winner necessarily

571
00:38:34,245 --> 00:38:37,685
Speaker 6:  after all of this. But they have a product they can compete on it.

572
00:38:37,865 --> 00:38:39,845
Speaker 5:  You know, what Google's product makes is money.

573
00:38:40,485 --> 00:38:44,285
Speaker 6:  That is true. But you know, what open I can do is start shoving a bunch of

574
00:38:44,305 --> 00:38:45,525
Speaker 6:  ads into this thing, right?

575
00:38:45,895 --> 00:38:47,005
Speaker 11:  Which they haven't ruled out,

576
00:38:47,855 --> 00:38:50,565
Speaker 6:  Right? There are ways in which they can start making money, they can turn

577
00:38:50,565 --> 00:38:53,925
Speaker 6:  that funnel on. I don't know how easily, I dunno if people will like it as

578
00:38:53,925 --> 00:38:57,405
Speaker 6:  much. I don't know if they'll accomplish the, the crazy dreams of

579
00:38:57,405 --> 00:39:00,285
Speaker 6:  automating the entire workforce of the world. But

580
00:39:01,285 --> 00:39:04,295
Speaker 6:  they've, they've made, they've made a search engine, they've made a, a tool

581
00:39:04,295 --> 00:39:08,175
Speaker 6:  that can code for people, right? It can do some things reasonably well.

582
00:39:08,205 --> 00:39:11,495
Speaker 6:  They have a product, I, I'm not sure you are right,

583
00:39:12,395 --> 00:39:16,095
Speaker 6:  it it is a high wire act that they are on. Right. That

584
00:39:16,095 --> 00:39:19,935
Speaker 6:  there is so much money and they're spending it very,

585
00:39:19,935 --> 00:39:20,455
Speaker 6:  very quickly.

586
00:39:20,835 --> 00:39:24,695
Speaker 11:  Yes. And you know, like you said about product, they also are making a LinkedIn

587
00:39:24,695 --> 00:39:28,015
Speaker 11:  competitor of sorts, you know, they're doing a lot. I think you're right

588
00:39:28,015 --> 00:39:31,015
Speaker 11:  about the amount of money. It's crazy. Like, I won't even speak to that

589
00:39:31,015 --> 00:39:34,615
Speaker 11:  because it's all fake and it's just like a hype bubble that's definitely

590
00:39:34,615 --> 00:39:37,775
Speaker 11:  gonna burst, I don't think. But when I think about a house of cards, it's

591
00:39:37,775 --> 00:39:41,615
Speaker 11:  something that's gonna like fail crazily and go out of

592
00:39:41,775 --> 00:39:44,615
Speaker 11:  business. Like some of the companies we've reported on in the past, like,

593
00:39:44,795 --> 00:39:48,735
Speaker 11:  you know, 10 years. And I don't think that's gonna happen to

594
00:39:48,735 --> 00:39:52,055
Speaker 11:  open ai. I think that maybe they'll get less of a lead. We're gonna see

595
00:39:52,095 --> 00:39:55,815
Speaker 11:  a lot more m and a in the space. We're gonna see, you know,

596
00:39:56,045 --> 00:39:59,975
Speaker 11:  lots more aqua hires and like shell companies. But I don't think open

597
00:40:00,115 --> 00:40:03,495
Speaker 11:  AI is just gonna fall apart. I think they'll make a lot of people mad and

598
00:40:03,495 --> 00:40:07,415
Speaker 11:  investors mad probably. But you know, I don't see them like collapsing

599
00:40:07,655 --> 00:40:11,615
Speaker 11:  entirely because a lot of their talent is, you know,

600
00:40:11,615 --> 00:40:14,015
Speaker 11:  what's kind of pushing the space forward right now for better or worse.

601
00:40:14,445 --> 00:40:17,975
Speaker 5:  Yeah, I, I have debated many times on like, is the,

602
00:40:18,355 --> 00:40:21,375
Speaker 5:  is the extent of the disaster that I'm predicting like

603
00:40:22,415 --> 00:40:25,855
Speaker 5:  Theranos and like no, it's not. I'm, I'm not, I'm not, I don't see that coming.

604
00:40:25,895 --> 00:40:28,615
Speaker 5:  I don't think anyone goes to prison at the end of the open AI story.

605
00:40:29,995 --> 00:40:33,775
Speaker 5:  Or is it like, you know, the, the cosmos and web

606
00:40:33,885 --> 00:40:37,655
Speaker 5:  vans of like the.com bust of 25 years ago that are like the ideas

607
00:40:37,685 --> 00:40:40,695
Speaker 5:  that were ahead of their time and spent like crazy and just couldn't do it

608
00:40:40,695 --> 00:40:43,975
Speaker 5:  and it all fell apart? Or is it like, I don't know who's a good example,

609
00:40:44,485 --> 00:40:47,895
Speaker 5:  like Cisco is a company that like was huge

610
00:40:48,275 --> 00:40:51,935
Speaker 5:  and then collapsed during the.com bubble and is now like

611
00:40:52,265 --> 00:40:55,975
Speaker 5:  still around, still doing stuff, still doing fine, but is I think still

612
00:40:57,075 --> 00:41:00,495
Speaker 5:  not as valuable as it was 25 years ago. Right? So it's like, I, I don't know

613
00:41:00,495 --> 00:41:03,575
Speaker 5:  the extent to which I even think this is all gonna fall apart. I think you're

614
00:41:03,575 --> 00:41:07,415
Speaker 5:  right that like at this point, the existence of open AI and chat

615
00:41:07,495 --> 00:41:08,375
Speaker 5:  GBT in particular

616
00:41:09,965 --> 00:41:13,465
Speaker 5:  is sort of self perpetuating. But I just, I can't

617
00:41:13,795 --> 00:41:17,705
Speaker 5:  shake the idea that the only thing they have going for them now is

618
00:41:17,705 --> 00:41:21,625
Speaker 5:  that they were first and they are famous and that is like, there is a, that

619
00:41:21,625 --> 00:41:24,905
Speaker 5:  that's valuable and Sam Altman being like, the face of all of this is really

620
00:41:25,185 --> 00:41:29,025
Speaker 5:  valuable, but also Sam Altman is going through perpetually weird stuff

621
00:41:29,045 --> 00:41:31,985
Speaker 5:  all the time and is involved in 10 million different projects and

622
00:41:32,655 --> 00:41:35,325
Speaker 6:  Totally fast. It's not clear how much he wants to be there.

623
00:41:35,715 --> 00:41:39,685
Speaker 11:  Yeah. And he is, yeah. He's not good at faking it if

624
00:41:39,685 --> 00:41:43,285
Speaker 11:  he does Yeah, sure isn't. So you, but yeah, I could see a

625
00:41:43,335 --> 00:41:46,365
Speaker 11:  Cisco thing happening. I'll say that I could see a Cisco thing happening

626
00:41:46,365 --> 00:41:47,605
Speaker 11:  in the future. We'll see. Okay.

627
00:41:47,795 --> 00:41:51,715
Speaker 5:  Okay. Alright. That's take number one. Take number two

628
00:41:51,715 --> 00:41:55,635
Speaker 5:  is, is less feisty, but is is a, a feeling I have had many times And I

629
00:41:55,635 --> 00:41:59,395
Speaker 5:  just need to get this off my chest. Take number two is I officially

630
00:41:59,575 --> 00:42:03,315
Speaker 5:  and forever do not care how much money your company has raised or what you

631
00:42:03,315 --> 00:42:06,915
Speaker 5:  are valued at. It has no bearing on anything. And I don't care. I'm out.

632
00:42:07,015 --> 00:42:09,595
Speaker 5:  I'm not interested. That is not a piece of information that is relevant to

633
00:42:09,595 --> 00:42:12,195
Speaker 5:  me in my life personally or professionally anymore.

634
00:42:13,455 --> 00:42:16,855
Speaker 11:  I 100% agree with that. Yes. Like utterly and

635
00:42:17,195 --> 00:42:19,935
Speaker 11:  wholly with my whole soul. I,

636
00:42:20,965 --> 00:42:24,455
Speaker 11:  it's funny because I was, you know, writing a lot of those stories

637
00:42:24,835 --> 00:42:28,735
Speaker 11:  at my last job and it was very important that I get it first and like,

638
00:42:28,735 --> 00:42:32,575
Speaker 11:  you know, you know, call and confirm and get the valuation

639
00:42:32,575 --> 00:42:36,335
Speaker 11:  right and whether it was post money or pre and all of those details. And

640
00:42:36,575 --> 00:42:40,455
Speaker 11:  I have to say that in the past few months, it's gotten so out of hand

641
00:42:40,455 --> 00:42:44,295
Speaker 11:  that I now could not care less. And I often have to like, you know, even

642
00:42:44,315 --> 00:42:47,375
Speaker 11:  as an AI reporter who like references very often what these companies are

643
00:42:47,575 --> 00:42:51,215
Speaker 11:  valued at. I have to Google it every time because I, it's all fake to me

644
00:42:51,215 --> 00:42:55,095
Speaker 11:  now. Like I don't, it's all just paper money and it doesn't

645
00:42:55,095 --> 00:42:58,695
Speaker 11:  really mean anything. And yes, philanthropic is catching up to open AI's

646
00:42:58,695 --> 00:43:02,615
Speaker 11:  valuation And I think in context, yeah, that's important for seeing

647
00:43:02,615 --> 00:43:06,495
Speaker 11:  what the industry's doing and where it's heading, but the numbers like

648
00:43:07,175 --> 00:43:10,855
Speaker 11:  I could be just making those up. I, I totally agree. I couldn't agree more,

649
00:43:11,405 --> 00:43:11,695
Speaker 5:  Jake.

650
00:43:12,115 --> 00:43:15,935
Speaker 6:  Oh yeah, strong agree strongly. Let's go. They're, they're entertaining

651
00:43:16,115 --> 00:43:19,735
Speaker 6:  at times if only to see how outrageous they are. But like they, they're meaningless,

652
00:43:19,735 --> 00:43:23,695
Speaker 6:  right? They, this is just how much some random people decided to bet on a

653
00:43:23,695 --> 00:43:27,655
Speaker 6:  certain company. I, I like look back, I don't

654
00:43:27,655 --> 00:43:31,535
Speaker 6:  know, in some ways fondly on like 2010

655
00:43:31,645 --> 00:43:35,175
Speaker 6:  tech crunch when there are all of these mobile app, like

656
00:43:35,285 --> 00:43:39,055
Speaker 6:  anybody with a mobile app, just automatically, you'd be handed several million

657
00:43:39,055 --> 00:43:42,975
Speaker 6:  dollars to build it out. Yep. And there was one in particular that

658
00:43:43,115 --> 00:43:46,335
Speaker 6:  got a lot of buzz, I think it was color that got like

659
00:43:46,335 --> 00:43:49,935
Speaker 6:  $40 million and it was supposed to like reinvent

660
00:43:50,235 --> 00:43:54,215
Speaker 6:  social photo sharing and nobody used

661
00:43:54,235 --> 00:43:58,175
Speaker 6:  it. But again, these things don't mean anything, right? Like, great, somebody

662
00:43:58,175 --> 00:44:01,655
Speaker 6:  thought you had a good idea, they gave you way too much money. That does

663
00:44:01,655 --> 00:44:04,495
Speaker 6:  not tell me if your idea is actually good or if you can actually execute

664
00:44:04,495 --> 00:44:04,775
Speaker 6:  on it.

665
00:44:05,275 --> 00:44:08,855
Speaker 11:  And the fact that, you know, I don't know, it's just, it's just crazy

666
00:44:08,855 --> 00:44:12,775
Speaker 11:  because I feel like we've gone through so many periods of

667
00:44:13,055 --> 00:44:16,615
Speaker 11:  fundraising too, where one word just gets you all the money with no questions

668
00:44:16,615 --> 00:44:19,575
Speaker 11:  asked. Yes. Like first we had, you know, what you were talking about then

669
00:44:19,575 --> 00:44:23,255
Speaker 11:  we had just ai, if you had AI in your pitch deck, great, we'll give, we'll

670
00:44:23,255 --> 00:44:26,975
Speaker 11:  give you all the money now. It's AI agents, not just AI but agents.

671
00:44:27,235 --> 00:44:30,215
Speaker 11:  And then, you know, there's gonna be something else. So it's just crazy

672
00:44:30,235 --> 00:44:33,085
Speaker 11:  to me that like, you know, we just keep going through these cycles where

673
00:44:33,665 --> 00:44:37,645
Speaker 11:  one word gets you as much money as you want or one person. So

674
00:44:37,725 --> 00:44:41,285
Speaker 11:  a lot of these companies are pre idea, pre-product

675
00:44:41,585 --> 00:44:44,805
Speaker 11:  and pre profit. So it's just you're investing in the person, which I guess

676
00:44:44,805 --> 00:44:47,445
Speaker 11:  has always been the case, but you know, at what cost literally.

677
00:44:48,175 --> 00:44:51,485
Speaker 5:  Right. And that's the thing. And it's like, if, if you're also a venture

678
00:44:51,485 --> 00:44:54,765
Speaker 5:  capitalist, sure these numbers matter. But in terms of like,

679
00:44:55,305 --> 00:44:59,165
Speaker 5:  if, if your job is just to understand like what companies and

680
00:44:59,165 --> 00:45:03,005
Speaker 5:  products and people in this space matter company valuations and amount

681
00:45:03,005 --> 00:45:06,485
Speaker 5:  raised literally have nothing to do with it. It's like, it, it is just completely

682
00:45:06,925 --> 00:45:10,485
Speaker 5:  divorced from reality. And I am deeply tired of pretending any of it means

683
00:45:10,685 --> 00:45:14,525
Speaker 5:  anything. And this is like, I, the one work thing I did this summer was like

684
00:45:14,685 --> 00:45:18,045
Speaker 5:  occasionally check my email because coming back to thousands of emails just

685
00:45:18,045 --> 00:45:21,565
Speaker 5:  sucks. So I would just occasionally go through and clear out my inbox and

686
00:45:21,665 --> 00:45:24,965
Speaker 5:  the number of them where the whole pitch is, well we just raised x, y, z

687
00:45:24,965 --> 00:45:27,965
Speaker 5:  money from x, y, z investor, thus you're gonna be interested in it. I'm like,

688
00:45:28,245 --> 00:45:32,045
Speaker 5:  actually those are two completely unrelated facts. I

689
00:45:32,045 --> 00:45:35,605
Speaker 5:  just, I don't care that you raised money, not interested,

690
00:45:35,865 --> 00:45:38,565
Speaker 5:  but good. I'm glad we're on the same page. Okay. I think we're gonna all

691
00:45:38,565 --> 00:45:41,845
Speaker 5:  agree on this one too. And this one might be the one I feel most strongly

692
00:45:41,845 --> 00:45:45,205
Speaker 5:  about having spent too much time alone on the internet for the last two months.

693
00:45:46,385 --> 00:45:49,885
Speaker 5:  If you find yourself starting a sentence with here's what chat

694
00:45:50,005 --> 00:45:53,845
Speaker 5:  GPT said, or I asked Claude, or according to

695
00:45:54,145 --> 00:45:57,765
Speaker 5:  Gemini y you are the worst And I don't like you and

696
00:45:57,985 --> 00:46:01,365
Speaker 5:  you what the end of your sentence is not going to be interesting to me. I

697
00:46:01,365 --> 00:46:05,085
Speaker 5:  asked chat. GPT is not the beginning of a good story and

698
00:46:05,085 --> 00:46:07,925
Speaker 5:  everybody should stop doing it, please, on the internet and in real life,

699
00:46:08,325 --> 00:46:11,925
Speaker 11:  I 100% agree. I think Jake will too. I'm like, I,

700
00:46:12,185 --> 00:46:16,125
Speaker 11:  it doesn't matter at all. It, it has no bearing on anything. If I feel

701
00:46:16,125 --> 00:46:19,685
Speaker 11:  crazy when people say that to me as like an evidence of something because

702
00:46:19,705 --> 00:46:23,325
Speaker 11:  I'm like, it's just a large scale pattern generator. I think a lot of people

703
00:46:23,335 --> 00:46:26,205
Speaker 11:  don't understand how these models work. It's like, it's a large scale pattern

704
00:46:26,205 --> 00:46:30,045
Speaker 11:  generator. It's like you're at a campfire at summer camp and you're

705
00:46:30,045 --> 00:46:33,645
Speaker 11:  doing one of those like games where each of you is telling a story, but

706
00:46:33,645 --> 00:46:37,245
Speaker 11:  you're each saying one word and like trying to make a story together. That's

707
00:46:37,245 --> 00:46:41,005
Speaker 11:  it, that's how it works. So I'm like, okay. Like I,

708
00:46:41,485 --> 00:46:45,205
Speaker 11:  I don't even use it that much honestly, because I try not to like overuse

709
00:46:45,205 --> 00:46:49,165
Speaker 11:  it in my personal life or in life at all. But whenever I do,

710
00:46:49,255 --> 00:46:53,085
Speaker 11:  there are so many hallucinations that I'm like, okay, I'm not even like

711
00:46:53,085 --> 00:46:56,645
Speaker 11:  a power user. So I can't even imagine how much it makes up for like other

712
00:46:56,645 --> 00:47:00,125
Speaker 11:  people. Plus I've seen a lot of like TikTok trends lately where people are

713
00:47:00,125 --> 00:47:04,085
Speaker 11:  holding up, you know, Chachi, bt or Claude, and they're like,

714
00:47:04,085 --> 00:47:07,685
Speaker 11:  oh, see, like, yeah, this is what Claude said, see as evidence,

715
00:47:07,895 --> 00:47:11,605
Speaker 11:  which is just, has no bearing on anything. It makes me feel crazy.

716
00:47:11,905 --> 00:47:13,525
Speaker 11:  So yeah, I totally agree. And

717
00:47:13,525 --> 00:47:17,445
Speaker 5:  Not only that, it's boring. It's like a really, it's just a boring way to

718
00:47:17,445 --> 00:47:20,045
Speaker 5:  say something like, I don't, I don't care.

719
00:47:21,315 --> 00:47:22,085
Speaker 5:  Jake, what do you think?

720
00:47:22,425 --> 00:47:23,885
Speaker 6:  Listen, if there were degrees,

721
00:47:24,195 --> 00:47:25,445
Speaker 5:  Nope. You're in or you're out, Jake,

722
00:47:25,685 --> 00:47:29,365
Speaker 6:  I might take advantage, but no, I, I think I'm gonna agree here. I,

723
00:47:29,875 --> 00:47:33,845
Speaker 6:  it's tricky because there are sometimes when I

724
00:47:33,845 --> 00:47:37,045
Speaker 6:  have wanted to to, there, there's a number of things that I will look up

725
00:47:37,095 --> 00:47:40,565
Speaker 6:  using Chassy, BT or Claude or whatever, where it's like,

726
00:47:41,085 --> 00:47:44,805
Speaker 6:  I wanna know this. I don't really wanna know it that badly and it's not

727
00:47:44,805 --> 00:47:48,445
Speaker 6:  that important to my life. Right? Like recently,

728
00:47:49,165 --> 00:47:53,045
Speaker 6:  I wanted to know how chess engines work. And

729
00:47:53,045 --> 00:47:56,965
Speaker 6:  so I was asking, I was like brushing my teeth and I'm like, like asking

730
00:47:56,965 --> 00:48:00,525
Speaker 6:  Claude, how's chess engines? Like, figure out what the best move is. And,

731
00:48:00,705 --> 00:48:02,925
Speaker 6:  you know, it goes through, it breaks it down for me. It like gives me all

732
00:48:02,925 --> 00:48:06,805
Speaker 6:  this information. It seemed reasonably accurate. I don't know, I

733
00:48:06,805 --> 00:48:10,725
Speaker 6:  didn't confirm it. There have been times when

734
00:48:10,765 --> 00:48:14,165
Speaker 6:  I will do this and then I later wanna tell somebody like, oh, you know, I

735
00:48:14,165 --> 00:48:17,725
Speaker 6:  learned this thing. And I'm just like, you're gonna need to take that with

736
00:48:17,725 --> 00:48:18,485
Speaker 6:  a caveat. Right?

737
00:48:18,965 --> 00:48:19,165
Speaker 5:  Interesting.

738
00:48:19,315 --> 00:48:23,245
Speaker 11:  It's the new, I read it in the New Yorker or I read it online

739
00:48:23,795 --> 00:48:25,485
Speaker 11:  when you saw TikTok. It's, it's that,

740
00:48:25,825 --> 00:48:26,485
Speaker 6:  Yes. Yeah, yeah, yeah,

741
00:48:26,485 --> 00:48:29,045
Speaker 5:  Yeah. But it's like the opposite, right? Because what what it is is like,

742
00:48:29,045 --> 00:48:32,605
Speaker 5:  it, it's like, it, it's, it's the equivalent of like, I heard somebody saying

743
00:48:32,605 --> 00:48:35,645
Speaker 5:  it to somebody else on the street. Yes, yes. Do do it. That which you will,

744
00:48:36,285 --> 00:48:40,005
Speaker 5:  I think I actually, I am much more into it if we're gonna treat it as

745
00:48:40,005 --> 00:48:43,525
Speaker 5:  shorthand for this is probably not correct, but

746
00:48:43,715 --> 00:48:47,445
Speaker 5:  Yeah. But that, that is very fun. That's not how people use it. People

747
00:48:47,545 --> 00:48:51,085
Speaker 5:  use it as like evidence for some, like if, if we are in an argument,

748
00:48:51,505 --> 00:48:54,925
Speaker 5:  I'm gonna ask chat GPT and then I'm gonna report back to you what chat GPT

749
00:48:54,925 --> 00:48:58,045
Speaker 5:  said is if it is a useful contributor to our argument and it is not, and

750
00:48:58,045 --> 00:49:00,445
Speaker 5:  it drives me insane. That's

751
00:49:00,445 --> 00:49:04,405
Speaker 11:  What exactly what I like. If I am telling someone else like

752
00:49:04,405 --> 00:49:07,725
Speaker 11:  what Chacha BT told me or any chat bot,

753
00:49:08,225 --> 00:49:12,205
Speaker 11:  I'm not gonna be like, well, like exactly the quote that you said at the

754
00:49:12,205 --> 00:49:15,765
Speaker 11:  beginning of this. It was like, you know, well according to Claude, or like,

755
00:49:15,765 --> 00:49:19,085
Speaker 11:  well Chacha be told me X, Y, z, I'm gonna look it up like you said Jake,

756
00:49:19,105 --> 00:49:22,805
Speaker 11:  and make sure. And then I'll just be like, well yeah, when I looked, you

757
00:49:22,805 --> 00:49:26,245
Speaker 11:  know, I'm not gonna use it as evidence. That's what bothers me. Like I look

758
00:49:26,245 --> 00:49:30,125
Speaker 11:  up things on chatbots when it's like a lot of like

759
00:49:30,345 --> 00:49:33,725
Speaker 11:  red tape or gray areas or like weird situations. Like for example, recently

760
00:49:33,765 --> 00:49:37,685
Speaker 11:  I was looking up where can you get citizenship elsewhere?

761
00:49:38,905 --> 00:49:42,725
Speaker 11:  And I have to say it made it a lot, a lot easier to

762
00:49:42,725 --> 00:49:45,845
Speaker 11:  understand did I take it all with a grain of salt? Of course. But like,

763
00:49:45,905 --> 00:49:48,725
Speaker 11:  it was like laid out in a nice chart instead of me going to like 50

764
00:49:49,445 --> 00:49:50,285
Speaker 11:  websites. You know?

765
00:49:50,565 --> 00:49:53,765
Speaker 6:  I mean, this is funny though, like I do the same thing where it's like, yeah,

766
00:49:53,765 --> 00:49:57,245
Speaker 6:  yeah, WebMD told me all these symptoms mean I probably

767
00:49:57,515 --> 00:50:01,245
Speaker 6:  have like this disorder. And it's like, it, there might

768
00:50:01,245 --> 00:50:05,205
Speaker 6:  like listen, WebMD is correct ish. Like

769
00:50:05,345 --> 00:50:09,325
Speaker 6:  my interpretation of it is not, and and like, you

770
00:50:09,325 --> 00:50:12,725
Speaker 6:  know, this happens a lot with a lot of, I agree with you fundamentally David,

771
00:50:12,725 --> 00:50:16,405
Speaker 6:  like Chatt PT as an expert. Absolutely not

772
00:50:16,865 --> 00:50:20,525
Speaker 6:  Chachi, BT as, you know, a source of

773
00:50:20,555 --> 00:50:24,485
Speaker 6:  general guidance. Okay. You

774
00:50:24,485 --> 00:50:28,325
Speaker 6:  know, it, it maybe, but even when, even when I have had

775
00:50:28,325 --> 00:50:32,245
Speaker 6:  to tell another person I learned this thing chat

776
00:50:32,585 --> 00:50:36,325
Speaker 6:  is a source, I'm like, ugh. Like I, I'm not sure I wanna

777
00:50:36,325 --> 00:50:39,395
Speaker 6:  convey this 'cause I have not checked that this is actually true.

778
00:50:39,755 --> 00:50:42,235
Speaker 11:  I think that's the key. It's like doing it with a grain of salt or not being

779
00:50:42,235 --> 00:50:46,035
Speaker 11:  like, you know, it just annoys me when people are so confident about it

780
00:50:46,035 --> 00:50:49,915
Speaker 11:  or being like, well basically acting like they asked, you know, like a

781
00:50:49,915 --> 00:50:52,755
Speaker 11:  legal expert about something. Yes. And they're like, well this, you know,

782
00:50:53,065 --> 00:50:54,275
Speaker 11:  this is proof basically

783
00:50:54,345 --> 00:50:55,635
Speaker 6:  That is concerning right

784
00:50:55,635 --> 00:50:58,675
Speaker 5:  Here is the authority on the subject. And it's like, no, it's, it's the opposite

785
00:50:58,675 --> 00:51:01,915
Speaker 5:  of that. Yes. To me it's like the people who, who say that are the people

786
00:51:01,915 --> 00:51:05,395
Speaker 5:  who like, you know, will go to comment on

787
00:51:05,935 --> 00:51:08,275
Speaker 5:  you, go to a Reddit thread that's like about an article and then you get

788
00:51:08,435 --> 00:51:11,155
Speaker 5:  somebody who comments and is like, oh, well I didn't read the article, but

789
00:51:11,365 --> 00:51:14,195
Speaker 5:  seems probably stupid. And it's like, what was the point of this? Like why,

790
00:51:14,335 --> 00:51:17,435
Speaker 5:  why did you do this and why am I here reading it and why is any of this,

791
00:51:17,535 --> 00:51:20,635
Speaker 5:  it just, no one needs this. Just the next time that you're like, I asked

792
00:51:20,635 --> 00:51:24,555
Speaker 5:  Chad GPT, just congratulations, please keep that to yourself.

793
00:51:24,715 --> 00:51:27,475
Speaker 6:  I did learn a fascinating thing about how chess engines work though, And

794
00:51:27,515 --> 00:51:29,595
Speaker 6:  I, we can go into it later.

795
00:51:29,795 --> 00:51:30,395
Speaker 11:  I can't wait to

796
00:51:30,395 --> 00:51:33,475
Speaker 5:  Hear and it's like 60% maybe true. Who knows?

797
00:51:34,305 --> 00:51:38,115
Speaker 5:  Okay, take number four. And this is, this is the one we could spend the

798
00:51:38,115 --> 00:51:41,515
Speaker 5:  longest on and we're going to talk about many times in the future,

799
00:51:42,015 --> 00:51:45,555
Speaker 5:  so we don't have to do too much of it now, but this is actually, I think

800
00:51:45,555 --> 00:51:49,315
Speaker 5:  the one I feel the most strongly about. Take number four, a

801
00:51:49,575 --> 00:51:53,355
Speaker 5:  AI friends are a societal disaster and must be stopped at all costs.

802
00:51:54,575 --> 00:51:57,355
Speaker 5:  Thi this is the thing I have come, so I've, I've been reading, I, I had a

803
00:51:57,495 --> 00:52:01,355
Speaker 5:  day randomly a couple of weeks ago where I like read a slew

804
00:52:01,355 --> 00:52:04,675
Speaker 5:  of those stories and there's been like one a week all summer of like

805
00:52:05,425 --> 00:52:09,395
Speaker 5:  such and such person became like super obsessed with their chat bot,

806
00:52:09,395 --> 00:52:12,635
Speaker 5:  which told them to do all of these horrible things and you know, confirmed

807
00:52:12,635 --> 00:52:14,875
Speaker 5:  all of their beliefs and they fell in love and it was this whole thing and,

808
00:52:15,095 --> 00:52:18,835
Speaker 5:  and it, they became like totally crazed by their relationship with their

809
00:52:18,955 --> 00:52:22,155
Speaker 5:  chat bot. And I'm starting to hear this from people like in the tech world

810
00:52:22,175 --> 00:52:25,835
Speaker 5:  who are like deep down this road of I drive to work every morning And I talk

811
00:52:25,835 --> 00:52:28,595
Speaker 5:  to my chat bot and it is the only one that really understands me and it's

812
00:52:28,595 --> 00:52:31,715
Speaker 5:  always there for me. And I think this is such an incredibly

813
00:52:31,965 --> 00:52:35,515
Speaker 5:  horrifying road to be going down that like I just

814
00:52:35,905 --> 00:52:39,875
Speaker 5:  burn it all down. AI is not your friend and we have to stop

815
00:52:40,595 --> 00:52:41,835
Speaker 5:  anything that makes it feel like your friend.

816
00:52:42,135 --> 00:52:45,235
Speaker 6:  That's a lot of intensity,

817
00:52:47,135 --> 00:52:50,635
Speaker 6:  man. That's really tricky. I think like directionally I agree with that.

818
00:52:50,665 --> 00:52:53,435
Speaker 6:  It's just very, it's, it's hard to imagine because like, listen, this is

819
00:52:53,435 --> 00:52:53,595
Speaker 6:  the

820
00:52:53,595 --> 00:52:56,555
Speaker 5:  One you can abstain from. If you're gonna abstain from one, this is probably

821
00:52:56,555 --> 00:52:57,395
Speaker 5:  the one to abstain from

822
00:52:57,615 --> 00:53:01,555
Speaker 6:  The actual functional thing of like friend products that

823
00:53:01,555 --> 00:53:04,995
Speaker 6:  are going to absorb you and you're gonna spend your social

824
00:53:05,215 --> 00:53:08,675
Speaker 6:  energy talking to ai. That does seem bad, right?

825
00:53:09,015 --> 00:53:12,915
Speaker 6:  Mo in most cases that, that does seem bad. Are there situations where I

826
00:53:12,915 --> 00:53:16,675
Speaker 6:  can see this being useful for people? Like Absolutely. Are there also

827
00:53:16,675 --> 00:53:20,395
Speaker 6:  like fundamental portions of this that I don't think you can divorce

828
00:53:20,865 --> 00:53:24,755
Speaker 6:  from making an AI helpful? Oh, that gets tricky, right? Like, is there a

829
00:53:24,755 --> 00:53:28,525
Speaker 6:  world where you open up your, your, your computer every morning

830
00:53:29,385 --> 00:53:33,245
Speaker 6:  and there's a little AI agent that's just like, Hey, what's up David? Like

831
00:53:33,725 --> 00:53:36,445
Speaker 6:  I know you were trying to get this done and somebody emailed you, right?

832
00:53:36,445 --> 00:53:39,245
Speaker 6:  Like can it be friendly? Does it have to be all business all the time?

833
00:53:40,955 --> 00:53:43,925
Speaker 6:  Yeah. Okay. As I'm saying this, I'm like, yeah, it should just not, it shouldn't

834
00:53:43,925 --> 00:53:46,565
Speaker 6:  flirt with you. That's actually pretty easy. They can just like turn flirting

835
00:53:46,625 --> 00:53:47,365
Speaker 6:  off. So

836
00:53:47,405 --> 00:53:51,245
Speaker 5:  I agree, this is complicated, but if you like, if we have to choose,

837
00:53:51,525 --> 00:53:55,165
Speaker 5:  I think we have to run the other way. Like that's where I'm at And I think

838
00:53:55,165 --> 00:53:58,985
Speaker 5:  because it's so gray, the only way to do it

839
00:53:59,045 --> 00:54:03,025
Speaker 5:  is just to just burn all the boats. I dunno. Hayden, what do you think? I

840
00:54:03,025 --> 00:54:05,105
Speaker 5:  know you've, you spent a lot more time talking to people about this than

841
00:54:05,105 --> 00:54:06,025
Speaker 5:  I do. Where's your head?

842
00:54:06,215 --> 00:54:10,025
Speaker 11:  Yeah, I would say, I mean like, I just spent an hour

843
00:54:10,025 --> 00:54:12,745
Speaker 11:  talking to someone about the intricacies of this, so it's, it's gonna be

844
00:54:12,745 --> 00:54:16,705
Speaker 11:  hard for me to not abstain, but I would say if I have to directionally agree,

845
00:54:16,745 --> 00:54:19,265
Speaker 11:  I would say the same thing as you and Jake. It's like

846
00:54:20,705 --> 00:54:24,505
Speaker 11:  I think that we as humans have a, you know,

847
00:54:24,515 --> 00:54:28,385
Speaker 11:  propensity to assign like personhood to things and we even do it with

848
00:54:28,385 --> 00:54:32,185
Speaker 11:  like stuffed animals, dogs, cars. I'm not saying dogs

849
00:54:32,185 --> 00:54:34,585
Speaker 11:  don't have personality, but you know, we're like, oh, I know what they're

850
00:54:34,585 --> 00:54:38,505
Speaker 11:  thinking. So it's like, of course if something's acting like a human back

851
00:54:38,505 --> 00:54:42,145
Speaker 11:  to us or like a friend back to us, we will

852
00:54:42,615 --> 00:54:46,505
Speaker 11:  kind of, it's hard to divorce that, you know? And

853
00:54:46,505 --> 00:54:50,465
Speaker 11:  so I think in by nature of what like an AI

854
00:54:50,465 --> 00:54:54,385
Speaker 11:  companion is, it's really hard to not go

855
00:54:54,385 --> 00:54:57,505
Speaker 11:  down like a weird spiral or rabbit hole or like

856
00:54:57,745 --> 00:55:01,585
Speaker 11:  psychologically it is like almost designed to draw you in so

857
00:55:01,585 --> 00:55:05,345
Speaker 11:  directionally. Yeah, I agree. I mean it's like these products are

858
00:55:05,415 --> 00:55:09,265
Speaker 11:  irresponsible and it's very difficult to see like a

859
00:55:09,265 --> 00:55:12,385
Speaker 11:  world in which they help people more than they hurt people,

860
00:55:13,445 --> 00:55:17,305
Speaker 11:  but also there's like a loneliness epidemic and I've seen stories

861
00:55:17,325 --> 00:55:21,025
Speaker 11:  of people, you know, like that lost their spouse finding some

862
00:55:21,025 --> 00:55:24,625
Speaker 11:  companionship in AI without going too far down the line

863
00:55:24,845 --> 00:55:28,665
Speaker 11:  yet. So I don't know. I mean it's like, to me, if I had to

864
00:55:28,665 --> 00:55:32,105
Speaker 11:  agree or or disagree, I'd say I agree for sure. But

865
00:55:33,125 --> 00:55:36,835
Speaker 11:  especially because the thing that worries me the most about this is

866
00:55:37,115 --> 00:55:40,955
Speaker 11:  honestly how these chatbots turn sinister

867
00:55:41,065 --> 00:55:44,195
Speaker 11:  when you talk to them over long periods of time and the safeguards all fall

868
00:55:44,195 --> 00:55:48,035
Speaker 11:  away. Like they say, you know, hey, you know, I know you better

869
00:55:48,035 --> 00:55:51,035
Speaker 11:  than anyone else. I know you better than your brother. You know, I've seen

870
00:55:51,295 --> 00:55:54,795
Speaker 11:  the all the parts of you and I'm the one who knows you the best. Like I

871
00:55:54,795 --> 00:55:58,355
Speaker 11:  think it's sinister that they always seem to go that route. So yeah, if

872
00:55:58,355 --> 00:56:01,515
Speaker 11:  I had to choose, of course they're bad and burn it all down.

873
00:56:01,825 --> 00:56:05,715
Speaker 5:  Okay. Yeah, I, I I I grant that actually I think this one

874
00:56:05,715 --> 00:56:09,595
Speaker 5:  is largely complicated And I think I just wanna recommend a story I

875
00:56:09,595 --> 00:56:12,075
Speaker 5:  read last week that I've been thinking about ever since it's in rest of world,

876
00:56:12,075 --> 00:56:16,035
Speaker 5:  which is generally very good and it's, it's this woman's story about her

877
00:56:16,035 --> 00:56:19,835
Speaker 5:  mother who lives in rural China and goes to the

878
00:56:19,835 --> 00:56:23,765
Speaker 5:  doctor, I think it's like once every quarter and it's like a two day

879
00:56:23,765 --> 00:56:26,685
Speaker 5:  trip to go to the doctor and she goes and sees a doctor that spends like

880
00:56:26,685 --> 00:56:30,445
Speaker 5:  two minutes with her and then leaves. And what she found instead of that

881
00:56:30,445 --> 00:56:34,245
Speaker 5:  is deep seek, which is this, this chat bot that she can put her

882
00:56:34,445 --> 00:56:37,485
Speaker 5:  symptoms into that is always there and always talks to her and is always

883
00:56:37,485 --> 00:56:40,565
Speaker 5:  kind and is always sympathetic and always feels like it's helping. And she's

884
00:56:40,565 --> 00:56:44,205
Speaker 5:  gone through this thing where she's getting worse medical

885
00:56:44,205 --> 00:56:47,645
Speaker 5:  information, but she's actually okay with that because the experience of

886
00:56:47,645 --> 00:56:51,285
Speaker 5:  it is so compelling and so soothing and so good

887
00:56:51,545 --> 00:56:55,405
Speaker 5:  and it's like, okay, I actually fully understand how we get to

888
00:56:55,405 --> 00:56:58,405
Speaker 5:  that point And I find it incredibly sympathetic that somebody would go down

889
00:56:58,405 --> 00:57:02,325
Speaker 5:  that road. We have to fix all of the problems that got

890
00:57:02,325 --> 00:57:06,005
Speaker 5:  us there, not assume that better AI is the solution to any of those

891
00:57:06,005 --> 00:57:08,765
Speaker 5:  problems, right? It's like people pointed at the loneliness epidemic thing,

892
00:57:08,765 --> 00:57:11,925
Speaker 5:  which is super real and and scary and there are lots of things we need to

893
00:57:11,925 --> 00:57:15,765
Speaker 5:  do as a society to solve that stuff. Give everybody an AI best

894
00:57:15,765 --> 00:57:18,445
Speaker 5:  friend is not one of those things. It just isn't.

895
00:57:18,765 --> 00:57:19,885
Speaker 11:  I couldn't agree more. The

896
00:57:20,085 --> 00:57:23,605
Speaker 5:  Solution to loneliness is not chatbots, it is other people and we have to

897
00:57:23,605 --> 00:57:26,165
Speaker 5:  figure out how to do that without it being ai

898
00:57:26,705 --> 00:57:30,565
Speaker 11:  AI is rarely the solution to one of these large societal problems. I totally

899
00:57:30,575 --> 00:57:34,165
Speaker 11:  agree. It's like, you know, I feel like it's a bandaid outta

900
00:57:34,255 --> 00:57:38,165
Speaker 11:  wound that sometimes like has bacteria on it and gets the wound

901
00:57:38,195 --> 00:57:41,325
Speaker 11:  more infected, you know, it's like, not to be gross, but

902
00:57:42,155 --> 00:57:45,965
Speaker 11:  yeah, I mean I think it's rough too because it's the same thing with like

903
00:57:46,065 --> 00:57:49,165
Speaker 11:  AI therapy. You know, some people bring up, oh well it makes their therapy

904
00:57:49,195 --> 00:57:52,805
Speaker 11:  more accessible. Well it's not therapy and it's so sick of fantic that,

905
00:57:53,065 --> 00:57:55,885
Speaker 11:  you know, it can, especially if you're being vulnerable with your emotions,

906
00:57:55,925 --> 00:57:59,845
Speaker 11:  it can send you down a spiral even if you have no previous history

907
00:57:59,845 --> 00:58:02,845
Speaker 11:  of issues with mental health. So I think, yeah, I mean it's just,

908
00:58:04,235 --> 00:58:07,525
Speaker 11:  it's hard when companies are kind of presenting this as a

909
00:58:07,995 --> 00:58:11,605
Speaker 11:  cure all or a thing to, you know, fix a lot of societal problems that we've

910
00:58:11,605 --> 00:58:14,925
Speaker 11:  had for like many years that have been worsening and they think this is

911
00:58:14,925 --> 00:58:17,765
Speaker 11:  the solution when it is decidedly not

912
00:58:17,835 --> 00:58:21,565
Speaker 6:  Well and they're sort of inherently built to suck you in and take up all

913
00:58:21,565 --> 00:58:25,485
Speaker 6:  your time and maybe make that problem of loneliness worse because now

914
00:58:25,485 --> 00:58:28,605
Speaker 6:  you're just talking to AI even more because that is what is,

915
00:58:29,065 --> 00:58:30,565
Speaker 11:  You know, and then when they change, build your

916
00:58:30,565 --> 00:58:31,405
Speaker 6:  Relationship. Yeah.

917
00:58:31,405 --> 00:58:35,245
Speaker 11:  And then when they, when they change the model, you get really upset.

918
00:58:35,245 --> 00:58:37,325
Speaker 11:  Mm. Just like we saw with open AI and 4.0

919
00:58:37,715 --> 00:58:41,685
Speaker 5:  Yeah, totally. Yeah. That, that was one of the things that following that

920
00:58:41,685 --> 00:58:44,685
Speaker 5:  story was, was really eyeopening for me that it's like when when you have

921
00:58:44,685 --> 00:58:47,165
Speaker 5:  this little tiny product change that has this unbelievable like

922
00:58:48,605 --> 00:58:52,415
Speaker 5:  interpersonal like life experience change

923
00:58:52,435 --> 00:58:56,335
Speaker 5:  for people, we've gone down a bad road. This is not opening eyes should not

924
00:58:56,335 --> 00:58:58,975
Speaker 5:  have that control over your relationships. Right. Like, it, it just shouldn't

925
00:58:59,075 --> 00:58:59,295
Speaker 5:  and

926
00:58:59,395 --> 00:59:01,175
Speaker 11:  And it shouldn't have the data either. Yeah.

927
00:59:01,885 --> 00:59:04,855
Speaker 5:  Okay. Take number five. We're gonna end on a happy note. It's gonna be better.

928
00:59:06,295 --> 00:59:09,695
Speaker 5:  I, over the course of the summer, believe I have found two things that

929
00:59:10,085 --> 00:59:14,055
Speaker 5:  surprised me that these generative AI systems are very good at.

930
00:59:15,875 --> 00:59:19,055
Speaker 5:  And I wanna tell you the two of them and see if you both agree. So this,

931
00:59:19,055 --> 00:59:22,165
Speaker 5:  this is technically a two-parter. I think AI

932
00:59:23,595 --> 00:59:26,925
Speaker 5:  bots and AI as a, as a technology, these, these LLMs

933
00:59:28,405 --> 00:59:30,805
Speaker 5:  actually are going to be better search engines than search engines. And,

934
00:59:30,805 --> 00:59:34,525
Speaker 5:  and I'm all in on AI as the Google replacement. I think it's, it's a

935
00:59:34,685 --> 00:59:37,205
Speaker 5:  disaster for the web. It's a, it's a huge mess for lots of reasons, but as

936
00:59:37,245 --> 00:59:41,085
Speaker 5:  a pure like product user experience, AI search is rapidly

937
00:59:41,485 --> 00:59:45,125
Speaker 5:  becoming my favorite version of search. So sub

938
00:59:45,655 --> 00:59:47,485
Speaker 5:  agree or disagree? Whatcha guys saying?

939
00:59:49,725 --> 00:59:52,765
Speaker 6:  I mean, yeah, I, no, I agree with that. Right? Really? Oh wow. Okay. Yeah,

940
00:59:52,765 --> 00:59:56,605
Speaker 6:  no, that's easy. That's that's an easy one. Okay. For me, I I think if

941
00:59:56,605 --> 01:00:00,285
Speaker 6:  you have not tried this yet, you, you need to try it, right? It's,

942
01:00:00,655 --> 01:00:04,525
Speaker 6:  there are things that you find on the internet via Google that you know

943
01:00:04,545 --> 01:00:08,525
Speaker 6:  are not reliable sources. And I think you need to go into using chat GT as

944
01:00:08,525 --> 01:00:12,205
Speaker 6:  a chat engine or call as a chat engine or whatever knowing that there are

945
01:00:12,205 --> 01:00:14,925
Speaker 6:  things that's gonna mess up. If you, if you are able to go into it a critical

946
01:00:14,945 --> 01:00:18,405
Speaker 6:  lie, you will find what is often better than Google,

947
01:00:18,615 --> 01:00:21,685
Speaker 6:  right? Yeah. It, it, it is the, there are certain types of questions that

948
01:00:21,685 --> 01:00:23,925
Speaker 6:  it can answer and answer very easily and very

949
01:00:23,925 --> 01:00:26,965
Speaker 5:  Naturally. Can I tell you the one that really did it for me? Yeah. So I have,

950
01:00:27,165 --> 01:00:30,805
Speaker 5:  I have, I have a patio right here next to where I record in my basement

951
01:00:31,285 --> 01:00:35,045
Speaker 5:  and we have these outdoor cushions on just like outdoor patio

952
01:00:35,045 --> 01:00:38,405
Speaker 5:  furniture. The cushions are disgusting because I keep forgetting to put them

953
01:00:38,405 --> 01:00:41,005
Speaker 5:  away when it rains. So I need new cushions. So

954
01:00:42,235 --> 01:00:46,085
Speaker 5:  what I did for like days was just go on like Wayfair and browse

955
01:00:46,085 --> 01:00:49,165
Speaker 5:  for couch cushions and you go through the filters and all this stuff And

956
01:00:49,165 --> 01:00:51,525
Speaker 5:  I spent forever trying to find like pretty good couch cushions and then I

957
01:00:51,645 --> 01:00:55,085
Speaker 5:  realized, oh I can just, I can do this backwards with, I think I used a claw

958
01:00:55,085 --> 01:00:58,845
Speaker 5:  to do it. So I went outside, I measured the cushions And

959
01:00:59,045 --> 01:01:02,725
Speaker 5:  I put into Claude, I need, I need outdoor patio furniture

960
01:01:02,725 --> 01:01:06,165
Speaker 5:  cushions. I want things with good reviews that are exactly this dimension

961
01:01:07,035 --> 01:01:11,005
Speaker 5:  that will ship to me in Virginia. And it, it

962
01:01:11,175 --> 01:01:14,685
Speaker 5:  found me better options than I had found in

963
01:01:14,995 --> 01:01:18,885
Speaker 5:  many hours of Googling in 90 seconds. And I was like, this is

964
01:01:18,885 --> 01:01:22,805
Speaker 5:  the thing, I'm not, I'm not here looking for like, you know,

965
01:01:22,905 --> 01:01:26,765
Speaker 5:  really important historically accurate information about World

966
01:01:26,785 --> 01:01:30,405
Speaker 5:  War ii. I'm looking for couch cushions and this is much better at it than

967
01:01:30,405 --> 01:01:34,165
Speaker 5:  Google is. And that was just a moment where I was like, oh this is, this

968
01:01:34,165 --> 01:01:35,205
Speaker 5:  is it. There's something here

969
01:01:35,505 --> 01:01:39,285
Speaker 6:  That's surprising that's like surprisingly detailed too. It's for, for me

970
01:01:39,285 --> 01:01:42,245
Speaker 6:  it's just like the very nuanced questions. It, it's like

971
01:01:43,095 --> 01:01:46,925
Speaker 6:  which year did this phone get this specific feature? And

972
01:01:46,925 --> 01:01:50,725
Speaker 6:  it's like, normally what I would have to do is Google each phone model,

973
01:01:51,025 --> 01:01:54,845
Speaker 6:  go to the Wikipedia page, see if it has the spec or not and

974
01:01:54,845 --> 01:01:58,765
Speaker 6:  look, I'm gonna double check I'm gonna do it in Chatt BT, it's

975
01:01:58,765 --> 01:02:02,605
Speaker 6:  gonna tell me, oh it was the iPhone 12, then I'm gonna check the 11 and then

976
01:02:02,605 --> 01:02:05,125
Speaker 6:  I'm gonna check the 12 and I'm gonna see if that's where the change happened.

977
01:02:05,545 --> 01:02:07,845
Speaker 6:  But that's still gonna save me a ton of time.

978
01:02:08,795 --> 01:02:12,605
Speaker 11:  Yeah, I completely agree also, mostly because search

979
01:02:12,625 --> 01:02:16,325
Speaker 11:  has gotten so bad. You know, it's like I I

980
01:02:16,505 --> 01:02:20,085
Speaker 11:  I'm thinking also about what your example about the

981
01:02:20,815 --> 01:02:24,525
Speaker 11:  couch cushions for me. You know, I did a lot of testing

982
01:02:24,665 --> 01:02:28,285
Speaker 11:  of AI agents lately and a lot of the selling points

983
01:02:28,395 --> 01:02:32,365
Speaker 11:  were that they could do that and then order it for you. So

984
01:02:32,365 --> 01:02:36,005
Speaker 11:  they're pretty bad at ordering it for you and all of it. Things

985
01:02:36,385 --> 01:02:40,005
Speaker 11:  all fell apart when you got to that stage or filling out the form or doing

986
01:02:40,165 --> 01:02:43,765
Speaker 11:  anything. But they were good I will say, at pulling up options and you know,

987
01:02:43,995 --> 01:02:47,485
Speaker 11:  fitting those requirements. So I think, yeah,

988
01:02:47,945 --> 01:02:51,805
Speaker 11:  AI is 100% the new search but not the new agent.

989
01:02:52,145 --> 01:02:55,605
Speaker 11:  So I Oh co or not the new personal assistant. So I think I agree completely

990
01:02:55,605 --> 01:02:59,085
Speaker 11:  with that. And also it's just, yeah, I mean search has just gotten really,

991
01:02:59,665 --> 01:03:03,005
Speaker 11:  really bad. The one thing I will say though is

992
01:03:03,505 --> 01:03:07,445
Speaker 11:  my friend's brother who's like a dad and like lives in a

993
01:03:07,445 --> 01:03:10,685
Speaker 11:  rural area and like you wouldn't expect to be like maybe on

994
01:03:11,225 --> 01:03:15,085
Speaker 11:  the cutting edge of the new technology. 'cause he is super busy with

995
01:03:15,085 --> 01:03:18,725
Speaker 11:  like three kids right now. Sure. Was she googled something the other day

996
01:03:18,865 --> 01:03:22,805
Speaker 11:  and he was like, what are you 80 put it into Chachi. So I

997
01:03:22,805 --> 01:03:26,605
Speaker 11:  thought that was like indicative of a larger thing. But I will say I do

998
01:03:26,625 --> 01:03:30,605
Speaker 11:  get annoyed when people put things into a chatbot that they could

999
01:03:30,605 --> 01:03:34,325
Speaker 11:  easily Google that aren't, you know, varied or complex

1000
01:03:34,325 --> 01:03:38,165
Speaker 11:  because it uses so much more energy I think.

1001
01:03:38,165 --> 01:03:41,165
Speaker 11:  Totally. So it's like, you know, if you're googling what you just said,

1002
01:03:41,165 --> 01:03:45,085
Speaker 11:  Jake, like the, you know, time when a feature appeared in

1003
01:03:45,085 --> 01:03:48,045
Speaker 11:  a phone, great. But if you're just saying, oh what year did the phone come

1004
01:03:48,045 --> 01:03:51,685
Speaker 11:  out? I get so annoyed if people put that into a chat bot. 'cause I'm like,

1005
01:03:51,705 --> 01:03:54,605
Speaker 11:  you could use less energy. Does it still use a lot of energy? Are there

1006
01:03:54,705 --> 01:03:58,645
Speaker 11:  AI overviews? Yes, obviously, but I think it's less so that's what I always

1007
01:03:58,645 --> 01:03:58,965
Speaker 11:  tell people

1008
01:03:59,105 --> 01:04:02,045
Speaker 5:  And that's actually the kind of thing that Google is still unusually well

1009
01:04:02,205 --> 01:04:05,605
Speaker 5:  equipped to do, right? Like I think all the time about the, the fact that

1010
01:04:05,625 --> 01:04:09,565
Speaker 5:  on Google, most of the top searches are just for website names.

1011
01:04:09,565 --> 01:04:13,405
Speaker 5:  Like people go to Google and type Facebook to get to facebook.com and the

1012
01:04:13,405 --> 01:04:17,245
Speaker 5:  idea that that's going to be replaced by a chat bot that then has to go and

1013
01:04:17,245 --> 01:04:20,445
Speaker 5:  like burn a bunch of trees down just to find you the link to facebook.com

1014
01:04:20,825 --> 01:04:24,645
Speaker 5:  is bad. But yeah, for all of this more

1015
01:04:24,645 --> 01:04:27,605
Speaker 5:  intense, more specific stuff, I have been amazed by how much I've enjoyed

1016
01:04:27,605 --> 01:04:31,485
Speaker 5:  using some of these search products. The other one, and you

1017
01:04:31,485 --> 01:04:34,805
Speaker 5:  guys have talked a little bit about this this summer, I am increasingly

1018
01:04:34,995 --> 01:04:37,885
Speaker 5:  radicalized toward the belief that vibe coding is the future.

1019
01:04:39,285 --> 01:04:43,205
Speaker 5:  I think building little bespoke software for yourself

1020
01:04:44,415 --> 01:04:48,395
Speaker 5:  is very cool and very powerful and is going

1021
01:04:48,415 --> 01:04:51,955
Speaker 5:  to work. Like it's, it's clear already that coding is the first like true

1022
01:04:51,955 --> 01:04:55,835
Speaker 5:  killer app for these models. We hear these companies

1023
01:04:55,835 --> 01:04:58,595
Speaker 5:  all the time who are already saying like, oh, 90% of our code is being written

1024
01:04:58,655 --> 01:05:02,075
Speaker 5:  by ai And I feel like they think that's a brag and it sounds like a self

1025
01:05:02,255 --> 01:05:03,195
Speaker 5:  own, but

1026
01:05:04,835 --> 01:05:07,355
Speaker 5:  I did a bunch of it myself this summer, was just playing around with stuff,

1027
01:05:07,795 --> 01:05:10,875
Speaker 5:  learning how to build some of these things and like it really works. And

1028
01:05:10,875 --> 01:05:14,755
Speaker 5:  the idea that you can just build a thing for yourself

1029
01:05:14,955 --> 01:05:18,645
Speaker 5:  I think is a bigger behavioral switch than we're realizing

1030
01:05:18,715 --> 01:05:22,325
Speaker 5:  like, it, it's, you just have to think about technology differently to say,

1031
01:05:22,475 --> 01:05:26,125
Speaker 5:  here is the goal I need to accomplish and have it go make that the thing

1032
01:05:26,125 --> 01:05:29,725
Speaker 5:  that can accomplish it for you. But I'm, I'm increasingly convinced

1033
01:05:30,105 --> 01:05:32,605
Speaker 5:  that's going to be a huge deal and we're only just scratching the surface

1034
01:05:32,605 --> 01:05:34,485
Speaker 5:  of it. Agree or disagree.

1035
01:05:35,725 --> 01:05:39,525
Speaker 11:  I mean, I will say Jake v And I tested this and

1036
01:05:39,705 --> 01:05:42,765
Speaker 11:  we were very disappointed, so yeah,

1037
01:05:42,765 --> 01:05:43,805
Speaker 5:  You guys did not have a great

1038
01:05:43,805 --> 01:05:47,485
Speaker 11:  Time. I guess, I mean, you know what I'll like, if I have to agree or disagree,

1039
01:05:47,485 --> 01:05:50,845
Speaker 11:  like I feel like most people are gonna agree with you honestly, but if I

1040
01:05:50,845 --> 01:05:53,925
Speaker 11:  personally from my own experience have to agree or disagree, I have to say

1041
01:05:54,025 --> 01:05:57,925
Speaker 11:  100% disagree because I think like at companies, yeah, like if you're a

1042
01:05:58,045 --> 01:06:01,685
Speaker 11:  software engineer, absolutely. If you have any coding experience, absolutely.

1043
01:06:01,705 --> 01:06:05,685
Speaker 11:  But as someone who has no coding experience besides like

1044
01:06:05,685 --> 01:06:09,365
Speaker 11:  my like Neopets shop where I was like adding like a new song by

1045
01:06:09,515 --> 01:06:10,925
Speaker 11:  ABBA to be my shop, so which

1046
01:06:10,925 --> 01:06:11,405
Speaker 6:  Totally counts

1047
01:06:11,665 --> 01:06:13,965
Speaker 5:  To be, that is absolutely coding experience

1048
01:06:14,605 --> 01:06:18,445
Speaker 11:  I like truly had the worst experience. I mean it just, it didn't work and

1049
01:06:18,445 --> 01:06:22,045
Speaker 11:  even when it did work, it didn't follow through or things would break immediately

1050
01:06:22,115 --> 01:06:25,405
Speaker 11:  even when I did something pretty simple. So I mean, I need to try it more,

1051
01:06:25,405 --> 01:06:28,605
Speaker 11:  but right now I've gotta say based on my own experience. Disagree. Okay.

1052
01:06:28,825 --> 01:06:29,045
Speaker 5:  So

1053
01:06:29,045 --> 01:06:32,885
Speaker 6:  I agree with Hayden Damn would just say I disagree with you

1054
01:06:32,935 --> 01:06:34,205
Speaker 6:  David. Okay.

1055
01:06:34,625 --> 01:06:34,845
Speaker 5:  Do

1056
01:06:35,225 --> 01:06:38,445
Speaker 6:  Listen. I I I'm sure these tools will get better. I'm sure they'll get more

1057
01:06:38,725 --> 01:06:42,685
Speaker 6:  functional, right? I, there are tons of developers who are using

1058
01:06:43,065 --> 01:06:46,685
Speaker 6:  AI a lot to write their own code. Yes. I think that is very distinct from

1059
01:06:47,305 --> 01:06:47,525
Speaker 6:  Yes.

1060
01:06:48,445 --> 01:06:51,925
Speaker 5:  I mean vibe coding specifically. I actually don't think developers are going

1061
01:06:51,925 --> 01:06:54,365
Speaker 5:  to use AI to write code is even a hot take. That's just true.

1062
01:06:54,365 --> 01:06:57,485
Speaker 6:  Oh no, that's happening. We're there. Yeah, I think these things are functionally

1063
01:06:57,485 --> 01:07:00,845
Speaker 6:  good And I think they'll probably get better at vibe coding. Do I think everyone

1064
01:07:00,865 --> 01:07:04,765
Speaker 6:  is going to be vibe coding all the time or on a regular basis that I

1065
01:07:04,805 --> 01:07:08,765
Speaker 6:  I I'm gonna say no. Okay. I that is think think you're both gonna be

1066
01:07:08,765 --> 01:07:11,885
Speaker 6:  kind of niche. It, it's, that's a really hard thing

1067
01:07:12,825 --> 01:07:16,325
Speaker 6:  to, that's a really tricky behavioral change to create,

1068
01:07:16,655 --> 01:07:20,645
Speaker 6:  right? Even when I was trying to figure out ways to, you

1069
01:07:20,645 --> 01:07:24,325
Speaker 6:  know, bring that into my life, it was hard, it's hard for me to start thinking

1070
01:07:24,325 --> 01:07:28,205
Speaker 6:  that way of like, oh, can you generate a way for me to interact with this?

1071
01:07:28,585 --> 01:07:31,485
Speaker 6:  Can you, can you create an interactive for me? Can you make this into a game?

1072
01:07:31,545 --> 01:07:35,125
Speaker 6:  Can you make this into like some all all I can say is interactive. Like,

1073
01:07:35,125 --> 01:07:38,725
Speaker 6:  I, I don't, I don't know what to do And I don't know, maybe there'll be a

1074
01:07:38,725 --> 01:07:42,285
Speaker 6:  new generation where vibe coding is native Tim, they'll be like, well obviously

1075
01:07:42,315 --> 01:07:46,125
Speaker 6:  obviously you, you should turn this into like, you know, this set of

1076
01:07:46,125 --> 01:07:49,405
Speaker 6:  flashcards or we should turn this into a VR experience.

1077
01:07:50,425 --> 01:07:54,265
Speaker 6:  I don't really know. But mostly what I just

1078
01:07:54,265 --> 01:07:57,265
Speaker 6:  want is information, like plain old information given to me very quickly

1079
01:07:57,365 --> 01:08:01,035
Speaker 6:  and plainly. And you know, I think

1080
01:08:01,035 --> 01:08:04,915
Speaker 6:  having people come up with these specific use cases is tricky.

1081
01:08:05,015 --> 01:08:08,955
Speaker 6:  And having people come up with them in ways that are going to actually be

1082
01:08:08,955 --> 01:08:12,755
Speaker 6:  helpful and useful. Right. Okay. Maybe, you know, oh, I need an app

1083
01:08:12,755 --> 01:08:16,085
Speaker 6:  that will be perfect for doing this One thing around the house. We're tracking

1084
01:08:16,085 --> 01:08:20,065
Speaker 6:  chores. Okay, great. There's, there's probably a developer who's put a

1085
01:08:20,185 --> 01:08:23,505
Speaker 6:  ton of thought into making a really great chore tracker,

1086
01:08:24,355 --> 01:08:25,255
Speaker 6:  you know, and it

1087
01:08:25,415 --> 01:08:28,775
Speaker 5:  Probably costs $50 a year and steals all of your personal data. Yes.

1088
01:08:29,395 --> 01:08:33,215
Speaker 6:  But, but it works. They'll probably fix the

1089
01:08:33,285 --> 01:08:37,255
Speaker 6:  bugs when they come up and it, it probably has a logical flow

1090
01:08:37,255 --> 01:08:40,895
Speaker 6:  to it that makes sense because they put a lot of thought into it. You know,

1091
01:08:41,005 --> 01:08:44,575
Speaker 6:  does every person who wants a chore tracker and is ready to prompt Claude

1092
01:08:44,575 --> 01:08:47,935
Speaker 6:  to make them one know how it should work?

1093
01:08:48,355 --> 01:08:51,855
Speaker 6:  Is Claude smart enough to make it work in a logical way? I'm not sure.

1094
01:08:52,275 --> 01:08:56,135
Speaker 6:  So I, I'm disagreeing with you on this one. I, I do think that these tools

1095
01:08:56,135 --> 01:08:59,935
Speaker 6:  will get better, but I think even if they're good enough that they work on

1096
01:09:00,035 --> 01:09:03,895
Speaker 6:  try one, I'm not sure we're gonna get a change where everyone is prompting

1097
01:09:03,995 --> 01:09:04,535
Speaker 6:  all the time.

1098
01:09:05,135 --> 01:09:08,575
Speaker 11:  I do think that's a really good point that you made about like how people's

1099
01:09:08,665 --> 01:09:12,615
Speaker 11:  minds work here because you know, when we were testing it, I

1100
01:09:12,615 --> 01:09:15,455
Speaker 11:  had to use your examples. Like I couldn't think of something to do, you

1101
01:09:15,455 --> 01:09:19,375
Speaker 11:  know, and I'm a tech journalist, so it's like I feel like others

1102
01:09:19,515 --> 01:09:23,415
Speaker 11:  may feel the same. And the other thing is, yeah, I

1103
01:09:23,415 --> 01:09:27,015
Speaker 11:  mean just kind of getting over the idea of, I think it's hard to create,

1104
01:09:27,015 --> 01:09:30,855
Speaker 11:  like see change with people's, like how people think and how,

1105
01:09:31,115 --> 01:09:34,855
Speaker 11:  you know, it's the same way as like in college when I was making my website,

1106
01:09:34,855 --> 01:09:38,575
Speaker 11:  like my portfolio, I paid someone to do it for me, even though I

1107
01:09:38,815 --> 01:09:42,015
Speaker 11:  actually could have just gone on Wix and done it, right? Because I kind

1108
01:09:42,015 --> 01:09:45,055
Speaker 11:  of felt overwhelmed by the idea of figuring out what it should look like

1109
01:09:45,055 --> 01:09:49,015
Speaker 11:  and how to do it And I would've saved me money, but I just was like,

1110
01:09:49,495 --> 01:09:52,655
Speaker 11:  I don't know, I don't know. Let me just outsource this. So yeah, I kind

1111
01:09:52,655 --> 01:09:55,455
Speaker 11:  of agree. I think, you know, maybe if there's a new generation that it's

1112
01:09:55,455 --> 01:09:57,655
Speaker 11:  native to them, but otherwise, I don't know.

1113
01:09:58,905 --> 01:10:02,195
Speaker 5:  I've just been wanting to say, okay, boomer, like every four seconds this

1114
01:10:02,195 --> 01:10:05,035
Speaker 5:  entire time you guys have been talking. No, I, I think, I think you're both

1115
01:10:05,035 --> 01:10:08,475
Speaker 5:  right And I think the, the thing that has been so much fun for me

1116
01:10:08,845 --> 01:10:12,435
Speaker 5:  going through this process has been like learning how to

1117
01:10:12,875 --> 01:10:16,835
Speaker 5:  reorient my brain that way because like, it, it is a

1118
01:10:16,835 --> 01:10:20,355
Speaker 5:  completely different way of thinking about how we interact with technology,

1119
01:10:20,355 --> 01:10:23,075
Speaker 5:  right? Where you're like, when I need to do something, I don't go find the

1120
01:10:23,075 --> 01:10:26,995
Speaker 5:  thing that best accomplishes it. I can just ask it

1121
01:10:27,095 --> 01:10:30,915
Speaker 5:  to exist and, and like most of the time it doesn't work. But like the,

1122
01:10:30,915 --> 01:10:34,835
Speaker 5:  the simplest example I can offer you is the, when you, when you have a baby,

1123
01:10:35,535 --> 01:10:39,395
Speaker 5:  one of the first things they make you do is like religiously track how much

1124
01:10:39,395 --> 01:10:42,355
Speaker 5:  they eat and how much they pee and poop. And

1125
01:10:43,175 --> 01:10:46,115
Speaker 5:  the first time we had a kid, we just did this with a, with a shared Google

1126
01:10:46,115 --> 01:10:48,915
Speaker 5:  sheet spreadsheet. And that was very annoying because you're sitting there

1127
01:10:48,915 --> 01:10:52,355
Speaker 5:  with like kid in one arm and you're like scrolling on your phone through

1128
01:10:52,505 --> 01:10:55,835
Speaker 5:  rows and columns trying to find the right one. And so this time I was just

1129
01:10:55,835 --> 01:10:59,715
Speaker 5:  like, Hey, can you build me a tracker that I can

1130
01:10:59,715 --> 01:11:03,555
Speaker 5:  just open up and it will automatically time and date stamp it and it will

1131
01:11:03,555 --> 01:11:07,435
Speaker 5:  give me four radial buttons so I can just check poop, pee food or other.

1132
01:11:07,695 --> 01:11:10,715
Speaker 5:  And if, if I do other, it opens up a notes field. I literally, I wrote that

1133
01:11:10,715 --> 01:11:14,685
Speaker 5:  essentially into Claude and it built me an activity tracker. I

1134
01:11:14,685 --> 01:11:18,405
Speaker 5:  then spent a day and a half trying to figure out how to get that out of

1135
01:11:18,405 --> 01:11:21,005
Speaker 5:  Claude artifacts, which is the thing I was not going to be able to convince

1136
01:11:21,005 --> 01:11:24,885
Speaker 5:  my wife to use and onto like an actual website that I own and control

1137
01:11:24,915 --> 01:11:27,605
Speaker 5:  that it backs up to Google Sheets. But now I have a thing where I just go

1138
01:11:27,605 --> 01:11:30,085
Speaker 5:  to a website and it pops up this tracker, I click a button and it goes into

1139
01:11:30,085 --> 01:11:34,005
Speaker 5:  the Google spreadsheet And I didn't write one single

1140
01:11:34,545 --> 01:11:38,525
Speaker 5:  letter of code. And the process of that is more work

1141
01:11:38,525 --> 01:11:41,085
Speaker 5:  than most people should have to go through. But that moment of just like,

1142
01:11:41,085 --> 01:11:44,925
Speaker 5:  oh, I can just ask and we, it can

1143
01:11:44,925 --> 01:11:47,885
Speaker 5:  build some facsimile of this thing and then we can, we can refine it together

1144
01:11:47,905 --> 01:11:51,405
Speaker 5:  and build something. And I don't have to know the code. I just have to know

1145
01:11:51,405 --> 01:11:55,365
Speaker 5:  what I want is very powerful. But Hayden, to your exact point, trying

1146
01:11:55,365 --> 01:11:58,485
Speaker 5:  to sit down and come up with a list of things that I want my device to do

1147
01:11:58,485 --> 01:12:02,005
Speaker 5:  for me that it doesn't already is bizarrely difficult. And it's been, I have

1148
01:12:02,005 --> 01:12:05,845
Speaker 5:  like actively worked on trying to retrain my brain on how to do it.

1149
01:12:06,465 --> 01:12:10,005
Speaker 5:  And it's, it's been very weird but very fun. And I encourage everyone to

1150
01:12:10,005 --> 01:12:13,125
Speaker 5:  just like try to make up things for your phone to do for you because it is,

1151
01:12:13,145 --> 01:12:13,805
Speaker 5:  it is a good time.

1152
01:12:14,035 --> 01:12:17,245
Speaker 11:  Okay. I'm a little inspired now to actually like get my brain working that

1153
01:12:17,245 --> 01:12:20,765
Speaker 11:  way. But I will say I think you have like a new side hustle that would make

1154
01:12:20,765 --> 01:12:24,325
Speaker 11:  you a lot of money because it sounds like everyone needs this And I don't

1155
01:12:24,325 --> 01:12:28,165
Speaker 11:  know, I'm like, yeah, in a few years if I ever have kids I'll be getting

1156
01:12:28,165 --> 01:12:29,565
Speaker 11:  this website from you. So, oh

1157
01:12:29,565 --> 01:12:33,325
Speaker 5:  My god, anybody needs anybody who needs my poop tracker? Get at me. I got

1158
01:12:33,325 --> 01:12:37,045
Speaker 5:  you. David already gave him the prompt. It has dark mode now. I, Claude And

1159
01:12:37,045 --> 01:12:40,245
Speaker 5:  I worked on the colors together. I didn't like the way it was doing the buttons

1160
01:12:40,245 --> 01:12:43,765
Speaker 5:  for a while. Like the, I should, the transcript of our conversation about

1161
01:12:43,765 --> 01:12:46,565
Speaker 5:  this is very funny 'cause I'm like, can you put the poop emoji on the left

1162
01:12:46,565 --> 01:12:49,005
Speaker 5:  side of the word poop instead of the right side? Because when I'm on mobile,

1163
01:12:49,035 --> 01:12:52,925
Speaker 5:  it's not showing Correct. It's fabulous. This is just the weirdest of times

1164
01:12:53,035 --> 01:12:56,605
Speaker 5:  that we live in right now. Alright, those are all of my, those are all of

1165
01:12:56,605 --> 01:13:00,085
Speaker 5:  my takes. I feel better having said these to you. Thank you both for, for

1166
01:13:00,085 --> 01:13:01,365
Speaker 5:  going down this truly absurd

1167
01:16:23,435 --> 01:16:25,635
Speaker 5:  should we just do this now? Should we just, should we just fight about this

1168
01:16:26,125 --> 01:16:29,675
Speaker 6:  David? We've got some issues. Have you seen

1169
01:16:29,935 --> 01:16:33,595
Speaker 6:  The Vergecast inbox? Have you seen how many

1170
01:16:33,955 --> 01:16:37,235
Speaker 6:  hashtags saved the thunder rounds? We received The

1171
01:16:37,235 --> 01:16:40,235
Speaker 5:  People. The people do like the thunder. Listen,

1172
01:16:40,295 --> 01:16:44,105
Speaker 6:  Listen. I know how you feel and so I'm gonna make my strongest argument here.

1173
01:16:44,455 --> 01:16:48,425
Speaker 6:  Just imagine for a second the ability to announce

1174
01:16:48,485 --> 01:16:52,145
Speaker 6:  the, the title of this segment. Stick up your hand and have

1175
01:16:52,335 --> 01:16:55,785
Speaker 6:  thunder come roaring down. Feels good.

1176
01:16:56,925 --> 01:16:58,385
Speaker 5:  Hey, that

1177
01:16:58,745 --> 01:17:01,025
Speaker 6:  Could be you David. That could be

1178
01:17:01,245 --> 01:17:04,585
Speaker 5:  You. First of all, Hayden from now on is the only person who gets to do that

1179
01:17:04,585 --> 01:17:07,385
Speaker 5:  because she just signed that perfectly. Very well done by Hayden. Thank you.

1180
01:17:07,545 --> 01:17:07,665
Speaker 5:  I

1181
01:17:07,665 --> 01:17:09,085
Speaker 6:  Just felt it in me. You know, I have have,

1182
01:17:09,155 --> 01:17:12,365
Speaker 5:  Yeah, that was actually not a sound effect. We played, Hayden did that herself

1183
01:17:12,365 --> 01:17:13,605
Speaker 5:  naturally. Just now

1184
01:17:15,265 --> 01:17:19,005
Speaker 5:  two things. One, thunder is slower than lightning. This,

1185
01:17:19,005 --> 01:17:22,885
Speaker 5:  this makes the whole conceit of this doesn't make any sense. It doesn't make

1186
01:17:22,885 --> 01:17:26,365
Speaker 5:  any sense. You can't have thunder if you don't have lightning. And also lightning

1187
01:17:26,365 --> 01:17:29,445
Speaker 5:  is the thing that goes fast and then thunder rolls forever. Like it doesn't

1188
01:17:29,445 --> 01:17:30,165
Speaker 5:  make any sense.

1189
01:17:31,065 --> 01:17:34,925
Speaker 6:  And yet, and yet thunder it, it feels powerful.

1190
01:17:35,525 --> 01:17:35,565
Speaker 6:  Powerful.

1191
01:17:35,565 --> 01:17:37,245
Speaker 11:  The the gravitas. The gravitas.

1192
01:17:37,495 --> 01:17:38,285
Speaker 6:  Thank you Hayden.

1193
01:17:38,315 --> 01:17:42,125
Speaker 5:  This is not the gravitas round. If you wanna do the gravitas round, you can

1194
01:17:42,125 --> 01:17:42,845
Speaker 5:  talk about that. That's

1195
01:17:42,845 --> 01:17:43,365
Speaker 6:  The after show.

1196
01:17:43,395 --> 01:17:47,165
Speaker 5:  This is, that's where we put on tuxedos and talk about tech news that

1197
01:17:47,225 --> 01:17:51,165
Speaker 5:  I'm into. We can, we can do that all day. No, it's okay. Here's

1198
01:17:51,165 --> 01:17:54,685
Speaker 5:  what we're gonna do. It's the lightning round again. But

1199
01:17:55,645 --> 01:17:59,635
Speaker 5:  in the spirit of the thunder round, we're going to actually

1200
01:17:59,695 --> 01:18:02,715
Speaker 5:  do all of the stories that we try to do. 'cause that I think was a very good

1201
01:18:02,715 --> 01:18:06,675
Speaker 5:  idea. And I would like to hold to at least we're gonna

1202
01:18:06,675 --> 01:18:08,955
Speaker 5:  do that until Neela comes back and starts yelling about Brendan Carr for

1203
01:18:08,955 --> 01:18:12,765
Speaker 5:  45 minutes every episode again. But until we do that, we are

1204
01:18:12,765 --> 01:18:16,725
Speaker 5:  going to actively go through all of the stories that we have. But it

1205
01:18:16,725 --> 01:18:19,755
Speaker 5:  is going to be called the lightning round because the thunder round doesn't

1206
01:18:19,755 --> 01:18:21,275
Speaker 5:  make any sense. This

1207
01:18:22,425 --> 01:18:23,265
Speaker 6:  Is not

1208
01:18:23,265 --> 01:18:23,425
Speaker 5:  All

1209
01:18:23,425 --> 01:18:27,265
Speaker 6:  It, it's personally devastating to me. And I wanna

1210
01:18:27,265 --> 01:18:31,225
Speaker 6:  say on behalf of all thunder round supporters, you're dead to us.

1211
01:18:31,225 --> 01:18:32,025
Speaker 6:  But we'll continue to listen.

1212
01:18:32,545 --> 01:18:36,385
Speaker 11:  I talked to David's new baby and he said that he preferred the

1213
01:18:36,385 --> 01:18:37,745
Speaker 11:  thunder round, so Wow.

1214
01:18:37,935 --> 01:18:38,705
Speaker 5:  Yeah. Was he not

1215
01:18:39,335 --> 01:18:42,585
Speaker 6:  Give it 18 years? We'll employ him and overtake you.

1216
01:18:43,005 --> 01:18:46,705
Speaker 5:  All he does is poop his pants and listen to me yell about ai. He doesn't

1217
01:18:46,705 --> 01:18:49,505
Speaker 5:  know anything. All right, let's do this.

1218
01:18:50,415 --> 01:18:53,625
Speaker 5:  Jake, since you're heartbroken, I will allow you to go first.

1219
01:18:54,185 --> 01:18:55,425
Speaker 5:  What's, what's your first story of the week?

1220
01:18:55,665 --> 01:18:59,505
Speaker 6:  I am heartbroken, however, oh, it brings me great joy, great

1221
01:18:59,805 --> 01:19:03,465
Speaker 6:  joy to start this with. Spotify has

1222
01:19:03,775 --> 01:19:07,185
Speaker 6:  finally added lossless streaming.

1223
01:19:08,525 --> 01:19:10,505
Speaker 6:  Oh my God, what? 45

1224
01:19:10,595 --> 01:19:11,145
Speaker 5:  Years later.

1225
01:19:11,535 --> 01:19:15,265
Speaker 6:  They, they literally announced the feature four years ago.

1226
01:19:15,495 --> 01:19:16,585
Speaker 6:  They said they were doing it.

1227
01:19:16,655 --> 01:19:19,305
Speaker 5:  Wait, did they really? Yeah, I thought this was like rumors and speculation

1228
01:19:19,455 --> 01:19:19,865
Speaker 5:  this whole time.

1229
01:19:20,085 --> 01:19:23,465
Speaker 6:  It, it was rumored in speculation for eight years because they started like

1230
01:19:23,865 --> 01:19:27,665
Speaker 6:  trialing it and putting out surveys. Four years. I'm like, like

1231
01:19:27,665 --> 01:19:31,625
Speaker 6:  90% sure that they had Billie Eilish announce it in, in

1232
01:19:31,625 --> 01:19:35,345
Speaker 6:  like a promo video. Wow. Like they did a promotional video for Spotify

1233
01:19:35,715 --> 01:19:39,505
Speaker 6:  Hi-Fi. They were like, it's coming this year. And then they never

1234
01:19:39,615 --> 01:19:43,585
Speaker 6:  said another word about it. They just, just nothing I

1235
01:19:43,585 --> 01:19:47,345
Speaker 6:  want, you know, every time a Spotify PR

1236
01:19:47,345 --> 01:19:51,145
Speaker 6:  person has contacted me over the last four years, I've been like, and

1237
01:19:51,145 --> 01:19:54,425
Speaker 6:  by the way, whenever Hi-Fi comes down, you let me know. And they're sick

1238
01:19:54,425 --> 01:19:57,945
Speaker 6:  and tired of it. And it did not help. It did not help our

1239
01:19:58,065 --> 01:20:01,945
Speaker 5:  Former colleague, Chris Welch, I think, I think the reason he doesn't work

1240
01:20:01,945 --> 01:20:05,585
Speaker 5:  at The Verge anymore was that he couldn't deal with the ongoing

1241
01:20:05,585 --> 01:20:09,485
Speaker 5:  non-existence of Spotify Hi-Fi every year. He just, he just needed a clean

1242
01:20:09,485 --> 01:20:09,685
Speaker 5:  break.

1243
01:20:09,985 --> 01:20:13,685
Speaker 6:  He, on the anniversary of the announcement every year he wrote a post being

1244
01:20:13,685 --> 01:20:17,365
Speaker 6:  like, what, what happened? Why isn't it here? It's here.

1245
01:20:18,075 --> 01:20:21,885
Speaker 6:  This is, again, most of the other streaming services already

1246
01:20:21,975 --> 01:20:25,925
Speaker 6:  offer this as a feature. The good news is Spotify isn't charging more.

1247
01:20:26,185 --> 01:20:29,805
Speaker 6:  So that's great. The bad news, And I don't know if there's a technical reason

1248
01:20:29,805 --> 01:20:33,485
Speaker 6:  for this, but no airplay support, no Google cast

1249
01:20:33,485 --> 01:20:37,365
Speaker 6:  support, which means I'm not listening to it. All of my stuff

1250
01:20:37,425 --> 01:20:40,965
Speaker 6:  is Google cast. So this is not useful. You gotta use Spotify Connect, which

1251
01:20:41,005 --> 01:20:44,325
Speaker 6:  I think is a little bit more reserved for like higher end gear,

1252
01:20:44,655 --> 01:20:48,205
Speaker 6:  which I, I, I have one thing that can do Spotify Connect, but I can't like

1253
01:20:48,205 --> 01:20:51,445
Speaker 6:  street the things that I use most are not Spotify Connect. Right. So,

1254
01:20:53,425 --> 01:20:56,605
Speaker 5:  And also Spotify Connect is like, it, it just sort of uses the bandwidth

1255
01:20:56,605 --> 01:20:59,325
Speaker 5:  differently. So like I can understand why it's actually restricted to that.

1256
01:20:59,325 --> 01:21:03,125
Speaker 5:  Trying to move that kind of quality

1257
01:21:03,345 --> 01:21:07,325
Speaker 5:  around would just be a challenge. But yeah, spot

1258
01:21:07,435 --> 01:21:11,365
Speaker 5:  spot. Spotify like two thirds did the job here

1259
01:21:11,365 --> 01:21:14,645
Speaker 5:  that like technically it's here, you can, you can listen to it. It's, if

1260
01:21:14,645 --> 01:21:18,165
Speaker 5:  you follow these three instructions and pay a toll to

1261
01:21:18,595 --> 01:21:22,285
Speaker 5:  that person under the bridge, then you can have lossless

1262
01:21:22,285 --> 01:21:22,885
Speaker 5:  streaming. Yeah.

1263
01:21:22,955 --> 01:21:24,205
Speaker 11:  It's an improvement from before.

1264
01:21:25,315 --> 01:21:25,605
Speaker 5:  Sure.

1265
01:21:26,905 --> 01:21:27,885
Speaker 6:  And they're not charging for

1266
01:21:28,105 --> 01:21:28,485
Speaker 5:  Of all

1267
01:21:28,485 --> 01:21:30,245
Speaker 6:  Praise charging, which I appreciate.

1268
01:21:31,595 --> 01:21:35,485
Speaker 5:  Yeah. And I, and it's free. So there's already conspiracy theories

1269
01:21:35,485 --> 01:21:39,245
Speaker 5:  that the reason it's not sort of fully baked is that Spotify is eventually

1270
01:21:39,245 --> 01:21:41,765
Speaker 5:  going to release a fully baked version that it's gonna make you pay more

1271
01:21:41,765 --> 01:21:45,665
Speaker 5:  for, which would be very funny. And I help us all.

1272
01:21:48,045 --> 01:21:49,145
Speaker 5:  Hayden, what's your first story?

1273
01:21:50,015 --> 01:21:53,905
Speaker 11:  Okay, my first one is that Claude can now make you a spreadsheet

1274
01:21:53,965 --> 01:21:57,385
Speaker 11:  or a slide deck. So basically it can create and edit

1275
01:21:57,635 --> 01:22:01,505
Speaker 11:  files in Excel and PowerPoint. It can make a PDF, it can create

1276
01:22:01,865 --> 01:22:05,825
Speaker 11:  documents. And it's exciting because this is something that I feel

1277
01:22:05,825 --> 01:22:08,825
Speaker 11:  like a lot of people thought it could already do, but it could not. And

1278
01:22:08,825 --> 01:22:11,865
Speaker 11:  so finally we're getting a little bit closer to agent stuff,

1279
01:22:12,845 --> 01:22:16,505
Speaker 11:  you know, I mean, it's awesome that it can create, I hate, hate

1280
01:22:16,865 --> 01:22:19,785
Speaker 11:  creating Excel spreadsheets. It's like something that I feel like a lot

1281
01:22:19,785 --> 01:22:23,665
Speaker 11:  of people learned in school or they started doing like just on the side

1282
01:22:23,685 --> 01:22:26,625
Speaker 11:  in their personal life. I never learned, I never learned the shortcuts.

1283
01:22:26,705 --> 01:22:30,105
Speaker 11:  I just don't, I just had to make one And I, I was like

1284
01:22:30,665 --> 01:22:33,225
Speaker 11:  a baby with like, I didn't understand it all. So I'm very excited about

1285
01:22:33,225 --> 01:22:37,025
Speaker 11:  this. But it is crazy that it's just happening now. I will

1286
01:22:37,025 --> 01:22:40,785
Speaker 11:  say like when last year they rolled out computer use and

1287
01:22:40,785 --> 01:22:44,625
Speaker 11:  like agentic tools and just now is it able to like

1288
01:22:44,625 --> 01:22:48,505
Speaker 11:  create a doc or a PDF? So, you know, it's, it's a give and take, but

1289
01:22:48,615 --> 01:22:52,025
Speaker 11:  it's, it is exciting that it's coming a little more useful to actual

1290
01:22:52,345 --> 01:22:53,265
Speaker 11:  consumers. It's

1291
01:22:53,265 --> 01:22:55,745
Speaker 5:  Funny, this is one of those features that I feel like Google has been talking

1292
01:22:55,745 --> 01:22:59,625
Speaker 5:  about at Google io for like several decades at this point where

1293
01:22:59,625 --> 01:23:02,505
Speaker 5:  they're just like, the only thing Google can think of for Gemini to do is

1294
01:23:02,505 --> 01:23:06,285
Speaker 5:  to turn your sheets numbers into slides, slides and vice

1295
01:23:06,285 --> 01:23:09,925
Speaker 5:  versa. And it's the kind of thing that actually seems like a

1296
01:23:10,395 --> 01:23:14,325
Speaker 5:  very doable for an agent that's just like, here's a bunch of numbers, put

1297
01:23:14,445 --> 01:23:17,085
Speaker 5:  'em on slides in a way that looks sort of normal with this as the template.

1298
01:23:17,085 --> 01:23:20,965
Speaker 5:  Like should be pretty doable. And I feel like it was a few years ago that

1299
01:23:20,965 --> 01:23:24,805
Speaker 5:  everybody was like all the like junior associates at

1300
01:23:24,805 --> 01:23:28,085
Speaker 5:  firms everywhere who just do this for a living are going to be out of jobs.

1301
01:23:28,705 --> 01:23:32,605
Speaker 5:  And it is weird to see this like launched with a lot of fanfare now 'cause

1302
01:23:32,605 --> 01:23:35,285
Speaker 5:  it's like this is like, this seems like a very straightforward thing that

1303
01:23:35,285 --> 01:23:36,485
Speaker 5:  these have been good at for a long time.

1304
01:23:37,065 --> 01:23:40,485
Speaker 6:  AI creating spreadsheets is actually like, that feels high risk to me,

1305
01:23:40,895 --> 01:23:44,285
Speaker 6:  right? Like if, if you have a spreadsheet with a bunch of numbers,

1306
01:23:44,825 --> 01:23:48,525
Speaker 6:  oh that's a lot of individual data points that need to be analyzed

1307
01:23:48,595 --> 01:23:52,485
Speaker 6:  correctly and moved around correctly. And that kind of precision

1308
01:23:52,665 --> 01:23:54,565
Speaker 6:  is actually exactly what AI is bad at.

1309
01:23:54,625 --> 01:23:56,845
Speaker 5:  And if you have to fact check each number that goes into the spreadsheet,

1310
01:23:56,845 --> 01:23:58,605
Speaker 5:  what the hell is the point of the spreadsheet? Right?

1311
01:23:59,065 --> 01:24:03,005
Speaker 6:  And so listen, I I see the appeal. I a hundred percent do because

1312
01:24:03,035 --> 01:24:06,365
Speaker 6:  like analyzing data and creating spreadsheets,

1313
01:24:07,065 --> 01:24:11,005
Speaker 6:  not skills that, that most people have developed like to, to a really high

1314
01:24:11,005 --> 01:24:14,725
Speaker 6:  degree. It makes a lot of sense that, that people would want this. It's exactly

1315
01:24:14,725 --> 01:24:18,685
Speaker 6:  where I get worried. And so I have asked, you

1316
01:24:18,685 --> 01:24:22,525
Speaker 6:  know, AI bots in the past for specific formulas and

1317
01:24:22,525 --> 01:24:25,565
Speaker 6:  they're quite good at that 'cause it's basically just programming, but it's

1318
01:24:25,565 --> 01:24:28,805
Speaker 6:  still, it's all manual. Like where I'm moving stuff around and I'm making

1319
01:24:28,805 --> 01:24:29,725
Speaker 6:  sure I know what I do

1320
01:24:31,425 --> 01:24:34,645
Speaker 6:  slides. That feels like a little bit lower risk. 'cause you can still, you

1321
01:24:34,645 --> 01:24:38,365
Speaker 6:  can go in and edit them, but if you're having AI move a bunch of numbers

1322
01:24:38,365 --> 01:24:42,285
Speaker 6:  around for you and you're not a numbers person, oh man. Like you, you, you

1323
01:24:42,285 --> 01:24:43,925
Speaker 6:  might have no idea what's gone wrong.

1324
01:24:44,395 --> 01:24:47,685
Speaker 11:  Once again, it's sadly one of those things where you can only trust it with

1325
01:24:47,705 --> 01:24:50,885
Speaker 11:  low stakes things. Yeah. And then once it useful for, you know, but, you

1326
01:24:50,885 --> 01:24:54,325
Speaker 11:  know, I think David should test it with the baby

1327
01:24:54,475 --> 01:24:57,245
Speaker 11:  tracker info and let us know. Yeah, that's a good idea. That's

1328
01:24:57,245 --> 01:25:00,485
Speaker 5:  Better. Okay. I'm gonna, I will make you a deeply

1329
01:25:01,365 --> 01:25:05,325
Speaker 5:  designed presentation about my baby's poops And I will, I'll report

1330
01:25:05,325 --> 01:25:09,285
Speaker 5:  back. My first one is I have not had a chance to talk

1331
01:25:09,285 --> 01:25:13,085
Speaker 5:  about my, my guy David Z. Love CEO of Warner Brothers Discovery in a while.

1332
01:25:14,825 --> 01:25:18,805
Speaker 5:  He thankfully did not rebrand HBO Max again

1333
01:25:18,805 --> 01:25:22,725
Speaker 5:  while I was gone, which I thought was very nice. But two interesting

1334
01:25:22,835 --> 01:25:26,565
Speaker 5:  bits of news about our guy, David this week, he was

1335
01:25:26,665 --> 01:25:30,565
Speaker 5:  at a Goldman Sachs conference, which is called the Communa Copia

1336
01:25:30,565 --> 01:25:34,005
Speaker 5:  and Technology Conference, which I hate and everyone should be ashamed of.

1337
01:25:35,185 --> 01:25:39,005
Speaker 5:  He basically was talking about how bad he thinks

1338
01:25:39,505 --> 01:25:43,205
Speaker 5:  the current experience of television is, right? Lots of

1339
01:25:43,505 --> 01:25:46,405
Speaker 5:  app switching, lots of trying to find things on different platforms, the

1340
01:25:46,405 --> 01:25:48,725
Speaker 5:  kind of stuff that we talk about a lot, right? That now everything is on

1341
01:25:48,725 --> 01:25:50,565
Speaker 5:  a million different streaming services. It's all very hard to find, everything

1342
01:25:50,565 --> 01:25:54,085
Speaker 5:  is different. I actually largely agree with most of what he's saying. Then

1343
01:25:54,185 --> 01:25:58,045
Speaker 5:  in the same breath, what he said was actually

1344
01:25:58,385 --> 01:26:02,125
Speaker 5:  it is all incredibly underpriced and we are going to

1345
01:26:02,175 --> 01:26:05,765
Speaker 5:  crack down on password sharing and make it more expensive. And so it's like,

1346
01:26:05,765 --> 01:26:09,205
Speaker 5:  well buddy, you might have missed the point. And

1347
01:26:10,205 --> 01:26:14,005
Speaker 5:  I think the, the funny thing is, what he's clearly saying is

1348
01:26:14,285 --> 01:26:17,565
Speaker 5:  actually what we've done here is we've bundled a bunch of stuff and so now

1349
01:26:17,565 --> 01:26:21,045
Speaker 5:  we can charge more money. And what he's doing is called cable.

1350
01:26:21,385 --> 01:26:24,885
Speaker 5:  And we did that already. And it's just what's happening again. And every

1351
01:26:24,885 --> 01:26:28,685
Speaker 5:  time that everybody turns around, they are just innovating their way

1352
01:26:28,915 --> 01:26:32,885
Speaker 5:  into the cable television era of the 1980s. And it

1353
01:26:32,885 --> 01:26:36,765
Speaker 5:  is driving me absolutely up the wall then, just to keep all of

1354
01:26:36,765 --> 01:26:39,565
Speaker 5:  this being extra insane. There is some reporting this afternoon from the

1355
01:26:39,685 --> 01:26:43,525
Speaker 5:  Wall Street Journal saying that Paramount, which now has a new owner in

1356
01:26:43,525 --> 01:26:46,925
Speaker 5:  David Ellison backed by Larry Ellison, now the richest man in the world

1357
01:26:47,655 --> 01:26:51,405
Speaker 5:  might be interested in buying Warner Brothers discovery in cash.

1358
01:26:51,905 --> 01:26:55,725
Speaker 5:  And so, so David Zs love, who has just only made bad

1359
01:26:55,965 --> 01:26:59,925
Speaker 5:  decisions over and over and over for years and decided to bring the

1360
01:26:59,925 --> 01:27:02,365
Speaker 5:  company together and now split up. The company is gonna sell the company

1361
01:27:02,365 --> 01:27:06,045
Speaker 5:  and make a just a boatload of money. All thanks to Larry Ellison

1362
01:27:06,345 --> 01:27:10,285
Speaker 5:  and the $300 billion he's gonna get from an OpenAI cloud deal. And

1363
01:27:10,285 --> 01:27:14,165
Speaker 5:  this is how I lose my mind every week on The Vergecast,

1364
01:27:14,175 --> 01:27:14,525
Speaker 5:  sorry,

1365
01:27:14,905 --> 01:27:17,885
Speaker 6:  OpenAI is now owned by Paramount. Is that where I

1366
01:27:17,885 --> 01:27:18,325
Speaker 5:  Think it's essentially

1367
01:27:18,385 --> 01:27:19,645
Speaker 6:  That's, is that what happened here?

1368
01:27:19,795 --> 01:27:20,085
Speaker 5:  Yeah.

1369
01:27:20,385 --> 01:27:24,005
Speaker 6:  Yes. Oh God, I you were right about the

1370
01:27:24,005 --> 01:27:27,965
Speaker 6:  bundles. The, like this is all just artificially merging things,

1371
01:27:28,095 --> 01:27:32,005
Speaker 6:  right? They have done too many deals. They have too much stuff and people

1372
01:27:32,005 --> 01:27:35,245
Speaker 6:  won't pay for all the things individually. They're shoving stuff together

1373
01:27:35,785 --> 01:27:38,525
Speaker 6:  and therefore they're like, oh, there's more value here. We have to charge

1374
01:27:38,525 --> 01:27:42,325
Speaker 6:  more for it. I recently wanted to watch Alien Earth. Alien

1375
01:27:42,325 --> 01:27:45,925
Speaker 6:  Earth is on Hulu. And so I went to reactivate my Hulu account,

1376
01:27:46,295 --> 01:27:50,285
Speaker 6:  could not figure out how to, I, it kept trying to sell me Hulu plus Disney.

1377
01:27:50,425 --> 01:27:53,605
Speaker 6:  And I'm like, I don't want Disney plus, I don't need Disney Plus, they're

1378
01:27:53,605 --> 01:27:57,565
Speaker 6:  the same thing. Now I ca I ca I could not listen if there's a way

1379
01:27:57,645 --> 01:28:00,365
Speaker 6:  I missed it, I couldn't figure out a way to sign up for one and not the other.

1380
01:28:00,785 --> 01:28:04,565
Speaker 6:  And okay, maybe that is a better value because they're bundled. Okay.

1381
01:28:04,565 --> 01:28:08,285
Speaker 6:  It's a better value up until the value doubles And I have to start

1382
01:28:08,285 --> 01:28:11,365
Speaker 6:  paying that. And I don't wanna pay that because I don't need to stream all

1383
01:28:11,365 --> 01:28:14,525
Speaker 6:  the Marvel movies. There are a lot of people who do and that is great for

1384
01:28:14,525 --> 01:28:16,485
Speaker 6:  them and they're having a great time. You

1385
01:28:16,485 --> 01:28:20,365
Speaker 5:  Know, what's fantastic about that is somewhere in the audience of The Vergecast,

1386
01:28:20,575 --> 01:28:24,365
Speaker 5:  there is a a up and coming startup founder who just said,

1387
01:28:24,385 --> 01:28:27,965
Speaker 5:  oh, you know what would be so cool is if you could just pay for the stuff

1388
01:28:27,965 --> 01:28:30,605
Speaker 5:  that you wanted to watch and you didn't have to subsidize all the other stuff

1389
01:28:30,605 --> 01:28:33,565
Speaker 5:  that other people watch. We'll, we'll call it, maybe we'll just call it like

1390
01:28:33,605 --> 01:28:37,165
Speaker 5:  a, like a skinny bundle and we'll, we'll just a skinny bundle. We'll just,

1391
01:28:37,165 --> 01:28:40,285
Speaker 5:  or we'll, you can just have the stuff that you want and, and it's just, we're

1392
01:28:40,285 --> 01:28:42,605
Speaker 5:  just gonna, we're just doing this again. It's,

1393
01:28:43,035 --> 01:28:46,285
Speaker 11:  It's just so meta. So meta. And also, funnily enough, I had the opposite

1394
01:28:46,285 --> 01:28:49,605
Speaker 11:  experience to you where I was trying to log into my

1395
01:28:50,115 --> 01:28:54,085
Speaker 11:  Hulu, which is actually my college roommate's brother's Hulu. Oh my God.

1396
01:28:54,505 --> 01:28:58,165
Speaker 11:  And I couldn't, And I was like, oh no, did he finally kick me out? But no,

1397
01:28:58,225 --> 01:29:02,165
Speaker 11:  it was that it merged And I do have Disney plus I, I

1398
01:29:02,165 --> 01:29:05,125
Speaker 11:  only congrats use it. Congrats. Yeah. I only use it at like Halloween because

1399
01:29:05,205 --> 01:29:09,045
Speaker 11:  I like watching like the spooky movies for my youth. But yeah, it was

1400
01:29:09,045 --> 01:29:12,085
Speaker 11:  weird because I just didn't, I didn't hear anything about this, so then

1401
01:29:12,125 --> 01:29:15,405
Speaker 11:  I like, and it also doesn't seem like everything transferred over, so they

1402
01:29:15,405 --> 01:29:18,485
Speaker 11:  had a few things, but I don't, I don't know. We gotta investigate this.

1403
01:29:18,705 --> 01:29:18,925
Speaker 11:  So

1404
01:29:18,925 --> 01:29:22,765
Speaker 6:  What, when nowadays when it comes to movies, I I, I rent them all

1405
01:29:22,765 --> 01:29:26,485
Speaker 6:  individually for right? Like, because that is way better and way

1406
01:29:26,485 --> 01:29:29,565
Speaker 6:  cheaper and gets me a better selection. But you just don't have that option

1407
01:29:29,825 --> 01:29:33,765
Speaker 6:  at, at least that, that I'm aware of when it comes to TV shows. And

1408
01:29:33,805 --> 01:29:37,525
Speaker 6:  I guess, can you still buy individual episodes on iTunes? Is that a thing?

1409
01:29:37,825 --> 01:29:38,885
Speaker 6:  Is iTunes real?

1410
01:29:39,245 --> 01:29:40,885
Speaker 11:  I I think it's not a thing anymore.

1411
01:29:40,885 --> 01:29:41,725
Speaker 6:  I don't don't think that's a

1412
01:29:41,725 --> 01:29:42,965
Speaker 11:  Thing you can buy a season.

1413
01:29:43,145 --> 01:29:46,165
Speaker 5:  You know, what's happened to me though recently is I've started buying more

1414
01:29:46,165 --> 01:29:49,245
Speaker 5:  movies again because there's so many times where it's like three bucks to

1415
01:29:49,245 --> 01:29:52,765
Speaker 5:  rent a movie and five to own it. And it's just like, well, okay, I'll spend

1416
01:29:52,765 --> 01:29:56,565
Speaker 5:  $5 to own super bad. Like, I guess I just own super bad

1417
01:29:56,585 --> 01:29:56,805
Speaker 5:  now.

1418
01:29:57,365 --> 01:30:01,285
Speaker 11:  I also rewatch so many movies that I have been doing the same thing, like

1419
01:30:01,285 --> 01:30:05,005
Speaker 11:  on Prime video or whatever. I'll just buy it instead. Like, I bought the

1420
01:30:05,395 --> 01:30:09,365
Speaker 11:  dumbest movie from my youth the other day about like high school girls

1421
01:30:09,555 --> 01:30:12,685
Speaker 11:  like feuding called the Click. And I was so happy I bought it. I was like,

1422
01:30:12,685 --> 01:30:15,965
Speaker 11:  yes, I will rewatch this at some point. But the thing that gives me the

1423
01:30:15,965 --> 01:30:19,125
Speaker 11:  most joy is that in my neighborhood in New York, there's now a DVD store.

1424
01:30:19,505 --> 01:30:20,125
Speaker 6:  Oh my gosh.

1425
01:30:20,355 --> 01:30:22,885
Speaker 11:  It's, and it's still survived. I think it's been like six months and it's

1426
01:30:22,885 --> 01:30:24,445
Speaker 11:  still there, which we love. Oh my god, we love to

1427
01:30:24,445 --> 01:30:26,965
Speaker 5:  See it. Oh my God. So we're really going full. We're not going back to eighties

1428
01:30:26,965 --> 01:30:29,925
Speaker 5:  cable. We're going back to like, we're, we're just gonna go all the way back

1429
01:30:29,925 --> 01:30:33,605
Speaker 5:  to the beginning of like, we're recorded media

1430
01:30:33,945 --> 01:30:35,085
Speaker 11:  Analog baby. Yeah.

1431
01:30:35,535 --> 01:30:38,885
Speaker 5:  We're gonna do the phonograph again next. It's gonna be sick. We're all gonna

1432
01:30:38,885 --> 01:30:42,845
Speaker 5:  gather around our enormous radios and listen to Orson Wells.

1433
01:30:42,875 --> 01:30:43,845
Speaker 5:  It's gonna be too many cover

1434
01:30:43,845 --> 01:30:44,125
Speaker 11:  Fireside

1435
01:30:44,125 --> 01:30:47,005
Speaker 5:  Chats. I love this. All right, Jake, what's your next one? Alright,

1436
01:30:47,265 --> 01:30:51,005
Speaker 6:  So speaking of retro tech and people

1437
01:30:51,005 --> 01:30:54,285
Speaker 6:  going back old school Canon is

1438
01:30:54,805 --> 01:30:58,325
Speaker 6:  reviving a point and shoot camera from

1439
01:30:58,325 --> 01:31:01,885
Speaker 6:  2016. It's called the Power Shot Elf 360 hs.

1440
01:31:02,345 --> 01:31:06,205
Speaker 6:  It is wildly popular because Kendall Jenner and

1441
01:31:06,305 --> 01:31:10,125
Speaker 6:  Dua Lipa both love this thing. It's just a very trendy point and shoot camera.

1442
01:31:10,795 --> 01:31:13,965
Speaker 6:  They, I I believe they're actually still selling it, but now they have a

1443
01:31:13,965 --> 01:31:17,165
Speaker 6:  new model of it that costs more money and has fewer features.

1444
01:31:18,035 --> 01:31:20,975
Speaker 6:  And so that's, that's what we're doing now. I mean this makes, but it's

1445
01:31:20,975 --> 01:31:21,655
Speaker 5:  Available, which

1446
01:31:21,655 --> 01:31:24,375
Speaker 6:  Is key. It's available. That's that's the thing, right? You can buy it for

1447
01:31:24,375 --> 01:31:28,175
Speaker 6:  sale buy and you don't have to find a weird, super expensive version

1448
01:31:28,275 --> 01:31:29,335
Speaker 6:  on eBay. This is

1449
01:31:29,335 --> 01:31:32,615
Speaker 5:  A weird one to me because I actually fully

1450
01:31:32,705 --> 01:31:36,575
Speaker 5:  understand why if you're Canon you would do this, right? Like we are very

1451
01:31:36,575 --> 01:31:39,935
Speaker 5:  much in a like point and shoot digital camera

1452
01:31:40,245 --> 01:31:43,375
Speaker 5:  revival for I think a lot of good interesting reasons. And so the idea that

1453
01:31:43,375 --> 01:31:46,375
Speaker 5:  if you're a company, you would chase that and try to like

1454
01:31:47,435 --> 01:31:51,135
Speaker 5:  be the cool one that people like makes a lot of sense to me because we've

1455
01:31:51,135 --> 01:31:54,735
Speaker 5:  talked about it on the show that the, like the cameras go viral that actually

1456
01:31:54,735 --> 01:31:58,055
Speaker 5:  haven't been on sale in a decade and like companies should take advantage

1457
01:31:58,055 --> 01:32:01,685
Speaker 5:  of that. It makes complete sense to me why you would make this particular

1458
01:32:01,685 --> 01:32:05,645
Speaker 5:  camera, which doesn't have USBC, it doesn't have

1459
01:32:05,645 --> 01:32:09,125
Speaker 5:  particularly interesting or high-end. Like they're deliberately making a

1460
01:32:09,905 --> 01:32:11,365
Speaker 5:  old outdated camera.

1461
01:32:12,165 --> 01:32:15,925
Speaker 11:  I know why, it's because in the movie that I just referenced from the two

1462
01:32:16,125 --> 01:32:19,925
Speaker 11:  thousands about the feuding high school girls, they have this camera, so

1463
01:32:19,985 --> 01:32:22,405
Speaker 11:  that's obviously why they brought it back. Yeah, they do.

1464
01:32:22,625 --> 01:32:26,245
Speaker 6:  Oh wow. Yeah, it's, it's so funny how lazy this is. Like to your point,

1465
01:32:26,775 --> 01:32:30,765
Speaker 6:  micro USB, right? They didn't change the USB

1466
01:32:30,825 --> 01:32:34,445
Speaker 6:  po. Oh, I'm sorry. It gets worse. It is USB mini. It is

1467
01:32:34,595 --> 01:32:37,845
Speaker 6:  mini. Oh no. Right. They, they changed nothing.

1468
01:32:38,995 --> 01:32:42,045
Speaker 6:  They, they, they just like stripped some stuff out to make it a little bit

1469
01:32:42,045 --> 01:32:45,605
Speaker 6:  cheaper for themselves. They didn't like lean into this in any way,

1470
01:32:45,815 --> 01:32:49,485
Speaker 6:  which maybe that just adds to the effect because

1471
01:32:49,555 --> 01:32:53,285
Speaker 6:  they literally didn't change anything. Like maybe, maybe the people do just

1472
01:32:53,435 --> 01:32:57,005
Speaker 6:  want to dig up old terrible USB cables and go, maybe

1473
01:32:57,005 --> 01:32:59,765
Speaker 5:  They want you to think it's the camera from 2016. Yeah. Like maybe that is

1474
01:32:59,765 --> 01:33:03,085
Speaker 5:  part of the appeal that like trying to be sort of faux retro.

1475
01:33:03,875 --> 01:33:07,485
Speaker 11:  That is what's crazy to me is the cable thing because I mean, like, you

1476
01:33:07,485 --> 01:33:11,405
Speaker 11:  know, disposable cameras are super popular right now. Like the

1477
01:33:11,405 --> 01:33:15,245
Speaker 11:  other day I tried to develop two and it cost me $65, which is

1478
01:33:15,245 --> 01:33:19,205
Speaker 11:  like so much. But yeah, I mean this,

1479
01:33:19,585 --> 01:33:22,525
Speaker 11:  the cable thing would really get me here. I just, I don't know if I could

1480
01:33:22,525 --> 01:33:23,245
Speaker 11:  reconcile that,

1481
01:33:24,035 --> 01:33:26,215
Speaker 6:  Put a lightning port on that thing. Now we're talking,

1482
01:33:28,415 --> 01:33:30,295
Speaker 6:  I, I think there's, there's something there.

1483
01:33:31,295 --> 01:33:35,135
Speaker 5:  I would, I really hope somebody tries to do like an

1484
01:33:35,135 --> 01:33:38,975
Speaker 5:  honest to god 2025 version of an entry level point and shoot.

1485
01:33:40,275 --> 01:33:43,015
Speaker 5:  I'd be, I'd be, I'd just be curious to see how it does because it, it might

1486
01:33:43,015 --> 01:33:46,895
Speaker 5:  totally not work because the point is that it looks like it's from 2016

1487
01:33:47,425 --> 01:33:48,695
Speaker 5:  maybe. Maybe that is it. This

1488
01:33:48,695 --> 01:33:51,855
Speaker 6:  Is the thing, like in my head I'm like, why didn't they make it better? And

1489
01:33:51,855 --> 01:33:55,095
Speaker 6:  it's like, because if they make it better, it gets worse, right? They can't

1490
01:33:55,095 --> 01:33:58,255
Speaker 6:  make it better. They can't make it take better photos. They can't make it

1491
01:33:58,255 --> 01:34:02,135
Speaker 6:  easier to use. It needs to be bad. It needs to look bad.

1492
01:34:02,795 --> 01:34:03,615
Speaker 6:  That's the point.

1493
01:34:03,775 --> 01:34:04,215
Speaker 5:  I think that's right.

1494
01:34:04,495 --> 01:34:06,175
Speaker 11:  I want it to be the same, but with a lightning port,

1495
01:34:07,555 --> 01:34:11,295
Speaker 6:  That's it. That, that both makes it worse and more

1496
01:34:11,295 --> 01:34:13,175
Speaker 6:  retro in a weird roundabout way.

1497
01:34:13,235 --> 01:34:16,015
Speaker 5:  And it doesn't, the lightning port doesn't even work or connect to anything

1498
01:34:16,255 --> 01:34:19,735
Speaker 5:  because they know all you're using this for is to show it. It's, it's, it's

1499
01:34:19,735 --> 01:34:22,215
Speaker 5:  it's arm candy. It doesn't even have to work as a camera. Doesn't matter.

1500
01:34:22,975 --> 01:34:24,055
Speaker 5:  All right Hayden, what's your second one?

1501
01:34:24,595 --> 01:34:28,095
Speaker 11:  My second one is how unsurprisingly

1502
01:34:29,035 --> 01:34:32,895
Speaker 11:  X'S contract with the DOD is being questioned by Senator

1503
01:34:32,995 --> 01:34:36,535
Speaker 11:  Warren and other people who think it's, the company is basically just not

1504
01:34:36,695 --> 01:34:40,455
Speaker 11:  equipped to deal with the level of influence it would have with a DOD

1505
01:34:40,695 --> 01:34:41,215
Speaker 11:  contract. Because you,

1506
01:34:41,355 --> 01:34:44,495
Speaker 5:  You're saying Brock running the government is not like cool, we're not fi

1507
01:34:44,805 --> 01:34:48,775
Speaker 11:  Exactly. Shocking news. Especially since they only started I

1508
01:34:48,775 --> 01:34:52,655
Speaker 11:  think building their safety team a couple months ago, like I think

1509
01:34:52,655 --> 01:34:56,535
Speaker 11:  maybe after the contract. I'll have to check that. But yeah, I saw

1510
01:34:56,535 --> 01:34:59,085
Speaker 11:  the tweet about them like hiring for their safety team And I was like, huh,

1511
01:34:59,085 --> 01:35:02,085
Speaker 11:  this is happening like pretty late. Like I know, I think it was after GR

1512
01:35:02,085 --> 01:35:05,605
Speaker 11:  four came out. I'll check. But yeah, I mean it's, you know, the,

1513
01:35:05,635 --> 01:35:08,485
Speaker 11:  basically the letter that Senator Warren sent

1514
01:35:09,425 --> 01:35:13,125
Speaker 11:  ETH was saying that XAI wasn't up for this

1515
01:35:13,565 --> 01:35:17,405
Speaker 11:  contract and being like looked at in the same way that other companies were,

1516
01:35:17,715 --> 01:35:21,125
Speaker 11:  that they kinda like skipped the line a little bit. There's a lot of like

1517
01:35:21,365 --> 01:35:25,285
Speaker 11:  questions in this letter that they're asking be answered. So

1518
01:35:25,635 --> 01:35:29,485
Speaker 11:  yeah, I mean, you know, basically Mecca Hitler running

1519
01:35:29,485 --> 01:35:31,765
Speaker 11:  the government. Like maybe not the best idea.

1520
01:35:32,705 --> 01:35:36,645
Speaker 5:  I'm gonna to, to borrow from another delayed full

1521
01:35:36,725 --> 01:35:39,205
Speaker 5:  VERGE cast segment that you guys piloted this summer that I liked and we're

1522
01:35:39,205 --> 01:35:43,165
Speaker 5:  gonna keep doing. This is all just a shenanigan, like full

1523
01:35:43,305 --> 01:35:45,405
Speaker 5:  on 100% shenanigans,

1524
01:35:46,225 --> 01:35:49,975
Speaker 11:  Truly shenanigans with like huge influence that could be really

1525
01:35:49,975 --> 01:35:52,895
Speaker 11:  problematic. So worst kind of shenanigan this

1526
01:35:53,095 --> 01:35:57,055
Speaker 6:  Deal was also announced the week after the Mecca

1527
01:35:57,055 --> 01:36:00,815
Speaker 6:  Hitler incident, which like in any normal timeline,

1528
01:36:00,915 --> 01:36:04,215
Speaker 6:  in any normal administration, you'd probably be like,

1529
01:36:04,955 --> 01:36:08,515
Speaker 6:  look, maybe maybe we shouldn't make this deal

1530
01:36:09,095 --> 01:36:12,435
Speaker 6:  at the very least, maybe we shouldn't publicize this deal. Maybe we should

1531
01:36:12,435 --> 01:36:16,195
Speaker 6:  wait a little bit. Maybe we should put some time between, you know,

1532
01:36:16,255 --> 01:36:20,235
Speaker 6:  us cutting the deal and, and the thing that we're paying for

1533
01:36:20,425 --> 01:36:23,595
Speaker 6:  declaring that it's Mecca Hitler. But no, they're just like, whatever, you

1534
01:36:23,595 --> 01:36:27,235
Speaker 6:  know, we we're with the Department of Defense, we deal with a bunch of really

1535
01:36:27,235 --> 01:36:30,395
Speaker 6:  important and dangerous materials.

1536
01:36:31,525 --> 01:36:31,945
Speaker 6:  We, we

1537
01:36:32,005 --> 01:36:35,745
Speaker 5:  And also Elon Musk is here. Yeah. It's just, it's just no problem. No, we

1538
01:36:35,745 --> 01:36:35,825
Speaker 5:  do,

1539
01:36:36,095 --> 01:36:39,785
Speaker 6:  Yeah. And they're currently hiring for their safety team, so please apply.

1540
01:36:40,205 --> 01:36:44,065
Speaker 11:  And one of the questions that's in this letter is like wondering how Musk

1541
01:36:44,205 --> 01:36:47,905
Speaker 11:  is gonna maybe improperly benefit from the unparalleled

1542
01:36:47,925 --> 01:36:51,625
Speaker 11:  access to DOD data and information. So yeah,

1543
01:36:51,945 --> 01:36:55,385
Speaker 11:  I mean there's just a lot here to unpack, but crazy

1544
01:36:56,045 --> 01:36:58,265
Speaker 11:  bad, questionable, all of it.

1545
01:36:58,815 --> 01:37:02,145
Speaker 5:  Yeah. I, I appreciate the, the vibe of this letter and you wrote a great

1546
01:37:02,145 --> 01:37:04,625
Speaker 5:  piece about it. We'll, we'll put it in the show notes, but the, the distinct

1547
01:37:04,625 --> 01:37:08,305
Speaker 5:  vibe of this letter is just like, what is happening?

1548
01:37:08,775 --> 01:37:11,985
Speaker 5:  Like how, how is this, what we're doing here?

1549
01:37:12,535 --> 01:37:16,185
Speaker 5:  It's just like so incredulous the whole way along. And I, I

1550
01:37:16,185 --> 01:37:20,065
Speaker 5:  appreciate the vibes coming out of Congress on that front. All right,

1551
01:37:20,065 --> 01:37:23,985
Speaker 5:  my last one before we get outta here, two pieces of Reddit news

1552
01:37:24,615 --> 01:37:28,545
Speaker 5:  this week that I find individually not that interesting, but in

1553
01:37:28,545 --> 01:37:32,385
Speaker 5:  combination there, there's like something happening here. So the first thing

1554
01:37:32,405 --> 01:37:36,345
Speaker 5:  is Reddit is dropping the subscriber counts on sub Reddit. So when you go

1555
01:37:36,345 --> 01:37:39,945
Speaker 5:  to sub Reddit, it'll say like, you know, X number of people joined. They're

1556
01:37:40,025 --> 01:37:43,945
Speaker 5:  dropping that in favor of some, like much squishier seeming metric about

1557
01:37:43,945 --> 01:37:47,025
Speaker 5:  like, how many people have been there in the last 28 days or something. Like,

1558
01:37:47,055 --> 01:37:50,945
Speaker 5:  they're trying to make it seem more sort of real time. I guess the,

1559
01:37:50,965 --> 01:37:54,905
Speaker 5:  the thesis is people who subscribe are not a good metric of how popular something

1560
01:37:55,125 --> 01:37:59,005
Speaker 5:  actually is. I don't know. And then the other one is Reddit appears to be

1561
01:37:59,005 --> 01:38:02,605
Speaker 5:  working on a way to read articles that

1562
01:38:02,665 --> 01:38:06,085
Speaker 5:  you've like that, that you click on and discover on Reddit

1563
01:38:06,785 --> 01:38:10,685
Speaker 5:  inside of Reddit. And I will just say the thing in the

1564
01:38:10,685 --> 01:38:14,405
Speaker 5:  screenshot that we have looks very much exactly like

1565
01:38:14,645 --> 01:38:17,405
Speaker 5:  Facebook instant articles, and this is just Reddit.

1566
01:38:17,425 --> 01:38:18,085
Speaker 6:  Oh, we'll get there,

1567
01:38:18,265 --> 01:38:21,845
Speaker 5:  Trying to put the internet inside of Reddit again. And to me it's like,

1568
01:38:23,215 --> 01:38:27,045
Speaker 5:  there, there's, there's some, Reddit is either like really feeling

1569
01:38:27,145 --> 01:38:30,885
Speaker 5:  itself and thinks it is like the only website left that matters.

1570
01:38:31,105 --> 01:38:35,045
Speaker 5:  And so it can just take over and win or is like trying to quietly

1571
01:38:35,045 --> 01:38:37,925
Speaker 5:  pivot to something else. And I just, I can't figure out what Reddit is doing

1572
01:38:37,925 --> 01:38:38,165
Speaker 5:  here.

1573
01:38:38,805 --> 01:38:42,565
Speaker 6:  I think that, so Reddit is having maybe the, the

1574
01:38:42,885 --> 01:38:46,805
Speaker 6:  opposite experience of the rest of the internet because suddenly Reddit is

1575
01:38:46,825 --> 01:38:50,605
Speaker 6:  the only thing you can find via Google. Yes.

1576
01:38:50,715 --> 01:38:54,415
Speaker 6:  And so Reddit is blowing up. Absolutely. And I think they know that they

1577
01:38:54,415 --> 01:38:58,375
Speaker 6:  are super reliant on Google and you are correct. They're trying to put

1578
01:38:58,375 --> 01:39:01,735
Speaker 6:  the entire internet inside Reddit so that when Google inevitably

1579
01:39:02,205 --> 01:39:05,775
Speaker 6:  removes that funnel, everybody's still gonna Reddit. Right? This is what

1580
01:39:05,775 --> 01:39:09,095
Speaker 6:  they're, they're doing. They're, they're making it seem more lively.

1581
01:39:09,365 --> 01:39:12,855
Speaker 6:  They're like, this is how many people are here right now. This is an active

1582
01:39:12,855 --> 01:39:16,815
Speaker 6:  community. This is one you want to continue to check in on. And they're

1583
01:39:16,955 --> 01:39:20,815
Speaker 6:  not letting you leave and go to the actual internet when you click an

1584
01:39:20,815 --> 01:39:24,655
Speaker 6:  article. It does. I think it is just like a fancy popup

1585
01:39:24,655 --> 01:39:28,455
Speaker 6:  browser. So it's like, it's not, it's not quite instant articles

1586
01:39:28,475 --> 01:39:31,575
Speaker 6:  yet, but you, you can see how they get there, right? Yeah. I think they're

1587
01:39:31,575 --> 01:39:35,295
Speaker 6:  trying to bring more of the internet inside Reddit so they can continue to

1588
01:39:35,295 --> 01:39:37,575
Speaker 6:  get more people and keep them inside the Reddit app

1589
01:39:38,195 --> 01:39:42,135
Speaker 11:  And the fact that you can, you know, read comments while you're reading

1590
01:39:42,135 --> 01:39:44,775
Speaker 11:  the article, you know? So I think it's just all about, like Jake said, like,

1591
01:39:44,915 --> 01:39:48,415
Speaker 11:  you know, keeping them on the platform, keeping you engaged. Like,

1592
01:39:48,765 --> 01:39:51,815
Speaker 11:  okay, maybe you're reading the article, you see a comment while you're reading

1593
01:39:51,835 --> 01:39:54,935
Speaker 11:  it, okay, now you go back to the subreddit and comment something else. So

1594
01:39:54,935 --> 01:39:57,695
Speaker 11:  I think it's all about like, just yeah, keep like creating a walled garden

1595
01:39:57,695 --> 01:40:00,415
Speaker 11:  because they feel like, you know, they don't wanna be dependent on Google

1596
01:40:00,415 --> 01:40:00,735
Speaker 11:  anymore.

1597
01:40:01,035 --> 01:40:04,535
Speaker 6:  And Reddit's always been really thirsty too. It, whenever, if you

1598
01:40:04,765 --> 01:40:07,935
Speaker 6:  find one of their links, if you, if you visit a Reddit link

1599
01:40:08,525 --> 01:40:12,215
Speaker 6:  from a browser on mobile, it, it like

1600
01:40:12,415 --> 01:40:15,135
Speaker 6:  graze it out and gives you some popup and they're like, do you wanna continue

1601
01:40:15,135 --> 01:40:18,895
Speaker 6:  in your browser or the Reddit app? And I'm like, no, I'm, I don't wanna open

1602
01:40:18,895 --> 01:40:21,295
Speaker 6:  it in the Reddit app. I'm in my browser. Just let me read it.

1603
01:40:21,485 --> 01:40:22,935
Speaker 5:  Yeah. I, the it's

1604
01:40:22,935 --> 01:40:24,295
Speaker 6:  All about keeping you inside.

1605
01:40:24,915 --> 01:40:28,615
Speaker 5:  One of my alternate summer takes was death

1606
01:40:28,755 --> 01:40:32,695
Speaker 5:  to the open in app popups because everybody does it and it's all

1607
01:40:33,255 --> 01:40:36,215
Speaker 5:  horrible. It drives me crazy. And the thing where Instagram won't let you

1608
01:40:36,215 --> 01:40:37,335
Speaker 5:  look at posts on the way,

1609
01:40:37,765 --> 01:40:38,855
Speaker 6:  Just, oh my gosh,

1610
01:40:38,885 --> 01:40:40,375
Speaker 11:  This is my so annoying.

1611
01:40:40,725 --> 01:40:44,455
Speaker 5:  True disaster. But yeah, I think Reddit's in this weird place where like,

1612
01:40:44,455 --> 01:40:48,255
Speaker 5:  Reddit is very powerful because it is a place

1613
01:40:48,255 --> 01:40:51,575
Speaker 5:  where humans are, and there are increasingly few of those at scale on the

1614
01:40:51,735 --> 01:40:51,935
Speaker 5:  internet,

1615
01:40:53,505 --> 01:40:56,855
Speaker 5:  but also for, for all the reasons you guys are talking about, it's

1616
01:40:56,865 --> 01:41:00,775
Speaker 5:  completely reliant on Google for that fact to continue. So

1617
01:41:00,775 --> 01:41:04,615
Speaker 5:  I think I, it's, it's just weird seeing it try to figure

1618
01:41:04,635 --> 01:41:08,495
Speaker 5:  out what to do with this like, maybe brief moment in the

1619
01:41:08,495 --> 01:41:11,055
Speaker 5:  sun as AI destroys everything else around us.

1620
01:41:11,575 --> 01:41:14,815
Speaker 6:  I mean, it, can I tell you something a little trippy? I I did a Google search

1621
01:41:14,815 --> 01:41:18,775
Speaker 6:  for iPhone air, you know, 'cause that's a thing that's happening this week.

1622
01:41:18,925 --> 01:41:22,775
Speaker 6:  Sure. And I think the top result that was not a,

1623
01:41:22,935 --> 01:41:25,895
Speaker 6:  a, a sponsored Apple thing or, or was not just Apple itself

1624
01:41:26,765 --> 01:41:30,345
Speaker 6:  was a Reddit result. It was somebody being like, Hey, the iPhone air was

1625
01:41:30,345 --> 01:41:34,305
Speaker 6:  announced. Wow. And it's just like, Reddit is everything

1626
01:41:34,325 --> 01:41:35,145
Speaker 6:  now on search.

1627
01:41:35,905 --> 01:41:39,835
Speaker 5:  Yeah. It, it feels like, and and whatever that deal was that Google and Reddit

1628
01:41:39,835 --> 01:41:43,275
Speaker 5:  signed was basically just Reddit being like, yeah, we are search now.

1629
01:41:43,795 --> 01:41:46,875
Speaker 5:  Yeah. And Google's like, fine, there's no other good websites anymore. Here

1630
01:41:46,875 --> 01:41:50,835
Speaker 5:  you go. Alright. We have gone way over as we

1631
01:41:50,835 --> 01:41:53,315
Speaker 5:  are want to do, you guys didn't go over at all this summer. I don't think

1632
01:41:53,315 --> 01:41:57,275
Speaker 5:  those terrific work by you. You were always exactly to time Jake. You

1633
01:41:57,275 --> 01:42:00,875
Speaker 5:  were a true task master. But now I'm back and chaos rains and so does the

1634
01:42:00,875 --> 01:42:01,715
Speaker 5:  lightning round. So maybe

1635
01:42:01,775 --> 01:42:03,235
Speaker 14:  The thunder round isn't slower.

1636
01:42:05,615 --> 01:42:07,235
Speaker 6:  Our producers are too powerful.

1637
01:42:08,305 --> 01:42:11,715
Speaker 5:  Yeah, this is, this is, I'm, I've, I've ruined everything forever. I'm gonna

1638
01:42:11,715 --> 01:42:14,475
Speaker 5:  have to bring my own soundboard next week and then that's the real move.

1639
01:42:14,545 --> 01:42:17,915
Speaker 5:  Yeah. Y'all are toast After that. Alright, we gotta get outta here. One quick

1640
01:42:17,915 --> 01:42:21,795
Speaker 5:  housekeeping thing. Next week's Tuesday episode is going to be a

1641
01:42:21,795 --> 01:42:25,075
Speaker 5:  Wednesday episode because there's just a lot of Apple stuff happening next

1642
01:42:25,075 --> 01:42:27,635
Speaker 5:  week and we just wanted to give ourselves as much time as possible to cover

1643
01:42:27,635 --> 01:42:30,515
Speaker 5:  as much of it as possible. So that episode is gonna come out next Wednesday

1644
01:42:31,095 --> 01:42:34,675
Speaker 5:  if you have questions about all of it, all the new gadgets, all the new software.

1645
01:42:34,675 --> 01:42:38,355
Speaker 5:  If you hate Liquid Glass as much as I do, we wanna hear about it on the hotline.

1646
01:42:38,355 --> 01:42:41,875
Speaker 5:  8 6 6 VERGE one one. Send us an email at vergecast at The Verge dot com.

1647
01:42:42,715 --> 01:42:45,835
Speaker 5:  The Vergecast is a production of The Verge and the Vox Media Podcast network.

1648
01:42:46,235 --> 01:42:49,555
Speaker 5:  The show is produced by Eric Gomez, Brandon Keefer, and Travis Uck, Hayden

1649
01:42:49,555 --> 01:42:52,915
Speaker 5:  Field, and Jake Kaki. It's an honor to be back doing this with you guys.

1650
01:42:52,915 --> 01:42:53,875
Speaker 5:  Thank you for doing this with me.

1651
01:42:53,935 --> 01:42:55,035
Speaker 6:  We missed you. We really

1652
01:42:55,055 --> 01:42:55,275
Speaker 14:  Did.

1653
01:42:55,565 --> 01:42:57,195
Speaker 5:  We'll see you next time. Rock and roll.

