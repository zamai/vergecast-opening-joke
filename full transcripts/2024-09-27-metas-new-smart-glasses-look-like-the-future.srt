1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 23db5c07-cfb7-46a9-8cdc-1baa27455ede
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/434036981777114548/1777972915800737291/s93290-US-6292s-1727432530.mp3
Description: The Verge's Alex Heath joins Nilay, Alex, and David to talk about all the announcements coming out of Meta Connect: the impressive (and expensive) Orion glasses, the new features for the Ray-Ban Smart Glasses, and lots and lots of new AI. Then they discuss the latest executive departures at OpenAI, as the industry's foremost AI company undergoes a huge shift. In the lightning round, it's time for more AI gadgets, the PS5 Pro... and then some more AI gadgets.

2
00:00:39,065 --> 00:00:42,845
Speaker 3:  of wearable stuff. I don't wanna start with a swear word, but

3
00:00:43,025 --> 00:00:45,645
Speaker 3:  If. you know, there it's usually a swear word. Hi, I'm your friend. Neli.

4
00:00:45,645 --> 00:00:46,365
Speaker 3:  Alex. Kran here.

5
00:00:46,585 --> 00:00:49,005
Speaker 5:  I'm also wearing my augmented reality glasses right now

6
00:00:49,395 --> 00:00:51,085
Speaker 3:  Because they pass light through them. Yeah,

7
00:00:51,085 --> 00:00:53,525
Speaker 5:  They pass light through them and everything is augmented now. I can see

8
00:00:54,795 --> 00:00:58,205
Speaker 3:  It's been augmented into focus. Yeah, I got you. David Pierce is here.

9
00:00:58,295 --> 00:00:58,645
Speaker 6:  Hello?

10
00:00:59,265 --> 00:01:02,845
Speaker 3:  And Alex Heath is here. Alex, are you actually wearing a face computer?

11
00:01:03,685 --> 00:01:05,805
Speaker 7:  I am, but you'll never know.

12
00:01:08,235 --> 00:01:12,165
Speaker 3:  It's, it's Big week in Tech News. Quite a lot going on. It was Meta, Connect.

13
00:01:12,315 --> 00:01:16,165
Speaker 3:  Alex was there, along with Kylie Robinson and j Peters.

14
00:01:16,515 --> 00:01:20,205
Speaker 3:  Alex. You wore the Orion AR glasses, the demo you interviewed Zuckerberg.

15
00:01:20,205 --> 00:01:23,525
Speaker 3:  We gotta talk all about that. There's tons of other news outta Meta Connect

16
00:01:23,865 --> 00:01:26,765
Speaker 3:  and then there's chaos at Open ai, which a company

17
00:01:28,055 --> 00:01:31,755
Speaker 3:  for being as successful as it is remains mired in, in nothing but

18
00:01:31,785 --> 00:01:33,195
Speaker 3:  pure chaos. We

19
00:01:33,195 --> 00:01:36,435
Speaker 6:  Could just snip that and play it every single week on the first cast. Yeah,

20
00:01:36,555 --> 00:01:40,115
Speaker 6:  just that thing you just said is like a, it's just a universally true statement

21
00:01:40,115 --> 00:01:40,555
Speaker 6:  at this point.

22
00:01:40,945 --> 00:01:42,715
Speaker 3:  Yeah, we, we have to talk about that. And then

23
00:01:44,495 --> 00:01:46,355
Speaker 3:  we have a lightning round unsponsored

24
00:01:46,925 --> 00:01:47,275
Speaker 5:  Still.

25
00:01:48,075 --> 00:01:51,675
Speaker 3:  I have walked into rooms at this company. Yeah. Demanded why the lightning

26
00:01:51,675 --> 00:01:52,715
Speaker 3:  round is unsponsored.

27
00:01:53,095 --> 00:01:54,075
Speaker 5:  Was anybody else in the room?

28
00:01:54,295 --> 00:01:58,275
Speaker 3:  No one else was in the rooms. This is the, I'm getting, I'm working

29
00:01:58,415 --> 00:02:02,355
Speaker 3:  up to the, the final result. But you walk into a

30
00:02:02,355 --> 00:02:05,675
Speaker 3:  room, you know where Eater is having a staff meeting demanding the lightning

31
00:02:05,675 --> 00:02:08,475
Speaker 3:  round be sponsored and they're like, I don't, we're doing a roundup on cakes.

32
00:02:08,475 --> 00:02:12,155
Speaker 3:  Like get outta here. I'm working on it every day. Closer

33
00:02:12,335 --> 00:02:16,155
Speaker 3:  to the, the goal. Okay, let's start with Meta. Alex.

34
00:02:16,335 --> 00:02:19,155
Speaker 3:  You wore the Orion. We, I think the Orion is the thing to talk about. They've

35
00:02:19,155 --> 00:02:22,395
Speaker 3:  been working on this for 10 years at Reality Labs burning billions of dollars

36
00:02:22,595 --> 00:02:26,355
Speaker 3:  a year. They did it. They made AR glasses, but you can't buy them and they

37
00:02:26,355 --> 00:02:27,195
Speaker 3:  cost $10,000

38
00:02:27,665 --> 00:02:31,275
Speaker 7:  Kind of. Yeah, you can't buy them. So they are glasses

39
00:02:31,455 --> 00:02:34,955
Speaker 7:  in the sense that you could put them on and they work to a degree.

40
00:02:36,715 --> 00:02:39,875
Speaker 7:  I wrote this in the story and I had a hard time writing about this because

41
00:02:40,585 --> 00:02:44,475
Speaker 7:  I've been getting a lot of almost products put on my face

42
00:02:44,795 --> 00:02:46,515
Speaker 7:  recently. Like just coming off of Snap.

43
00:02:47,655 --> 00:02:50,675
Speaker 3:  We do have a series of photos of you that is incredible right now.

44
00:02:50,745 --> 00:02:54,675
Speaker 7:  Yeah. I need to make like a, like a photo book to just have at

45
00:02:54,675 --> 00:02:56,755
Speaker 7:  home and look at it and go like, that's a cry for help

46
00:02:59,025 --> 00:03:00,565
Speaker 7:  Me wearing all these face computers.

47
00:03:02,235 --> 00:03:04,605
Speaker 7:  Yeah, it's, it's a really impressive demo.

48
00:03:06,165 --> 00:03:09,765
Speaker 7:  I think Meta is doing the demos

49
00:03:09,875 --> 00:03:13,485
Speaker 7:  because it knows it's impressive, but it's not a product. So

50
00:03:14,165 --> 00:03:17,565
Speaker 7:  I mean, I wrote this in the story. It's, it's not vaporware. Like it's very

51
00:03:17,565 --> 00:03:21,285
Speaker 7:  real and it's not a simulation, it's not totally on

52
00:03:21,375 --> 00:03:25,325
Speaker 7:  rails. I used it for probably a total of two and a half hours between

53
00:03:25,325 --> 00:03:29,205
Speaker 7:  the two days we were shooting. And I had enough opportunity

54
00:03:29,225 --> 00:03:32,925
Speaker 7:  to go off of the beaten path a little bit and make sure I wasn't just

55
00:03:32,955 --> 00:03:36,765
Speaker 7:  getting piped in a complete simulation. And it's, it's a real

56
00:03:36,765 --> 00:03:40,165
Speaker 7:  working piece of kit but it's not a product.

57
00:03:40,665 --> 00:03:44,405
Speaker 7:  And that says a lot about the state of AR and these glasses.

58
00:03:45,345 --> 00:03:49,225
Speaker 7:  And at the same time I finally

59
00:03:49,415 --> 00:03:53,185
Speaker 7:  feel like I've been running about this for so long, banging my head against

60
00:03:53,185 --> 00:03:56,385
Speaker 7:  the wall and being like, what am I doing? This is never gonna happen.

61
00:03:57,125 --> 00:04:00,835
Speaker 7:  And I finally feel after this week that AR glasses

62
00:04:01,195 --> 00:04:03,755
Speaker 7:  I may actually want to use are not a pipe dream.

63
00:04:03,865 --> 00:04:06,635
Speaker 3:  Yeah. I wanna argue with you about the definition of the word vaporware,

64
00:04:06,635 --> 00:04:08,195
Speaker 3:  which is very important to me personally.

65
00:04:08,295 --> 00:04:08,995
Speaker 7:  And holograms.

66
00:04:09,055 --> 00:04:12,475
Speaker 3:  And holograms. So let's start, that's, and Alex and I got into a real fight

67
00:04:12,475 --> 00:04:15,715
Speaker 3:  about what ho the word holograms means this week. We'll get into all this

68
00:04:15,755 --> 00:04:19,475
Speaker 3:  I promise, but let's start with what it is, right? Because AR glasses

69
00:04:20,535 --> 00:04:23,155
Speaker 3:  you are correct. The industry has been talking about them for a long time.

70
00:04:24,165 --> 00:04:28,035
Speaker 3:  Magic Leap promised AR glasses years ago, if

71
00:04:28,035 --> 00:04:31,835
Speaker 3:  you'll remember, their founder claimed that he could hack the

72
00:04:31,995 --> 00:04:35,975
Speaker 3:  GPU of your brain. This is a real thing that, and that was

73
00:04:36,035 --> 00:04:39,935
Speaker 3:  in reference to a display technology because this is the challenge. How do

74
00:04:39,935 --> 00:04:43,255
Speaker 3:  we build a display that you can look through that can augment reality, have

75
00:04:43,255 --> 00:04:46,975
Speaker 3:  the processing power to see reality and augment it, have connectivity, have

76
00:04:46,975 --> 00:04:50,935
Speaker 3:  a battery that, and no one can solve these problems. Most

77
00:04:51,055 --> 00:04:54,935
Speaker 3:  of all the display. Yeah. The, the thing doesn't

78
00:04:54,935 --> 00:04:58,775
Speaker 3:  exist. The thing that you look through to perceive the world and then layer

79
00:04:58,775 --> 00:05:02,695
Speaker 3:  information over stuff you could maybe solve battery and processing

80
00:05:02,695 --> 00:05:06,135
Speaker 3:  and all this stuff in, in, you're wearing a backpack, but the actual display

81
00:05:06,135 --> 00:05:10,015
Speaker 3:  technology to make it good is more or less not

82
00:05:10,015 --> 00:05:13,775
Speaker 3:  existed in any realistic way. And Magic Leap had to give up on their

83
00:05:13,775 --> 00:05:16,455
Speaker 3:  idea and they tried another thing. And HoloLens was another thing with a

84
00:05:16,455 --> 00:05:20,015
Speaker 3:  tiny field of view. And there's a long list of things with bad fields of

85
00:05:20,015 --> 00:05:23,895
Speaker 3:  view. and it seems like that's the thing Meta solved most of all

86
00:05:23,895 --> 00:05:24,135
Speaker 3:  here.

87
00:05:24,605 --> 00:05:28,455
Speaker 7:  Yeah. As quote that really stuck out to me from the

88
00:05:28,455 --> 00:05:31,735
Speaker 7:  product lead when I was getting my demo, was that the display

89
00:05:32,395 --> 00:05:35,815
Speaker 7:  was a scientific breakthrough problem they had to solve.

90
00:05:36,435 --> 00:05:40,335
Speaker 7:  And now they're in the engineering problem solving phase of making these

91
00:05:40,335 --> 00:05:44,175
Speaker 7:  glasses work at a price point that people can actually buy. And

92
00:05:44,175 --> 00:05:47,615
Speaker 7:  that really stuck with me. I you're right that the display is the hardest

93
00:05:47,685 --> 00:05:51,535
Speaker 7:  part. The distinction between ar glasses like these in the

94
00:05:51,535 --> 00:05:55,375
Speaker 7:  Vision Pro or the Meta quest is that yes, you can do mixed

95
00:05:55,375 --> 00:05:58,365
Speaker 7:  reality in the pro and the quest in the vision and the quest, but

96
00:05:59,155 --> 00:06:03,045
Speaker 7:  what they're doing is fully enclosing your face in a computer piping

97
00:06:03,045 --> 00:06:07,005
Speaker 7:  video in and mixing all that in the displays. These are literally

98
00:06:07,005 --> 00:06:10,805
Speaker 7:  just these glasses. Orion are letting light in their actual glasses. And

99
00:06:10,805 --> 00:06:14,725
Speaker 7:  so the, the challenge there is, is much different

100
00:06:15,385 --> 00:06:19,085
Speaker 7:  and Meta has a lot of good ideas here

101
00:06:19,505 --> 00:06:23,395
Speaker 7:  and they also I think realized that the

102
00:06:23,915 --> 00:06:27,395
Speaker 7:  specific optical stack that they went with for Orion was just

103
00:06:28,145 --> 00:06:31,835
Speaker 7:  inex like inexplicably hard to manufacture.

104
00:06:32,295 --> 00:06:35,675
Speaker 7:  And it's, these lenses are made of silicon carbide,

105
00:06:36,005 --> 00:06:39,115
Speaker 7:  which is also used in like space.

106
00:06:40,025 --> 00:06:41,835
Speaker 7:  It's used in EVs, it's, it's used

107
00:06:41,835 --> 00:06:45,155
Speaker 5:  In like Dremels. It's, it's like the, what you use for cutting tools, it's

108
00:06:45,155 --> 00:06:45,435
Speaker 5:  primarily,

109
00:06:45,435 --> 00:06:47,795
Speaker 7:  It's literally like a giant crystal. And so yeah,

110
00:06:47,865 --> 00:06:51,755
Speaker 5:  It's also used for wedding rings sometimes. So basically it's like having

111
00:06:51,775 --> 00:06:53,315
Speaker 5:  two fake diamonds on your face.

112
00:06:53,545 --> 00:06:56,675
Speaker 7:  Yeah. And they were talking to me about this in this like challenge of the

113
00:06:56,675 --> 00:07:00,315
Speaker 7:  yields on this. It's like, yeah, you, you have to cut the crystal perfectly.

114
00:07:00,825 --> 00:07:04,195
Speaker 7:  He's like, and there's not enough of it in the world. So we're, we're growing

115
00:07:04,315 --> 00:07:07,875
Speaker 7:  crystals we're growing like big ass silicon carbide

116
00:07:07,875 --> 00:07:11,595
Speaker 3:  Rocks. I'm sorry the, the image of Mark Zuckerberg walking into the basement

117
00:07:11,595 --> 00:07:15,155
Speaker 3:  of his layer looking at his like crystal farm in a haze of like purple

118
00:07:15,285 --> 00:07:18,235
Speaker 3:  smoke and being like, I will conquer the world.

119
00:07:20,625 --> 00:07:24,115
Speaker 3:  Fuck. I mean like I'm go get it Mark. You know? Yeah. Like yeah.

120
00:07:24,185 --> 00:07:25,115
Speaker 5:  Very distinct image.

121
00:07:25,695 --> 00:07:29,115
Speaker 3:  But but you have to be that person to do this I think. Yeah, yeah,

122
00:07:29,115 --> 00:07:32,635
Speaker 7:  Yeah. Yeah. And that's another thing of all this that we'll get into this

123
00:07:32,635 --> 00:07:36,595
Speaker 7:  is like, I think this is a device that only Meta could have built in a way

124
00:07:36,595 --> 00:07:38,955
Speaker 7:  that they can show to the world because for a lot of reasons

125
00:07:40,385 --> 00:07:40,955
Speaker 7:  that are very,

126
00:07:41,235 --> 00:07:42,995
Speaker 5:  'cause everybody else would expect it to ship.

127
00:07:43,625 --> 00:07:43,915
Speaker 7:  Yeah.

128
00:07:44,395 --> 00:07:47,955
Speaker 5:  Like everybody else does hardware more often. So we'd be like, okay, but

129
00:07:47,955 --> 00:07:48,235
Speaker 5:  when

130
00:07:49,115 --> 00:07:52,555
Speaker 7:  I think if Meta was not a founder mode company

131
00:07:52,935 --> 00:07:56,715
Speaker 7:  to the fullest extent, this thing would've been killed a long time ago.

132
00:07:56,935 --> 00:08:00,755
Speaker 3:  So can I read you, I just wanna read you a quote from Ben Thompson

133
00:08:01,475 --> 00:08:04,555
Speaker 3:  who writes a newsletter called Trek. He tried on Hawaiian and he just said

134
00:08:04,555 --> 00:08:08,475
Speaker 3:  this thing that it just made me start laughing a

135
00:08:08,475 --> 00:08:11,875
Speaker 3:  lot and I'll explain why it made me laugh so hard. Here's the quote, the

136
00:08:11,875 --> 00:08:14,315
Speaker 3:  difference from the quest. And he is him talking about Orion,

137
00:08:15,855 --> 00:08:19,035
Speaker 3:  the obvious limitations of display, particularly low resolution, felt immaterial.

138
00:08:19,095 --> 00:08:22,675
Speaker 3:  The difference from the Quest or Vision Pro is that actually looking at reality

139
00:08:22,775 --> 00:08:26,675
Speaker 3:  is so dramatically different from even best in class pass

140
00:08:26,675 --> 00:08:30,595
Speaker 3:  through that holographic video quality doesn't really matter. Even the highest

141
00:08:30,625 --> 00:08:34,235
Speaker 3:  quality presentation layer will pale in comparison to reality.

142
00:08:34,895 --> 00:08:38,475
Speaker 3:  Hmm. Yeah dude, I mean this is very funny. He's presenting this as like a

143
00:08:38,485 --> 00:08:41,555
Speaker 3:  right and it's Ben and that's how he writes and that's fun. But If, you'll

144
00:08:41,555 --> 00:08:45,315
Speaker 3:  recall my review of the Vision Pro was looking at display

145
00:08:45,315 --> 00:08:48,555
Speaker 3:  sucks. Like this is the end of the road for video pass through

146
00:08:49,095 --> 00:08:52,595
Speaker 3:  If. you want to put a screen in front of your head in a VR headset and then

147
00:08:52,595 --> 00:08:55,965
Speaker 3:  do camera based pass through. This is as good as it will ever be. and it

148
00:08:55,965 --> 00:08:59,535
Speaker 3:  is nowhere near good enough. At the time. Many people

149
00:08:59,815 --> 00:09:02,935
Speaker 3:  disagreed with me. I believe that I have been proven to be correct about

150
00:09:02,935 --> 00:09:06,895
Speaker 3:  the value of the Vision Pro over time. Still not pleased with

151
00:09:06,895 --> 00:09:09,535
Speaker 3:  myself that I gave it a seven, seven outta 10. So, so,

152
00:09:10,715 --> 00:09:14,135
Speaker 3:  but like this is the thing, right? Meta built the displays that grew the

153
00:09:14,135 --> 00:09:17,575
Speaker 3:  crystals. Zuckerberg is like, I'm spending the money, I can't be fired because

154
00:09:17,695 --> 00:09:21,495
Speaker 3:  I own super voting shares of this company. Here's here

155
00:09:21,525 --> 00:09:23,375
Speaker 3:  it's, I made the displays.

156
00:09:25,105 --> 00:09:27,995
Speaker 3:  When you say it's not a product, did he make the rest of it? Like does the,

157
00:09:27,995 --> 00:09:29,155
Speaker 3:  is the software good?

158
00:09:29,485 --> 00:09:33,235
Speaker 7:  There is an os, right? So I. Guess I'll just quickly explain like how

159
00:09:33,395 --> 00:09:36,635
Speaker 7:  we got to where we are. They started developing this about 10 years ago.

160
00:09:37,025 --> 00:09:40,955
Speaker 7:  This is like Zuckerberg's big bet to maybe control the

161
00:09:40,955 --> 00:09:44,875
Speaker 7:  next computing platform. If, you buy into the idea that face computers are

162
00:09:44,875 --> 00:09:48,675
Speaker 7:  maybe that in 2022 it became everything

163
00:09:48,875 --> 00:09:52,675
Speaker 7:  everyone remembers the year of efficiency, Meta stock was in

164
00:09:52,775 --> 00:09:56,675
Speaker 7:  was not doing as well. They were cutting back budgets and they decided

165
00:09:56,675 --> 00:10:00,355
Speaker 7:  looking at how expensive it was gonna be to create Orion.

166
00:10:00,935 --> 00:10:04,315
Speaker 7:  I'm told that the cost to build is somewhere around $10,000 per pair.

167
00:10:05,655 --> 00:10:09,635
Speaker 7:  And that the display stack, especially the lenses, the silicon carbide was

168
00:10:09,635 --> 00:10:13,395
Speaker 7:  just not something that would scale. They decided to make it a

169
00:10:13,395 --> 00:10:16,755
Speaker 7:  prototype internally. And then there was debate after that of, okay, do we

170
00:10:16,905 --> 00:10:20,755
Speaker 7:  show it to the world at all? Is it good enough? And I mean

171
00:10:20,755 --> 00:10:24,435
Speaker 7:  the thing that stuck out to me that Boz, the CTO told me was like, we just,

172
00:10:24,815 --> 00:10:27,755
Speaker 7:  we just didn't think this was gonna work at all. We, when we set out to build

173
00:10:27,755 --> 00:10:30,875
Speaker 7:  this, we thought maybe a 10% chance we actually get to a working device.

174
00:10:31,575 --> 00:10:35,355
Speaker 7:  and it, I think he literally said, I was just like, holy shit,

175
00:10:35,375 --> 00:10:35,755
Speaker 7:  it works.

176
00:10:36,545 --> 00:10:36,835
Speaker 3:  Yeah.

177
00:10:37,255 --> 00:10:40,795
Speaker 7:  And I think they were amazed that it works. And so they started in

178
00:10:40,905 --> 00:10:44,835
Speaker 7:  earnest on the software stack like three months ago deciding that they were

179
00:10:44,835 --> 00:10:48,435
Speaker 7:  gonna show it off at Connect. So it does have an os

180
00:10:49,255 --> 00:10:53,035
Speaker 7:  you know, they have pretty concrete ideas, especially on the interaction

181
00:10:53,115 --> 00:10:57,075
Speaker 7:  elements of it, which we'll get into the software is is bare bones.

182
00:10:57,075 --> 00:11:00,475
Speaker 7:  They've got some demo apps. They had Instagram, you and I did a call over

183
00:11:00,475 --> 00:11:04,355
Speaker 7:  Messenger neli, they've got a web browser. But

184
00:11:04,355 --> 00:11:08,195
Speaker 7:  these are like the early primitives of how you would bring

185
00:11:08,335 --> 00:11:12,275
Speaker 7:  2D experiences into 3D space. It's like a float A, it's like Vision Pro.

186
00:11:12,305 --> 00:11:16,075
Speaker 7:  It's like a floating pain. Yeah. I think the work they're doing now that

187
00:11:16,075 --> 00:11:19,195
Speaker 7:  they have a working kit is in the next couple of years, how do you actually

188
00:11:19,195 --> 00:11:21,715
Speaker 7:  make uniquely 3D

189
00:11:22,625 --> 00:11:26,595
Speaker 7:  augmented type interfaces? Which is like, you just have to

190
00:11:26,595 --> 00:11:29,875
Speaker 7:  have the thing on your face. You have to be able to use it. And for the longest

191
00:11:29,945 --> 00:11:33,915
Speaker 7:  time, this hasn't been something that even resembles an actual pair of

192
00:11:33,915 --> 00:11:37,755
Speaker 7:  glasses. Like the, the thing they showed me that it was even like in 2022,

193
00:11:37,755 --> 00:11:41,515
Speaker 7:  it had like a backpack. I mean it was just the, the iteration they've done

194
00:11:41,585 --> 00:11:45,235
Speaker 7:  even in just the last couple years is is pretty remarkable. Yeah. So

195
00:11:46,465 --> 00:11:50,355
Speaker 7:  yeah, I, the software had enough ideas

196
00:11:50,415 --> 00:11:54,275
Speaker 7:  in it to where I went, okay, they have ideas of where this

197
00:11:54,275 --> 00:11:58,045
Speaker 7:  is going. Still super rough, but like the AI

198
00:11:58,045 --> 00:12:01,365
Speaker 7:  stuff especially, it's compelling the idea that what all did

199
00:12:01,365 --> 00:12:02,765
Speaker 3:  You get to actually do in the headset?

200
00:12:03,195 --> 00:12:06,285
Speaker 7:  Yeah. We did, you know, web browsing, video calling,

201
00:12:08,015 --> 00:12:11,845
Speaker 7:  basic kind of Instagram stuff, calling in a

202
00:12:11,965 --> 00:12:15,925
Speaker 7:  2D HD pane, which like, NELI beamed him that way. And I could see him,

203
00:12:15,945 --> 00:12:19,005
Speaker 7:  he couldn't see me. 'cause they, there's all these things in Orion that they

204
00:12:19,005 --> 00:12:21,725
Speaker 7:  just turned off because they decided to not make it a product. Like there's,

205
00:12:21,725 --> 00:12:24,765
Speaker 7:  they have inward facing cameras that could potentially map your face to an

206
00:12:24,765 --> 00:12:27,205
Speaker 7:  avatar to show someone and they just haven't turned off. 'cause like they're

207
00:12:27,205 --> 00:12:29,365
Speaker 7:  not, that's not being used for that now. Yeah. But they could

208
00:12:29,365 --> 00:12:30,725
Speaker 5:  Also just look like garbage.

209
00:12:31,315 --> 00:12:31,605
Speaker 3:  Yeah.

210
00:12:31,635 --> 00:12:35,045
Speaker 7:  Yeah. So we did that. Some Meta employees came in as

211
00:12:35,235 --> 00:12:39,005
Speaker 7:  avatars, like floating, like think of the horizon quest avatar style. But

212
00:12:39,005 --> 00:12:39,965
Speaker 3:  Like legs or no legs,

213
00:12:40,355 --> 00:12:43,125
Speaker 7:  Legs, legs and like full body scale across the

214
00:12:43,125 --> 00:12:45,245
Speaker 3:  World. $10,000 a leg is what I'm told. Yeah.

215
00:12:46,545 --> 00:12:50,485
Speaker 7:  And then we did like a code. They have their hyper realistic kind of unca,

216
00:12:50,755 --> 00:12:54,605
Speaker 7:  uncanny Valley Kodak avatars, someone called in as one of those as well.

217
00:12:56,065 --> 00:12:58,965
Speaker 7:  And then there were some games. And the games were actually, you know, I've

218
00:12:58,965 --> 00:13:02,725
Speaker 7:  done a lot of really kind of I would say just gimmicky ar

219
00:13:02,815 --> 00:13:06,685
Speaker 7:  games in my career. And the games were actually decent, like the interactions

220
00:13:06,685 --> 00:13:10,285
Speaker 7:  because they've nailed a lot of the interaction elements and input

221
00:13:10,285 --> 00:13:14,205
Speaker 7:  elements of the glasses. The game experience was, was

222
00:13:14,405 --> 00:13:16,885
Speaker 7:  actually surprisingly good. And they have some connected ones where like

223
00:13:16,885 --> 00:13:20,485
Speaker 7:  you scan a QR code, you're in this pong game immediately with someone else

224
00:13:20,485 --> 00:13:23,725
Speaker 7:  wearing the glasses who just scanned it. And that's how I did it with Zuckerberg.

225
00:13:23,725 --> 00:13:27,485
Speaker 7:  And the video, you can see on all of the verges channels. He,

226
00:13:27,505 --> 00:13:28,845
Speaker 7:  he beat me of course in Palm,

227
00:13:29,945 --> 00:13:33,685
Speaker 5:  Did they have a laser tag game? I just, that's my AR dream.

228
00:13:33,955 --> 00:13:37,725
Speaker 7:  Yeah, that would be cool. They had this kind of space invaders esque game

229
00:13:37,725 --> 00:13:41,485
Speaker 7:  where your head was move the ship. And the band, which we'll talk about was,

230
00:13:41,625 --> 00:13:43,805
Speaker 7:  was the, was the lasers for the ship.

231
00:13:43,945 --> 00:13:47,485
Speaker 3:  So here's what I'm curious about the Yeah, they've built a lot of stuff

232
00:13:48,145 --> 00:13:51,605
Speaker 3:  in the Quest, right? Like they've taken Android, they've built an entire

233
00:13:51,875 --> 00:13:55,805
Speaker 3:  operating system, they have a store. A lot of

234
00:13:55,805 --> 00:13:59,245
Speaker 3:  that is complete. And I've always assumed based on what Mark and others have

235
00:13:59,245 --> 00:14:02,765
Speaker 3:  said is that they're doing all that work there in that form

236
00:14:02,925 --> 00:14:06,765
Speaker 3:  factor. And that lets them build the software experiences and then

237
00:14:06,765 --> 00:14:10,685
Speaker 3:  they're building the ray bands and the other form factor. And then, you

238
00:14:10,685 --> 00:14:14,565
Speaker 3:  know, Orion is like the goal. Are they using

239
00:14:14,665 --> 00:14:18,605
Speaker 3:  any of the stuff from the Quest? Like any of the, the user

240
00:14:18,605 --> 00:14:21,485
Speaker 3:  interface gestures, any of the, is it Android? Like

241
00:14:21,515 --> 00:14:25,205
Speaker 7:  Yeah, it's, it's Android based. It's a similar kind of app launcher ui.

242
00:14:26,785 --> 00:14:29,605
Speaker 7:  The thing with the app launcher though that's different is like, it's, it's

243
00:14:29,605 --> 00:14:33,085
Speaker 7:  much more minimal and your finger gesture brings it up and then when, and

244
00:14:33,085 --> 00:14:37,005
Speaker 7:  then takes it away just as quickly. It, they're very different

245
00:14:37,005 --> 00:14:40,645
Speaker 7:  products. I mean the app, the avatar was the same as what you would see on

246
00:14:40,645 --> 00:14:41,525
Speaker 7:  like a Quest game.

247
00:14:41,665 --> 00:14:44,765
Speaker 3:  But I'm just getting at, you know, like Zuck has laid out the idea that like

248
00:14:44,785 --> 00:14:47,885
Speaker 3:  the Meta ray bands are on one side of the spectrum

249
00:14:48,625 --> 00:14:52,525
Speaker 3:  and the headset is on the other side where it, it, this is not

250
00:14:52,525 --> 00:14:55,765
Speaker 3:  the right form factor, but I can do everything in it and the raybans are

251
00:14:55,765 --> 00:14:58,805
Speaker 3:  the right form factor. I can't do anything in them hardly. And in the middle

252
00:14:58,825 --> 00:15:01,685
Speaker 3:  are these glasses right? And they're, these products are gonna converge towards

253
00:15:01,685 --> 00:15:04,685
Speaker 3:  the glasses So. I'm just, it just seems interesting to me that they haven't

254
00:15:05,355 --> 00:15:08,165
Speaker 3:  used all the stuff from the Quest. 'cause that was the plan that they sort

255
00:15:08,165 --> 00:15:08,645
Speaker 3:  of articulated.

256
00:15:08,645 --> 00:15:11,445
Speaker 7:  Well like I said, they started doing the software for this like three months

257
00:15:11,445 --> 00:15:15,045
Speaker 7:  ago. Sure. And I will say the coolest thing, David, to your earlier

258
00:15:15,365 --> 00:15:19,005
Speaker 7:  question that we did was this Meta AI thing where they laid out all these

259
00:15:19,005 --> 00:15:22,645
Speaker 7:  ingredients for a smoothie on a table. They gave me the prompt,

260
00:15:22,855 --> 00:15:26,125
Speaker 7:  which means they tuned it a little bit. Right? But there's

261
00:15:26,125 --> 00:15:27,445
Speaker 3:  Just a guy in the background being like,

262
00:15:27,865 --> 00:15:30,365
Speaker 7:  No, I messed around with it to know that it was actually, it was a model

263
00:15:30,365 --> 00:15:30,885
Speaker 7:  running, but

264
00:15:31,025 --> 00:15:32,885
Speaker 3:  It wasn't Tom Brady being like, all right, smoothie

265
00:15:33,145 --> 00:15:35,845
Speaker 7:  Go. Yeah. But it was like I asked it to make a smoothie outta the ingredients

266
00:15:35,845 --> 00:15:39,565
Speaker 7:  and it popped up like a recipe pane above me with, I could like click through

267
00:15:39,565 --> 00:15:40,245
Speaker 7:  the different steps.

268
00:15:40,705 --> 00:15:43,765
Speaker 6:  Can I just quickly be the, the turd in the punch bowl on this particular

269
00:15:44,035 --> 00:15:47,085
Speaker 6:  demo? Because I've seen a bunch of people talking about this particular demo

270
00:15:47,425 --> 00:15:51,405
Speaker 6:  and I am so spectacularly unimpressed with that demo. And I, I would

271
00:15:51,405 --> 00:15:55,005
Speaker 6:  like you to tell me why I'm wrong. So first of all, If, you go look at

272
00:15:55,115 --> 00:15:58,965
Speaker 6:  that demo. Every single thing on that table says what it is with Yeah.

273
00:15:59,065 --> 00:16:01,125
Speaker 6:  Big ass letters. That's true. And you know, it's a really, really easy thing

274
00:16:01,125 --> 00:16:04,645
Speaker 6:  to do. It does. The bag of dates says dates in big ass letters and the ba

275
00:16:04,665 --> 00:16:08,445
Speaker 6:  the box of matcha says matcha in big ass letters. Like those

276
00:16:08,465 --> 00:16:10,445
Speaker 6:  are not hard computer problems to solve

277
00:16:10,665 --> 00:16:11,885
Speaker 7:  It. Recognize that if

278
00:16:11,885 --> 00:16:13,965
Speaker 3:  You're listen to this in your car, I want you to know that right now, Alex

279
00:16:13,975 --> 00:16:17,885
Speaker 3:  Heath is scrolling through a picture to confirm or deny that the

280
00:16:17,885 --> 00:16:19,325
Speaker 3:  bag of dates says dates on it.

281
00:16:19,455 --> 00:16:23,405
Speaker 6:  There are two things on the table that don't say in words what

282
00:16:23,405 --> 00:16:26,205
Speaker 6:  they are on the box. It's the banana and it's the pineapple banana and it

283
00:16:26,485 --> 00:16:29,125
Speaker 6:  identifies the banana, which is again a really easy thing for a computer

284
00:16:29,125 --> 00:16:30,845
Speaker 6:  to do. and it misses the pineapple entirely.

285
00:16:31,095 --> 00:16:34,685
Speaker 3:  Again, I'm just, I'm just putting this out there. If you're listening, you

286
00:16:34,685 --> 00:16:37,885
Speaker 3:  know, when you're on a Google meet call with someone and their face instantly

287
00:16:37,885 --> 00:16:41,765
Speaker 3:  goes to I'm browsing the web face. Yeah, yeah. I've never seen anyone

288
00:16:41,835 --> 00:16:45,725
Speaker 3:  move to, I'm browsing the web face as fast as Alex did when

289
00:16:45,725 --> 00:16:47,165
Speaker 3:  David said everything had a label.

290
00:16:47,675 --> 00:16:50,485
Speaker 7:  Well, okay, you're right. So David, a big

291
00:16:50,505 --> 00:16:53,645
Speaker 6:  Box that says dates on it is not a hard computer problem to

292
00:16:53,645 --> 00:16:57,485
Speaker 7:  Solve, David. So the pineapple it missed in the video

293
00:16:57,565 --> 00:17:00,805
Speaker 7:  I did was zuck it Got it right the first day I did it.

294
00:17:00,995 --> 00:17:02,325
Speaker 6:  Okay, that's good. That's

295
00:17:02,405 --> 00:17:03,685
Speaker 7:  Encouraging. So you still

296
00:17:03,685 --> 00:17:07,245
Speaker 6:  Picked the two most distinctive fruits that you could have possibly picked.

297
00:17:07,585 --> 00:17:11,205
Speaker 6:  I'm just saying this demo is the easiest possible version of this demo. And

298
00:17:11,205 --> 00:17:15,125
Speaker 6:  still it gives you a recipe that involves not everything on the table

299
00:17:15,125 --> 00:17:17,925
Speaker 6:  and a bunch of stuff you don't have on the table. So, I, I, I get to the

300
00:17:17,925 --> 00:17:20,165
Speaker 6:  end of that demo and I'm like, what problem did we just solve?

301
00:17:20,295 --> 00:17:23,965
Speaker 7:  David? I fully agree with your, your big point like yes

302
00:17:23,965 --> 00:17:27,005
Speaker 7:  there's a lot of smoke and mirrors here. The bar is also low.

303
00:17:27,945 --> 00:17:31,165
Speaker 7:  The what they were trying to communicate is like, oh, what happens when you

304
00:17:31,165 --> 00:17:34,925
Speaker 7:  have the visual AI in the ray bands with a display? And so what I'm talking

305
00:17:34,925 --> 00:17:38,685
Speaker 7:  about is not the fact that it recognized everything right or wrong, it's

306
00:17:38,685 --> 00:17:42,545
Speaker 7:  just this idea of like that visual AI with

307
00:17:42,585 --> 00:17:46,265
Speaker 7:  a display and then, oh I can actually, like, I don't have to like just listen

308
00:17:46,285 --> 00:17:49,100
Speaker 7:  to the recipe. I can see it and I can move it around and I can make it it

309
00:17:49,100 --> 00:17:49,380
Speaker 7:  big and

310
00:17:49,380 --> 00:17:51,285
Speaker 6:  I can edit it. That was cool. Edit the thing in the demo where it popped

311
00:17:51,285 --> 00:17:53,845
Speaker 6:  up above it. Yeah. Saying what each thing was. I actually thought was like,

312
00:17:53,845 --> 00:17:56,725
Speaker 6:  that's a really cool little bit of ui that it was like this is the cacao.

313
00:17:56,725 --> 00:17:59,925
Speaker 6:  Yeah. Nevermind that there was a box that said cacao right underneath the

314
00:17:59,925 --> 00:18:03,885
Speaker 6:  label. But still, like I-I-I-I-I actually thought the UI was

315
00:18:03,885 --> 00:18:07,685
Speaker 6:  very cool for what amounted to a not particularly impressive problem.

316
00:18:07,825 --> 00:18:11,205
Speaker 6:  So looking at it as like, here is how you do this, I think is actually very

317
00:18:11,205 --> 00:18:15,045
Speaker 6:  clever. I just was so like there so many people were like, oh my god,

318
00:18:15,065 --> 00:18:18,045
Speaker 6:  the smoothie thing. And it's like, did we actually do anything here

319
00:18:18,315 --> 00:18:20,965
Speaker 3:  Also to make a smoothie? You just dump everything. I was gonna say like,

320
00:18:20,965 --> 00:18:22,045
Speaker 3:  push the button. Yeah. Like

321
00:18:22,145 --> 00:18:23,045
Speaker 6:  That's, it's blender

322
00:18:24,065 --> 00:18:25,245
Speaker 3:  It in, it'll

323
00:18:25,245 --> 00:18:25,365
Speaker 6:  Be fine.

324
00:18:26,035 --> 00:18:29,765
Speaker 3:  There's a technique here that the AI is gonna walk you through. You hit pulse

325
00:18:29,885 --> 00:18:32,085
Speaker 3:  a couple times and then you hit plants. Yeah. Should've showed us you'd make

326
00:18:32,135 --> 00:18:32,485
Speaker 3:  bread.

327
00:18:32,705 --> 00:18:36,685
Speaker 7:  So on the smoothie thing, just really quick, I kind of freaked out not

328
00:18:36,685 --> 00:18:40,405
Speaker 7:  because of how crazy I thought it was that it correctly identified a

329
00:18:40,405 --> 00:18:43,645
Speaker 7:  pineapple the first time. David, they had been doing all these little Easter

330
00:18:43,675 --> 00:18:47,205
Speaker 7:  eggs for me throughout my, I I spent like a full day at Meta and I'd done

331
00:18:47,205 --> 00:18:50,765
Speaker 7:  a bunch of other demos before this and they were like dropping little things

332
00:18:50,825 --> 00:18:54,725
Speaker 7:  all throughout my demos. Like the text that came up in the glasses was

333
00:18:54,725 --> 00:18:57,325
Speaker 7:  like an employee being like, Hey, I've got the scoop for you on the next

334
00:18:57,465 --> 00:19:01,285
Speaker 7:  ar glasses. Like I need to go like step out the room to like not get caught.

335
00:19:01,785 --> 00:19:05,725
Speaker 7:  And then they, by the time I got to the smoothie I do,

336
00:19:05,805 --> 00:19:09,685
Speaker 7:  I make smoothies every morning. And so by the, I thought I was like, did

337
00:19:09,685 --> 00:19:13,605
Speaker 7:  they, they do they have cameras in my house. Like I, I got

338
00:19:13,605 --> 00:19:16,125
Speaker 7:  to the point I just turned around to the room 'cause there's like 12 people

339
00:19:16,125 --> 00:19:19,845
Speaker 7:  in the room and I'm just like, are you guys like watching me at home?

340
00:19:20,105 --> 00:19:20,325
Speaker 7:  Are

341
00:19:20,325 --> 00:19:22,805
Speaker 3:  You listening to me on my phone? Just say yes or no. Yeah,

342
00:19:22,875 --> 00:19:26,645
Speaker 7:  Yeah, yeah. It was the smoothie thing felt special and So I was actually

343
00:19:26,645 --> 00:19:29,445
Speaker 7:  very disappointed to see that everyone got the smoothie demo, but

344
00:19:29,625 --> 00:19:33,365
Speaker 3:  That's okay. So I wanna come back to whether the demo

345
00:19:33,425 --> 00:19:36,685
Speaker 3:  is real or fake and the debate about what the word vaporware means. But you

346
00:19:36,685 --> 00:19:40,445
Speaker 3:  talked about the control Yeah. Band the wristband several times. Yes. Let's

347
00:19:40,445 --> 00:19:43,805
Speaker 3:  explain that real quick first. 'cause I, there's a part of this

348
00:19:44,415 --> 00:19:48,165
Speaker 3:  where the, the neural wristband is the most

349
00:19:48,215 --> 00:19:51,565
Speaker 3:  ready to go product, which is fascinating in and of itself. It's kind of

350
00:19:51,565 --> 00:19:54,685
Speaker 3:  the coolest I think. Yeah. I mean it's done. It's, it's one part of the dream

351
00:19:54,705 --> 00:19:55,045
Speaker 3:  for sure.

352
00:19:55,195 --> 00:19:59,085
Speaker 7:  It's very clear that the band is done. I also know this because they're releasing

353
00:19:59,765 --> 00:20:03,405
Speaker 7:  a pair of glasses with a very small heads up display. It's not full ar

354
00:20:03,635 --> 00:20:07,525
Speaker 7:  that will use the band. I'm pretty sure next year it was very

355
00:20:07,525 --> 00:20:10,765
Speaker 7:  clear that the band is done. And that's why I spent more time in the story

356
00:20:10,765 --> 00:20:14,445
Speaker 7:  than I originally thought writing about the band. Also because it was genuinely,

357
00:20:15,005 --> 00:20:18,045
Speaker 7:  I mean, I think I said this in the video, it was one of the coolest experiences

358
00:20:18,075 --> 00:20:21,965
Speaker 7:  with a new piece of technology I've ever had because

359
00:20:22,395 --> 00:20:25,965
Speaker 7:  there's no calibration. You just, you put it on you, you go through the

360
00:20:25,965 --> 00:20:29,845
Speaker 7:  gestures and it has this haptic feedback in the

361
00:20:29,845 --> 00:20:33,365
Speaker 7:  band that kind of reinforces when you're doing it correctly. I did that for

362
00:20:33,365 --> 00:20:36,365
Speaker 7:  like 10 seconds and I was just flying through the thing

363
00:20:37,465 --> 00:20:41,415
Speaker 7:  and to the point where I had to take them off at one point and put them

364
00:20:41,415 --> 00:20:44,015
Speaker 7:  back on and like go back through the setup and I didn't even, I just did

365
00:20:44,015 --> 00:20:47,925
Speaker 7:  it on my own and like, it, it just clicked so fast and it's so

366
00:20:47,925 --> 00:20:50,845
Speaker 7:  precise and yeah, I'll, it uses EMG

367
00:20:51,145 --> 00:20:55,085
Speaker 7:  electromyography and it, it's not reading your thoughts, but it's

368
00:20:55,085 --> 00:20:58,685
Speaker 7:  interpreting neural signals through the movements of your wrist and

369
00:20:58,875 --> 00:21:02,765
Speaker 7:  translating those into input in the glasses and Meta Meta

370
00:21:02,855 --> 00:21:06,805
Speaker 7:  botta startup that we have covered extensively. I believe Addie

371
00:21:06,805 --> 00:21:10,445
Speaker 7:  covered this even before they sold to, to Facebook. This was like in

372
00:21:10,445 --> 00:21:14,165
Speaker 7:  2019 Control labs and it's this tech and

373
00:21:15,275 --> 00:21:18,885
Speaker 7:  it's really powerful. I think they've stumbled onto something here that

374
00:21:19,645 --> 00:21:23,205
Speaker 7:  I haven't seen for headsets, which is how do you control 'em without

375
00:21:23,475 --> 00:21:27,325
Speaker 7:  putting your hands out in front of you? You know, like I use the spectacles

376
00:21:27,325 --> 00:21:30,285
Speaker 7:  which rely on just hand tracking the week before.

377
00:21:31,145 --> 00:21:35,045
Speaker 7:  And I was thinking when I was like flying to Meta

378
00:21:35,105 --> 00:21:39,005
Speaker 7:  the next week, like in my airplane seat, it's like you're not gonna stick

379
00:21:39,005 --> 00:21:41,765
Speaker 7:  your hands out like in an airplane seat to control your glasses.

380
00:21:41,795 --> 00:21:45,125
Speaker 5:  Well North Glasses did that too, right? They had, they had like a ring that

381
00:21:45,125 --> 00:21:46,765
Speaker 5:  would that they used to control it. Yeah,

382
00:21:46,765 --> 00:21:49,125
Speaker 6:  It was like a joystick on a ring. Yeah, it was just

383
00:21:49,125 --> 00:21:51,245
Speaker 7:  Weird. Yeah, it wasn't but it was cool. Yeah. But this

384
00:21:51,245 --> 00:21:54,125
Speaker 5:  Is like, yeah, it wasn't like moving your hands out in front of you. Yeah,

385
00:21:54,125 --> 00:21:56,925
Speaker 7:  This is like hyper precise click like

386
00:21:57,815 --> 00:22:01,525
Speaker 7:  input that you can do with very, very small hand

387
00:22:01,525 --> 00:22:04,845
Speaker 7:  gestures in your pocket or behind your back. And

388
00:22:06,365 --> 00:22:09,885
Speaker 7:  I just, I mean I like audibly gasped when I started using it. Well

389
00:22:09,885 --> 00:22:13,245
Speaker 5:  This is like cool technology we've seen for ages, right? Like,

390
00:22:13,245 --> 00:22:14,565
Speaker 6:  Well Control labs has been around but

391
00:22:14,565 --> 00:22:18,405
Speaker 5:  Yeah. Yeah, like Control labs. We, we saw, we've, we've seen like horrible

392
00:22:18,445 --> 00:22:21,845
Speaker 5:  products from small startups using this stuff before, but it's also like

393
00:22:22,035 --> 00:22:25,885
Speaker 5:  just regularly used in prosthetics now, particularly like hand

394
00:22:25,885 --> 00:22:29,045
Speaker 5:  prosthetics and arm prosthetics to, to give that movement. So it's like,

395
00:22:29,045 --> 00:22:31,885
Speaker 5:  it's really cool to see it come to consumer products.

396
00:22:31,955 --> 00:22:34,685
Speaker 7:  Yeah. I've never seen EMG in a consumer products.

397
00:22:36,265 --> 00:22:38,045
Speaker 7:  So it was, it was really

398
00:22:38,045 --> 00:22:41,725
Speaker 5:  Cool. There's one in 2014 it was called like the Frog or something. Does

399
00:22:41,725 --> 00:22:45,165
Speaker 5:  nobody remember this? No, no. I like, I swear

400
00:22:45,165 --> 00:22:47,245
Speaker 6:  That there was a real, you know, face when everyone immediately started Googling.

401
00:22:47,245 --> 00:22:48,845
Speaker 5:  Yeah. We were all like, that's my face right now.

402
00:22:50,345 --> 00:22:54,045
Speaker 6:  No, but Alex the thing you said in your story that most got me was

403
00:22:54,265 --> 00:22:58,205
Speaker 6:  the, the moment where you your, like you had your hands in your jacket pockets

404
00:22:58,205 --> 00:23:00,405
Speaker 6:  Yeah. And you're controlling the thing and that's the moment where you're

405
00:23:00,405 --> 00:23:04,125
Speaker 6:  like, oh this is obviously the correct answer for this. Yeah. And I think

406
00:23:04,985 --> 00:23:08,885
Speaker 6:  I'm fascinated by the whole kind of kit that they put together where it's

407
00:23:08,885 --> 00:23:12,685
Speaker 6:  the, it's the glasses, there's the wireless compute puck that

408
00:23:12,685 --> 00:23:15,925
Speaker 6:  feels like you put it in like your jacket pocket or your backpack or your

409
00:23:15,955 --> 00:23:19,205
Speaker 6:  back pocket or whatever and then it's the band. Yep. And I think

410
00:23:19,785 --> 00:23:22,565
Speaker 6:  at least for now, that strikes me as like

411
00:23:23,965 --> 00:23:27,945
Speaker 6:  the exact Right. Three parts in the right way. Yeah. I think like

412
00:23:27,965 --> 00:23:30,865
Speaker 6:  the Vision pros cable thing is, is wrong. The

413
00:23:32,175 --> 00:23:35,745
Speaker 6:  only hand motions that the cameras can see in front of your face is wrong.

414
00:23:35,775 --> 00:23:39,625
Speaker 6:  Like I, I honestly believe Meta got that part of this thing

415
00:23:39,625 --> 00:23:43,025
Speaker 6:  like Exactly. Correct. and it just feels like you instantly are like using

416
00:23:43,025 --> 00:23:46,485
Speaker 6:  it in a way that feels way more natural. Yes. Than even like

417
00:23:46,695 --> 00:23:49,925
Speaker 6:  Eli's experience with the Vision Pro where you, like you, you still have

418
00:23:49,925 --> 00:23:53,885
Speaker 6:  to sort of keep your hands on like the front plane of your body and in view

419
00:23:54,065 --> 00:23:57,165
Speaker 6:  and that is just an amount of thinking that you don't have to do with this

420
00:23:57,225 --> 00:23:58,405
Speaker 6:  and that feels much better.

421
00:23:58,795 --> 00:24:02,645
Speaker 7:  Yeah, I totally agree. I wanna talk about the puck. Just I guess on the

422
00:24:02,645 --> 00:24:06,605
Speaker 7:  band though too, what Meta hopes is that over time the band

423
00:24:06,605 --> 00:24:10,445
Speaker 7:  becomes its own platform and that it interfaces with

424
00:24:10,445 --> 00:24:14,125
Speaker 7:  appliances, it interfaces with your car, other gadgets.

425
00:24:14,425 --> 00:24:17,565
Speaker 7:  And the idea is like this is probably a 10 to 15 year out thing honestly

426
00:24:17,745 --> 00:24:19,205
Speaker 7:  for it to really, you know,

427
00:24:19,345 --> 00:24:20,925
Speaker 3:  It interfaces with your car.

428
00:24:21,795 --> 00:24:25,285
Speaker 7:  Yeah. So the idea is like you're walking around with these glasses, you look

429
00:24:25,305 --> 00:24:29,165
Speaker 7:  at your car and you want to start the engine as you're walking

430
00:24:29,165 --> 00:24:32,445
Speaker 7:  up to it, you do a little tap because it sees that you're looking at your

431
00:24:32,445 --> 00:24:36,405
Speaker 7:  car, the band is connected, there's an API, you're logged in and you

432
00:24:36,405 --> 00:24:38,525
Speaker 7:  turn your AC on or you turn your, this is the

433
00:24:38,525 --> 00:24:41,845
Speaker 3:  Idea of a man who can grow crystals in the basement of his mansion.

434
00:24:42,045 --> 00:24:45,885
Speaker 7:  Well it's honestly, it's it's, there's several leaps to get there. It's not

435
00:24:45,885 --> 00:24:49,285
Speaker 7:  like the ecosystem of it all will be tough to develop until there's scale

436
00:24:49,285 --> 00:24:52,925
Speaker 7:  with these glasses. But it's pretty obvious to think about, okay, if I'm

437
00:24:52,925 --> 00:24:56,725
Speaker 7:  wearing contextually, you know, spatially wear glasses at all times and

438
00:24:56,725 --> 00:25:00,445
Speaker 7:  I'm walking around my house and I look at my thermostat and I want to change

439
00:25:00,465 --> 00:25:04,285
Speaker 7:  the setting, why can my band not, because it's

440
00:25:04,545 --> 00:25:07,765
Speaker 7:  all connected. Why can my band not adjust the thermostat? Right. And that,

441
00:25:07,765 --> 00:25:10,125
Speaker 7:  that's, that's the idea they have. I think it's a really cool

442
00:25:10,125 --> 00:25:13,805
Speaker 3:  Idea. Why can't I turn reality into a bitmap display with windows and a mouse?

443
00:25:14,555 --> 00:25:14,845
Speaker 3:  Yeah.

444
00:25:14,915 --> 00:25:18,805
Speaker 6:  With, with a camera and a controller and good enough

445
00:25:18,805 --> 00:25:21,125
Speaker 6:  processing. You can get a pretty long way towards that.

446
00:25:21,435 --> 00:25:24,925
Speaker 7:  Yeah. So people will see the band soon like,

447
00:25:25,155 --> 00:25:28,645
Speaker 7:  like next year and, and I'm big excited. I

448
00:25:28,645 --> 00:25:31,725
Speaker 5:  Gotta of I got an update real fast. Yeah. I found the band. Oh wow. It was

449
00:25:31,725 --> 00:25:35,645
Speaker 5:  called the Mayo. It cost $200. They

450
00:25:35,645 --> 00:25:39,565
Speaker 5:  first started reporting on it in 2013, came out in 2016 and you wore it

451
00:25:39,565 --> 00:25:42,925
Speaker 5:  like on the middle of your for Oh sure, yeah. To control your, your laptop

452
00:25:42,925 --> 00:25:43,125
Speaker 5:  and your,

453
00:25:43,185 --> 00:25:45,365
Speaker 3:  And also keep this sweat away from me while you play tennis. Yeah,

454
00:25:45,465 --> 00:25:46,405
Speaker 5:  No it's so ugly.

455
00:25:47,245 --> 00:25:49,245
Speaker 6:  And it use, I remember this thing, I tried

456
00:25:49,245 --> 00:25:51,005
Speaker 3:  This thing thing. The thing looks like a ball bangle.

457
00:25:52,265 --> 00:25:52,805
Speaker 6:  It really does.

458
00:25:53,425 --> 00:25:55,125
Speaker 7:  And it uses EMG Kranz.

459
00:25:55,515 --> 00:25:59,325
Speaker 5:  Yeah. Yeah. Used EMG like, like that particular technology, the E

460
00:25:59,445 --> 00:26:03,325
Speaker 5:  mg technology has been around a while and we've seen it in other stuff but

461
00:26:03,325 --> 00:26:07,045
Speaker 5:  it's always like been kind of, nobody's gotten the software part of it. Right.

462
00:26:07,185 --> 00:26:07,885
Speaker 5:  And there's interactions

463
00:26:07,885 --> 00:26:11,045
Speaker 7:  And the form factor it looks like the fit and it. Yeah. Yeah. Like this thing

464
00:26:11,065 --> 00:26:13,525
Speaker 7:  is not bulky and it and it just sits

465
00:26:13,525 --> 00:26:15,885
Speaker 3:  On your wrist. Yeah. This is cool. Did you have to wear it tightly around

466
00:26:15,885 --> 00:26:16,285
Speaker 3:  your wrist?

467
00:26:16,555 --> 00:26:20,445
Speaker 7:  It's tight but it's not like, like there, there are sensors that indent a

468
00:26:20,445 --> 00:26:24,045
Speaker 7:  little bit into your skin but it wasn't like uncomfortable. I wore it, I

469
00:26:24,195 --> 00:26:28,085
Speaker 7:  left the, the demo room with it still on to go interview Zuckerberg and like

470
00:26:28,085 --> 00:26:30,765
Speaker 7:  they came running after me and we were like, you still got the band on?

471
00:26:32,315 --> 00:26:32,605
Speaker 3:  Like

472
00:26:32,635 --> 00:26:35,565
Speaker 7:  Keep running. Please let us keep that. So if we're talking about, you know,

473
00:26:35,945 --> 00:26:39,085
Speaker 7:  the three parts of this I guess on the puck, I just like,

474
00:26:40,455 --> 00:26:44,005
Speaker 7:  David, I agree with you that this feels like the right combination for now.

475
00:26:44,195 --> 00:26:48,005
Speaker 7:  They obviously don't want the puck to be in the picture long term.

476
00:26:48,075 --> 00:26:48,365
Speaker 7:  Sure.

477
00:26:48,465 --> 00:26:49,685
Speaker 3:  But I think we're a long way away

478
00:26:49,685 --> 00:26:52,845
Speaker 7:  From that. Yeah. They made the decision, which I think is the correct call,

479
00:26:52,865 --> 00:26:56,805
Speaker 7:  is that they want the glasses to be as light as possible and to not burn

480
00:26:56,805 --> 00:27:00,005
Speaker 7:  your face. Which is, you know what I've experienced a lot. Not literally

481
00:27:00,005 --> 00:27:03,885
Speaker 7:  burning but just they get really hot and so they'd

482
00:27:03,885 --> 00:27:07,445
Speaker 7:  made the decision to offload most of the app logic onto the puck. They

483
00:27:07,805 --> 00:27:11,485
Speaker 7:  invented their own wifi protocol and it has to be 12 to

484
00:27:11,685 --> 00:27:15,085
Speaker 7:  13 feet max away at all times. Or the glasses just don't work. And

485
00:27:15,145 --> 00:27:17,005
Speaker 5:  Why do we call it a puck and not a computer?

486
00:27:18,085 --> 00:27:21,165
Speaker 7:  I mean why do they call 'em glasses and not a computer? I don't know.

487
00:27:21,325 --> 00:27:22,325
Speaker 5:  Yeah. Oh yeah. But like the,

488
00:27:22,545 --> 00:27:23,205
Speaker 3:  Is it a circle?

489
00:27:23,555 --> 00:27:27,165
Speaker 7:  Yeah. It's like, it looks like one of the big like

490
00:27:27,545 --> 00:27:31,445
Speaker 7:  iPhone brick chargers you could like put on the back of the iPhone with

491
00:27:31,445 --> 00:27:34,085
Speaker 7:  like MagSafe, like a big ass anchor. Yeah.

492
00:27:34,465 --> 00:27:37,605
Speaker 5:  It looks like you could put it in your back pocket but you wanna wear a belt.

493
00:27:37,835 --> 00:27:38,125
Speaker 3:  Okay.

494
00:27:38,125 --> 00:27:41,165
Speaker 7:  You could, I could put it in my back pocket 'cause I have huge back pockets.

495
00:27:41,165 --> 00:27:42,325
Speaker 7:  But yeah, I mean the, the idea

496
00:27:42,425 --> 00:27:45,725
Speaker 3:  Is like are you wearing JCOs? Did we just learn something about Flex? Alright.

497
00:27:46,635 --> 00:27:50,365
Speaker 3:  Yeah I know you live in LA but like how bad is it gotten over there? It's

498
00:27:50,365 --> 00:27:50,605
Speaker 7:  Pretty bad.

499
00:27:54,395 --> 00:27:58,285
Speaker 7:  Yeah. So the puck is the right trade

500
00:27:58,285 --> 00:28:01,925
Speaker 7:  off to make because these glasses only weigh 98 grams.

501
00:28:02,135 --> 00:28:05,605
Speaker 7:  Right. Whereas the Vision Pro is like five, six x that

502
00:28:06,065 --> 00:28:09,565
Speaker 7:  and I, like I said, I wore them for two hours and I, I never felt

503
00:28:09,875 --> 00:28:13,765
Speaker 7:  like uncomfortable. And a funny thing about the two hours I was

504
00:28:14,085 --> 00:28:17,765
Speaker 7:  informed as we were wrapping, like you know there, there's a bunch of met

505
00:28:18,005 --> 00:28:21,845
Speaker 7:  employees in the room. I'm, I think I was the second journalist ever to try

506
00:28:21,845 --> 00:28:25,445
Speaker 7:  them. I've also written about these extensively. So they, they were really

507
00:28:25,445 --> 00:28:29,285
Speaker 7:  like on edge and they, towards the end, like

508
00:28:29,365 --> 00:28:31,605
Speaker 7:  I took them off and they, I could just hear everyone like breathe a sigh

509
00:28:31,605 --> 00:28:35,485
Speaker 7:  of relief and like they were like, you just broke the demo, the record for

510
00:28:35,485 --> 00:28:39,365
Speaker 7:  longest demo. Oh actually longest continuous wear of them at two

511
00:28:39,365 --> 00:28:42,245
Speaker 7:  hours. We were like yeah we thought they would just like crap out by now.

512
00:28:43,705 --> 00:28:45,125
Speaker 3:  That's what's up. So that was,

513
00:28:45,305 --> 00:28:46,965
Speaker 5:  Was there a battery indicator or anything?

514
00:28:47,345 --> 00:28:50,925
Speaker 7:  No. No there wasn't. And they didn't swap them out or anything. That's cool.

515
00:28:51,195 --> 00:28:51,485
Speaker 7:  Yeah.

516
00:28:51,625 --> 00:28:55,365
Speaker 5:  How, okay. You wear glasses. Yeah. How heavy versus

517
00:28:55,585 --> 00:28:57,845
Speaker 5:  the ones you're wearing now, which seem fairly lightweight

518
00:28:57,845 --> 00:29:01,605
Speaker 7:  Like you notice but like I have a pair of chunky LA

519
00:29:01,605 --> 00:29:05,125
Speaker 7:  glasses that honestly felt in the same ballpark. Okay.

520
00:29:05,125 --> 00:29:07,685
Speaker 5:  Like it wasn't, it wasn't too heavy because like it was on the ears. It was

521
00:29:07,685 --> 00:29:08,805
Speaker 5:  just those ear pieces

522
00:29:08,805 --> 00:29:11,725
Speaker 7:  Are so no pressure on the ears. I mean if anything it's a little in the front

523
00:29:11,725 --> 00:29:14,885
Speaker 7:  of your face but, and the thing that struck me was, you know, they told me

524
00:29:14,885 --> 00:29:18,325
Speaker 7:  definitively like the frames will be half as thick in the consumer version,

525
00:29:18,615 --> 00:29:19,285
Speaker 7:  which means that

526
00:29:19,285 --> 00:29:22,885
Speaker 3:  Okay so okay wait, that's it. That's my cue to Are you fromwhere There go.

527
00:29:24,075 --> 00:29:28,045
Speaker 3:  Okay. So just describe the product that we, you saw, which is a very impressive

528
00:29:28,045 --> 00:29:31,925
Speaker 3:  demo, right? Yeah. Lots of people saw the demo. Everyone is suitably impressed.

529
00:29:32,935 --> 00:29:36,885
Speaker 3:  Great. The thing that they accomplished that no one else has

530
00:29:36,885 --> 00:29:40,645
Speaker 3:  been able to accomplish is getting that display to work in that form

531
00:29:40,645 --> 00:29:44,445
Speaker 3:  factor 98 grams on your face, two hours of battery life. You can

532
00:29:44,445 --> 00:29:48,405
Speaker 3:  look at reality through the lenses and it will put, from what I understand,

533
00:29:48,405 --> 00:29:51,685
Speaker 3:  labels above boxes of cocoa. Yeah. That's wonderful. Mark, Zuckerberg can

534
00:29:51,685 --> 00:29:55,365
Speaker 3:  play pong with you. They had right, they, they've iterated it and a and

535
00:29:55,365 --> 00:29:58,205
Speaker 3:  developed the existing EMG control band.

536
00:29:59,915 --> 00:30:03,775
Speaker 3:  We put a computer in a giant battery and are sending signals from it

537
00:30:03,975 --> 00:30:06,815
Speaker 3:  wirelessly to something else challenging 'cause they gotta do it in real

538
00:30:06,815 --> 00:30:09,495
Speaker 3:  time but Right. A a thing that existed,

539
00:30:11,275 --> 00:30:15,135
Speaker 3:  we put it all together in a product and we sell it far, far away. Right.

540
00:30:15,135 --> 00:30:18,415
Speaker 3:  Like I'm giving them credit for a bunch of stuff. Some stuff they iterated

541
00:30:18,535 --> 00:30:22,455
Speaker 3:  some stuff, they bought some stuff they had to build from scratch and spend

542
00:30:22,455 --> 00:30:25,935
Speaker 3:  billions of dollars that basically no one else has managed to crack yet.

543
00:30:26,435 --> 00:30:30,265
Speaker 3:  All great. It's a long way from here to there three years.

544
00:30:30,685 --> 00:30:33,785
Speaker 3:  So that's their promise. And so like, you know the thing I would say is like

545
00:30:33,785 --> 00:30:36,745
Speaker 3:  it's a vapor till it ships and Meta has the

546
00:30:37,285 --> 00:30:41,145
Speaker 3:  extraordinarily opportunity to show a thing that isn't shipping.

547
00:30:41,555 --> 00:30:44,785
Speaker 3:  Right. Like I, they're all proud of it. Yeah. You can see they're bursting

548
00:30:44,785 --> 00:30:48,625
Speaker 3:  with pride. They in particular built a

549
00:30:48,625 --> 00:30:52,225
Speaker 3:  display technology they can demo for two hours with a variety of people doing

550
00:30:52,235 --> 00:30:55,905
Speaker 3:  stuff that no one else has been able to do. Magic

551
00:30:55,975 --> 00:30:59,945
Speaker 3:  leap hacking GPU of your brain I think is the closest to this. And

552
00:30:59,945 --> 00:31:03,585
Speaker 3:  they had people sitting down next to a box the size of a refrigerator

553
00:31:03,845 --> 00:31:04,905
Speaker 3:  and they couldn't ship it.

554
00:31:06,435 --> 00:31:10,375
Speaker 3:  What is the the, and Meta doesn't have to do that, right? They have,

555
00:31:10,375 --> 00:31:12,975
Speaker 3:  they're selling the quest. They make a bunch of money selling ads. They got

556
00:31:13,325 --> 00:31:17,175
Speaker 3:  Kristen Bell being an AI voice that they have a whole business that's running

557
00:31:17,175 --> 00:31:18,695
Speaker 3:  that can subsidize this thing.

558
00:31:20,685 --> 00:31:24,325
Speaker 3:  W it's still vapor in my opinion. Like they have to ship it. They're just

559
00:31:24,325 --> 00:31:27,285
Speaker 3:  able to be confident that they've gotten this far.

560
00:31:28,225 --> 00:31:32,085
Speaker 3:  But it's unclear to me what this actually looks like as a product because

561
00:31:32,165 --> 00:31:35,685
Speaker 3:  I sincerely doubt it will have a wireless compute puck and like

562
00:31:36,845 --> 00:31:40,815
Speaker 3:  once they start shipping the neural wristband, it won't take on a life

563
00:31:40,815 --> 00:31:44,335
Speaker 3:  of its own in some other way and it will be completely divorced from the

564
00:31:44,375 --> 00:31:47,935
Speaker 3:  Quest ecosystem there. It just like, there's a set of

565
00:31:48,305 --> 00:31:52,095
Speaker 3:  unanswered questions here that I think it's very tempting to pres answer

566
00:31:52,235 --> 00:31:56,135
Speaker 3:  or imagine. And that honestly is the fun part and I'm excited to do some

567
00:31:56,135 --> 00:32:00,015
Speaker 3:  of that with all of you. But it's also like three years is a long time. A

568
00:32:00,015 --> 00:32:03,735
Speaker 3:  lot of things can change in three years and a lot of other things have to

569
00:32:03,735 --> 00:32:07,615
Speaker 3:  go right. Like the lenses in your story, they're planning to ship

570
00:32:07,615 --> 00:32:11,355
Speaker 3:  regular lenses, right? They're gonna go from silicon carbide

571
00:32:11,595 --> 00:32:12,075
Speaker 3:  to glass.

572
00:32:12,305 --> 00:32:15,915
Speaker 7:  Well they wouldn't tell me the material and the truth is that they're

573
00:32:16,115 --> 00:32:19,555
Speaker 7:  parallel pathing like four or five different options. So they're Right. But

574
00:32:19,555 --> 00:32:23,475
Speaker 3:  If your big innovation is the display and you're like

575
00:32:23,575 --> 00:32:26,635
Speaker 3:  we have four options to bring this display to mar, you actually haven't picked,

576
00:32:26,955 --> 00:32:27,195
Speaker 3:  I think

577
00:32:27,195 --> 00:32:30,835
Speaker 7:  You're being simplistic when you say display 'cause the display is the

578
00:32:30,835 --> 00:32:34,115
Speaker 7:  projectors, the wave guides and the lenses. The lenses

579
00:32:34,795 --> 00:32:38,715
Speaker 7:  specifically are what they can't manufacture in a cheap enough way at scale.

580
00:32:39,265 --> 00:32:43,085
Speaker 7:  So the lenses will be different. The projectors are on the

581
00:32:43,085 --> 00:32:46,845
Speaker 7:  path of what I saw going to be the same kind of technology. They invented

582
00:32:46,845 --> 00:32:50,365
Speaker 7:  them, you know, from scratch. The wave guide's the same.

583
00:32:50,835 --> 00:32:53,365
Speaker 7:  They wouldn't tell me what the lenses are. Not because they don't think,

584
00:32:53,555 --> 00:32:57,085
Speaker 7:  they don't know necessarily, but because they haven't fully decided

585
00:32:57,365 --> 00:33:01,125
Speaker 7:  because they're locking these things in on like a timeline

586
00:33:01,395 --> 00:33:05,245
Speaker 7:  that is aggressive. But also they don't want to speak

587
00:33:05,245 --> 00:33:08,405
Speaker 7:  before they, like if they would've said, you know,

588
00:33:09,895 --> 00:33:13,805
Speaker 7:  lemme back up like they decided to not ship Orion two

589
00:33:13,805 --> 00:33:17,285
Speaker 7:  years ago. So the timeline for this hardware stuff is farther out. They,

590
00:33:17,285 --> 00:33:20,565
Speaker 7:  when they, when they say, you know, this is coming in a few years,

591
00:33:21,475 --> 00:33:25,045
Speaker 7:  it's not like we have not set anything up for this to happen in three years.

592
00:33:25,045 --> 00:33:28,805
Speaker 7:  They have, they're on a believe me heads will roll if there is not a

593
00:33:29,165 --> 00:33:32,365
Speaker 7:  consumer version of these error classes in a few years. Well sure. But those

594
00:33:32,365 --> 00:33:32,525
Speaker 7:  are

595
00:33:32,525 --> 00:33:36,005
Speaker 3:  The stakes. The stakes are, we are either, we're all double clicking on cars,

596
00:33:36,905 --> 00:33:40,765
Speaker 3:  you know, to see what happens or heads will roll. Like I, I

597
00:33:40,765 --> 00:33:43,885
Speaker 3:  don't want to shy away from the stakes. Yeah. But I, the part of me that

598
00:33:43,885 --> 00:33:47,725
Speaker 3:  says it's great to imagine how these products might work, especially

599
00:33:47,725 --> 00:33:51,165
Speaker 3:  products that are meant to deliver AI is a new platform that replace

600
00:33:51,165 --> 00:33:55,085
Speaker 3:  smartphones on balance. I don't believe you

601
00:33:55,085 --> 00:33:59,045
Speaker 3:  and it probably doesn't work is like the right answer. And the fact that

602
00:33:59,045 --> 00:34:02,885
Speaker 3:  they got the display to work, which no one else has ever achieved as far

603
00:34:02,885 --> 00:34:04,685
Speaker 3:  as I can tell is incredible.

604
00:34:06,295 --> 00:34:09,115
Speaker 3:  Now comes like an incredible hard part. Okay. But let's

605
00:34:09,115 --> 00:34:11,955
Speaker 5:  Talk about these lenses though because like the lenses is part of the magic

606
00:34:11,955 --> 00:34:15,715
Speaker 5:  of these things, right? Like they, they went with this really expensive product

607
00:34:16,295 --> 00:34:20,155
Speaker 5:  to do this, to have the best light refraction and stuff. And that's

608
00:34:20,155 --> 00:34:23,875
Speaker 5:  because that material exists in the wor I mean it doesn't, very little of

609
00:34:23,875 --> 00:34:26,715
Speaker 5:  it exists in the world. They usually make it all. But like they have to do

610
00:34:26,715 --> 00:34:29,355
Speaker 5:  all of that now they're gonna have to go to a whole different thing which

611
00:34:29,355 --> 00:34:32,675
Speaker 5:  presumably would have a lower price, but similar

612
00:34:32,905 --> 00:34:36,795
Speaker 5:  qualities. And that seems not like an engineering but like

613
00:34:37,155 --> 00:34:40,835
Speaker 5:  a science problem. And that seems like a big science problem

614
00:34:40,935 --> 00:34:41,715
Speaker 5:  for them to have.

615
00:34:42,595 --> 00:34:45,315
Speaker 7:  I don't think they see it that way. I think the Yeah, I'm

616
00:34:45,315 --> 00:34:46,115
Speaker 5:  Sure they don't. Yeah,

617
00:34:46,275 --> 00:34:50,155
Speaker 7:  I, I kind of agree with you. I mean look, here's what they told me. The

618
00:34:50,435 --> 00:34:53,955
Speaker 7:  consumer version will be, the frames will be about a half as thick projector

619
00:34:53,955 --> 00:34:57,315
Speaker 7:  technology will, the projector technology will be very similar, will be in

620
00:34:57,315 --> 00:35:01,075
Speaker 7:  line with what I saw the wave guides will, the field of view which was 70

621
00:35:01,075 --> 00:35:04,755
Speaker 7:  degrees, which is super wide, will be slightly smaller

622
00:35:05,015 --> 00:35:06,395
Speaker 7:  but not like dramatically.

623
00:35:08,255 --> 00:35:11,435
Speaker 7:  And the puck will exist. The band will exist.

624
00:35:12,145 --> 00:35:15,675
Speaker 7:  Like it's just the lenses that they I think are looking

625
00:35:15,935 --> 00:35:19,195
Speaker 7:  at a few options and they don't have to make the call right now. So they're

626
00:35:19,195 --> 00:35:23,035
Speaker 7:  not committing to it. And on the why they're not using

627
00:35:23,035 --> 00:35:26,915
Speaker 7:  silicon carbide and why they did it in the first place is they told me

628
00:35:26,915 --> 00:35:29,795
Speaker 7:  they had hoped that the rest of the industry, whether it was other companies

629
00:35:29,795 --> 00:35:33,435
Speaker 7:  doing AR headsets or even the EV industry for example, which hasn't grown

630
00:35:33,455 --> 00:35:37,285
Speaker 7:  in the last five years, I think as everyone thought it would maybe

631
00:35:37,435 --> 00:35:40,685
Speaker 7:  five years ago, which is when they began the MA manufacturing of Orion and

632
00:35:40,685 --> 00:35:44,205
Speaker 7:  Earnest, they thought the rest of the industry would go to silicon

633
00:35:44,435 --> 00:35:48,365
Speaker 7:  carbide and build up Oh interesting. Economies of scale with

634
00:35:48,365 --> 00:35:52,245
Speaker 7:  them and they ended up being the only company that was trying to do

635
00:35:52,245 --> 00:35:52,365
Speaker 7:  this.

636
00:35:52,985 --> 00:35:56,525
Speaker 3:  So that's like a really interesting bet, right? You think Apple and Google

637
00:35:56,585 --> 00:36:00,285
Speaker 3:  and Samsung are all gonna go forward, invest in a technology Yeah.

638
00:36:00,585 --> 00:36:04,165
Speaker 3:  And you'll just be able to catch the tailwind and that didn't happen. Yeah.

639
00:36:04,165 --> 00:36:07,725
Speaker 7:  They thought economies of scale would make silicon carbide more efficient

640
00:36:07,865 --> 00:36:11,845
Speaker 7:  and less costly to produce. And that didn't happen. I mean Bos told me

641
00:36:11,865 --> 00:36:15,245
Speaker 7:  90% of the cost is the lenses. So Yeah.

642
00:36:15,405 --> 00:36:17,365
Speaker 5:  'cause it's like having two diamond rings on your face.

643
00:36:17,595 --> 00:36:21,405
Speaker 3:  Yeah. Right. But I'm just, I'm coming back to the thing no

644
00:36:21,405 --> 00:36:25,285
Speaker 3:  one has solved is the displays. So whether the lenses are the

645
00:36:25,285 --> 00:36:29,205
Speaker 3:  key element of the displays or just they happen to have bought a lot of

646
00:36:29,205 --> 00:36:33,125
Speaker 3:  silicon carbide and they use them this time. Like I don't, I I

647
00:36:33,305 --> 00:36:37,125
Speaker 3:  I'm curious to know like how much of the thing that they

648
00:36:37,345 --> 00:36:41,285
Speaker 3:  demoed is down to that lens because everybody's vision

649
00:36:41,385 --> 00:36:44,085
Speaker 3:  is the same, right? We're gonna, we're gonna put glasses in your face, you're

650
00:36:44,085 --> 00:36:46,805
Speaker 3:  gonna look at the world, we're gonna layer digital information over the world

651
00:36:47,145 --> 00:36:49,925
Speaker 3:  and then you're gonna be able to take action on it. This is Apple's vision

652
00:36:49,945 --> 00:36:53,805
Speaker 3:  and they couldn't build it. So they built the vision pro. And if

653
00:36:53,805 --> 00:36:56,845
Speaker 3:  Apple is like we can't make it good enough on a timeline to sell,

654
00:36:57,505 --> 00:37:01,405
Speaker 3:  here's a VR headset that fakes it. Meta doesn't have to

655
00:37:01,545 --> 00:37:05,485
Speaker 3:  do that. Right. Meta's business is good enough to keep funneling money into

656
00:37:05,485 --> 00:37:08,565
Speaker 3:  this r and d project. I think that, I think I'm curious for you to read on

657
00:37:08,595 --> 00:37:12,365
Speaker 3:  Zuck wanting to show it. Yeah. 'cause I think he, he was just having

658
00:37:12,385 --> 00:37:15,565
Speaker 3:  the time of his life yesterday at Meta Connect. Yeah. Like showing up all

659
00:37:15,565 --> 00:37:19,045
Speaker 3:  the toys that he's built and like how far ahead of both Apple and Google

660
00:37:19,065 --> 00:37:21,725
Speaker 3:  in various ways. There were a lot of shots at Apple and Google in that. Well

661
00:37:21,795 --> 00:37:25,245
Speaker 6:  Wait, NELI y you and I have paid a lot of attention to these companies this

662
00:37:25,245 --> 00:37:29,205
Speaker 6:  year and have talked about this. Would you bet for or against

663
00:37:29,655 --> 00:37:33,365
Speaker 6:  Apple having something that looks and works an awful lot like Orion and is

664
00:37:33,365 --> 00:37:37,125
Speaker 6:  just as expensive to make in existence in their offices right now,

665
00:37:37,845 --> 00:37:41,205
Speaker 3:  I would say they probably have 500

666
00:37:41,255 --> 00:37:44,965
Speaker 3:  variations of something that looks and works exactly like Orion and Apple

667
00:37:44,985 --> 00:37:48,885
Speaker 3:  is not the kind of company that shows off science projects like this at

668
00:37:48,885 --> 00:37:52,745
Speaker 3:  all. They just won't do it. They've talked about it, right? I mean

669
00:37:52,745 --> 00:37:56,305
Speaker 3:  like Tim Cook in the lead up to the Vision Pro. Before the Vision Pro existed,

670
00:37:56,725 --> 00:38:00,505
Speaker 3:  Tim Cook was like, I'm making glasses. Like I'm gonna, everything that he

671
00:38:00,505 --> 00:38:04,305
Speaker 3:  ever described was Orion, So, I. Think Zuck loves the

672
00:38:04,305 --> 00:38:07,265
Speaker 3:  fact that he showed off the thing that Apple has been describing for years,

673
00:38:07,575 --> 00:38:10,865
Speaker 3:  well before Apple was ready to do it. I do wonder

674
00:38:11,295 --> 00:38:15,205
Speaker 3:  like when Apple's like we need chips, they

675
00:38:15,345 --> 00:38:19,045
Speaker 3:  go to TSMC and they're like, we're gonna buy all the chips, we're gonna build

676
00:38:19,045 --> 00:38:23,005
Speaker 3:  you a factory Corning, but it's your, we don't want to own it, we

677
00:38:23,005 --> 00:38:25,805
Speaker 3:  just want to build it for you so we have the capacity for it. You you run

678
00:38:25,805 --> 00:38:29,645
Speaker 3:  it. We're not putting that on our books. Like that's the level that Apple

679
00:38:29,645 --> 00:38:33,545
Speaker 3:  makes investments at. And I, I don't think they were able to pull off

680
00:38:33,575 --> 00:38:37,125
Speaker 3:  this form factor. And even with the Vision Pro, the form factor

681
00:38:37,125 --> 00:38:40,445
Speaker 3:  compromises are like now in retrospect like ludicrous,

682
00:38:40,855 --> 00:38:44,125
Speaker 3:  right? Like the battery pa like all the stuff right, the hand tracking,

683
00:38:45,185 --> 00:38:48,685
Speaker 3:  I'm actually, you know, even the Orion, right? That uses your eyes to the

684
00:38:48,685 --> 00:38:52,365
Speaker 3:  pointers still feels like a miss to me. That's still overloading an input

685
00:38:52,365 --> 00:38:53,045
Speaker 3:  within output.

686
00:38:53,285 --> 00:38:57,125
Speaker 7:  I disagree because of the band, the eyes when they're your drag and not your

687
00:38:57,125 --> 00:39:01,085
Speaker 7:  click it's and the click is not sticking hands up.

688
00:39:01,665 --> 00:39:05,365
Speaker 7:  It works pretty well. Like I I I thought the same thing with the Vision Pro.

689
00:39:06,875 --> 00:39:10,205
Speaker 7:  When you If you try Orion at some point. I'd be curious to hear how you

690
00:39:10,615 --> 00:39:14,365
Speaker 7:  think when you try it because the eye tracking was, was

691
00:39:14,365 --> 00:39:15,685
Speaker 7:  surprisingly good with the band.

692
00:39:15,995 --> 00:39:19,525
Speaker 5:  When you were having like the conversation with Neli, were you able to also

693
00:39:19,545 --> 00:39:22,205
Speaker 5:  do other stuff at the same time? Like Yeah, because I'm just curious like

694
00:39:22,205 --> 00:39:25,445
Speaker 5:  how that works if you're like looking at him and then you need to move something

695
00:39:25,445 --> 00:39:29,205
Speaker 5:  over here and that means you have to drag it so you have to kind of like

696
00:39:29,205 --> 00:39:32,675
Speaker 5:  look away from him in a potentially awkward way.

697
00:39:32,935 --> 00:39:36,515
Speaker 7:  You could stick your hand out and pinch it and drag it or you could glance

698
00:39:36,535 --> 00:39:39,635
Speaker 7:  at it really quick. Tap your fingers together to to

699
00:39:39,895 --> 00:39:41,315
Speaker 3:  Oh 'cause it does hand tracking too.

700
00:39:41,415 --> 00:39:44,595
Speaker 7:  It does hand tracking and it will merge hand tracking with all of it anytime

701
00:39:44,595 --> 00:39:45,395
Speaker 7:  you put your hands up.

702
00:39:45,395 --> 00:39:48,035
Speaker 3:  That's smart. Yeah, well the, the reason I brought brought all this up is

703
00:39:48,035 --> 00:39:51,915
Speaker 3:  like Apple, a Apple punted on the big problem on

704
00:39:51,915 --> 00:39:54,315
Speaker 3:  the display problem and then tried to solve a bunch of the other problems

705
00:39:54,775 --> 00:39:57,235
Speaker 3:  or at least show you what a bunch of the other problems could look like if

706
00:39:57,235 --> 00:40:01,155
Speaker 3:  they were solved. Like hand tracking like windows and space, spatial compute,

707
00:40:01,155 --> 00:40:03,875
Speaker 3:  all this stuff. But they couldn't solve the display problem so that you end

708
00:40:03,875 --> 00:40:07,155
Speaker 3:  up with a Vision Pro. Even in the compromise state of the Vision Pro form

709
00:40:07,155 --> 00:40:10,965
Speaker 3:  factor, Meta has solved the display problem, at least

710
00:40:10,965 --> 00:40:14,605
Speaker 3:  we think in a way that costs $10,000 and we have yet to see how they will

711
00:40:14,605 --> 00:40:18,565
Speaker 3:  solve the rest of the problems. And that is kind of just an interesting place.

712
00:40:19,405 --> 00:40:20,285
Speaker 7:  I agree. Here's the

713
00:40:20,285 --> 00:40:23,725
Speaker 3:  Company that could not solve the display but they shipped the product like

714
00:40:23,725 --> 00:40:27,645
Speaker 3:  the operating system and the app model and the blah blah blah. And then here's

715
00:40:27,645 --> 00:40:30,605
Speaker 3:  the company that solved the display but can't ship it 'cause it's too expensive.

716
00:40:30,815 --> 00:40:34,445
Speaker 3:  Eventually it seems like the answer is gonna be someone will get to the right

717
00:40:34,445 --> 00:40:35,325
Speaker 3:  answer in the middle first.

718
00:40:35,545 --> 00:40:39,005
Speaker 6:  But again, I keep coming back to like Heath last year

719
00:40:39,515 --> 00:40:43,245
Speaker 6:  when Meta tried to front run the Vision Pro, one of the things that

720
00:40:43,735 --> 00:40:47,565
Speaker 6:  Zuckerberg basically said was, we could have done something

721
00:40:47,565 --> 00:40:49,845
Speaker 6:  as good as the Vision Pro, but it would've been as expensive as the Vision

722
00:40:49,845 --> 00:40:53,005
Speaker 6:  Pro. and we don't wanna do that. I think it is perfectly plausible that at

723
00:40:53,165 --> 00:40:56,405
Speaker 6:  a bunch of other companies in the tech industry right now, there is a thing

724
00:40:56,405 --> 00:40:59,525
Speaker 6:  that looks and works and costs just like Orion and

725
00:40:59,525 --> 00:41:01,445
Speaker 3:  Then there's whatever Snap has, which is well, and

726
00:41:01,445 --> 00:41:03,845
Speaker 6:  I was gonna say the difference is there are only two companies willing to

727
00:41:04,125 --> 00:41:07,845
Speaker 6:  show it to people and of those two Meta is just absolutely

728
00:41:07,845 --> 00:41:11,805
Speaker 6:  kicking Snap's ass. But in a certain way kudos to Meta

729
00:41:11,865 --> 00:41:14,645
Speaker 6:  for being the ones who are actually willing to be out in public sort of showing

730
00:41:14,665 --> 00:41:18,405
Speaker 6:  the state of the art on what they're working on. But I, I genuinely

731
00:41:18,405 --> 00:41:22,365
Speaker 6:  wonder how far ahead it actually is because the

732
00:41:22,365 --> 00:41:25,925
Speaker 6:  gap between, we've made a thousand of these and they cost $10,000 each

733
00:41:26,185 --> 00:41:30,165
Speaker 6:  and we can make millions of them at a reasonable price is so much bigger

734
00:41:30,195 --> 00:41:33,645
Speaker 6:  than anybody ever makes it out to be, including experienced hardware companies.

735
00:41:33,645 --> 00:41:37,245
Speaker 6:  Like the gap between I can make one and I can make a thousand is huge

736
00:41:37,465 --> 00:41:41,405
Speaker 6:  and like kudos to Meta they're there, but thousands to millions is a completely

737
00:41:41,405 --> 00:41:41,925
Speaker 6:  different thing.

738
00:41:41,955 --> 00:41:45,685
Speaker 5:  Wait, wait, wait. But have we seen people wearing, is there an increased

739
00:41:45,745 --> 00:41:49,685
Speaker 5:  use of glassware in like at Google at at

740
00:41:49,685 --> 00:41:53,565
Speaker 5:  Apple? Like does it just seem like more people have bad vision in thick glasses?

741
00:41:54,285 --> 00:41:57,565
Speaker 6:  I mean Google's been showing off the, the, there, there are the prototype

742
00:41:57,565 --> 00:42:00,605
Speaker 6:  glasses in a bunch of Google videos recently. Like they're, that kind of

743
00:42:00,605 --> 00:42:04,565
Speaker 6:  look like the size and shape of Orion. Like this stuff is

744
00:42:04,565 --> 00:42:05,405
Speaker 6:  just out there. I

745
00:42:05,445 --> 00:42:09,165
Speaker 7:  I just as the verges foremost phase computer expert, again this is a cry

746
00:42:09,185 --> 00:42:10,565
Speaker 7:  for help. This is not a brag.

747
00:42:12,205 --> 00:42:15,645
Speaker 7:  I actually will push back on you guys. I do not think anyone has anything

748
00:42:15,645 --> 00:42:19,605
Speaker 7:  working in this form factor as a standalone kit that is not

749
00:42:19,605 --> 00:42:23,245
Speaker 7:  completely on rails or something on a desk that you look through.

750
00:42:23,715 --> 00:42:25,245
Speaker 7:  Yeah, I don't think that actually exists.

751
00:42:25,665 --> 00:42:29,325
Speaker 3:  Can I just for the sake of our own comments, can I just say a bunch of nouns

752
00:42:29,465 --> 00:42:29,965
Speaker 3:  so that people

753
00:42:31,115 --> 00:42:31,405
Speaker 7:  What

754
00:42:32,045 --> 00:42:35,925
Speaker 3:  HoloLens X reel two Pro Air or whatever it's called,

755
00:42:36,805 --> 00:42:40,725
Speaker 3:  HTC, other companies? Yes. I know other companies have

756
00:42:40,725 --> 00:42:44,205
Speaker 3:  made glasses before. I know that the Hol Alex and I have both changed

757
00:42:44,775 --> 00:42:48,645
Speaker 3:  Spark plugs wearing a HoloLens like the, the form

758
00:42:48,645 --> 00:42:51,965
Speaker 3:  factor innovation here is real. Yeah, like, like getting it down in glasses.

759
00:42:52,245 --> 00:42:56,025
Speaker 3:  I I'm not trying to take away from that. I'm, I'm just pointing at like it's

760
00:42:56,025 --> 00:42:59,985
Speaker 3:  vapor till it ships. Like it's one of our rules, right? And the,

761
00:43:00,285 --> 00:43:03,425
Speaker 3:  the distance from what we see today to a product.

762
00:43:04,525 --> 00:43:06,945
Speaker 3:  All of the questions I have to answer in the middle, this is what I was asking

763
00:43:06,945 --> 00:43:09,505
Speaker 3:  about. The quest is like they've answered a bunch of these questions with

764
00:43:09,505 --> 00:43:13,265
Speaker 3:  the Quest. I suspect they think that some of those answers are the wrong

765
00:43:13,265 --> 00:43:16,785
Speaker 3:  answers actually and they need to go in a different way to enable some of

766
00:43:16,785 --> 00:43:18,345
Speaker 3:  the things they want with true AR glasses.

767
00:43:18,945 --> 00:43:21,705
Speaker 7:  I think that's right. I also just think that before this week

768
00:43:22,865 --> 00:43:26,745
Speaker 7:  I honestly did it no where they were at

769
00:43:26,745 --> 00:43:30,715
Speaker 7:  with this in terms of how they were going to do it. And I feel like

770
00:43:30,765 --> 00:43:33,995
Speaker 7:  after this week they actually have the right approach of how they're going

771
00:43:33,995 --> 00:43:37,955
Speaker 7:  about it, which is just relentlessly focusing on the

772
00:43:37,955 --> 00:43:41,915
Speaker 7:  form factor, which Meta has made a lot of hardware mistakes

773
00:43:41,915 --> 00:43:45,795
Speaker 7:  over the years and has, I think just not had the right priorities

774
00:43:45,815 --> 00:43:49,395
Speaker 7:  in terms of what they're building and what it's for or even

775
00:43:49,395 --> 00:43:52,595
Speaker 7:  understanding what it's for. It took them 10 years really to understand that

776
00:43:52,595 --> 00:43:55,595
Speaker 7:  the quest is really just a gaming device even still. Yeah.

777
00:43:55,655 --> 00:43:58,155
Speaker 6:  How much do you think that's the RayBan lesson? That's

778
00:43:58,155 --> 00:44:02,035
Speaker 7:  Part of it, but I just, I think, I think there's clarity here

779
00:44:02,285 --> 00:44:05,875
Speaker 7:  about why people would want these and like something

780
00:44:05,875 --> 00:44:09,795
Speaker 7:  Zuckerberg told me was I thought pretty illustrative of this

781
00:44:09,855 --> 00:44:13,675
Speaker 7:  is like, we want them to be just as good when they're off because we know

782
00:44:13,675 --> 00:44:17,515
Speaker 7:  that you're not going to have the AR on maybe most of the day.

783
00:44:18,175 --> 00:44:22,075
Speaker 7:  And so focusing on that first and letting

784
00:44:22,095 --> 00:44:25,755
Speaker 7:  the technology then kind of fill in, I think is the right approach versus

785
00:44:25,785 --> 00:44:28,675
Speaker 7:  just how they've approached hardware so far, which is like, let's just put

786
00:44:28,675 --> 00:44:32,645
Speaker 7:  as much technology in something as we can and see how

787
00:44:32,645 --> 00:44:35,445
Speaker 7:  people will use it. And here they're like, no, we know how people will use

788
00:44:35,445 --> 00:44:39,125
Speaker 7:  this. It's utility. It's like heads up lightweight interactions,

789
00:44:39,575 --> 00:44:43,365
Speaker 7:  video calling and AI and

790
00:44:43,465 --> 00:44:47,405
Speaker 7:  but the form factor is, is primary. And that's what like,

791
00:44:47,405 --> 00:44:51,245
Speaker 7:  that's the intro of the piece. Like I walk in and I'm looking at

792
00:44:51,245 --> 00:44:54,805
Speaker 7:  them, you know, I'm probably four feet away and I you can't tell, you can't

793
00:44:54,805 --> 00:44:58,725
Speaker 7:  tell that they're AR glasses and it's like even that and as a

794
00:44:58,725 --> 00:45:02,715
Speaker 7:  prototype and I struggle with this 'cause yeah, NELI is is vapor until it

795
00:45:02,795 --> 00:45:06,515
Speaker 7:  ships but it's, it's also not like it's somewhere between a

796
00:45:06,675 --> 00:45:10,595
Speaker 7:  mirage and a product. Like it's, it is real. Like I touched it, I used it

797
00:45:11,095 --> 00:45:14,875
Speaker 7:  but it's not, it's not productized. So seeing that and going

798
00:45:14,895 --> 00:45:18,315
Speaker 7:  wow like the form like and it's gonna be half as thick in a few years. Like

799
00:45:18,865 --> 00:45:21,795
Speaker 7:  okay, I finally see where this is going, especially with the band and I feel

800
00:45:21,795 --> 00:45:24,795
Speaker 7:  like before this week even I, as someone who's been reporting on this a lot,

801
00:45:24,795 --> 00:45:28,275
Speaker 7:  couldn't really see where they were going and I think they feel so

802
00:45:28,275 --> 00:45:31,195
Speaker 7:  confident in where they're going and the clarity of what they're gonna do

803
00:45:31,225 --> 00:45:35,035
Speaker 7:  that that's why they shut it off this week. And also I think Zuck just thinks

804
00:45:35,035 --> 00:45:35,555
Speaker 7:  it's really cool.

805
00:45:36,075 --> 00:45:39,915
Speaker 3:  Yeah and he's right. It is really cool. No one else has done, I, again, I'm

806
00:45:39,915 --> 00:45:42,435
Speaker 3:  just not taking anything away from him. No one else has pulled off the display

807
00:45:42,465 --> 00:45:44,115
Speaker 3:  like hundreds

808
00:45:44,115 --> 00:45:44,875
Speaker 7:  Of, with the form factor,

809
00:45:45,115 --> 00:45:48,955
Speaker 3:  Millions of dollars if not billions of dollars have been thrown at this

810
00:45:48,955 --> 00:45:52,915
Speaker 3:  problem of can I put lenses in front of your face that can convincingly in

811
00:45:52,915 --> 00:45:56,715
Speaker 3:  3D augment reality. Not just show you a TV like the X

812
00:45:56,875 --> 00:46:00,795
Speaker 3:  reel glasses do and not require you to wear a hollow lens and still

813
00:46:00,795 --> 00:46:04,755
Speaker 3:  have no field of view. Like billions upon billions of dollars in this

814
00:46:04,915 --> 00:46:07,835
Speaker 3:  industry been thrown out this problem and only Meta has allowed people to

815
00:46:07,835 --> 00:46:08,395
Speaker 3:  wear it for two

816
00:46:08,395 --> 00:46:12,275
Speaker 7:  Hours. And it's not an overestimation to say that they have probably

817
00:46:12,275 --> 00:46:15,955
Speaker 7:  spent snap's market cap on Orion in the last

818
00:46:16,175 --> 00:46:20,115
Speaker 7:  10 years. And it's like no other company would do this like, like

819
00:46:20,125 --> 00:46:23,795
Speaker 7:  Apple killed the car project 'cause it's like we don't see a

820
00:46:23,795 --> 00:46:27,475
Speaker 7:  realistic timeline to shipping. We're not even sure what it is. Like this

821
00:46:27,475 --> 00:46:31,435
Speaker 7:  is a uniquely Meta thing and it's, it's like a personal thing for

822
00:46:31,435 --> 00:46:35,195
Speaker 7:  Zuckerberg, which is just like screw Apple and Google. I'm never going through

823
00:46:35,195 --> 00:46:38,515
Speaker 7:  this shit again on mobile. You know that he's gone through

824
00:46:39,115 --> 00:46:42,315
Speaker 3:  Actually hold right there. Alex, I wanna talk about Zuck versus Apple and

825
00:46:42,315 --> 00:46:44,475
Speaker 3:  Google and I wanna talk about the Ray bands a bit, but we gotta take a break.

826
00:46:44,695 --> 00:46:47,595
Speaker 3:  So let's take a break and then come back and then we can talk about Zucks

827
00:46:47,595 --> 00:46:49,315
Speaker 3:  War with Tim Cook. We'll be right back.

828
00:47:53,905 --> 00:47:56,685
Speaker 3:  All right, we're back. Keith, right before the break we're talking about

829
00:47:56,835 --> 00:48:00,365
Speaker 3:  Zuck and you said he doesn't want to go through this shit again, which is

830
00:48:01,065 --> 00:48:04,285
Speaker 3:  you, you just interviewed him for quite a long time. You saw him on stage

831
00:48:04,425 --> 00:48:08,365
Speaker 3:  at Meta Connect. I mean, he is, I mean the hair's flowing. The,

832
00:48:08,545 --> 00:48:12,325
Speaker 3:  the Latin T-shirts are in Latin. He's feeling himself chain. He's bringing

833
00:48:12,345 --> 00:48:16,325
Speaker 3:  out chain. He's got a chain. He's bringing out MMA fighters for Meta,

834
00:48:16,505 --> 00:48:19,845
Speaker 3:  RayBan demos just for the hell of it at this point. Take mine out. He's like,

835
00:48:19,845 --> 00:48:23,125
Speaker 3:  I can produce in the MMA lightweight champion of the world. It will, like

836
00:48:23,395 --> 00:48:27,245
Speaker 3:  here he is, get outta here. Like it's

837
00:48:27,245 --> 00:48:31,005
Speaker 3:  great. It's, it's all good. But the, the thing that strikes me about that

838
00:48:31,305 --> 00:48:31,525
Speaker 3:  is

839
00:48:33,085 --> 00:48:35,265
Speaker 3:  yes, there's a politics of it, which maybe we should talk about a little

840
00:48:35,265 --> 00:48:39,185
Speaker 3:  bit, but he really thinks that these glasses are the

841
00:48:39,185 --> 00:48:42,545
Speaker 3:  next great computing platform and he

842
00:48:43,525 --> 00:48:47,395
Speaker 3:  wants to win that fight more than anything. And

843
00:48:47,655 --> 00:48:51,355
Speaker 3:  he probably perceives that he's ahead, but put that in context of

844
00:48:51,575 --> 00:48:53,835
Speaker 3:  why he does not want to lose to Apple and Google.

845
00:48:54,425 --> 00:48:58,315
Speaker 7:  There's so many reasons. Do you guys remember when all of Facebook's

846
00:48:58,715 --> 00:49:02,675
Speaker 7:  internal apps went down for like a full day in the entire company? Like

847
00:49:02,935 --> 00:49:06,475
Speaker 7:  ground to a halt? Yeah. Yeah. Because Apple revoked its developer license.

848
00:49:07,115 --> 00:49:07,355
Speaker 3:  I do.

849
00:49:07,695 --> 00:49:11,635
Speaker 7:  That's just one example. There's, there's app tracking transparency. I

850
00:49:11,635 --> 00:49:15,395
Speaker 7:  don't want it to get into a moral debate about that, but like it objectively

851
00:49:16,065 --> 00:49:18,875
Speaker 7:  like killed billions of dollars of meta's ad revenue.

852
00:49:20,705 --> 00:49:24,115
Speaker 7:  There's all of the app store policies that he is talked about for a very

853
00:49:24,115 --> 00:49:24,595
Speaker 7:  long time.

854
00:49:26,625 --> 00:49:30,275
Speaker 7:  Like people think of Meta as just an app developer and they are really in

855
00:49:30,275 --> 00:49:34,075
Speaker 7:  terms of their business. But they came up, you know, 20 years ago they

856
00:49:34,075 --> 00:49:36,995
Speaker 7:  watched mobile happen. They tried to do a phone, failed at it.

857
00:49:38,725 --> 00:49:42,635
Speaker 7:  Zuckerberg has always wanted to be in control of a platform. And

858
00:49:43,185 --> 00:49:45,835
Speaker 7:  this is something that I think like companies that were born in the mobile

859
00:49:45,855 --> 00:49:49,035
Speaker 7:  era don't even really like think is possible. 'cause it's like you just come

860
00:49:49,035 --> 00:49:52,755
Speaker 7:  into the reality you're in. But he knows what the reality was before Mobile

861
00:49:52,785 --> 00:49:56,715
Speaker 7:  when he was building Facebook early on. And I think

862
00:49:56,715 --> 00:50:00,475
Speaker 7:  they really feel that, you know, if Apple does glasses and the vision pro

863
00:50:00,575 --> 00:50:04,315
Speaker 7:  people start using it and they ship a cheaper one and these

864
00:50:04,375 --> 00:50:08,315
Speaker 7:  become, you know, they start selling, maybe they

865
00:50:08,315 --> 00:50:12,275
Speaker 7:  don't let METAS apps on there at all. And there's this just real tension

866
00:50:12,325 --> 00:50:15,475
Speaker 7:  there of who has the distribution control.

867
00:50:16,185 --> 00:50:20,155
Speaker 7:  It's why Google pays billions of dollars to Apple to have search in

868
00:50:20,315 --> 00:50:23,835
Speaker 7:  Safari. Whoever controls how you access your thing ultimately has

869
00:50:24,235 --> 00:50:27,845
Speaker 7:  leverage over you. And Zuckerberg's been feeling that pretty acutely for

870
00:50:27,905 --> 00:50:31,605
Speaker 7:  10 plus years. And so yeah, this is like a, this is a

871
00:50:31,825 --> 00:50:35,645
Speaker 7:  as much about like inventing the future as it is Correct. In the past. And

872
00:50:37,405 --> 00:50:41,045
Speaker 7:  I don't think any company without that unique context would be doing this.

873
00:50:41,225 --> 00:50:43,045
Speaker 7:  And I think that, so that's a uniquely Meta thing.

874
00:50:43,425 --> 00:50:46,525
Speaker 6:  Can I just read a quote from the interview that I thought was, was very telling

875
00:50:47,585 --> 00:50:50,925
Speaker 6:  you, you, you guys spent a long time talking about basically what

876
00:50:51,545 --> 00:50:54,645
Speaker 6:  AR and AI are gonna do to the next generation of gadgets. And then he, what

877
00:50:54,645 --> 00:50:58,365
Speaker 6:  he says is, for what it's worth, I also think that all the AI work is gonna

878
00:50:58,365 --> 00:51:02,005
Speaker 6:  make phones a lot more exciting. You know, blah blah blah. AI is cool. If

879
00:51:02,085 --> 00:51:05,485
Speaker 6:  I were at any of the other companies trying to design what the next few versions

880
00:51:05,485 --> 00:51:08,645
Speaker 6:  of iPhone or Google's phones should be, I think that there's a long and interesting

881
00:51:08,645 --> 00:51:12,605
Speaker 6:  roadmap of things that they can do with AI that as an app developer, we can't.

882
00:51:12,755 --> 00:51:16,005
Speaker 6:  Yeah. Like to me that's the whole thing, right? Yeah. He's like, if, if I

883
00:51:16,005 --> 00:51:19,565
Speaker 6:  am convinced that if Meta had its way, the puck

884
00:51:19,565 --> 00:51:23,485
Speaker 6:  wouldn't exist on Orion, the puck would be your phone. Yes. Yep. That's

885
00:51:23,485 --> 00:51:27,205
Speaker 6:  what those companies want. And they just can't do it because the only companies

886
00:51:27,205 --> 00:51:30,725
Speaker 6:  that are ever gonna be allowed to do it are Google and Apple and and like,

887
00:51:30,945 --> 00:51:34,685
Speaker 6:  and so if I'm Mark, I'm like, oh, a gigantic part of what I am

888
00:51:34,895 --> 00:51:37,445
Speaker 6:  doing should be tethered to this thing that I'm just not allowed to touch

889
00:51:38,265 --> 00:51:39,445
Speaker 6:  and that would piss me off.

890
00:51:39,635 --> 00:51:43,405
Speaker 7:  They're so mad that they can't automatically sync photos off your Ray

891
00:51:43,405 --> 00:51:45,965
Speaker 7:  bands into your iPhone Camera roll. Yes. Yes. They can do it on Android.

892
00:51:46,275 --> 00:51:46,965
Speaker 5:  It's super annoying.

893
00:51:47,075 --> 00:51:47,685
Speaker 3:  It's so dumb.

894
00:51:48,195 --> 00:51:51,245
Speaker 7:  They can do it on Android because the APIs are there. Android's a little

895
00:51:51,245 --> 00:51:55,045
Speaker 7:  looser. iOS No, like the reason the first ones,

896
00:51:55,105 --> 00:51:58,045
Speaker 7:  the first Ray bands also had a lot of issues. They had a lot of Bluetooth

897
00:51:58,045 --> 00:52:01,285
Speaker 7:  pairing issues and like limitations with what they could do with Apple. And

898
00:52:01,285 --> 00:52:05,005
Speaker 7:  Apple is because of the EU gradually being forced to open up its

899
00:52:05,235 --> 00:52:09,165
Speaker 7:  APIs. But yeah, they're like, they're pissed. They can't sync photos to

900
00:52:09,165 --> 00:52:09,845
Speaker 7:  a camera rolls.

901
00:52:09,865 --> 00:52:13,845
Speaker 5:  But why doesn't Meta complain more? I guess like, like

902
00:52:13,845 --> 00:52:16,445
Speaker 5:  we saw this, they complain Epic all the time. No, no, but they complain all

903
00:52:16,445 --> 00:52:19,805
Speaker 5:  the time. We saw Epic put their, their money where their mouth is like, does

904
00:52:19,805 --> 00:52:21,845
Speaker 5:  does Meta do that? It doesn't seem like they do.

905
00:52:21,995 --> 00:52:23,965
Speaker 3:  Well Meta's also Monopolistically.

906
00:52:24,285 --> 00:52:27,165
Speaker 5:  Yeah. I was like, I was like, is it because they know that like Lena will

907
00:52:27,165 --> 00:52:30,285
Speaker 5:  be like, yeah. Yeah, that's true. We are. I mean,

908
00:52:30,385 --> 00:52:33,845
Speaker 3:  And this is what I mean by the politics of it all. And yeah, Alex in your

909
00:52:33,845 --> 00:52:37,565
Speaker 3:  talk like Mark, just like, there's just hard

910
00:52:37,565 --> 00:52:41,005
Speaker 3:  shots. The EU like throughout your interview where he is like, they should

911
00:52:41,005 --> 00:52:43,725
Speaker 3:  figure out what they want and it's like, dude, what they want is like slightly

912
00:52:43,725 --> 00:52:47,325
Speaker 3:  better Bluetooth than iPhone, right? They want to open

913
00:52:47,435 --> 00:52:51,165
Speaker 3:  interop between messaging platforms and so that is bad for

914
00:52:51,365 --> 00:52:55,245
Speaker 3:  WhatsApp. Like straight up. I think they're trapped between,

915
00:52:55,625 --> 00:52:59,565
Speaker 3:  we would love for you to kick open the doors on iOS but also

916
00:52:59,565 --> 00:53:02,965
Speaker 3:  don't do that to any of our platforms that have the same kind of restrictions.

917
00:53:02,965 --> 00:53:05,685
Speaker 7:  Well that's, I mean they're being forced to do interop with WhatsApp like

918
00:53:05,685 --> 00:53:07,925
Speaker 7:  we just wrote about. Yeah. You're gonna be able to message people outside

919
00:53:07,925 --> 00:53:11,885
Speaker 7:  of WhatsApp. Yeah, I, yes, there's truth to what

920
00:53:11,885 --> 00:53:15,005
Speaker 7:  you're saying. I would argue like Apple is still super locks down

921
00:53:15,705 --> 00:53:19,685
Speaker 7:  and it's opening up over time, but I don't think they think Apple will

922
00:53:19,685 --> 00:53:20,205
Speaker 7:  open up

923
00:53:21,915 --> 00:53:24,765
Speaker 7:  soon enough. And so it's like we need to just invent the next thing.

924
00:53:25,155 --> 00:53:28,845
Speaker 6:  Well, and I think my read of this is that if you're Meta,

925
00:53:29,265 --> 00:53:32,565
Speaker 6:  the easiest way to get where you're going would be to start

926
00:53:33,225 --> 00:53:37,165
Speaker 6:  all of this cool ar stuff as an accessory to your phone, right? And the reason

927
00:53:37,165 --> 00:53:40,085
Speaker 6:  that the Ray bands have worked is that they are an accessory to your phone.

928
00:53:40,085 --> 00:53:44,045
Speaker 6:  They're, they're vastly underpowered accessory to your

929
00:53:44,045 --> 00:53:46,765
Speaker 6:  phone just because of what they're allowed to do, but also the restrictions

930
00:53:46,765 --> 00:53:50,685
Speaker 6:  of the technology and stuff. But like the 1.5 step of this transition,

931
00:53:50,685 --> 00:53:54,365
Speaker 6:  you would want to be your, your phone becomes the computer

932
00:53:54,505 --> 00:53:58,325
Speaker 6:  and then you, you have a bunch of new wearable accessories that you use.

933
00:53:58,585 --> 00:54:01,965
Speaker 6:  You're just not allowed to build that. And so what all these companies have

934
00:54:02,125 --> 00:54:06,005
Speaker 6:  to do is basically like engineer a giant societal shift out of

935
00:54:06,005 --> 00:54:09,805
Speaker 6:  nowhere because the like gradual change that actually would make

936
00:54:09,805 --> 00:54:13,285
Speaker 6:  this make sense is just walled off to all but two companies on the planet.

937
00:54:13,285 --> 00:54:16,005
Speaker 6:  Yeah. And if I were anybody but one of those two companies, I would be really

938
00:54:16,005 --> 00:54:16,565
Speaker 6:  pissed about that.

939
00:54:16,865 --> 00:54:20,765
Speaker 7:  So what has Zuckerberg done? He has gone and linked up with

940
00:54:20,765 --> 00:54:24,485
Speaker 7:  the Italians and the French 'cause it's technically right. Ellisor

941
00:54:24,555 --> 00:54:28,045
Speaker 7:  Luxottica, the parent company of RayBan is French and Italian. But

942
00:54:28,995 --> 00:54:32,965
Speaker 7:  what did you think Neli of his comment? So they've just done

943
00:54:33,005 --> 00:54:36,725
Speaker 7:  a 10 year deal with Ellisor Luxottica. The idea is that Meta's tech stack

944
00:54:36,725 --> 00:54:40,605
Speaker 7:  is something Ellisor will be able to put into any of its lines. It owns

945
00:54:40,645 --> 00:54:42,285
Speaker 7:  a ton of brands. Oakley, Raven,

946
00:54:42,395 --> 00:54:43,245
Speaker 5:  It's a monopoly.

947
00:54:43,765 --> 00:54:43,925
Speaker 7:  It's

948
00:54:44,595 --> 00:54:47,925
Speaker 5:  Wear. You and I are both wearing glasses made by them right now, presumably.

949
00:54:48,075 --> 00:54:50,085
Speaker 3:  Yeah. Yeah. Pull over in your car, look at your glasses.

950
00:54:51,845 --> 00:54:53,085
Speaker 3:  Probably made by s

951
00:54:53,155 --> 00:54:57,005
Speaker 7:  They just bought Supreme. So Supreme glasses. He

952
00:54:57,005 --> 00:54:59,845
Speaker 7:  confirmed in our interview that they're buying a stake in Ellisor Luxottica,

953
00:54:59,845 --> 00:55:03,765
Speaker 7:  which was news. But his comment about he

954
00:55:03,765 --> 00:55:07,725
Speaker 7:  thinks that Ellisor will be for Europe and smart glasses, what

955
00:55:07,725 --> 00:55:10,605
Speaker 7:  Samsung was for Korea and phones. Incredible.

956
00:55:10,605 --> 00:55:13,445
Speaker 3:  What you think about that, Nina? Oh, interesting. It's a good line. It's

957
00:55:13,445 --> 00:55:17,205
Speaker 3:  a great line. It is extraordinarily presumptuous

958
00:55:17,305 --> 00:55:21,165
Speaker 3:  in the best possible way. Yeah. Like if you're at Samsung,

959
00:55:21,265 --> 00:55:23,565
Speaker 3:  you're like, yo, we were Samsung before

960
00:55:25,505 --> 00:55:26,885
Speaker 10:  We make ships like,

961
00:55:27,795 --> 00:55:31,125
Speaker 3:  Like our nuclear reactor division is doing just fine.

962
00:55:33,065 --> 00:55:36,605
Speaker 3:  So that is confusing. But what he means is

963
00:55:37,155 --> 00:55:41,005
Speaker 3:  Android is the operating system enabled Samsung to enter the mobile

964
00:55:41,005 --> 00:55:44,765
Speaker 3:  phone market. Samsung is now even more Samsung than it was before.

965
00:55:44,765 --> 00:55:48,325
Speaker 3:  Yeah. I would point out by the way, a Saturday Samsung alert If, you are

966
00:55:48,325 --> 00:55:51,885
Speaker 3:  over a chess listener, know that Samsung required all of its executives to

967
00:55:51,885 --> 00:55:55,685
Speaker 3:  work six days in the office to, in a sense insert

968
00:55:55,805 --> 00:55:58,805
Speaker 3:  a sense of urgency and crisis into the company. They don't make anything.

969
00:55:58,805 --> 00:56:02,445
Speaker 3:  So all they can do is come up with deals. They cut the price of one of their

970
00:56:02,445 --> 00:56:05,445
Speaker 3:  gaming monitors by 50% and gave you not one but two TVs for free. If, you

971
00:56:05,445 --> 00:56:09,365
Speaker 3:  buy one. Incredible. It's on the website. Saturday Samsung. Everybody,

972
00:56:09,465 --> 00:56:09,845
Speaker 3:  you had

973
00:56:09,845 --> 00:56:11,205
Speaker 7:  To go on that tangent. You had to.

974
00:56:11,355 --> 00:56:14,285
Speaker 3:  It's it's just incredible. Yeah. Every part of every part of Saturday Samsung

975
00:56:14,505 --> 00:56:18,445
Speaker 3:  it is better than less. Makes me happy. But wait, what he's saying is

976
00:56:18,535 --> 00:56:22,445
Speaker 3:  there was a hardware vendor in Samsung and Android came along

977
00:56:22,765 --> 00:56:25,445
Speaker 3:  provided at the operating system and the opportunity to go address the world

978
00:56:25,445 --> 00:56:28,925
Speaker 3:  market. And now they are Samsung. Yeah. Again, extraordinarily presumptuous

979
00:56:28,925 --> 00:56:32,845
Speaker 3:  in the best way. Are you saying that Esor Luxottica is a hardware maker

980
00:56:33,745 --> 00:56:37,725
Speaker 3:  and are something, is the operating system that will let you

981
00:56:37,725 --> 00:56:41,645
Speaker 3:  go become Samsung? Well, you're missing some key components, right?

982
00:56:42,245 --> 00:56:46,045
Speaker 3:  Es Asada doesn't make chips. Samsung makes fucking dram. Like

983
00:56:46,045 --> 00:56:49,965
Speaker 3:  they're like the hardware maker. They make ole displays and

984
00:56:50,055 --> 00:56:54,005
Speaker 3:  chips. The first ch the first processor in they made batteries was

985
00:56:54,085 --> 00:56:57,965
Speaker 3:  a Samsung arm processor. Right? So like the industry was built on top

986
00:56:57,965 --> 00:57:00,125
Speaker 3:  of Samsung from the jump.

987
00:57:00,745 --> 00:57:03,685
Speaker 7:  I'm pretty sure I'm looking at these new transparent ray bands. They announced,

988
00:57:03,865 --> 00:57:07,485
Speaker 7:  I'm sorry, Tom Warren translucent, translucent ray

989
00:57:07,485 --> 00:57:10,485
Speaker 3:  Bands. He's really ran into like, I work with a bunch of nerds this week

990
00:57:11,455 --> 00:57:13,205
Speaker 3:  piece and

991
00:57:13,205 --> 00:57:14,805
Speaker 7:  I think it's a Qualcomm chip inside actually,

992
00:57:15,145 --> 00:57:18,285
Speaker 3:  I'm just saying like all of that, like Samsung's latent capabilities

993
00:57:19,075 --> 00:57:22,925
Speaker 3:  were brought together because Google provided them a, an

994
00:57:22,925 --> 00:57:26,165
Speaker 3:  operating system that let them become dominant in phones. Yeah. Maybe Microsoft

995
00:57:26,165 --> 00:57:28,965
Speaker 3:  could have provided an operating system. You remember Samsung made a bunch

996
00:57:28,965 --> 00:57:31,885
Speaker 3:  of weaker Windows phones in in the early days. Mm.

997
00:57:33,085 --> 00:57:36,885
Speaker 3:  I But does Luxottica have chips

998
00:57:36,905 --> 00:57:40,645
Speaker 3:  and Ram or does it just have design chops and retail distribution? I think

999
00:57:40,645 --> 00:57:44,205
Speaker 3:  that whole comment was basically another like

1000
00:57:44,555 --> 00:57:48,525
Speaker 3:  shot at the eu because the big criticism of all the EU regulatory

1001
00:57:48,575 --> 00:57:51,045
Speaker 3:  stuff is we, the United States,

1002
00:57:52,305 --> 00:57:56,285
Speaker 3:  deeply weird libertarian, unregulated United States makes the tech

1003
00:57:56,565 --> 00:58:00,405
Speaker 3:  companies and you make the taxes and all you have is Spotify, which

1004
00:58:00,405 --> 00:58:04,285
Speaker 3:  only ever complains about not having access to iOS. And that

1005
00:58:04,555 --> 00:58:08,365
Speaker 3:  basically is the, the shape of the complaint. and we have European

1006
00:58:08,365 --> 00:58:10,365
Speaker 3:  listeners are gonna argue with me about something or the other. It's fine.

1007
00:58:10,665 --> 00:58:13,365
Speaker 3:  But that is the shape of the complaint from Silicon Valley. And I think Mark

1008
00:58:13,365 --> 00:58:16,605
Speaker 3:  is saying, look, I'll take one of your companies and I'll turn 'em into Samsung

1009
00:58:16,675 --> 00:58:20,085
Speaker 3:  just to get the hell outta my way. And I don't know that that comparison

1010
00:58:20,375 --> 00:58:24,165
Speaker 3:  holds up because again, Luxottica does own everything. Yeah. But instead

1011
00:58:24,165 --> 00:58:28,125
Speaker 3:  of dram fabs they own Supreme. Yeah.

1012
00:58:29,035 --> 00:58:32,085
Speaker 3:  Like it's just a very different Yeah. Thing. But

1013
00:58:32,305 --> 00:58:36,165
Speaker 6:  But potentially like as the, as the proprietor of the Eli's

1014
00:58:36,625 --> 00:58:38,245
Speaker 6:  insane theory of wearable bullshit.

1015
00:58:39,305 --> 00:58:41,165
Speaker 3:  I'm ready, I'm ready for this. You have to acknowledge if you're opening

1016
00:58:41,165 --> 00:58:42,485
Speaker 3:  this door, I'm, I'm walking right in. No,

1017
00:58:42,485 --> 00:58:45,925
Speaker 6:  You, you have to acknowledge that making the DRAM and owning Supreme might

1018
00:58:45,925 --> 00:58:48,565
Speaker 6:  be equally important in this. Like, oh,

1019
00:58:48,565 --> 00:58:48,805
Speaker 3:  They are,

1020
00:58:49,195 --> 00:58:50,085
Speaker 7:  They think that it doesn't,

1021
00:58:50,225 --> 00:58:54,085
Speaker 6:  You can't sit here and tell me that fids and value

1022
00:58:54,425 --> 00:58:58,365
Speaker 6:  are opposing things unless you agree that looking good on your face is

1023
00:58:58,365 --> 00:59:02,165
Speaker 6:  important. And there there are a small number of companies that are very,

1024
00:59:02,195 --> 00:59:05,925
Speaker 6:  very good at making things that people like wearing on their face. And

1025
00:59:06,165 --> 00:59:09,245
Speaker 6:  I, I think you could argue that a lot of companies in tech have tried to

1026
00:59:09,915 --> 00:59:13,605
Speaker 6:  like, acquire or develop that capability and can't do it.

1027
00:59:13,675 --> 00:59:17,565
Speaker 7:  There's no way Meta would've made these, there's no way they would look anything

1028
00:59:17,565 --> 00:59:17,965
Speaker 7:  like these.

1029
00:59:18,345 --> 00:59:22,085
Speaker 6:  It honestly, it might be easier to learn how to make DRAM as a company than

1030
00:59:22,085 --> 00:59:22,925
Speaker 6:  to learn how to be cool.

1031
00:59:23,075 --> 00:59:27,045
Speaker 3:  Yeah. I was like, okay, well can we just clip that, that line and

1032
00:59:27,045 --> 00:59:30,805
Speaker 3:  just put it on TikTok and just let it live its own life. I sincerely believe

1033
00:59:30,805 --> 00:59:32,285
Speaker 3:  that. But like the hundred years,

1034
00:59:32,285 --> 00:59:33,765
Speaker 6:  The history of technology said that is

1035
00:59:33,885 --> 00:59:36,525
Speaker 3:  Probably true. Easier to make dram than glasses to look good.

1036
00:59:36,995 --> 00:59:40,325
Speaker 5:  It's, I mean the, the ones that they wear, like they got just a little right,

1037
00:59:40,325 --> 00:59:43,245
Speaker 5:  the Orion's because they look like Buddy Holly glasses from the fifties,

1038
00:59:43,535 --> 00:59:46,565
Speaker 7:  Which are actually kind of coming back. Like that was another thing. That

1039
00:59:46,565 --> 00:59:49,285
Speaker 7:  was another thing Zuckerberg said is like, it's kind of nice that chunky

1040
00:59:49,285 --> 00:59:50,365
Speaker 7:  glasses are back in style.

1041
00:59:50,915 --> 00:59:54,845
Speaker 3:  Like this is like a Zuckerberg long game, right? Like Yeah, he, he, he

1042
00:59:54,845 --> 00:59:57,485
Speaker 3:  bought off a bunch of fashion houses in the background. I was like, make

1043
00:59:57,605 --> 01:00:00,645
Speaker 3:  the glasses bigger and like, and you know, it's like that scene from Devil

1044
01:00:00,645 --> 01:00:01,205
Speaker 3:  Horse product.

1045
01:00:01,345 --> 01:00:04,685
Speaker 6:  He turned all the knobs on Instagram to make vintage cool again and now it's

1046
01:00:04,685 --> 01:00:04,805
Speaker 3:  Back.

1047
01:00:05,285 --> 01:00:08,325
Speaker 7:  I mean he's he's right, he's right. I was at the Snap event the week before

1048
01:00:08,425 --> 01:00:11,565
Speaker 7:  and I saw someone wearing what I thought were the new spectacles and they

1049
01:00:11,565 --> 01:00:12,165
Speaker 7:  were Prada glasses.

1050
01:00:13,465 --> 01:00:16,965
Speaker 3:  I'm just saying Ian was picked in this room for you. Alex.

1051
01:00:17,285 --> 01:00:18,245
Speaker 3:  That's what's happening here.

1052
01:00:20,585 --> 01:00:24,245
Speaker 3:  No, but like the, I look, I'm saying I, I, I agree. I'm very

1053
01:00:24,245 --> 01:00:27,005
Speaker 3:  excited to get my clear Raybans on Monday. They

1054
01:00:27,005 --> 01:00:27,405
Speaker 6:  Look so good.

1055
01:00:27,405 --> 01:00:30,565
Speaker 3:  They're pretty cool. They only make them in this small size. And I have a

1056
01:00:30,565 --> 01:00:31,965
Speaker 3:  huge head and I'm furious about this.

1057
01:00:32,025 --> 01:00:34,645
Speaker 7:  You're 49 or 50 or 52,

1058
01:00:35,925 --> 01:00:37,765
Speaker 3:  Whatever. What's the bigger go? Bigger. Bigger. Number

1059
01:00:37,765 --> 01:00:38,805
Speaker 7:  52 is like you

1060
01:00:39,055 --> 01:00:40,365
Speaker 3:  60. Good. Just as big

1061
01:00:40,365 --> 01:00:40,605
Speaker 7:  As they

1062
01:00:40,605 --> 01:00:41,165
Speaker 3:  Can be. No,

1063
01:00:41,535 --> 01:00:44,965
Speaker 7:  52 is like, most brands are like, sorry, like Yeah,

1064
01:00:45,525 --> 01:00:46,725
Speaker 3:  I know. Which is why I can't. So

1065
01:00:46,725 --> 01:00:49,245
Speaker 7:  You're probably a 50. I'm like a 49 50. These are comfortable.

1066
01:00:49,675 --> 01:00:51,485
Speaker 3:  Stop measuring my head first of all. Like

1067
01:00:52,235 --> 01:00:56,085
Speaker 7:  I've just been enough with you in person to kind of, you know, map it in

1068
01:00:56,085 --> 01:00:56,205
Speaker 7:  my

1069
01:00:56,205 --> 01:00:59,565
Speaker 3:  Mind. I I have a side hobby of head measurement. Yeah.

1070
01:00:59,995 --> 01:01:01,285
Speaker 3:  It's not problematic at all.

1071
01:01:04,345 --> 01:01:08,285
Speaker 3:  I'm just saying as big as they can get. And I know Boz has an equally sized

1072
01:01:08,305 --> 01:01:11,325
Speaker 3:  noggin that's, I know that he should have built the bigger ones 'cause it,

1073
01:01:11,325 --> 01:01:14,405
Speaker 3:  the regular ones come two sizes and these only come in medium. But I'm getting

1074
01:01:14,565 --> 01:01:16,285
Speaker 3:  'em on Monday. I'm very excited. It's the first time I've got them. I think

1075
01:01:16,285 --> 01:01:20,165
Speaker 3:  the clear ones look sick. I'm excited to do all this stuff with them.

1076
01:01:20,665 --> 01:01:24,605
Speaker 3:  The, the jump that I'm curious about, right? 'cause now Meta AI is

1077
01:01:24,995 --> 01:01:28,605
Speaker 3:  more conversational. It can remember things. It can, they've added some capability

1078
01:01:28,605 --> 01:01:32,045
Speaker 3:  to it. That's all running in their

1079
01:01:32,255 --> 01:01:35,645
Speaker 3:  cloud still. Right? Like you talk to the glasses, it talks to your

1080
01:01:36,175 --> 01:01:37,925
Speaker 3:  phone, it uses your phone's connection.

1081
01:01:37,995 --> 01:01:39,885
Speaker 7:  They've got a decent amount that's on device now.

1082
01:01:40,025 --> 01:01:41,325
Speaker 3:  On the glasses on device. Yeah.

1083
01:01:41,595 --> 01:01:45,245
Speaker 7:  Because they're, they're doing with llama these super fine tuned distilled

1084
01:01:45,245 --> 01:01:48,765
Speaker 7:  models. So the latency on these is like pretty incredible

1085
01:01:49,505 --> 01:01:53,365
Speaker 7:  in terms of how quick the AI is. It's not humane pin. Wait a minute to

1086
01:01:53,365 --> 01:01:56,925
Speaker 7:  set a timer. Yeah. It's like answer something in like

1087
01:01:57,365 --> 01:02:01,325
Speaker 7:  a second. Right. Or like, tell me what's in this photo and it does

1088
01:02:01,325 --> 01:02:04,885
Speaker 7:  it in a couple seconds. And I got the demo of the new

1089
01:02:05,105 --> 01:02:09,085
Speaker 7:  AI stuff that they're adding to the Ray bands. So did Kylie, so did Jay.

1090
01:02:09,985 --> 01:02:13,645
Speaker 7:  And it's like, wow, okay. They're, they're understanding this form factor

1091
01:02:13,665 --> 01:02:17,085
Speaker 7:  and what's unique about it. So being able to like look at a phone number

1092
01:02:17,345 --> 01:02:21,005
Speaker 7:  and say, call that phone number and it just calls it and the call comes in

1093
01:02:21,005 --> 01:02:24,805
Speaker 7:  on your glasses because it's paired to your phone or scan that QR

1094
01:02:24,805 --> 01:02:28,525
Speaker 7:  code like you're looking at a menu, the webpage for the menu just gets

1095
01:02:28,525 --> 01:02:32,245
Speaker 7:  sent to your phone. Like breaking down some of the

1096
01:02:33,125 --> 01:02:36,485
Speaker 7:  interactions you would do with a phone that require extra steps and like,

1097
01:02:36,485 --> 01:02:40,245
Speaker 7:  just like taking a step away is like an kind of an aha

1098
01:02:40,245 --> 01:02:43,565
Speaker 7:  moment when you do it. You're like, oh, like this is where it's going.

1099
01:02:43,995 --> 01:02:47,805
Speaker 7:  Yeah. And it's the first time that I feel like AI makes

1100
01:02:47,805 --> 01:02:51,725
Speaker 7:  sense in a wearable And did, did

1101
01:02:51,725 --> 01:02:55,245
Speaker 7:  you guys watch the keynote in the live translation demo that Zuck did? Yeah,

1102
01:02:55,245 --> 01:02:55,405
Speaker 7:  that's

1103
01:02:55,405 --> 01:02:58,685
Speaker 3:  When he brought the MMA fighter. Yeah. Yeah. He said yell some words at me

1104
01:02:58,685 --> 01:02:59,685
Speaker 3:  in Spanish. That is

1105
01:02:59,685 --> 01:03:03,285
Speaker 7:  Wild. That is wild. That is like, that is like Putin's earpiece

1106
01:03:03,665 --> 01:03:06,605
Speaker 7:  on stage like at scale, you know, for like anyone.

1107
01:03:07,625 --> 01:03:09,325
Speaker 7:  and it works. And

1108
01:03:09,405 --> 01:03:12,125
Speaker 5:  I mean it was a thing like Google promised a couple of years ago, right?

1109
01:03:12,435 --> 01:03:12,725
Speaker 5:  Yeah.

1110
01:03:12,805 --> 01:03:16,405
Speaker 3:  I think that the really interesting part of this is these

1111
01:03:16,495 --> 01:03:20,325
Speaker 3:  ideas are all just the ideas. Like these are the demos

1112
01:03:20,325 --> 01:03:24,205
Speaker 3:  we have been hearing about or promised for a decade if not more,

1113
01:03:24,695 --> 01:03:28,045
Speaker 3:  right. Live translation. Like Apple has live translation on your iPhone.

1114
01:03:28,045 --> 01:03:31,445
Speaker 3:  You should open the app and it'll do it. Google can do it. It's the form

1115
01:03:31,445 --> 01:03:34,365
Speaker 3:  factor like you're saying Alex that like, okay we've put this in glasses,

1116
01:03:34,475 --> 01:03:38,405
Speaker 3:  your phone is away, there's no screen, there's just an ambient

1117
01:03:38,685 --> 01:03:42,325
Speaker 3:  computer. Another thing that has been promised for a billion years and it's

1118
01:03:42,325 --> 01:03:45,845
Speaker 3:  just paying attention and helping you out as you go through your day. Does

1119
01:03:45,845 --> 01:03:49,685
Speaker 3:  that ambient computer require sending an awful lot of data to Meta? It

1120
01:03:49,875 --> 01:03:53,765
Speaker 3:  sure does, right? It just really, really does. But that's the

1121
01:03:53,765 --> 01:03:57,605
Speaker 3:  trade off all the way down to one day. I'm guessing Orion will have

1122
01:03:57,625 --> 01:04:01,005
Speaker 3:  my dream feature, which is I will look at someone and it will tell me their

1123
01:04:01,005 --> 01:04:04,925
Speaker 3:  name. Yes. And that will absolutely require Meta searching.

1124
01:04:05,145 --> 01:04:08,485
Speaker 3:  Its gigantic worldwide surveillance database of names and faces,

1125
01:04:09,145 --> 01:04:11,005
Speaker 3:  but like they're gonna build, that's the technical

1126
01:04:11,005 --> 01:04:13,685
Speaker 7:  Name. I was waiting for you to bring this up in my Orion demo.

1127
01:04:15,065 --> 01:04:19,045
Speaker 7:  The VP of wearables at Meta said we're excited

1128
01:04:19,045 --> 01:04:21,365
Speaker 7:  about name tags. Yeah it

1129
01:04:21,365 --> 01:04:24,405
Speaker 3:  Is. It's it is the feature If. you can do name tags, it doesn't matter. I

1130
01:04:24,405 --> 01:04:25,485
Speaker 3:  will wear the backpack. Yeah,

1131
01:04:25,695 --> 01:04:26,045
Speaker 7:  Right.

1132
01:04:26,155 --> 01:04:27,845
Speaker 3:  Like all day long. Everybody

1133
01:04:27,845 --> 01:04:29,405
Speaker 5:  At CES. Yeah.

1134
01:04:29,965 --> 01:04:33,045
Speaker 7:  I wanna double click on what you said, like that the phones have live translation.

1135
01:04:33,045 --> 01:04:35,845
Speaker 7:  Because I think this is important when we're talking about like these form

1136
01:04:35,845 --> 01:04:39,445
Speaker 7:  factors. Yes they do. Like, especially iOS 18, it's really easy to just do

1137
01:04:39,445 --> 01:04:43,205
Speaker 7:  like live language translation from the action button and from the action

1138
01:04:43,205 --> 01:04:46,765
Speaker 7:  button. There's something about not having your phone out though

1139
01:04:47,125 --> 01:04:50,445
Speaker 7:  that feels like, oh I would actually use this. I like think about like talking

1140
01:04:50,465 --> 01:04:54,445
Speaker 7:  to someone in another language and holding your phone between you. It's

1141
01:04:54,445 --> 01:04:57,605
Speaker 7:  like an interview. Like it's just awkward, but it's like, oh wait, when this

1142
01:04:57,605 --> 01:05:00,645
Speaker 7:  isn't a form factor where like they can't even hear that what they're saying

1143
01:05:00,645 --> 01:05:04,605
Speaker 7:  is being translated to me in my language and I'm not even pulling a device

1144
01:05:04,625 --> 01:05:08,605
Speaker 7:  out. Like all of a sudden these features make sense as like something

1145
01:05:08,605 --> 01:05:11,605
Speaker 7:  you would use in the world. And I think that's what these mean, like these,

1146
01:05:11,715 --> 01:05:15,565
Speaker 7:  it's like taking all these concepts and like putting in a device that like,

1147
01:05:15,565 --> 01:05:16,965
Speaker 7:  oh, like you'd actually do this.

1148
01:05:17,715 --> 01:05:21,045
Speaker 5:  Yeah. 'cause they are cuter than the pixel buds. They're no disrespect,

1149
01:05:21,045 --> 01:05:24,285
Speaker 3:  They're Well, so here these are, they're just, again the ideas,

1150
01:05:24,825 --> 01:05:28,685
Speaker 3:  the end state, the goals very familiar. Everybody

1151
01:05:28,685 --> 01:05:32,325
Speaker 3:  shares them. The demos as described very familiar.

1152
01:05:32,325 --> 01:05:35,725
Speaker 3:  Everybody has the same ones. It's really down to

1153
01:05:36,015 --> 01:05:39,045
Speaker 3:  where is the form factor? How fast can we get there? Can we ship it at scale?

1154
01:05:39,505 --> 01:05:42,765
Speaker 3:  Are the phone makers, the operating system vendors gonna get in our way?

1155
01:05:42,815 --> 01:05:46,645
Speaker 3:  Which is a big deal. And you're kind of like, okay, well the closest Apple

1156
01:05:46,745 --> 01:05:50,285
Speaker 3:  is fundamentally is AirPods. Yeah. Right. Like

1157
01:05:50,285 --> 01:05:53,885
Speaker 3:  fundamentally the closest they are to this kind of idea is AirPods or they

1158
01:05:53,885 --> 01:05:56,565
Speaker 3:  haven't put glasses on their face yet. They have an Apple watch but doesn't

1159
01:05:56,565 --> 01:06:00,365
Speaker 3:  really do any AR stuff. Yeah. They have pinchy pinch. You can, you

1160
01:06:00,365 --> 01:06:01,325
Speaker 5:  Can do, I mean honestly, every

1161
01:06:01,325 --> 01:06:02,605
Speaker 3:  Time time you tap away with an Apple watch,

1162
01:06:02,845 --> 01:06:06,805
Speaker 5:  I wear my Meta ray bands. The, the number one feeling I have is, boy I

1163
01:06:06,805 --> 01:06:09,725
Speaker 5:  wish this actually tied in with my phone. Yeah. So, I could use Siri because

1164
01:06:10,115 --> 01:06:11,885
Speaker 5:  then I would have access to all my stuff.

1165
01:06:12,275 --> 01:06:12,565
Speaker 3:  Yeah,

1166
01:06:12,645 --> 01:06:16,525
Speaker 7:  Yeah. Siri could just like, you know, like text the wrong person at

1167
01:06:16,525 --> 01:06:16,885
Speaker 7:  any point

1168
01:06:17,285 --> 01:06:19,445
Speaker 5:  I could just play my music because

1169
01:06:19,565 --> 01:06:22,845
Speaker 3:  I don't, okay. So that's that. So it's AirPods for Apple, it, it Alex you

1170
01:06:22,845 --> 01:06:26,285
Speaker 3:  were just bringing up the pixel buds. Yeah, that is Google's. Although does

1171
01:06:26,285 --> 01:06:28,205
Speaker 3:  Google remember that it made the pixel buds and it made,

1172
01:06:28,305 --> 01:06:30,325
Speaker 5:  It made the pixel buds too, which

1173
01:06:30,755 --> 01:06:31,645
Speaker 3:  Sure Neli.

1174
01:06:31,645 --> 01:06:35,125
Speaker 5:  Yeah. The review came up the same time. Yeah. The metal event.

1175
01:06:35,155 --> 01:06:38,925
Speaker 7:  Yeah. So Neli AirPods, great example with my AirPods. I can say, Hey

1176
01:06:38,945 --> 01:06:42,165
Speaker 7:  remind me about whatever. I can say whatever I want it to remind me about

1177
01:06:42,225 --> 01:06:44,845
Speaker 7:  at a certain time. Right. And I'll get the notification and the reminders

1178
01:06:44,845 --> 01:06:48,685
Speaker 7:  app with the Ray bands you can say, Hey look at this and remind me about

1179
01:06:48,685 --> 01:06:50,685
Speaker 7:  it at whatever time. Right?

1180
01:06:50,845 --> 01:06:51,205
Speaker 3:  'cause it can

1181
01:06:51,205 --> 01:06:55,085
Speaker 7:  See, yeah, that's like, that's wildly useful to me. I

1182
01:06:55,085 --> 01:06:58,845
Speaker 7:  cannot tell you how many times throughout the day. I just wanna have a snapshot

1183
01:06:58,865 --> 01:07:02,805
Speaker 7:  of whatever I'm looking at and go back to it later. And like those

1184
01:07:02,895 --> 01:07:06,685
Speaker 7:  ideas, because you had literally have a camera on your face. You can't do

1185
01:07:06,685 --> 01:07:09,765
Speaker 7:  that with AirPods. And so you're right, like the closest we have are these

1186
01:07:09,795 --> 01:07:13,685
Speaker 7:  earbuds that are internet connected and can hear our voice. There's

1187
01:07:13,685 --> 01:07:15,565
Speaker 7:  something about adding the cameras though. That's

1188
01:07:15,565 --> 01:07:19,445
Speaker 3:  Big. So you know the the prevailing theory of why the camera control

1189
01:07:19,445 --> 01:07:23,125
Speaker 3:  button is not just on the pro phone but also on the regular 16 is that Apple

1190
01:07:23,305 --> 01:07:26,445
Speaker 3:  add visual intelligence and then you'll be able to quickly access the camera

1191
01:07:26,505 --> 01:07:27,845
Speaker 3:  and look at stuff and Well,

1192
01:07:27,845 --> 01:07:31,045
Speaker 6:  When, when you say theory, you mean Apple just said that out loud in that

1193
01:07:31,055 --> 01:07:31,605
Speaker 6:  Benet words,

1194
01:07:32,195 --> 01:07:34,485
Speaker 3:  Well they haven't shipped yet, is vapor till ships. Like,

1195
01:07:34,545 --> 01:07:37,405
Speaker 6:  No, but I mean that is, it's, whether it's good or not is a question, but

1196
01:07:37,405 --> 01:07:40,325
Speaker 6:  like that is, that is clearly that is half the purpose of the thing. Like

1197
01:07:40,325 --> 01:07:41,205
Speaker 6:  they have just said as much

1198
01:07:41,945 --> 01:07:45,925
Speaker 3:  At this point, my theory, like whether Apple has its own unified

1199
01:07:45,945 --> 01:07:49,805
Speaker 3:  theory of what it's doing. It's like sure, I've used control center

1200
01:07:49,825 --> 01:07:53,755
Speaker 3:  and iOS a t enough to be like, did anybody pay attention to this?

1201
01:07:53,825 --> 01:07:54,115
Speaker 3:  Like,

1202
01:07:54,255 --> 01:07:57,915
Speaker 6:  But also there are, there are increasingly convincing and well sourced rumors

1203
01:07:57,915 --> 01:08:01,035
Speaker 6:  about things like AirPods with a camera, which, what would that look like?

1204
01:08:01,215 --> 01:08:05,195
Speaker 6:  And an Apple watch with a camera because I, I agree with you Heath. Like

1205
01:08:05,195 --> 01:08:09,155
Speaker 6:  the the camera is the thing. Yeah, both. Both as the input and

1206
01:08:09,155 --> 01:08:13,035
Speaker 6:  as like the activity, right? Like I hear from people all the time for

1207
01:08:13,035 --> 01:08:15,965
Speaker 6:  whom the reason to have the smart glasses is to take pictures of your kids

1208
01:08:16,235 --> 01:08:19,525
Speaker 6:  like, or your pets or whoever. Like I'm convinced my dog knows when I take

1209
01:08:19,525 --> 01:08:22,165
Speaker 6:  out my phone to take a picture of her, I'm a hundred percent sure. And she

1210
01:08:22,165 --> 01:08:24,405
Speaker 6:  runs away and now she doesn't anymore. And I can take pictures of her. It's

1211
01:08:24,405 --> 01:08:24,485
Speaker 6:  awesome.

1212
01:08:25,005 --> 01:08:27,285
Speaker 3:  I can't wait to get these glasses. Did you buy the glasses too, David?

1213
01:08:27,605 --> 01:08:31,445
Speaker 6:  I already have two pairs. Okay. I don't have a great answer for why

1214
01:08:31,485 --> 01:08:32,245
Speaker 6:  I have two pairs.

1215
01:08:32,325 --> 01:08:34,645
Speaker 3:  What do you have like the large size or the small size? 'cause If you don't

1216
01:08:34,645 --> 01:08:36,045
Speaker 3:  need the large size. I'm in the market.

1217
01:08:37,165 --> 01:08:40,725
Speaker 6:  I have, I don't know. I I also have a big head. So We'll, we'll, we'll have

1218
01:08:40,725 --> 01:08:41,485
Speaker 6:  to figure this out together.

1219
01:08:42,315 --> 01:08:44,485
Speaker 3:  Alex, how big do you think David said is, what do you think? 49 50?

1220
01:08:44,505 --> 01:08:46,765
Speaker 7:  I'm gonna guess he's like a 48, 47.

1221
01:08:48,795 --> 01:08:51,005
Speaker 6:  Neil has like a 65. Yeah, I'm saying

1222
01:08:51,185 --> 01:08:55,085
Speaker 3:  Bigger than better. I, it's not insulting to me. 80. Let's go the big the

1223
01:08:55,085 --> 01:08:55,285
Speaker 3:  better.

1224
01:08:57,665 --> 01:09:01,405
Speaker 3:  All right, let's we we this, so we talked a lot about the Meta stuff. I wanna

1225
01:09:01,405 --> 01:09:04,805
Speaker 3:  make sure we talk about two other pieces of Meta Connect that are

1226
01:09:04,805 --> 01:09:08,685
Speaker 3:  important and then spend a little time in OpenAI before we

1227
01:09:08,685 --> 01:09:11,965
Speaker 3:  go to light around. The other piece of Meta Connect that I think is deeply

1228
01:09:12,365 --> 01:09:16,205
Speaker 3:  fascinating is you guys did talk about AI a lot and

1229
01:09:16,205 --> 01:09:19,285
Speaker 3:  how it'll be expressed. It seems like they're chasing a big distribution

1230
01:09:19,285 --> 01:09:23,165
Speaker 3:  advantage with glasses that maybe other people will catch up to. But then

1231
01:09:23,165 --> 01:09:25,645
Speaker 3:  there's like training data and open source models.

1232
01:09:26,775 --> 01:09:30,285
Speaker 3:  Zuckerberg said, and I think this is one of the shots at Google, like I think

1233
01:09:30,285 --> 01:09:34,125
Speaker 3:  all of the, we're doing live demos. We shots at Apple for doing infomercials.

1234
01:09:34,365 --> 01:09:37,725
Speaker 3:  I think when he says things like we are the Linux of open source

1235
01:09:38,035 --> 01:09:41,525
Speaker 3:  because llama's like that's a shot at Google, right? Yeah. We're just gonna

1236
01:09:41,525 --> 01:09:43,485
Speaker 3:  have more distribution, we're gonna have more development, we're gonna be

1237
01:09:43,485 --> 01:09:45,805
Speaker 3:  better at everybody else. Be is open always piece closed, which is usually

1238
01:09:45,965 --> 01:09:49,005
Speaker 3:  Google's model. And that's just not how Google's doing it.

1239
01:09:50,775 --> 01:09:54,505
Speaker 3:  They had to suck up a lot of training data and you asked about people wanting

1240
01:09:54,505 --> 01:09:58,425
Speaker 3:  to opt out. There's all the celebrities on Instagram right now

1241
01:09:58,425 --> 01:10:02,265
Speaker 3:  saying, opt me out of this. His answer, explain his answer

1242
01:10:02,265 --> 01:10:04,145
Speaker 3:  and then we, we should talk about it a little bit 'cause it was really interesting.

1243
01:10:04,655 --> 01:10:08,305
Speaker 7:  Yeah, he said the quiet part out loud, which is that

1244
01:10:09,385 --> 01:10:12,065
Speaker 7:  everyone thinks their data is more valuable than it actually is for these

1245
01:10:12,065 --> 01:10:14,905
Speaker 7:  models In aggregate it's valuable. But

1246
01:10:17,615 --> 01:10:20,745
Speaker 7:  when you're some, when you're a company like Meta and it's like the entire

1247
01:10:20,745 --> 01:10:24,465
Speaker 7:  world is your corpus of information in the internet at large.

1248
01:10:26,055 --> 01:10:29,785
Speaker 7:  What exactly do you have to have? And I think, you know,

1249
01:10:30,125 --> 01:10:33,785
Speaker 7:  we were talking a lot about publishers and about how Meta has basically thrown

1250
01:10:33,845 --> 01:10:37,665
Speaker 7:  its hands up on news and you know, Rupert Murdoch is in Australia

1251
01:10:37,805 --> 01:10:40,825
Speaker 7:  saying pay me or I'm gonna take your news off and Zuckerberg's like fine,

1252
01:10:41,015 --> 01:10:42,905
Speaker 7:  like whatever. Like people don't even like this.

1253
01:10:45,085 --> 01:10:48,825
Speaker 7:  So we, we were talking a lot about publishers but I think he's

1254
01:10:48,975 --> 01:10:52,905
Speaker 7:  kind of just saying that look like yes, you

1255
01:10:52,905 --> 01:10:56,825
Speaker 7:  know, people have feelings about their data being

1256
01:10:56,825 --> 01:10:57,945
Speaker 7:  used to train these models

1257
01:10:59,565 --> 01:11:02,785
Speaker 7:  and yes we're all doing it but we also like

1258
01:11:03,365 --> 01:11:07,345
Speaker 7:  If you, you know, If, you don't like it like go away. Like

1259
01:11:07,705 --> 01:11:09,065
Speaker 7:  whatever. It's like it's, so it's

1260
01:11:09,065 --> 01:11:12,465
Speaker 3:  Really interesting to me about this is that's the line to the publishers.

1261
01:11:12,465 --> 01:11:16,125
Speaker 3:  Like we will deran your news and we won't have news on threads. However you

1262
01:11:16,125 --> 01:11:19,285
Speaker 3:  want to interpret all of the many things Adam Saria said about that

1263
01:11:20,635 --> 01:11:24,605
Speaker 3:  there's no opt out for any user of these services unless you're in

1264
01:11:24,605 --> 01:11:26,045
Speaker 3:  the EU from having your stuff trained on.

1265
01:11:26,265 --> 01:11:28,925
Speaker 7:  And guess where Meta AI is not available in the eu.

1266
01:11:29,515 --> 01:11:33,125
Speaker 3:  Yeah. Right. And so, and he did say I remain what eternally

1267
01:11:33,125 --> 01:11:36,525
Speaker 3:  confident that we'll launch this in the eu, something like that on stage.

1268
01:11:36,865 --> 01:11:39,925
Speaker 3:  But there's just, I would just draw a connection. It, I think it is very

1269
01:11:39,925 --> 01:11:43,645
Speaker 3:  funny to dunk on people posting what amounts to chain letters

1270
01:11:43,745 --> 01:11:47,005
Speaker 3:  on their Instagram stories being like, dear Zuckerberg, by the

1271
01:11:47,275 --> 01:11:49,645
Speaker 3:  statute of Rome, I command you from not,

1272
01:11:50,145 --> 01:11:53,205
Speaker 7:  We were doing this on our Facebook walls like 15 years ago. Yeah.

1273
01:11:53,205 --> 01:11:54,005
Speaker 6:  This keeps happening.

1274
01:11:54,035 --> 01:11:56,925
Speaker 3:  Yeah. This is a chain letter. Like that's what it is. Yeah. And it's like

1275
01:11:57,105 --> 01:12:00,805
Speaker 3:  people think the law is magic words, you know, If, you just like

1276
01:12:01,015 --> 01:12:04,045
Speaker 3:  issue an incantation to the internet. Like someone has to do what you say

1277
01:12:04,045 --> 01:12:04,365
Speaker 3:  and it's like

1278
01:12:04,365 --> 01:12:07,885
Speaker 5:  Usually chain letters have a lot more like promising death than then than

1279
01:12:07,885 --> 01:12:11,445
Speaker 5:  these. Yeah. Yeah. And I really miss that. I wish if it was like send this

1280
01:12:11,445 --> 01:12:14,645
Speaker 5:  to 12 of your friends or Zuckerberg will appear in your house in his Latin

1281
01:12:14,645 --> 01:12:17,485
Speaker 5:  shirt and beat the shit outta you, that would be great.

1282
01:12:17,715 --> 01:12:21,485
Speaker 3:  Have you ever fallen down the hole of courtroom video? So people

1283
01:12:22,245 --> 01:12:26,205
Speaker 3:  invoking the sovereign citizen defense. Oh Lord, yes. In like local courtrooms

1284
01:12:26,745 --> 01:12:26,965
Speaker 3:  and

1285
01:12:26,965 --> 01:12:27,485
Speaker 5:  Then they're like,

1286
01:12:27,485 --> 01:12:30,685
Speaker 3:  Shut up. And the judges are like that, that doesn't mean anything. Yeah.

1287
01:12:30,825 --> 01:12:31,045
Speaker 3:  And

1288
01:12:31,045 --> 01:12:31,845
Speaker 5:  You're going to jail.

1289
01:12:33,185 --> 01:12:35,605
Speaker 3:  Shh. They're like by what authority? And the judges always like, because

1290
01:12:35,705 --> 01:12:39,605
Speaker 3:  I'm the judge and it is just like that, that's happening on in. and it is

1291
01:12:39,605 --> 01:12:40,005
Speaker 3:  very funny.

1292
01:12:40,435 --> 01:12:43,885
Speaker 6:  It's Michael Scott on the office yelling, I declare bankruptcy. It is. Exactly.

1293
01:12:43,985 --> 01:12:44,205
Speaker 3:  And

1294
01:12:44,205 --> 01:12:46,685
Speaker 6:  Then somebody pulls 'em aside and says that's nothing. And he goes, I didn't

1295
01:12:46,685 --> 01:12:49,085
Speaker 6:  say it, I declared it. That's what these people are doing.

1296
01:12:49,625 --> 01:12:53,525
Speaker 3:  So it is very funny. And I and Tom Brady, who has a Meta

1297
01:12:53,525 --> 01:12:57,285
Speaker 3:  deal to use his face for a chatbot has done it. He did. He did.

1298
01:12:57,385 --> 01:12:59,605
Speaker 3:  He did it. He did. They killed, they canceled the deal because that idea

1299
01:12:59,625 --> 01:13:03,365
Speaker 3:  was bad. Yeah. And they came up with a better idea of what if we just used

1300
01:13:03,365 --> 01:13:07,005
Speaker 3:  the celebrities voices and said they were the celebrities instead of pretending

1301
01:13:07,005 --> 01:13:08,205
Speaker 3:  they were other characters. Yeah.

1302
01:13:08,205 --> 01:13:11,085
Speaker 6:  It was Tom Brady as like Barry your workout partner or something.

1303
01:13:11,195 --> 01:13:14,765
Speaker 3:  Yeah, it was very confus confusing. Not great, but it was his face. And then

1304
01:13:15,005 --> 01:13:18,285
Speaker 3:  Kristen Bell, you can just chat with Kristen Bell. She put up one of these

1305
01:13:18,885 --> 01:13:22,325
Speaker 3:  that Kylie noticed 'cause she's Kristen Bell fan. And so she's like, you

1306
01:13:22,325 --> 01:13:25,405
Speaker 3:  have a deal with Meta AI and you have an Instagram post saying don't use

1307
01:13:25,405 --> 01:13:26,365
Speaker 3:  my stuff for Meta AI

1308
01:13:27,525 --> 01:13:29,845
Speaker 7:  Ship sales. Well that was before she saw the zeros on the check.

1309
01:13:30,195 --> 01:13:30,485
Speaker 3:  Yeah,

1310
01:13:30,895 --> 01:13:32,085
Speaker 5:  Money, money is cool.

1311
01:13:32,115 --> 01:13:33,645
Speaker 7:  Yeah. They're paying for these celebrity voices,

1312
01:13:34,495 --> 01:13:37,125
Speaker 3:  Great reporting, paying, paying millions of dollars for the rest of us. Yeah.

1313
01:13:37,265 --> 01:13:41,255
Speaker 3:  So here's what I will just say about that thing. The

1314
01:13:41,925 --> 01:13:45,335
Speaker 3:  idea that you can negotiate with Meta feels

1315
01:13:45,335 --> 01:13:49,215
Speaker 3:  intuitive to everyone, right? Or any platform.

1316
01:13:50,495 --> 01:13:54,235
Speaker 3:  I'm posting my stuff here, I should be able to tell you how I want you to

1317
01:13:54,235 --> 01:13:56,875
Speaker 3:  use it, but you don't. And the answer is, well you already signed the terms

1318
01:13:56,875 --> 01:14:00,235
Speaker 3:  of service and you go away. You didn't, but everyone knows nobody reads that

1319
01:14:00,235 --> 01:14:00,395
Speaker 3:  shit

1320
01:14:02,025 --> 01:14:05,635
Speaker 3:  when half of your users are like collectively

1321
01:14:05,635 --> 01:14:08,915
Speaker 3:  trying to renegotiate the terms of their agreement with you.

1322
01:14:09,505 --> 01:14:11,565
Speaker 3:  That means there's a problem. Like kind

1323
01:14:11,565 --> 01:14:15,085
Speaker 7:  Of they're doing it on your platform though, that's the thing. Yeah. Like,

1324
01:14:15,115 --> 01:14:15,405
Speaker 7:  well

1325
01:14:15,405 --> 01:14:18,925
Speaker 3:  That's fine, but like you can't, there's, there's so other

1326
01:14:19,265 --> 01:14:23,165
Speaker 3:  things in the world where like you don't get to

1327
01:14:23,165 --> 01:14:27,085
Speaker 3:  negotiate on this level except for weird internet terms of service that

1328
01:14:27,445 --> 01:14:31,325
Speaker 3:  everyone agrees. No one reads, right? Like and I would just say

1329
01:14:31,325 --> 01:14:35,125
Speaker 3:  like If, you are one of the many, many, many young staffers

1330
01:14:35,125 --> 01:14:38,845
Speaker 3:  in DC who listens to the show, which is a weird audience that we have. And

1331
01:14:38,845 --> 01:14:42,425
Speaker 3:  I love you. I'm glad that we're making the commute to your basement office

1332
01:14:42,425 --> 01:14:45,665
Speaker 3:  in the capitol better. You should look at all the people

1333
01:14:46,215 --> 01:14:50,105
Speaker 3:  posting. I don't want you to train on my data on Meta's

1334
01:14:50,105 --> 01:14:53,905
Speaker 3:  own platform and the basic response of, yeah, go fuck

1335
01:14:54,105 --> 01:14:57,885
Speaker 3:  yourself and be like, oh this is actually what regulations are for,

1336
01:14:58,175 --> 01:15:02,085
Speaker 3:  right? Like the people are expressing that they do not like that

1337
01:15:02,085 --> 01:15:05,605
Speaker 3:  the terms of this arrangement are not in their favor

1338
01:15:06,385 --> 01:15:09,965
Speaker 3:  and no one is an individual has enough power

1339
01:15:10,905 --> 01:15:14,765
Speaker 3:  to change it. And Mark Zuckerberg is like everyone overvalues the,

1340
01:15:15,015 --> 01:15:18,965
Speaker 3:  their work in this context, So I don't have to pay attention to it. Like

1341
01:15:18,995 --> 01:15:22,845
Speaker 3:  that is actually the problem that like, it doesn't matter if you're a

1342
01:15:23,125 --> 01:15:27,005
Speaker 3:  Republican or a Democrat or a libertarian or whatever. That thing is

1343
01:15:27,145 --> 01:15:29,645
Speaker 3:  the problem that governments are meant to equalize.

1344
01:15:29,945 --> 01:15:33,925
Speaker 7:  How is this any different from using data for ad targeting? Think about when

1345
01:15:33,925 --> 01:15:37,525
Speaker 7:  we copy and pasted protest messages on Facebook 15 years ago, what was it

1346
01:15:37,525 --> 01:15:38,005
Speaker 7:  about? It was,

1347
01:15:38,945 --> 01:15:42,405
Speaker 3:  I'm I'm putting this all in the same line, right? This is all the same line

1348
01:15:42,405 --> 01:15:45,845
Speaker 3:  of thing. My point is when everyone is like, I signed this agreement, I didn't

1349
01:15:45,875 --> 01:15:49,765
Speaker 3:  read it right and now I've handed over whatever leverage I might have had

1350
01:15:49,765 --> 01:15:52,885
Speaker 3:  because I signed this agreement that I didn't read. And the second I'm made

1351
01:15:52,895 --> 01:15:56,765
Speaker 3:  aware that I that by saying abracadabra,

1352
01:15:57,155 --> 01:16:00,405
Speaker 3:  this is like go back in my favor, I will just happily start yelling

1353
01:16:00,635 --> 01:16:04,485
Speaker 3:  abracadabra as loudly as I can. Like that is, that's the

1354
01:16:04,485 --> 01:16:04,685
Speaker 3:  problem.

1355
01:16:05,235 --> 01:16:08,765
Speaker 7:  Yeah. But that's also just like no one reads EULAs and that's that's

1356
01:16:08,945 --> 01:16:12,925
Speaker 3:  But like, so who should read the EULA for you? Should we all hire and you

1357
01:16:12,925 --> 01:16:16,085
Speaker 3:  can't do ai? And then, and then what are you, do you, do you have bargaining

1358
01:16:16,085 --> 01:16:19,485
Speaker 3:  power If you disagree with the terms? No. If the uses

1359
01:16:20,315 --> 01:16:24,285
Speaker 3:  it's terms of service and ships it to you, are you like, you know, Tim,

1360
01:16:24,995 --> 01:16:27,445
Speaker 3:  paragraph five, a couple of notes. Are you

1361
01:16:27,445 --> 01:16:29,405
Speaker 7:  Saying that social media needs to unionize?

1362
01:16:30,125 --> 01:16:33,205
Speaker 3:  I am saying terms of service agreements should be illegal like flatly

1363
01:16:33,915 --> 01:16:36,885
Speaker 3:  because there are con Kristen Bell for president, they are contracts. No

1364
01:16:36,885 --> 01:16:40,805
Speaker 3:  one reads and it's these moments. I I just have a lot of empathy.

1365
01:16:41,045 --> 01:16:44,445
Speaker 3:  I have written the, don't believe the Instagram

1366
01:16:44,955 --> 01:16:48,805
Speaker 3:  meme story five times in my career. Yeah. And one time I got a call

1367
01:16:48,805 --> 01:16:52,125
Speaker 3:  from Instagram, they're like, thank you so much. And I was like, I I don't

1368
01:16:52,125 --> 01:16:56,085
Speaker 3:  like this because it happens over and over again for a

1369
01:16:56,085 --> 01:16:59,845
Speaker 3:  reason, which is whenever you offer somebody back the

1370
01:16:59,845 --> 01:17:03,525
Speaker 3:  mechanism of control over their own information, they're like, yeah, I'd

1371
01:17:03,525 --> 01:17:07,005
Speaker 3:  like that back please. Yeah. It universally, yep. And

1372
01:17:07,665 --> 01:17:10,130
Speaker 3:  no one reads the agreements. The the agreements change all the time. The

1373
01:17:10,130 --> 01:17:12,925
Speaker 3:  agreements always change in, in favor of the platform using your data for

1374
01:17:12,925 --> 01:17:16,805
Speaker 3:  more and more and more things. And then you get Zuckerberg saying, everyone

1375
01:17:16,805 --> 01:17:20,285
Speaker 3:  overestimates the value of their individual data. And it's like, who, how,

1376
01:17:20,285 --> 01:17:23,885
Speaker 3:  what is the mechanism that you would ba rebalance this equation with?

1377
01:17:24,335 --> 01:17:25,165
Speaker 3:  There isn't one.

1378
01:17:25,415 --> 01:17:28,645
Speaker 7:  There isn't one. And I think Zuckerberg's also thinking, yeah, guess what?

1379
01:17:28,645 --> 01:17:30,405
Speaker 7:  You're using Instagram and you're gonna keep using

1380
01:17:30,405 --> 01:17:33,005
Speaker 5:  Instagram. Well he's not incentivized to say actually yeah we

1381
01:17:33,005 --> 01:17:34,205
Speaker 3:  Should deliver more value to you.

1382
01:17:34,395 --> 01:17:37,725
Speaker 5:  Yeah. Like he doesn't care. He's like, yeah, give me all of your data for

1383
01:17:37,725 --> 01:17:41,565
Speaker 5:  free. So I can make lots of money and afford my cool shirts. Like of course

1384
01:17:41,585 --> 01:17:42,325
Speaker 5:  he is. Look,

1385
01:17:42,345 --> 01:17:45,485
Speaker 3:  I'm not saying we all shouldn't dunk on a bunch of people posting advocate

1386
01:17:45,485 --> 01:17:49,445
Speaker 3:  AB to Instagram. Like we absolutely should. We should abs It

1387
01:17:49,445 --> 01:17:53,365
Speaker 3:  is one of the funniest repeat memes that can possibly exist

1388
01:17:53,905 --> 01:17:57,765
Speaker 3:  is people basically doing sovereign citizen on Instagram. Like very

1389
01:17:57,765 --> 01:18:01,725
Speaker 3:  funny. But If, you just, I'm just tr one step back from a place of empathy.

1390
01:18:02,195 --> 01:18:05,445
Speaker 3:  It's a bunch of people communicating that they don't like the terms of the

1391
01:18:05,445 --> 01:18:09,005
Speaker 3:  agreement and there's no mechanism to channel that into any change.

1392
01:18:09,155 --> 01:18:10,325
Speaker 3:  That agreement is not changing.

1393
01:18:10,805 --> 01:18:14,365
Speaker 7:  I fully agree with you and I, that's how I frame it to him. I'm like, do

1394
01:18:14,365 --> 01:18:18,125
Speaker 7:  you sympathize with this icky feeling people have about this trade off and

1395
01:18:18,125 --> 01:18:22,045
Speaker 7:  the sense that value is not flowing back to them? And he said the thing about

1396
01:18:22,065 --> 01:18:23,525
Speaker 7:  how everyone overvalues their data.

1397
01:18:25,635 --> 01:18:25,925
Speaker 3:  Well

1398
01:18:26,035 --> 01:18:29,965
Speaker 7:  There's also a sense of yeah, If, you feel this way, stop using the product.

1399
01:18:30,225 --> 01:18:34,125
Speaker 7:  We were doing this about ad targeting and our data being used for

1400
01:18:34,125 --> 01:18:37,765
Speaker 7:  ad targeting 15 years ago and copy paste messages on

1401
01:18:37,965 --> 01:18:41,885
Speaker 7:  Facebook. Everyone's still using, well not everyone, 3 billion people

1402
01:18:42,165 --> 01:18:46,085
Speaker 7:  apparently are still on Facebook. So for them it's

1403
01:18:46,085 --> 01:18:49,965
Speaker 7:  like the platforms, they don't see any data

1404
01:18:50,105 --> 01:18:54,045
Speaker 7:  to suggest that this value exchange is actually unfair because in their mind

1405
01:18:54,045 --> 01:18:55,645
Speaker 7:  we would stop using the services. Yeah.

1406
01:18:55,675 --> 01:18:55,965
Speaker 3:  Yeah.

1407
01:18:56,065 --> 01:18:59,525
Speaker 5:  And that just presumes that people have that power and and what do you mean

1408
01:18:59,625 --> 01:19:00,005
Speaker 5:  can afford

1409
01:19:00,005 --> 01:19:01,125
Speaker 7:  To do that? You can delete Instagram.

1410
01:19:01,515 --> 01:19:04,525
Speaker 5:  Yeah. I would say these things are businesses for a lot of people, right?

1411
01:19:04,525 --> 01:19:07,325
Speaker 5:  Like this is a way they advertise their businesses. Sure. This is a way they,

1412
01:19:07,515 --> 01:19:11,005
Speaker 5:  they advertise themselves if, if they're influencers. Like,

1413
01:19:11,105 --> 01:19:14,805
Speaker 7:  But like most people in the vers newsroom are no longer posting on X.

1414
01:19:14,875 --> 01:19:16,965
Speaker 7:  Like people can make decisions about that. People can

1415
01:19:17,185 --> 01:19:18,125
Speaker 5:  On people. And I think even when

1416
01:19:18,125 --> 01:19:19,285
Speaker 7:  They have career implications,

1417
01:19:19,605 --> 01:19:22,525
Speaker 5:  I think there's also a lot of journalists who are still on XI mean, I think

1418
01:19:22,815 --> 01:19:26,445
Speaker 5:  there is a power imbalance there that, that neli is speaking to of like,

1419
01:19:26,535 --> 01:19:30,485
Speaker 5:  these people have no power in this relationship. It is gone. It is If.

1420
01:19:30,485 --> 01:19:34,405
Speaker 5:  you wanna use this, suck it up. And I think people slowly get tired of that,

1421
01:19:35,055 --> 01:19:38,765
Speaker 3:  Right? I think, I think it's just that there are very few other

1422
01:19:38,765 --> 01:19:42,525
Speaker 3:  relationships you have If you are a creator and creators

1423
01:19:42,585 --> 01:19:45,325
Speaker 3:  are mostly just business people at this point. Yeah. They're all running

1424
01:19:45,325 --> 01:19:48,845
Speaker 3:  content businesses on the terms of the platforms. If you're a celebrity,

1425
01:19:49,145 --> 01:19:52,365
Speaker 3:  you're just a content business on the platform. Which is why I think the

1426
01:19:52,365 --> 01:19:56,165
Speaker 3:  celebrities are so fast to be like, don't use my stuff. Like they know they

1427
01:19:56,325 --> 01:19:59,685
Speaker 3:  do not want their voice and likeness to use without payment. And I'm just,

1428
01:19:59,905 --> 01:20:03,525
Speaker 3:  all I'm saying is from a place of empathy, one step back, there's no

1429
01:20:03,525 --> 01:20:07,445
Speaker 3:  mechanism to channel this frustration into anything. And

1430
01:20:07,445 --> 01:20:10,605
Speaker 3:  that is actually like, again, it's, I I I don't think you have to be very

1431
01:20:10,605 --> 01:20:14,045
Speaker 3:  political on either side of the spectrum to be like, oh this is actually

1432
01:20:14,045 --> 01:20:17,965
Speaker 3:  the thing we should, this is what it's for. Right? Like a lot of people,

1433
01:20:18,035 --> 01:20:20,965
Speaker 3:  like most people on the society would like to renegotiate the terms of their

1434
01:20:20,965 --> 01:20:24,885
Speaker 3:  agreement with the large platforms that is called the privacy law,

1435
01:20:25,905 --> 01:20:29,175
Speaker 3:  right? Where we're just gonna reset the floor of the agreement. A lot of

1436
01:20:29,175 --> 01:20:32,135
Speaker 3:  people wanna reset the terms of how train, how their content can be used

1437
01:20:32,135 --> 01:20:36,055
Speaker 3:  for training. That's just a AI training law like

1438
01:20:36,055 --> 01:20:39,975
Speaker 3:  that it's just very simple and like, I don't know what those laws should

1439
01:20:39,975 --> 01:20:43,655
Speaker 3:  do or how they should read or whether you are a

1440
01:20:43,975 --> 01:20:47,965
Speaker 3:  conservative and you think the answer is like, I don't know, some

1441
01:20:47,965 --> 01:20:51,605
Speaker 3:  weird public private partnership that the Heritage Foundation runs. Like

1442
01:20:51,605 --> 01:20:54,805
Speaker 3:  tho those are those ideas. Or you're a hardcore liberal and you're like,

1443
01:20:54,845 --> 01:20:58,315
Speaker 3:  I will start a government commission and we will, the government will set

1444
01:20:58,315 --> 01:21:01,475
Speaker 3:  the rates, which is what we do in copyright law. Like there's a million solutions

1445
01:21:01,475 --> 01:21:04,755
Speaker 3:  to this. I don't think that's a very liberal solution. Copper, I'm just saying

1446
01:21:04,755 --> 01:21:07,635
Speaker 3:  there are government entities that set rates in other parts of this world.

1447
01:21:09,015 --> 01:21:12,795
Speaker 3:  But it's just, I would just point like we're talking about AI and

1448
01:21:12,995 --> 01:21:16,195
Speaker 3:  distributing it and who has the power, where the models run and how powerful

1449
01:21:16,855 --> 01:21:20,355
Speaker 3:  the, the experiences can be that you had Alex and

1450
01:21:20,355 --> 01:21:24,155
Speaker 3:  underneath it all is like, Hey, did do all of these people

1451
01:21:24,155 --> 01:21:27,835
Speaker 3:  feel ripped off? Like is that, is that okay? And like

1452
01:21:28,115 --> 01:21:31,515
Speaker 3:  Zuckerberg's answer is Zuckerberg's answer. I asked Sundar Phai this about

1453
01:21:31,515 --> 01:21:34,515
Speaker 3:  YouTube I in the same kind of framework of a question, how do you feel about

1454
01:21:34,665 --> 01:21:38,075
Speaker 3:  open AI training on YouTube? And he was like, I think that would be inappropriate.

1455
01:21:38,095 --> 01:21:41,715
Speaker 3:  And it's like, do you understand why all of your creators think that's

1456
01:21:41,715 --> 01:21:45,355
Speaker 3:  inappropriate? And he just like sided me and I, I suspect something

1457
01:21:45,545 --> 01:21:49,475
Speaker 3:  else is gonna happen there. Like some set of lawsuits

1458
01:21:49,475 --> 01:21:52,835
Speaker 3:  or some Scarlet Johansson open AI situation

1459
01:21:53,405 --> 01:21:57,395
Speaker 3:  where it just becomes less and less tenable to be this this

1460
01:21:57,495 --> 01:21:59,115
Speaker 3:  Blythe about it. I we,

1461
01:21:59,315 --> 01:22:01,515
Speaker 6:  We should get off this point 'cause we could do this for hours and we'll

1462
01:22:01,515 --> 01:22:03,635
Speaker 6:  end up talking about the Fedi verse and it'll be a whole thing. Oh my God,

1463
01:22:04,205 --> 01:22:05,235
Speaker 3:  Let's do it. But

1464
01:22:05,235 --> 01:22:09,155
Speaker 6:  The thing is no one has any reason to believe that

1465
01:22:09,155 --> 01:22:12,475
Speaker 6:  any of what you just said is true. And what's actually happening is everybody

1466
01:22:12,535 --> 01:22:15,435
Speaker 6:  is now saying the quiet part out loud. Eric Schmidt is out here being like,

1467
01:22:15,435 --> 01:22:18,755
Speaker 6:  oh you want data from the internet? Just steal it. Mustafa Suleman was like,

1468
01:22:18,755 --> 01:22:21,315
Speaker 6:  oh it's all free. It's on the internet. You can just have it. Like this is

1469
01:22:21,315 --> 01:22:24,635
Speaker 6:  what everybody thinks and there has been absolutely nothing

1470
01:22:25,095 --> 01:22:28,795
Speaker 6:  to convince them otherwise so far. So if I'm Mark Zuckerberg, why I'm gonna

1471
01:22:28,795 --> 01:22:31,755
Speaker 6:  look around and be like, oh I'm gonna be the good guy here and it's gonna

1472
01:22:31,755 --> 01:22:35,595
Speaker 6:  cost me in this race to AI that is suddenly the only thing anyone

1473
01:22:35,595 --> 01:22:38,195
Speaker 6:  cares about. Like no, of course he's not gonna do that. Right? He's gonna

1474
01:22:38,195 --> 01:22:39,995
Speaker 6:  say, oh you like Instagram, keep using Instagram.

1475
01:22:40,175 --> 01:22:43,315
Speaker 3:  We, we can do this for another hour. But also his new attitude, which is

1476
01:22:43,315 --> 01:22:46,035
Speaker 3:  like, I no longer apologize for everything. Apologizing was a 20 year mistake

1477
01:22:46,035 --> 01:22:46,955
Speaker 3:  that I'm not gonna make anymore.

1478
01:22:49,975 --> 01:22:50,195
Speaker 11:  No

1479
01:22:50,705 --> 01:22:54,435
Speaker 3:  Dude, you grow the hair out, you get a little older, you know, like I'm thinking

1480
01:22:54,435 --> 01:22:57,355
Speaker 3:  about growing my hair out. I watched that interview, I was like, oh I could,

1481
01:22:57,435 --> 01:23:00,075
Speaker 3:  I could get the, is it the cauliflower hair? Is that what they call it? Look

1482
01:23:00,075 --> 01:23:03,795
Speaker 3:  when every, every 12-year-old and boy is gifted a gold chain and you have

1483
01:23:03,795 --> 01:23:07,085
Speaker 3:  to make a decision. And I made one decision and I'm saying I could remake

1484
01:23:07,085 --> 01:23:08,205
Speaker 3:  that decision. You could.

1485
01:23:08,785 --> 01:23:12,525
Speaker 7:  The hair is getting long. You could, yeah. I feel like you're like you're

1486
01:23:12,525 --> 01:23:13,725
Speaker 7:  a few months away from curls.

1487
01:23:14,025 --> 01:23:17,565
Speaker 3:  Oh this hair is very curly. I could tomorrow we're not talking about this

1488
01:23:17,565 --> 01:23:21,125
Speaker 3:  right now. We are changing the subject. Mila's hair is so French and we need

1489
01:23:21,125 --> 01:23:24,325
Speaker 3:  to go to a break. Yeah, yeah. Can we just before we go to break, I do wanna

1490
01:23:24,325 --> 01:23:28,125
Speaker 3:  talk about OpenAI. Oh yeah it it God seems

1491
01:23:28,125 --> 01:23:29,845
Speaker 3:  like chaos over there. What is going on over there? Alex,

1492
01:23:30,465 --> 01:23:32,165
Speaker 7:  Did you guys know that OpenAI is a nonprofit?

1493
01:23:34,065 --> 01:23:34,725
Speaker 3:  Do they know that?

1494
01:23:35,545 --> 01:23:39,445
Speaker 7:  I'm not sure they do. I think they're finding out and that's what's going

1495
01:23:39,545 --> 01:23:41,885
Speaker 7:  on honestly like at a very high level.

1496
01:23:42,025 --> 01:23:45,685
Speaker 3:  But everyone's leaving like Mira Dy, the CTO is leaving Greg

1497
01:23:45,685 --> 01:23:48,845
Speaker 3:  Brockman, the president just apparently just vanished.

1498
01:23:49,315 --> 01:23:52,925
Speaker 7:  Yeah, there's this great photo of all of the like execs,

1499
01:23:53,205 --> 01:23:56,805
Speaker 7:  Aliyah, Greg, Mira and Sam together for this big New York Times

1500
01:23:56,805 --> 01:24:00,685
Speaker 7:  profile. This was like right before the boardroom boardroom coup, which Neli

1501
01:24:00,865 --> 01:24:04,285
Speaker 7:  was almost a year ago when you were at Disney. No way. Yeah.

1502
01:24:04,535 --> 01:24:08,325
Speaker 7:  Isn't that crazy? You were at Disney not getting to ride the rides

1503
01:24:08,385 --> 01:24:11,765
Speaker 7:  almost a year ago. 'cause we were reporting on this, which is yeah nuts to

1504
01:24:11,765 --> 01:24:14,885
Speaker 7:  me. But there's this photo of him and all these execs and now they've just

1505
01:24:14,885 --> 01:24:18,685
Speaker 7:  photoshopped out everyone except Sam Altman who's the only one left. And

1506
01:24:19,665 --> 01:24:23,165
Speaker 7:  what's happening is that OpenAI just raised the largest round of funding

1507
01:24:23,165 --> 01:24:27,045
Speaker 7:  of all time. I think they just went above Elon's mega round for Xai

1508
01:24:27,095 --> 01:24:30,965
Speaker 7:  which was I think 6 billion on purpose. Of course optics,

1509
01:24:31,915 --> 01:24:35,525
Speaker 7:  they're valued at $150 billion, which is more than the market cap of Goldman

1510
01:24:35,645 --> 01:24:39,365
Speaker 7:  Sachs. Guess what? OpenAI is legally still a nonprofit.

1511
01:24:40,035 --> 01:24:43,935
Speaker 7:  They get tax breaks in the state of

1512
01:24:43,935 --> 01:24:47,855
Speaker 7:  California as a nonprofit. They make billions of dollars

1513
01:24:48,015 --> 01:24:51,535
Speaker 7:  a year. And so what's happening is this very chaotic fast

1514
01:24:51,535 --> 01:24:53,935
Speaker 7:  transition from what was a

1515
01:24:55,615 --> 01:24:59,495
Speaker 7:  research lab. We're gonna invent a GI all the IUs stuff

1516
01:24:59,755 --> 01:25:03,135
Speaker 7:  to in the last year when Sam won the board coup,

1517
01:25:03,555 --> 01:25:06,455
Speaker 7:  no we are a large commercial for-profit

1518
01:25:07,725 --> 01:25:11,295
Speaker 7:  next big mega tech company and they hired A CFO,

1519
01:25:11,725 --> 01:25:15,615
Speaker 7:  they hired a CPO who used to run product at Instagram, not the

1520
01:25:15,735 --> 01:25:18,895
Speaker 7:  other one who used to run product at Instagram. He's philanthropic and

1521
01:25:19,325 --> 01:25:23,215
Speaker 7:  they're very chaotically turning into a real big company.

1522
01:25:23,875 --> 01:25:27,455
Speaker 7:  And I think what you're seeing is a lot of the previous era

1523
01:25:27,625 --> 01:25:31,335
Speaker 7:  being abruptly managed out quitting

1524
01:25:31,885 --> 01:25:35,855
Speaker 7:  what have you and it's the Altman show and he

1525
01:25:36,055 --> 01:25:39,895
Speaker 7:  famously does not have equity in OpenAI has been doing a ton

1526
01:25:39,895 --> 01:25:43,375
Speaker 7:  of interesting dealings with other startups and investments

1527
01:25:43,875 --> 01:25:47,815
Speaker 7:  around OpenAI. It is now reportedly gonna be getting a large stake

1528
01:25:47,955 --> 01:25:51,855
Speaker 7:  in this new for-profit company that they're creating. I

1529
01:25:51,855 --> 01:25:55,815
Speaker 7:  will love to see how, what the tax implications are of this transition

1530
01:25:56,245 --> 01:25:59,855
Speaker 7:  more to come on that. And the state of California really

1531
01:25:59,855 --> 01:26:03,605
Speaker 7:  doesn't like when nonprofits become for-profits. It's a very, very

1532
01:26:03,605 --> 01:26:07,565
Speaker 7:  contested thing and yeah, I think that's what's happening

1533
01:26:07,565 --> 01:26:11,285
Speaker 7:  at high level. So Mira, the CTO is out who was

1534
01:26:11,335 --> 01:26:14,885
Speaker 7:  MeMed with her reaction to, did you use YouTube to train Sora? Yeah,

1535
01:26:15,075 --> 01:26:16,965
Speaker 3:  They were very unhappy about that from what I understand.

1536
01:26:17,225 --> 01:26:20,325
Speaker 7:  And then they're head of research who literally just did an interview about

1537
01:26:20,325 --> 01:26:23,085
Speaker 7:  the new reasoning model with Kylie a couple weeks ago

1538
01:26:24,545 --> 01:26:28,485
Speaker 7:  who won out against Ilya in the research kind of group battle a

1539
01:26:28,485 --> 01:26:32,285
Speaker 7:  year ago. So yeah, it's just like stuff's happening very fast and yeah big

1540
01:26:32,285 --> 01:26:36,205
Speaker 7:  picture. This is open AI entering a decidedly commercial

1541
01:26:37,505 --> 01:26:39,965
Speaker 7:  big tech company phase. They are speed running.

1542
01:26:40,005 --> 01:26:43,205
Speaker 5:  Should that be terrifying for us given that they were supposed to be the

1543
01:26:43,405 --> 01:26:44,245
Speaker 5:  safeguards of ai?

1544
01:26:44,435 --> 01:26:48,005
Speaker 7:  Well yeah, now Eli is doing, Ilia is doing super safe

1545
01:26:48,325 --> 01:26:49,925
Speaker 7:  whatever ai, so it's gonna be super safe.

1546
01:26:49,925 --> 01:26:51,485
Speaker 5:  But you didn't have the money raised

1547
01:26:51,485 --> 01:26:53,005
Speaker 3:  Billion. He raised a bunch of money. Yeah

1548
01:26:53,005 --> 01:26:55,005
Speaker 7:  He raised a bunch of money but not

1549
01:26:55,005 --> 01:26:56,365
Speaker 3:  As much. No, not as, yeah

1550
01:26:56,625 --> 01:26:57,405
Speaker 7:  Not as much. But

1551
01:28:59,665 --> 01:29:01,925
Speaker 3:  All right, we're back. We are so over.

1552
01:29:03,615 --> 01:29:06,555
Speaker 3:  We are often asked how long the show is supposed to be and the answer is

1553
01:29:06,555 --> 01:29:09,995
Speaker 3:  not this long. Six and a half minutes but we're never gonna tell you how

1554
01:29:09,995 --> 01:29:10,555
Speaker 3:  long it's supposed

1555
01:29:10,555 --> 01:29:11,915
Speaker 5:  To be. Actually a 92nd show.

1556
01:29:12,565 --> 01:29:15,395
Speaker 3:  We've gotten some incoming lightning around sponsorships. Again, I don't

1557
01:29:15,395 --> 01:29:18,755
Speaker 3:  make the deals, I just walk around Vox Media demanding why the deals aren't

1558
01:29:18,755 --> 01:29:22,555
Speaker 3:  made, which has proven to be ineffective. So

1559
01:29:22,575 --> 01:29:26,355
Speaker 3:  I'm gonna try some new strategies. But today we remain unsponsored,

1560
01:29:27,455 --> 01:29:31,365
Speaker 3:  which is a personal failure. I, for somebody who complains

1561
01:29:31,365 --> 01:29:35,045
Speaker 3:  about creator like influence and brand deals as much as I do, I'm horrible

1562
01:29:35,045 --> 01:29:37,845
Speaker 3:  at this. I should makes that money anyway. The lightning round is available

1563
01:29:37,845 --> 01:29:41,805
Speaker 3:  to sponsor I I might say your company's name, If. you give us a bunch

1564
01:29:41,805 --> 01:29:45,485
Speaker 3:  of money or I might not because of ethics policy you won't know until you

1565
01:29:45,485 --> 01:29:48,765
Speaker 3:  pay me money. That's lightning round. All right Alex, let's start with you

1566
01:29:48,885 --> 01:29:51,405
Speaker 3:  'cause I think you've, you've got the most relevant lightning round item

1567
01:29:51,415 --> 01:29:52,805
Speaker 3:  after that previous conversation.

1568
01:29:52,995 --> 01:29:56,765
Speaker 7:  Yeah. Trip Mickel, the New York Times has this great story about what

1569
01:29:56,765 --> 01:30:00,685
Speaker 7:  Johnny Ive has been up to post Apple and this design firm he founded

1570
01:30:00,685 --> 01:30:04,245
Speaker 7:  called Love from lots of nuggets in here. I thought it was very

1571
01:30:04,605 --> 01:30:08,005
Speaker 7:  interesting that he says in the story he interviewed I in June

1572
01:30:08,665 --> 01:30:11,285
Speaker 7:  and this came out the week of iPhone 16.

1573
01:30:12,505 --> 01:30:13,605
Speaker 7:  The timing was interesting

1574
01:30:15,505 --> 01:30:19,285
Speaker 7:  but yeah, Johnny's, he's working, I think the Time's kind of buried the lead

1575
01:30:19,285 --> 01:30:20,525
Speaker 7:  here. He's

1576
01:30:20,555 --> 01:30:23,765
Speaker 3:  Literally, it's like the last paragraph of the story. Yeah, it's very, very

1577
01:30:23,765 --> 01:30:23,925
Speaker 3:  end.

1578
01:30:24,345 --> 01:30:28,085
Speaker 7:  He confirms that he's working on some kind of AI device with open ai. It

1579
01:30:28,085 --> 01:30:31,965
Speaker 7:  sounds like they haven't quite nailed down what it will be. It was the first

1580
01:30:31,965 --> 01:30:35,765
Speaker 7:  time he confirmed it on the record. My understanding is that love from

1581
01:30:35,765 --> 01:30:39,725
Speaker 7:  is super small. It's like 40 ish, 50 people and there's

1582
01:30:39,725 --> 01:30:39,885
Speaker 7:  only

1583
01:30:39,885 --> 01:30:41,805
Speaker 5:  10 people working on this project I

1584
01:30:41,805 --> 01:30:45,685
Speaker 7:  Think. Yeah. And a wild detail in this story is is

1585
01:30:45,705 --> 01:30:49,125
Speaker 7:  as Mr Ive climbed a wooden staircase to the studio second floor that morning.

1586
01:30:49,125 --> 01:30:52,685
Speaker 7:  And by the way he bought like a whole block, a city block of downtown San

1587
01:30:52,685 --> 01:30:53,845
Speaker 7:  Francisco for their office.

1588
01:30:55,745 --> 01:30:59,605
Speaker 7:  He said he spoke about love firm's clients love firm's clients which

1589
01:30:59,665 --> 01:31:03,645
Speaker 7:  pay the firm as much as $200 million annually. That's very

1590
01:31:03,645 --> 01:31:07,165
Speaker 7:  good. And that includes like Airbnb, Ferrari, he just designed a

1591
01:31:07,165 --> 01:31:11,085
Speaker 7:  $3,000 Ja jacket with Montclair Love firm is like

1592
01:31:11,335 --> 01:31:14,645
Speaker 7:  50 people. So how much money are they making

1593
01:31:14,925 --> 01:31:15,525
Speaker 3:  Johnny? Ive

1594
01:31:16,145 --> 01:31:18,605
Speaker 5:  Bought a whole block in San Francisco. Like they're doing good.

1595
01:31:18,695 --> 01:31:22,565
Speaker 7:  Brian Chesky is paying him $200 million a year to

1596
01:31:22,565 --> 01:31:24,965
Speaker 7:  like riff on what the Airbnb logo should

1597
01:31:24,965 --> 01:31:28,485
Speaker 3:  Be. Can I, can I just tell you a story about the Airbnb Johnny Ive connection?

1598
01:31:28,675 --> 01:31:32,245
Speaker 3:  Yeah. Which, because I was reading this and it says what he worked on, like

1599
01:31:32,245 --> 01:31:35,765
Speaker 3:  they did the experiences where you can like live in a pineapple house or

1600
01:31:35,765 --> 01:31:39,485
Speaker 3:  something. What whatever 200 million nonsense is happening. Right.

1601
01:31:40,865 --> 01:31:44,845
Speaker 3:  Airbnb last year, the year before after the

1602
01:31:44,845 --> 01:31:45,765
Speaker 3:  Johnny Ive stuff was out

1603
01:31:47,595 --> 01:31:50,445
Speaker 3:  like announced a bunch of redesign stuff and like an app redesign and all

1604
01:31:50,445 --> 01:31:53,805
Speaker 3:  this stuff and we emailed them and we're like, was this the stuff Johnny

1605
01:31:53,875 --> 01:31:57,045
Speaker 3:  I've worked on? Because obviously that is very relevant and interesting detail

1606
01:31:57,045 --> 01:32:00,165
Speaker 3:  and they're like yeah, yeah. And then we like publish and they like freaked

1607
01:32:00,225 --> 01:32:03,645
Speaker 3:  out at us and they're like, that's not wrong. Everyone's like take it down.

1608
01:32:03,645 --> 01:32:06,805
Speaker 3:  We're like, but you said okay and we like adjusted the story. You can like

1609
01:32:06,805 --> 01:32:09,845
Speaker 3:  read it. There's all these like back and forth corrections in it because

1610
01:32:10,005 --> 01:32:13,845
Speaker 3:  Airbnb's trying to clarify this and I was like, what is the point of Jo spending

1611
01:32:13,845 --> 01:32:16,565
Speaker 3:  all this money and Johnny I If you don't want say that he worked on this

1612
01:32:16,565 --> 01:32:16,765
Speaker 3:  stuff.

1613
01:32:17,315 --> 01:32:20,725
Speaker 6:  Yeah. That's worth easily a hundred of the 200 million is just to be able

1614
01:32:20,725 --> 01:32:22,325
Speaker 6:  to put Johnny Ive in your press release,

1615
01:32:22,575 --> 01:32:26,335
Speaker 3:  Check out the new Airbnb app designed by Johnny Ive, I

1616
01:32:26,335 --> 01:32:29,535
Speaker 3:  dunno, Brian Chassis's coming on decoder in a little bit. I'm gonna ask you

1617
01:32:29,535 --> 01:32:32,415
Speaker 3:  about it in addition to talking about founder mode, which he's excited to

1618
01:32:32,415 --> 01:32:35,615
Speaker 3:  talk about but it's, I read this profile and I was like,

1619
01:32:36,485 --> 01:32:40,375
Speaker 3:  yeah we tried to write the story about him designing this

1620
01:32:40,375 --> 01:32:43,375
Speaker 3:  app and they were like not into it. They were like pushed back on this idea

1621
01:32:43,375 --> 01:32:44,655
Speaker 3:  that he had done it super

1622
01:32:44,685 --> 01:32:47,575
Speaker 7:  Hard. He's like the Wizard of Oz, he just needs to be in the background.

1623
01:32:47,645 --> 01:32:48,375
Speaker 7:  There's also a

1624
01:32:48,375 --> 01:32:51,855
Speaker 3:  Part did he, he, there's a part in the story that I loved where he designed

1625
01:32:51,935 --> 01:32:55,575
Speaker 3:  a steering wheel for like an EV Ferrari and he's like, he completely rethought

1626
01:32:55,575 --> 01:32:57,295
Speaker 3:  what a steering wheel should be. I'm like, it's a circle.

1627
01:32:58,795 --> 01:32:59,815
Speaker 7:  Oh he didn't do a yoke.

1628
01:33:01,925 --> 01:33:05,495
Speaker 3:  It's, it's definitely a circle. I've famously a car guy.

1629
01:33:05,735 --> 01:33:06,215
Speaker 3:  It's very good.

1630
01:33:06,405 --> 01:33:10,175
Speaker 7:  Yeah, So I. Just think it's like Ive is clearly gearing up and I think

1631
01:33:10,175 --> 01:33:14,055
Speaker 7:  there's a lot of pressure on him if this AI device is gonna be

1632
01:33:14,255 --> 01:33:18,215
Speaker 7:  real, like that is a, that is your Johnny Ive like, this thing has to work.

1633
01:33:18,315 --> 01:33:22,255
Speaker 7:  It has to not be the humane pin. And he's, he's got Evans hanky who

1634
01:33:22,405 --> 01:33:26,295
Speaker 7:  succeeded him at Apple leading design at love from working on this device

1635
01:33:26,295 --> 01:33:30,095
Speaker 7:  with him. So it's, it's a bunch of OG apple people that invented all of

1636
01:33:30,095 --> 01:33:34,055
Speaker 7:  like the original Apple stuff with him. So that's a really

1637
01:33:34,535 --> 01:33:35,695
Speaker 7:  interesting situation to watch.

1638
01:33:35,905 --> 01:33:39,695
Speaker 6:  We've seen one company with a very similar description to that make

1639
01:33:39,795 --> 01:33:43,575
Speaker 6:  AI hardware and it didn't go super great so we'll we'll see.

1640
01:33:43,885 --> 01:33:44,175
Speaker 6:  Gosh.

1641
01:33:44,525 --> 01:33:47,895
Speaker 3:  Yeah. You know like he doesn't have, for example, Apple's famed antenna team,

1642
01:33:48,025 --> 01:33:51,495
Speaker 3:  which once had to save his ass from his own designs

1643
01:33:52,575 --> 01:33:52,975
Speaker 3:  wireless product.

1644
01:33:53,185 --> 01:33:56,255
Speaker 6:  It'll be super thin. Whatever it is, you can, you can bet it will be thin

1645
01:33:56,355 --> 01:33:58,055
Speaker 3:  25 minutes of battery life.

1646
01:33:59,405 --> 01:33:59,695
Speaker 5:  Five.

1647
01:34:00,075 --> 01:34:02,975
Speaker 3:  I'm very curious. I mean he, after we just had this whole conversation about

1648
01:34:02,975 --> 01:34:06,815
Speaker 3:  Meta, they have all of the same pro, like Apple is not gonna give him hooks

1649
01:34:06,815 --> 01:34:07,415
Speaker 3:  into iOS

1650
01:34:09,075 --> 01:34:13,065
Speaker 3:  presumably. Or the reason that chat BT got announced

1651
01:34:13,065 --> 01:34:16,145
Speaker 3:  as integrated iOS A 18 is when this device comes out. Tim Cook can be like,

1652
01:34:17,065 --> 01:34:17,755
Speaker 3:  it's mine now.

1653
01:34:18,235 --> 01:34:21,995
Speaker 7:  I just have a feeling whatever it is, it's gonna be so deeply, deeply weird

1654
01:34:22,345 --> 01:34:25,635
Speaker 7:  that it's gonna be awesome. Like I have the longer, he's away from Apple,

1655
01:34:25,635 --> 01:34:29,275
Speaker 7:  he just is doing weirder and weirder stuff and so

1656
01:34:29,665 --> 01:34:32,715
Speaker 7:  some kind of AI device from him is like, yes.

1657
01:34:32,715 --> 01:34:33,315
Speaker 3:  Yeah, I I

1658
01:34:33,315 --> 01:34:35,675
Speaker 6:  Want it. Yeah. I'm excited about it. Yeah, I agree. It's gonna be insane

1659
01:34:35,775 --> 01:34:36,275
Speaker 6:  and I love

1660
01:34:36,275 --> 01:34:39,515
Speaker 5:  It. Altman probably isn't gonna be excited about it 'cause he wants something

1661
01:34:39,515 --> 01:34:41,995
Speaker 5:  that he can sell and make lots of money. What do

1662
01:34:41,995 --> 01:34:43,435
Speaker 7:  You mean he open AI's working with him?

1663
01:34:43,825 --> 01:34:47,475
Speaker 5:  Yeah, I know but like, is that the guy you hire If, you wanna make something

1664
01:34:47,475 --> 01:34:49,875
Speaker 5:  really commercial and sell and make lots of money. I mean

1665
01:34:49,875 --> 01:34:50,555
Speaker 7:  You argue

1666
01:34:50,555 --> 01:34:51,595
Speaker 5:  Have 10 Johnny people on their

1667
01:34:51,595 --> 01:34:53,475
Speaker 7:  Staff already done okay with that. He's done.

1668
01:34:53,475 --> 01:34:54,475
Speaker 5:  Yeah. Yeah, he did

1669
01:34:54,475 --> 01:34:55,795
Speaker 3:  Great. He the iPhone, he made the

1670
01:34:55,795 --> 01:34:56,675
Speaker 7:  IPhone iPod, apple

1671
01:34:56,915 --> 01:34:57,485
Speaker 3:  IPod did decent.

1672
01:34:57,955 --> 01:34:59,405
Speaker 5:  This is a design firm. Decent.

1673
01:34:59,405 --> 01:35:02,005
Speaker 3:  That's true. Yeah. I will say there's a picture of him in that profile where

1674
01:35:02,005 --> 01:35:05,445
Speaker 3:  he's just holding his iPhone in like a regular blue apple rubber case.

1675
01:35:05,865 --> 01:35:09,645
Speaker 3:  And I'm like, that's not weird enough for Shaw. I've and my God. But he made

1676
01:35:09,645 --> 01:35:12,405
Speaker 3:  the iPhone, he puts his feet no gold Apple watch either. Gosh. Yeah.

1677
01:35:12,465 --> 01:35:14,765
Speaker 5:  It was upsetting. He put his feet on the couch. That was the part that got

1678
01:35:14,765 --> 01:35:17,965
Speaker 5:  me like these gorgeous white couches and he had his shoes on them.

1679
01:35:18,925 --> 01:35:19,405
Speaker 5:  I was like, oh

1680
01:35:20,095 --> 01:35:23,365
Speaker 3:  Hurts. He can just get new ones. All right. Yeah. Kranz, what's your lightning

1681
01:35:23,365 --> 01:35:23,685
Speaker 3:  around Adam?

1682
01:35:24,635 --> 01:35:28,605
Speaker 5:  Sean got a hands-on with the PS five pro and If. you like to

1683
01:35:28,605 --> 01:35:32,565
Speaker 5:  pixel peep. It's gonna rule. I do. It's it's apparently

1684
01:35:32,635 --> 01:35:36,525
Speaker 5:  it's, it, it, he, he says it really like lives up to the hype as far as

1685
01:35:36,525 --> 01:35:40,445
Speaker 5:  like things just look a lot clearer. They're a lot prettier. It's

1686
01:35:40,445 --> 01:35:44,345
Speaker 5:  awesome in that way, but also it is still so much

1687
01:35:44,345 --> 01:35:47,985
Speaker 5:  money and, and you can, there's a lot of photos

1688
01:35:48,125 --> 01:35:51,945
Speaker 5:  in his piece where you can go and look and try to see the differences.

1689
01:35:52,325 --> 01:35:56,305
Speaker 5:  and it is sort of like playing highlights as a kid. You can

1690
01:35:56,305 --> 01:36:00,105
Speaker 5:  see them, but you gotta, you gotta look for 'em. So I would say

1691
01:36:00,125 --> 01:36:03,985
Speaker 5:  If, you don't have a giant monitor that you sit like two feet

1692
01:36:03,985 --> 01:36:07,865
Speaker 5:  from, you're probably Okay. But otherwise this is cool.

1693
01:36:08,665 --> 01:36:12,505
Speaker 3:  I will say that I was in the queue to buy the, the PS

1694
01:36:12,505 --> 01:36:15,825
Speaker 3:  five Pro 30th anniversary edition. And then I forgot I was in the q and o,

1695
01:36:15,965 --> 01:36:16,585
Speaker 3:  my place in line.

1696
01:36:16,685 --> 01:36:20,545
Speaker 5:  The the one to really look at is in, and David Ma and me before

1697
01:36:20,925 --> 01:36:24,585
Speaker 5:  we recorded it, 'cause I pointed this out, is the ratchet and clank rift

1698
01:36:24,585 --> 01:36:28,185
Speaker 5:  apart. You can really see the ray tracing working. It's, it's, it's, it's

1699
01:36:28,185 --> 01:36:28,585
Speaker 5:  beautiful.

1700
01:36:28,945 --> 01:36:32,865
Speaker 6:  Thank God. I've always said that's the main thing missing from ratchet

1701
01:36:32,865 --> 01:36:36,385
Speaker 6:  and clank rift apart is is ray tracing. That's the thing.

1702
01:36:36,385 --> 01:36:39,225
Speaker 6:  Preventing me from enjoying ratchet and clink rift apart.

1703
01:36:39,625 --> 01:36:43,385
Speaker 3:  There's a very funny line in Sean's hands on where he, he notes that all

1704
01:36:43,385 --> 01:36:46,385
Speaker 3:  the controllers were wired so they couldn't get far away from the screen

1705
01:36:46,485 --> 01:36:49,825
Speaker 3:  and not see the ray tracing anymore. Yeah. Choice. It's beautiful.

1706
01:36:49,825 --> 01:36:50,305
Speaker 6:  That's pretty good.

1707
01:36:50,305 --> 01:36:51,865
Speaker 3:  Alright, David, what's, what's yours

1708
01:36:52,395 --> 01:36:55,345
Speaker 6:  While you're over here? Neil denigrating Google's headphones.

1709
01:36:56,675 --> 01:37:00,265
Speaker 6:  Chris Welch published our view of the Google Pixel Buds Pro two,

1710
01:37:00,675 --> 01:37:04,665
Speaker 6:  which is a name that I have never said correctly until just now. So I.

1711
01:37:05,045 --> 01:37:06,065
Speaker 5:  I'm very proud of you. They're

1712
01:37:06,065 --> 01:37:09,345
Speaker 6:  Awesome. They're, they're smaller. They sound better, they're a little more

1713
01:37:09,345 --> 01:37:13,305
Speaker 6:  expensive. Seem great. But the thing I just wanna point out is that

1714
01:37:13,305 --> 01:37:17,265
Speaker 6:  Google absolutely crushed this hardware cycle, like in a, in a way

1715
01:37:17,265 --> 01:37:21,065
Speaker 6:  that Google Yeah. Never has before. The, the TV streamer is great. The

1716
01:37:21,065 --> 01:37:23,465
Speaker 6:  buds are great, the watches is great, the phones are great. The foldable

1717
01:37:23,465 --> 01:37:27,025
Speaker 6:  phones are great. Like Google just like did the whole thing this year.

1718
01:37:27,285 --> 01:37:29,865
Speaker 6:  And that is sort of wild to me. Do

1719
01:37:29,865 --> 01:37:32,385
Speaker 3:  You think that's Rick Oslo now runs the whole thing? It's

1720
01:37:32,385 --> 01:37:33,465
Speaker 5:  Dieter, it's all here. It's

1721
01:37:35,805 --> 01:37:36,545
Speaker 6:  No, I think whatever.

1722
01:37:36,805 --> 01:37:38,265
Speaker 3:  And Dan, don't forget Dan. Yeah, it's

1723
01:37:38,265 --> 01:37:39,625
Speaker 5:  Dieter and Dan. They did it. Thank you guys.

1724
01:37:39,945 --> 01:37:43,145
Speaker 6:  I think there's a certain amount of this that is like that compound interest

1725
01:37:43,465 --> 01:37:46,265
Speaker 6:  phenomenon, right? It's just like, Google's been at this a while and like,

1726
01:37:46,325 --> 01:37:50,145
Speaker 6:  Hey Google, if you're listening, this is why it's good to stick

1727
01:37:50,165 --> 01:37:53,825
Speaker 6:  to things because you can make them better over time and then they're good

1728
01:37:53,965 --> 01:37:57,845
Speaker 6:  and people like them. Yeah. Like that's a concept. Try

1729
01:37:57,845 --> 01:38:01,685
Speaker 6:  it with other things. But at any rate, like what Google did

1730
01:38:01,685 --> 01:38:05,485
Speaker 6:  here is not like reinvent the wheel as it is prone to do all the time.

1731
01:38:05,585 --> 01:38:08,445
Speaker 6:  It just made all of its products better. and it did that a bunch of years

1732
01:38:08,445 --> 01:38:11,925
Speaker 6:  in a row. And I think that the thing Rick Oslo gets credit for

1733
01:38:12,745 --> 01:38:16,325
Speaker 6:  is he has, he has made a plan and stuck to it. Like I talked to him years

1734
01:38:16,345 --> 01:38:19,325
Speaker 6:  ago at the very beginning and I was like, why on earth would anyone believe

1735
01:38:19,325 --> 01:38:22,325
Speaker 6:  you that you're gonna care about this for a long time? And he's like, I you

1736
01:38:22,325 --> 01:38:25,805
Speaker 6:  shouldn't, I don't know why you would, but we are going to, like, we're we're,

1737
01:38:25,805 --> 01:38:29,445
Speaker 6:  we're bought into this. And this feels like the first time that Google is

1738
01:38:29,445 --> 01:38:32,925
Speaker 6:  like really, truly playing hardware offense

1739
01:38:33,585 --> 01:38:36,765
Speaker 6:  in like it's, it's up there with everybody. We gave the TV streamer a nine,

1740
01:38:37,095 --> 01:38:40,965
Speaker 6:  Chris gave the Pixel Buds Pro two a nine. Like these are some of the best

1741
01:38:40,965 --> 01:38:44,845
Speaker 6:  products you can buy in their class. And I don't think that has ever been

1742
01:38:44,845 --> 01:38:47,165
Speaker 6:  true of Google products before. Yeah. So. I. Just think that's very cool.

1743
01:38:47,605 --> 01:38:51,405
Speaker 3:  I haven't, I didn't put this in the iPhone review 'cause I, I think

1744
01:38:51,405 --> 01:38:54,405
Speaker 3:  it's unfair to say this until Apple Intelligence comes out and we can use

1745
01:38:54,405 --> 01:38:58,165
Speaker 3:  the features, but I spent a lot of time using a pixel line pro camera

1746
01:38:58,335 --> 01:39:01,325
Speaker 3:  stuff while I was doing that review to compare the cameras. And every time

1747
01:39:01,325 --> 01:39:04,325
Speaker 3:  I picked up a pixel, I was like, this phone is a lot more fun than iOS right

1748
01:39:04,325 --> 01:39:07,765
Speaker 3:  now. Yeah. Yeah. Like it's just like bursting with ideas. The chaotic,

1749
01:39:08,135 --> 01:39:11,405
Speaker 3:  weird clippy level ideas about what every

1750
01:39:11,405 --> 01:39:12,685
Speaker 6:  Time you breathe it's like Gemini.

1751
01:39:12,685 --> 01:39:15,285
Speaker 3:  Yeah. Should be Gemini. Do you want a Gemini? It's, it's, it's, it's, it's,

1752
01:39:15,355 --> 01:39:18,925
Speaker 3:  it's a little nuts, but it's fun because it's just like

1753
01:39:19,215 --> 01:39:22,645
Speaker 3:  ideas, like new ideas for what a phone could do or should do or why it should

1754
01:39:22,645 --> 01:39:26,525
Speaker 3:  do anything at all. And Apple is like, all the icons are

1755
01:39:26,525 --> 01:39:30,275
Speaker 3:  brown. Huh? You've been asking for big

1756
01:39:30,275 --> 01:39:32,815
Speaker 3:  brown icons and now you can have 'em.

1757
01:39:34,085 --> 01:39:36,265
Speaker 3:  Can I just say one more thing about the iPhone and then I'll do my lighting

1758
01:39:36,265 --> 01:39:39,895
Speaker 3:  round item control center. Total

1759
01:39:40,225 --> 01:39:44,215
Speaker 3:  total chaos. Like a mess. And they should just let

1760
01:39:44,215 --> 01:39:45,775
Speaker 3:  me edit it on my Mac.

1761
01:39:47,495 --> 01:39:48,775
Speaker 6:  I feel that way about my home screen.

1762
01:39:49,195 --> 01:39:51,855
Speaker 3:  Let me, yeah, let me do the home screen and control center on my Mac. I know

1763
01:39:51,855 --> 01:39:54,655
Speaker 3:  you can do phone mirror and you click direct. No, no, no. I want like full

1764
01:39:55,325 --> 01:39:58,215
Speaker 3:  like old school Adobe PageMaker print layout,

1765
01:39:59,275 --> 01:40:02,935
Speaker 3:  you know, like all the tools, the mirror, the, the

1766
01:40:02,935 --> 01:40:06,655
Speaker 3:  rulers and just let, just, this is, we're we're past

1767
01:40:06,655 --> 01:40:07,775
Speaker 3:  being able to do this on the phone

1768
01:40:07,775 --> 01:40:10,935
Speaker 6:  Control center is like the, once you get it set up, it's pretty great. But

1769
01:40:10,935 --> 01:40:13,615
Speaker 6:  the thing is like, and I feel the same way about the home screen. Like if

1770
01:40:13,655 --> 01:40:17,495
Speaker 6:  I drag an icon somewhere into a page that is already largely

1771
01:40:17,525 --> 01:40:21,415
Speaker 6:  full of icons, it takes a, it takes a PhD to figure out where

1772
01:40:21,415 --> 01:40:24,575
Speaker 6:  all those icons are gonna go. Yeah. Yeah. Like it is, it is just a mystery

1773
01:40:24,575 --> 01:40:25,255
Speaker 6:  every single time

1774
01:40:25,595 --> 01:40:28,895
Speaker 3:  The fastest, most capable, most efficient processors

1775
01:40:29,045 --> 01:40:32,975
Speaker 3:  humankind has ever created. And it's like, I don't know what's going on with

1776
01:40:32,975 --> 01:40:35,895
Speaker 3:  these icons. Like too much for me man. Yeah. Like,

1777
01:40:37,005 --> 01:40:37,295
Speaker 3:  yeah.

1778
01:40:38,075 --> 01:40:39,415
Speaker 6:  All right Mila, what's yours? We

1779
01:40:39,415 --> 01:40:43,375
Speaker 3:  Have to end here because we've been talking about AI gadgets the

1780
01:40:43,375 --> 01:40:47,135
Speaker 3:  whole time. Only 5,000 people use the Rabbit R

1781
01:40:47,155 --> 01:40:51,095
Speaker 3:  one every day. According to c said, how many people own it? He gave

1782
01:40:51,095 --> 01:40:55,045
Speaker 3:  an interview at some conference and the number is 5,000 daily active users

1783
01:40:55,105 --> 01:40:56,605
Speaker 3:  of the rabbit. That's more than I thought.

1784
01:40:56,915 --> 01:40:59,405
Speaker 6:  Yeah. I was like, I'm surprised that many people have found a good use for

1785
01:40:59,405 --> 01:40:59,685
Speaker 6:  the rabbit.

1786
01:41:00,465 --> 01:41:04,365
Speaker 3:  The other thing to note is If, you, you cannot recycle or resell a humane

1787
01:41:04,505 --> 01:41:06,885
Speaker 3:  AI pin, but you can just return it to the company for full price,

1788
01:41:06,975 --> 01:41:10,605
Speaker 6:  Which kudos good to that. Good for them. Send it back. That is the correct

1789
01:41:10,605 --> 01:41:13,325
Speaker 6:  thing to do. It's just my bad. Wait, I, I am curious. I've spent a lot of

1790
01:41:13,325 --> 01:41:13,645
Speaker 6:  time trying

1791
01:41:13,645 --> 01:41:17,445
Speaker 3:  To, so it's 5% of buyers. Five, 5,000 people is 5% of the rabbit R one buyers.

1792
01:41:17,635 --> 01:41:20,645
Speaker 6:  Well that's, that's a hundred thousand is the biggest number we heard. I

1793
01:41:20,725 --> 01:41:23,885
Speaker 6:  actually think it's probably true that more people bought it than that. That's

1794
01:41:23,885 --> 01:41:27,845
Speaker 6:  just the last number we heard. Is that higher or lower than you

1795
01:41:27,845 --> 01:41:31,795
Speaker 6:  would've guessed. Like reasonably knowing way higher that at least a hundred

1796
01:41:32,035 --> 01:41:35,675
Speaker 6:  thousand people bought the thing. Most people buy gadgets intending to use

1797
01:41:35,675 --> 01:41:39,525
Speaker 6:  them. You think 5,000 is is higher than you would've expected.

1798
01:41:40,725 --> 01:41:41,985
Speaker 3:  Do you use yours every

1799
01:41:41,985 --> 01:41:44,985
Speaker 6:  Day? No, it's sitting right here. The battery's been dead since, I dunno,

1800
01:41:44,985 --> 01:41:45,305
Speaker 6:  April.

1801
01:41:46,985 --> 01:41:48,825
Speaker 6:  I am gonna fire it back up though. Do

1802
01:41:48,825 --> 01:41:51,625
Speaker 3:  You podcast from like a pile of dead useless gadgets?

1803
01:41:51,785 --> 01:41:54,945
Speaker 6:  I do everything from a pile of dead useless gadgets. Yes. That's, that's

1804
01:41:54,945 --> 01:41:58,745
Speaker 6:  what my job is. I've lived my life. You know, everything you

1805
01:41:58,745 --> 01:42:02,465
Speaker 6:  can't see in this maybe fake background of mine, it's just a pile of dead

1806
01:42:02,465 --> 01:42:03,265
Speaker 6:  useless gadgets. It's

1807
01:42:03,265 --> 01:42:05,105
Speaker 3:  Just slowly swelling. Batterie. I

1808
01:42:05,105 --> 01:42:09,065
Speaker 6:  Also, I have the, the humane pin right here. Oh good. It's been, it's

1809
01:42:09,065 --> 01:42:12,905
Speaker 6:  been six months since these things came out. Almost. I believe it was

1810
01:42:12,905 --> 01:42:16,465
Speaker 6:  April 11th. We're a couple weeks away from the six month anniversary and

1811
01:42:16,745 --> 01:42:19,545
Speaker 6:  I promised when I did them that in six months I would come back. So God help

1812
01:42:19,545 --> 01:42:22,665
Speaker 6:  me. I have to fire these devices back up and see how it's going. Yeah,

1813
01:42:23,185 --> 01:42:25,665
Speaker 3:  I think, I think it's substantially higher than I expected. I expected the

1814
01:42:25,665 --> 01:42:28,305
Speaker 3:  people who work at the company to use this thing every day and everything

1815
01:42:28,305 --> 01:42:30,185
Speaker 3:  else. We'll see, I'll say

1816
01:42:30,355 --> 01:42:33,585
Speaker 6:  Daily is, daily is a lot. I think I is a lot. I would guess the number was

1817
01:42:33,585 --> 01:42:37,345
Speaker 6:  higher than this for like people who still turn it on sometimes. Yeah,

1818
01:42:37,635 --> 01:42:38,465
Speaker 6:  daily is a lot.

1819
01:42:38,995 --> 01:42:42,985
Speaker 3:  Jesse Lou, the C of Rabbit has told us he's

1820
01:42:42,985 --> 01:42:46,915
Speaker 3:  coming on decoder. I'll let you know when that happens, but he

1821
01:42:46,915 --> 01:42:50,795
Speaker 3:  is, he's, we are booked. I have the, the, it's on my calendar. I'm

1822
01:42:50,805 --> 01:42:54,635
Speaker 3:  dying to ask him questions. So let me know what your questions are and

1823
01:42:54,635 --> 01:42:56,715
Speaker 3:  we'll see if we can get some answers about the rabbit.

1824
01:42:56,875 --> 01:43:00,275
Speaker 6:  I will say too, rabbits credit, they have like continued to post through

1825
01:43:00,275 --> 01:43:03,755
Speaker 6:  it. Like they, they are not shy about the stuff they've been dealing with.

1826
01:43:03,905 --> 01:43:04,195
Speaker 6:  Yeah,

1827
01:43:04,415 --> 01:43:06,875
Speaker 3:  No, he's out there. I mean he's obviously on a media tour, right? Yeah. He's

1828
01:43:06,875 --> 01:43:10,555
Speaker 3:  at this conference. He, he wants to be on decoder. We're, we're gonna do

1829
01:43:10,555 --> 01:43:14,515
Speaker 3:  it. I'm very curious like many of the things we talked about

1830
01:43:14,515 --> 01:43:17,155
Speaker 3:  with Meta, can you get past the phone operating system or do you have to

1831
01:43:17,155 --> 01:43:20,235
Speaker 3:  build your own hardware? Rabbit is an answer to that question. Yep. But then

1832
01:43:20,235 --> 01:43:23,555
Speaker 3:  you have to do all the rest of it. We'll see. Yeah.

1833
01:43:24,185 --> 01:43:28,145
Speaker 3:  Alright. I we're way over. We gotta wrap this thing up. Does anybody else

1834
01:43:28,175 --> 01:43:31,905
Speaker 3:  have any last minute Zuckerberg style dunks on the whole

1835
01:43:32,105 --> 01:43:35,745
Speaker 3:  industry issue? No. All right. Let us know. You can get a hold of us.

1836
01:43:35,745 --> 01:43:38,625
Speaker 3:  There's quite a lot to talk about so we welcome your feedback. Leave us your

1837
01:43:38,625 --> 01:43:42,465
Speaker 3:  voicemails. You can send David a text to his rabbit R one I believe.

1838
01:43:42,605 --> 01:43:42,825
Speaker 3:  I'm

1839
01:43:42,825 --> 01:43:43,145
Speaker 6:  Trying to figure out

1840
01:43:54,045 --> 01:43:57,645
Speaker 12:  Vergecast everybody. We'll be back next week. Rock and roll.

