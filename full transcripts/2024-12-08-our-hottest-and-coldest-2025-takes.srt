1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 2c2d5895-bc16-4e93-878f-02f2f0711035
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-3028386712359205687/1412775986284796380/s93290-US-4045s-1733657203.mp3
Description: Welcome to our two-part preview of the year to come! For the first installment, Nilay, David, and Wall Street Journal columnist Joanna Stern bring all the predictions for 2025 â€” their mildest, medium-est, and spiciest ideas about the year to come. Each host presents their take on TikTok bans, social platforms, smart homes, streaming services, and more, and the others get to decide whether they agree. Whoever gets the most right at the end of the year will win a big prize. (There's a points system for determining all that, but we'll figure that out later.)
Email us at vergecast@theverge.com or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Enabled (10 ads detected)

2
00:00:01,995 --> 00:00:05,845
Speaker 2:  Welcome To The Vergecast, the flagship podcast of extremely

3
00:00:05,915 --> 00:00:09,485
Speaker 2:  mild, very hot takes. I'm your friend David Pierce, and I

4
00:00:09,705 --> 00:00:13,085
Speaker 2:  am Christmas shopping. I have my whole list. I'm very organized this year.

5
00:00:13,325 --> 00:00:16,045
Speaker 2:  I have all the people that I need. I know roughly what I'm getting them.

6
00:00:16,285 --> 00:00:19,925
Speaker 2:  I had like a big self brainstorm of ideas, but do you know what I

7
00:00:20,125 --> 00:00:23,925
Speaker 2:  discovered? For me at least, the single hardest thing

8
00:00:23,925 --> 00:00:27,405
Speaker 2:  to buy is like a pretty good $20 gift.

9
00:00:27,825 --> 00:00:31,525
Speaker 2:  The things for like secret Santa parties or colleagues at work,

10
00:00:31,705 --> 00:00:35,165
Speaker 2:  or just this like list of people in the world. You need to get

11
00:00:35,235 --> 00:00:39,125
Speaker 2:  something but you don't know them well enough to

12
00:00:39,125 --> 00:00:42,685
Speaker 2:  really get something like super personal. And also, it might be weird If

13
00:00:42,685 --> 00:00:46,525
Speaker 2:  you did and you don't wanna spend a ton of money. I think this is why

14
00:00:46,805 --> 00:00:50,565
Speaker 2:  I end up both like giving and receiving a lot of Starbucks gift cards every

15
00:00:50,565 --> 00:00:54,165
Speaker 2:  year. It's just a pretty universally useful thing that people like.

16
00:00:55,025 --> 00:00:58,925
Speaker 2:  But I don't want to do that so much anymore. I just don't know

17
00:00:58,925 --> 00:01:02,725
Speaker 2:  what else to do. I'm sort of lost on this idea of like, what is a good

18
00:01:03,185 --> 00:01:06,805
Speaker 2:  $20 relatively safe and

19
00:01:06,995 --> 00:01:10,965
Speaker 2:  universally liked gift to give? If you have the answer, I want

20
00:01:10,965 --> 00:01:14,645
Speaker 2:  to know, please tell me. Sincerely, you will make everything about my holiday

21
00:01:15,165 --> 00:01:18,485
Speaker 2:  planning for forever better and easier. So get at me.

22
00:01:18,785 --> 00:01:22,445
Speaker 2:  Anyway. This episode is the first in a two-part series. We're doing

23
00:01:22,575 --> 00:01:26,405
Speaker 2:  about 2025. It's the end of 2024. We're doing some looking

24
00:01:26,405 --> 00:01:28,845
Speaker 2:  back on this show, but we thought it would also be fun to spend some time

25
00:01:28,845 --> 00:01:32,805
Speaker 2:  looking forward. 2025 is gonna be a big year in tech. We have

26
00:01:32,965 --> 00:01:36,325
Speaker 2:  a new administration coming into office that is gonna change the way that

27
00:01:36,325 --> 00:01:39,965
Speaker 2:  we think about a lot of politics and regulation and has a lot of feelings

28
00:01:39,965 --> 00:01:43,085
Speaker 2:  about big tech. Frankly. We have this AI

29
00:01:43,585 --> 00:01:46,685
Speaker 2:  bubble slash hype cycle slash

30
00:01:47,205 --> 00:01:51,125
Speaker 2:  takeover of the world that is still ongoing. We have all

31
00:01:51,135 --> 00:01:55,125
Speaker 2:  kinds of questions about antitrust and big tech and what's gonna happen

32
00:01:55,225 --> 00:01:59,165
Speaker 2:  to the venture capital world. There's just a lot going on and

33
00:01:59,165 --> 00:02:03,005
Speaker 2:  it feels like in so many ways, 2025 is going to

34
00:02:03,005 --> 00:02:06,885
Speaker 2:  be maybe not a turning point, but a moment in certain

35
00:02:06,885 --> 00:02:10,125
Speaker 2:  ways. So we figured we'd just look ahead and see what we could guess

36
00:02:10,575 --> 00:02:14,445
Speaker 2:  about what's coming. I grabbed Ne Patel and the Wall Street Journal's, Joanna

37
00:02:14,445 --> 00:02:18,325
Speaker 2:  Stern, two of my favorite people to speculate wildly about tech with,

38
00:02:18,585 --> 00:02:22,525
Speaker 2:  and we spent some time doing it for this first episode. We each came with

39
00:02:22,525 --> 00:02:25,765
Speaker 2:  predictions. I gave them both the homework to come with three different predictions

40
00:02:25,825 --> 00:02:28,845
Speaker 2:  ranked in order of spiciness, and we're just gonna go around and talk about

41
00:02:29,125 --> 00:02:33,045
Speaker 2:  it. We invented a little game that, if I'm honest, only like half makes

42
00:02:33,045 --> 00:02:36,005
Speaker 2:  sense to me at this point, but we're gonna figure it out as we go. It's gonna

43
00:02:36,005 --> 00:02:39,525
Speaker 2:  be very fun. All that is coming up in just a second, But first,

44
00:02:40,125 --> 00:02:44,025
Speaker 2:  I guess I'm just buying Starbucks gift cards. This is life now. Merry Christmas.

45
00:02:44,025 --> 00:02:46,665
Speaker 2:  Everybody have some Starbucks. This is The Verge cast. We'll be right back.

46
00:03:23,315 --> 00:03:26,765
Speaker 2:  Welcome back. Neil Patella is here. Hello, Joanna Stern.

47
00:03:27,095 --> 00:03:29,565
Speaker 2:  Hello, hello. We're all in the studio. This is so exciting. I'm very, this

48
00:03:29,565 --> 00:03:30,085
Speaker 2:  guys very so

49
00:03:30,085 --> 00:03:32,845
Speaker 3:  Happy. I know we're, I'm gonna look at you or I'm gonna look at both of you.

50
00:03:32,995 --> 00:03:33,285
Speaker 3:  Yeah,

51
00:03:33,825 --> 00:03:37,805
Speaker 2:  We have spent like a lot of time in rooms together over the years and not

52
00:03:37,805 --> 00:03:41,725
Speaker 2:  in a very long time. This is very exciting. Okay, here's how this is gonna

53
00:03:41,725 --> 00:03:45,445
Speaker 2:  work. Okay? I have told both of you to come with three predictions

54
00:03:45,785 --> 00:03:49,605
Speaker 2:  for 2025 in increasing level of spiciness.

55
00:03:49,625 --> 00:03:53,285
Speaker 2:  Not necessarily like less likely to come true, but like

56
00:03:53,645 --> 00:03:57,165
Speaker 2:  I want your victory lap for each one to be successively bigger. Does that

57
00:03:57,165 --> 00:04:01,125
Speaker 2:  make sense? Like If you, your third take should be the one that If

58
00:04:01,125 --> 00:04:03,685
Speaker 2:  you are right, you're gonna, you're gonna tell a lot of people about how

59
00:04:03,685 --> 00:04:06,765
Speaker 2:  you were right. Oh good. Okay. Okay. So

60
00:04:07,585 --> 00:04:09,655
Speaker 2:  we're gonna go around, we're gonna talk about them. And then the way that

61
00:04:09,655 --> 00:04:12,575
Speaker 2:  this game plays is after each one of us gives a prediction, we're gonna talk

62
00:04:12,575 --> 00:04:16,415
Speaker 2:  about it. The other two get to decide if they wanna like co-sign

63
00:04:16,445 --> 00:04:20,295
Speaker 2:  that prediction at the end of the year. You get a

64
00:04:20,295 --> 00:04:24,145
Speaker 2:  point if that prediction comes true. I guess you lose a point if it

65
00:04:24,145 --> 00:04:26,305
Speaker 2:  doesn't 'cause otherwise you should just sign on to all of them so you

66
00:04:26,305 --> 00:04:27,185
Speaker 4:  Can end up with negative points.

67
00:04:27,425 --> 00:04:31,185
Speaker 2:  I think you have to be able to end up with negative points. Okay. So there

68
00:04:31,185 --> 00:04:34,185
Speaker 2:  should be some consequence for picking all of them. So I'm just making up

69
00:04:34,185 --> 00:04:37,505
Speaker 2:  the rules as we go here. Yeah, so you, you lose a point.

70
00:04:38,335 --> 00:04:41,485
Speaker 2:  We'll do half points. I'm just kidding. You lose a point If you pick a prediction

71
00:04:41,485 --> 00:04:44,325
Speaker 2:  and it's wrong, but you get a point If you pick a prediction and it's right

72
00:04:44,705 --> 00:04:48,405
Speaker 2:  at the end of the year, this episode and the next episode next week, which

73
00:04:48,405 --> 00:04:51,805
Speaker 2:  we're gonna do more 2025 stuff, we're gonna total all the points and whoever

74
00:04:51,835 --> 00:04:55,685
Speaker 2:  wins The Vergecast is going to buy you the

75
00:04:55,875 --> 00:04:59,645
Speaker 2:  most cool gadget of 2025. What will it be?

76
00:04:59,785 --> 00:05:03,765
Speaker 2:  How much will it cost? Who knows? But we're gonna do this again. This

77
00:05:03,765 --> 00:05:05,605
Speaker 4:  Is a room full of people that does not need help acquiring

78
00:05:05,605 --> 00:05:05,805
Speaker 2:  This.

79
00:05:05,805 --> 00:05:07,485
Speaker 3:  Yeah, I was, I'm gonna have already bought that.

80
00:05:07,985 --> 00:05:09,725
Speaker 4:  Can I just get the cash value? You can

81
00:05:09,725 --> 00:05:10,725
Speaker 3:  Have, have the cash value. Can

82
00:05:10,725 --> 00:05:13,685
Speaker 2:  The cash value is of this prize is one 100th of a Senate?

83
00:05:14,715 --> 00:05:15,525
Speaker 3:  Well, it depends.

84
00:05:15,945 --> 00:05:19,285
Speaker 2:  All right. So this is what we're doing. We're gonna make it work. I'm excited

85
00:05:19,285 --> 00:05:22,325
Speaker 2:  about it. Joanna, you're the guest. You get to go first. But we're, we're

86
00:05:22,325 --> 00:05:24,645
Speaker 2:  gonna start small and build up to it. Okay. So what is your, what is your

87
00:05:24,755 --> 00:05:27,045
Speaker 2:  mildest prediction for 2025?

88
00:05:28,515 --> 00:05:31,995
Speaker 3:  I have two. Of course you do. Is that, would I lose a point already

89
00:05:32,735 --> 00:05:36,435
Speaker 3:  for having two? Okay. I lose a point. It's fine. Starting at negative. Negative,

90
00:05:36,435 --> 00:05:39,915
Speaker 3:  perfect. Okay. It's 2026

91
00:05:40,895 --> 00:05:44,515
Speaker 3:  at the end, or we're at the end of 2025 and I am

92
00:05:44,565 --> 00:05:48,555
Speaker 3:  still posting to 500 different social media accounts.

93
00:05:49,145 --> 00:05:52,995
Speaker 3:  Yeah, because social media is still more fractured.

94
00:05:53,025 --> 00:05:53,315
Speaker 3:  Wait,

95
00:05:53,355 --> 00:05:56,795
Speaker 4:  I have a question. A clarifying question. Do you mean

96
00:05:57,835 --> 00:05:59,685
Speaker 4:  Twitter, like social media accounts?

97
00:05:59,945 --> 00:06:01,805
Speaker 3:  Yes. T yes. And also TikTok.

98
00:06:01,965 --> 00:06:04,245
Speaker 4:  'cause like TikTok, TikTok and an Instagram post are different.

99
00:06:04,725 --> 00:06:08,365
Speaker 3:  Actually this was another one in here. Okay. TikTok survives. So I'm still

100
00:06:08,365 --> 00:06:11,125
Speaker 3:  posting there. Okay. I actually don't post there that often, but maybe I

101
00:06:11,125 --> 00:06:14,365
Speaker 3:  should. Maybe I will. So TikTok survives, but also

102
00:06:14,855 --> 00:06:18,005
Speaker 3:  we've got blue Sky, we've got threads, we have something else. We've got

103
00:06:18,625 --> 00:06:22,605
Speaker 3:  masted on 0.3 0.0, we've got X

104
00:06:23,595 --> 00:06:24,205
Speaker 3:  Instagram.

105
00:06:24,205 --> 00:06:26,845
Speaker 4:  Right. I'm just saying that the Twitter likes Facebook are

106
00:06:26,945 --> 00:06:28,885
Speaker 2:  One. Yeah. Let's just keep it to the Twitter likes for this one. This is,

107
00:06:28,885 --> 00:06:29,165
Speaker 2:  yeah,

108
00:06:29,165 --> 00:06:31,365
Speaker 3:  I mean mostly I'm talking about the, the Twitter likes. Yeah. Because

109
00:06:31,365 --> 00:06:34,765
Speaker 4:  There's no chance the short form video ones are gonna consolidate

110
00:06:35,845 --> 00:06:37,775
Speaker 4:  like no Instagram reels and TikTok and YouTube

111
00:06:37,945 --> 00:06:40,295
Speaker 3:  Short. No, I'm just saying there's more it, it's just more, there's just

112
00:06:40,295 --> 00:06:42,215
Speaker 3:  more of 'em. Like there was, yes, there, there was.

113
00:06:42,355 --> 00:06:44,335
Speaker 4:  You're, you're yelping for days. This is

114
00:06:44,335 --> 00:06:48,055
Speaker 3:  This, you know, there is years, you know, it was like 2022 where it was like

115
00:06:48,055 --> 00:06:51,375
Speaker 3:  the backlash to social media. Next year people are gonna spend more time.

116
00:06:51,795 --> 00:06:55,735
Speaker 3:  No, next year we are more on social media and yeah, I am

117
00:06:55,735 --> 00:06:58,895
Speaker 3:  still posting every day to 500 different accounts

118
00:06:59,555 --> 00:07:00,815
Speaker 3:  and my AI agent,

119
00:07:01,805 --> 00:07:02,865
Speaker 4:  Are you gonna still post to x

120
00:07:02,885 --> 00:07:06,305
Speaker 3:  Is also coming. But that my AI agent also that that's one of the things it

121
00:07:06,305 --> 00:07:08,185
Speaker 3:  has to do is, is keep posting. Do

122
00:07:08,185 --> 00:07:11,385
Speaker 2:  You think it's the same set that you're posting to now?

123
00:07:11,385 --> 00:07:14,025
Speaker 3:  There could be more. There's probably gonna be more. Okay.

124
00:07:14,605 --> 00:07:15,785
Speaker 2:  So you think the number goes up?

125
00:07:17,075 --> 00:07:20,665
Speaker 3:  I don't think the number goes down and that is my prediction. Okay.

126
00:07:20,895 --> 00:07:22,785
Speaker 3:  That is just not gonna get any better.

127
00:07:24,645 --> 00:07:25,985
Speaker 4:  I'm not signing onto this one. Oh,

128
00:07:26,025 --> 00:07:29,265
Speaker 2:  I a hundred percent am You're not. I'm ex what? What goes away? Yeah,

129
00:07:29,265 --> 00:07:29,625
Speaker 3:  What wins?

130
00:07:31,255 --> 00:07:35,025
Speaker 4:  I think that the ability

131
00:07:35,125 --> 00:07:38,825
Speaker 4:  to hit one button and post to multiple Twitter likes Okay. Will go up

132
00:07:39,365 --> 00:07:42,345
Speaker 4:  and that will, you will experience that as going down.

133
00:07:43,255 --> 00:07:44,065
Speaker 4:  Does that make any sense?

134
00:07:44,285 --> 00:07:46,265
Speaker 3:  Yes, it does. But where am I gonna look at all the replies?

135
00:07:46,825 --> 00:07:48,665
Speaker 4:  Probably, probably, probably one of those clients. 'cause of the whole point

136
00:07:48,665 --> 00:07:52,305
Speaker 4:  of these except for X, which I, I will say probably stubbornly

137
00:07:52,325 --> 00:07:56,105
Speaker 4:  remain in like a walled garden. Everyone else is gonna

138
00:07:56,215 --> 00:07:57,345
Speaker 4:  pick a way to interoperate.

139
00:07:57,445 --> 00:07:58,865
Speaker 3:  That's a nice solution. Even like

140
00:07:59,815 --> 00:08:00,625
Speaker 4:  Socials of the world.

141
00:08:00,805 --> 00:08:03,825
Speaker 2:  He does get the point. And it is true if, if like if the Fedi verse wins

142
00:08:04,085 --> 00:08:05,985
Speaker 2:  Yep, it counts as one. It's now.

143
00:08:06,365 --> 00:08:07,105
Speaker 4:  So that's the whole

144
00:08:07,105 --> 00:08:09,825
Speaker 2:  Point. No, but that's the whole point because the fedi verse is many things,

145
00:08:09,845 --> 00:08:13,745
Speaker 2:  but it is one thing you only have to post to one place and it posts everything

146
00:08:13,745 --> 00:08:16,385
Speaker 2:  to everywhere. That's the whole point of the fedi verse, right? Yeah. So

147
00:08:16,385 --> 00:08:18,985
Speaker 2:  what you're saying is like, yeah, these things will come together in such

148
00:08:18,985 --> 00:08:21,745
Speaker 2:  a way that makes it actually more but feel like less.

149
00:08:22,015 --> 00:08:25,425
Speaker 4:  Yeah. And that will enable more to exist. Right? Which, So

150
00:08:25,665 --> 00:08:28,345
Speaker 3:  I think we're saying kind of the same thing, but you win. I think this point,

151
00:08:28,425 --> 00:08:32,225
Speaker 3:  I don't even know how the game works, frankly. Sorry you don't have to, but

152
00:08:32,225 --> 00:08:33,945
Speaker 3:  you went 'cause you gave a solution to my problem.

153
00:08:34,215 --> 00:08:36,665
Speaker 4:  Well see, I don't know. I dunno what's gonna happen. I just know that even,

154
00:08:36,945 --> 00:08:37,145
Speaker 4:  I think

155
00:08:37,145 --> 00:08:39,065
Speaker 3:  You're right. I think both of our things are gonna happen.

156
00:08:39,155 --> 00:08:43,105
Speaker 4:  Truth social is a Mastodon clone. It's actually very funny.

157
00:08:43,655 --> 00:08:47,585
Speaker 4:  They just copied the open source Mastodon code base and the license of

158
00:08:48,065 --> 00:08:51,785
Speaker 4:  is so restrictive that true social has to publish its own source code.

159
00:08:52,175 --> 00:08:55,330
Speaker 4:  This is a real thing and they obfuscate it. So now there's like other people

160
00:08:55,425 --> 00:08:59,085
Speaker 4:  who try to un like clear it up and explain what's going on through. It's

161
00:08:59,085 --> 00:09:00,805
Speaker 4:  very funny. All that's very funny. But the point is,

162
00:09:00,965 --> 00:09:03,085
Speaker 3:  I didn't know you were such a truth social user. So, well

163
00:09:03,085 --> 00:09:07,045
Speaker 4:  I'm just keeping track of how you would build new social products. And the

164
00:09:07,045 --> 00:09:10,885
Speaker 4:  obvious way to do it is to take the open source projects, right? So if

165
00:09:10,885 --> 00:09:14,685
Speaker 4:  that's just the way that people begin to build new things, then they're gonna

166
00:09:14,685 --> 00:09:17,485
Speaker 4:  interoperate. 'cause those things are already built to interoperate. I don't

167
00:09:17,485 --> 00:09:20,685
Speaker 4:  know that's gonna play out. There's a, there's like, you know Yeah. A greater

168
00:09:20,715 --> 00:09:23,645
Speaker 4:  than nothing chance that blue sky's like, oh wait, everyone's on blue sky

169
00:09:23,645 --> 00:09:26,605
Speaker 4:  and they just shut it down. Yeah. And they become a walled garden. I don't

170
00:09:26,605 --> 00:09:29,095
Speaker 4:  think that's gonna happen. That's not how they talk. But I just don't dunno

171
00:09:29,095 --> 00:09:32,415
Speaker 4:  what's gonna happen six months from now. But my, my belief,

172
00:09:32,955 --> 00:09:36,135
Speaker 4:  the reason I'm not signing onto this prediction is that just at the user

173
00:09:36,135 --> 00:09:39,575
Speaker 4:  level, you'll, for the Twitter likes, you'll push a button post everywhere

174
00:09:39,575 --> 00:09:41,015
Speaker 4:  and collect all the replies in one place. Mm.

175
00:09:41,285 --> 00:09:42,975
Speaker 2:  Okay. I hope you're right. I don't think you're, I kind,

176
00:09:43,215 --> 00:09:45,855
Speaker 3:  I was bundling TikTok in there too because I, I wanted one of them to be

177
00:09:45,855 --> 00:09:48,735
Speaker 3:  that like TikTok survives. So I was trying to get everything in one that

178
00:09:49,395 --> 00:09:53,335
Speaker 3:  social media is just still a mess and it's fractured and we're

179
00:09:53,335 --> 00:09:55,535
Speaker 3:  everywhere and we still have a million apps on our phones that we're opening.

180
00:09:55,565 --> 00:09:58,175
Speaker 4:  Yeah. And I'm just making the split between the things that look like Twitter

181
00:09:58,235 --> 00:10:00,815
Speaker 4:  and the video platforms. Yes. Smart. The video platforms. Smart. Smart. I

182
00:10:00,815 --> 00:10:02,175
Speaker 4:  agree. Will proliferate. Let's,

183
00:10:02,175 --> 00:10:05,135
Speaker 2:  Let's take TikTok out because I, we're gonna come back to TikTok. Yeah, sure.

184
00:10:05,415 --> 00:10:07,175
Speaker 2:  I have an odd feeling we're gonna come back to

185
00:10:07,175 --> 00:10:07,415
Speaker 4:  TikTok.

186
00:10:07,575 --> 00:10:07,935
Speaker 3:  I, I'm

187
00:10:07,935 --> 00:10:11,895
Speaker 2:  Sure. Okay. So I'm I'm in on that one with Joanna Neli out and

188
00:10:11,895 --> 00:10:13,935
Speaker 2:  is wrong. Neli, what's yours? You go

189
00:10:13,935 --> 00:10:17,135
Speaker 4:  First. It's extremely mild. Okay. This is,

190
00:10:17,635 --> 00:10:19,135
Speaker 2:  We will still have computers.

191
00:10:19,965 --> 00:10:23,055
Speaker 4:  This is like, I didn't put any seasoning on the stock code. Do you know what

192
00:10:23,055 --> 00:10:26,775
Speaker 4:  I'm saying? I think when they do the Alexa

193
00:10:27,075 --> 00:10:30,375
Speaker 4:  ai, it will be okay. That

194
00:10:30,375 --> 00:10:30,775
Speaker 3:  Is okay.

195
00:10:31,635 --> 00:10:32,295
Speaker 4:  That's pretty good.

196
00:10:32,415 --> 00:10:35,535
Speaker 2:  I was gonna say that's not as mild a take as it would've been six months

197
00:10:35,595 --> 00:10:35,815
Speaker 2:  ago.

198
00:10:36,045 --> 00:10:39,535
Speaker 4:  Well, here lemme explain why. So the stakes for Amazon

199
00:10:39,875 --> 00:10:43,755
Speaker 4:  are so low, right? They're not Google where they, it

200
00:10:43,755 --> 00:10:47,515
Speaker 4:  has to be good and they have to get it out in the future of all

201
00:10:47,515 --> 00:10:51,275
Speaker 4:  search depends on Gemini. They're not Apple where

202
00:10:51,275 --> 00:10:55,155
Speaker 4:  they're like, look at this glowing idiot. And they have to fix

203
00:10:55,155 --> 00:10:58,795
Speaker 4:  it and they are advertising the products against it. They're just like, yeah,

204
00:10:58,985 --> 00:11:00,835
Speaker 4:  this thing that does timers is already in your house.

205
00:11:02,575 --> 00:11:06,545
Speaker 4:  What if it was better? Right. And they have Infinity to solve

206
00:11:06,545 --> 00:11:10,305
Speaker 4:  that problem. Like there's no pressure to solve that problem.

207
00:11:10,765 --> 00:11:14,525
Speaker 4:  And I think Panos will wait. I think he's very

208
00:11:14,525 --> 00:11:17,285
Speaker 4:  comfortable waiting to solve that problem. And so that's, that's

209
00:11:17,475 --> 00:11:20,165
Speaker 3:  It's Will he wait till after 2025? He

210
00:11:20,165 --> 00:11:23,325
Speaker 4:  Could, yeah. My whole prediction is it'll be okay.

211
00:11:24,145 --> 00:11:26,165
Speaker 4:  I'm not saying it'll, it launched. Who knows

212
00:11:26,305 --> 00:11:26,845
Speaker 3:  In this year.

213
00:11:27,345 --> 00:11:29,685
Speaker 4:  Huh? I I think it'll come in the next year.

214
00:11:29,865 --> 00:11:33,685
Speaker 3:  See, my second mild was gonna be Apple Intelligence gets

215
00:11:33,785 --> 00:11:36,525
Speaker 3:  better because it can't get any worse. Yeah.

216
00:11:36,525 --> 00:11:39,645
Speaker 2:  That's also pretty kind of in the exact same vein like thing that sucks.

217
00:11:39,785 --> 00:11:41,125
Speaker 2:  Yes. Sucks slightly less. No.

218
00:11:41,225 --> 00:11:44,885
Speaker 4:  See, I, So I would counter yours. I think it will get way worse.

219
00:11:46,045 --> 00:11:49,885
Speaker 4:  I think Apple's going to feel the pressure of the other products doing stuff.

220
00:11:49,885 --> 00:11:53,645
Speaker 4:  Okay. Yeah. And they're gonna try to make it do a bunch more stuff and it

221
00:11:53,655 --> 00:11:56,895
Speaker 4:  can't do those things as we've all already experienced.

222
00:11:56,895 --> 00:11:58,855
Speaker 2:  But don't think Amazon's gonna feel that pressure. No, because that same

223
00:11:58,975 --> 00:11:59,775
Speaker 2:  pressure is coming from Amazon,

224
00:12:00,455 --> 00:12:03,955
Speaker 4:  But they don't have a business based on that pressure. Right? Right. If one

225
00:12:03,955 --> 00:12:07,755
Speaker 4:  person switches from an iPhone to a Pixel, because Gemini can do

226
00:12:07,755 --> 00:12:11,275
Speaker 4:  something that's like, they have a meeting, right? Like Tim Cook is like,

227
00:12:11,275 --> 00:12:13,835
Speaker 4:  everybody get in here like, what is going on? Where are

228
00:12:13,835 --> 00:12:15,475
Speaker 2:  Robots? It should be kill RCS. Yeah. Yeah.

229
00:12:15,585 --> 00:12:19,235
Speaker 4:  It's right. There's a whole thing that happens. It's bad. Amazon is like,

230
00:12:19,235 --> 00:12:21,635
Speaker 4:  what are you gonna do? You're gonna get a Google assistant. Like no, you're

231
00:12:21,635 --> 00:12:25,475
Speaker 4:  not like you're lazy. Use it to Right. To play a time, play music and, and

232
00:12:25,475 --> 00:12:28,455
Speaker 4:  set timers. So that's, that's their mildest prediction I have. They will

233
00:12:28,455 --> 00:12:30,095
Speaker 4:  wait. Okay. I could be wrong.

234
00:12:30,485 --> 00:12:33,615
Speaker 2:  It's a pretty mild prediction. I'm actually out on that one. Okay. I think

235
00:12:33,615 --> 00:12:37,455
Speaker 2:  If you had made this prediction in July or like this time

236
00:12:37,485 --> 00:12:41,095
Speaker 2:  last year, I would've been with you. But now I feel like the longer it goes

237
00:12:41,595 --> 00:12:45,495
Speaker 2:  and every new headline that is like, actually the new

238
00:12:45,495 --> 00:12:48,735
Speaker 2:  Alexa sucks. It does feel like the pressure is getting higher.

239
00:12:49,245 --> 00:12:50,735
Speaker 4:  Well there isn't a new Alexa yet.

240
00:12:51,735 --> 00:12:54,715
Speaker 2:  The new Alexa that they announced over a year ago. Yeah.

241
00:12:54,715 --> 00:12:55,555
Speaker 3:  They've announced it forever

242
00:12:55,555 --> 00:12:59,385
Speaker 2:  And haven't shipped. It's like it's, it's, we know what it is. They told

243
00:12:59,385 --> 00:13:02,025
Speaker 2:  us what it is and then they didn't ship it. And it feels like, but

244
00:13:02,025 --> 00:13:04,705
Speaker 4:  It has to arrive. That's what I'm saying. It has the best shot. Maybe I'll

245
00:13:04,705 --> 00:13:08,025
Speaker 4:  revise my prediction of all of these. It has the best shot of being Okay.

246
00:13:08,485 --> 00:13:09,065
Speaker 4:  It it,

247
00:13:09,755 --> 00:13:11,295
Speaker 2:  That's probably true. Think I

248
00:13:11,295 --> 00:13:13,215
Speaker 4:  Would agree with that. They have the most ability to wait. Yeah.

249
00:13:13,635 --> 00:13:16,375
Speaker 2:  Do do think the new Alexa is gonna to get a lot of people fired?

250
00:13:17,635 --> 00:13:19,335
Speaker 2:  That's my, that's my other take.

251
00:13:20,085 --> 00:13:23,975
Speaker 3:  Well, that's my thing. I kind of want it to not be okay. It will

252
00:13:23,975 --> 00:13:25,935
Speaker 3:  be so funny if it's not. Okay. This

253
00:13:25,935 --> 00:13:26,615
Speaker 4:  Is your, can you

254
00:13:26,615 --> 00:13:29,775
Speaker 2:  Imagine? 'cause they, especially they have this giant install base of regular

255
00:13:29,775 --> 00:13:31,455
Speaker 2:  people who use these things all the time. I regular

256
00:13:31,455 --> 00:13:34,095
Speaker 3:  People. That's like the Apple intelligence stuff. It's so funny when you

257
00:13:34,095 --> 00:13:37,935
Speaker 3:  see these things happen. I, yeah. I'm, I'm actually, I'm with Neli

258
00:13:37,935 --> 00:13:40,335
Speaker 3:  because, well, no, I'm not with you.

259
00:13:41,355 --> 00:13:41,895
Speaker 4:  I'm not with you.

260
00:13:42,235 --> 00:13:44,895
Speaker 3:  I'm not with you because I want it to not be Okay.

261
00:13:45,595 --> 00:13:46,775
Speaker 4:  You just want the headlines.

262
00:13:46,775 --> 00:13:48,135
Speaker 3:  Yeah. I think the headlines we just,

263
00:13:48,635 --> 00:13:51,575
Speaker 2:  You're imagining the video you're gonna make about terrible Alexa and you're

264
00:13:51,575 --> 00:13:53,695
Speaker 2:  like, it's much better if it sucks than if it's good. Yeah.

265
00:13:54,675 --> 00:13:58,335
Speaker 4:  We were home for Thanksgiving and every time my mom set a timer on our Alexa,

266
00:13:58,395 --> 00:14:02,055
Speaker 4:  it played an audio clip from the movie The Wild Robot. And she, and she had

267
00:14:02,055 --> 00:14:05,495
Speaker 4:  not seen this movie, max and I have seen this movie. Yeah. And so the thing

268
00:14:05,495 --> 00:14:08,295
Speaker 4:  would be like processing beep boop bop and then it would like set the timer

269
00:14:08,475 --> 00:14:10,535
Speaker 4:  and my mom would be like, what's wrong with Alexa?

270
00:14:11,125 --> 00:14:13,335
Speaker 3:  Wait, Amazon just built that in as like a fun thing. Yeah.

271
00:14:13,335 --> 00:14:16,455
Speaker 4:  She's like, every time you do, so it's like, it's like processing. Yeah.

272
00:14:16,455 --> 00:14:19,855
Speaker 4:  Like it does the thing that the robot does in that movie. And Max is like

273
00:14:20,155 --> 00:14:23,655
Speaker 4:  losing her mind. She thinks it's the cutest thing in the world. And my mom

274
00:14:24,195 --> 00:14:28,135
Speaker 4:  is like, why is my Alexa so much stupid than

275
00:14:28,175 --> 00:14:28,295
Speaker 4:  I

276
00:14:28,295 --> 00:14:31,495
Speaker 2:  Was? Wait, that's actually such a perfect example of why ambient computing

277
00:14:31,495 --> 00:14:35,455
Speaker 2:  is so impossible. Like what a perfect low stakes example of like, you have

278
00:14:35,455 --> 00:14:38,415
Speaker 2:  to build a thing that makes sense to everyone in the room. Yeah. Right? And

279
00:14:38,415 --> 00:14:39,375
Speaker 2:  that's so hard to do.

280
00:14:39,965 --> 00:14:43,815
Speaker 4:  Yeah. It was just like out of context. It made no sense except for the

281
00:14:43,815 --> 00:14:45,255
Speaker 4:  6-year-old was like, I love that movie.

282
00:14:47,205 --> 00:14:48,975
Speaker 3:  Wait, they did, they rolled this out to everyone.

283
00:14:49,215 --> 00:14:51,095
Speaker 4:  I they rolled it out to my mom. That's

284
00:14:51,165 --> 00:14:51,525
Speaker 3:  Not smart.

285
00:14:51,665 --> 00:14:52,605
Speaker 4:  She didn't turn it on on

286
00:14:52,605 --> 00:14:53,725
Speaker 3:  Purpose. That's absolutely not smart.

287
00:14:54,085 --> 00:14:57,975
Speaker 4:  I know. Did he? Well, I mean, I thought it was delightful. Yeah. How

288
00:14:57,995 --> 00:15:01,575
Speaker 4:  in many ways my mother's experience of computers is exactly the same as Max's

289
00:15:01,575 --> 00:15:05,295
Speaker 4:  experience of computers in that things happen until they stop happening and

290
00:15:05,295 --> 00:15:08,935
Speaker 4:  they ask me to fix them. Right. And then I have to deduce what happened here.

291
00:15:08,955 --> 00:15:10,975
Speaker 4:  And I don't know that she ever went down.

292
00:15:10,995 --> 00:15:14,415
Speaker 3:  I'm gonna call my mom mom and talk and ask her to talk to Alexa with me on

293
00:15:14,415 --> 00:15:15,655
Speaker 3:  the phone today to see if she got this.

294
00:15:16,195 --> 00:15:16,415
Speaker 4:  You

295
00:15:16,415 --> 00:15:17,975
Speaker 3:  Know, they have it in the kitchen. They have like,

296
00:15:17,995 --> 00:15:20,215
Speaker 4:  That's that's what it's for. And I'm telling you they just, they just have

297
00:15:20,215 --> 00:15:23,535
Speaker 4:  to wait. Right. People are gonna keep using 'em, set timers and then one

298
00:15:23,535 --> 00:15:26,955
Speaker 4:  day they're like, you're Alexa way smarter. And then everyone's gonna fall

299
00:15:26,955 --> 00:15:28,275
Speaker 4:  in love with their kitchen timer.

300
00:15:28,345 --> 00:15:29,275
Speaker 3:  Okay. David, what's yours?

301
00:15:29,295 --> 00:15:32,515
Speaker 2:  All right. That's a good one. Joanna and I are both out, so we'll see. Okay.

302
00:15:33,175 --> 00:15:35,635
Speaker 2:  I'm actually out Joanna. It's just crossing our fingers and hoping. Yeah.

303
00:15:36,305 --> 00:15:40,235
Speaker 2:  Mine is that, I think this is, this gets milder by

304
00:15:40,235 --> 00:15:43,875
Speaker 2:  the day. I think cable TV is going to pretty much totally die in

305
00:15:43,875 --> 00:15:47,555
Speaker 2:  2025. Like the idea that you are going to

306
00:15:48,145 --> 00:15:51,995
Speaker 2:  have a cable box through which you get television

307
00:15:52,215 --> 00:15:55,035
Speaker 2:  and it's a bunch of linear channels and that's what you pay a lot of money

308
00:15:55,035 --> 00:15:58,995
Speaker 2:  for. And mostly watch is going to be essentially completely out

309
00:15:58,995 --> 00:15:59,315
Speaker 2:  of style.

310
00:15:59,595 --> 00:16:01,315
Speaker 4:  I have a number of follow-up questions. Okay.

311
00:16:02,905 --> 00:16:06,555
Speaker 4:  When you say pretty much die there, there,

312
00:16:06,565 --> 00:16:08,195
Speaker 4:  there won't be any anymore.

313
00:16:08,325 --> 00:16:12,115
Speaker 2:  There will be some, but it'll be, it'll be like the people

314
00:16:12,255 --> 00:16:14,835
Speaker 2:  who still get a OL discs in the mail and

315
00:16:15,135 --> 00:16:16,555
Speaker 4:  Pay for, which sustained AOL for years.

316
00:16:17,105 --> 00:16:19,395
Speaker 2:  It's, it's, there are still people who do it. Right. Like it's, it's still

317
00:16:19,435 --> 00:16:21,075
Speaker 2:  a thing that exists, but it, but

318
00:16:21,075 --> 00:16:23,435
Speaker 4:  We work at aol. There are people who are like, you know, this whole company

319
00:16:23,505 --> 00:16:25,275
Speaker 4:  runs on CDs in the mail. Oh

320
00:16:25,275 --> 00:16:29,035
Speaker 2:  Yeah. And there are still, I'm sure some, you know, hundreds of

321
00:16:29,195 --> 00:16:32,235
Speaker 2:  thousands or millions of people who pay for America online, they

322
00:16:32,235 --> 00:16:33,195
Speaker 3:  Pay for their email address.

323
00:16:33,345 --> 00:16:37,315
Speaker 2:  Yeah. And so that I think will continue more or less forever,

324
00:16:37,815 --> 00:16:41,075
Speaker 2:  but like it's going to die to the extent that it is no longer an interesting

325
00:16:41,395 --> 00:16:45,315
Speaker 2:  business to the companies that run it. Like the thing that

326
00:16:45,315 --> 00:16:48,275
Speaker 2:  Comcast is doing where it's spinning off all of its cable channels.

327
00:16:49,195 --> 00:16:52,515
Speaker 2:  Everyone is going to do that and they're going to just absolutely run away

328
00:16:52,545 --> 00:16:52,835
Speaker 2:  from

329
00:16:53,525 --> 00:16:57,395
Speaker 4:  Cable. Okay. So second follow up question. Yeah. YouTube, TV and FUBU

330
00:16:57,495 --> 00:17:01,075
Speaker 4:  and Sling, you're over the top cable bundles. Are they included?

331
00:17:02,545 --> 00:17:06,515
Speaker 2:  They don't count in this. And I, I grant that this is,

332
00:17:06,655 --> 00:17:10,415
Speaker 2:  I'm, I'm like splitting hairs on that one, but they are

333
00:17:10,415 --> 00:17:12,215
Speaker 2:  meaningfully different products.

334
00:17:12,315 --> 00:17:14,175
Speaker 3:  So you're talking about like the Xfinity

335
00:17:14,555 --> 00:17:15,415
Speaker 4:  The box offering

336
00:17:15,555 --> 00:17:16,615
Speaker 2:  The the box Yeah. Is

337
00:17:16,615 --> 00:17:19,615
Speaker 3:  Really the same, the Xfinity box, the guy that comes to your house. Right.

338
00:17:19,615 --> 00:17:22,735
Speaker 2:  Third follow question. The, the cable that I buy from my internet provider,

339
00:17:23,145 --> 00:17:26,255
Speaker 2:  which is essentially what it is now, is gone.

340
00:17:26,475 --> 00:17:28,735
Speaker 4:  So third, third follow up question. Yeah. You can really tell that. I was

341
00:17:28,735 --> 00:17:31,455
Speaker 4:  just in my parents' house. They don't have Spectrum boxes anymore. They have

342
00:17:31,455 --> 00:17:35,255
Speaker 4:  an insane Spectrum app on their Apple TVs. Yeah. Which

343
00:17:35,255 --> 00:17:37,335
Speaker 4:  does not, it's it's not great.

344
00:17:39,225 --> 00:17:40,195
Speaker 4:  It's not, it

345
00:17:40,195 --> 00:17:41,355
Speaker 2:  Has a grid in the Nest channels.

346
00:17:41,355 --> 00:17:43,355
Speaker 4:  Yeah. You know what I mean? Yeah. It's like, it's super there.

347
00:17:43,535 --> 00:17:47,195
Speaker 3:  So they're paying spectrum for those channels. Right. And they, that's everything's

348
00:17:47,195 --> 00:17:51,165
Speaker 4:  Strange. Yeah. And then is it broadly the same as YouTube tv? She

349
00:17:51,165 --> 00:17:54,985
Speaker 4:  can watch it on her iPad wherever she's So that's like a big win. Does that

350
00:17:54,985 --> 00:17:55,225
Speaker 4:  count?

351
00:17:56,485 --> 00:17:56,705
Speaker 1:  No,

352
00:17:57,105 --> 00:18:00,825
Speaker 2:  But I can't explain why. Oh wait, no, that counts as cable.

353
00:18:01,025 --> 00:18:02,145
Speaker 2:  I think that is the thing that is

354
00:18:02,145 --> 00:18:02,825
Speaker 3:  Dying too broad

355
00:18:02,825 --> 00:18:04,345
Speaker 4:  Here. But that's not YouTube tv. Okay.

356
00:18:04,345 --> 00:18:06,465
Speaker 2:  Let me, let me say this more the, I can be more

357
00:18:06,985 --> 00:18:07,345
Speaker 4:  Specific. You're

358
00:18:07,345 --> 00:18:10,625
Speaker 2:  Killing, I'm killing everything except YouTube TV and Hulu with live tv.

359
00:18:10,775 --> 00:18:13,025
Speaker 2:  Okay. I'm killing all of it except those two things.

360
00:18:14,295 --> 00:18:16,985
Speaker 4:  Okay. That's where I'm at. I'm super out in this prediction. You're out on

361
00:18:16,985 --> 00:18:17,105
Speaker 2:  This one.

362
00:18:17,585 --> 00:18:18,945
Speaker 4:  I win this round. I think, I think inertia,

363
00:18:19,075 --> 00:18:23,065
Speaker 2:  Again, not debt varies but, but completely uninteresting

364
00:18:23,065 --> 00:18:25,185
Speaker 2:  to everyone in including the people that run these services.

365
00:18:25,765 --> 00:18:29,545
Speaker 4:  My parents also have an illegal Indian IP TV box that gets every channel

366
00:18:29,545 --> 00:18:32,545
Speaker 4:  for free, including locals in 4K. And that is, and

367
00:18:32,545 --> 00:18:33,665
Speaker 2:  They pay for the Spectrum app on their

368
00:18:33,675 --> 00:18:37,105
Speaker 4:  IPads? No, they pay some guy the on Venmo over the phone once a year.

369
00:18:38,455 --> 00:18:41,225
Speaker 4:  What? These things, you should write a column. This, there's an entire economy,

370
00:18:41,225 --> 00:18:42,785
Speaker 4:  these things. Wow. What? Yeah.

371
00:18:43,785 --> 00:18:45,155
Speaker 2:  Okay. That's fantastic. This,

372
00:18:45,275 --> 00:18:47,235
Speaker 3:  I was gonna say, this episode is, I think that

373
00:18:47,235 --> 00:18:48,875
Speaker 2:  Counts Eli visits. I think your parents are on my side.

374
00:18:49,475 --> 00:18:49,915
Speaker 3:  I was gonna say

375
00:18:49,915 --> 00:18:50,915
Speaker 4:  That It's very entertaining.

376
00:18:51,215 --> 00:18:54,155
Speaker 3:  The title of this episode was gonna be Neli Goes to visit his parents. No,

377
00:18:54,155 --> 00:18:54,475
Speaker 4:  I just blew,

378
00:18:54,705 --> 00:18:57,195
Speaker 3:  It's actually Neli gets his parents arrested. Yeah.

379
00:18:57,495 --> 00:19:00,715
Speaker 4:  No, no. I just blew up like the entire Indian uncle economy here.

380
00:19:01,385 --> 00:19:04,475
Speaker 4:  This is what they talk about. They all know a guy. They are scams.

381
00:19:04,545 --> 00:19:07,475
Speaker 2:  It's fantastic. It's great. Alright, so Eli's out. Joanna, are you in or

382
00:19:07,475 --> 00:19:07,635
Speaker 2:  out?

383
00:19:08,625 --> 00:19:11,005
Speaker 3:  I'm still not sure I understand. So I'm out. Yes, you do.

384
00:19:11,005 --> 00:19:13,405
Speaker 4:  Do you think she thinks traditional cable's going away except for YouTube?

385
00:19:13,545 --> 00:19:15,765
Speaker 2:  Joanna just keeps getting more cable boxes. By

386
00:19:15,765 --> 00:19:16,285
Speaker 4:  The way, this implies

387
00:19:16,285 --> 00:19:18,845
Speaker 3:  That No, I don't have cable boxes and my parents don't have cable boxes.

388
00:19:18,845 --> 00:19:22,685
Speaker 3:  Anyway, I'm, I'm in this, I'm just not talking about my parents as much as

389
00:19:22,945 --> 00:19:26,085
Speaker 3:  Eli because I didn't feel like this was Joana. I love my parents, I love

390
00:19:26,085 --> 00:19:26,525
Speaker 3:  my parents

391
00:19:28,185 --> 00:19:31,005
Speaker 3:  and they have a lot of the same commonality with your, let's get our parents

392
00:19:31,245 --> 00:19:32,885
Speaker 3:  together. Let's bring our parents to this podcast.

393
00:19:33,435 --> 00:19:33,725
Speaker 2:  Done.

394
00:19:34,075 --> 00:19:35,245
Speaker 4:  Done. No thank you.

395
00:19:37,305 --> 00:19:40,295
Speaker 3:  But I, I guess I'm in. Okay,

396
00:19:40,305 --> 00:19:44,175
Speaker 2:  Great. Love it. Joanna. Just picking it random. Are you writing these down?

397
00:19:44,295 --> 00:19:45,575
Speaker 2:  I am writing these down. Where?

398
00:19:45,725 --> 00:19:46,015
Speaker 4:  Yeah,

399
00:19:46,275 --> 00:19:47,175
Speaker 2:  In I have a doc.

400
00:19:47,505 --> 00:19:50,135
Speaker 4:  Every cable company, except for YouTube TV is going outta

401
00:19:50,295 --> 00:19:53,615
Speaker 2:  Business. Every cable. Not going outta business. Don't just irrelevant. We're

402
00:19:53,615 --> 00:19:54,015
Speaker 3:  Just not getting them.

403
00:19:54,015 --> 00:19:55,015
Speaker 4:  Are they already irrelevant?

404
00:19:55,015 --> 00:19:56,975
Speaker 3:  Yeah, that's the thing. No, So I think it's already happened. We've

405
00:19:56,975 --> 00:20:00,935
Speaker 2:  Been doing this thing where they all invest in streaming and bank the

406
00:20:01,015 --> 00:20:03,775
Speaker 2:  money from cable. That's been happening for a very long time. And everybody

407
00:20:03,775 --> 00:20:06,935
Speaker 2:  thought it was gonna happen for a really long time and then it isn't. And

408
00:20:06,935 --> 00:20:10,295
Speaker 2:  I think it's going to the, the speed of that death of

409
00:20:10,995 --> 00:20:14,775
Speaker 2:  the cable money is going to increase so fast that by

410
00:20:14,775 --> 00:20:17,215
Speaker 2:  this time next year. Oh I see. It's to be essentially

411
00:21:40,465 --> 00:21:44,365
Speaker 2:  All right, we're back. Spicy time. Let's

412
00:21:44,395 --> 00:21:47,645
Speaker 2:  flip the order. Not spicy t just spicy or

413
00:21:48,195 --> 00:21:52,165
Speaker 2:  neli you go first this time. What's your, what's your most medium prediction

414
00:21:52,165 --> 00:21:52,925
Speaker 2:  for 2025?

415
00:21:53,305 --> 00:21:53,725
Speaker 4:  Medium.

416
00:21:54,275 --> 00:21:54,565
Speaker 2:  Yeah.

417
00:21:54,875 --> 00:21:56,245
Speaker 4:  Walmart buy TikTok.

418
00:21:56,635 --> 00:21:57,125
Speaker 2:  Walmart.

419
00:21:57,355 --> 00:22:00,285
Speaker 4:  Walmart Buy TikTok. This is your medium taste. Medium.

420
00:22:01,515 --> 00:22:02,285
Speaker 4:  It's gonna be Amazon or

421
00:22:02,285 --> 00:22:03,525
Speaker 2:  This Likey, but you're not.

422
00:22:04,035 --> 00:22:05,885
Speaker 4:  Yeah, I I think there's only two. This is like

423
00:22:06,305 --> 00:22:09,845
Speaker 2:  The third question on Hot ones level of, of spice is what we're talking about.

424
00:22:09,915 --> 00:22:13,405
Speaker 4:  Okay. Well so the, he like Donald Trump has said, I won't shut it down.

425
00:22:14,495 --> 00:22:18,035
Speaker 4:  He, one of his big benefactors, a major investor in TikTok, but he can't

426
00:22:18,355 --> 00:22:22,315
Speaker 4:  overturn the law that Congress already passed that says TikTok has to go

427
00:22:22,375 --> 00:22:25,795
Speaker 4:  and App Source have to kick it out. So the number of options are very limited

428
00:22:26,455 --> 00:22:30,355
Speaker 4:  and I don't think that he cares what happens. And I don't think

429
00:22:30,355 --> 00:22:34,285
Speaker 4:  the people on TikTok actually care what happens. Right. So if he's, as

430
00:22:34,285 --> 00:22:35,485
Speaker 2:  Long as TikTok continues to exist,

431
00:22:35,505 --> 00:22:37,965
Speaker 4:  As long as TikTok continues to exist. So there's this very natural out which

432
00:22:37,965 --> 00:22:41,325
Speaker 4:  is they should sell it. Right? Which is the thing the law is sort of designed

433
00:22:41,345 --> 00:22:45,285
Speaker 4:  to force into happening. And then Trump loves a deal

434
00:22:47,175 --> 00:22:50,665
Speaker 4:  whether or not those deals are real. Whether or not LCD factories actually

435
00:22:50,665 --> 00:22:53,585
Speaker 4:  get built. We love talking about deals. So then who are you gonna sell it

436
00:22:53,585 --> 00:22:56,985
Speaker 4:  to? Amazon is terrified of TikTok because it's basically QVC.

437
00:22:57,605 --> 00:23:00,345
Speaker 4:  But even then I think you get some weird antitrust concerns. The other big

438
00:23:00,345 --> 00:23:04,265
Speaker 4:  tech companies will basically say no. So you're kind of stuck with

439
00:23:04,265 --> 00:23:05,305
Speaker 4:  the other big store

440
00:23:06,915 --> 00:23:10,205
Speaker 4:  because that's all TikTok is, is a funnel into TikTok shop. Yeah.

441
00:23:10,425 --> 00:23:14,005
Speaker 3:  And hasn't the biggest sticking point in the algorithm that

442
00:23:14,905 --> 00:23:17,715
Speaker 4:  Yeah, it's like who controls it Right In Like what

443
00:23:17,715 --> 00:23:20,875
Speaker 3:  Makes you, what makes you think that by dance is gonna say okay,

444
00:23:21,485 --> 00:23:23,235
Speaker 3:  we're given it all, we'll sell it all.

445
00:23:23,385 --> 00:23:27,275
Speaker 4:  What makes anyone think that people can perceive the quality of an

446
00:23:27,275 --> 00:23:27,675
Speaker 4:  algorithm?

447
00:23:29,875 --> 00:23:33,765
Speaker 4:  Like that was a very important, very good question. Sticky like

448
00:23:33,765 --> 00:23:37,085
Speaker 4:  it when TikTok was growing, this was important. Right? Right.

449
00:23:37,395 --> 00:23:40,765
Speaker 4:  Because it was finding you interest, it would like be really, really valuable.

450
00:23:40,785 --> 00:23:44,325
Speaker 4:  And now it's kind of like, yeah man, you can make that thing 20% worse and

451
00:23:44,325 --> 00:23:46,725
Speaker 4:  all the people are already on it. Yep. Yeah. And really all you're trying

452
00:23:46,725 --> 00:23:50,645
Speaker 4:  to get 'em to do is shop and we can watch Elon Musk just like dial a

453
00:23:50,645 --> 00:23:54,205
Speaker 4:  Twitter algorithm at Will and it doesn't seem to matter to that audience.

454
00:23:54,705 --> 00:23:57,285
Speaker 4:  So I, I think there's less danger there than anyone thinks.

455
00:23:57,505 --> 00:24:01,205
Speaker 2:  It does feel anecdotally like the sort of perceived

456
00:24:01,205 --> 00:24:04,685
Speaker 2:  quality gap in like how well the platform knows me

457
00:24:04,875 --> 00:24:08,845
Speaker 2:  between Yeah. Reels, shorts and TikTok has gone away.

458
00:24:08,845 --> 00:24:10,125
Speaker 3:  Has gotten much smaller. Yeah, I agree.

459
00:24:10,155 --> 00:24:13,725
Speaker 2:  Like I agree. I think I, for so long it was like

460
00:24:13,965 --> 00:24:17,765
Speaker 2:  Reels was old tiktoks and Shorts was just like over here doing something

461
00:24:17,765 --> 00:24:20,685
Speaker 2:  else that everyone hated. I feel like they're all the same thing now. Yeah.

462
00:24:20,785 --> 00:24:21,005
Speaker 2:  And

463
00:24:21,285 --> 00:24:23,605
Speaker 4:  A bunch of the creators have figured out how to post the same stuff to the

464
00:24:23,605 --> 00:24:26,685
Speaker 4:  same platforms without getting dinged. But that's, this is my medium take.

465
00:24:26,725 --> 00:24:29,485
Speaker 4:  I don't actually know what's gonna happen but I if you're gonna sell it,

466
00:24:29,655 --> 00:24:33,605
Speaker 4:  which seems like the most likely outcome. Yeah. 'cause otherwise they have

467
00:24:33,605 --> 00:24:36,445
Speaker 4:  to overturn a law that a bunch of Republican members of Congress passed.

468
00:24:37,155 --> 00:24:38,285
Speaker 4:  It's still hard. Even why

469
00:24:38,285 --> 00:24:40,285
Speaker 2:  Isn't it Amazon though? I feel like it's Amazon

470
00:24:40,285 --> 00:24:42,205
Speaker 3:  Because I think he's right on the antitrust stuff. Like

471
00:24:42,205 --> 00:24:45,365
Speaker 4:  How is Amazon company? I think Meta and Google and Apple all get mad about

472
00:24:45,365 --> 00:24:45,485
Speaker 4:  this.

473
00:24:46,075 --> 00:24:50,025
Speaker 2:  Yeah. And same for all of those other companies. What if it's Netflix?

474
00:24:50,375 --> 00:24:53,665
Speaker 2:  What if Netflix is just like, what's up short form video. We own TikTok now.

475
00:24:53,935 --> 00:24:56,785
Speaker 4:  Yeah, I could see it. I don't think Netflix super wants to be in that business.

476
00:24:56,785 --> 00:24:59,665
Speaker 4:  Like they don't wanna be in a user-generated, isn't

477
00:24:59,665 --> 00:25:02,905
Speaker 2:  It Netflix is like specifically pitting itself against all of those companies.

478
00:25:03,105 --> 00:25:07,025
Speaker 4:  Right? And also it's, they're, they're not gonna convert into

479
00:25:07,025 --> 00:25:10,825
Speaker 4:  Netflix subscriptions, which is the only thing they sell. Right. Walmart's

480
00:25:10,825 --> 00:25:14,065
Speaker 4:  like here's some garbage. I saw a man on TikTok yesterday

481
00:25:14,565 --> 00:25:18,225
Speaker 4:  trying to sell me a wall-mounted hose reel as an innovation

482
00:25:18,345 --> 00:25:21,425
Speaker 4:  that I should buy for my family for Christmas. And I was like, my dude,

483
00:25:22,205 --> 00:25:25,945
Speaker 4:  my dad bought that shit already at Menards in 1982. Like

484
00:25:25,975 --> 00:25:29,585
Speaker 4:  what are we doing on this platform right now? And that, that's just

485
00:25:30,235 --> 00:25:31,905
Speaker 4:  where we are on TikTok. It is just

486
00:25:32,345 --> 00:25:35,345
Speaker 3:  A store. Totally. Yeah. No and that's like, there was a point where my whole

487
00:25:35,345 --> 00:25:39,185
Speaker 3:  entire feed was just hair products. I was like, I already have a hair

488
00:25:39,185 --> 00:25:39,705
Speaker 3:  iron because, and

489
00:25:39,705 --> 00:25:41,705
Speaker 4:  You're like, my mom bought these at Menards and they,

490
00:25:43,725 --> 00:25:46,625
Speaker 3:  My current hair iron, what I bought at Menards.

491
00:25:47,265 --> 00:25:48,505
Speaker 3:  Google's Menards. Great deal.

492
00:25:48,645 --> 00:25:48,865
Speaker 4:  See

493
00:25:49,185 --> 00:25:49,505
Speaker 3:  Because

494
00:25:49,505 --> 00:25:50,905
Speaker 2:  Menards a real thing. What

495
00:25:50,905 --> 00:25:51,385
Speaker 3:  Is Menards?

496
00:25:51,525 --> 00:25:53,345
Speaker 2:  Is this like a Midwest thing? Do we need to talk

497
00:25:53,345 --> 00:25:56,265
Speaker 4:  About this? I gotta stop hanging out with East Coasters. This is like the

498
00:25:56,265 --> 00:25:57,865
Speaker 4:  most deeply Wisconsin store in the

499
00:25:57,865 --> 00:25:59,305
Speaker 3:  World. Is that your version of Home Depot?

500
00:26:00,095 --> 00:26:02,305
Speaker 4:  It's it's Superior Depot.

501
00:26:02,305 --> 00:26:03,105
Speaker 3:  It's your version of Depot,

502
00:26:03,105 --> 00:26:05,625
Speaker 4:  Lowe's, home Depot's corporate. Yeah. Yeah. This is like I knew Menards when

503
00:26:05,625 --> 00:26:06,505
Speaker 4:  they like first album.

504
00:26:07,305 --> 00:26:09,585
Speaker 2:  I see. Does Menards to

505
00:26:09,615 --> 00:26:12,665
Speaker 4:  Home Depots. The Chainsmokers. I wanna be very clear about

506
00:26:13,645 --> 00:26:15,065
Speaker 4:  to comparison I'm making here.

507
00:26:15,095 --> 00:26:18,985
Speaker 2:  Okay, that works for me. Yeah, I'm actually in on this one. I like it.

508
00:26:19,625 --> 00:26:22,945
Speaker 2:  I think somebody is going to buy TikTok. Yes. And I feel like Walmart's as

509
00:26:22,945 --> 00:26:24,745
Speaker 2:  good bet as any, so I'm, I'm in on this one

510
00:26:25,205 --> 00:26:28,605
Speaker 3:  And I just believe TikTok survives. So Sure.

511
00:26:28,605 --> 00:26:29,885
Speaker 4:  That's your medium take. No,

512
00:26:29,885 --> 00:26:31,285
Speaker 3:  That was my like take. Yeah, the take that

513
00:26:31,285 --> 00:26:32,885
Speaker 2:  Was take would've TikTok survives.

514
00:26:33,075 --> 00:26:36,765
Speaker 3:  That was my mild take. It was like all the social media survives and we get

515
00:26:36,765 --> 00:26:40,005
Speaker 3:  more. Right? Sure. Walmart seems nice. All right. Let until

516
00:26:40,005 --> 00:26:43,725
Speaker 2:  You in we're all in. Sure I'm in. I love it all. I'll go next. My

517
00:26:44,565 --> 00:26:47,865
Speaker 2:  medium prediction, which I actually think might be spicier than I realized

518
00:26:48,365 --> 00:26:52,265
Speaker 2:  is that someone in 2025 is going to make an AI gadget that like actually

519
00:26:52,315 --> 00:26:54,825
Speaker 2:  kicks ass and it's gonna be a huge hit. Ooh,

520
00:26:55,135 --> 00:26:56,225
Speaker 4:  This is your medium. This

521
00:26:56,225 --> 00:26:56,585
Speaker 2:  Is my medium

522
00:26:57,185 --> 00:26:58,945
Speaker 4:  Compared to my mild of Alexa is Okay.

523
00:26:59,535 --> 00:27:03,145
Speaker 2:  Yeah. Like I don't know, it probably won't be

524
00:27:03,445 --> 00:27:07,025
Speaker 2:  the rabbit R two or the Humane ai pin two

525
00:27:07,245 --> 00:27:11,145
Speaker 2:  or so. But like maybe it's the next meta RayBan

526
00:27:11,145 --> 00:27:14,705
Speaker 2:  smart glasses that go like deep into more AI stuff.

527
00:27:14,875 --> 00:27:18,635
Speaker 2:  Maybe it's like AirPods something. So I don't know.

528
00:27:19,035 --> 00:27:22,795
Speaker 2:  Somebody is going to make a gadget that is like explicitly about AI and it's

529
00:27:22,795 --> 00:27:25,035
Speaker 2:  gonna be awesome and tons of people are gonna want it.

530
00:27:25,905 --> 00:27:29,675
Speaker 3:  Okay. Actually mine is similar to that. Yeah. My medium take. But

531
00:27:29,735 --> 00:27:31,355
Speaker 3:  we should all vote on yours first. Okay.

532
00:27:33,785 --> 00:27:34,565
Speaker 4:  No, no.

533
00:27:35,185 --> 00:27:37,885
Speaker 2:  Is not gonna happen. What about this sale? The Johnny I thing This is

534
00:27:37,885 --> 00:27:39,565
Speaker 4:  Deeply related to I don't think the Johnny,

535
00:27:39,605 --> 00:27:40,365
Speaker 3:  I think's coming

536
00:27:40,365 --> 00:27:43,645
Speaker 4:  At this year. I have three spicy takes and this is deeply related to one

537
00:27:43,645 --> 00:27:44,325
Speaker 4:  of them. Okay,

538
00:27:44,515 --> 00:27:47,005
Speaker 2:  Well then you're not gonna give it to me. So what was your spicy take that

539
00:27:47,005 --> 00:27:47,245
Speaker 2:  you're

540
00:27:47,505 --> 00:27:49,845
Speaker 4:  Oh sure. Yeah. Well I'll I'll just do it now. I'll do it now. Roll this.

541
00:27:49,915 --> 00:27:51,485
Speaker 4:  Yeah. This is a rebuttal. Yeah.

542
00:27:51,995 --> 00:27:52,285
Speaker 2:  With

543
00:27:52,285 --> 00:27:53,125
Speaker 3:  It. Okay. That's a good order.

544
00:27:53,625 --> 00:27:55,845
Speaker 4:  AI conclusively proven to be a bubble. Ooh.

545
00:27:57,115 --> 00:27:58,165
Speaker 2:  Okay. It

546
00:27:58,165 --> 00:28:02,085
Speaker 4:  It's Bluetooth. I pr it's just, it's Bluetooth next year

547
00:28:02,085 --> 00:28:03,165
Speaker 4:  Bluetooth is gonna be great. AI

548
00:28:03,185 --> 00:28:03,725
Speaker 2:  Is Bluetooth.

549
00:28:03,945 --> 00:28:07,205
Speaker 4:  AI is Bluetooth ai. Everyone talks about it the same way. They make the same

550
00:28:07,495 --> 00:28:10,165
Speaker 4:  lofty predictions about Bluetooth is gonna do. Yeah.

551
00:28:10,165 --> 00:28:10,925
Speaker 3:  When did they do that?

552
00:28:11,465 --> 00:28:13,685
Speaker 4:  All the time. They're like, these headphones are gonna rule and then you're

553
00:28:13,685 --> 00:28:17,045
Speaker 4:  like, well Apple had to hijack the entire Bluetooth product call and make

554
00:28:17,045 --> 00:28:17,525
Speaker 4:  their own Bluetooth.

555
00:28:17,525 --> 00:28:18,405
Speaker 2:  Isn't it more that

556
00:28:18,405 --> 00:28:20,085
Speaker 3:  No one else can, a different memory of Bluetooth Isn't

557
00:28:20,425 --> 00:28:21,405
Speaker 2:  AI 5G?

558
00:28:22,115 --> 00:28:22,405
Speaker 4:  Yeah.

559
00:28:22,505 --> 00:28:23,085
Speaker 2:  In that case,

560
00:28:23,555 --> 00:28:27,005
Speaker 4:  Sure, sure. Whatever garbage wireless protocol you want to use,

561
00:28:28,925 --> 00:28:32,485
Speaker 4:  whatever garbage, wireless protocol you want to use, go for it. Sure. But

562
00:28:32,485 --> 00:28:36,165
Speaker 4:  Bluetooth in particular was like an enabling technology that never

563
00:28:36,305 --> 00:28:40,165
Speaker 4:  pan out. Right. That you would have an ecosystem Yep. Of

564
00:28:40,165 --> 00:28:44,005
Speaker 4:  products all over around you that were all Bluetooth together. The smart

565
00:28:44,005 --> 00:28:47,725
Speaker 4:  home would run on Bluetooth, low energy, all that stuff exists.

566
00:28:48,155 --> 00:28:49,285
Speaker 4:  It's there. Yeah. 'cause

567
00:28:49,285 --> 00:28:50,845
Speaker 3:  That's where I was thinking you were going with like you can go to the

568
00:28:50,845 --> 00:28:51,525
Speaker 4:  Bluetooth conference,

569
00:28:52,385 --> 00:28:54,325
Speaker 3:  You can go to the B Can you still Yeah.

570
00:28:54,545 --> 00:28:56,125
Speaker 4:  The sig. Do you remember that Rocket

571
00:28:56,405 --> 00:28:56,925
Speaker 3:  Sig still around?

572
00:28:57,275 --> 00:28:57,565
Speaker 4:  Yeah.

573
00:28:58,425 --> 00:29:01,685
Speaker 2:  Do you remember what everybody was obsessed with? The like retail Bluetooth

574
00:29:01,685 --> 00:29:04,445
Speaker 2:  where you would walk into a store and Oh no. Just like it would like Bluetooth.

575
00:29:04,465 --> 00:29:05,805
Speaker 2:  All the coupons on Apples gonna

576
00:29:05,805 --> 00:29:08,925
Speaker 4:  Do that. Yeah. Yeah. Oh yeah. The they still do that by the way, just to

577
00:29:08,925 --> 00:29:11,965
Speaker 4:  track you. That is super happy. It's still there every time you walk through

578
00:29:11,965 --> 00:29:15,525
Speaker 4:  the door of a store in the mall, it's like we found you again. Yeah. And

579
00:29:15,525 --> 00:29:17,925
Speaker 4:  then people wonder why it sound seems like everyone's listening to them.

580
00:29:18,185 --> 00:29:20,685
Speaker 4:  No, it's just 'cause you existed with your phone and Bluetooth,

581
00:29:21,875 --> 00:29:24,785
Speaker 4:  which again the core benefits of Bluetooth

582
00:29:25,525 --> 00:29:28,985
Speaker 4:  pretty mild because Apple had to invent their own special Bluetooth to make

583
00:29:28,985 --> 00:29:30,225
Speaker 4:  AirPods work. Okay. Which is what

584
00:29:30,255 --> 00:29:31,905
Speaker 3:  Most, I have a lot of feelings about what he's saying.

585
00:29:32,005 --> 00:29:35,945
Speaker 4:  Do you see what I'm saying? AI is on the exact same trajectory as

586
00:29:35,945 --> 00:29:39,225
Speaker 4:  Bluetooth only 10,000 times more expensive. Okay. Okay.

587
00:29:39,535 --> 00:29:43,445
Speaker 4:  There's not one product that is bigger than chat GPT that

588
00:29:43,445 --> 00:29:44,405
Speaker 4:  you can make with AI today.

589
00:29:44,595 --> 00:29:47,085
Speaker 3:  Okay. I'm not with you and I'm not with you. Okay.

590
00:29:47,085 --> 00:29:48,085
Speaker 2:  Okay then where are you? I

591
00:29:48,085 --> 00:29:49,685
Speaker 4:  Like that you just keep announcing this. Yeah.

592
00:29:50,295 --> 00:29:51,285
Speaker 2:  Where are you? That that's

593
00:29:51,285 --> 00:29:53,485
Speaker 3:  My job here. No and no where

594
00:29:53,795 --> 00:29:55,845
Speaker 4:  Mine was just a rebuttal. It's on a prediction. You

595
00:29:55,845 --> 00:29:57,525
Speaker 3:  Did your prediction now. Well,

596
00:29:57,525 --> 00:29:58,765
Speaker 2:  But if yours is true, mine can't be

597
00:29:59,595 --> 00:29:59,885
Speaker 4:  Okay.

598
00:29:59,895 --> 00:30:01,845
Speaker 2:  Right. Because if if, if we get to that is

599
00:30:01,845 --> 00:30:03,325
Speaker 3:  Your spicy, you chose your spicy. That's what

600
00:30:03,865 --> 00:30:06,725
Speaker 2:  Not spicy. That's not spicy. That's a reject spicy that he's rebutting.

601
00:30:06,725 --> 00:30:08,085
Speaker 3:  Oh, so now you are getting two spicy.

602
00:30:08,425 --> 00:30:12,405
Speaker 4:  No, no. That's not a prediction. No point. If AI is a bubble, I get no points.

603
00:30:12,405 --> 00:30:16,005
Speaker 4:  Which is, I'm giving that up now in order to rebut David who says the

604
00:30:16,065 --> 00:30:17,365
Speaker 4:  humane pit is gonna be

605
00:30:17,365 --> 00:30:19,125
Speaker 3:  Good. You kind of a restaurant is this, you got so

606
00:30:21,325 --> 00:30:22,605
Speaker 2:  Mila's just sneaking dishes in here.

607
00:30:22,675 --> 00:30:24,885
Speaker 3:  This is my new restaurant called Menards. No, he

608
00:30:24,985 --> 00:30:28,725
Speaker 4:  Say he made his prediction there would be a good AI gadget. And I'm saying

609
00:30:29,035 --> 00:30:30,445
Speaker 4:  that requires B boost

610
00:30:30,505 --> 00:30:33,045
Speaker 3:  To be good. Yeah. But now you're gonna get too spicy.

611
00:30:33,425 --> 00:30:35,845
Speaker 4:  I'm just explaining why I'm not signing up. Yeah.

612
00:30:36,315 --> 00:30:40,085
Speaker 3:  Okay. I don't, I don't think we're gonna get a great AI gadget that

613
00:30:40,245 --> 00:30:44,075
Speaker 3:  everyone buys. Okay. I'm gonna, can I do my medium now? Sure,

614
00:30:44,075 --> 00:30:44,355
Speaker 3:  please.

615
00:30:45,035 --> 00:30:46,355
Speaker 2:  I So you're both out on mine.

616
00:30:47,945 --> 00:30:50,825
Speaker 3:  I would like to respond to you just pick that as you're spicy. 'cause then

617
00:30:50,825 --> 00:30:51,745
Speaker 3:  we can come back to it. Okay,

618
00:30:51,745 --> 00:30:55,385
Speaker 4:  Fine. I'll add that to my spicy. Okay. Least pretty spicy and

619
00:30:55,385 --> 00:30:55,785
Speaker 4:  appetizer

620
00:30:56,225 --> 00:30:56,945
Speaker 3:  A chili's too.

621
00:30:59,575 --> 00:31:03,105
Speaker 3:  Okay. My medium was that meta

622
00:31:03,185 --> 00:31:06,625
Speaker 3:  releases another pair of the smart, the RayBan smart glasses.

623
00:31:07,565 --> 00:31:11,465
Speaker 3:  But it has a display in it. It's like a heads up display. There's been rumors

624
00:31:11,465 --> 00:31:15,315
Speaker 3:  of this and I guess the like more spicy

625
00:31:15,315 --> 00:31:19,235
Speaker 3:  version of this is that meta continues to outpace apple

626
00:31:19,935 --> 00:31:21,435
Speaker 3:  in the race for smart glasses.

627
00:31:22,525 --> 00:31:26,465
Speaker 2:  Oh I'm extremely in on that one. I'm like, every day I become

628
00:31:26,535 --> 00:31:30,305
Speaker 2:  more radicalized that Meta did this right. And Apple did this wrong. Like

629
00:31:30,305 --> 00:31:32,625
Speaker 2:  the, the story of 2024 with

630
00:31:32,625 --> 00:31:35,745
Speaker 3:  That, I'm writing a column about that right now and I believe that I'm, I

631
00:31:35,745 --> 00:31:39,665
Speaker 3:  love the Raybans. I think the path they are taking is better than the path

632
00:31:39,835 --> 00:31:40,785
Speaker 3:  Apple has been taking.

633
00:31:41,865 --> 00:31:45,035
Speaker 4:  Okay. I agree with meta continues to outpace Apple. Yeah, yeah. Yeah. You,

634
00:31:45,315 --> 00:31:45,915
Speaker 4:  I don't agree

635
00:31:45,915 --> 00:31:46,555
Speaker 3:  With me on something.

636
00:31:46,835 --> 00:31:48,755
Speaker 4:  I don't think the Raybans are, I sent mine back.

637
00:31:49,335 --> 00:31:49,555
Speaker 2:  You

638
00:31:49,885 --> 00:31:50,835
Speaker 3:  Don't how to use them.

639
00:31:50,895 --> 00:31:51,595
Speaker 2:  You've a big head.

640
00:31:51,595 --> 00:31:52,915
Speaker 3:  Yeah. You don't know how to use them. That's not,

641
00:31:53,215 --> 00:31:53,675
Speaker 2:  That's not

642
00:31:53,725 --> 00:31:55,995
Speaker 4:  Fault. Are different ideas. You can't agree with him

643
00:31:58,465 --> 00:31:59,915
Speaker 2:  What she said big head. Yeah.

644
00:32:00,535 --> 00:32:02,075
Speaker 3:  If you have a big head and you know, know how to use that,

645
00:32:02,695 --> 00:32:06,435
Speaker 4:  You're dumb. There's big head, tiny brain. I get it. I understand what you're

646
00:32:06,435 --> 00:32:10,155
Speaker 4:  saying. Yes. Look, all of those things might be true

647
00:32:10,335 --> 00:32:14,155
Speaker 4:  but I use them and this is some Apple stuff, right.

648
00:32:14,155 --> 00:32:17,235
Speaker 4:  Where they won't let the photos automatically go to your phone. If you have

649
00:32:17,335 --> 00:32:19,955
Speaker 4:  iOS, they will let you on Android course. Fine. I think the camera's like

650
00:32:19,955 --> 00:32:23,115
Speaker 4:  just fine. Fine. The AI stuff is like extremely medium.

651
00:32:23,875 --> 00:32:25,235
Speaker 3:  I could, I could take the rest

652
00:35:38,305 --> 00:35:41,405
Speaker 2:  it actually, it not only doesn't add more appeal, it actually kills a bunch

653
00:35:41,405 --> 00:35:44,325
Speaker 2:  of appeal. Because the thing that's nice about the ones now is they are mostly

654
00:35:44,355 --> 00:35:45,045
Speaker 2:  just sunglasses.

655
00:35:45,155 --> 00:35:48,525
Speaker 3:  Totally. I think they, they have to do something in between

656
00:35:49,395 --> 00:35:52,045
Speaker 3:  what they've been showing with Orion and what they're, they've been doing

657
00:35:52,045 --> 00:35:55,445
Speaker 3:  with the smart glasses. Yes. And that is very basic

658
00:35:56,395 --> 00:35:58,765
Speaker 3:  information in your line of eye. And so

659
00:35:58,915 --> 00:36:00,485
Speaker 2:  Just show me a text message. Right. That's

660
00:36:00,485 --> 00:36:04,125
Speaker 3:  It. And that's where I think there's going to be AI potential. I don't think

661
00:36:04,125 --> 00:36:06,845
Speaker 3:  that's a killer. I don't think people buy them because they're, they have

662
00:36:06,985 --> 00:36:10,565
Speaker 3:  ai. Okay, that's fair. I's with you a little bit on the, like these gadgets

663
00:36:10,565 --> 00:36:14,365
Speaker 3:  are gonna get better and I've said repeatedly the meta glasses are the best

664
00:36:14,425 --> 00:36:16,805
Speaker 3:  AI gadget you can get because they're not only about ai.

665
00:36:17,505 --> 00:36:20,085
Speaker 2:  So, okay. Wait for you. We're gonna move on from this, but we should move

666
00:36:20,085 --> 00:36:23,285
Speaker 2:  on. But the, the, the raybans, it feels like it's the three things are

667
00:36:23,825 --> 00:36:27,745
Speaker 2:  camera, mic slash speaker. Yep. Ai,

668
00:36:27,925 --> 00:36:29,585
Speaker 2:  AI rank those three things for you personally.

669
00:36:29,845 --> 00:36:30,265
Speaker 3:  Camera,

670
00:36:33,335 --> 00:36:33,955
Speaker 3:  ai, audio.

671
00:36:34,835 --> 00:36:38,115
Speaker 2:  Interesting. So for me it's audio first by a mile. Oh, and that's what things

672
00:36:38,115 --> 00:36:41,555
Speaker 2:  and then camera and then ai. Yeah. Like I love them as like a pair of headphones

673
00:36:41,855 --> 00:36:44,475
Speaker 2:  or for making, thats what they say for making calls and stuff like, and,

674
00:36:44,495 --> 00:36:48,115
Speaker 2:  but I've found other people that are like, why would I just want to shout

675
00:36:48,135 --> 00:36:51,155
Speaker 2:  air into the air when I have Yeah. I can just wear AirPods. It'll be fine.

676
00:36:52,125 --> 00:36:54,035
Speaker 2:  Neela sent his back. So you don't get, you don't get to answer

677
00:36:54,035 --> 00:36:56,515
Speaker 4:  That. You don't think that this is gonna run into the I use it to play music

678
00:36:56,515 --> 00:36:57,475
Speaker 4:  and set timers problem.

679
00:36:58,135 --> 00:36:58,955
Speaker 3:  No, I think it might,

680
00:36:59,985 --> 00:37:01,365
Speaker 2:  But there are, there are worse things

681
00:37:04,585 --> 00:37:08,475
Speaker 4:  Like smart speakers we're supposed to do all these things and

682
00:37:08,505 --> 00:37:12,475
Speaker 4:  it's music and timers and you're like, oh, then this category kind of just

683
00:37:12,475 --> 00:37:12,715
Speaker 4:  died.

684
00:37:12,865 --> 00:37:15,035
Speaker 2:  Yeah. And now it's on my face. Yeah.

685
00:37:15,305 --> 00:37:18,835
Speaker 4:  Yeah. Like I don't know if there's a worse thing than the, we spent a lot

686
00:37:18,835 --> 00:37:20,195
Speaker 4:  of money to set Timer problem

687
00:37:21,075 --> 00:37:24,765
Speaker 2:  Fair. And I mean, Amazon has been trying to find places to put Alexa on your

688
00:37:24,765 --> 00:37:28,285
Speaker 2:  body for a long time and has not found it. Yeah. So, all right. We're, we're

689
00:37:28,285 --> 00:37:32,165
Speaker 2:  all in on the specific one of Meta is going to continue to outpace

690
00:37:32,165 --> 00:37:32,725
Speaker 2:  Apple on classes

691
00:37:33,105 --> 00:37:34,605
Speaker 4:  But only 'cause Apple's not gonna launch

692
00:39:20,705 --> 00:39:24,605
Speaker 2:  All right. We're back. Spicy takes, these are the ones, again,

693
00:39:24,975 --> 00:39:28,285
Speaker 2:  there should be a chance that this comes true, but if it does come true,

694
00:39:29,285 --> 00:39:33,225
Speaker 2:  you're not gonna shut up about it. Yep. Okay. Good. Yep. Everybody feel good?

695
00:39:33,645 --> 00:39:36,225
Speaker 2:  All right. I guess I get to go first this time.

696
00:39:38,005 --> 00:39:41,625
Speaker 2:  My spicy take for 2025 is that

697
00:39:41,905 --> 00:39:44,705
Speaker 2:  everyone is gonna give up on matter and bail on the smart home.

698
00:39:45,785 --> 00:39:49,645
Speaker 2:  And we're just gonna get to the end of the year and we're gonna

699
00:39:49,645 --> 00:39:53,405
Speaker 2:  have like, individual smart gadgets and that'll be fine. But this idea of

700
00:39:53,405 --> 00:39:57,085
Speaker 2:  like the, the big beautiful, interconnected smart home is going to cease

701
00:39:57,085 --> 00:39:58,925
Speaker 2:  to be interesting to almost everybody. Okay.

702
00:39:58,985 --> 00:40:01,605
Speaker 4:  Joanna, do you wanna respond to this As someone who just fixed your garage

703
00:40:01,855 --> 00:40:02,965
Speaker 4:  after weeks of effort?

704
00:40:03,025 --> 00:40:05,165
Speaker 2:  Oh yeah. We should talk about this actually. Oh, not garage. Can we just,

705
00:40:05,165 --> 00:40:08,885
Speaker 2:  let's do, told you I wouldn't let do, let's just do a one minute Joanna interlude

706
00:40:08,885 --> 00:40:11,005
Speaker 2:  on the garage because the, the people do want to know.

707
00:40:11,155 --> 00:40:13,645
Speaker 3:  Okay. Can we get a music? Yeah. Can we get a music track under here?

708
00:40:13,645 --> 00:40:14,685
Speaker 4:  You just assume there's music playing now.

709
00:40:14,835 --> 00:40:18,805
Speaker 3:  Okay. It's happy. Like it needs to be a happy track. Like a

710
00:40:18,805 --> 00:40:20,205
Speaker 3:  little bit like whimsical. You don't

711
00:40:20,225 --> 00:40:21,045
Speaker 2:  The Six Flags theme

712
00:40:21,045 --> 00:40:22,765
Speaker 4:  Song. I'll pick the music at a later time. You tell

713
00:40:24,385 --> 00:40:24,605
Speaker 2:  I'm

714
00:40:24,605 --> 00:40:27,525
Speaker 3:  Producing, I'm producing, I'm producing right now.

715
00:40:29,605 --> 00:40:30,185
Speaker 3:  It happened.

716
00:40:31,805 --> 00:40:35,305
Speaker 3:  My garage now opens. I can't say it because if I do

717
00:40:35,605 --> 00:40:39,515
Speaker 3:  my, my phone will open my garage at

718
00:40:39,515 --> 00:40:42,955
Speaker 3:  home. But when I say, hey blank,

719
00:40:43,785 --> 00:40:47,615
Speaker 3:  open the garage. It happens. This is

720
00:40:47,615 --> 00:40:51,135
Speaker 3:  after many weeks of texts to Eli

721
00:40:51,595 --> 00:40:55,335
Speaker 3:  who responded three minutes Exactly after because

722
00:40:55,475 --> 00:40:59,135
Speaker 3:  he scheduled them. Yep. This is after many weeks of people

723
00:40:59,305 --> 00:41:02,975
Speaker 3:  responding on threads. Thank you all your all to all your

724
00:41:02,975 --> 00:41:03,495
Speaker 3:  listeners.

725
00:41:04,565 --> 00:41:07,025
Speaker 2:  We got a lot of feedback on the garage

726
00:41:07,025 --> 00:41:08,505
Speaker 3:  Door, which Yes. And I would like to apologize.

727
00:41:08,505 --> 00:41:11,185
Speaker 2:  Which range from you idiot. This is simple to, this is the hardest problem

728
00:41:11,205 --> 00:41:12,185
Speaker 2:  in the history of the universe.

729
00:41:12,505 --> 00:41:15,945
Speaker 4:  Outright conspiracy theories about cred FI's garage. Yes.

730
00:41:16,095 --> 00:41:19,745
Speaker 3:  Well I believe those now I I've come to, I I

731
00:41:19,745 --> 00:41:23,065
Speaker 3:  understand this landscape better than anybody. Yes. Maybe not as well as

732
00:41:23,065 --> 00:41:23,145
Speaker 3:  you.

733
00:41:24,715 --> 00:41:28,095
Speaker 3:  And it is a very hard problem to solve. So those people that call me an idiot,

734
00:41:28,155 --> 00:41:29,335
Speaker 3:  you are actually an idiot,

735
00:41:31,675 --> 00:41:34,365
Speaker 3:  but I just thank you to the listeners. You did it though. I

736
00:41:34,365 --> 00:41:35,165
Speaker 4:  Did it. What'd you have to do?

737
00:41:35,345 --> 00:41:37,205
Speaker 3:  Oh, we can't, it's too long. It's longer than a minute.

738
00:41:37,235 --> 00:41:38,885
Speaker 4:  Just explain the little adapter that they sang.

739
00:41:38,995 --> 00:41:42,855
Speaker 3:  Okay. I got the Miros Miros. What? How do you

740
00:41:42,855 --> 00:41:43,135
Speaker 3:  pronounce it?

741
00:41:43,255 --> 00:41:44,335
Speaker 4:  I think I always say Miros.

742
00:41:44,545 --> 00:41:48,295
Speaker 3:  Miros. Okay. I got the Miros adapter. I get up on a ladder. I sent Eli a

743
00:41:48,295 --> 00:41:52,135
Speaker 3:  picture. I was wearing my meta ray bands for both music and

744
00:41:52,155 --> 00:41:55,535
Speaker 3:  for just taking photos and video of it. Therapy. Therapy.

745
00:41:56,115 --> 00:41:59,655
Speaker 3:  It was using the calm app. Then we should get them as a sponsor.

746
00:41:59,875 --> 00:42:03,695
Speaker 3:  That's a good idea. Yeah. I get up there, I get everything all set,

747
00:42:04,405 --> 00:42:07,735
Speaker 3:  plug in into the sensor, put the sensor on the door. There's the whole complicated

748
00:42:07,965 --> 00:42:11,855
Speaker 3:  kind of wiring, not that and it doesn't work. And

749
00:42:11,855 --> 00:42:15,575
Speaker 3:  it turns out because my lift master is a newer

750
00:42:15,845 --> 00:42:19,815
Speaker 3:  lift master from 2018, it is using some proprietary

751
00:42:20,175 --> 00:42:23,855
Speaker 3:  protocol to talk to the door opener on the wall and it will not work. So

752
00:42:23,945 --> 00:42:27,455
Speaker 4:  Dudes, they have DR md the garage door button and they have

753
00:42:28,445 --> 00:42:30,415
Speaker 4:  labeled it a security feature.

754
00:42:30,955 --> 00:42:31,175
Speaker 3:  And

755
00:42:31,485 --> 00:42:35,375
Speaker 4:  It's very good. I, because I'm opening the door as a security feature.

756
00:42:35,375 --> 00:42:36,295
Speaker 4:  Your garage door button.

757
00:42:36,775 --> 00:42:40,135
Speaker 3:  I guess there was a way I could have known this earlier. Yeah. But I didn't

758
00:42:40,135 --> 00:42:44,055
Speaker 3:  like go through all the support forums to know, because my learn button on

759
00:42:44,055 --> 00:42:47,975
Speaker 3:  my lift master is yellow. And it turns out If you have the yellow button,

760
00:42:48,475 --> 00:42:49,935
Speaker 3:  you cannot use this.

761
00:42:50,085 --> 00:42:51,135
Speaker 4:  Then you have a DRM.

762
00:42:51,475 --> 00:42:55,295
Speaker 3:  But Miros, the geniuses at Miros who I've not gotten

763
00:42:55,295 --> 00:42:58,175
Speaker 3:  in touch with, but you are great people,

764
00:42:59,135 --> 00:43:03,125
Speaker 3:  great people. They made a little adapter, which is really

765
00:43:03,125 --> 00:43:06,965
Speaker 3:  just the opener, like the opener you'd put in your like car.

766
00:43:07,635 --> 00:43:11,525
Speaker 3:  It's a hacked opener that connects to the Miros. And So

767
00:43:11,565 --> 00:43:15,205
Speaker 3:  I didn't, I get it. They sent it to me in the mail and one week, again,

768
00:43:15,415 --> 00:43:18,085
Speaker 3:  thank you to the people at Miros. Please sponsor this podcast.

769
00:43:20,125 --> 00:43:20,805
Speaker 3:  I just love them.

770
00:43:21,405 --> 00:43:24,005
Speaker 4:  Apparently they don't have enough money.

771
00:43:25,075 --> 00:43:28,285
Speaker 4:  They're, they're making one hacked garage door repair a time,

772
00:43:28,825 --> 00:43:32,725
Speaker 3:  One a day for me. Anyway, they send this to me, I set it

773
00:43:32,725 --> 00:43:34,285
Speaker 3:  up and it works perfectly. Now

774
00:43:34,605 --> 00:43:37,645
Speaker 4:  I just, can I, can I explain what's happening? I sent Joanna like a paragraph

775
00:43:37,795 --> 00:43:41,445
Speaker 4:  excited paragraph of nerd speak. So they're like, okay we can't

776
00:43:41,835 --> 00:43:45,685
Speaker 4:  Yeah, push the hardwired button 'cause it's dmd. Yes. But we can take a regular

777
00:43:45,745 --> 00:43:49,485
Speaker 4:  garage door opener that is DRM

778
00:43:49,485 --> 00:43:53,325
Speaker 4:  compatible with this and we'll just put a wire in the actual button

779
00:43:53,345 --> 00:43:57,125
Speaker 4:  of that garage door opener. Oh wow. So that when you tell Siri to

780
00:43:57,365 --> 00:44:01,285
Speaker 4:  I open the thing. Yes. It just does that. We'll push the button on the garage

781
00:44:01,365 --> 00:44:04,925
Speaker 4:  door opener. So I just that from start coming out a garage door opener should

782
00:44:04,925 --> 00:44:08,805
Speaker 4:  done from 'cause that is crazy. Can you imagine Craig Federighi

783
00:44:08,875 --> 00:44:12,685
Speaker 4:  knowing any of this information when he's like, the future of

784
00:44:12,785 --> 00:44:15,165
Speaker 4:  AI is my smart home. This is validating data.

785
00:44:15,165 --> 00:44:17,725
Speaker 3:  I just wanna entire prediction tell that I told you I wouldn't do this and

786
00:44:17,725 --> 00:44:20,365
Speaker 3:  I did not wanna go down this route. I just wanted to thank everyone and tell

787
00:44:20,365 --> 00:44:21,205
Speaker 3:  them about my success.

788
00:44:21,975 --> 00:44:23,165
Speaker 4:  She's very proud of her. I'm psyched

789
00:44:23,165 --> 00:44:24,845
Speaker 3:  For, I'm very proud of myself. I now have Can

790
00:44:24,845 --> 00:44:28,245
Speaker 4:  You, can you explain the, the one bug that you had to explain to me, which

791
00:44:28,245 --> 00:44:30,285
Speaker 4:  is perfect. It didn't work right away. And why?

792
00:44:32,075 --> 00:44:34,605
Speaker 3:  Well that was with the, oh no, that was with that.

793
00:44:35,275 --> 00:44:35,565
Speaker 4:  It's

794
00:44:35,565 --> 00:44:38,725
Speaker 3:  Very good. Okay. So I go away. Well I don't even know why I was, I was in

795
00:44:38,745 --> 00:44:41,965
Speaker 3:  LA and I set everything up and I thought it's working perfectly.

796
00:44:42,665 --> 00:44:46,325
Speaker 3:  But yet the garage door keeps opening and closing randomly.

797
00:44:46,465 --> 00:44:50,285
Speaker 3:  And my wife is texting me saying, who is opening and closing the garage door?

798
00:44:50,785 --> 00:44:54,685
Speaker 3:  And I'm like, I, not me. It should be working. It turns out

799
00:44:54,685 --> 00:44:58,365
Speaker 3:  when I pressed the learn button, it started picking up some signal

800
00:44:58,475 --> 00:45:01,845
Speaker 3:  from someone around the neighborhood. So whenever they opened their garage,

801
00:45:01,985 --> 00:45:05,925
Speaker 3:  oh my God, it opened my garage, which almost

802
00:45:06,025 --> 00:45:09,445
Speaker 3:  led to divorce. So I had to get a garage guy

803
00:45:10,545 --> 00:45:12,325
Speaker 3:  who then came to the house, helped me

804
00:45:12,325 --> 00:45:13,045
Speaker 4:  Fix it. He's very, the song perfect.

805
00:45:14,275 --> 00:45:15,295
Speaker 3:  And now it all works perfect.

806
00:45:15,595 --> 00:45:18,375
Speaker 2:  All because you can't be bothered to push the button Yes. When you pull into

807
00:45:18,375 --> 00:45:19,055
Speaker 2:  the driveway. But

808
00:45:19,055 --> 00:45:22,535
Speaker 3:  You know what the amount, like this is where we need some music.

809
00:45:23,675 --> 00:45:27,575
Speaker 3:  The amount of happiness and true pride. I feel now

810
00:45:27,605 --> 00:45:31,215
Speaker 3:  when I pull out of my garage and say, Hey

811
00:45:31,405 --> 00:45:35,295
Speaker 3:  Siri, open the garage door is, I may

812
00:45:35,295 --> 00:45:36,215
Speaker 3:  have never felt it before.

813
00:45:36,315 --> 00:45:39,295
Speaker 2:  And then 15 minutes later it just starts randomly closing and opening on

814
00:45:39,295 --> 00:45:39,495
Speaker 2:  its own.

815
00:45:40,325 --> 00:45:43,215
Speaker 3:  That hasn't happened in at least two weeks. That's,

816
00:45:43,435 --> 00:45:47,295
Speaker 2:  I'm thrilled for you. We really, the smart home is getting to the point

817
00:45:47,315 --> 00:45:50,935
Speaker 2:  of humanoid robots to stand in your garage and push buttons. And that

818
00:45:50,935 --> 00:45:53,815
Speaker 4:  Is stupid. Yeah, that's by the way, this is door bot. Yes. You could have

819
00:45:53,815 --> 00:45:56,375
Speaker 4:  just put a door bot on the actual garage door button.

820
00:45:56,675 --> 00:46:00,255
Speaker 3:  But just back to what you're saying, this is why I don't think, I mean

821
00:46:00,255 --> 00:46:01,295
Speaker 4:  Switch bot, not door bot,

822
00:46:01,575 --> 00:46:04,935
Speaker 3:  I don't think Matter disappears. I think we actually see these tech companies

823
00:46:04,935 --> 00:46:08,135
Speaker 3:  double down on it. I think they're all gonna start talking about how AI is

824
00:46:08,135 --> 00:46:11,295
Speaker 3:  gonna be great for the smart home. And we're gonna hear it with that Alexa

825
00:46:11,575 --> 00:46:14,615
Speaker 3:  announcement. It's just like all these things and this is the dream and our

826
00:46:14,675 --> 00:46:18,535
Speaker 3:  robots and the, and the house is connected and none of it is actually

827
00:46:18,535 --> 00:46:22,215
Speaker 3:  really material to real people because they have old

828
00:46:22,245 --> 00:46:26,095
Speaker 3:  shit and they have different standards. And

829
00:46:26,095 --> 00:46:29,175
Speaker 3:  there's DRM in the freaking button on the wall

830
00:46:30,195 --> 00:46:33,455
Speaker 3:  and it doesn't work. And I think we're gonna hear from Apple this year because

831
00:46:33,455 --> 00:46:36,655
Speaker 3:  they're apparently working on this home tablet. And I think they're gonna

832
00:46:36,655 --> 00:46:38,255
Speaker 3:  push matter and they're gonna say it's, they have

833
00:46:38,255 --> 00:46:39,935
Speaker 4:  To push, they have no choice but to push matters. Right.

834
00:46:40,235 --> 00:46:41,255
Speaker 3:  And no becausecause,

835
00:46:41,255 --> 00:46:43,455
Speaker 4:  They not an e system of these devices matters.

836
00:46:43,475 --> 00:46:45,375
Speaker 3:  And a lot of these devices don't even have matter.

837
00:46:45,765 --> 00:46:46,695
Speaker 4:  Yeah, yeah.

838
00:46:46,735 --> 00:46:47,155
Speaker 3:  Anyway.

839
00:46:47,535 --> 00:46:48,995
Speaker 4:  You just think they're gonna give up. You think,

840
00:46:49,435 --> 00:46:51,835
Speaker 2:  I don't know that they're gonna, I just think everyone is going to stop caring

841
00:46:52,415 --> 00:46:54,075
Speaker 2:  in in every me like I

842
00:46:54,075 --> 00:46:55,635
Speaker 3:  Think they did. Stop caring maybe.

843
00:46:56,175 --> 00:46:59,715
Speaker 2:  But I, I like even the companies themselves who have been making these

844
00:47:00,545 --> 00:47:03,955
Speaker 2:  long elaborate bets that eventually the smart home is going to become a thing

845
00:47:03,955 --> 00:47:07,035
Speaker 2:  that is like mainstream useful. I think everybody's just gonna start walking

846
00:47:07,035 --> 00:47:09,435
Speaker 2:  away from that next year. It's 'cause it's just not gonna happen.

847
00:47:09,785 --> 00:47:11,395
Speaker 3:  Yeah. I mean when you get a new house

848
00:47:11,405 --> 00:47:14,715
Speaker 2:  Light switches kick ass, it's probably fine. We've probably solved light

849
00:47:14,955 --> 00:47:16,715
Speaker 2:  switches. I don't know that we need to worry about them anymore.

850
00:47:17,055 --> 00:47:20,835
Speaker 4:  No. Enough of the light switches in our house are are smart and

851
00:47:20,935 --> 00:47:24,795
Speaker 4:  do things. Yeah. Just all on their own. That

852
00:47:24,995 --> 00:47:28,765
Speaker 4:  actually, once you get used to it, you're like, oh, this rules. Yeah. Right.

853
00:47:28,765 --> 00:47:32,245
Speaker 4:  Like there's one level up, we're like, oh this is great.

854
00:47:32,785 --> 00:47:35,925
Speaker 2:  My Rube Goldberg machine works really well is like a perfectly viable,

855
00:47:36,075 --> 00:47:38,805
Speaker 4:  It's not a Rub Goldberg machine. It's, it's, they're just, I just bought

856
00:47:38,805 --> 00:47:42,605
Speaker 4:  some Lutron Cas and put them in the wall and now when the sun sets

857
00:47:43,025 --> 00:47:43,885
Speaker 4:  our house slice,

858
00:47:43,885 --> 00:47:44,885
Speaker 3:  Will they sponsor this podcast?

859
00:47:45,285 --> 00:47:48,525
Speaker 4:  I don't know. Well, they, they have so much money that they own a custom

860
00:47:48,575 --> 00:47:52,405
Speaker 4:  slice of RF spectrum, which is why their products work the best. Oh, there

861
00:47:52,405 --> 00:47:54,885
Speaker 4:  go. It's a real thing, but I don't know if they wanna spend the money.

862
00:47:55,145 --> 00:47:57,685
Speaker 3:  You like those don't even go on sale. Black Fri they just don't go on sale.

863
00:47:58,515 --> 00:48:01,285
Speaker 4:  Yeah. 'cause they have their own RF spectrum and they have the best problem.

864
00:48:01,525 --> 00:48:02,085
Speaker 2:  What are you gonna do?

865
00:48:02,835 --> 00:48:06,125
Speaker 4:  This is a real thing. They bought their own slice of RF spectrum that Brendan

866
00:48:06,275 --> 00:48:09,485
Speaker 4:  Carr Trump's new commissioner of the FCC is gonna turn over to Elon Musk

867
00:48:09,715 --> 00:48:12,085
Speaker 3:  When you interview him. I want you to ask about Lutron Casitas.

868
00:48:12,085 --> 00:48:15,775
Speaker 4:  Brendan, if you're listening and I know you are, come on the, come on the

869
00:48:15,775 --> 00:48:16,295
Speaker 4:  show. Yeah.

870
00:48:18,075 --> 00:48:19,095
Speaker 2:  I'd, we'd love to have you tell

871
00:48:19,095 --> 00:48:20,335
Speaker 4:  Me how your garage door works. All right.

872
00:48:20,355 --> 00:48:24,045
Speaker 3:  You If you own a house. I do. You own a house? Yeah. Okay. I was gonna say

873
00:48:24,045 --> 00:48:27,285
Speaker 3:  like, if this is the year 2025 that David buys a house,

874
00:48:28,045 --> 00:48:31,925
Speaker 4:  Actually a good, a good prediction here, like an ancillary prediction to

875
00:48:31,925 --> 00:48:35,445
Speaker 4:  yours is no one will come up with a smart home idea that compels you,

876
00:48:35,445 --> 00:48:38,925
Speaker 4:  David Pierce, owner of the most garbage TV in America

877
00:48:39,665 --> 00:48:41,565
Speaker 4:  to do any smart home thing. Yeah.

878
00:48:42,205 --> 00:48:43,125
Speaker 2:  I love that. Right.

879
00:48:43,185 --> 00:48:46,845
Speaker 4:  That's the, because like I have a whole smart home. It's just doing stuff

880
00:48:46,865 --> 00:48:47,285
Speaker 4:  all the time.

881
00:48:47,625 --> 00:48:51,605
Speaker 3:  And I'm slowly trying to be neli like he's my, he's

882
00:48:51,605 --> 00:48:52,765
Speaker 3:  my mentor of the smart home.

883
00:48:52,995 --> 00:48:56,845
Speaker 2:  Neli has never once described a use case and an amount

884
00:48:56,845 --> 00:48:59,685
Speaker 2:  of work to get to that use case that has ever made sense to me.

885
00:48:59,925 --> 00:49:02,685
Speaker 3:  I just described the garage to you and it is perfect.

886
00:49:02,835 --> 00:49:04,365
Speaker 4:  It's, it's super not good enough.

887
00:49:05,465 --> 00:49:09,285
Speaker 3:  It is so good. What do you mean? I just sat next

888
00:49:09,285 --> 00:49:13,125
Speaker 2:  To you. My wife texted me and said, why is the garage door

889
00:49:13,125 --> 00:49:14,485
Speaker 2:  opening and closing by itself?

890
00:49:16,265 --> 00:49:16,925
Speaker 3:  But then our wives

891
00:49:17,105 --> 00:49:18,805
Speaker 2:  Can talk to each other. It not applicable solution to my house.

892
00:49:19,465 --> 00:49:23,205
Speaker 4:  You don't, you don't want to build a relationship on that. That's not the

893
00:49:23,205 --> 00:49:25,245
Speaker 4:  foundation of relationship. That's good for anyone's marriage.

894
00:49:25,275 --> 00:49:28,005
Speaker 2:  It's, it's bad times all the way around. Alright, so you're, you're both

895
00:49:28,065 --> 00:49:29,325
Speaker 2:  out on mine. This is great,

896
00:49:30,865 --> 00:49:31,645
Speaker 2:  Joanna. I do

897
00:49:31,645 --> 00:49:34,805
Speaker 3:  Be, I mean, I do believe it's gonna be a big topic next year. So

898
00:49:36,245 --> 00:49:36,665
Speaker 3:  that's,

899
00:49:37,225 --> 00:49:38,105
Speaker 2:  I hope So. I mean,

900
00:49:38,105 --> 00:49:41,865
Speaker 4:  To be clear, David's prediction is everyone walks away from matter. That's

901
00:49:41,865 --> 00:49:43,665
Speaker 4:  your specific prediction. I, I'm out. Yeah. I

902
00:49:43,665 --> 00:49:44,385
Speaker 3:  Don't think that matter.

903
00:49:44,385 --> 00:49:44,625
Speaker 4:  They're,

904
00:49:44,625 --> 00:49:46,505
Speaker 3:  They're all in on it. Great. Yeah, they can't, they have nothing else to

905
00:49:46,505 --> 00:49:50,265
Speaker 3:  do. I wish. I mean, I don't wish, I don't, I, anyway, okay. My spicy

906
00:49:50,445 --> 00:49:50,665
Speaker 3:  one,

907
00:49:52,375 --> 00:49:53,955
Speaker 3:  the Mac gets a touch screen.

908
00:49:54,375 --> 00:49:57,115
Speaker 4:  Oh, we've done this like every year. I know. Every time we've done predictions

909
00:49:57,275 --> 00:49:58,515
Speaker 4:  together, someone has done this. I know.

910
00:49:58,775 --> 00:50:02,755
Speaker 3:  And we'll go, I think I'm trying to find The Vergecast transcripts of the

911
00:50:02,755 --> 00:50:06,195
Speaker 3:  time I predicted and I can't find it, but I believe I said by the end of

912
00:50:06,195 --> 00:50:06,795
Speaker 3:  2024,

913
00:50:07,955 --> 00:50:10,835
Speaker 4:  I think the last time we did this, we, we set timelines and we were all wrong.

914
00:50:10,935 --> 00:50:14,875
Speaker 3:  We were, Dieter was on the, on the podcast. Yeah. And, but I,

915
00:50:14,955 --> 00:50:18,795
Speaker 3:  I, I, I think we are coming towards that time.

916
00:50:19,575 --> 00:50:21,195
Speaker 3:  One day we will get there and I I think

917
00:50:21,455 --> 00:50:25,315
Speaker 2:  25, is it just a Mac as you currently imagine it, but

918
00:50:25,315 --> 00:50:28,475
Speaker 2:  it's a touchscreen? Or does it change more meaningfully than that?

919
00:50:29,355 --> 00:50:30,565
Speaker 3:  They'll have to do something.

920
00:50:31,115 --> 00:50:31,725
Speaker 2:  What do they do?

921
00:50:34,245 --> 00:50:34,365
Speaker 3:  I

922
00:50:34,365 --> 00:50:35,725
Speaker 2:  Don't know. Does it run iPad apps?

923
00:50:37,115 --> 00:50:37,815
Speaker 3:  It already runs

924
00:50:37,815 --> 00:50:41,095
Speaker 2:  IPad apps. Well, like, like does it just get the iPad app store natively?

925
00:50:42,345 --> 00:50:44,485
Speaker 3:  Mm. No, I think they just keep it that way. Okay.

926
00:50:46,405 --> 00:50:49,905
Speaker 2:  I'm just looking at these touch targets being like, eh, I don't really want

927
00:50:50,105 --> 00:50:51,705
Speaker 2:  to poke my menu bar that. Yeah.

928
00:50:51,945 --> 00:50:54,185
Speaker 4:  I don't think they do it until they know why they're doing it. I wanna scroll

929
00:50:54,205 --> 00:50:58,065
Speaker 4:  and I don't know that they even know why they make the iPad. Right.

930
00:50:58,365 --> 00:51:01,505
Speaker 4:  Do you like the I the iPad is an application environment. They're not like,

931
00:51:01,505 --> 00:51:04,505
Speaker 4:  here's why. They're just like, well, that keeps happening.

932
00:51:05,325 --> 00:51:07,985
Speaker 4:  And they, I don't think they're gonna add cost and complexity to the Mac

933
00:51:07,985 --> 00:51:11,945
Speaker 4:  unless they have like a great reason to do it. And they seem to

934
00:51:11,945 --> 00:51:15,805
Speaker 4:  be selling enough Macs. I'm walking this all the way back. 'cause I thought,

935
00:51:15,805 --> 00:51:17,725
Speaker 4:  but you don't think were gonna do it. I thought I, the last time we did this,

936
00:51:17,925 --> 00:51:21,485
Speaker 4:  I thought that they had reached a point with the Mac and the iPad where

937
00:51:22,245 --> 00:51:25,365
Speaker 4:  bringing them closer together was the only choice. Yep. And they have not

938
00:51:25,365 --> 00:51:29,045
Speaker 4:  only resisted that, they pulled them further apart to the point where everyone's

939
00:51:29,045 --> 00:51:30,725
Speaker 4:  just like turned this iPad into a Mac.

940
00:51:31,915 --> 00:51:35,735
Speaker 2:  I think Apple silicon changed that. Like I think if, if Apple

941
00:51:36,015 --> 00:51:39,815
Speaker 2:  hadn't solved like laptop processing,

942
00:51:40,715 --> 00:51:43,175
Speaker 2:  it would've been different and the Macs would've started to look more like

943
00:51:43,675 --> 00:51:47,375
Speaker 2:  the iPads and vice versa. But now, like the, the

944
00:51:48,035 --> 00:51:51,695
Speaker 2:  Mac lineup is easily the best it's ever been. Yeah. And

945
00:51:51,995 --> 00:51:55,935
Speaker 2:  is so compelling to so many people. Like Yeah. I I tend to

946
00:51:55,935 --> 00:51:59,455
Speaker 2:  agree. I, I years ago would've thought that eventually the

947
00:51:59,485 --> 00:52:01,935
Speaker 2:  MacBook and the iPad in particular would eventually be the same product.

948
00:52:02,615 --> 00:52:03,495
Speaker 2:  I don't think that anymore.

949
00:52:03,695 --> 00:52:07,295
Speaker 4:  I think i I the spicy follow up,

950
00:52:08,175 --> 00:52:11,575
Speaker 4:  whatever that is, the dip conman hot sauce.

951
00:52:12,675 --> 00:52:16,255
Speaker 4:  If, If you could turn your Mac into an

952
00:52:16,485 --> 00:52:20,325
Speaker 4:  iPad and gain touchscreen support Yes. Or you could turn

953
00:52:20,325 --> 00:52:23,845
Speaker 4:  your iPad into a Mac in the lose touchscreen support, which one would you,

954
00:52:24,015 --> 00:52:25,045
Speaker 4:  which one would you pick?

955
00:52:25,775 --> 00:52:28,255
Speaker 3:  I can take my Mac. What was the first option?

956
00:52:28,315 --> 00:52:30,695
Speaker 4:  So you have your Mac sitting right here. Yes. And I can take it up and I

957
00:52:30,695 --> 00:52:32,735
Speaker 4:  can push a button and be like, now this is an iPad and you get a touch screen

958
00:52:32,835 --> 00:52:33,135
Speaker 4:  and I

959
00:52:33,135 --> 00:52:34,015
Speaker 3:  Can take the screen off.

960
00:52:34,155 --> 00:52:37,695
Speaker 4:  No. Whatever. It's, it's just that it can run iPad apps, but it has a touchscreen.

961
00:52:37,695 --> 00:52:40,295
Speaker 4:  Yeah. It's an iPad. And the other one is you got an iPad and a keyboard case

962
00:52:40,515 --> 00:52:44,255
Speaker 4:  and you're like, boom, hit a button. It runs Macs but the touchscreen

963
00:52:44,255 --> 00:52:44,775
Speaker 4:  stops working.

964
00:52:45,165 --> 00:52:45,615
Speaker 2:  It's that,

965
00:52:46,255 --> 00:52:46,375
Speaker 3:  I

966
00:52:46,375 --> 00:52:47,135
Speaker 4:  Guess that, see what I'm

967
00:52:47,135 --> 00:52:50,175
Speaker 2:  Saying? I want a dockable iPad much more than I want a Touch Mac.

968
00:52:50,525 --> 00:52:50,815
Speaker 3:  Yeah.

969
00:52:51,805 --> 00:52:52,095
Speaker 4:  Yeah.

970
00:52:52,155 --> 00:52:55,295
Speaker 2:  And there's a bunch of stuff you have to do. Like, it, it would have to essentially

971
00:52:55,295 --> 00:52:59,015
Speaker 2:  like run the two operating systems side by side. No,

972
00:52:59,015 --> 00:53:02,975
Speaker 4:  I'm saying I'm, I'm, I'm making this hardcore. Okay. You push

973
00:53:02,975 --> 00:53:05,615
Speaker 4:  the button. This is now runs iPad os Yeah.

974
00:53:06,045 --> 00:53:07,015
Speaker 2:  With a touchscreen. With

975
00:53:07,015 --> 00:53:08,935
Speaker 4:  A touchscreen. With it Doesn it's a Mac. Right. But

976
00:53:08,935 --> 00:53:11,455
Speaker 3:  Then when you run Mac os it disables the touchscreen.

977
00:53:11,955 --> 00:53:15,935
Speaker 4:  No, it doesn't run Mac os I'm saying this just becomes an iPad. Mm.

978
00:53:16,195 --> 00:53:19,935
Speaker 4:  Or you could take your iPad and you can run Mac Os and it disables the touchscreen.

979
00:53:19,935 --> 00:53:20,255
Speaker 4:  Which

980
00:53:20,255 --> 00:53:22,015
Speaker 2:  One? It's definitely an iPad with Mac os.

981
00:53:22,195 --> 00:53:23,095
Speaker 4:  See what I'm saying? And I think,

982
00:53:23,515 --> 00:53:23,735
Speaker 3:  No

983
00:53:23,815 --> 00:53:27,205
Speaker 4:  Question. Same. This is just the end of the argument I think for a long time.

984
00:53:27,485 --> 00:53:30,125
Speaker 4:  'cause they don't know why any, they don't know why any of these products

985
00:53:30,125 --> 00:53:30,725
Speaker 4:  have touchscreens.

986
00:53:31,165 --> 00:53:31,405
Speaker 2:  Right.

987
00:53:32,105 --> 00:53:35,405
Speaker 4:  Except for the iPhone. I I know why the iPhone has a touchscreen. They have

988
00:53:35,405 --> 00:53:36,845
Speaker 4:  not yet solved the problem of why the iPad

989
00:53:36,845 --> 00:53:40,765
Speaker 3:  Has. So maybe I'm changing mine to that the iPad can

990
00:53:40,765 --> 00:53:41,605
Speaker 3:  run Mac os.

991
00:53:42,075 --> 00:53:43,605
Speaker 4:  Yeah. That's the only rational answer.

992
00:53:43,685 --> 00:53:47,295
Speaker 3:  Okay. But that to me, it seems the same thing. Mac gets a touchscreen still

993
00:53:47,295 --> 00:53:48,495
Speaker 3:  Mac os getting a touchscreen. I'll

994
00:53:48,495 --> 00:53:51,335
Speaker 2:  Give, I'll give you both as one prediction. Okay. That, that one of those

995
00:53:51,335 --> 00:53:54,535
Speaker 2:  two things will happen. That the, the, the Mac, Mac I, Mac, I mean it's really,

996
00:53:54,535 --> 00:53:58,325
Speaker 2:  it's like the Venn diagram, the Mac, that's why Mac and the iPad smash into

997
00:53:58,325 --> 00:53:58,845
Speaker 2:  each other. I

998
00:53:58,845 --> 00:54:01,165
Speaker 4:  Think they have figured out they can sell a lot of both. Yes. And they don't

999
00:54:01,165 --> 00:54:03,685
Speaker 4:  have to solve this problem and there's no pressure on them to solve the problem

1000
00:54:04,495 --> 00:54:07,685
Speaker 4:  until there's some sort of Windows tablet or Android tablet

1001
00:54:08,355 --> 00:54:12,205
Speaker 4:  that print provides an ounce of competition to the iPad. And I know, like

1002
00:54:12,245 --> 00:54:14,925
Speaker 4:  I know there are Windows tablets and people like them and the surface exists

1003
00:54:14,925 --> 00:54:17,965
Speaker 4:  and that's a whole thing. They're not competition to the iPad. There are

1004
00:54:17,965 --> 00:54:18,885
Speaker 4:  competition to the MacBook,

1005
00:54:18,905 --> 00:54:19,605
Speaker 3:  To the Mac. Yeah.

1006
00:54:19,615 --> 00:54:23,605
Speaker 4:  Until there's one sliver of competition for the things that people use

1007
00:54:23,655 --> 00:54:26,325
Speaker 4:  iPads for, they are just gonna stay exactly the way they're

1008
00:54:27,695 --> 00:54:28,535
Speaker 2:  I didn't agree. Yeah.

1009
00:54:28,805 --> 00:54:30,855
Speaker 3:  Yeah. I was my other spicy one.

1010
00:54:30,855 --> 00:54:32,095
Speaker 2:  You can't talk yourself out of your own connection.

1011
00:54:32,255 --> 00:54:34,695
Speaker 3:  No, no. My other, no, I really want that to happen. That's why it's spicy

1012
00:54:34,715 --> 00:54:37,655
Speaker 3:  and that's why it's there. But my other spicy was gonna be that Tim Cook

1013
00:54:37,655 --> 00:54:41,055
Speaker 3:  steps down and then they, the Mac gets the touchscreen.

1014
00:54:41,275 --> 00:54:43,055
Speaker 4:  Ooh. Tim Cook can't step down, I don't think

1015
00:54:43,195 --> 00:54:45,375
Speaker 3:  On president. Don't think I know. It's like, it's, it's really

1016
00:54:45,405 --> 00:54:47,375
Speaker 4:  He's gotta call him every day and be like, like, I need you to not

1017
00:54:47,375 --> 00:54:48,655
Speaker 3:  Do these tariffs. No, I think they just broaden.

1018
00:54:48,655 --> 00:54:51,175
Speaker 4:  Do you understand what I'm saying, Donald? That this time you cannot do tariffs.

1019
00:54:51,175 --> 00:54:55,015
Speaker 4:  You like your iPhone, right? I can turn that off. No tariffs. And he's just

1020
00:54:55,015 --> 00:54:56,095
Speaker 4:  gotta do that every single day.

1021
00:54:56,925 --> 00:55:00,885
Speaker 2:  Yeah. All right. Last, and these has to stay Neli. What is

1022
00:55:00,885 --> 00:55:01,925
Speaker 2:  your spiciest prediction?

1023
00:55:02,445 --> 00:55:02,725
Speaker 4:  This is

1024
00:55:02,725 --> 00:55:05,565
Speaker 2:  Wild. Full spice. This is wild. Hit me with it. Google

1025
00:55:05,565 --> 00:55:06,645
Speaker 4:  Breaks itself up.

1026
00:55:07,425 --> 00:55:07,645
Speaker 2:  Oh,

1027
00:55:10,235 --> 00:55:14,205
Speaker 4:  Okay. They're just like, you know what? This is not worth it anymore. We're

1028
00:55:14,205 --> 00:55:17,245
Speaker 4:  just gonna, we're gonna, we're gonna spin off our own companies.

1029
00:55:17,315 --> 00:55:17,605
Speaker 2:  Okay.

1030
00:55:18,155 --> 00:55:21,725
Speaker 4:  This is the opposite of merger mania, which is a thing big

1031
00:55:22,045 --> 00:55:26,005
Speaker 4:  companies do to create shareholder value. Sure. When they're out

1032
00:55:26,005 --> 00:55:29,735
Speaker 4:  of ideas, I think Google is just gonna look at the marketplace

1033
00:55:30,115 --> 00:55:33,415
Speaker 4:  and say that we're under a lot of regulatory pressure. And you know what

1034
00:55:33,415 --> 00:55:35,375
Speaker 4:  if we just spun off YouTube,

1035
00:55:36,975 --> 00:55:40,825
Speaker 4:  just put it over there, signed a big lucrative AI training data

1036
00:55:40,825 --> 00:55:44,705
Speaker 4:  deal for Google AI and let this thing go be cable, the future

1037
00:55:44,725 --> 00:55:48,265
Speaker 4:  of cable television and compete with TikTok and whatever.

1038
00:55:49,245 --> 00:55:52,825
Speaker 4:  And we'll, that'll go public and the stock will go up and Google stock will

1039
00:55:52,825 --> 00:55:56,185
Speaker 4:  go up and everyone's stock will go up. And that's all anybody cares about.

1040
00:55:57,125 --> 00:56:00,995
Speaker 4:  You can make the argument today absent the antitrust pressure and

1041
00:56:01,015 --> 00:56:04,195
Speaker 4:  you get to take YouTube away from the antitrust pressure. Right. And the

1042
00:56:04,395 --> 00:56:05,435
Speaker 4:  regulatory pressure, because now it's just

1043
00:56:05,435 --> 00:56:08,075
Speaker 2:  YouTube. Does that solve? But does that Yeah. Google's antitrust problems

1044
00:56:08,075 --> 00:56:08,235
Speaker 2:  though.

1045
00:56:08,395 --> 00:56:10,315
Speaker 4:  I have no idea. This is my spicy take. Okay.

1046
00:56:10,335 --> 00:56:10,675
Speaker 2:  But like,

1047
00:56:10,675 --> 00:56:13,435
Speaker 3:  Does that solve the scrutiny of Chrome and the ad?

1048
00:56:13,525 --> 00:56:17,445
Speaker 4:  Right. So all that's noise, right? It doesn't solve those problems. It

1049
00:56:17,445 --> 00:56:19,405
Speaker 4:  just takes YouTube away from them.

1050
00:56:20,715 --> 00:56:24,405
Speaker 2:  Hmm. Right. And it lets Google say we've made ourselves

1051
00:56:24,475 --> 00:56:27,605
Speaker 2:  smaller and less powerful because now the second most powerful search engine

1052
00:56:27,605 --> 00:56:29,925
Speaker 2:  on the internet doesn't belong to us anymore. Yeah. It's over here. It's

1053
00:56:29,925 --> 00:56:32,565
Speaker 4:  YouTube and we can, you know, the fact that we all work together and we're

1054
00:56:32,565 --> 00:56:35,205
Speaker 4:  friends and sometimes I call each other on the phone and who knows what messaging

1055
00:56:35,205 --> 00:56:38,605
Speaker 4:  app we're using that's communicate because we want not only delete all of

1056
00:56:38,605 --> 00:56:41,925
Speaker 4:  our records, we have too many messaging apps for you. And see there's a,

1057
00:56:42,105 --> 00:56:45,845
Speaker 4:  that's my spiciest take is Google solves this problem the way that

1058
00:56:45,945 --> 00:56:47,565
Speaker 4:  big conglomerates solve this problem.

1059
00:56:47,595 --> 00:56:51,205
Speaker 2:  What if Google does all of its like secret messaging just on

1060
00:56:51,395 --> 00:56:54,885
Speaker 2:  aloe because they know no one is paying attention. You don't even have like,

1061
00:56:54,885 --> 00:56:58,685
Speaker 2:  no lawyer would ever think to like subpoena the aloe messages.

1062
00:56:59,505 --> 00:57:00,885
Speaker 2:  So that's just where Google is

1063
00:57:00,985 --> 00:57:03,845
Speaker 4:  Now. Yeah. They're just like one of their, this is why they've had so many,

1064
00:57:03,855 --> 00:57:04,885
Speaker 4:  right. It's

1065
00:57:04,915 --> 00:57:07,565
Speaker 3:  Long game Was a before Duo Chat or meet?

1066
00:57:07,825 --> 00:57:09,085
Speaker 4:  No, it was after Duo

1067
00:57:09,085 --> 00:57:12,885
Speaker 2:  Was Alo was with Duo. They launched Alo and Duo together and Alo was Duo

1068
00:57:12,885 --> 00:57:15,485
Speaker 2:  was the first one that was like, we're gonna put AI inside of your chats.

1069
00:57:15,505 --> 00:57:18,605
Speaker 2:  So when you say, do you wanna go to the movies, it's like, oh, would you

1070
00:57:18,765 --> 00:57:22,725
Speaker 2:  like to buy movie tickets? And that was a super good idea that everyone liked

1071
00:57:23,585 --> 00:57:26,955
Speaker 2:  and it went really well for Google. That was

1072
00:57:27,455 --> 00:57:28,955
Speaker 2:  10 years ago, ages ago. Yeah.

1073
00:57:29,575 --> 00:57:32,995
Speaker 4:  The number of Dieter Bone we have sorted out Google's messaging strategy

1074
00:57:32,995 --> 00:57:36,965
Speaker 4:  stories that we bring. Yeah, it has, here it is. Here's the

1075
00:57:36,965 --> 00:57:37,845
Speaker 4:  plan by Dieter.

1076
00:57:39,635 --> 00:57:41,885
Speaker 4:  None of them came to bass. That's my spiciest tick.

1077
00:57:42,105 --> 00:57:44,725
Speaker 2:  That's pretty good. I'm out on that one. Yeah.

1078
00:57:44,905 --> 00:57:46,685
Speaker 4:  It no one should set up my mistake.

1079
00:57:47,965 --> 00:57:49,405
Speaker 2:  I think, I think If you had said,

1080
00:57:49,425 --> 00:57:53,365
Speaker 4:  But to your point, if I, if I'm right. No, everyone will. Oh, you'll never

1081
00:57:53,365 --> 00:57:54,085
Speaker 4:  hear the end of this.

1082
00:57:54,435 --> 00:57:58,285
Speaker 2:  Yeah. You, they have to make you the CEO of YouTube if, if, if

1083
00:57:58,285 --> 00:58:01,285
Speaker 2:  you're right now officially they have to do it. Yeah.

1084
00:58:02,365 --> 00:58:06,165
Speaker 2:  I think, I think If you had said Google breaks up in 2025,

1085
00:58:06,285 --> 00:58:09,165
Speaker 2:  I might have thought long and hard about signing on, but Google does it of

1086
00:58:09,185 --> 00:58:10,005
Speaker 2:  its own volition.

1087
00:58:10,425 --> 00:58:14,205
Speaker 4:  That's why it's I love it. But someone breaks up Google. Yeah. Fine. It's,

1088
00:58:14,235 --> 00:58:17,645
Speaker 4:  it's, it's, we're headed that way. Google itself is like, you know what,

1089
00:58:17,645 --> 00:58:21,175
Speaker 4:  this is really hard. Yeah. It's just YouTube. You go have fun,

1090
00:58:21,235 --> 00:58:22,535
Speaker 4:  create some shareholder value.

1091
00:58:24,805 --> 00:58:27,735
Speaker 2:  It's for the good of the people. Yeah. All right. This is great stuff. All

1092
00:58:27,735 --> 00:58:30,575
Speaker 2:  right, let me review and then we're gonna get outta here. Joanna's predictions,

1093
00:58:30,755 --> 00:58:34,455
Speaker 2:  her mild prediction is that a year from now, we're all still gonna be posting

1094
00:58:34,915 --> 00:58:38,095
Speaker 2:  to a million social accounts. I'm in on that. Neil's out.

1095
00:58:38,725 --> 00:58:42,095
Speaker 2:  Your medium take is that meta is going to continue to outpace Apple on glasses.

1096
00:58:42,505 --> 00:58:46,295
Speaker 2:  Neela and I are both in. And your spicy one is that the

1097
00:58:46,295 --> 00:58:49,415
Speaker 2:  touchscreen Mac and the iPad with Mac os some

1098
00:58:50,095 --> 00:58:53,895
Speaker 2:  smashing together thing is gonna happen there. Neela and I are both

1099
00:58:53,915 --> 00:58:57,895
Speaker 2:  out. I hope to, the one I most hope I'm wrong about is that one, because

1100
00:58:57,935 --> 00:58:59,855
Speaker 2:  I want that to happen so bad. If

1101
00:58:59,855 --> 00:59:03,335
Speaker 3:  That happens and we're at an event together, I will stand up and cheer.

1102
00:59:04,365 --> 00:59:07,685
Speaker 2:  I I deservedly so that will be a good victory that for Yeah, like imagine

1103
00:59:07,685 --> 00:59:11,525
Speaker 2:  if Apple had made a television, how insufferable Gene Munster would've been.

1104
00:59:12,005 --> 00:59:13,605
Speaker 2:  Like, that's what I want for you if

1105
00:59:13,605 --> 00:59:16,725
Speaker 3:  This happens. I have never clapped at an Apple event. I believe the on, sorry,

1106
00:59:16,725 --> 00:59:19,765
Speaker 3:  I'll take that back. I believe I might have clapped when they announced multiple

1107
00:59:19,765 --> 00:59:23,645
Speaker 3:  timers and I've never ever clapped at an Apple event

1108
00:59:23,645 --> 00:59:26,715
Speaker 3:  other than that. But I will clap. I will,

1109
00:59:26,855 --> 00:59:29,515
Speaker 2:  But then you have to say out loud, to be clear, I'm clapping for myself.

1110
00:59:29,535 --> 00:59:30,115
Speaker 2:  Yes. And then

1111
00:59:30,115 --> 00:59:30,315
Speaker 3:  Yeah.

1112
00:59:30,565 --> 00:59:31,675
Speaker 2:  Right. Okay.

1113
00:59:31,845 --> 00:59:32,515
Speaker 3:  Journalism.

1114
00:59:34,915 --> 00:59:38,395
Speaker 2:  I love it. All right. NE's predictions, the mild prediction Alexa is going

1115
00:59:38,395 --> 00:59:42,315
Speaker 2:  to be fine. Yeah. Yeah. I even put the ellipsis in here. It's

1116
00:59:42,315 --> 00:59:44,835
Speaker 2:  gonna be fine. Fine. That's fine. I'm out and Joanna's out.

1117
00:59:45,615 --> 00:59:46,235
Speaker 4:  That's rough.

1118
00:59:47,155 --> 00:59:49,035
Speaker 3:  I think it's probably true, but I'm hoping, I'm betting against

1119
00:59:49,575 --> 00:59:52,915
Speaker 2:  The medium take is Walmart is gonna buy TikTok. Strangely, Joanna and I are

1120
00:59:52,915 --> 00:59:56,475
Speaker 2:  both in on this. I love it. And the

1121
00:59:56,685 --> 00:59:59,035
Speaker 2:  spicy take is the Google breaks itself up.

1122
01:00:00,095 --> 01:00:00,715
Speaker 3:  We are not in,

1123
01:00:00,895 --> 01:00:04,655
Speaker 2:  I'm giving you all versions of breakups, even though you specified

1124
01:00:04,655 --> 01:00:06,295
Speaker 2:  YouTube. I think, oh,

1125
01:00:06,295 --> 01:00:06,935
Speaker 4:  Any, any Google

1126
01:00:06,935 --> 01:00:09,135
Speaker 2:  Breaks itself up in any meaningful way. Okay. That's nice to idea. Spicy

1127
01:00:09,135 --> 01:00:10,735
Speaker 2:  enough that I'm giving you the whole take as

1128
01:00:10,735 --> 01:00:12,095
Speaker 4:  Long as it's by its own volition. Correct.

1129
01:00:12,125 --> 01:00:14,615
Speaker 2:  Okay. That's nice. And Joanna and I are both out,

1130
01:00:16,875 --> 01:00:20,725
Speaker 4:  But I, I will, that means I will take any little thing. Yep.

1131
01:00:20,815 --> 01:00:23,085
Speaker 4:  Right, because Google is also Alphabet.

1132
01:00:23,465 --> 01:00:25,125
Speaker 3:  That's right. So if Waymo

1133
01:00:25,335 --> 01:00:27,485
Speaker 4:  Right, if they're, yeah. Waymo.

1134
01:00:27,595 --> 01:00:28,525
Speaker 2:  Waymo's not part of Google.

1135
01:00:28,955 --> 01:00:32,725
Speaker 3:  It's part of Alphabet. And I, I don't think that's ridiculous.

1136
01:00:34,595 --> 01:00:35,335
Speaker 4:  You have to decide.

1137
01:00:35,715 --> 01:00:39,295
Speaker 2:  No, I'll, I'm, I'm still out and I'll so give it to you. Okay. Any, any

1138
01:00:39,575 --> 01:00:43,415
Speaker 2:  alphabet company, but not, not one of the stupid moonshots that loses billions

1139
01:00:43,415 --> 01:00:46,495
Speaker 2:  of dollars. I'll give you Waymo. That's basically the only other one I'm

1140
01:00:46,495 --> 01:00:50,335
Speaker 2:  willing to give you. Fine. My predictions are, my

1141
01:00:50,335 --> 01:00:53,535
Speaker 2:  mild prediction is that cable TV is going to pretty much totally die.

1142
01:00:54,625 --> 01:00:55,975
Speaker 2:  Eli's out Joanna's in.

1143
01:00:56,735 --> 01:01:00,415
Speaker 4:  I still don't know what that means. I'm in, if, if the most generous reading

1144
01:01:00,475 --> 01:01:01,895
Speaker 4:  is like we stop talking about

1145
01:01:01,895 --> 01:01:05,655
Speaker 2:  It. If I just, if I just make it the cable box, business

1146
01:01:06,475 --> 01:01:09,335
Speaker 2:  is dead and boring, would would you be into it? Yeah.

1147
01:01:09,395 --> 01:01:11,735
Speaker 4:  But that because it's already true. Like we should all just take the point

1148
01:01:11,735 --> 01:01:12,415
Speaker 4:  today. It's though,

1149
01:01:12,485 --> 01:01:16,455
Speaker 2:  It's not true. All right. It's boring already, but it's not dead.

1150
01:01:17,645 --> 01:01:21,305
Speaker 2:  And, and I think it, it, it got boring faster than anybody expected and I

1151
01:01:21,305 --> 01:01:23,145
Speaker 2:  think it's gonna get dead faster than anybody expects.

1152
01:01:23,865 --> 01:01:27,385
Speaker 4:  I think our minority investor Comcast requires me to tell you the Xfinity

1153
01:01:27,465 --> 01:01:29,745
Speaker 4:  X one box is cool.

1154
01:01:32,215 --> 01:01:34,945
Speaker 2:  Also, disclosure Neli produced a Netflix show.

1155
01:01:35,265 --> 01:01:35,345
Speaker 4:  Yeah.

1156
01:01:35,345 --> 01:01:38,545
Speaker 2:  Something. Subscribe to The Verge. I don't know. It's pretty,

1157
01:01:38,775 --> 01:01:39,145
Speaker 4:  It's pretty

1158
01:01:39,145 --> 01:01:42,425
Speaker 2:  Good. Yeah. All right. Do you want to end on this one? This is your last

1159
01:01:42,425 --> 01:01:42,665
Speaker 2:  chance.

1160
01:01:42,975 --> 01:01:43,825
Speaker 4:  Yeah. I'll, I'll take it.

1161
01:01:43,825 --> 01:01:45,625
Speaker 2:  Keep in mind that I'm deciding. Yeah, I know.

1162
01:01:45,625 --> 01:01:48,065
Speaker 4:  You're gonna give yourself this point somehow and it's like fine.

1163
01:01:48,245 --> 01:01:52,225
Speaker 2:  All right. Neli. Joan's in my medium take is that

1164
01:01:52,225 --> 01:01:56,025
Speaker 2:  someone is gonna make an AI gadget that actually kicks ass. You're both out.

1165
01:01:56,285 --> 01:02:00,265
Speaker 2:  Yep. And my spicy take is that the industry and the world are going to

1166
01:02:00,265 --> 01:02:03,105
Speaker 2:  collectively give up on matter and you're both out,

1167
01:02:03,285 --> 01:02:03,825
Speaker 4:  Out, super

1168
01:02:03,845 --> 01:02:05,185
Speaker 2:  Out. Love it. Alright.

1169
01:02:05,385 --> 01:02:08,345
Speaker 4:  I think a thing that I don't understand is how many points have we all potentially,

1170
01:02:08,385 --> 01:02:08,865
Speaker 4:  I don up

1171
01:02:08,865 --> 01:02:09,705
Speaker 3:  Understand, Don understand this game at all.

1172
01:02:10,505 --> 01:02:13,985
Speaker 2:  Who's to say I got 12 months to figure out the answer to that question? What

1173
01:02:13,985 --> 01:02:14,785
Speaker 2:  do you win If you win?

1174
01:02:14,965 --> 01:02:18,425
Speaker 4:  I'm saying if Google breaks itself up, I win. Yeah. Whatever that is. If,

1175
01:02:18,445 --> 01:02:20,605
Speaker 4:  if I call that one right, Google

1176
01:02:20,635 --> 01:02:21,805
Speaker 2:  Does voluntary

1177
01:02:21,805 --> 01:02:22,085
Speaker 4:  Spin also there

1178
01:02:22,085 --> 01:02:23,845
Speaker 2:  Be more points for spicier takes. Yes.

1179
01:02:24,105 --> 01:02:27,565
Speaker 3:  But if, yeah, he had so many spicy takes and then he also had that spice,

1180
01:02:27,765 --> 01:02:29,765
Speaker 3:  I think that should be disqualified. The Joanne

1181
01:02:29,765 --> 01:02:31,405
Speaker 2:  Ai Joanna's so mad at how much you got to talk.

1182
01:02:31,795 --> 01:02:32,245
Speaker 4:  I've already,

1183
01:02:33,145 --> 01:02:36,525
Speaker 3:  The AI means nothing and AI is a failure of what it was. Your other one?

1184
01:02:36,635 --> 01:02:38,485
Speaker 3:  Yeah, the bubble pops. The bubble pops. No,

1185
01:02:38,785 --> 01:02:39,565
Speaker 4:  That's not on the list.

1186
01:02:39,565 --> 01:02:41,085
Speaker 2:  No. Neli doesn't get to have that one. Yeah.

1187
01:02:41,195 --> 01:02:42,205
Speaker 3:  Okay, good. That's

1188
01:02:42,205 --> 01:02:42,365
Speaker 2:  Just

1189
01:02:42,825 --> 01:02:43,645
Speaker 4:  AI is Bluetooth. Not, we

1190
01:02:43,645 --> 01:02:47,005
Speaker 3:  Should delete from the podcast. AI is Bluetooth. Yeah, Bluetooth. That's

1191
01:02:47,185 --> 01:02:48,165
Speaker 2:  Too spicy for this

1192
01:02:48,165 --> 01:02:50,845
Speaker 4:  Podcast. Delete it. It's funny 'cause Bluetooth like never had a bubble that

1193
01:02:50,845 --> 01:02:53,405
Speaker 4:  popped. Everyone was just kind of like, yeah, it's just not happening.

1194
01:02:54,675 --> 01:02:56,595
Speaker 3:  I think a lot of people think Bluetooth happened.

1195
01:02:58,105 --> 01:03:02,045
Speaker 4:  Do you find one person who thinks Bluetooth happened? Like in the way

1196
01:03:02,075 --> 01:03:03,205
Speaker 4:  that people thought it would happen?

1197
01:03:03,895 --> 01:03:07,365
Speaker 2:  Right. Bluetooth happened in the sense that it's here and you use it. Right?

1198
01:03:07,365 --> 01:03:10,645
Speaker 4:  Sometimes it works in your car and some people have one of those

1199
01:03:11,285 --> 01:03:12,085
Speaker 4:  ee boom speakers.

1200
01:03:13,545 --> 01:03:13,925
Speaker 2:  But like,

1201
01:03:14,305 --> 01:03:14,925
Speaker 4:  And that's it.

1202
01:03:15,105 --> 01:03:18,685
Speaker 2:  Is there a hundred billion dollar Bluetooth startup out there? Like probably

1203
01:03:18,685 --> 01:03:19,245
Speaker 2:  not. Right?

1204
01:03:20,865 --> 01:03:23,085
Speaker 2:  If that is you, please email me. I

1205
01:03:23,085 --> 01:03:25,525
Speaker 4:  Wanna know there like Bluetooth was at the point where there were like meaningful

1206
01:03:25,525 --> 01:03:26,765
Speaker 4:  Bluetooth security threats.

1207
01:03:27,655 --> 01:03:27,945
Speaker 3:  Yeah.

1208
01:03:28,465 --> 01:03:29,585
Speaker 4:  Remember there was like Blue Snaring.

1209
01:03:31,255 --> 01:03:34,865
Speaker 3:  Yeah, I do rem I think there was a whole CES where it was really just

1210
01:03:35,135 --> 01:03:35,985
Speaker 4:  Bluetooth stuff.

1211
01:03:35,985 --> 01:03:37,785
Speaker 3:  Bluetooth stuff. The Happy Fork.

1212
01:03:38,405 --> 01:03:38,625
Speaker 4:  Yep.

1213
01:03:38,625 --> 01:03:39,225
Speaker 3:  Bluetooth.

1214
01:03:39,285 --> 01:03:40,145
Speaker 4:  And it just didn't happen.

1215
01:03:40,145 --> 01:03:42,665
Speaker 3:  It was Bluetooth. Yeah. I mean, but some of it really did happen.

1216
01:03:43,145 --> 01:03:46,625
Speaker 4:  I once sat through an entire press event where they told me that they would

1217
01:03:46,775 --> 01:03:50,705
Speaker 4:  combine Bluetooth and wifi so that you would use Bluetooth to pair to

1218
01:03:50,705 --> 01:03:53,225
Speaker 4:  a gadget that would then provision it for wifi and you would get the best

1219
01:03:53,225 --> 01:03:53,905
Speaker 4:  of both worlds and

1220
01:03:53,905 --> 01:03:54,545
Speaker 3:  Look at Apple's whole

1221
01:03:54,985 --> 01:03:57,585
Speaker 4:  Strategy. And maybe that sort of worked and maybe it exists, it did not.

1222
01:03:57,825 --> 01:04:01,465
Speaker 3:  I know that you wanna say like, okay, yes, apple added their things to

1223
01:04:01,465 --> 01:04:04,585
Speaker 3:  Bluetooth to make it better clearly, but AirPods,

1224
01:04:04,995 --> 01:04:08,265
Speaker 4:  Right? They made up a fake, fake Bluetooth and layered it on top of Bluetooth

1225
01:04:08,265 --> 01:04:10,265
Speaker 4:  and no one else gets to use it. But without

1226
01:04:10,265 --> 01:04:10,745
Speaker 3:  Bluetooth

1227
01:04:11,165 --> 01:04:14,825
Speaker 4:  And their entire, their entire explanation for why they have

1228
01:04:14,825 --> 01:04:18,425
Speaker 4:  locked down the, what's it now they're onto like the H two chip Yep.

1229
01:04:18,725 --> 01:04:21,225
Speaker 4:  Is because Bluetooth isn't good enough. So they had to make their own

1230
01:04:21,225 --> 01:04:22,705
Speaker 3:  Bluetooth, but there's Bluetooth in there. Apple

1231
01:04:22,755 --> 01:04:26,225
Speaker 2:  Would love to get rid of Bluetooth and, and just connect the Apple devices

1232
01:04:26,485 --> 01:04:27,345
Speaker 2:  to the Apple head front.

1233
01:04:27,405 --> 01:04:30,945
Speaker 3:  The Apple watch, I mean, these are massive businesses that Bluetooth were,

1234
01:04:31,385 --> 01:04:31,905
Speaker 3:  I get what you're saying.

1235
01:04:31,905 --> 01:04:35,425
Speaker 4:  Yeah. Apple made a set of proprietary extensions to Bluetooth in order to

1236
01:04:35,425 --> 01:04:36,665
Speaker 4:  make those things happen. There's

1237
01:04:36,665 --> 01:04:37,785
Speaker 3:  A Bluetooth underpinning.

1238
01:04:38,325 --> 01:04:40,945
Speaker 4:  All right. And, and maybe one day there'll be an AI underpinning.

1239
01:04:41,485 --> 01:04:42,145
Speaker 2:  I'm giving us all,

1240
01:04:42,645 --> 01:04:42,945
Speaker 4:  But the

1241
01:04:43,125 --> 01:04:44,985
Speaker 2:  AI is, Bluetooth is a take. We're all in

1242
01:04:45,615 --> 01:04:46,985
Speaker 3:  AI's not Bluetooth. It's,

1243
01:04:47,655 --> 01:04:48,025
Speaker 2:  It's out

1244
01:04:48,585 --> 01:04:51,545
Speaker 4:  A, the bubble will pop on. AI is actually the thing, and I'm just making

1245
01:04:51,585 --> 01:04:51,705
Speaker 4:  a

1246
01:04:51,705 --> 01:04:55,145
Speaker 2:  Comparison. I'm saying, okay, AI is Bluetooth, we're all in. And the specific

1247
01:04:55,145 --> 01:04:55,705
Speaker 2:  comparison is,

1248
01:04:55,965 --> 01:04:59,185
Speaker 3:  So we're not putting that in. That's not even a spicy cake. It's not allowed.

1249
01:04:59,565 --> 01:05:01,865
Speaker 4:  And all that's gonna happen is we're gonna, we're gonna be here next year,

1250
01:05:01,865 --> 01:05:04,105
Speaker 4:  we're gonna talk about this take. And someone's gonna say, well, it'll be

1251
01:05:04,105 --> 01:05:07,265
Speaker 4:  better next year, which is all they ever said about Bluetooth. That's the

1252
01:05:07,265 --> 01:05:08,585
Speaker 4:  only comparison that makes. Okay.

1253
01:05:08,585 --> 01:05:09,185
Speaker 3:  Okay. That

1254
01:05:09,975 --> 01:05:12,175
Speaker 2:  I like it. All right. We're gonna do the Smart Home. We're gonna do one more

1255
01:05:12,175 --> 01:05:16,055
Speaker 2:  of these next week. We have some other fun 2025 prediction stuff to do,

1256
01:05:16,195 --> 01:05:19,645
Speaker 2:  but for now, we're done. Thank you all. Appreciate you guys doing this with

1257
01:05:19,645 --> 01:05:19,925
Speaker 2:  me. That's

1258
01:05:19,925 --> 01:05:20,765
Speaker 1:  Me. Classic. I already won.

1259
01:05:22,945 --> 01:05:26,045
Speaker 2:  All right. That's it for The Vergecast today. Thank you to Neli and Joanna

1260
01:05:26,065 --> 01:05:29,645
Speaker 2:  for playing this very silly game with me. And thank you as always for listening.

1261
01:05:29,955 --> 01:05:33,885
Speaker 2:  There's lots more on, frankly all of the stuff we've been making predictions

1262
01:05:33,885 --> 01:05:37,645
Speaker 2:  about all over The Verge dot com. I'll put some links in the show notes,

1263
01:05:37,665 --> 01:05:41,525
Speaker 2:  as many as I can think of. But keep it locked on the website. Clearly.

1264
01:05:41,525 --> 01:05:45,285
Speaker 2:  2025 is gonna be a year. We have a subscription now. Fun Time to

1265
01:05:45,445 --> 01:05:48,805
Speaker 2:  subscribe to The Verge. There's just a lot that is coming. And as always,

1266
01:05:48,975 --> 01:05:52,765
Speaker 2:  check out the homepage. It's free, it's awesome. Have a peek and If you haveve

1267
01:05:52,765 --> 01:05:56,725
Speaker 2:  thoughts, questions, feelings, or other predictions for 2025, you'd like

1268
01:05:56,725 --> 01:05:59,725
Speaker 2:  to get off your chest, you can always email us at Vergecast at The Verge

1269
01:05:59,745 --> 01:06:03,565
Speaker 2:  dot com or call the hotline eight six six VERGE one one. We truly love

1270
01:06:03,565 --> 01:06:06,645
Speaker 2:  hearing from you. Thank you to everybody who's called in with questions for

1271
01:06:06,645 --> 01:06:09,925
Speaker 2:  the meta hotline that's running on Tuesday. Tons of fun stuff. That's a really

1272
01:06:09,925 --> 01:06:13,205
Speaker 2:  fun episode. Really enjoyed doing that. And If you have more questions, keep

1273
01:06:13,325 --> 01:06:16,765
Speaker 2:  'em coming. We have a backlog of really, really fun ones. We have plans to

1274
01:06:16,765 --> 01:06:20,365
Speaker 2:  do stuff with. Hit me up. I'm ready for it. This show is produced by Liam

1275
01:06:20,365 --> 01:06:23,565
Speaker 2:  James Wil Pour and Eric Gomez. Vergecast is VERGE Production and part of

1276
01:06:23,565 --> 01:06:27,485
Speaker 2:  the Vox Media podcast network. We'll be back on Tuesday with the meta episode

1277
01:06:27,485 --> 01:06:30,605
Speaker 2:  that we've been talking about for a while, and then back to our regularly

1278
01:06:30,605 --> 01:06:33,805
Speaker 2:  scheduled programming for a couple of weeks before the end of the year. We'll

1279
01:06:33,805 --> 01:06:34,845
Speaker 2:  see you then. Rock and roll

