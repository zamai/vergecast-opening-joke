1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 34e71979-de90-456a-a888-5dd82bec16fd
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-762096955406828610/5917599941658685726/s93290-US-5720s-1717147769.mp3
Description: The Verge's Nilay Patel, Alex Cranz, and David Pierce discuss Google's algorithm leak, OpenAI content deals, and more tech news from this week.

2
00:01:14,275 --> 00:01:16,835
Speaker 3:  immediately starting there. Hi, I'm your friend. Neli Alex. Cranz

3
00:01:56,695 --> 00:02:00,635
Speaker 3:  how the Facebook algorithm works. Like this is true insight into the

4
00:02:00,635 --> 00:02:03,275
Speaker 3:  Google Search algorithm. So you gotta talk about that and the fallout across

5
00:02:03,275 --> 00:02:04,035
Speaker 3:  the web from that

6
00:02:05,695 --> 00:02:09,315
Speaker 3:  Google Search continues to be bananas. There's a bunch of open AI news.

7
00:02:09,755 --> 00:02:13,275
Speaker 3:  I know people want us to talk about Fox Media's deal with OpenAI, which

8
00:02:13,955 --> 00:02:17,555
Speaker 3:  I will to whatever extent that is interesting. Then we got a lightning round

9
00:02:19,225 --> 00:02:21,515
Speaker 3:  unsponsored for now, Sam.

10
00:02:23,255 --> 00:02:27,195
Speaker 3:  But there's one piece of news that I think

11
00:02:27,915 --> 00:02:28,555
Speaker 3:  dominates the week

12
00:02:29,715 --> 00:02:32,075
Speaker 5:  Y. Yeah, you definitely think it dominates the week.

13
00:02:32,495 --> 00:02:35,955
Speaker 3:  And that is The. Verge has received a review unit

14
00:02:36,415 --> 00:02:40,075
Speaker 3:  of the Sony Field seven ULT speaker. It's

15
00:02:40,315 --> 00:02:43,475
Speaker 3:  enormous. It's, this is a medium sized one. It's so big. If you're

16
00:02:43,475 --> 00:02:47,235
Speaker 6:  Not watching this on YouTube, just imagine Neli pulled a grenade launcher

17
00:02:47,235 --> 00:02:48,195
Speaker 6:  out from underneath

18
00:02:48,295 --> 00:02:51,595
Speaker 3:  The table. I love it so much. It's

19
00:02:51,595 --> 00:02:55,515
Speaker 3:  3 99 and as as many of you know, I think the internet

20
00:02:55,515 --> 00:02:59,365
Speaker 3:  has eras and I think technology has eras. We've talked a lot about the end

21
00:02:59,365 --> 00:03:03,205
Speaker 3:  of the Google Search era on the internet. What that might mean, perhaps with

22
00:03:03,205 --> 00:03:06,685
Speaker 3:  the dawn of the AI era. Certainly we were in the mobile era for quite a long

23
00:03:06,685 --> 00:03:10,525
Speaker 3:  time. The social era, this is the ULT era. And

24
00:03:10,525 --> 00:03:14,165
Speaker 3:  what I mean by that is if the eighties were dominated by Megabase in the

25
00:03:14,325 --> 00:03:18,085
Speaker 3:  nineties were dominated by Megabase, I would say that the twenties, the,

26
00:03:18,105 --> 00:03:21,605
Speaker 3:  the two thousands, 2010s kind of a stumble through

27
00:03:21,705 --> 00:03:23,005
Speaker 3:  Sony's extra base era.

28
00:03:23,115 --> 00:03:24,765
Speaker 5:  Yeah, it wasn't pleasant. There was no,

29
00:03:24,945 --> 00:03:28,765
Speaker 3:  You know, it didn't hit. We're now in what Sony has called the

30
00:03:28,885 --> 00:03:29,685
Speaker 3:  ULT era.

31
00:03:30,825 --> 00:03:31,325
Speaker 5:  Ooh, I like

32
00:03:31,325 --> 00:03:33,405
Speaker 3:  These candles. That's what the buttons, that's what the button says on it

33
00:03:33,405 --> 00:03:34,325
Speaker 3:  right here. ULT.

34
00:03:34,955 --> 00:03:37,085
Speaker 6:  There's a ULT button. Wait, that changes

35
00:03:37,085 --> 00:03:40,005
Speaker 3:  Everything. There's a T button and it lights up. I'm just gonna turn this

36
00:03:40,005 --> 00:03:43,965
Speaker 3:  guy on here. It's so big. There we go. I in

37
00:03:43,965 --> 00:03:44,085
Speaker 3:  fact

38
00:03:44,455 --> 00:03:46,245
Speaker 5:  Can't see Neli through the speaker.

39
00:03:46,585 --> 00:03:50,005
Speaker 3:  I'm told that if I hold this play button down for five seconds, we get

40
00:03:51,475 --> 00:03:54,685
Speaker 3:  royalty free demo music. You hear that YouTube

41
00:03:55,675 --> 00:03:56,405
Speaker 3:  royalty free

42
00:03:56,985 --> 00:03:59,645
Speaker 5:  And you guys can't see the the, the lights, but they're there.

43
00:04:02,655 --> 00:04:03,285
Speaker 3:  There she goes.

44
00:04:05,785 --> 00:04:09,685
Speaker 3:  Now, I don't know if you can see the amount of the speaker that's currently

45
00:04:09,685 --> 00:04:13,605
Speaker 3:  lit up, but it's, it's both drivers. And then

46
00:04:15,945 --> 00:04:16,525
Speaker 3:  on the front,

47
00:04:18,305 --> 00:04:22,245
Speaker 3:  the ULT button is rainbow blinking. And when you push that,

48
00:04:22,315 --> 00:04:26,205
Speaker 3:  yeah, you get massive base. Ultimate vibe. This

49
00:04:26,205 --> 00:04:27,605
Speaker 3:  is the most important product in technology.

50
00:04:28,025 --> 00:04:31,885
Speaker 6:  Do you think if you press the ULT button right now, the podcast

51
00:04:31,935 --> 00:04:32,605
Speaker 6:  would explode.

52
00:04:33,095 --> 00:04:33,725
Speaker 3:  Let's find out.

53
00:04:35,435 --> 00:04:36,965
Speaker 3:  Wait, you gotta wait for the drop to come back.

54
00:04:40,145 --> 00:04:40,885
Speaker 3:  Is this English?

55
00:04:41,635 --> 00:04:42,365
Speaker 5:  It's ish.

56
00:04:43,185 --> 00:04:43,965
Speaker 3:  Oh, there's another song.

57
00:04:45,265 --> 00:04:45,645
Speaker 7:  Oh yeah.

58
00:04:47,265 --> 00:04:49,205
Speaker 3:  Oh. Got so much quieter when I pushed the ULT button.

59
00:04:52,115 --> 00:04:55,765
Speaker 3:  Does it just, it just makes little drum hits when you push the U.

60
00:04:57,625 --> 00:04:59,725
Speaker 3:  Can you hear that? Yes. It's like a Tim,

61
00:05:03,805 --> 00:05:07,325
Speaker 3:  I don't know man. Like I'm trying to sell this and it's not going great.

62
00:05:07,665 --> 00:05:07,885
Speaker 3:  The

63
00:05:07,885 --> 00:05:11,285
Speaker 5:  Handles are great. We're turning into QVC or TikTok.

64
00:05:12,045 --> 00:05:14,885
Speaker 5:  I, this is on our TikTok store right now. Now we do have a good handle for

65
00:05:14,885 --> 00:05:15,565
Speaker 5:  $400.

66
00:05:17,425 --> 00:05:19,005
Speaker 3:  It won't burn down your house

67
00:05:19,475 --> 00:05:20,565
Speaker 5:  That we know of. Yeah.

68
00:05:20,905 --> 00:05:24,445
Speaker 3:  Anyway, look, all I'm saying is we went from the Megabase era to the

69
00:05:24,575 --> 00:05:28,245
Speaker 3:  extra base era, which again, I think was a failure. I don't,

70
00:05:28,765 --> 00:05:32,685
Speaker 5:  I mean the ULT era is is not bumping so

71
00:05:32,685 --> 00:05:33,245
Speaker 5:  far. Well

72
00:05:33,245 --> 00:05:34,645
Speaker 3:  It's just, I mean the first song is good

73
00:05:35,415 --> 00:05:39,405
Speaker 6:  Extra is not more than mega. And so what happened is in the mega

74
00:05:39,585 --> 00:05:43,405
Speaker 6:  era, everybody went deaf and so couldn't hear the extra era.

75
00:05:43,505 --> 00:05:47,485
Speaker 6:  So, but now we have Ultimate, which all the deaf people in their forties

76
00:05:48,185 --> 00:05:48,405
Speaker 6:  can

77
00:05:48,405 --> 00:05:52,125
Speaker 3:  Hear now. So it's back it look, it has powerful sound with an ex

78
00:05:52,125 --> 00:05:56,085
Speaker 3:  balance speaker unit and 30 hours

79
00:05:56,085 --> 00:05:57,085
Speaker 3:  of battery life. It

80
00:05:57,205 --> 00:05:59,645
Speaker 5:  If it just, also the windows rattle though, is it really

81
00:06:00,385 --> 00:06:02,845
Speaker 3:  Big? I just think it's funny when you try to make a spec sheet for a product

82
00:06:02,845 --> 00:06:06,645
Speaker 3:  that is insane and you're just like, or be lights

83
00:06:06,955 --> 00:06:09,765
Speaker 3:  next to a bullet point. Look, it's the ULT era. I've never been more excited

84
00:06:09,765 --> 00:06:12,165
Speaker 3:  about a product in my entire life. That's The Vergecast everybody. People

85
00:06:12,165 --> 00:06:12,485
Speaker 3:  have been

86
00:06:12,485 --> 00:06:15,645
Speaker 6:  Wondering about when we're gonna give a 10 outta 10 and I think it might

87
00:06:15,645 --> 00:06:16,885
Speaker 6:  be happening it's, it might

88
00:06:16,885 --> 00:06:20,845
Speaker 3:  Be time. By the way, this is the medium sized one. Oh my god,

89
00:06:20,845 --> 00:06:22,645
Speaker 3:  this is the seven. There's also a 10.

90
00:06:24,205 --> 00:06:27,925
Speaker 3:  I cannot wait for that one to arrive. They also sent us two sevens. Chris

91
00:06:27,925 --> 00:06:31,165
Speaker 3:  Welsh just has one in his house taking up most of his home. All right. There's

92
00:06:31,205 --> 00:06:34,965
Speaker 3:  a lot of news this week. A lot of it is about

93
00:06:35,225 --> 00:06:39,045
Speaker 3:  AI and what it is doing to the internet. If you've been listening

94
00:06:39,045 --> 00:06:42,325
Speaker 3:  to our show or reading The Verge or listening to coder, whatever,

95
00:06:42,825 --> 00:06:46,725
Speaker 3:  you know that we've had a thesis for a while now, stretching

96
00:06:46,725 --> 00:06:49,605
Speaker 3:  back into the middle of last year that the internet was about to get flipped

97
00:06:49,605 --> 00:06:53,165
Speaker 3:  over. Not just by AI but by search in general,

98
00:06:54,265 --> 00:06:58,205
Speaker 3:  by social platforms falling apart. I dunno if you're aware,

99
00:06:58,355 --> 00:07:02,165
Speaker 3:  they changed the name from Twitter to X, like something's

100
00:07:02,165 --> 00:07:05,725
Speaker 3:  happening. Yeah. And one thing that we really wanted to do

101
00:07:06,185 --> 00:07:10,125
Speaker 3:  was pay a lot of attention to what things were like now so we could

102
00:07:11,125 --> 00:07:15,085
Speaker 3:  properly describe how they changed, which meant we did a lot of SEO coverage

103
00:07:15,085 --> 00:07:18,325
Speaker 3:  last year. Covered the culture of SEO, the community of SEO,

104
00:07:18,865 --> 00:07:22,685
Speaker 3:  why, why the web looks like an SEO disaster. How Google

105
00:07:22,705 --> 00:07:26,245
Speaker 3:  fights back against SEO Mia Sato did a lot of that reporting for us.

106
00:07:27,885 --> 00:07:31,645
Speaker 3:  I think I've radicalized her, like you make someone care about SEO for eight

107
00:07:31,645 --> 00:07:33,965
Speaker 3:  months. They come out a different person on the other side. But Mia's doing

108
00:07:33,965 --> 00:07:36,565
Speaker 3:  a great job of that reporting. We had a great feature from Amanda Chicago

109
00:07:36,565 --> 00:07:40,325
Speaker 3:  Lewis. The SEO community is still mad about that. Featured an alligator

110
00:07:40,325 --> 00:07:43,805
Speaker 3:  party. We, we will link all this up. You can read it. The, the point I'm

111
00:07:43,805 --> 00:07:46,885
Speaker 3:  trying to make is we felt like it was changing. I think that hunch was correct,

112
00:07:47,935 --> 00:07:48,765
Speaker 3:  right? Ye

113
00:07:48,915 --> 00:07:52,805
Speaker 5:  Yeah. I mean Google kind of sucks now, right? I'm using coy,

114
00:07:54,345 --> 00:07:58,285
Speaker 3:  So Google sucks now, right? There's other search products. Google is rolling

115
00:07:58,285 --> 00:08:02,205
Speaker 3:  out AI overviews and then over the

116
00:08:02,475 --> 00:08:03,125
Speaker 3:  long weekend

117
00:08:04,645 --> 00:08:07,725
Speaker 3:  a bunch of SEO people discovered that

118
00:08:08,745 --> 00:08:12,525
Speaker 3:  the API documentation for Google Search had been

119
00:08:12,525 --> 00:08:15,445
Speaker 3:  inadvertently made public on GitHub for quite some time.

120
00:08:17,085 --> 00:08:20,145
Speaker 3:  And there were a couple blog posts, one that was just like, here's how I

121
00:08:20,145 --> 00:08:23,225
Speaker 3:  found it, here's who showed it to me. That one's really interesting. And

122
00:08:23,225 --> 00:08:25,865
Speaker 3:  then there's another one that's more of a deep dive into here's what it says.

123
00:08:26,525 --> 00:08:28,945
Speaker 3:  And then there was a little bit of back and forth about is this real? Like

124
00:08:29,005 --> 00:08:32,105
Speaker 3:  can we trust what we're seeing? Because some of what the

125
00:08:32,705 --> 00:08:36,385
Speaker 3:  documentation revealed is that Google has not been telling the whole truth

126
00:08:36,385 --> 00:08:40,105
Speaker 3:  about how search works for a very, very long time. And so some of the

127
00:08:40,265 --> 00:08:43,545
Speaker 3:  headlines in these posts are like, is Google lying to us? And some of the

128
00:08:43,545 --> 00:08:46,985
Speaker 3:  copy in these posts is like, Google has been lying to us. Google was initially

129
00:08:46,985 --> 00:08:50,945
Speaker 3:  just totally dead silent, which is weird. Like usually we

130
00:08:50,945 --> 00:08:54,705
Speaker 3:  at least get a no comment. But Mia sent a bunch of emails, we sent some

131
00:08:54,705 --> 00:08:58,245
Speaker 3:  texts, Hey, is there anything? Do you want to deny that this is real

132
00:08:58,915 --> 00:09:02,285
Speaker 3:  dead silence? Then yesterday, Wednesday, Google

133
00:09:02,395 --> 00:09:05,765
Speaker 3:  confirmed the leaks. They said, this is real. And they said,

134
00:09:06,185 --> 00:09:08,805
Speaker 3:  and they said, we would caution against making inaccurate assumptions about

135
00:09:08,805 --> 00:09:11,405
Speaker 3:  search based on out of context Tator and complete information. Basically

136
00:09:11,405 --> 00:09:15,325
Speaker 3:  they're saying, yeah, this is real. But no, it's not super real. It's a

137
00:09:15,325 --> 00:09:19,045
Speaker 3:  lot. David, you have been covering search and how it works and

138
00:09:19,165 --> 00:09:22,765
Speaker 3:  thinking about it. You use the most browsers and search engines of anyone.

139
00:09:22,805 --> 00:09:26,765
Speaker 3:  I know there's some real explosive

140
00:09:27,235 --> 00:09:30,925
Speaker 3:  information here, but it's still not clear how much we should take seriously

141
00:09:31,105 --> 00:09:34,965
Speaker 3:  and how much Google is lying. It's just a lot of angry people are

142
00:09:35,085 --> 00:09:36,725
Speaker 3:  suddenly like, oh, this is what I've been angry about.

143
00:09:37,315 --> 00:09:41,165
Speaker 6:  Yeah, it's a weird moment because Google Search has always been

144
00:09:41,605 --> 00:09:45,045
Speaker 6:  a black box. Google has very deliberately not

145
00:09:46,045 --> 00:09:50,005
Speaker 6:  revealed how Google Search works and what it cares about. In

146
00:09:50,005 --> 00:09:53,085
Speaker 6:  part because it's so complicated that it's actually a hard,

147
00:09:53,615 --> 00:09:57,365
Speaker 6:  borderline impossible thing to sit down and explain to somebody why

148
00:09:57,365 --> 00:10:00,485
Speaker 6:  something is where it is in search results. Like I don't think any individual

149
00:10:00,485 --> 00:10:03,165
Speaker 6:  person at Google knows the answer to that question. It's just not how the

150
00:10:03,165 --> 00:10:06,845
Speaker 6:  system works anymore. But also because the more

151
00:10:06,865 --> 00:10:10,805
Speaker 6:  Google reveals about how search works, the more tools it is

152
00:10:10,805 --> 00:10:14,445
Speaker 6:  giving people with which to game Google Search, which has been the cat and

153
00:10:14,445 --> 00:10:17,685
Speaker 6:  mouse game they've been playing forever. And so what has been happening

154
00:10:18,265 --> 00:10:21,605
Speaker 6:  is people have been asking Google what

155
00:10:22,345 --> 00:10:26,125
Speaker 6:  is going on? What systems and rankings does Google care about? What

156
00:10:26,225 --> 00:10:29,925
Speaker 6:  can I do to make my stuff rank higher in Google Search? And Google has given

157
00:10:30,165 --> 00:10:33,885
Speaker 6:  a lot of answers that these 2,500 pages

158
00:10:33,985 --> 00:10:37,925
Speaker 6:  of internal API documents say are essentially not true.

159
00:10:37,995 --> 00:10:41,965
Speaker 6:  Like there, there are a series of things that Google has in these documents

160
00:10:41,965 --> 00:10:45,805
Speaker 6:  that it has explicitly said out loud. It does not consider in search ranking.

161
00:10:46,865 --> 00:10:50,845
Speaker 6:  Are those two statements completely mutually exclusive? No. Which is why

162
00:10:50,845 --> 00:10:54,285
Speaker 6:  this gets so weird, right? Like there are, I forget the exact number, but

163
00:10:54,285 --> 00:10:57,605
Speaker 6:  it was right around 14,000 individual things

164
00:10:58,525 --> 00:11:02,445
Speaker 6:  referenced in these pages, which is basically like 14,000 different signals.

165
00:11:03,985 --> 00:11:07,965
Speaker 6:  How those are ranked which matter more, which matter less,

166
00:11:07,965 --> 00:11:11,685
Speaker 6:  whether they're all even counted how old this information is,

167
00:11:12,075 --> 00:11:15,605
Speaker 6:  what some of the terms actually mean. Very hard to know because a lot of

168
00:11:15,605 --> 00:11:18,045
Speaker 6:  them are terms we've never seen before that Google has been saying for years

169
00:11:18,145 --> 00:11:21,445
Speaker 6:  didn't exist. But what what seems to be true is

170
00:11:22,025 --> 00:11:25,885
Speaker 6:  you don't have a, a heading in your API for

171
00:11:25,925 --> 00:11:29,805
Speaker 6:  a thing that you don't care about. Yeah. And so for things that Google

172
00:11:29,945 --> 00:11:33,685
Speaker 6:  has for years said that it doesn't care about, there is now

173
00:11:33,925 --> 00:11:36,925
Speaker 6:  evidence that it is at least a piece of data that Google collects. And one

174
00:11:36,925 --> 00:11:40,365
Speaker 6:  of the wild things is that people who do SEO spend a lot of time testing

175
00:11:40,445 --> 00:11:44,325
Speaker 6:  theories and they've been testing theories and people like the,

176
00:11:44,325 --> 00:11:47,165
Speaker 6:  the guy who broke the story, Rand Fishkin, have gotten

177
00:11:48,155 --> 00:11:52,045
Speaker 6:  crap from people in the community for running tests and saying things like,

178
00:11:52,045 --> 00:11:55,245
Speaker 6:  oh, it seems like Google Search really cares about clickthrough rates. And

179
00:11:55,245 --> 00:11:57,525
Speaker 6:  people at Google saying, no, no, no, no, we don't care about clickthrough

180
00:11:57,525 --> 00:12:01,205
Speaker 6:  rates. You're an idiot. And this overwhelmingly makes it look like Google

181
00:12:01,255 --> 00:12:04,645
Speaker 6:  cares an awful lot about clickthrough rates. And so now we're in this place

182
00:12:04,645 --> 00:12:07,605
Speaker 6:  where I think a big part of what we've been seeing from the SEO community

183
00:12:07,825 --> 00:12:10,725
Speaker 6:  is people who are like, oh, not only has Google not been telling us the truth,

184
00:12:10,795 --> 00:12:14,565
Speaker 6:  they've been lying to our faces and making like gaslighting us into

185
00:12:14,565 --> 00:12:18,445
Speaker 6:  believing the wrong thing about how Google Search works. And it's

186
00:12:18,445 --> 00:12:20,885
Speaker 6:  a weird like existential crisis when that happens.

187
00:12:21,425 --> 00:12:25,125
Speaker 3:  And the thing I'll just like try to chain together is we started paying attention

188
00:12:25,145 --> 00:12:28,365
Speaker 3:  to this story last year. 'cause we wanted to know what

189
00:12:29,075 --> 00:12:32,925
Speaker 3:  this ecosystem was like, right? Like we wanted a picture

190
00:12:33,745 --> 00:12:37,725
Speaker 3:  of maybe like the last days of disco, right? Like here's what it was

191
00:12:37,725 --> 00:12:41,525
Speaker 3:  like before the comment hits. And I thought the comment would be AI

192
00:12:41,705 --> 00:12:45,445
Speaker 3:  or the end of social networks or Google keeping more traffic inside a

193
00:12:45,645 --> 00:12:49,165
Speaker 3:  featured whatever the comment is. And it kind of feels like the comment is

194
00:12:49,485 --> 00:12:52,805
Speaker 3:  actually just knowing that Google wasn't telling the whole truth, right?

195
00:12:52,805 --> 00:12:56,125
Speaker 3:  Like the headings in these blog posts, like legitimately there's a, a trade

196
00:12:56,125 --> 00:12:58,965
Speaker 3:  publication called Search Engine Land that we've been watching a lot of the

197
00:12:59,125 --> 00:13:02,285
Speaker 3:  coverage of this on that site. It's one of the bigger SEO trade publications

198
00:13:02,285 --> 00:13:05,805
Speaker 3:  to exist. And the headings are like, how does SEO move on from here? One

199
00:13:05,805 --> 00:13:09,445
Speaker 3:  of the subheadings in their piece where they run the Google statement was,

200
00:13:09,705 --> 00:13:13,605
Speaker 3:  did Google lie to us? That's just a subhead. That's just a straight H

201
00:13:13,665 --> 00:13:15,685
Speaker 3:  two on their story. Because that,

202
00:13:15,685 --> 00:13:19,445
Speaker 6:  Which by the way, people do in order to be ranked higher in Google, you put

203
00:13:19,685 --> 00:13:22,165
Speaker 6:  questions people might Google in an H two. I'm serious, right? And that is

204
00:13:22,165 --> 00:13:25,845
Speaker 6:  like push this all the way down and it's like what's inside this

205
00:13:26,125 --> 00:13:29,405
Speaker 6:  document is how the internet works, right? Yeah. Like people have built the

206
00:13:29,565 --> 00:13:33,365
Speaker 6:  internet to try to figure out how to game the stuff that is

207
00:13:33,365 --> 00:13:37,325
Speaker 6:  inside these 2,500 pages. And like you, you can reverse engineer the

208
00:13:37,485 --> 00:13:41,245
Speaker 6:  internet out of Google's API, which I think is why this feels so huge. Like

209
00:13:41,245 --> 00:13:43,965
Speaker 6:  your your point about the Facebook algorithm that you've been saying all

210
00:13:43,965 --> 00:13:46,725
Speaker 6:  week, like this is the, on the order of leaking the Facebook algorithm like

211
00:13:47,225 --> 00:13:50,645
Speaker 6:  it is, and in the way that understanding the Facebook algorithm would

212
00:13:50,645 --> 00:13:54,365
Speaker 6:  essentially help us understand a decade of our online relationships. Like

213
00:13:54,635 --> 00:13:58,365
Speaker 6:  this is the internet in 2,500 pages of like weird inscrutable

214
00:13:58,405 --> 00:13:59,405
Speaker 6:  API calls. And

215
00:13:59,405 --> 00:14:03,125
Speaker 5:  I think that's hard for people who aren't in the SEO business or our

216
00:14:03,325 --> 00:14:06,125
Speaker 5:  business, which is kind of the SEO business to fully wrap their

217
00:14:06,125 --> 00:14:09,605
Speaker 3:  Hands up. We make websites, if you make a website, you care about this a

218
00:14:09,605 --> 00:14:10,605
Speaker 3:  little bit. Yeah, yeah,

219
00:14:11,155 --> 00:14:15,005
Speaker 5:  Yeah. We have to, right? Like it's required. I I I edit buying

220
00:14:15,005 --> 00:14:18,885
Speaker 5:  guides. I I have to care a lot about SEO and people who don't care about

221
00:14:19,045 --> 00:14:22,565
Speaker 5:  SEO. They like, I go and I tell my friends, I'm like this huge document,

222
00:14:22,675 --> 00:14:26,285
Speaker 5:  like cash of documents drop. This is huge. And they're like, why are you,

223
00:14:26,285 --> 00:14:27,245
Speaker 5:  what is SEO

224
00:14:27,595 --> 00:14:30,245
Speaker 3:  Elon? Musk says I'm gonna open source the Twitter algorithm and this is front

225
00:14:30,245 --> 00:14:34,085
Speaker 3:  page news. The API calls or fields

226
00:14:34,155 --> 00:14:37,485
Speaker 3:  basically of what data Google collects to run ranking algorithm

227
00:14:38,095 --> 00:14:41,205
Speaker 3:  leaks. And it's like us like freaking out. Yeah. And it's kind of nowhere.

228
00:14:41,345 --> 00:14:45,165
Speaker 3:  And I, and like to David's point, we

229
00:14:45,165 --> 00:14:48,725
Speaker 3:  don't know how these things are ranked. That's true. But we do know that

230
00:14:48,725 --> 00:14:51,805
Speaker 3:  Google has said for years it does not collect some of this data or care about

231
00:14:51,805 --> 00:14:54,925
Speaker 3:  some of this data. And it definitely does. What are you gonna do with that?

232
00:14:55,515 --> 00:14:59,405
Speaker 3:  Rand Fishkin the same person you mentioned, David has gone spent a long time

233
00:14:59,405 --> 00:15:02,885
Speaker 3:  saying it seems like that this thing called dwell time is important.

234
00:15:03,305 --> 00:15:05,565
Speaker 3:  So you click through a Google result, you land on a website, you're there

235
00:15:05,565 --> 00:15:08,525
Speaker 3:  for however long you come back to Google, you go to the next one, that time

236
00:15:08,545 --> 00:15:11,605
Speaker 3:  you spend in the website. He is like, that seems important. And Google has

237
00:15:11,605 --> 00:15:15,405
Speaker 3:  basically said no. Yep. They're tracking that too. Yeah. The one that I think

238
00:15:15,405 --> 00:15:18,805
Speaker 3:  is the most explosive, which we don't really know how to understand,

239
00:15:19,625 --> 00:15:23,365
Speaker 3:  is click data from Chrome and it's there

240
00:15:23,395 --> 00:15:27,165
Speaker 3:  somewhere. Right? So one thing we know that Google does,

241
00:15:27,165 --> 00:15:31,045
Speaker 3:  which is a little shaky, is when you search

242
00:15:31,045 --> 00:15:34,245
Speaker 3:  for a website, I think the example that came out in one of the antitrust

243
00:15:34,245 --> 00:15:38,125
Speaker 3:  trials was Vogue or Cosmopolitan. It was some magazine like

244
00:15:38,125 --> 00:15:38,245
Speaker 3:  this.

245
00:15:38,245 --> 00:15:39,245
Speaker 6:  Yeah, it was one of those. Yeah.

246
00:15:39,505 --> 00:15:42,245
Speaker 3:  And you get the website and right below it in the search result, you get

247
00:15:42,245 --> 00:15:45,365
Speaker 3:  their headings like beauty, fashion style coverage, met gala.

248
00:15:45,975 --> 00:15:49,485
Speaker 3:  Those headings are generated by what people click on in those websites in

249
00:15:49,485 --> 00:15:52,565
Speaker 3:  Chrome. Yeah. And Google has forever

250
00:15:54,195 --> 00:15:57,125
Speaker 3:  said it does not use data from Chrome to impact search.

251
00:15:58,705 --> 00:16:02,525
Speaker 3:  And then you look at these API docs and you're like, oh, it's in, there's

252
00:16:02,525 --> 00:16:06,405
Speaker 3:  data from Chrome. Like it's potential that Google is actually

253
00:16:06,405 --> 00:16:09,845
Speaker 3:  using that for search. And they have sworn up and down to every regulator,

254
00:16:09,845 --> 00:16:12,805
Speaker 3:  to every SEO professional to everyone that these things are not the same.

255
00:16:13,715 --> 00:16:14,845
Speaker 3:  What are you gonna do with that?

256
00:16:15,475 --> 00:16:19,445
Speaker 6:  It's such a funny example too because like of course Google does that,

257
00:16:19,475 --> 00:16:23,205
Speaker 6:  like thi this to me, so much of this leak is things that you

258
00:16:23,405 --> 00:16:27,325
Speaker 6:  would obviously assume Google is doing except that Google has been denying

259
00:16:27,325 --> 00:16:30,805
Speaker 6:  doing it for years. That it turns out, in fact Google is doing, like

260
00:16:31,465 --> 00:16:35,405
Speaker 6:  I'm in the business of knowing which links are good. And I also run

261
00:16:35,445 --> 00:16:38,925
Speaker 6:  a browser in which billions of people click links every day. Like

262
00:16:39,385 --> 00:16:43,365
Speaker 6:  at some point you'd be insane not to let one affect

263
00:16:43,365 --> 00:16:47,165
Speaker 6:  the other. You have maybe the best possible data stream, which is the

264
00:16:47,175 --> 00:16:50,965
Speaker 6:  links that people go to and how long they spend there, which is literally,

265
00:16:50,965 --> 00:16:54,845
Speaker 6:  that is all you could ever want to know in search rankings. And so

266
00:16:54,865 --> 00:16:58,645
Speaker 6:  the idea that they are spread apart and not, you know,

267
00:16:58,665 --> 00:17:01,485
Speaker 6:  in any way correlated out of the goodness of Google's heart, I think has

268
00:17:01,485 --> 00:17:05,485
Speaker 6:  always been sort of silly to people. And so to some extent

269
00:17:05,555 --> 00:17:09,445
Speaker 6:  it's like, it, it just confirms what your instincts tell you in

270
00:17:09,525 --> 00:17:10,645
Speaker 6:  a lot of this league. Yeah.

271
00:17:10,645 --> 00:17:13,685
Speaker 5:  Yeah. I I keep going back to Neli. Earlier you said this was kinda like a

272
00:17:13,685 --> 00:17:16,565
Speaker 5:  comment hitting, and I feel like it's definitely a comment for the SEO community,

273
00:17:17,305 --> 00:17:20,925
Speaker 5:  but for the rest of us, we've kind of been in more like high

274
00:17:20,945 --> 00:17:24,685
Speaker 5:  waters rising as apocalypses, right? Like the Google,

275
00:17:24,865 --> 00:17:28,325
Speaker 5:  the Google experience for 90% of people has just been like, okay, the sea

276
00:17:28,325 --> 00:17:31,845
Speaker 5:  levels are rising now and and it feels like this was maybe that

277
00:17:33,465 --> 00:17:37,125
Speaker 5:  big push in the water. Oh, now it's covering Manhattans. Dang it.

278
00:17:37,635 --> 00:17:37,925
Speaker 5:  Yeah.

279
00:17:38,515 --> 00:17:42,405
Speaker 3:  Yeah. I mean it, it, it does feel like the dam is breaking. One

280
00:17:42,405 --> 00:17:45,445
Speaker 3:  of the things that we were talking about when we did our decoder episode

281
00:17:45,725 --> 00:17:49,645
Speaker 3:  recently about Google Zero was the stuff leaks. 'cause people are mad.

282
00:17:49,835 --> 00:17:53,245
Speaker 3:  Yeah. And so if you were an SEO operator and you

283
00:17:53,245 --> 00:17:57,005
Speaker 3:  uncovered a bunch of secret data that Google was

284
00:17:57,005 --> 00:18:00,045
Speaker 3:  collecting, you would not tell the SEO community.

285
00:18:00,735 --> 00:18:04,085
Speaker 3:  Right? Like you would, you would definitely keep that to yourself. But instead

286
00:18:04,085 --> 00:18:06,925
Speaker 3:  what's happening is people are mad and they're like, look at all these lies

287
00:18:07,505 --> 00:18:11,365
Speaker 3:  or look at what we perceive to be lies. Yeah. And there's

288
00:18:11,365 --> 00:18:15,245
Speaker 3:  just a lot of the, the ideas that people have had about

289
00:18:15,245 --> 00:18:19,205
Speaker 3:  how Google Search works, one of them is domain authority. So a very

290
00:18:19,255 --> 00:18:22,925
Speaker 3:  funny thing that happens is every year I publish Best Printer

291
00:18:22,925 --> 00:18:26,565
Speaker 3:  2024 by a brother laser printer and it goes to the top of the

292
00:18:26,565 --> 00:18:30,205
Speaker 3:  rankings, it goes to the top of the search rankings one, because I have the

293
00:18:30,205 --> 00:18:32,605
Speaker 3:  right answer, which is you should write brother laser printer and never think

294
00:18:32,605 --> 00:18:36,365
Speaker 3:  about it. Two, because I'm the best person to write about printers in world

295
00:18:36,365 --> 00:18:39,245
Speaker 3:  history. No one else has WR written a better printer post than me. I'm sorry.

296
00:18:39,245 --> 00:18:43,205
Speaker 3:  That's just the truth. Certainly these two can try and

297
00:18:43,205 --> 00:18:46,845
Speaker 3:  I don't mean that because there's not better writers than me. I mean, those

298
00:18:46,845 --> 00:18:49,285
Speaker 3:  writers are not wasting their time. Do they have better things do writing

299
00:18:49,285 --> 00:18:52,885
Speaker 3:  about printers? Right. You're the perfect, the perfect

300
00:18:52,885 --> 00:18:56,765
Speaker 3:  middle of good at your job and also interested in printer posts has ever

301
00:18:56,765 --> 00:19:00,205
Speaker 3:  existed. I mean, like the whole staff is better at this than me. I just won't

302
00:19:00,445 --> 00:19:00,605
Speaker 3:  nn diagram.

303
00:19:01,075 --> 00:19:01,365
Speaker 5:  Yeah.

304
00:19:01,615 --> 00:19:05,365
Speaker 3:  Right. That's fine. And it, and then

305
00:19:05,565 --> 00:19:08,805
Speaker 3:  everyone tweets it and shares it and people write about it. 'cause it's a

306
00:19:08,805 --> 00:19:12,165
Speaker 3:  joke and it's funny and it's at the top of the list. And then the SEO o community

307
00:19:12,165 --> 00:19:14,845
Speaker 3:  says things like The Verge is just taking advantage of their domain authority,

308
00:19:15,255 --> 00:19:18,285
Speaker 3:  which Yeah, yeah, that's true. That's totally what we're doing. And then

309
00:19:18,285 --> 00:19:20,765
Speaker 3:  Google's like, we don't have domain authority. That's not a thing we keep

310
00:19:20,765 --> 00:19:23,765
Speaker 3:  track of. And then you look at the thing and they track something called

311
00:19:23,765 --> 00:19:27,565
Speaker 3:  site authority and it's that dynamic authority. Yeah.

312
00:19:27,565 --> 00:19:30,885
Speaker 3:  Right. It's just that dynamic which is like, okay, like

313
00:19:32,265 --> 00:19:35,485
Speaker 3:  we understand that you don't want people to game search.

314
00:19:36,225 --> 00:19:39,125
Speaker 3:  We have been very critical of SEO forms at game search.

315
00:19:39,935 --> 00:19:43,605
Speaker 3:  Again, decoder this week is just about

316
00:19:43,625 --> 00:19:46,165
Speaker 3:  people gaming search and putting small businesses outta business.

317
00:19:48,065 --> 00:19:51,845
Speaker 3:  But if you're not honest right then, and if you

318
00:19:51,995 --> 00:19:55,765
Speaker 3:  deny the things are happening, then the backlash is really strong. The

319
00:19:55,765 --> 00:19:59,525
Speaker 3:  example I keep thinking about is what if every Instagram

320
00:19:59,525 --> 00:20:03,405
Speaker 3:  influencer woke up today and was like, Instagram

321
00:20:03,425 --> 00:20:07,325
Speaker 3:  has been lying to us for a decade. Like, how'd that go for that platform?

322
00:20:08,115 --> 00:20:10,605
Speaker 5:  Adam, er just like immediately like, Hey guys,

323
00:20:10,875 --> 00:20:11,805
Speaker 3:  He's not making it better.

324
00:20:12,225 --> 00:20:15,445
Speaker 5:  I'm here with a video on why the lies were worth it. Yeah,

325
00:20:15,445 --> 00:20:15,845
Speaker 3:  Exactly.

326
00:20:16,545 --> 00:20:17,845
Speaker 5:  Now I gotta go to the Met Gala.

327
00:20:17,955 --> 00:20:20,565
Speaker 3:  Yeah, exactly. I mean kind of. Yeah. He is like, my glasses are getting more

328
00:20:20,565 --> 00:20:21,605
Speaker 3:  expensive every day and

329
00:20:21,605 --> 00:20:22,405
Speaker 5:  They look fabulous.

330
00:20:22,795 --> 00:20:26,765
Speaker 3:  They're very good. What would happen if every YouTuber, I always joke that

331
00:20:26,765 --> 00:20:29,445
Speaker 3:  every YouTuber gets their wings and they make the video about how term had

332
00:20:29,445 --> 00:20:32,525
Speaker 3:  at YouTube, what, what would happen if every YouTuber was like, they've been

333
00:20:32,525 --> 00:20:36,445
Speaker 3:  lying to us for a decade. That's, that's where Google is landing with the

334
00:20:36,445 --> 00:20:39,925
Speaker 3:  web with these links. We're gonna have a lot more coverage of them now that

335
00:20:39,925 --> 00:20:41,845
Speaker 3:  we know they're real. We're gonna pull 'em apart. We're gonna talk to some

336
00:20:41,845 --> 00:20:45,765
Speaker 3:  experts. I have people from other

337
00:20:46,205 --> 00:20:49,005
Speaker 3:  companies in my inbox saying things like,

338
00:20:50,385 --> 00:20:53,605
Speaker 3:  if some of this is real, then Chrome is essentially spyware.

339
00:20:54,275 --> 00:20:58,165
Speaker 5:  Yeah, it's, I mean it sounds like last week we were having this whole conversation

340
00:20:58,165 --> 00:21:01,965
Speaker 5:  about copilot and how everybody was very upset because they felt like copilot

341
00:21:02,075 --> 00:21:05,685
Speaker 5:  plus PCs, all this stuff that's hap Microsoft is doing is horrible.

342
00:21:06,145 --> 00:21:09,085
Speaker 5:  And it was, it was essentially key loggers and it's like, okay, well now

343
00:21:09,085 --> 00:21:11,885
Speaker 5:  we basically have confirmation that Chrome is a key logger.

344
00:21:12,115 --> 00:21:13,005
Speaker 3:  Well, we almost,

345
00:21:13,145 --> 00:21:13,365
Speaker 5:  We

346
00:21:13,655 --> 00:21:16,165
Speaker 3:  Right, right. We there's like a field.

347
00:21:16,795 --> 00:21:17,085
Speaker 5:  Yeah.

348
00:21:17,675 --> 00:21:20,325
Speaker 3:  It's like if you were to make a spreadsheet and one of the things in spreadsheet

349
00:21:20,325 --> 00:21:23,685
Speaker 3:  would be like my friend's bank account numbers, and you're like, but I never

350
00:21:23,925 --> 00:21:27,805
Speaker 3:  filled it in. Yeah. I just kind of wanted, in case someone

351
00:21:27,805 --> 00:21:29,005
Speaker 3:  told me their bank account number.

352
00:21:29,235 --> 00:21:30,885
Speaker 5:  Sure. I do that all the time. Yeah.

353
00:21:30,905 --> 00:21:34,765
Speaker 3:  People my friends have gone out with on dates. Like I just,

354
00:21:34,845 --> 00:21:38,565
Speaker 3:  I just keep, maybe maybe that's a page I wanna have in my notebook. Right.

355
00:21:38,565 --> 00:21:38,885
Speaker 3:  But again,

356
00:21:38,925 --> 00:21:42,525
Speaker 6:  I, I, I would encourage anyone who is alarmed by this

357
00:21:42,705 --> 00:21:46,685
Speaker 6:  to go to your Chrome history, think about all the cookies that you

358
00:21:46,685 --> 00:21:50,085
Speaker 6:  have. I mean, like, of course it's a key, like what the hell is a browser

359
00:21:50,225 --> 00:21:54,005
Speaker 6:  if not a key logger? Yeah. That's, that's literally its job

360
00:21:54,465 --> 00:21:57,285
Speaker 6:  is to know all the links that you've been to and all the things that you've

361
00:21:57,285 --> 00:22:00,965
Speaker 6:  typed inside of them. And I think to some extent, again, I just keep

362
00:22:01,125 --> 00:22:04,725
Speaker 6:  coming back to this idea that like Google is going to say, okay, we, we run

363
00:22:04,725 --> 00:22:08,045
Speaker 6:  a search engine. Wouldn't it be cool if we knew all the links people would

364
00:22:08,045 --> 00:22:10,765
Speaker 6:  go to when they weren't on Google? And then somebody on Chrome is like, what

365
00:22:10,765 --> 00:22:13,485
Speaker 6:  if we just built an awesome browser and they just, it would be the most,

366
00:22:13,635 --> 00:22:17,605
Speaker 6:  like, have you met Google thing in history? And to

367
00:22:17,605 --> 00:22:21,165
Speaker 6:  be fair, if any company could accidentally keep those two things apart, it

368
00:22:21,165 --> 00:22:25,085
Speaker 6:  is Google, but like, just strategically, it, it, it would be

369
00:22:25,105 --> 00:22:28,885
Speaker 6:  absurd for Google to do this and not actually connect those

370
00:22:28,955 --> 00:22:29,845
Speaker 6:  dots together. Right.

371
00:22:30,015 --> 00:22:33,485
Speaker 3:  Again, and I think from some of the antitrust trials, David, you covered

372
00:22:33,485 --> 00:22:36,525
Speaker 3:  some of them. Google's been pretty open. Like our engineers wanted a bunch

373
00:22:36,525 --> 00:22:39,085
Speaker 3:  of click data to make the search engine better and that's engine,

374
00:22:39,305 --> 00:22:40,245
Speaker 6:  So we gave about $20 billion.

375
00:22:40,735 --> 00:22:44,605
Speaker 3:  Right. Okay. Well a bunch of people run Windows. We don't

376
00:22:44,605 --> 00:22:47,765
Speaker 3:  have to pay Microsoft, we just have to make a browser and put it on there.

377
00:22:48,625 --> 00:22:51,045
Speaker 3:  And now we run the biggest browser in the world and we get all the clicks.

378
00:22:51,045 --> 00:22:53,885
Speaker 3:  Like that is exactly what you would do. Yeah. Yeah.

379
00:22:53,925 --> 00:22:57,685
Speaker 5:  I think, I think the thing is the, what's different here is that everybody

380
00:22:57,685 --> 00:23:01,445
Speaker 5:  should understand this, right? Like, I understand that Google is reading

381
00:23:01,465 --> 00:23:05,285
Speaker 5:  my, my emails because I signed up for Gmail in like 2004,

382
00:23:05,285 --> 00:23:09,205
Speaker 5:  2005. That was part of the deal, you know, it reads my

383
00:23:09,205 --> 00:23:12,965
Speaker 5:  emails to deliver me ads. So I understand that most people don't, and a lot

384
00:23:12,965 --> 00:23:16,405
Speaker 5:  of times they have these moments when stuff like this happens where it's

385
00:23:16,405 --> 00:23:20,085
Speaker 5:  like, oh shit, they have so much more information about me than I ever thought

386
00:23:20,085 --> 00:23:23,085
Speaker 5:  they did. And it's just this moment for a lot of people where it's just like,

387
00:23:23,085 --> 00:23:26,365
Speaker 5:  oh, I didn't, I never intellectualize this. I never like fully

388
00:23:26,445 --> 00:23:28,965
Speaker 5:  comprehended how much these companies have about me.

389
00:23:29,675 --> 00:23:33,285
Speaker 3:  Yeah. And then on, on the flip side, you have people who are trying to build

390
00:23:33,565 --> 00:23:36,845
Speaker 3:  businesses saying, Hey, it looks like you are doing this. And Google's saying

391
00:23:36,905 --> 00:23:37,485
Speaker 3:  no. Yeah.

392
00:23:37,485 --> 00:23:41,085
Speaker 5:  And just flat out lying to them in a way that's like,

393
00:23:41,585 --> 00:23:44,405
Speaker 5:  you know, I don't think they Google has any interest in rebuilding trust

394
00:23:44,405 --> 00:23:44,645
Speaker 5:  with the

395
00:23:44,765 --> 00:23:48,205
Speaker 3:  SEO people. Right. Actually, one of the funniest things about this is that

396
00:23:48,205 --> 00:23:51,205
Speaker 3:  it's such an antagonistic relationship. Yeah. I often make the comparison

397
00:23:51,305 --> 00:23:55,005
Speaker 3:  to platforms. Like I think the web is essentially Google's platform and certainly

398
00:23:55,005 --> 00:23:58,965
Speaker 3:  a lot of these businesses are building their businesses on the platform

399
00:23:58,965 --> 00:24:02,445
Speaker 3:  known as Google Search, not the web. Right? Right. They're, they're, they're

400
00:24:02,445 --> 00:24:06,405
Speaker 3:  search dependent businesses. And Google does not have like

401
00:24:06,515 --> 00:24:09,685
Speaker 3:  warm and fuzzy platform creator relationships

402
00:24:10,315 --> 00:24:14,085
Speaker 3:  with these folks. No. Like Adam er is like, I'm gonna sit down with creators,

403
00:24:14,115 --> 00:24:16,765
Speaker 3:  like, look at all these great creators. He's got a great sweater on. Right.

404
00:24:16,765 --> 00:24:20,725
Speaker 3:  Neil Mohan, who runs YouTube loves, loves a creator breakfast. Yeah.

405
00:24:20,735 --> 00:24:24,605
Speaker 3:  Right. Like every platform that depends on creators has that relationship

406
00:24:25,115 --> 00:24:28,965
Speaker 3:  that extracts more value than it pays them. That's life and platform

407
00:24:28,965 --> 00:24:32,805
Speaker 3:  world. They, they try to mollify the creators all the time. Google does not

408
00:24:32,805 --> 00:24:33,965
Speaker 3:  try to mollify website owners.

409
00:24:34,665 --> 00:24:38,365
Speaker 6:  No, because I mean, at this point, the, the internet is reliant on Google.

410
00:24:38,465 --> 00:24:41,565
Speaker 6:  And what Google says is, Hey, run our ads on your site and you can have some

411
00:24:41,565 --> 00:24:44,085
Speaker 6:  money. Does that seem good? But what I think is so interesting about this

412
00:24:44,085 --> 00:24:47,805
Speaker 6:  is like the, the YouTube, the sort of social platform example is really interesting

413
00:24:47,805 --> 00:24:51,325
Speaker 6:  because what those companies by and large have done

414
00:24:52,065 --> 00:24:56,005
Speaker 6:  is be inscrutable on purpose, right? Like you,

415
00:24:56,005 --> 00:24:59,725
Speaker 6:  you look at Aer responding to people who are like, why

416
00:24:59,725 --> 00:25:02,925
Speaker 6:  didn't my post do numbers? Why is this one working and this one not working?

417
00:25:03,425 --> 00:25:07,365
Speaker 6:  And they never really answer the question except to say, you know,

418
00:25:07,545 --> 00:25:11,445
Speaker 6:  do good work and, and keep posting and whatever. And so what you see

419
00:25:11,445 --> 00:25:14,285
Speaker 6:  is like, the people who are successful on these platforms are the ones who

420
00:25:14,285 --> 00:25:17,885
Speaker 6:  are constantly running experiments in public. Like, do, do you remember Mr.

421
00:25:17,915 --> 00:25:21,085
Speaker 6:  Beast's whole thing where he was like, if I have my mouth open in the thumbnail,

422
00:25:21,085 --> 00:25:24,445
Speaker 6:  it gets more clicks. Like YouTube didn't tell him that these are the experiments

423
00:25:24,475 --> 00:25:28,365
Speaker 6:  he's running in public. What Google has done that is so wild is it's,

424
00:25:28,365 --> 00:25:31,885
Speaker 6:  it's as if Neil Mohan called Mr. Beast and said, shut your mouth. It doesn't

425
00:25:31,885 --> 00:25:32,005
Speaker 6:  help.

426
00:25:32,865 --> 00:25:33,085
Speaker 3:  And,

427
00:25:33,585 --> 00:25:33,805
Speaker 6:  And,

428
00:25:34,385 --> 00:25:34,605
Speaker 3:  And

429
00:25:34,605 --> 00:25:38,405
Speaker 6:  Instead, so it's like, okay, it's one thing to not be told the rules

430
00:25:38,425 --> 00:25:41,405
Speaker 6:  of the game and figure them out for yourself. I actually think that relationship

431
00:25:41,405 --> 00:25:45,245
Speaker 6:  is like odd but fine. Right? And it's like, here,

432
00:25:45,275 --> 00:25:49,205
Speaker 6:  here is a, a black box, it's your job to figure it out. That is sort of the

433
00:25:49,285 --> 00:25:52,085
Speaker 6:  internet we live on. But for Google to have spent this long

434
00:25:53,475 --> 00:25:57,365
Speaker 6:  denying the existence of what people are finding on their own and sort

435
00:25:57,365 --> 00:26:00,365
Speaker 6:  of making people question what they're finding with their own two hands in

436
00:26:00,365 --> 00:26:03,645
Speaker 6:  front of their own two eyes is just wild. Yeah. And again, we should say

437
00:26:03,645 --> 00:26:07,205
Speaker 6:  there is a lot about how all of this works that we still don't know. I think

438
00:26:07,285 --> 00:26:11,045
Speaker 6:  a lot of it is going to start to come out very fast because there are a lot

439
00:26:11,045 --> 00:26:14,565
Speaker 6:  of people who do these experiments who are now armed with a

440
00:26:14,565 --> 00:26:17,525
Speaker 6:  tremendous amount of new data. And so I think we're gonna learn a lot about

441
00:26:17,525 --> 00:26:21,285
Speaker 6:  how Google works really, really quickly now. But it's just, it just feels

442
00:26:21,345 --> 00:26:24,325
Speaker 6:  so weird to hear the people who do this for a living be like, yeah, I've

443
00:26:24,325 --> 00:26:28,125
Speaker 6:  been asking these questions and being publicly lied to about how my job

444
00:26:28,135 --> 00:26:31,365
Speaker 6:  works for a decade. Yeah. That just feels crazy.

445
00:26:31,995 --> 00:26:35,565
Speaker 3:  Also, we should know there are pending antitrust lawsuits against Google

446
00:26:35,665 --> 00:26:39,125
Speaker 3:  and lots and lots of regulators around the world who have been asking the

447
00:26:39,125 --> 00:26:41,245
Speaker 3:  same questions and getting the same kind of answers. Well,

448
00:26:41,245 --> 00:26:43,450
Speaker 6:  Which is another place a lot of this information is coming from, by the way.

449
00:26:43,450 --> 00:26:47,045
Speaker 6:  Like the, there was this thing called Nav Boost that came up a bunch in the,

450
00:26:47,045 --> 00:26:50,645
Speaker 6:  in the API, which talks a lot about how click through rate and the stuff

451
00:26:50,645 --> 00:26:53,445
Speaker 6:  you're talking about, like the, the long and short clicks, whether you come

452
00:26:53,445 --> 00:26:56,605
Speaker 6:  back very quickly from a search result or stay on the page a while,

453
00:26:57,225 --> 00:27:00,685
Speaker 6:  all of that is part of a system Google has called Nav Boost that came up

454
00:27:00,705 --> 00:27:03,765
Speaker 6:  in the antitrust trial and made some noise where it's like, okay, this is

455
00:27:04,005 --> 00:27:07,845
Speaker 6:  actually overriding a lot of our other rankings is what you do

456
00:27:08,395 --> 00:27:12,285
Speaker 6:  once you interact with a search result. And that is very different

457
00:27:12,285 --> 00:27:13,365
Speaker 6:  from what Google has told people.

458
00:27:13,715 --> 00:27:17,005
Speaker 3:  Yeah. Actually my favorite part of all this, my favorite thing because it's

459
00:27:17,005 --> 00:27:20,325
Speaker 3:  such a good name, let's be honest. How do you get me, you give something

460
00:27:20,465 --> 00:27:23,925
Speaker 3:  an adorable name. Google has spent

461
00:27:24,415 --> 00:27:28,125
Speaker 3:  years positioning search as a utility, right?

462
00:27:28,265 --> 00:27:31,885
Speaker 3:  Not as a business that they run, but as the water or

463
00:27:32,205 --> 00:27:34,965
Speaker 3:  electricity of the internet. It's just a neutral utility. You just stop.

464
00:27:35,025 --> 00:27:38,805
Speaker 3:  You just use it. And we don't have any ideas about it. It's just we set the

465
00:27:38,805 --> 00:27:39,965
Speaker 3:  robots to crawl the internet and they,

466
00:27:39,965 --> 00:27:40,885
Speaker 5:  They're just a baby.

467
00:27:41,035 --> 00:27:44,645
Speaker 3:  Yeah. They just find the stuff and they show it to you. And when you try

468
00:27:44,645 --> 00:27:48,205
Speaker 3:  to cover search as anything other than a utility, the

469
00:27:48,485 --> 00:27:51,205
Speaker 3:  attitude from Google is like, why would you do that? Right? We wanna teach

470
00:27:51,205 --> 00:27:53,365
Speaker 3:  people how search works. And we're like, no, there's like a culture of search.

471
00:27:53,365 --> 00:27:57,165
Speaker 3:  Like the same way that there's a culture of TikTok, right. And that's been

472
00:27:57,165 --> 00:28:00,405
Speaker 3:  a disconnect. But they have done that on purpose, right? Because if you treat

473
00:28:00,405 --> 00:28:04,285
Speaker 3:  something like a utility or a neutral algorithm or just the right

474
00:28:04,285 --> 00:28:07,965
Speaker 3:  answer that the Google brilliance of page rank has discovered across the

475
00:28:07,965 --> 00:28:11,685
Speaker 3:  web, then maybe you don't poke at it too much. And inside these

476
00:28:11,925 --> 00:28:15,725
Speaker 3:  documents we find things like Nav Boost as part of a

477
00:28:15,725 --> 00:28:19,085
Speaker 3:  system that is called Twiddles. Yeah,

478
00:28:20,235 --> 00:28:20,525
Speaker 6:  TWIs.

479
00:28:21,105 --> 00:28:24,685
Speaker 3:  And the way, so to think about it is like the big Google

480
00:28:24,685 --> 00:28:28,645
Speaker 3:  algorithm is like the backend and right before it displays your

481
00:28:28,645 --> 00:28:32,565
Speaker 3:  result, the Twiddles show up and they twiddle the

482
00:28:32,585 --> 00:28:33,005
Speaker 3:  result.

483
00:28:33,625 --> 00:28:34,285
Speaker 5:  We just twiddle

484
00:28:34,405 --> 00:28:36,925
Speaker 3:  A little thought. And so nav boosts is a twiddler, it's like categorized

485
00:28:36,925 --> 00:28:39,045
Speaker 3:  as a twiddler. It's like we went and found some other stuff and we're just,

486
00:28:39,185 --> 00:28:42,045
Speaker 3:  we gonna shuffle that around a little bit. And there's a bunch of those.

487
00:28:42,905 --> 00:28:46,245
Speaker 3:  And like lots of Google systems are built as Twiddler, so they have plausible

488
00:28:46,245 --> 00:28:49,805
Speaker 3:  deniability that the core search ranking algorithm

489
00:28:50,155 --> 00:28:53,645
Speaker 3:  doesn't take these factors in. Right. But right

490
00:28:53,745 --> 00:28:54,965
Speaker 3:  before they show 'em to you

491
00:28:55,995 --> 00:28:56,925
Speaker 5:  Just a little twiddle

492
00:28:57,285 --> 00:29:01,085
Speaker 3:  Twiddles baby. And it's like, I'm not that stupid.

493
00:29:02,265 --> 00:29:05,245
Speaker 3:  You know? It's like it's one system that displays a search result at the

494
00:29:05,245 --> 00:29:08,645
Speaker 3:  end where it happens. Like I don't think they can run around being like we

495
00:29:08,645 --> 00:29:11,525
Speaker 3:  were always telling the truth. Yeah. It's just these, these twiddles are

496
00:29:11,525 --> 00:29:12,605
Speaker 3:  outta control, right.

497
00:29:13,075 --> 00:29:16,885
Speaker 5:  They, they have no control over it. They're just a baby. I, that's, it's

498
00:29:16,885 --> 00:29:19,725
Speaker 5:  my favorite thing that everybody does now when they screw up, they just go,

499
00:29:19,745 --> 00:29:21,165
Speaker 5:  I'm just a baby. No, no,

500
00:29:21,185 --> 00:29:22,925
Speaker 3:  No. It's my first day running search

501
00:29:23,425 --> 00:29:25,205
Speaker 5:  Who can say over

502
00:29:25,205 --> 00:29:27,925
Speaker 3:  Yourselves? Anyhow, we are gonna learn a lot more about this. I,

503
00:29:28,985 --> 00:29:32,725
Speaker 3:  we often try not to oversell things. I'm just telling you the, the web, the

504
00:29:32,725 --> 00:29:36,645
Speaker 3:  people who make the web are a flame because of these

505
00:29:36,925 --> 00:29:40,885
Speaker 3:  documents. Because they do make Google seem, if not outright a

506
00:29:40,965 --> 00:29:44,885
Speaker 3:  liar as though they have been socially engineering a community of

507
00:29:44,885 --> 00:29:48,245
Speaker 3:  people who make things into not believing what they see as David is saying.

508
00:29:48,385 --> 00:29:52,165
Speaker 3:  You know? And I think the backlash there is going to be ferocious.

509
00:29:52,395 --> 00:29:56,205
Speaker 3:  Yeah. Especially as search traffic declines, especially as user

510
00:29:56,485 --> 00:30:00,165
Speaker 3:  behavior changes around ai, especially as the AI results continue to tell

511
00:30:00,165 --> 00:30:04,045
Speaker 3:  people to eat glue. Like it's not, there's not a lot of

512
00:30:04,055 --> 00:30:07,965
Speaker 3:  trust left in this ecosystem. And it's, it's, to me,

513
00:30:07,965 --> 00:30:10,765
Speaker 3:  it's weird that there's not more coverage of it. It's not as sexy as the

514
00:30:10,885 --> 00:30:13,645
Speaker 3:  Facebook algorithm or Elon saying is an open source, the Twitter algorithm.

515
00:30:14,505 --> 00:30:17,445
Speaker 3:  But like David said, this is the architecture of the internet. Yeah. I

516
00:30:17,445 --> 00:30:21,205
Speaker 5:  Think it is. That's why it's so hard for people. It it is so ingrained in

517
00:30:21,225 --> 00:30:25,205
Speaker 5:  how most people function that it's shocking to

518
00:30:25,205 --> 00:30:28,205
Speaker 5:  them to a where point where it's like, I, I can't even process this. I have

519
00:30:28,205 --> 00:30:31,605
Speaker 5:  to go. Yeah. Like most people, I don't think fully grasp how much the goog,

520
00:30:31,785 --> 00:30:35,565
Speaker 5:  the Google and most people don't fully grasp how much Google affects

521
00:30:35,575 --> 00:30:39,325
Speaker 5:  their online experience. They just don't. They know it. They see it and everything,

522
00:30:39,325 --> 00:30:43,125
Speaker 5:  but it's just like, just gloss over it. And now it's like, oh,

523
00:30:43,125 --> 00:30:45,925
Speaker 5:  you're having to actually reckon with this and think about this. Yeah.

524
00:30:45,955 --> 00:30:49,245
Speaker 6:  It's why I always like to talk about cooking websites because the, if you

525
00:30:49,245 --> 00:30:52,845
Speaker 6:  want the, if you want the single cleanest example of how Google

526
00:30:52,845 --> 00:30:56,645
Speaker 6:  changes the way a webpage works, go read a recipe

527
00:30:57,075 --> 00:31:01,005
Speaker 6:  site. You, you will see everything you need to

528
00:31:01,005 --> 00:31:04,405
Speaker 6:  see, you'll see the H twos, which Google wants because they're gonna be questions

529
00:31:04,405 --> 00:31:07,485
Speaker 6:  that people might be Googling. You're gonna see the jump to recipe thing.

530
00:31:07,485 --> 00:31:11,245
Speaker 6:  But then you're also gonna see 2000 words of nonsense about their lives

531
00:31:11,245 --> 00:31:14,845
Speaker 6:  because you have to actually stay on the page a long time in order for Google

532
00:31:15,105 --> 00:31:18,365
Speaker 6:  to believe that that's a successful search. They want images that's very

533
00:31:18,365 --> 00:31:22,085
Speaker 6:  important to Google. Like you, every single pixel of that

534
00:31:22,155 --> 00:31:26,045
Speaker 6:  page right down to how the recipe is structured is made for Google. And

535
00:31:26,045 --> 00:31:28,485
Speaker 6:  anyone who runs a food blog will tell you that the fundamental tension is

536
00:31:28,485 --> 00:31:31,605
Speaker 6:  like, I did this because I like food and I actually work for Google. And

537
00:31:31,605 --> 00:31:33,365
Speaker 6:  that feels crappy to a lot of people.

538
00:31:33,505 --> 00:31:36,125
Speaker 3:  And now Google's gonna take that stuff and show the recipes to people in

539
00:31:36,185 --> 00:31:36,405
Speaker 3:  ai.

540
00:31:36,575 --> 00:31:39,485
Speaker 6:  Right. But I do think, what one more thought on this that I've, I've been

541
00:31:39,665 --> 00:31:43,565
Speaker 6:  seeing a lot of increasingly in the SEO world and I think is a really interesting,

542
00:31:43,565 --> 00:31:47,325
Speaker 6:  like internet question is one way to read

543
00:31:47,645 --> 00:31:51,525
Speaker 6:  a lot of what we've seen in these leaks is that SEO

544
00:31:51,585 --> 00:31:55,485
Speaker 6:  is dead and no longer will work. Like there,

545
00:31:55,485 --> 00:31:59,125
Speaker 6:  lemme, I, I copied this one paragraph out from the thing that Rand wrote.

546
00:32:00,505 --> 00:32:04,445
Speaker 6:  He said, Google no longer rewards scrappy, clever SEO savvy operators

547
00:32:04,445 --> 00:32:07,645
Speaker 6:  who know all the right tricks. They reward established brands, search measurable

548
00:32:07,645 --> 00:32:11,205
Speaker 6:  forms of popularity and established domains that searchers already know and

549
00:32:11,205 --> 00:32:14,845
Speaker 6:  click from 1998 to 2018 or so, one could reasonably start a

550
00:32:15,005 --> 00:32:18,765
Speaker 6:  powerful marketing flywheel with SEO for Google in 2024. I don't think that's

551
00:32:18,765 --> 00:32:22,045
Speaker 6:  realistic, at least not on the English language web in competitive sectors.

552
00:32:22,605 --> 00:32:26,485
Speaker 6:  Hmm. Like there is a, there is a real defeatism to the idea

553
00:32:26,485 --> 00:32:30,085
Speaker 6:  that Google cares a lot about the sites that already exist, the places people

554
00:32:30,085 --> 00:32:33,885
Speaker 6:  already go, what has been going on for a long time. And the idea that

555
00:32:33,885 --> 00:32:37,805
Speaker 6:  you can come and be new and good and smart and people will find you because

556
00:32:37,805 --> 00:32:38,645
Speaker 6:  that's how Google works

557
00:32:39,305 --> 00:32:42,765
Speaker 3:  Is a dying theory. Yeah. I asked this question to

558
00:32:43,325 --> 00:32:47,085
Speaker 3:  a lot of just media people, website

559
00:32:47,475 --> 00:32:50,565
Speaker 3:  CEOs and decoder. I asked this question to Sundar, why would anyone make

560
00:32:50,565 --> 00:32:53,685
Speaker 3:  a website? You're a new creator. We're we're all gonna quit our jobs at a

561
00:32:53,685 --> 00:32:57,445
Speaker 3:  OL, which you should do. Can't recommend it

562
00:32:57,565 --> 00:32:59,125
Speaker 3:  enough. Best decision I've ever made.

563
00:32:59,365 --> 00:33:00,525
Speaker 5:  I, I don't plan on doing it, but

564
00:33:00,625 --> 00:33:04,405
Speaker 3:  You should go get a job at AAL just to quit. Just to quit. But that's, you

565
00:33:04,405 --> 00:33:06,845
Speaker 3:  know, that's how we found out The Verge. We all worked at Eng Gadget 2010.

566
00:33:06,845 --> 00:33:10,765
Speaker 3:  2011. We had this idea for The Verge, we all quit and we're gonna start

567
00:33:10,765 --> 00:33:14,005
Speaker 3:  a new thing. We started a website, like a big

568
00:33:15,035 --> 00:33:18,925
Speaker 3:  desktop website. We didn't even have a mobile site. We started a

569
00:33:18,925 --> 00:33:22,725
Speaker 3:  big hairy desktop website with like forums and features and all this

570
00:33:22,725 --> 00:33:25,925
Speaker 3:  stuff. And then the mobile web came and we shrunk down the thing and whatever.

571
00:33:26,865 --> 00:33:30,405
Speaker 3:  But it was never a question that we would start anything but a website.

572
00:33:30,735 --> 00:33:34,445
Speaker 3:  There were 12 of us. We had a big idea. We wanted to do a thing. What we

573
00:33:34,765 --> 00:33:38,645
Speaker 3:  were gonna do was start a website. I think if you get to that place in

574
00:33:38,645 --> 00:33:42,085
Speaker 3:  2024, maybe some people are gonna start a substack. I don't think they think

575
00:33:42,085 --> 00:33:44,885
Speaker 3:  of those things as websites. Those are newsletters or independent newsletter

576
00:33:44,885 --> 00:33:48,565
Speaker 3:  and ghost or whatever. Mostly what they're gonna do is start YouTube channels

577
00:33:48,905 --> 00:33:50,485
Speaker 3:  and TikTok channels. Yeah. The,

578
00:33:50,545 --> 00:33:53,845
Speaker 5:  The only people I see who are kind of doing that sort of thing, like Right,

579
00:33:53,845 --> 00:33:56,765
Speaker 5:  leaving their jobs, whatever and being like, I'm gonna start a website are

580
00:33:56,765 --> 00:34:00,085
Speaker 5:  already established brands. Right? Yep. Like the folks who are over at oh

581
00:34:00,085 --> 00:34:03,885
Speaker 5:  four, KU 4 0 4 who are from Vice, these folks just said, I'm gonna go and

582
00:34:03,885 --> 00:34:07,165
Speaker 5:  I'm gonna start a new thing. And I, they all take that model from Deadspin

583
00:34:07,165 --> 00:34:10,885
Speaker 5:  that became defector. Yeah. And, and that works.

584
00:34:11,065 --> 00:34:11,965
Speaker 5:  But that is,

585
00:34:12,585 --> 00:34:13,965
Speaker 3:  You have to have an audience already. Yeah.

586
00:34:13,965 --> 00:34:17,205
Speaker 5:  The, the, that worked because they have that audience, right? Like most people

587
00:34:17,205 --> 00:34:20,205
Speaker 5:  don't have that audience and don't have that scale. And I think Casey's written

588
00:34:20,205 --> 00:34:24,125
Speaker 5:  about that a lot of like, he has to work to get platformer out. He has

589
00:34:24,125 --> 00:34:27,805
Speaker 5:  to like really put in the effort because scale is hard

590
00:34:28,505 --> 00:34:30,765
Speaker 5:  and it's much, much harder now because of Google.

591
00:34:31,035 --> 00:34:34,845
Speaker 3:  Yeah. And I, those sites are all great. I don't think they like four

592
00:34:34,845 --> 00:34:37,925
Speaker 3:  four is on ghost. Yeah. Right. So they're taking advantage of some, some

593
00:34:37,925 --> 00:34:40,565
Speaker 3:  infrastructure for newsletter that exists that lets them be a different kind

594
00:34:40,565 --> 00:34:44,525
Speaker 3:  of thing. But the idea that like we coded our

595
00:34:44,525 --> 00:34:47,365
Speaker 3:  website from scratch, you wouldn't do that. We're like, build a product that

596
00:34:47,365 --> 00:34:49,725
Speaker 3:  is a website. I didn't do it. Yeah,

597
00:34:50,065 --> 00:34:51,925
Speaker 5:  But you, you people would do that in 2024.

598
00:34:52,225 --> 00:34:55,405
Speaker 3:  We, it was just not a good investment in 2024 for the reason David is saying.

599
00:34:55,435 --> 00:34:59,165
Speaker 3:  Yeah. And there's, you know, many things have changed in the past 13 years,

600
00:34:59,465 --> 00:35:02,845
Speaker 3:  but the idea that the new creators

601
00:35:03,745 --> 00:35:07,685
Speaker 3:  on the internet will not go to the open web, but instead

602
00:35:07,815 --> 00:35:11,045
Speaker 3:  we'll go to a closed video platform, I think is very dangerous.

603
00:35:11,665 --> 00:35:15,165
Speaker 3:  And I don't know the right answer to get people back to making

604
00:35:15,755 --> 00:35:19,205
Speaker 3:  open searchable web properties. If the biggest search engine is like,

605
00:35:19,615 --> 00:35:23,605
Speaker 3:  screw it, like Hearst, we'll just everyone can go read Dash Meredith,

606
00:35:24,315 --> 00:35:27,765
Speaker 3:  like whatever. You know, like maybe that's the right outcome. And maybe that's

607
00:35:27,765 --> 00:35:31,565
Speaker 3:  just the closing of the web. But I, again, the reason we started

608
00:35:31,845 --> 00:35:34,605
Speaker 3:  covering it last year is 'cause I was like, oh, the comment's coming and

609
00:35:34,605 --> 00:35:37,285
Speaker 3:  the more we covered it we're like, oh, the comment's coming. Like we should

610
00:35:37,285 --> 00:35:41,245
Speaker 3:  capture this moment. And it feels like, again, I thought the

611
00:35:41,245 --> 00:35:44,885
Speaker 3:  comment would be ai. I thought I did not expect it to be like

612
00:35:45,205 --> 00:35:49,125
Speaker 3:  everyone is this mad and, and it just feels like, ugh. We'll we'll see

613
00:35:49,125 --> 00:35:51,245
Speaker 3:  how it goes. We're gonna cover a lot more of it. I think the other browser

614
00:35:51,245 --> 00:35:55,085
Speaker 3:  makers, regulators, there's just flood

615
00:35:55,085 --> 00:35:58,645
Speaker 3:  of negative emotion about how Google has behaved

616
00:35:58,955 --> 00:36:01,445
Speaker 3:  that it might, it just, it feels like it's coming to a head. I

617
00:36:01,605 --> 00:36:04,325
Speaker 5:  I do have one question for you guys. Yeah. Especially you David. 'cause you

618
00:36:04,325 --> 00:36:08,165
Speaker 5:  use a lot of different search engines. Are any of them good?

619
00:36:08,315 --> 00:36:11,085
Speaker 5:  Like do any of them when you go, when you search something actually give

620
00:36:11,085 --> 00:36:15,045
Speaker 5:  you those unique results that used to be like, Ooh, yeah, now I know

621
00:36:15,045 --> 00:36:17,045
Speaker 5:  what I'm doing on this, this search engine?

622
00:36:19,465 --> 00:36:23,085
Speaker 6:  Yes and no. Coy, which is the one you mentioned, which is also what I use.

623
00:36:23,085 --> 00:36:25,845
Speaker 6:  It's 10 bucks a month. It's excellent. I cannot recommend it enough. Paying

624
00:36:25,845 --> 00:36:29,325
Speaker 6:  for a search engine feels ridiculous, but it's worth, it has a thing

625
00:36:30,195 --> 00:36:33,925
Speaker 6:  that it calls small web where it actually deliberately built

626
00:36:34,285 --> 00:36:37,925
Speaker 6:  a like crowdsource database of sites that aren't

627
00:36:38,225 --> 00:36:42,165
Speaker 6:  The Verge and aren't like big mainstream news sites, the

628
00:36:42,165 --> 00:36:46,085
Speaker 6:  kind that dominate search results but are like people's blogs and little

629
00:36:46,115 --> 00:36:49,565
Speaker 6:  alternative news sites and local newspapers and all the kinds of cool stuff.

630
00:36:49,585 --> 00:36:53,565
Speaker 6:  And you can, you can toggle the search just to that. Yeah. And I think

631
00:36:54,025 --> 00:36:57,885
Speaker 6:  the, the sort of big omnibus search is never coming back

632
00:36:57,915 --> 00:37:01,845
Speaker 6:  from what it is now. It's you, you, it's just interface changes really.

633
00:37:01,845 --> 00:37:05,085
Speaker 6:  Like I think Cogi stuff is better than Google, but mostly just because it's

634
00:37:05,085 --> 00:37:08,285
Speaker 6:  a nicer thing to use than Google is at this moment. Especially

635
00:37:08,285 --> 00:37:08,765
Speaker 5:  In Arc.

636
00:37:09,915 --> 00:37:13,405
Speaker 6:  Yeah. But where we are now is like the, the only

637
00:37:13,925 --> 00:37:17,245
Speaker 6:  solution is going to be to artificially decide

638
00:37:17,575 --> 00:37:21,285
Speaker 6:  which part of the web you wanna look at. Because all of the

639
00:37:21,285 --> 00:37:25,125
Speaker 6:  signals for the rest of the web are, are starting to break

640
00:37:25,125 --> 00:37:28,765
Speaker 6:  away from that. Like find and explore new things

641
00:37:29,475 --> 00:37:33,285
Speaker 6:  vibe because that's harder to do and harder to measure than,

642
00:37:34,025 --> 00:37:37,965
Speaker 6:  oh people generally believe that Neli is right about

643
00:37:37,965 --> 00:37:40,885
Speaker 6:  which printer to buy. And that's actually like a pretty easy thing for a

644
00:37:40,885 --> 00:37:44,245
Speaker 6:  search engine to believe and send you to over and over again. Yeah.

645
00:37:44,425 --> 00:37:47,165
Speaker 3:  And we will continue ruthlessly using our domain authority.

646
00:37:47,825 --> 00:37:48,685
Speaker 5:  We will I love it

647
00:37:48,705 --> 00:37:49,725
Speaker 3:  To break big printer.

648
00:37:51,815 --> 00:37:54,205
Speaker 3:  David, I can't remember if it was you who said this to Casey, might have

649
00:37:54,205 --> 00:37:57,525
Speaker 3:  said it to me in passing. We used to think of surfing the web as a fun thing

650
00:37:57,525 --> 00:38:01,445
Speaker 3:  to do and all of Google's messaging at IO was let go do

651
00:38:01,445 --> 00:38:05,405
Speaker 3:  the Googling for you. Yeah. Which makes it seem like work. And it's

652
00:38:05,405 --> 00:38:08,645
Speaker 3:  like, no, this is how I wasted time. Do you know how much I didn't pay attention

653
00:38:08,645 --> 00:38:11,645
Speaker 3:  in law school because I was just browsing the web in class.

654
00:38:12,635 --> 00:38:16,365
Speaker 3:  Like that's a, it's weird that we've made the web this unpleasant and the

655
00:38:16,565 --> 00:38:19,845
Speaker 3:  platforms figured it out. And hopefully we can get some of that back. I dunno

656
00:38:19,845 --> 00:38:23,325
Speaker 3:  if we can, we're gonna keep running a website. We're not. We do have a TikTok

657
00:38:23,325 --> 00:38:26,365
Speaker 3:  for as long as TikTok, but that's good. All right. We're gonna keep using

658
00:38:26,385 --> 00:38:28,765
Speaker 3:  our domain authority to crush big printer. Hell

659
00:38:28,785 --> 00:38:29,605
Speaker 5:  Yes. Just

660
00:38:29,605 --> 00:38:33,565
Speaker 3:  Ruthless, ruthless domain authority abuse. But that's our mission here

661
00:38:33,565 --> 00:38:35,445
Speaker 3:  at the bridge. We gotta take a break. We'll be right back.

662
00:41:51,365 --> 00:41:53,565
Speaker 3:  Media signed a content

663
00:42:41,125 --> 00:42:44,565
Speaker 3:  sincerely doubt that is true. I'll do my best. I'll, it is more likely that

664
00:42:44,565 --> 00:42:47,845
Speaker 3:  I will see someone else's contract before I see our own companies.

665
00:42:47,905 --> 00:42:51,445
Speaker 6:  Oh, that's interesting. That's a, that's a fun reporting tactic. Can I, can

666
00:42:51,445 --> 00:42:53,685
Speaker 6:  I bully my boss before I can bully somebody else?

667
00:42:54,785 --> 00:42:57,925
Speaker 3:  That's good. The, our company's very good at being like, no, you can't just

668
00:42:57,925 --> 00:43:01,045
Speaker 3:  report on our own company. Other companies. Like here's the stuff like Yeah.

669
00:43:01,305 --> 00:43:02,805
Speaker 3:  It, that's just the way of being a reporter.

670
00:43:02,995 --> 00:43:06,685
Speaker 6:  Yeah. That, that's fair. But so I, I am curious for you as like a, a newsroom

671
00:43:06,865 --> 00:43:10,765
Speaker 6:  leader, how you even think through what a deal like

672
00:43:10,765 --> 00:43:11,885
Speaker 6:  this means.

673
00:43:12,715 --> 00:43:13,005
Speaker 3:  Sure.

674
00:43:14,945 --> 00:43:18,685
Speaker 3:  We do a lot of disclosures on this show. Famously,

675
00:43:18,965 --> 00:43:22,845
Speaker 3:  I think I've had journalism professors talk to me about the fact that our

676
00:43:22,845 --> 00:43:26,805
Speaker 3:  disclosures are a running joke with the audience. Like we wanna be really

677
00:43:26,805 --> 00:43:29,525
Speaker 3:  transparent about where information comes from.

678
00:43:31,155 --> 00:43:34,965
Speaker 3:  Reasons to not trust us. If you don't wanna trust us, like

679
00:43:35,385 --> 00:43:38,965
Speaker 3:  my goal is always to just empower the audience with information.

680
00:43:39,505 --> 00:43:42,485
Speaker 3:  That's the top level. So like if you're listening to this and you've listened

681
00:43:42,485 --> 00:43:46,325
Speaker 3:  to the show, that's why we do disclosures. That's why they're a joke. Like

682
00:43:46,485 --> 00:43:49,925
Speaker 3:  I want, the only currency we have as a news organization is trust.

683
00:43:50,305 --> 00:43:53,125
Speaker 3:  So we're trying to, that's why we have the background policy, right? All

684
00:43:53,125 --> 00:43:56,925
Speaker 3:  the spokespeople have to use their names when they talk to us because

685
00:43:56,925 --> 00:44:00,365
Speaker 3:  we don't wanna pretend we know something that they just told us. If, right,

686
00:44:00,825 --> 00:44:04,445
Speaker 3:  if Google or Apple or Microsoft or whoever wants to talk to us and get some

687
00:44:04,445 --> 00:44:07,885
Speaker 3:  information on our pages, they need to be accountable for it, not us. And

688
00:44:07,885 --> 00:44:10,685
Speaker 3:  that's just trust. That's just who are you gonna trust? Where does a trust

689
00:44:10,745 --> 00:44:13,805
Speaker 3:  go? Who do you have to trust for to believe this story?

690
00:44:14,545 --> 00:44:18,125
Speaker 3:  So that's the top level right next to that, which I

691
00:44:18,255 --> 00:44:21,925
Speaker 3:  think the audience doesn't see as much because why would you

692
00:44:22,505 --> 00:44:25,845
Speaker 3:  is our newsroom has to not think about it.

693
00:44:26,635 --> 00:44:30,485
Speaker 3:  Like that's actually what independence is, right? Is not, I know

694
00:44:30,555 --> 00:44:34,405
Speaker 3:  that our company has a deal or an investor and

695
00:44:34,505 --> 00:44:38,245
Speaker 3:  I'm just going to like, I'm gonna think about it as I write the story.

696
00:44:38,385 --> 00:44:41,965
Speaker 3:  The goal is they don't think about it at all. Right? And we just go do the

697
00:44:41,965 --> 00:44:45,885
Speaker 3:  reporting and we publish what is true or what we believe or what we

698
00:44:45,885 --> 00:44:49,845
Speaker 3:  think people should know, right? And that that the, in any

699
00:44:49,845 --> 00:44:53,245
Speaker 3:  traditional newsroom, that's the what is called the firewall,

700
00:44:54,135 --> 00:44:57,525
Speaker 3:  right? So we do stuff, our sales team, there's advertising over it there.

701
00:44:57,545 --> 00:44:58,885
Speaker 3:  We just came back from an ad break,

702
00:45:00,535 --> 00:45:03,725
Speaker 3:  right? Like in that team. But we don't know what the ads are. I don't know

703
00:45:03,725 --> 00:45:06,965
Speaker 3:  what ads just played. I get so many emails. What the crypto ads? I don't

704
00:45:06,965 --> 00:45:10,885
Speaker 3:  know man. Yeah. Like I think crypto's stupid shit. Like what do

705
00:45:10,885 --> 00:45:14,365
Speaker 3:  you want me to do? Like that's that team. And if we open the door and start

706
00:45:14,365 --> 00:45:18,285
Speaker 3:  telling that team what to do, the danger, and this is a danger that is proven

707
00:45:18,305 --> 00:45:20,725
Speaker 3:  out over and over again in newsrooms around the world. If we open the door

708
00:45:20,725 --> 00:45:23,765
Speaker 3:  and start telling them what to do, they're like, Hey, that door's open, right?

709
00:45:24,175 --> 00:45:26,765
Speaker 3:  We're gonna start telling you what to do. So we just keep the door closed.

710
00:45:26,765 --> 00:45:29,325
Speaker 3:  This is why you have the firewall. It works in both directions.

711
00:45:30,825 --> 00:45:34,525
Speaker 3:  So for me, and I understand open eye in particular is pretty shady company.

712
00:45:34,605 --> 00:45:37,005
Speaker 3:  I feel like our entire episode last week was like, this company is pretty

713
00:45:37,005 --> 00:45:39,205
Speaker 3:  shady. We're gonna talk about Tim. I was like, I just wanna talk

714
00:45:41,405 --> 00:45:41,485
Speaker 3:  whatever.

715
00:45:43,915 --> 00:45:47,845
Speaker 3:  Fine. But like that's the commercial side of our company. And I

716
00:45:47,845 --> 00:45:50,285
Speaker 3:  understand, like I've talked to a lot of media executives, like I'm running

717
00:45:50,285 --> 00:45:53,165
Speaker 3:  around covering Google Zero. I've been talking to a lot of media people lately

718
00:45:53,165 --> 00:45:56,325
Speaker 3:  and I can talk about that bigger question David, of like, are these good

719
00:45:56,325 --> 00:45:59,125
Speaker 3:  deals? Are these like a good idea broadly? 'cause I think I've done some

720
00:45:59,125 --> 00:46:02,645
Speaker 3:  reporting, I have some thoughts about that. But the thing that

721
00:46:02,915 --> 00:46:06,605
Speaker 3:  like when our press release went out, like no, we're not gonna change our

722
00:46:06,605 --> 00:46:10,085
Speaker 3:  recover open ai. Yes. I think when it's appropriate we'll disclose it.

723
00:46:11,035 --> 00:46:14,885
Speaker 3:  It's not like a, like Comcast is an

724
00:46:15,205 --> 00:46:18,005
Speaker 3:  investor in our company, right? Like we disclose it every time we whisper

725
00:46:18,055 --> 00:46:21,845
Speaker 3:  about Comcast 'cause they're an investor. This is a licensing deal. Like

726
00:46:22,025 --> 00:46:24,925
Speaker 3:  we have a lot of those across our company. And I don't wanna just get into

727
00:46:25,205 --> 00:46:28,605
Speaker 3:  a situation where I'm like, disclosure Yahoo

728
00:46:28,885 --> 00:46:32,245
Speaker 3:  licenses and RSS feed of the Dodo. Like what do you want?

729
00:46:32,635 --> 00:46:35,725
Speaker 3:  Like I think that door can get too open. We can overread it so we'll just

730
00:46:35,725 --> 00:46:39,685
Speaker 3:  first cast would go a little long. It would go a little long. And

731
00:46:39,685 --> 00:46:42,405
Speaker 3:  I want to preserve our independence. So what independence really means to

732
00:46:42,405 --> 00:46:46,005
Speaker 3:  me is yes, we'll disclose it. Yes, we'll earn everyone's trust. But I would

733
00:46:46,005 --> 00:46:49,685
Speaker 3:  prefer it if we were just covering open AI without thinking about it.

734
00:46:50,105 --> 00:46:53,365
Speaker 3:  And so that's, that's the balance I'm trying to strike. I'm open to people's

735
00:46:53,365 --> 00:46:57,045
Speaker 3:  thoughts about how much you need from us to continue having that trust.

736
00:46:58,545 --> 00:47:02,325
Speaker 3:  But it is in many ways, like more of a normal

737
00:47:02,515 --> 00:47:06,085
Speaker 3:  deal than people are expecting. Right? Like when,

738
00:47:06,915 --> 00:47:10,405
Speaker 3:  when we did a Netflix show, I think there was less outcry,

739
00:47:10,745 --> 00:47:14,085
Speaker 3:  but like I was the producer of a disclosure. I made a Netflix show.

740
00:47:14,815 --> 00:47:18,525
Speaker 3:  Every time you should watch, you should watch a Netflix show. Like David

741
00:47:18,525 --> 00:47:21,765
Speaker 3:  and I are gonna make one just so that we, that like way messier, right? Like

742
00:47:21,785 --> 00:47:24,885
Speaker 3:  I'm going to meetings at Netflix about our show that I was not allowed to

743
00:47:24,885 --> 00:47:28,245
Speaker 3:  talk about until our show was made. So I wanna make sure we like find the

744
00:47:28,245 --> 00:47:31,765
Speaker 3:  right balance. And I understand there's just a lot of feelings about O

745
00:47:32,065 --> 00:47:36,045
Speaker 3:  AI and open AI in particular, but like at

746
00:47:36,045 --> 00:47:36,885
Speaker 3:  the end of the day,

747
00:47:38,625 --> 00:47:42,285
Speaker 3:  the goal for all of these media companies is to just get some

748
00:47:42,285 --> 00:47:44,925
Speaker 3:  control back out of a situation that felt out of control.

749
00:47:46,145 --> 00:47:47,205
Speaker 6:  In what situation is that?

750
00:47:47,755 --> 00:47:49,005
Speaker 3:  Well, they took everything anyway.

751
00:47:49,455 --> 00:47:49,805
Speaker 6:  Right?

752
00:47:50,655 --> 00:47:53,765
Speaker 3:  Right. That's the situation. And we can talk about that broadly. I just want

753
00:47:53,765 --> 00:47:57,565
Speaker 3:  to separate the two things. Like our newsroom is independent.

754
00:47:58,425 --> 00:48:02,325
Speaker 3:  OpenAI did not buy any control of our newsroom. We will

755
00:48:02,465 --> 00:48:06,325
Speaker 3:  be very honest with everybody when we think the disclosure would

756
00:48:06,425 --> 00:48:10,125
Speaker 3:  affect how you perceive one of our stories. And I think that,

757
00:48:10,585 --> 00:48:12,925
Speaker 3:  you know, around copyright law, like that makes sense to me. We're gonna

758
00:48:12,925 --> 00:48:16,085
Speaker 3:  write a story about the New York Times lawsuit against open ai. That is a

759
00:48:16,085 --> 00:48:20,045
Speaker 3:  great place for disclosure open AI launches a new GPT feature. Like, I dunno,

760
00:48:20,045 --> 00:48:23,565
Speaker 3:  you tell me. Maybe we need to do that every time. But like I I, I don't wanna

761
00:48:23,605 --> 00:48:27,525
Speaker 3:  overread it as though to make it seem like we're doing something

762
00:48:27,525 --> 00:48:31,405
Speaker 3:  we're not. So that's it. That's like my top line. Like we will have

763
00:48:31,405 --> 00:48:34,525
Speaker 3:  a disclosure. I love a disclosure disclosure. Comcast is an investor in Vox

764
00:48:34,525 --> 00:48:36,885
Speaker 3:  Media. I'm in an Netflix show.

765
00:48:36,885 --> 00:48:39,965
Speaker 6:  Disclosure, Alex. Cranz is the last remaining Paramount Plus subscriber.

766
00:48:40,245 --> 00:48:40,445
Speaker 6:  It's

767
00:48:40,445 --> 00:48:44,285
Speaker 3:  True. Hi, look, I, this is our brand and

768
00:48:44,285 --> 00:48:46,765
Speaker 3:  we're gonna do them. I just, the thing that I am

769
00:48:48,105 --> 00:48:51,925
Speaker 3:  trying to be careful about is separating

770
00:48:51,925 --> 00:48:55,485
Speaker 3:  how people feel about these deals broadly and what it means for our

771
00:48:55,485 --> 00:48:56,365
Speaker 3:  newsroom. Right?

772
00:48:56,365 --> 00:48:57,085
Speaker 6:  Bullet. Let's talk. And

773
00:48:57,085 --> 00:49:00,005
Speaker 3:  What it means for our newsroom is the status quo. Like it is not changing.

774
00:49:00,185 --> 00:49:03,645
Speaker 3:  We are gonna operate without fear or favor. And

775
00:49:04,015 --> 00:49:07,485
Speaker 3:  again, my goal is to earn everyone's trust by being as transparent as we

776
00:49:07,485 --> 00:49:11,165
Speaker 3:  can be. And I just wanna make sure that we're not so transparent that we

777
00:49:11,325 --> 00:49:15,245
Speaker 3:  actually go in a full circle and no one believes us. So like you

778
00:49:15,245 --> 00:49:17,605
Speaker 3:  tell me where you think the line is. I'm open to the feedback. I, I ask for

779
00:49:17,605 --> 00:49:21,285
Speaker 3:  it from our staff today. I'm asking for it from the audience today. But the,

780
00:49:21,385 --> 00:49:25,285
Speaker 3:  the main thing is not changing, which is I want, I, I would prefer it

781
00:49:25,345 --> 00:49:29,245
Speaker 3:  if our reporters were not worried about an opening ideal or thinking

782
00:49:29,245 --> 00:49:32,045
Speaker 3:  about it and we just covered the company like we have been for a long time.

783
00:49:32,075 --> 00:49:32,365
Speaker 3:  Yeah.

784
00:49:32,365 --> 00:49:35,925
Speaker 6:  Yeah. And this is the thing we should say, like a, a thing I've learned about

785
00:49:35,925 --> 00:49:38,445
Speaker 6:  the media business over the years is that it's very unusual in the sense

786
00:49:38,645 --> 00:49:42,445
Speaker 6:  that like, that tension you're describing between the work that we do and

787
00:49:42,445 --> 00:49:45,485
Speaker 6:  where the money comes from is like good and healthy and should always exist.

788
00:49:45,625 --> 00:49:49,365
Speaker 6:  And the, our editorial and sales team should always like, hate each other

789
00:49:49,485 --> 00:49:50,285
Speaker 6:  a little bit. Yeah. It's like

790
00:49:50,285 --> 00:49:50,685
Speaker 3:  A useful

791
00:49:50,685 --> 00:49:54,445
Speaker 6:  Thing. But also like we have tech company ads

792
00:49:54,745 --> 00:49:58,725
Speaker 6:  all over our website. Yeah. Like that is, that is a, it's, it's a not dissimilar

793
00:49:58,735 --> 00:50:02,525
Speaker 6:  thing. And it is, it is just something you have to navigate and get comfortable

794
00:50:02,525 --> 00:50:06,285
Speaker 6:  with. And like people always like sending us the stuff where I, we will,

795
00:50:06,285 --> 00:50:10,205
Speaker 6:  we will make a vergecast about how terrible Facebook is right before a Facebook

796
00:50:10,225 --> 00:50:14,165
Speaker 6:  ad. Like it's my favorite thing. It's so fun. But I do

797
00:50:14,165 --> 00:50:17,645
Speaker 6:  wanna talk about the broader piece of this because I think the, I think you're

798
00:50:17,645 --> 00:50:21,365
Speaker 6:  right that the reaction I saw out there was less like, you know,

799
00:50:22,065 --> 00:50:24,605
Speaker 3:  How, dare I say one more thing? Sure. We're not gonna start publishing a

800
00:50:24,605 --> 00:50:28,445
Speaker 3:  bunch of Hey high content who, hello. No,

801
00:50:28,565 --> 00:50:28,685
Speaker 3:  I

802
00:50:28,685 --> 00:50:30,405
Speaker 5:  Think people see partnership and they're like AI

803
00:50:30,405 --> 00:50:31,285
Speaker 6:  Content except for the printer post.

804
00:50:31,435 --> 00:50:35,165
Speaker 3:  Yeah. Yeah. I'm the only person who's put AI content on the website. Both

805
00:50:35,215 --> 00:50:39,085
Speaker 3:  posts are about printers You disclose. I wish you people would get mad

806
00:50:39,085 --> 00:50:41,125
Speaker 3:  at me about it and make that post go even more viral.

807
00:50:42,435 --> 00:50:42,725
Speaker 6:  Yeah.

808
00:50:42,725 --> 00:50:44,125
Speaker 3:  No one will do it. We will only

809
00:50:44,125 --> 00:50:47,245
Speaker 6:  Use AI to ruin our domain authority in Google Search. Yeah.

810
00:50:47,265 --> 00:50:50,925
Speaker 3:  That's what we're for it. I'm sure we're gonna end up building

811
00:50:51,035 --> 00:50:54,645
Speaker 3:  some ai, like there's one thing that all of us want, which is we would like

812
00:50:54,645 --> 00:50:57,805
Speaker 3:  better alt texts on our images to make them more accessible, to make the

813
00:50:57,805 --> 00:51:00,605
Speaker 3:  site more accessible. We would like our site to be better for screen readers.

814
00:51:00,735 --> 00:51:04,365
Speaker 3:  Right now it's not a very manual work. If we can use some of these tools

815
00:51:04,625 --> 00:51:07,365
Speaker 3:  to make that better or make our start more accessible, that's a great outcome.

816
00:51:07,365 --> 00:51:10,605
Speaker 3:  Right. I dunno if that's gonna work. Right now our creative team tells me

817
00:51:10,605 --> 00:51:13,885
Speaker 3:  like, this all text is not good enough and

818
00:51:15,505 --> 00:51:18,765
Speaker 3:  AI, everybody, it's just not good enough yet. But if we can start to build

819
00:51:18,765 --> 00:51:21,605
Speaker 3:  that stuff, that's great. So I, there's that part of it, which I think is

820
00:51:21,925 --> 00:51:24,605
Speaker 3:  interesting. I don't know what that looks like. I haven't talked to our product

821
00:51:24,605 --> 00:51:28,445
Speaker 3:  team about any of that stuff yet. But the other part where The

822
00:51:28,485 --> 00:51:31,485
Speaker 3:  Verge is just The Verge that's gonna remain exactly the same today as it

823
00:51:31,485 --> 00:51:31,965
Speaker 3:  was yesterday.

824
00:51:32,315 --> 00:51:35,205
Speaker 6:  Yeah. Okay. Let, let's talk about the broader side of this because I think

825
00:51:35,205 --> 00:51:39,045
Speaker 6:  there are, there are two pieces of the should media companies

826
00:51:39,105 --> 00:51:42,645
Speaker 6:  be making deals like this with OpenAI question that I find very interesting.

827
00:51:42,645 --> 00:51:46,285
Speaker 6:  We should talk about both of them. The first is, haven't you

828
00:51:46,305 --> 00:51:49,805
Speaker 6:  idiots learned your lesson from making these deals with companies like

829
00:51:50,125 --> 00:51:53,245
Speaker 6:  Facebook and Google and everybody else who promised you money to save journalism

830
00:51:53,465 --> 00:51:56,845
Speaker 6:  and in fact forced you to do a bunch of stuff, pulled out the rug and kind

831
00:51:56,845 --> 00:51:59,045
Speaker 6:  of screwed up the industry. The second is,

832
00:52:00,665 --> 00:52:04,525
Speaker 6:  aren't you guys, don't you realize that AI is out to put all of you out of

833
00:52:04,525 --> 00:52:08,325
Speaker 6:  jobs and just take your information, use it in training data,

834
00:52:08,425 --> 00:52:12,045
Speaker 6:  and then get rid of you? Why are you ushering in the

835
00:52:12,045 --> 00:52:15,725
Speaker 6:  journalism apocalypse? And I think to some extent those are like two versions

836
00:52:15,725 --> 00:52:19,645
Speaker 6:  of the same question, but I think are like the big picture things going

837
00:52:19,645 --> 00:52:23,325
Speaker 6:  on here. Like, are we contributing to our own downfall or are we chasing

838
00:52:23,375 --> 00:52:27,245
Speaker 6:  money at the expense of doing anything that is

839
00:52:27,245 --> 00:52:29,005
Speaker 6:  smart or long-term thinking?

840
00:52:30,035 --> 00:52:32,035
Speaker 3:  I mean, the media industry never does anything.

841
00:52:32,665 --> 00:52:36,515
Speaker 5:  Yeah. This is the media industry's not known for for really good business.

842
00:52:36,895 --> 00:52:38,195
Speaker 3:  No. But think like a vanity project.

843
00:52:38,695 --> 00:52:42,515
Speaker 6:  The thing we have talked a lot about on this media show is that we, the

844
00:52:42,515 --> 00:52:46,435
Speaker 6:  media industry as a whole probably should have spent more time over

845
00:52:46,435 --> 00:52:50,155
Speaker 6:  the last decade building Facebook competitors than making

846
00:52:50,475 --> 00:52:54,315
Speaker 6:  Facebook videos. And I think, like my hope is we have learned that

847
00:52:54,315 --> 00:52:57,595
Speaker 6:  lesson and that the next minute of the journalism industry will be learning

848
00:52:57,595 --> 00:53:00,755
Speaker 6:  that lesson and executing on it. Which is, I think part of why we're so excited

849
00:53:00,755 --> 00:53:03,835
Speaker 6:  about the Fedi verse. 'cause it's a thing that opens up possibilities for

850
00:53:03,855 --> 00:53:05,395
Speaker 6:  new kinds of media products.

851
00:53:07,895 --> 00:53:11,355
Speaker 6:  Is there a fear that open AI and the like

852
00:53:11,975 --> 00:53:15,795
Speaker 6:  AI search engine stuff that is inevitably coming is

853
00:53:15,825 --> 00:53:19,795
Speaker 6:  just the next pivot to video and everybody falls for it and gives up on

854
00:53:19,915 --> 00:53:21,035
Speaker 6:  building new things for five more years?

855
00:53:22,435 --> 00:53:26,365
Speaker 3:  Yes. Okay. So here's I just, I'm gonna

856
00:53:26,365 --> 00:53:30,325
Speaker 3:  bracket our company because they did not

857
00:53:30,325 --> 00:53:34,045
Speaker 3:  talk to me, which is like, that's the firewall. Yeah. But

858
00:53:34,715 --> 00:53:38,565
Speaker 3:  Nick Thompson, who is the CO of the Atlantic, has published a bunch

859
00:53:38,565 --> 00:53:40,445
Speaker 3:  about why the Atlantic did the deal. He made a video about it. You can go

860
00:53:40,445 --> 00:53:41,045
Speaker 3:  watch on LinkedIn.

861
00:53:42,555 --> 00:53:44,965
Speaker 3:  Nick used to be the editor-in-Chief of Wire. David used to work for Nick.

862
00:53:45,085 --> 00:53:46,125
Speaker 3:  I did. I love Nick.

863
00:53:47,715 --> 00:53:51,275
Speaker 3:  Nick knows, he knows, yeah. He gets it. I,

864
00:53:51,505 --> 00:53:54,155
Speaker 3:  Nick and I are friends. He, he knows, he un he understands what he's doing.

865
00:53:54,955 --> 00:53:57,235
Speaker 3:  Axel Springer has signed one of these deals. The Financial Times has signed

866
00:53:57,235 --> 00:54:00,715
Speaker 3:  one of these deals. A lot of these companies are signing these deals. My

867
00:54:00,715 --> 00:54:04,555
Speaker 3:  understanding of the deals from the reporting, not from the digging

868
00:54:04,555 --> 00:54:08,355
Speaker 3:  around our company, but from the reporting is twofold. One,

869
00:54:08,375 --> 00:54:10,035
Speaker 3:  we just spent a whole bunch of time talking at Google.

870
00:54:12,665 --> 00:54:16,485
Speaker 3:  Google is a fair use argument. Right? We're gonna come and index all of your

871
00:54:16,485 --> 00:54:19,085
Speaker 3:  information. We're gonna show it to people in return, you'll get traffic.

872
00:54:19,145 --> 00:54:23,005
Speaker 3:  And everyone said it's a little, little squeaky, but okay. And then Google

873
00:54:23,105 --> 00:54:27,085
Speaker 3:  won a bunch of cases against different media organizations that did not

874
00:54:27,085 --> 00:54:30,165
Speaker 3:  like this idea. Yeah. We're gonna index every book in the world and show

875
00:54:30,165 --> 00:54:33,605
Speaker 3:  it to people. And the book publishers are like, no, you're stealing our stuff.

876
00:54:33,605 --> 00:54:36,605
Speaker 3:  And Google won that case. Google, we're gonna index all the images on the

877
00:54:36,725 --> 00:54:39,925
Speaker 3:  internet. A bunch of porn publishers said, no, that's, we don't want you

878
00:54:39,925 --> 00:54:42,565
Speaker 3:  to do that. And they were not the most sympathetic defendants in the world.

879
00:54:42,565 --> 00:54:45,245
Speaker 3:  Google won that case. Google said, we're gonna put every episode of South

880
00:54:45,245 --> 00:54:48,845
Speaker 3:  Park on YouTube. And Viacom said no. And then they started posting episodes

881
00:54:48,845 --> 00:54:50,965
Speaker 3:  of South Park to YouTube on their own and they lost their case. That was

882
00:54:50,965 --> 00:54:52,725
Speaker 3:  not a great legal strategy, but that's what they did.

883
00:54:54,665 --> 00:54:58,485
Speaker 3:  But that all of Google, that whole platform dynamic

884
00:54:59,745 --> 00:55:02,605
Speaker 3:  was We're gonna take your stuff and we're gonna pay you and we'll, you'll

885
00:55:02,605 --> 00:55:05,485
Speaker 3:  get something, you'll get, you'll we'll pay you an exposure. Yeah. In that

886
00:55:05,725 --> 00:55:09,375
Speaker 3:  look around. So I, I thi I think

887
00:55:10,575 --> 00:55:13,655
Speaker 3:  a lot of the reaction right now is, well, we cannot let that happen again.

888
00:55:14,605 --> 00:55:18,585
Speaker 3:  We need some rules. I think a problem for

889
00:55:18,585 --> 00:55:22,505
Speaker 3:  all these companies is that OpenAI and Google and whoever

890
00:55:22,505 --> 00:55:23,345
Speaker 3:  else, philanthropic,

891
00:55:26,015 --> 00:55:29,165
Speaker 3:  perplexity, you name it, they've all taken it anyway. Yeah.

892
00:55:29,235 --> 00:55:29,525
Speaker 5:  Yeah.

893
00:55:30,355 --> 00:55:34,245
Speaker 3:  They, they have it llama scraped on the internet. Every Facebook video

894
00:55:34,245 --> 00:55:35,525
Speaker 3:  we've ever made, OpenAI

895
00:55:35,545 --> 00:55:39,485
Speaker 5:  Is in llama built a tool to scrape YouTube Yeah.

896
00:55:39,545 --> 00:55:43,285
Speaker 5:  For more data. Like Yeah. Like that's just how it's done. Yeah.

897
00:55:43,685 --> 00:55:47,525
Speaker 5:  I think, you know, Abson our own company, I know nothing about

898
00:55:47,525 --> 00:55:48,885
Speaker 5:  the deal beyond have

899
00:55:48,885 --> 00:55:49,165
Speaker 3:  One. We

900
00:55:49,165 --> 00:55:50,845
Speaker 5:  Have to keep saying. Yeah. Yeah. We have one. There is

901
00:55:51,135 --> 00:55:51,805
Speaker 3:  Disclosure,

902
00:55:51,805 --> 00:55:52,165
Speaker 5:  There's

903
00:55:52,165 --> 00:55:54,365
Speaker 3:  There it's box has a content and technology deal with opening.

904
00:55:54,915 --> 00:55:57,925
Speaker 5:  Yeah. I think you're right. Where it's like, it, it is a thing of they everybody,

905
00:55:58,115 --> 00:56:01,405
Speaker 5:  it's already been taken. It's already gone. Everybody, it's already like

906
00:56:01,985 --> 00:56:05,325
Speaker 5:  the cat is outta the bag. What? Right. Genie's outta the bottle. Whatever

907
00:56:05,445 --> 00:56:09,365
Speaker 5:  euphemism you wanna use there, it's happened and now it's

908
00:56:09,365 --> 00:56:12,245
Speaker 5:  okay, what do we put a price on that? And a lot of these companies, we we're,

909
00:56:12,525 --> 00:56:14,765
Speaker 5:  we're starting to hear more about the price there. We're starting to hear

910
00:56:14,765 --> 00:56:17,805
Speaker 5:  what it is and that might not end up being the right price. Right? Like,

911
00:56:17,805 --> 00:56:21,205
Speaker 5:  like these deals might not be the right deals, but they are deals,

912
00:56:21,515 --> 00:56:22,925
Speaker 5:  they are Right. Money where

913
00:56:22,925 --> 00:56:26,285
Speaker 3:  There wasn't money. I think a really interesting thing is how do you set

914
00:56:26,285 --> 00:56:29,725
Speaker 3:  the right price? What is the value? They've already trained on it. Yep. What

915
00:56:29,725 --> 00:56:32,645
Speaker 3:  is the deal for now? One of the things that has come out about these deals,

916
00:56:32,645 --> 00:56:35,325
Speaker 3:  which are all like, from what I understand, they're all basically the same

917
00:56:35,525 --> 00:56:38,805
Speaker 3:  structure. I think the, the News Corp deal is like

918
00:56:38,805 --> 00:56:42,765
Speaker 3:  $250 million over five or 10 years. Right? Most of the other

919
00:56:42,765 --> 00:56:45,605
Speaker 3:  deals are $10 million over five to 10 years, something like that.

920
00:56:47,125 --> 00:56:47,685
Speaker 3:  I think it's five.

921
00:56:50,275 --> 00:56:54,015
Speaker 3:  The main thing that has come out about them is that they govern how much

922
00:56:54,395 --> 00:56:58,295
Speaker 3:  can be displayed, how the information is displayed, how it's attributed,

923
00:56:58,325 --> 00:57:02,175
Speaker 3:  what links are in it. And you look at that and I, what

924
00:57:02,215 --> 00:57:06,015
Speaker 3:  I see is a honestly a reaction to Google, which has gone from,

925
00:57:06,015 --> 00:57:08,855
Speaker 3:  we're linking to your stuff to we're gonna cut out your stuff and put it

926
00:57:08,855 --> 00:57:12,535
Speaker 3:  in featured snippets to we're gonna have our AI rewrite whatever and just

927
00:57:12,535 --> 00:57:14,855
Speaker 3:  show you the answer and never send you a click. And then you'll eat glue

928
00:57:14,855 --> 00:57:17,695
Speaker 6:  And there's nothing you can do about it because we're indexing your website

929
00:57:17,705 --> 00:57:18,535
Speaker 6:  every single day.

930
00:57:18,745 --> 00:57:20,575
Speaker 3:  Right. And there's nothing you can do about it. 'cause there's no contract.

931
00:57:21,145 --> 00:57:24,935
Speaker 3:  Right. So I, what I have heard and what I see is like that control,

932
00:57:24,995 --> 00:57:28,895
Speaker 3:  and I, I think Nick again, Nick Thompson, that former editor Wired, who knows,

933
00:57:29,475 --> 00:57:33,375
Speaker 3:  has been public about this in his announcement in the Atlantic. That control

934
00:57:33,755 --> 00:57:36,935
Speaker 3:  is the thing. Because if you go beyond that, you don't have to

935
00:57:37,675 --> 00:57:41,415
Speaker 3:  go invent some copyright Yeah. Argument. You have a breach of contract claim

936
00:57:41,755 --> 00:57:45,135
Speaker 3:  and that's much easier to litigate. The other thing that I see happening

937
00:57:45,135 --> 00:57:47,815
Speaker 3:  all over the industry, and we made an entire decoder episode with Sarah Jang

938
00:57:47,815 --> 00:57:51,575
Speaker 3:  and I about how all of AI rests on a totally shaky

939
00:57:51,575 --> 00:57:54,935
Speaker 3:  copyright fair use argument that could blow up at any moment. Yeah. Like

940
00:57:54,935 --> 00:57:58,255
Speaker 3:  open ai, your business could blow up at any moment because you have weird

941
00:57:58,265 --> 00:58:02,055
Speaker 3:  ideas about copyright law. No one can afford to litigate these ideas.

942
00:58:02,795 --> 00:58:05,695
Speaker 3:  So the New York Times sued OpenAI, someone famously,

943
00:58:06,365 --> 00:58:09,775
Speaker 3:  they've spent a million dollars in that lawsuit so far. Public company. We,

944
00:58:09,775 --> 00:58:12,575
Speaker 3:  we just know the answer to get nothing.

945
00:58:13,525 --> 00:58:16,095
Speaker 3:  Like they haven't, they haven't achieved an outcome yet. Yeah. They're just

946
00:58:16,095 --> 00:58:19,255
Speaker 3:  done. And they could lose and they could lose. So that's a coin flip. The

947
00:58:19,255 --> 00:58:21,895
Speaker 3:  New York Times big public company, they run a very successful video game

948
00:58:21,895 --> 00:58:25,215
Speaker 3:  service. Maybe the most successful online game service of all is the New York

949
00:58:25,215 --> 00:58:29,015
Speaker 3:  Times the word all just paying the bills for this lawsuit. Most media

950
00:58:29,175 --> 00:58:32,895
Speaker 3:  companies do not have just some cash cow cooking website or gaming service

951
00:58:33,395 --> 00:58:36,735
Speaker 3:  to fund a lawsuit about their journalism. And so I think they're all looking

952
00:58:36,735 --> 00:58:39,455
Speaker 3:  at the Times lawsuit. They're saying, well this is gonna take five years,

953
00:58:39,525 --> 00:58:43,055
Speaker 3:  this is gonna take 10 years. It might go to Supreme Court, they might lose,

954
00:58:43,485 --> 00:58:47,455
Speaker 3:  hopefully the Times wins if they win. Our contracts will expire right

955
00:58:47,455 --> 00:58:51,255
Speaker 3:  around then and we'll renegotiate with the strength of this

956
00:58:51,535 --> 00:58:55,215
Speaker 3:  copyright precedent. And if they lose, we'll just re-up our deal. Yeah. And

957
00:58:55,215 --> 00:58:59,055
Speaker 3:  I, I see that playing out as most media companies cannot

958
00:58:59,235 --> 00:59:02,735
Speaker 3:  afford to go litigate these deals. And, and

959
00:59:02,735 --> 00:59:06,655
Speaker 3:  importantly, no one can afford to sue Google. Yeah. Like Google's

960
00:59:06,655 --> 00:59:07,615
Speaker 5:  Got infinite money

961
00:59:08,195 --> 00:59:11,575
Speaker 3:  And I, I know everyone's talking about Open Eye and whatever dis disclosure,

962
00:59:11,605 --> 00:59:15,415
Speaker 3:  open Eye has a constant technology of Fox Media. I would just, we just spent

963
00:59:15,415 --> 00:59:19,375
Speaker 3:  that whole first segment about Google, which

964
00:59:19,375 --> 00:59:23,285
Speaker 3:  is the thing, it's the 800 pound gorilla. Everyone on the web

965
00:59:23,805 --> 00:59:27,485
Speaker 3:  operates in the universe of Google, including OpenAI. Right.

966
00:59:28,025 --> 00:59:31,805
Speaker 3:  OpenAI has made Google dance to borrow a Dallas

967
00:59:31,815 --> 00:59:35,005
Speaker 3:  quote, but they're still, it. Like Google's the big profitable,

968
00:59:35,695 --> 00:59:37,285
Speaker 3:  ultra high margin company

969
00:59:38,815 --> 00:59:42,555
Speaker 3:  and OpenAI doesn't make a dollar as far as I understand. Right. They're,

970
00:59:42,555 --> 00:59:45,555
Speaker 3:  they're still losing money. So you just, there's a, there's a difference

971
00:59:45,555 --> 00:59:48,875
Speaker 3:  there in how these companies are perceiving their antagonists. And I think

972
00:59:48,875 --> 00:59:51,755
Speaker 3:  they can get OpenAI to come to the table and eventually what they're gonna

973
00:59:51,755 --> 00:59:55,715
Speaker 3:  do is they're gonna go to Google and they're gonna say, pay us and competitor

974
00:59:55,775 --> 00:59:59,755
Speaker 3:  is paying us. Our traffic is dropping and if it continues to

975
00:59:59,755 --> 01:00:03,275
Speaker 3:  drop, we're gonna let, we're gonna pull the plug on you indexing our website.

976
01:00:04,255 --> 01:00:07,115
Speaker 3:  And I dunno how long that's gonna take. Maybe it'll never happen because

977
01:00:07,135 --> 01:00:10,755
Speaker 3:  the threats are effective. But you just see that's where the trend line is

978
01:00:10,755 --> 01:00:11,395
Speaker 3:  headed. And

979
01:00:11,395 --> 01:00:15,275
Speaker 5:  Then you'll see, you'll only get the URL for buy this one printer in Eline

980
01:00:15,325 --> 01:00:15,675
Speaker 5:  Hotel

981
01:00:16,355 --> 01:00:20,155
Speaker 3:  Recommends, I'll sell you one link, Google. But

982
01:00:20,155 --> 01:00:23,235
Speaker 3:  that's, that's like broadly how I see the, the, the, the dynamic of this

983
01:00:23,235 --> 01:00:26,995
Speaker 3:  playing out is the copyright. I care a lot about copyright law. The

984
01:00:26,995 --> 01:00:30,195
Speaker 3:  copyright argument is so uncertain on both sides of the coin that people

985
01:00:30,195 --> 01:00:33,915
Speaker 3:  are trying to buy some certainty so that they have leverage to go

986
01:00:33,915 --> 01:00:35,835
Speaker 3:  negotiate against the real power in the ecosystem.

987
01:00:36,065 --> 01:00:39,955
Speaker 6:  Yeah. That makes logical sense to me. I also think it might be

988
01:00:40,295 --> 01:00:44,235
Speaker 6:  wildly optimistic about who is actually going to extract

989
01:00:44,675 --> 01:00:45,275
Speaker 6:  anything from Google.

990
01:00:45,715 --> 01:00:48,635
Speaker 3:  I like our media executives. I think they're brilliant. It it should be clear.

991
01:00:48,715 --> 01:00:52,585
Speaker 3:  I I think Nick is very smart. Most media executives

992
01:00:52,725 --> 01:00:53,465
Speaker 3:  are not No,

993
01:00:53,465 --> 01:00:54,225
Speaker 6:  I I mean it's

994
01:00:54,225 --> 01:00:54,705
Speaker 3:  Like a players,

995
01:00:55,175 --> 01:00:58,665
Speaker 6:  Even the thesis is good, right? Like I, I, I buy the thesis as far as it

996
01:00:58,665 --> 01:01:02,585
Speaker 6:  goes. I just think there is not a lot of evidence that

997
01:01:02,615 --> 01:01:06,025
Speaker 6:  says anyone can pick a fight with Google and win

998
01:01:06,255 --> 01:01:09,065
Speaker 6:  because we are in this spot. I mean, like you, you keep harping about Google's

999
01:01:09,065 --> 01:01:10,985
Speaker 6:  zero. Like when that happens

1000
01:01:12,605 --> 01:01:15,985
Speaker 6:  and people have nothing to lose by picking that fight with Google, they might

1001
01:01:15,985 --> 01:01:19,545
Speaker 6:  start to pick that fight with Google. Right Now if I

1002
01:01:19,735 --> 01:01:23,545
Speaker 6:  just say you can't crawl my website

1003
01:01:23,545 --> 01:01:27,505
Speaker 6:  anymore, overwhelmingly I go straight outta business. Yep.

1004
01:01:27,505 --> 01:01:27,665
Speaker 6:  Yep.

1005
01:01:28,045 --> 01:01:31,265
Speaker 3:  That's what I mean, that's, this is what I'm saying. Like the trend lines,

1006
01:01:31,515 --> 01:01:31,865
Speaker 3:  right.

1007
01:01:32,125 --> 01:01:35,465
Speaker 6:  But the trend, that trend is so slow. It's so, so slow.

1008
01:01:35,465 --> 01:01:38,425
Speaker 3:  It's, it's slow and it isn't slow. I think for some publishers it's, it's

1009
01:01:38,425 --> 01:01:40,905
Speaker 3:  super slow. For others it's not. Right. Yeah. I,

1010
01:01:41,115 --> 01:01:41,465
Speaker 6:  We'll

1011
01:01:41,465 --> 01:01:44,665
Speaker 3:  See you're, if you're seeing shakiness in your Google results and you're

1012
01:01:44,665 --> 01:01:48,425
Speaker 3:  seeing AI overviews and you're like, maybe Google Zero is real, or

1013
01:01:48,425 --> 01:01:52,265
Speaker 3:  you're a mid-size publisher, right. Which are not getting these

1014
01:01:52,265 --> 01:01:54,505
Speaker 3:  deals right now, that's all the big publishers are getting these deal. But

1015
01:01:54,505 --> 01:01:57,225
Speaker 3:  somewhere down the road, the mid-size publishers, I assume will get the deal

1016
01:01:58,645 --> 01:02:02,425
Speaker 3:  or we offered a deal or go ask for a deal. Who knows at point Point,

1017
01:02:02,715 --> 01:02:06,585
Speaker 3:  right. The trend line of our Google traffic is going down, are investment

1018
01:02:06,725 --> 01:02:10,585
Speaker 3:  in caring about you is no longer worth it. And they're paying

1019
01:02:10,585 --> 01:02:13,465
Speaker 3:  us money. Like I I I just, that is,

1020
01:02:14,575 --> 01:02:18,145
Speaker 3:  it's a destabilizing factor in all these conversations where there have never

1021
01:02:18,145 --> 01:02:21,525
Speaker 3:  been destabilizing factors for about a decade. Yeah. And so we'll just see

1022
01:02:21,525 --> 01:02:25,245
Speaker 3:  like the last time this happens, this is the negative argument.

1023
01:02:25,245 --> 01:02:28,125
Speaker 3:  I'll give everyone the negative argument. David wrote about this, he wrote

1024
01:02:28,125 --> 01:02:30,685
Speaker 3:  about Google Amp at the beginning of last year because I was like, we gotta

1025
01:02:30,685 --> 01:02:34,285
Speaker 3:  start with what Google has done to the web. Google did AMP because Facebook

1026
01:02:34,285 --> 01:02:37,725
Speaker 3:  showed up and said do instant articles and put all of your articles directly

1027
01:02:37,755 --> 01:02:41,485
Speaker 3:  into our platform and they'll load really fast and be native on the web and

1028
01:02:41,485 --> 01:02:44,445
Speaker 3:  we'll send a shitload of audience to them. And Google freaked out and did

1029
01:02:44,605 --> 01:02:47,925
Speaker 3:  amp and then all the publishers had do AMP and this was a disaster just broadly

1030
01:02:48,065 --> 01:02:50,525
Speaker 3:  all the way around a disaster. And then Facebook was like, we hate news.

1031
01:02:50,665 --> 01:02:52,925
Speaker 3:  And they're like, actually what we hate is text. All of you make videos and

1032
01:02:52,925 --> 01:02:56,725
Speaker 3:  we everyone pivots video. This equal growing disaster Amp

1033
01:02:56,725 --> 01:02:59,565
Speaker 3:  turned out to be a huge mess and he couldn't do anything good. It actually

1034
01:02:59,565 --> 01:03:02,445
Speaker 3:  spread misinformation. 'cause all the websites look the same. I could go

1035
01:03:02,445 --> 01:03:03,605
Speaker 3:  on about this for days and days and days.

1036
01:03:05,345 --> 01:03:09,085
Speaker 3:  Google is there again. Yep. They're afraid of

1037
01:03:09,085 --> 01:03:12,965
Speaker 3:  something. And so like the ripple effect of that I think is interesting.

1038
01:03:13,505 --> 01:03:17,445
Speaker 3:  And I think what most of the publishers that I've talked to, what they're

1039
01:03:17,445 --> 01:03:21,285
Speaker 3:  interested in is can we make them not copy in instant articles amp

1040
01:03:21,545 --> 01:03:25,325
Speaker 3:  but copy payments for search? Because

1041
01:03:25,325 --> 01:03:29,125
Speaker 3:  that's what they all want. One thing that we haven't talked a lot about on

1042
01:03:29,125 --> 01:03:32,645
Speaker 3:  the show is a bill in the United States called the JCPA, the

1043
01:03:32,805 --> 01:03:36,645
Speaker 3:  Journalism Competition Preservation Act. It's funny, you would

1044
01:03:36,645 --> 01:03:40,005
Speaker 3:  think that the publishers could all get together and,

1045
01:03:40,665 --> 01:03:44,565
Speaker 3:  and do and say, we're gonna pull our content from Google Search. They have

1046
01:03:44,565 --> 01:03:46,685
Speaker 3:  a lot of leverage. If they do it all together, you get a lot of leverage

1047
01:03:46,685 --> 01:03:50,445
Speaker 3:  what's left. They can't because that would be collusion under the antitrust

1048
01:03:50,445 --> 01:03:54,045
Speaker 3:  laws. Yep. Which is incredible. So the

1049
01:03:54,125 --> 01:03:58,005
Speaker 3:  JCPA is, I think it's a Klobuchar bill that would create an

1050
01:03:58,005 --> 01:04:01,485
Speaker 3:  exemption for publishers to bargain with large

1051
01:04:01,845 --> 01:04:04,765
Speaker 3:  platforms like over a billion in revenue. One of those numbers that like

1052
01:04:04,765 --> 01:04:08,485
Speaker 3:  makes it Google and Facebook. Yeah. Like it's one of those ways of saying

1053
01:04:08,485 --> 01:04:10,765
Speaker 3:  Google and Facebook without saying Google and Facebook, it would create a

1054
01:04:10,765 --> 01:04:14,525
Speaker 3:  con an exception to antitrust law. So they could bargain as a unit

1055
01:04:14,875 --> 01:04:16,245
Speaker 3:  against large platforms

1056
01:04:16,545 --> 01:04:20,485
Speaker 5:  Or they could just like rule that Google has built

1057
01:04:20,525 --> 01:04:21,125
Speaker 5:  a monopoly.

1058
01:04:21,395 --> 01:04:24,325
Speaker 3:  Yeah. There's a lot of that. Yeah. There's, there's just a lot of these ideas

1059
01:04:24,685 --> 01:04:28,285
Speaker 3:  floating around about how you equalize the bargain power. Yeah. Yeah. Anyway,

1060
01:04:28,605 --> 01:04:32,205
Speaker 3:  I that's, I I just see the bigger picture, which is

1061
01:04:32,505 --> 01:04:36,045
Speaker 3:  the raw deal is real. Like people got burned

1062
01:04:36,295 --> 01:04:40,045
Speaker 3:  super hard by the raw deal of the platforms. Most of which

1063
01:04:40,555 --> 01:04:44,325
Speaker 3:  were, were will give you some money with no contract that says where the

1064
01:04:44,325 --> 01:04:47,925
Speaker 3:  money will come from the Facebook news partnerships or the Google news

1065
01:04:47,925 --> 01:04:51,525
Speaker 3:  initiatives. Or it was make a thing for us that we want

1066
01:04:52,085 --> 01:04:55,965
Speaker 3:  Facebook video or it was, we're gonna take your stuff for free and pay

1067
01:04:55,965 --> 01:04:59,805
Speaker 3:  you an exposure, which is Google Search And I, what I see now is

1068
01:05:00,185 --> 01:05:04,045
Speaker 3:  we have a contract. Yeah. Right. We're just not doing this. Again. You're,

1069
01:05:04,045 --> 01:05:07,285
Speaker 3:  you're gonna pay us money. We're gonna tell you what you can take. And if

1070
01:05:07,345 --> 01:05:09,885
Speaker 3:  you don't pay us enough money, we'll see you. And if you take too much, we'll

1071
01:05:09,885 --> 01:05:13,685
Speaker 3:  see you. And that has a little bit of teeth. I dunno if it'll work again,

1072
01:05:14,405 --> 01:05:17,885
Speaker 3:  I know a lot of media executives, Alex used to work for some of the worst

1073
01:05:17,885 --> 01:05:18,925
Speaker 3:  media executives in the game.

1074
01:05:19,125 --> 01:05:19,685
Speaker 5:  I sure did.

1075
01:05:20,585 --> 01:05:24,525
Speaker 3:  And it's not like they're not all, this is not an

1076
01:05:24,685 --> 01:05:27,805
Speaker 3:  industry that can see the long game and it's an industry that's under pressure.

1077
01:05:27,805 --> 01:05:31,325
Speaker 3:  So it might be making mistakes. But I, I see the difference here. I don't

1078
01:05:31,325 --> 01:05:34,485
Speaker 3:  dunno if these are good ideas. I don't know if they feel great. Right. Like

1079
01:05:34,485 --> 01:05:38,445
Speaker 3:  there's a lot of the response yesterday and to all these other deals is do

1080
01:05:38,445 --> 01:05:42,365
Speaker 3:  these feel great? No, but I, I think I can identify the

1081
01:05:42,365 --> 01:05:44,285
Speaker 3:  differences and I think at least what I see

1082
01:05:46,015 --> 01:05:49,275
Speaker 3:  is well, they took the shit anyway. Yeah. But some money is better than no

1083
01:05:49,275 --> 01:05:52,115
Speaker 3:  money. Yeah. I mean, and a lot of the deal for a long time was no money.

1084
01:05:53,265 --> 01:05:55,915
Speaker 5:  That that's definitely where I'm sitting. It's like somebody is better than

1085
01:05:55,915 --> 01:05:59,835
Speaker 5:  no money. But also one I wanna just point out, this is

1086
01:05:59,835 --> 01:06:02,675
Speaker 5:  a lightning round and we've been on Eli's lightning round

1087
01:06:02,685 --> 01:06:03,755
Speaker 3:  Sorry, sorry, sorry.

1088
01:06:04,135 --> 01:06:07,075
Speaker 5:  For a while. And so I wanna take over for my lightning round. Oh yeah. Okay.

1089
01:06:07,075 --> 01:06:10,355
Speaker 5:  You got one which is also about open ai. Of course it is. Because

1090
01:06:11,955 --> 01:06:15,595
Speaker 5:  I called it, I just, back when, when

1091
01:06:15,735 --> 01:06:19,195
Speaker 5:  OpenAI, there was the coup and a bunch of the board members were like, we,

1092
01:06:19,295 --> 01:06:22,835
Speaker 5:  we don't like Sam. We're firing him. Everybody

1093
01:06:23,435 --> 01:06:26,195
Speaker 5:  gathered around. Sam was like, no, you are baby. We love you. Come back.

1094
01:06:26,665 --> 01:06:29,115
Speaker 5:  He's now back in charge. More powerful than ever.

1095
01:06:30,565 --> 01:06:34,115
Speaker 5:  Right. Like that, thats, that's the reporting allegedly like information

1096
01:06:34,115 --> 01:06:38,075
Speaker 5:  just said, open ai, CEO cements control. So like that's happening.

1097
01:06:38,075 --> 01:06:40,475
Speaker 3:  They started, they fired all the safety people or pushed him out and then

1098
01:06:40,475 --> 01:06:43,155
Speaker 3:  he started c they committee, he's the head of the safety committee. Yeah.

1099
01:06:43,155 --> 01:06:47,115
Speaker 5:  Woo. That's, that's a choice. Sam. But Helen Toner, who was one of

1100
01:06:47,115 --> 01:06:50,635
Speaker 5:  those board members who, who voted to have him kicked off,

1101
01:06:50,895 --> 01:06:54,155
Speaker 5:  kicked out and then left because he won,

1102
01:06:55,295 --> 01:06:58,715
Speaker 5:  was on a podcast this week and was like, yeah. We just didn't trust him.

1103
01:06:58,905 --> 01:07:02,875
Speaker 5:  Yeah. Like he, he just was so consistently not telling us

1104
01:07:02,875 --> 01:07:06,435
Speaker 5:  the truth. We, we just lost all trust in him. And that is

1105
01:07:06,535 --> 01:07:09,435
Speaker 5:  really, really interesting to think about as he does

1106
01:07:10,255 --> 01:07:13,395
Speaker 5:  cement more power, as he does get more powerful as he does put himself in

1107
01:07:13,395 --> 01:07:16,915
Speaker 5:  charge of safety at the company. And all of those people who were in charge

1108
01:07:16,915 --> 01:07:20,555
Speaker 5:  of safety have left. And as that company is still technically run by a

1109
01:07:20,555 --> 01:07:24,315
Speaker 5:  nonprofit, that's whole job is to protect us

1110
01:07:24,335 --> 01:07:27,915
Speaker 5:  all from ai. Like, oh buddy. Yeah.

1111
01:07:28,095 --> 01:07:29,435
Speaker 5:  That's not working for you.

1112
01:07:29,895 --> 01:07:32,955
Speaker 3:  I'm actually, I'm curious. It's been

1113
01:07:34,095 --> 01:07:38,025
Speaker 3:  like this Carl Johansen situation has not, there's been no new pieces

1114
01:07:38,025 --> 01:07:41,975
Speaker 3:  of information. It's been pretty quiet on that front. Yeah. That's not gonna

1115
01:07:41,975 --> 01:07:45,735
Speaker 3:  just end. No. Right. It ends with a settlement or a statement or

1116
01:07:45,935 --> 01:07:46,615
Speaker 3:  an apology. Well,

1117
01:07:46,615 --> 01:07:49,295
Speaker 5:  She's gonna do a partnership with OpenAI as well. Like no,

1118
01:07:52,355 --> 01:07:54,055
Speaker 3:  She has some great ideas for all text. Yeah.

1119
01:07:55,675 --> 01:07:59,015
Speaker 3:  But like the, the backlash to

1120
01:07:59,795 --> 01:08:02,895
Speaker 3:  AI in general, but I'll give you this little data point.

1121
01:08:04,215 --> 01:08:07,495
Speaker 3:  I think there's a real gap in how people feel about the thing and then what

1122
01:08:07,495 --> 01:08:10,855
Speaker 3:  people are doing. We've never gotten so many

1123
01:08:11,405 --> 01:08:15,320
Speaker 3:  sort of like unhappy notes about a decoder episode is when we had the CCO

1124
01:08:15,320 --> 01:08:18,325
Speaker 3:  of Adobe on. We had some happy ones too. People wanna hear from that guy.

1125
01:08:18,325 --> 01:08:20,845
Speaker 3:  He doesn't get a lot of interviews. I asked him what he thought a photo was.

1126
01:08:22,145 --> 01:08:25,245
Speaker 3:  He doesn't know. But then we got a lot of people who are like, screw this

1127
01:08:25,245 --> 01:08:28,565
Speaker 3:  guy. Yeah. We just don't like Adobe. We don't like ai. Like they're ruining

1128
01:08:28,565 --> 01:08:32,125
Speaker 3:  everything. His comments about AI are offensive. Weird.

1129
01:08:32,455 --> 01:08:33,085
Speaker 3:  Weird. Right.

1130
01:08:33,315 --> 01:08:35,165
Speaker 5:  There's real backlash to AI hack right now. There's

1131
01:08:35,165 --> 01:08:38,445
Speaker 3:  Some negativity. One thing he told me in that episode was

1132
01:08:39,135 --> 01:08:43,065
Speaker 3:  generative fill is used as much as layers. They

1133
01:08:43,225 --> 01:08:47,025
Speaker 3:  launched this tool and it is used on the order of layers in photo,

1134
01:08:47,025 --> 01:08:48,985
Speaker 3:  which is basically people open the app. Yeah.

1135
01:08:49,045 --> 01:08:51,745
Speaker 5:  That's how you get layers. You, you open the app,

1136
01:08:51,815 --> 01:08:54,865
Speaker 3:  Like you open the app and then like people use it. And so there's a real

1137
01:08:55,005 --> 01:08:58,985
Speaker 3:  gap and I think Sam kind of embodies the gap. Yeah. Right. Which is

1138
01:08:59,015 --> 01:09:02,905
Speaker 3:  he's just the face of boy, we're not being very careful with this.

1139
01:09:03,415 --> 01:09:07,025
Speaker 3:  He's the face of I can do whatever I want 'cause I'm so silicon

1140
01:09:07,055 --> 01:09:10,265
Speaker 5:  Someone's gonna call him the bad boy of AI soon. I'm sorry, I just,

1141
01:09:10,705 --> 01:09:14,145
Speaker 3:  No, there's nothing about his demeanor that supports bad boy. Yeah. I'm sorry.

1142
01:09:15,415 --> 01:09:15,705
Speaker 3:  It's

1143
01:09:15,705 --> 01:09:16,945
Speaker 5:  Just not It's coming. Don't worry. You

1144
01:09:16,945 --> 01:09:19,905
Speaker 3:  Can't, it's not gonna happen. I'm sorry. There's Brace Yourself. They're

1145
01:09:19,905 --> 01:09:22,265
Speaker 3:  much better contenders for Bad Boy than Sam Hallman,

1146
01:09:24,405 --> 01:09:27,425
Speaker 3:  but like he's the face of that gap. Yeah. Which is

1147
01:09:28,865 --> 01:09:32,465
Speaker 3:  actually the revealed behavior of many people is that the tools are useful,

1148
01:09:32,975 --> 01:09:36,825
Speaker 3:  they can be helpful people like them. Like I'm

1149
01:09:36,825 --> 01:09:40,745
Speaker 3:  the nation's foremost hand ringer of what is a photo. And I definitely use

1150
01:09:40,745 --> 01:09:44,545
Speaker 3:  Generative Eraser in Lightroom yesterday. That's for a family photo that

1151
01:09:44,545 --> 01:09:45,265
Speaker 3:  I shared with no one.

1152
01:09:47,025 --> 01:09:48,345
Speaker 5:  I would use it all the time.

1153
01:09:50,265 --> 01:09:53,905
Speaker 3:  DID noise in Lightroom I think is magic. I, I've talked about it and

1154
01:09:54,125 --> 01:09:57,265
Speaker 3:  it has re-contextualized how I think about some of my old cameras. Yeah.

1155
01:09:57,265 --> 01:09:57,505
Speaker 3:  We, we

1156
01:09:57,605 --> 01:10:00,145
Speaker 5:  Talked about this earlier today where I think a lot of people don't realize

1157
01:10:00,565 --> 01:10:03,985
Speaker 5:  how many of the tools we actually use are already ai. Right. Like, like Grammarly

1158
01:10:04,165 --> 01:10:07,905
Speaker 5:  is using some sort of ai. Photoshop

1159
01:10:08,285 --> 01:10:11,105
Speaker 5:  is all ai and if you've been using Photoshop for the last 10 years,

1160
01:10:12,285 --> 01:10:14,785
Speaker 5:  you've been using ai. Yeah. It's in there something. And, but, but I think

1161
01:10:14,785 --> 01:10:18,665
Speaker 5:  you're right where it's Sam Altman has become the kind of this, the center

1162
01:10:18,665 --> 01:10:21,745
Speaker 5:  point and and everybody's talking about him and they're talking about they

1163
01:10:21,955 --> 01:10:22,305
Speaker 3:  Don't

1164
01:10:22,305 --> 01:10:25,665
Speaker 5:  Trust him, they don't trust him and they don't trust the kind of AI he's

1165
01:10:25,665 --> 01:10:28,585
Speaker 5:  doing. Yeah. Which is very specific kind. Right. It's, it's taking over your

1166
01:10:28,585 --> 01:10:32,225
Speaker 5:  search. It's providing just easy generative content

1167
01:10:32,685 --> 01:10:36,265
Speaker 5:  in a way that most AI tools that people use have a very specific purpose

1168
01:10:36,565 --> 01:10:39,385
Speaker 5:  and are used for very specific things. And he's built the libo

1169
01:10:40,405 --> 01:10:44,265
Speaker 3:  And, you know, open this incredibly byzantine corporate

1170
01:10:44,465 --> 01:10:48,225
Speaker 3:  structure was all meant to box in the

1171
01:10:48,285 --> 01:10:48,705
Speaker 3:  bad things

1172
01:10:48,805 --> 01:10:51,025
Speaker 5:  You box in the Libo and keep the libo

1173
01:10:51,025 --> 01:10:54,665
Speaker 3:  And like keep it safe. And he's torn all that down. Yeah. And now OpenAI,

1174
01:10:54,665 --> 01:10:57,865
Speaker 3:  instead of being this weird non-profit with a profit center that supports

1175
01:10:57,865 --> 01:11:01,545
Speaker 3:  the non-profit is feels like just Sam Altman's company.

1176
01:11:01,775 --> 01:11:02,225
Speaker 3:  Yeah. I

1177
01:11:02,265 --> 01:11:05,705
Speaker 6:  Mean it's called Open ai. Like I, I would just, I would just point out

1178
01:11:06,135 --> 01:11:09,905
Speaker 6:  like their whole thing was being the good guys for so, so,

1179
01:11:10,125 --> 01:11:13,965
Speaker 6:  so long and they made it so far on big

1180
01:11:13,965 --> 01:11:17,485
Speaker 6:  promises of being the good guys and then just like on a dime

1181
01:11:18,025 --> 01:11:19,885
Speaker 6:  turned and went the other way. Yeah. The

1182
01:11:19,885 --> 01:11:20,165
Speaker 3:  Second the money

1183
01:11:20,395 --> 01:11:22,165
Speaker 6:  Wild how fast this has happened. Right.

1184
01:11:22,285 --> 01:11:26,205
Speaker 3:  GPT-3 0.5 hit, they're like, oh, people like this we're evil now.

1185
01:11:27,115 --> 01:11:30,685
Speaker 5:  Just, it's, they just cut on their little evil helmets. But so the

1186
01:11:31,205 --> 01:11:34,165
Speaker 3:  Interesting thing is they don't, again, they don't have any revenue.

1187
01:11:35,015 --> 01:11:38,885
Speaker 3:  Right. Like, this company is not wildly profitable. They, they might be on

1188
01:11:38,885 --> 01:11:40,485
Speaker 3:  a path to it. You don't need revenue. They make all this

1189
01:11:40,485 --> 01:11:42,885
Speaker 6:  Noise about revenue is not important. You've, you've been covering tech too

1190
01:11:42,885 --> 01:11:46,325
Speaker 6:  long to know that, to not realize that revenue is not important. As long

1191
01:11:46,325 --> 01:11:48,685
Speaker 6:  as people will keep giving you money, you don't need revenue.

1192
01:11:48,695 --> 01:11:51,205
Speaker 3:  Which is why I think they make all this noise about a GI all the time, right?

1193
01:11:51,205 --> 01:11:54,045
Speaker 3:  Yeah. They're like, we're we built the future. Yeah. People

1194
01:11:54,045 --> 01:11:55,045
Speaker 6:  Will keep giving you money.

1195
01:11:55,985 --> 01:11:59,365
Speaker 3:  The number one, the funniest the GBT apps are at now, right?

1196
01:12:00,035 --> 01:12:03,205
Speaker 3:  Yeah. For everybody. And I was just looking at the top one in lifestyles

1197
01:12:03,265 --> 01:12:06,205
Speaker 3:  in Astrology app and I was like, oh, this is actually a perfect use case

1198
01:12:06,225 --> 01:12:09,565
Speaker 3:  for ai. Yeah. Like, you'd be like, I'll just make some shit up about your

1199
01:12:09,565 --> 01:12:09,805
Speaker 3:  future.

1200
01:12:11,765 --> 01:12:14,165
Speaker 3:  Yeah. We should talk about that. So wdc is coming up, there was some reporting

1201
01:12:14,165 --> 01:12:18,085
Speaker 3:  this week that Apple has made the deal to sign

1202
01:12:18,085 --> 01:12:21,365
Speaker 3:  with OpenAI that OpenAI will power this stuff. Interestingly,

1203
01:12:21,795 --> 01:12:24,445
Speaker 3:  there's some back and forth about whether it will run locally on the phone,

1204
01:12:24,445 --> 01:12:28,205
Speaker 3:  which would match Apple's privacy promises or go up to the cloud,

1205
01:12:28,255 --> 01:12:30,245
Speaker 3:  which is fascinating because

1206
01:12:31,075 --> 01:12:31,845
Speaker 5:  More powerful.

1207
01:12:32,075 --> 01:12:35,405
Speaker 3:  More powerful. But where will it run? There's some reporting, I think Mark

1208
01:12:35,565 --> 01:12:39,125
Speaker 3:  Gerin and Bloomberg reported that they're gonna put M two Ultras

1209
01:12:39,905 --> 01:12:42,885
Speaker 3:  or M three Ultras in a data center and have a virtual black box

1210
01:12:43,345 --> 01:12:44,125
Speaker 5:  Oh boy. For

1211
01:12:44,125 --> 01:12:44,325
Speaker 3:  Privacy.

1212
01:12:44,675 --> 01:12:46,325
Speaker 5:  That, that works out every time.

1213
01:12:47,225 --> 01:12:47,725
Speaker 3:  Who knows?

1214
01:12:47,905 --> 01:12:51,845
Speaker 6:  It gives real like beeper running Mac Minis on your behalf. Exactly. Vibes.

1215
01:12:52,275 --> 01:12:56,045
Speaker 3:  Yeah. And then you've got open eye the mix, which is like, where's this model

1216
01:12:56,045 --> 01:12:58,805
Speaker 3:  gonna run? Can it run on the M two Ultra or M three Ultra or whatever.

1217
01:12:59,125 --> 01:13:01,805
Speaker 6:  I mean no, you can't fit the thing on your phone. I'm very confident that

1218
01:13:01,805 --> 01:13:05,165
Speaker 6:  you cannot run GPT-4 oh on your phone locally. Right.

1219
01:13:05,165 --> 01:13:09,005
Speaker 3:  But can you port it to arm like this thing Right, right now runs on

1220
01:13:09,025 --> 01:13:10,285
Speaker 3:  Nvidia H one hundreds.

1221
01:13:10,965 --> 01:13:13,125
Speaker 6:  A lot of them. Yeah. Like a lot of them.

1222
01:13:13,705 --> 01:13:17,165
Speaker 3:  And you know what two companies hate each other with the

1223
01:13:17,635 --> 01:13:21,445
Speaker 3:  Fury of a thousand Burning Suns So Good is Nvidia and Apple.

1224
01:13:21,665 --> 01:13:21,885
Speaker 3:  Yep.

1225
01:13:22,385 --> 01:13:26,285
Speaker 5:  But they're also two of the best people at making processors that can handle

1226
01:13:26,465 --> 01:13:27,245
Speaker 5:  AI stuff. Right. Except

1227
01:13:27,245 --> 01:13:29,605
Speaker 3:  For GPUs. One of them is really good. One

1228
01:13:29,605 --> 01:13:31,685
Speaker 5:  Of is really good at using the other one. Oh,

1229
01:13:31,985 --> 01:13:34,005
Speaker 3:  The other one just took the training wheels off. Its,

1230
01:13:34,125 --> 01:13:36,125
Speaker 5:  I I can play Crusader Kings on the laptop.

1231
01:13:37,265 --> 01:13:39,645
Speaker 3:  So I'm just very curious about how all this will play out. Because if you're

1232
01:13:39,645 --> 01:13:43,525
Speaker 3:  gonna run GBT four, there's a chance you're running it on a bunch of

1233
01:13:43,805 --> 01:13:47,725
Speaker 3:  H one hundreds in a Microsoft data center, which is a

1234
01:13:47,725 --> 01:13:49,405
Speaker 3:  real weird place for Apple to be. Well

1235
01:13:49,695 --> 01:13:53,565
Speaker 5:  Hagerman's piece this week about, about the the deal was also kind of

1236
01:13:53,725 --> 01:13:56,845
Speaker 5:  interesting 'cause it seemed to be like they're not gonna go full out

1237
01:13:57,435 --> 01:14:01,125
Speaker 5:  with all the AI tools. It, what we're gonna see from them at

1238
01:14:01,385 --> 01:14:05,325
Speaker 5:  ww DC as far as AI goes is gonna be a lot more Adobe like

1239
01:14:05,355 --> 01:14:08,245
Speaker 5:  than Yeah. Scarlet and

1240
01:14:08,245 --> 01:14:09,965
Speaker 3:  Voice. Like, I don't, I don't think they're gonna chat bot and I think that

1241
01:14:09,965 --> 01:14:11,525
Speaker 3:  is the right move. Yes. Oh,

1242
01:14:11,525 --> 01:14:14,965
Speaker 6:  That's so fun. I totally disagree. Yeah. Really? Yeah. I think they're going

1243
01:14:14,965 --> 01:14:18,485
Speaker 6:  to go full hard with Siri and I think that's the

1244
01:14:18,795 --> 01:14:22,765
Speaker 6:  open AI play is just take the Siri you

1245
01:14:22,765 --> 01:14:26,685
Speaker 6:  can talk to and plug it into GPT-4 Oh and instantly it's the best Siri

1246
01:14:26,685 --> 01:14:27,125
Speaker 6:  has ever been.

1247
01:14:28,995 --> 01:14:31,845
Speaker 6:  Then how you scale that down to like

1248
01:14:32,515 --> 01:14:36,285
Speaker 6:  turning off Bluetooth, which is a thing that I can do on my phone

1249
01:14:36,285 --> 01:14:39,765
Speaker 6:  that does not require the internet is becomes a really interesting

1250
01:14:40,345 --> 01:14:41,525
Speaker 6:  AI challenge That's big.

1251
01:14:41,745 --> 01:14:44,285
Speaker 3:  You just described like the promise of big speed. I mean,

1252
01:14:44,285 --> 01:14:48,085
Speaker 6:  What do you, what I use Siri for almost exclusively is playing

1253
01:14:48,085 --> 01:14:51,805
Speaker 6:  music, adding reminders to the reminders app and setting

1254
01:14:51,825 --> 01:14:54,805
Speaker 6:  timers. And none of those things require

1255
01:14:56,275 --> 01:15:00,085
Speaker 6:  pinging GPT-4. Oh. They just don't. But

1256
01:15:00,365 --> 01:15:04,045
Speaker 6:  I think Apple, like everyone else is going to have to convince

1257
01:15:04,045 --> 01:15:07,285
Speaker 6:  investors that it has a chat bot play

1258
01:15:08,065 --> 01:15:11,965
Speaker 6:  in order to survive. Not survive, but you know what I mean,

1259
01:15:12,115 --> 01:15:15,885
Speaker 6:  it's Wall Street wants to see that you have some big newfangled

1260
01:15:15,885 --> 01:15:18,765
Speaker 6:  idea and so they're gonna do it because they feel like they have to, all

1261
01:15:18,765 --> 01:15:22,445
Speaker 6:  the interesting AI stuff is going to be the like, on

1262
01:15:22,445 --> 01:15:25,365
Speaker 6:  device stuff. And that's the thing that we're already seeing Apple do well

1263
01:15:25,995 --> 01:15:28,925
Speaker 6:  just by putting AI features into apps, you're gonna see a lot of it with

1264
01:15:28,925 --> 01:15:32,685
Speaker 6:  photos. There's a lot of noise around AI generated

1265
01:15:32,695 --> 01:15:36,125
Speaker 6:  emoji. That's the kinda thing you don't really need open AI for that actually

1266
01:15:36,125 --> 01:15:40,085
Speaker 6:  Apple has been working on for a long time. The the only reason I

1267
01:15:40,085 --> 01:15:43,485
Speaker 6:  can see that you would strike a deal like this with open AI is if you wanna

1268
01:15:43,845 --> 01:15:47,125
Speaker 6:  blow out the like, conversational aspect of things

1269
01:15:47,595 --> 01:15:51,565
Speaker 5:  Just lies so much in the face of Apple's security stuff.

1270
01:15:51,995 --> 01:15:52,285
Speaker 5:  Like

1271
01:15:52,285 --> 01:15:54,405
Speaker 6:  Yeah. But so does the Google deal. Like, so, so

1272
01:15:54,555 --> 01:15:58,125
Speaker 5:  It's fine. That's true, that's true. But the Google deal, like we didn't

1273
01:15:58,125 --> 01:16:00,485
Speaker 5:  know the terms of the Google deal for years. Right. And whereas this was

1274
01:16:00,525 --> 01:16:03,845
Speaker 5:  a fairly public deal with AI really

1275
01:16:03,895 --> 01:16:07,445
Speaker 6:  Close. I mean, it's just been better reported on because Open AI is the luckiest

1276
01:16:07,445 --> 01:16:08,725
Speaker 6:  company in the history of the world.

1277
01:16:09,115 --> 01:16:11,805
Speaker 5:  Just like, just holes everywhere. Yeah.

1278
01:16:11,805 --> 01:16:14,685
Speaker 3:  By the way, it's only the M two Ultra only M two. This was driving me crazy.

1279
01:16:14,805 --> 01:16:17,485
Speaker 3:  I kept saying M three Ultra, they only 'cause they're on the M four now,

1280
01:16:17,485 --> 01:16:18,765
Speaker 3:  so I just assumed. Yeah.

1281
01:16:18,995 --> 01:16:20,485
Speaker 5:  They just got a lot of M two Ultras,

1282
01:16:20,605 --> 01:16:22,045
Speaker 3:  M two Ultras where they stopped with the,

1283
01:16:22,475 --> 01:16:26,285
Speaker 5:  They're like, is this as good as an H 100 Open ai?

1284
01:16:26,285 --> 01:16:26,685
Speaker 5:  Tell us.

1285
01:16:27,285 --> 01:16:31,085
Speaker 3:  I think Apple knows that the idea of the behind is an external perception

1286
01:16:31,085 --> 01:16:32,405
Speaker 3:  of the company and they're watching,

1287
01:16:34,395 --> 01:16:38,005
Speaker 3:  they're watching companies kinda light their brands on fire

1288
01:16:38,665 --> 01:16:42,405
Speaker 3:  and not, they're just never gonna do that. I think they're

1289
01:16:42,605 --> 01:16:46,085
Speaker 3:  cautious to the extreme in that way. Maybe. And I think this, I think this

1290
01:16:46,085 --> 01:16:49,845
Speaker 3:  crush ad disaster for them, which was not even about

1291
01:16:50,065 --> 01:16:53,525
Speaker 3:  ai, it was an iPad ad Yeah. That everyone

1292
01:16:53,915 --> 01:16:55,285
Speaker 3:  decided was about ai.

1293
01:16:56,885 --> 01:17:00,405
Speaker 3:  I think they saw that and they were like, no, like we are, we're gonna do

1294
01:17:00,405 --> 01:17:02,605
Speaker 3:  some stuff in photos and some stuff in emojis and well, there

1295
01:17:02,675 --> 01:17:04,325
Speaker 5:  There's gonna be stuff in search, so

1296
01:17:04,545 --> 01:17:07,605
Speaker 3:  I'm sure Yeah. There's gonna be like some like light dusting remember last

1297
01:17:07,605 --> 01:17:10,045
Speaker 3:  year where they were like, the keyboard has AI in it now and it's like, this

1298
01:17:10,325 --> 01:17:11,365
Speaker 3:  keyboard is dumb. Yeah.

1299
01:17:11,595 --> 01:17:11,885
Speaker 5:  It's

1300
01:17:11,885 --> 01:17:15,725
Speaker 3:  Real bad. It's like still pretty bad. They're gonna do that kind of thing.

1301
01:17:15,835 --> 01:17:18,805
Speaker 3:  Yeah. And I think it might be everywhere they might announce more features,

1302
01:17:18,825 --> 01:17:22,615
Speaker 3:  but that last turn where it's like, do you want to bang an

1303
01:17:22,645 --> 01:17:26,495
Speaker 3:  iPad? Like I don't, I don't know if we're gonna get there this time.

1304
01:17:26,895 --> 01:17:29,455
Speaker 3:  I I think they're very comfortable with the perception that they're quote

1305
01:17:29,455 --> 01:17:32,935
Speaker 3:  behind because they're, I I think they're watching Google. I think they're

1306
01:17:33,095 --> 01:17:36,295
Speaker 3:  watching the reaction to their own advertising and saying this stuff is not

1307
01:17:36,295 --> 01:17:40,255
Speaker 3:  ready and the culture around it is too negative. That is just my sense

1308
01:17:41,325 --> 01:17:44,695
Speaker 3:  from, you know, just talking to folks. But I don't, I don't know if I don't

1309
01:17:44,695 --> 01:17:45,575
Speaker 3:  know what they're actually gonna answer.

1310
01:17:46,535 --> 01:17:50,375
Speaker 6:  I look forward to we're gonna be there live. Yeah. And we're,

1311
01:17:50,375 --> 01:17:54,175
Speaker 6:  we're doing a podcast in Cupertino and I am going

1312
01:17:54,175 --> 01:17:57,655
Speaker 6:  to spend a lot of time gloating on that show about how right I was. And I'm

1313
01:17:57,655 --> 01:17:58,375
Speaker 6:  really looking forward to it.

1314
01:17:58,735 --> 01:18:01,535
Speaker 5:  I I really hope David's wrong, just so I can gloat.

1315
01:18:03,175 --> 01:18:06,815
Speaker 5:  I just, that's it. But I hope you're right for you spiritually, David,

1316
01:18:08,295 --> 01:18:12,135
Speaker 6:  I just, I think if you're worried about the stock

1317
01:18:12,135 --> 01:18:15,815
Speaker 6:  price of your company and I know that they are, you look at it what is

1318
01:18:15,815 --> 01:18:19,635
Speaker 6:  happening at Microsoft and you say, oh, we need

1319
01:18:19,985 --> 01:18:23,915
Speaker 6:  something like that. And what they'll say is they'll make a lot of noise

1320
01:18:23,915 --> 01:18:27,795
Speaker 6:  about like all the stuff you can do inside of apps and then it will come

1321
01:18:27,795 --> 01:18:31,475
Speaker 6:  around too. And also it wants to be your best friend.

1322
01:18:31,725 --> 01:18:32,395
Speaker 6:  Let's hang out.

1323
01:18:32,395 --> 01:18:35,915
Speaker 5:  Yeah. Also, Sirius Hornet. Now Tim Cook will be like, woo.

1324
01:18:38,975 --> 01:18:42,835
Speaker 3:  Can you imagine? Just imagine Tim Cook being like

1325
01:18:42,855 --> 01:18:43,875
Speaker 3:  in Siri warning now.

1326
01:18:43,985 --> 01:18:46,355
Speaker 5:  Yeah. Just flirty with Siri. I. love

1327
01:18:46,355 --> 01:18:49,915
Speaker 3:  It. Looks Kevin a ru Dead in the eyes. This you all right, we gotta, this

1328
01:18:49,915 --> 01:18:53,875
Speaker 3:  is the lightning round has ended up in strange places, but it's

1329
01:18:53,875 --> 01:18:56,715
Speaker 3:  been a good one. We'll be right back. We have yet another Unsponsored Lightning

1330
01:18:56,715 --> 01:18:56,875
Speaker 3:  round.

1331
01:22:22,425 --> 01:22:22,785
Speaker 3:  your call.

1332
01:22:24,495 --> 01:22:27,625
Speaker 3:  Mega Bass, ultimate Sound or whatever. Power Vibes, whatever. It's

1333
01:22:28,875 --> 01:22:32,785
Speaker 3:  Power vibes. ULT. All right. Kranz, you got I I I ran you

1334
01:22:32,785 --> 01:22:34,225
Speaker 3:  over in the last one. You get the first one? Yeah.

1335
01:22:35,125 --> 01:22:38,825
Speaker 5:  So it's, it's gonna be a gadget and that Fitbit

1336
01:22:39,125 --> 01:22:40,505
Speaker 5:  has a new watch for kids.

1337
01:22:41,525 --> 01:22:41,745
Speaker 3:  The

1338
01:22:41,845 --> 01:22:45,785
Speaker 5:  Ace. The Ace, the Ace LTE. And is it a way for

1339
01:22:45,785 --> 01:22:48,505
Speaker 5:  you to track your children with GPS? Yes. Yes.

1340
01:22:49,605 --> 01:22:52,505
Speaker 5:  Do you feel uncomfortable about that? I don't know. I'm not you if you do,

1341
01:22:52,575 --> 01:22:55,625
Speaker 5:  this probably is not an exciting gadget for you. But

1342
01:22:56,365 --> 01:23:00,305
Speaker 5:  it seems really cool because it like gamifies fitness in what appears

1343
01:23:00,305 --> 01:23:03,225
Speaker 5:  to be a really nice way Victoria Song went and got to check it out. I've

1344
01:23:03,225 --> 01:23:05,330
Speaker 5:  heard from some other people who have gotten to check it out and everybody's

1345
01:23:05,330 --> 01:23:08,685
Speaker 5:  just like, no, this thing rules and I kind of want one for myself. Yes. And

1346
01:23:08,685 --> 01:23:12,565
Speaker 5:  like, that's the hallmark of a good ass gadget for kids. Yeah. Like

1347
01:23:12,705 --> 01:23:16,285
Speaker 5:  you, you can take the, the band and replace the band and there's like a little

1348
01:23:16,295 --> 01:23:19,485
Speaker 5:  tamagotchi kind of thing in the watch. And so when you replace the band,

1349
01:23:19,485 --> 01:23:23,445
Speaker 5:  it'll like change it'ss a appearance and stuff. It's,

1350
01:23:23,645 --> 01:23:24,565
Speaker 5:  it's sick. Like all,

1351
01:23:24,625 --> 01:23:28,285
Speaker 6:  All adult fitness trackers are like, let's talk about your VO two max and

1352
01:23:28,285 --> 01:23:31,485
Speaker 6:  this one's just like, make the cool little guy go and like, that's how you

1353
01:23:31,485 --> 01:23:32,765
Speaker 6:  get me to do stuff. Come on.

1354
01:23:33,195 --> 01:23:35,725
Speaker 5:  Exactly. Like this, this thing just kind of rules

1355
01:23:37,025 --> 01:23:40,845
Speaker 5:  except for it's too expensive though. It is way too expensive. It is $229

1356
01:23:40,905 --> 01:23:41,965
Speaker 5:  and 95 cents.

1357
01:23:43,485 --> 01:23:44,345
Speaker 5:  And it's

1358
01:23:44,345 --> 01:23:48,105
Speaker 6:  Also called the Ace LTE, which is like the least cool

1359
01:23:48,245 --> 01:23:49,505
Speaker 6:  kid name I've ever heard.

1360
01:23:49,655 --> 01:23:53,345
Speaker 5:  It's real bad. And also you need a data plan to,

1361
01:23:53,445 --> 01:23:57,025
Speaker 5:  to get the full richness of it called the Ace Pass.

1362
01:23:57,325 --> 01:24:01,185
Speaker 5:  Oh boy. And it is not cheap. It is like

1363
01:24:01,185 --> 01:24:02,545
Speaker 5:  $10 a month. Ooh,

1364
01:24:03,165 --> 01:24:03,585
Speaker 3:  That's

1365
01:24:03,585 --> 01:24:04,345
Speaker 5:  Tough. So you,

1366
01:24:04,805 --> 01:24:06,185
Speaker 3:  I'm gonna stick with just putting an air tag.

1367
01:24:06,215 --> 01:24:09,225
Speaker 5:  Yeah. Just somewhere in my phone. You can, you can alternatively stick an

1368
01:24:09,225 --> 01:24:12,705
Speaker 5:  air tag in your child and give them a 20-year-old Tamagotchi. There you go.

1369
01:24:12,845 --> 01:24:14,225
Speaker 5:  And done. Yeah.

1370
01:24:14,845 --> 01:24:18,025
Speaker 3:  We are not yet, we have not yet hit the, let's put an air tag on her. What

1371
01:24:18,025 --> 01:24:18,185
Speaker 3:  if

1372
01:24:18,185 --> 01:24:22,145
Speaker 5:  You glue the air tag to the ka tamagotchi. I see. That's the or 3D

1373
01:24:22,145 --> 01:24:24,665
Speaker 5:  print some sort of case. I bet Sean could do that for you. Yeah,

1374
01:24:24,765 --> 01:24:28,585
Speaker 3:  No, there's a, there's infinite. This is the, the entire Etsy economy is

1375
01:24:28,585 --> 01:24:31,305
Speaker 3:  weird. AI generated crap and then 3D printed stuff.

1376
01:24:31,535 --> 01:24:32,145
Speaker 5:  It's beautiful.

1377
01:24:32,145 --> 01:24:35,585
Speaker 6:  That's real. And please you can put your air tag on anything. There is a

1378
01:24:35,585 --> 01:24:39,425
Speaker 6:  case for it. If you wanna attach your air tag to a thing, you can find

1379
01:24:39,465 --> 01:24:40,985
Speaker 6:  a case for it on Etsy. Yeah. Yeah.

1380
01:24:41,325 --> 01:24:42,225
Speaker 3:  All right. David, what's yours?

1381
01:24:43,105 --> 01:24:46,825
Speaker 6:  I just wanna talk about this like slightly weird Discord blog post

1382
01:24:46,935 --> 01:24:50,305
Speaker 6:  this week. The company basically announced

1383
01:24:51,045 --> 01:24:53,065
Speaker 6:  its pivoting back to video games.

1384
01:24:53,625 --> 01:24:54,305
Speaker 5:  I didn't know it left.

1385
01:24:55,245 --> 01:24:59,145
Speaker 6:  So this is the thing. So in 2020 when Discord was

1386
01:24:59,145 --> 01:25:02,705
Speaker 6:  like really feeling itself and there was noise that Discord was gonna be

1387
01:25:02,865 --> 01:25:06,785
Speaker 6:  acquired for I think like $10 billion. It was, it was the, the work

1388
01:25:06,785 --> 01:25:10,665
Speaker 6:  from home moment. The world was weird. We try not to talk about that period

1389
01:25:10,765 --> 01:25:14,665
Speaker 6:  of 2020. Very often Discord like announced that it

1390
01:25:14,665 --> 01:25:17,465
Speaker 6:  was going to be more than just a gaming thing, right? It wanted to be a,

1391
01:25:17,705 --> 01:25:21,545
Speaker 6:  a community app for the future of the world. And

1392
01:25:21,545 --> 01:25:24,385
Speaker 6:  Discord actually has like gotten a lot of things about building a community

1393
01:25:24,385 --> 01:25:26,425
Speaker 6:  app, really. Right. There are a lot of things about it that are very clever.

1394
01:25:28,185 --> 01:25:31,545
Speaker 6:  I don't think that worked except that people started planning like crypto

1395
01:25:31,685 --> 01:25:33,705
Speaker 6:  and crimes in Discord

1396
01:25:33,705 --> 01:25:36,625
Speaker 5:  More. Yeah. It turns out there's a lot of like shitty communities out there.

1397
01:25:37,135 --> 01:25:40,985
Speaker 6:  Yeah. And not a lot of like Fortune 500 companies running on Discord. So

1398
01:25:40,985 --> 01:25:44,785
Speaker 6:  anyway, so the company pivoted back and is now about gaming again, but then

1399
01:25:44,785 --> 01:25:47,985
Speaker 6:  made a bunch of small changes that don't really change anything. And then

1400
01:25:47,985 --> 01:25:51,705
Speaker 6:  said they want to be easier for connecting either

1401
01:25:51,765 --> 01:25:54,945
Speaker 6:  before, during, or after playing a game. And I would just point out that's

1402
01:25:54,945 --> 01:25:58,905
Speaker 6:  all the time. That's still just everything. So I think

1403
01:25:59,125 --> 01:26:01,985
Speaker 6:  I'm just in a strange place where it was like, I forget who it was, but somebody

1404
01:26:01,985 --> 01:26:04,925
Speaker 6:  in our Slack was saying like, this is not a message to users. This is a message

1405
01:26:04,945 --> 01:26:08,685
Speaker 6:  to investors of like, we get it, it's fine. We're we're running away from

1406
01:26:08,685 --> 01:26:12,565
Speaker 6:  crypto. Please stop doing crimes in Discord. And, but

1407
01:26:12,565 --> 01:26:14,765
Speaker 6:  I just thought it was very funny. It's like Discord is like, we will remain

1408
01:26:14,765 --> 01:26:18,365
Speaker 6:  Discord. Just like, please only only do games here. Please. Yeah,

1409
01:26:18,805 --> 01:26:22,085
Speaker 5:  I did learn new things from that blog post. I didn't know you could have

1410
01:26:22,085 --> 01:26:23,365
Speaker 5:  Discord on like the PS five.

1411
01:26:24,035 --> 01:26:24,805
Speaker 3:  Yeah. Yeah.

1412
01:26:24,805 --> 01:26:26,685
Speaker 5:  Just clearly I don't use that

1413
01:26:26,755 --> 01:26:30,485
Speaker 3:  Feature. It's a app. Like ultimately you can deploy web app anywhere. Yeah.

1414
01:26:30,485 --> 01:26:33,125
Speaker 3:  But like, like sometimes you're like, what if I deployed this on the PS five?

1415
01:26:33,125 --> 01:26:34,085
Speaker 3:  And you're like, w why?

1416
01:26:34,635 --> 01:26:36,005
Speaker 5:  It's 'cause it's got a sick process.

1417
01:26:37,415 --> 01:26:38,085
Speaker 3:  Looks cool.

1418
01:26:38,685 --> 01:26:42,005
Speaker 6:  I mean, discords a really good chat app. Part of me wishes it's great. They

1419
01:26:42,005 --> 01:26:45,645
Speaker 6:  had gone more mainstream and instead of like the

1420
01:26:45,735 --> 01:26:49,085
Speaker 6:  50 WhatsApp group chats I'm in, I was in a bunch of discords. Like, I feel

1421
01:26:49,085 --> 01:26:51,365
Speaker 6:  like I'd feel cooler, but alas,

1422
01:26:51,585 --> 01:26:53,325
Speaker 5:  No, I'm in a couple of, a bunch of discords.

1423
01:26:53,945 --> 01:26:55,965
Speaker 3:  You're not, you're fine enough crimes, you're fine.

1424
01:26:56,405 --> 01:26:56,525
Speaker 5:  I

1425
01:26:56,525 --> 01:26:59,725
Speaker 6:  Don't do enough crimes. Youre no crimes. I don't do enough know NFTs or crimes.

1426
01:27:00,265 --> 01:27:00,685
Speaker 5:  Oh no.

1427
01:27:01,315 --> 01:27:03,725
Speaker 3:  Alex, I'm guessing you're in at least one PL related Discord.

1428
01:27:03,885 --> 01:27:04,805
Speaker 5:  I, I am, I'm not,

1429
01:27:06,465 --> 01:27:09,325
Speaker 5:  but, but I did think of the, just putting that out. Some crimes have definitely

1430
01:27:09,485 --> 01:27:10,245
Speaker 5:  happened in some Discord

1431
01:27:10,275 --> 01:27:13,645
Speaker 3:  I've seen by the way, Jason was on a decoder a while ago,

1432
01:27:14,485 --> 01:27:18,365
Speaker 3:  basically previewing all us if you wanna listen, talk about it. I was, I

1433
01:27:18,365 --> 01:27:20,725
Speaker 3:  had spent a lot of time being like, crimes happen here. And he is like, I

1434
01:27:20,995 --> 01:27:24,885
Speaker 3:  need it to stop. Like more or less. And he

1435
01:27:24,885 --> 01:27:27,365
Speaker 3:  said to me a really interesting stat. He is like, most discords are like

1436
01:27:27,365 --> 01:27:30,725
Speaker 3:  three people. It's just like three or four friends hanging out in a Discord.

1437
01:27:30,725 --> 01:27:34,165
Speaker 3:  And that's like the vast majority of Discord activity. And

1438
01:27:34,755 --> 01:27:38,085
Speaker 3:  then the big ones are like for other stuff, right? But we talked about why

1439
01:27:38,085 --> 01:27:40,245
Speaker 3:  they make games and their app platform and all this stuff. And he is like,

1440
01:27:40,245 --> 01:27:43,165
Speaker 3:  we just do that to dog food, like features for the big games.

1441
01:27:44,585 --> 01:27:48,565
Speaker 3:  All right, I'm gonna pick one. I wanted to pick, I fix it.

1442
01:27:48,565 --> 01:27:51,925
Speaker 3:  And Samsung breaking up and other repair companies are starting to say they

1443
01:27:51,925 --> 01:27:55,405
Speaker 3:  can't fix Samsung stuff either. That's boring. What I want to pick

1444
01:27:55,905 --> 01:27:59,645
Speaker 3:  is X the platform formerly known as Twitter now hiding likes.

1445
01:27:59,995 --> 01:28:01,165
Speaker 6:  Wait, what? I missed this.

1446
01:28:01,875 --> 01:28:05,765
Speaker 3:  It's very good. So they're not hiding likes. They're hiding who likes something?

1447
01:28:06,265 --> 01:28:09,045
Speaker 3:  So, you know, people used to go on Twitter and like likes something you can

1448
01:28:09,045 --> 01:28:11,605
Speaker 3:  see all their public likes. They're hiding that. They're hiding replies.

1449
01:28:11,875 --> 01:28:15,685
Speaker 3:  They're doing this because bros keep liking porn.

1450
01:28:16,075 --> 01:28:18,765
Speaker 6:  Yeah. That's not, that's all the funniest stuff on

1451
01:28:18,765 --> 01:28:22,685
Speaker 5:  Twitter. That was the best like when Tim, Ted, Tim Cruise. Ted

1452
01:28:22,755 --> 01:28:26,085
Speaker 5:  Cruz, yeah. Like was like, I love this. It's

1453
01:28:26,085 --> 01:28:29,805
Speaker 3:  Very good. Yeah, you do. It is the funniest sign of a platform in decline

1454
01:28:29,875 --> 01:28:33,765
Speaker 3:  that it's user base is now so stupid. They don't

1455
01:28:33,765 --> 01:28:36,285
Speaker 3:  even have fake accounts to like porn. No,

1456
01:28:36,645 --> 01:28:39,685
Speaker 5:  I was hearing about there's, there's some, apparently some, some male reporters

1457
01:28:39,685 --> 01:28:42,725
Speaker 5:  who love to, to like models on the Instagram and they don't know that they

1458
01:28:42,725 --> 01:28:45,085
Speaker 5:  get the little, the emoji also is shared on threads.

1459
01:28:47,945 --> 01:28:51,925
Speaker 5:  So that's pretty good. Be be thoughtful if you're gonna be horny. Don't

1460
01:28:51,925 --> 01:28:53,045
Speaker 5:  be horny on Maine. Look,

1461
01:28:53,465 --> 01:28:57,245
Speaker 3:  How do you increase Android phone sales by a burner phone

1462
01:28:57,385 --> 01:29:00,765
Speaker 3:  to do horny stuff? All right. Are you listening to me? Google?

1463
01:29:02,705 --> 01:29:05,605
Speaker 3:  That's what the pixel is for horny stuff.

1464
01:29:06,035 --> 01:29:07,165
Speaker 6:  It's pretty good. Actually

1465
01:29:07,665 --> 01:29:08,805
Speaker 3:  Buy a burner pixel

1466
01:29:09,595 --> 01:29:10,645
Speaker 5:  Just for the horny stuff.

1467
01:29:10,845 --> 01:29:13,485
Speaker 3:  A refurb pixel five with that beautiful red case.

1468
01:29:14,755 --> 01:29:18,735
Speaker 3:  It's, it's available to you. It's just an idea. Have to increase your sales,

1469
01:29:19,295 --> 01:29:19,935
Speaker 3:  save your company

1470
01:29:22,405 --> 01:29:26,255
Speaker 3:  Twitter X is saying you soon you'll be able to like, without worrying

1471
01:29:26,275 --> 01:29:29,695
Speaker 3:  who might see it. We want to encourage people to like more edgy content.

1472
01:29:30,405 --> 01:29:32,655
Speaker 3:  They use the word edgy. Wow.

1473
01:29:33,155 --> 01:29:34,895
Speaker 5:  We want you to like your porn more often.

1474
01:29:36,035 --> 01:29:39,255
Speaker 3:  I'm if you are the sort of person who describes your own work as edgy,

1475
01:29:39,875 --> 01:29:43,335
Speaker 3:  not edgy, like, I don't know. It's like, it's like Sam Altman is the bad

1476
01:29:43,335 --> 01:29:47,055
Speaker 3:  boy of it's like he can't be, but he would love it. He would like it

1477
01:29:47,155 --> 01:29:50,855
Speaker 3:  so much that he'll never get it. Yeah. Elon wants Twitter to be edgy so much

1478
01:29:50,985 --> 01:29:51,975
Speaker 3:  he'll never have it.

1479
01:29:53,535 --> 01:29:57,375
Speaker 3:  I just think this is truly one of the funniest changes any social platform

1480
01:29:57,375 --> 01:30:01,135
Speaker 3:  has ever made. There's like other reasons, right? Like I'm, I'm confident

1481
01:30:01,245 --> 01:30:05,175
Speaker 3:  Elon wants the weird racist who now populate Twitter to be able to like

1482
01:30:05,175 --> 01:30:09,095
Speaker 3:  weird racist posts without seeing it like, yep. Yeah. There's there's a

1483
01:30:09,095 --> 01:30:09,735
Speaker 3:  deep dark.

1484
01:30:10,205 --> 01:30:11,015
Speaker 5:  Will you be able to

1485
01:30:11,015 --> 01:30:11,615
Speaker 3:  Like weirdness there,

1486
01:30:12,595 --> 01:30:15,535
Speaker 5:  Go into the likes and look at the likes still?

1487
01:30:16,595 --> 01:30:18,095
Speaker 3:  No other people can't see them at

1488
01:30:18,095 --> 01:30:18,255
Speaker 5:  All.

1489
01:30:19,125 --> 01:30:22,715
Speaker 3:  Right? Like you yourself will be able to see who liked your posts. Okay.

1490
01:30:23,255 --> 01:30:26,995
Speaker 3:  You can see the like counts for posts like public like counts man. But you'll

1491
01:30:26,995 --> 01:30:30,955
Speaker 3:  not see who likes someone else's post and you will not see others. You'll

1492
01:30:30,955 --> 01:30:31,835
Speaker 3:  not see what other people like.

1493
01:30:32,035 --> 01:30:35,915
Speaker 5:  I cannot wait for one of those creators of edgy content to

1494
01:30:35,915 --> 01:30:39,315
Speaker 5:  get fed up with their edgy followers and just put 'em all

1495
01:30:39,315 --> 01:30:41,395
Speaker 3:  On the, the saddest little black book in the world. Yeah.

1496
01:30:41,615 --> 01:30:44,155
Speaker 5:  The saddest little black book. It'll be so good.

1497
01:30:45,105 --> 01:30:48,955
Speaker 3:  It's, I mean it's truly deeply, wonderfully hilarious. I love it. The platform

1498
01:30:48,955 --> 01:30:50,715
Speaker 3:  and decline just doing the weirdest stuff you can add.

1499
01:30:50,875 --> 01:30:54,435
Speaker 6:  I just really like the idea of ultimately doing

1500
01:30:55,185 --> 01:30:59,075
Speaker 6:  good healthy things by removing engagement metrics in

1501
01:30:59,075 --> 01:31:02,955
Speaker 6:  the service of making your platform easier to be sketchy on. Like

1502
01:31:02,955 --> 01:31:03,715
Speaker 6:  I think that's great. Yeah.

1503
01:31:04,355 --> 01:31:07,555
Speaker 3:  I Twitter is gonna end up, X is gonna end up I think

1504
01:31:08,655 --> 01:31:12,155
Speaker 3:  as a porn platform. Like I think they will find a way to

1505
01:31:12,625 --> 01:31:15,795
Speaker 3:  subsume only fans because it's the last thing left for them to do.

1506
01:31:15,945 --> 01:31:17,755
Speaker 6:  It's video first now supposedly.

1507
01:31:18,135 --> 01:31:22,115
Speaker 3:  Oh yeah. Linda has, she appeared. She had not appeared anyway

1508
01:31:22,475 --> 01:31:25,795
Speaker 3:  anywhere since the code conference from what I understand, which went great

1509
01:31:25,795 --> 01:31:26,115
Speaker 3:  for her.

1510
01:31:27,455 --> 01:31:28,275
Speaker 5:  Can you repeat the question?

1511
01:31:30,375 --> 01:31:34,115
Speaker 3:  And she appeared and said X is now a video first platform for creators

1512
01:31:34,415 --> 01:31:37,555
Speaker 3:  and everyone went, what? You don't make any videos.

1513
01:31:39,185 --> 01:31:42,315
Speaker 3:  Elon Musk never makes a video on his video first

1514
01:31:42,675 --> 01:31:44,675
Speaker 5:  Platform. But if you wanna make corny videos, you can

1515
01:31:45,215 --> 01:31:46,595
Speaker 3:  And secretly like them. Yep.

1516
01:31:47,835 --> 01:31:49,355
Speaker 5:  Ted Cruz is just gonna be ecstatic.

1517
01:31:49,615 --> 01:31:53,155
Speaker 3:  All right. I'm just saying. And we are in a new era of the internet, right?

1518
01:31:53,235 --> 01:31:56,035
Speaker 3:  I dunno what's gonna happen to the web, but I know this is the ULT Power

1519
01:31:56,035 --> 01:31:59,845
Speaker 3:  Sound era, and I'm convinced this is the horny

1520
01:31:59,845 --> 01:32:02,565
Speaker 3:  burner Android phoner for when you're

1521
01:32:02,615 --> 01:32:05,685
Speaker 6:  Urged to like, something is irresistible, but you don't want anyone to

1522
01:32:05,685 --> 01:32:06,965
Speaker 3:  Know this. The Pixel six A be

1523
01:32:06,965 --> 01:32:08,285
Speaker 5:  Like, I just gotta hit that heart.

1524
01:32:09,955 --> 01:32:12,565
Speaker 6:  Yeah, you want them to know, but you don't want anyone else to know.

1525
01:32:13,065 --> 01:32:17,005
Speaker 3:  That's actually a great, like opposite of what happens on iPhone stays

1526
01:32:17,125 --> 01:32:21,085
Speaker 3:  on iPhone messaging for Google when you want them to know. But no

1527
01:32:21,085 --> 01:32:24,085
Speaker 3:  one else to know the Google picks Android.

1528
01:32:24,505 --> 01:32:26,125
Speaker 5:  You're just doing Google's job today. It's

1529
01:32:26,125 --> 01:32:29,165
Speaker 3:  Pretty good. I'm trying, man. I'm trying to help everybody. All right.

1530
01:32:30,315 --> 01:32:32,245
Speaker 3:  It's someone give us some money somehow.

1531
01:32:34,755 --> 01:32:37,805
Speaker 3:  Well, lightning Round's available for horny pixel sponsorship.

1532
01:32:38,545 --> 01:32:41,845
Speaker 3:  All right. That's it. We're way over time. I appreciate you all. We do want

1533
01:32:41,845 --> 01:32:45,165
Speaker 3:  your feedback. I I'm very sincere about this. I know people have a lot of

1534
01:32:45,165 --> 01:32:49,005
Speaker 3:  feelings. We are here to earn your trust in whatever way that this previous

1535
01:32:49,005 --> 01:32:52,205
Speaker 3:  segment earned your trust. Send us a note. You can reach out to us. You can

1536
01:32:52,205 --> 01:32:54,525
Speaker 3:  call David at some phone number. Eight six six

1537
01:32:54,845 --> 01:32:55,965
Speaker 6:  VERGE one, one. Call the hotline.

1538
01:32:56,185 --> 01:32:59,325
Speaker 3:  See it. Call us. We'll, we'll answer your questions. We're again, we are,

1539
01:32:59,325 --> 01:33:02,445
Speaker 3:  we are not trying to hide the ball here at all, but we are trying to go home

1540
01:33:02,445 --> 01:33:05,005
Speaker 3:  to our families. So that's it. That's ver chest rock and roll.

1541
01:33:08,945 --> 01:33:12,005
Speaker 8:  And that's it for The Verge Cast this week. Hey, we'd love to hear from you.

1542
01:33:12,035 --> 01:33:15,965
Speaker 8:  Give us a call at eight six six VERGE one. One. The Vergecast is the

1543
01:33:15,965 --> 01:33:19,605
Speaker 8:  production of The Verge and Vox Media Podcast Network. Our show is produced

1544
01:33:19,605 --> 01:33:23,165
Speaker 8:  by Andrew Marino and Liam James. That's it. We'll see you next week.

1545
01:33:25,705 --> 01:33:29,565
Speaker 3:  All right. Alex just made a huge discovery on the ULT seven or

1546
01:33:29,725 --> 01:33:32,805
Speaker 3:  whatever this is called. Tell us what the ports are.

1547
01:33:33,355 --> 01:33:37,085
Speaker 5:  Okay, we got, we got a light button. We got, we got a

1548
01:33:37,085 --> 01:33:39,845
Speaker 5:  battery button with a minus sign for battery care.

1549
01:33:40,315 --> 01:33:40,605
Speaker 3:  Okay.

1550
01:33:41,065 --> 01:33:43,205
Speaker 5:  Key control. I don't, I don't know music.

1551
01:33:43,305 --> 01:33:44,245
Speaker 3:  That's for karaoke.

1552
01:33:44,475 --> 01:33:48,405
Speaker 5:  Okay. Echo guitar. We got a

1553
01:33:48,405 --> 01:33:49,205
Speaker 5:  guitar input, right?

1554
01:33:49,355 --> 01:33:51,365
Speaker 3:  This thing rules this. I don't know what, I don't know.

1555
01:33:51,365 --> 01:33:52,685
Speaker 5:  There's a lot going on down there.

1556
01:33:52,685 --> 01:33:55,525
Speaker 3:  There. These are all fully karaoke controls and then you can play a guitar

1557
01:33:55,525 --> 01:33:55,885
Speaker 3:  through it.

1558
01:33:56,365 --> 01:33:57,085
Speaker 5:  I sure.

1559
01:33:57,645 --> 01:33:59,605
Speaker 3:  I dunno what Battery minus care does.

1560
01:34:00,165 --> 01:34:03,285
Speaker 5:  I really wanna know, but probably not Today on The. Verge cast

1561
01:34:04,025 --> 01:34:06,485
Speaker 3:  2, 3, 4, 5.

1562
01:34:08,625 --> 01:34:10,245
Speaker 3:  Boy, can I, there we go. There we go.

1563
01:34:12,035 --> 01:34:14,845
Speaker 5:  It's got some pneuma energy, right? Yeah.

1564
01:34:15,145 --> 01:34:17,045
Speaker 6:  It always starts in the middle, which I really like.

1565
01:34:19,445 --> 01:34:19,885
Speaker 3:  I love you.

1566
01:34:21,795 --> 01:34:25,485
Speaker 3:  This thing fills me with pure joy. You're so happy. Like every other tech

1567
01:34:25,485 --> 01:34:29,445
Speaker 3:  company is like, we gotta do some AI stuff that the robots are

1568
01:34:29,445 --> 01:34:30,525
Speaker 3:  gonna bang you. Like

1569
01:34:32,255 --> 01:34:34,925
Speaker 3:  Let's just threaten everyone. Ooh. And

