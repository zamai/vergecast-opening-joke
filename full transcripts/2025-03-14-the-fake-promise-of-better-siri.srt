1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: ea6ddfbb-193b-4ce3-aff2-b81a17d42ff3
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-2721834373325362072/9067088996932765627/s93290-US-6452s-1742177608.mp3
Description: Big tech companies are forever making promises about the future. And you might (or might not) be surprised how often they don't come true. On this episode, Nilay and David start by discussing the good and bad of Apple's new iPads and Macs, before diving into the supposedly AI-powered, all-powerful Siri that is delayed indefinitely. Maybe this whole "AI will fix everything" plan wasn't such a good one. After that, The Verge's Andy Hawkins joins to discuss what's going on with Tesla: why sales are down, how the perception of the company has shifted as Elon Musk's job description has changed, and how it happened that President Trump did a Tesla sales pitch on the White House lawn. Everything's computer, you know? Finally, in the lighting round, the hosts discuss Brendan Carr's ongoing shenanigans, Jay Graber's sartorial burns, the future of Pokemon Go, and much more.

2
00:01:32,655 --> 00:01:36,125
Speaker 5:  Hello everyone with Vergecast. The flagship podcast is being forced to buy

3
00:01:36,125 --> 00:01:40,045
Speaker 5:  a Tesla by the United States government. Which Tesla will the

4
00:01:40,045 --> 00:01:43,085
Speaker 5:  government force you to buy The triangle or the round one?

5
00:01:43,545 --> 00:01:46,845
Speaker 6:  Can I get a roadster out of this? Like, do you feel like if I play my cards

6
00:01:46,855 --> 00:01:48,605
Speaker 6:  right, I can at least get a Roadster?

7
00:01:48,865 --> 00:01:52,845
Speaker 5:  The Roadster is more vaporware than full self-driving. I just wanna be a

8
00:01:53,045 --> 00:01:53,965
Speaker 5:  hundred percent clear about this.

9
00:01:54,075 --> 00:01:55,045
Speaker 6:  Yeah, I agree with that.

10
00:01:55,465 --> 00:01:59,405
Speaker 5:  All the Teslas in the world will drive themselves before the next Roadster

11
00:01:59,405 --> 00:02:03,115
Speaker 5:  comes out. Even the ones that don't have the hardware to support full

12
00:02:03,115 --> 00:02:05,835
Speaker 5:  self-driving, they will get the ability to drive themselves before the next

13
00:02:05,835 --> 00:02:06,395
Speaker 5:  Roadster comes

14
00:02:06,395 --> 00:02:08,555
Speaker 6:  Out. I agree with that. They don't even talk about the Roadster anymore.

15
00:02:09,465 --> 00:02:13,005
Speaker 5:  No. They put one in space and they're like, well, we're good with that.

16
00:02:13,665 --> 00:02:17,185
Speaker 6:  Yeah. Why? It's the the literal final

17
00:02:17,505 --> 00:02:19,985
Speaker 6:  frontier of the roaster as we have gone to space with,

18
00:02:19,985 --> 00:02:23,945
Speaker 5:  Have you seen this unreliable triangle? Let's do it. I

19
00:02:23,945 --> 00:02:26,905
Speaker 5:  just wanna alert everyone to the fact that just before we started the show,

20
00:02:26,905 --> 00:02:30,705
Speaker 5:  David said that he had too many Tads open on his computer and his computer

21
00:02:30,725 --> 00:02:34,705
Speaker 5:  was freaking out. And David, I want to remind you, you are the

22
00:02:34,705 --> 00:02:38,345
Speaker 5:  world's foremost proponent of only having eight gigs of RAM on your Mac.

23
00:02:39,185 --> 00:02:42,665
Speaker 6:  I will just say 16 is better.

24
00:02:43,935 --> 00:02:47,865
Speaker 6:  This is my, my great take from the last couple of

25
00:02:47,865 --> 00:02:51,625
Speaker 6:  years of, of my life and gadget reviews. I now have

26
00:02:51,625 --> 00:02:55,585
Speaker 6:  16 gigs of RAM on this M four Mac mini that I bought last

27
00:02:55,585 --> 00:02:59,025
Speaker 6:  fall. It's better. Yeah. That's, that's, that's the takeaway.

28
00:02:59,605 --> 00:03:02,965
Speaker 6:  I still think eight is basically fine. Mostly because most people are not

29
00:03:03,105 --> 00:03:07,085
Speaker 6:  tab monsters the way that I'm a tab monster. But If you can

30
00:03:07,105 --> 00:03:10,525
Speaker 6:  get 16, it's life is good here.

31
00:03:11,725 --> 00:03:15,415
Speaker 5:  I disagree. I think most people are tab monsters. Yeah. I think most Macs

32
00:03:15,415 --> 00:03:16,375
Speaker 5:  are used as Chromebooks.

33
00:03:16,955 --> 00:03:20,735
Speaker 6:  Oh, I totally agree with that. I think most computers are, are just

34
00:03:20,775 --> 00:03:24,575
Speaker 6:  browsers now, which is like, makes it all the funnier that Google has

35
00:03:24,605 --> 00:03:27,975
Speaker 6:  sort of botched the Chromebook thing so badly because like the thesis was

36
00:03:27,975 --> 00:03:31,495
Speaker 6:  exactly correct, which is that most people just wanna do web stuff on their

37
00:03:31,655 --> 00:03:35,185
Speaker 6:  computer all day. And yet Chromebooks are awful at that.

38
00:03:35,375 --> 00:03:35,665
Speaker 6:  Yeah.

39
00:03:35,775 --> 00:03:38,985
Speaker 5:  What if we made this cheaper and it still didn't have enough rent?

40
00:03:40,525 --> 00:03:44,505
Speaker 5:  My, my advice for everybody is that it, it kind of, your CPU and your GPU

41
00:03:44,505 --> 00:03:48,145
Speaker 5:  don't matter unless you they matter to you. Well, you know, If you are the

42
00:03:48,145 --> 00:03:51,905
Speaker 5:  sort of person for whom those things matter, you've already self-identified

43
00:03:51,965 --> 00:03:55,765
Speaker 5:  and be free. Yeah. Run with the alphas, go nuts.

44
00:03:56,345 --> 00:03:58,325
Speaker 5:  But for most people, the number you should care about is ram.

45
00:03:59,035 --> 00:04:02,365
Speaker 6:  Yeah. I I totally agree. I think it goes RAM storage,

46
00:04:04,975 --> 00:04:08,895
Speaker 6:  C-P-U-G-P-U, everything else. Yeah. It's like how I would stack

47
00:04:08,895 --> 00:04:09,815
Speaker 6:  rank that for most people

48
00:04:10,635 --> 00:04:13,925
Speaker 5:  It's, there's a, a number of people who think GPU should be hired on CPU

49
00:04:13,925 --> 00:04:15,725
Speaker 5:  me, but that's like a new phenomenon. Yeah.

50
00:04:15,725 --> 00:04:18,045
Speaker 6:  And I think that's, that's a reasonable case to be made depending on what

51
00:04:18,045 --> 00:04:21,725
Speaker 6:  you do on your computer. But in terms of like what makes your computer

52
00:04:21,835 --> 00:04:25,525
Speaker 6:  feel smooth and fast and good so that you don't like, think about your

53
00:04:25,725 --> 00:04:27,925
Speaker 6:  computer a lot. That's, that's still how I would rank them.

54
00:04:28,305 --> 00:04:31,725
Speaker 5:  And you and you're still in that ranking. Going with eight gigs is enough.

55
00:04:32,005 --> 00:04:35,685
Speaker 6:  Listen, I, I have an M four mini that I sit here and use every day. And I

56
00:04:35,685 --> 00:04:39,285
Speaker 6:  have an M1 air that is my travel computer.

57
00:04:39,575 --> 00:04:41,605
Speaker 6:  Eight gigs of RAM works just fine

58
00:04:43,265 --> 00:04:45,565
Speaker 6:  as long as I don't make it do anything complicated.

59
00:04:47,365 --> 00:04:51,045
Speaker 5:  Well, I still have a tab open with the M four max, max Studio

60
00:04:51,905 --> 00:04:53,125
Speaker 5:  2199.

61
00:04:54,955 --> 00:04:58,855
Speaker 5:  You know, I'm just thinking about it every, as, as many Americans know, I've

62
00:04:58,855 --> 00:04:59,935
Speaker 5:  been thinking about buying a new computer.

63
00:05:00,675 --> 00:05:02,615
Speaker 6:  We have one. People are excited about it.

64
00:05:02,885 --> 00:05:05,215
Speaker 5:  They are. We and we should talk about that. We have reviews of all the new

65
00:05:05,215 --> 00:05:09,135
Speaker 5:  Mac stuff, the M four MacBook Air, sort of a half review

66
00:05:09,135 --> 00:05:12,615
Speaker 5:  of the M three Ultra Mac studio, which is really

67
00:05:12,935 --> 00:05:15,255
Speaker 5:  interesting. Some of the Ben early benchmarks are interesting. We should

68
00:05:15,255 --> 00:05:18,415
Speaker 5:  talk about that at length. And Chris is gonna keep reviewing that stuff.

69
00:05:18,415 --> 00:05:21,935
Speaker 5:  He's got a bunch of ideas about AI reviews there, which is interesting. And

70
00:05:21,935 --> 00:05:25,735
Speaker 5:  then David, you reviewed the new iPad here. I did as punishment. I,

71
00:05:27,295 --> 00:05:31,055
Speaker 6:  I really, one day I just want Apple to just sneak

72
00:05:31,055 --> 00:05:34,015
Speaker 6:  something weird into an iPad just to see if people notice anymore.

73
00:05:35,615 --> 00:05:39,295
Speaker 5:  So we should talk about all that. Apple's delaying the new Siri. David, you

74
00:05:39,295 --> 00:05:43,255
Speaker 5:  wrote a piece about just AI and gadgets in general that I want to talk about.

75
00:05:44,195 --> 00:05:47,055
Speaker 5:  We, we've seem to have gotten way out over our skis in the tech industry

76
00:05:47,165 --> 00:05:50,135
Speaker 5:  with ai. Andy Hawkins gonna join us. We're gonna talk about Tesla.

77
00:05:51,355 --> 00:05:55,295
Speaker 5:  Andy's gonna show up with a government issued Tesla. Then we got a

78
00:05:55,295 --> 00:05:58,615
Speaker 5:  lightning round. Brendan Carr won't shut, he won't shut up.

79
00:05:59,255 --> 00:06:03,175
Speaker 5:  I was gonna say an F on there. That's illegal now in

80
00:06:03,175 --> 00:06:06,335
Speaker 5:  Brendan's America. And we got some other, I guess talk about that later round.

81
00:06:06,445 --> 00:06:08,895
Speaker 5:  It's a, it's a show. We got a whole, we got a whole Vergecast in front of

82
00:06:08,895 --> 00:06:12,135
Speaker 5:  us. What's, do you wanna start quickly with reviews and then talk about Siri?

83
00:06:12,405 --> 00:06:12,695
Speaker 5:  Sure.

84
00:06:12,815 --> 00:06:16,695
Speaker 6:  I mean, I think we can do this quickly because this is sort of

85
00:06:16,735 --> 00:06:20,655
Speaker 6:  a fascinating case of Apple doing just precisely exactly what

86
00:06:20,675 --> 00:06:24,615
Speaker 6:  you would think Apple would do. And I think in one case

87
00:06:25,045 --> 00:06:28,785
Speaker 6:  with the M four MacBook Air, that is terrific news,

88
00:06:28,795 --> 00:06:32,265
Speaker 6:  right? Like Antonio de Beto on our team reviewed it and basically it's like

89
00:06:32,655 --> 00:06:36,545
Speaker 6:  this is the computer that you would hope it would be battery

90
00:06:36,545 --> 00:06:40,465
Speaker 6:  lasts a really long time. Performance is good. It, it throttles when it

91
00:06:40,465 --> 00:06:44,145
Speaker 6:  gets hot when you tax it too much because that's what MacBook airs do. But

92
00:06:44,145 --> 00:06:46,745
Speaker 6:  most people who buy an air aren't doing that kind of stuff anyway.

93
00:06:48,285 --> 00:06:51,945
Speaker 6:  The sky blue is like whatever. Even in Antonio's photos, it's often hard

94
00:06:51,945 --> 00:06:55,545
Speaker 6:  to tell whether it's sky blue or silver, depending on the light. It's just

95
00:06:55,585 --> 00:06:59,265
Speaker 6:  a computer. But it is like this thing is now a hundred dollars cheaper

96
00:07:00,555 --> 00:07:03,855
Speaker 6:  and it's great. And that is like fabulous news, right? And there are like

97
00:07:03,855 --> 00:07:07,775
Speaker 6:  little bits that you can quibble with about the screen quality and whatever,

98
00:07:07,775 --> 00:07:11,055
Speaker 6:  but like it isn't awesome computer for a hundred dollars less than it was

99
00:07:11,055 --> 00:07:14,615
Speaker 6:  before. And that's awesome. And then on the iPad I come out of this, I'm

100
00:07:14,615 --> 00:07:16,935
Speaker 6:  like, oh, it's it sure.

101
00:07:18,285 --> 00:07:18,575
Speaker 5:  It's

102
00:07:18,575 --> 00:07:22,215
Speaker 6:  Like this is like an the most iterative upgrade in

103
00:07:22,575 --> 00:07:26,375
Speaker 6:  a long run of incredibly iterative upgrades on the iPad. And like is it

104
00:07:26,375 --> 00:07:30,215
Speaker 6:  still good? Yes. But If you bought an

105
00:07:30,325 --> 00:07:32,815
Speaker 6:  iPad like since

106
00:07:34,095 --> 00:07:36,325
Speaker 6:  Covid, you don't need this iPad.

107
00:07:36,985 --> 00:07:39,725
Speaker 5:  We actually got a bunch of really interesting feedback to the last episode

108
00:07:39,725 --> 00:07:43,085
Speaker 5:  where we talked about how long iPadOS last and a number of people

109
00:07:44,155 --> 00:07:48,045
Speaker 5:  said that they overbuy the iPad because they want it to last

110
00:07:48,285 --> 00:07:49,285
Speaker 5:  a decade. Yeah.

111
00:07:49,735 --> 00:07:53,565
Speaker 6:  Which I would say tracks generally with my overarching gadget advice, which

112
00:07:53,565 --> 00:07:56,565
Speaker 6:  is I think everybody should buy the best thing they can afford,

113
00:07:57,515 --> 00:08:00,605
Speaker 6:  even if it's more than they need. And then keep it as long as humanly possible.

114
00:08:00,605 --> 00:08:03,885
Speaker 6:  Like I, I think that's a perfectly rational way to handle an iPad. And If

115
00:08:03,885 --> 00:08:07,775
Speaker 6:  you do that, you can probably squeeze a decade out of

116
00:08:07,775 --> 00:08:11,295
Speaker 6:  an iPad without trying too too hard. Yeah. In many cases, like the thing

117
00:08:11,295 --> 00:08:15,135
Speaker 6:  that goes away is you start to lose app support because like one by

118
00:08:15,155 --> 00:08:18,695
Speaker 6:  one streaming apps will stop supporting it and you'll just sort of

119
00:08:19,065 --> 00:08:22,775
Speaker 6:  piece by piece lose your iPad's ability to do stuff.

120
00:08:23,195 --> 00:08:26,935
Speaker 6:  But like If you just dig out a 2015

121
00:08:27,325 --> 00:08:30,735
Speaker 6:  iPad right now, it will still do the basic things that it does

122
00:08:31,075 --> 00:08:34,875
Speaker 6:  pretty successfully. Which is awesome 10 years ago.

123
00:08:35,145 --> 00:08:35,435
Speaker 6:  Yeah,

124
00:08:35,785 --> 00:08:39,635
Speaker 5:  Well it's, it's the ba it's you gotta overbuy, right? So we had people

125
00:08:39,635 --> 00:08:42,435
Speaker 5:  who are like, I'm, I'm buying an iPad Pro in the hopes that it'll last a

126
00:08:42,435 --> 00:08:45,955
Speaker 5:  decade. I think you buy the base model, it's a reasonable assumption that

127
00:08:45,955 --> 00:08:49,915
Speaker 5:  that thing will have a shorter life than If you buy a pro model

128
00:08:49,915 --> 00:08:53,715
Speaker 5:  or an air or something. Here it, it's the iPad Air, right,

129
00:08:53,715 --> 00:08:57,645
Speaker 5:  that we're talking about upgraded has the M three. I would guess that this

130
00:08:57,645 --> 00:09:00,765
Speaker 5:  thing will last you maybe not a decade, but seven years, right?

131
00:09:00,915 --> 00:09:02,245
Speaker 6:  Yeah. I think that's reasonable

132
00:09:02,355 --> 00:09:06,165
Speaker 5:  That that feels right. And the only thing that might change that is if

133
00:09:06,165 --> 00:09:10,045
Speaker 5:  there's some sort of paradigm shift in how much

134
00:09:10,045 --> 00:09:13,925
Speaker 5:  compute you need to do something. Right? I'm not sure

135
00:09:13,925 --> 00:09:17,765
Speaker 5:  what that is. Apple hasn't come up with it in a long time. Right? Right.

136
00:09:17,765 --> 00:09:21,165
Speaker 5:  Like iPad apps have not gotten more complicated. That whole application model

137
00:09:21,265 --> 00:09:23,845
Speaker 5:  has not allowed more complicated apps

138
00:09:24,895 --> 00:09:28,875
Speaker 5:  really to exist. I mean there are some, I I don't wanna, I don't wanna underplay

139
00:09:28,875 --> 00:09:32,555
Speaker 5:  it. There are some very intense iPad apps, but it's not,

140
00:09:33,725 --> 00:09:34,775
Speaker 5:  it's not the ecosystem.

141
00:09:35,395 --> 00:09:38,495
Speaker 6:  No. And there's really nothing. It was actually really funny testing the

142
00:09:38,655 --> 00:09:42,395
Speaker 6:  M three because there are so few apps out there that are

143
00:09:42,395 --> 00:09:46,195
Speaker 6:  willing to push the boundaries of the thing specifically because

144
00:09:46,945 --> 00:09:50,275
Speaker 6:  lots of people own iPadOS, lots of people own older iPadOS. So actually if

145
00:09:50,275 --> 00:09:53,735
Speaker 6:  you're a developer, you shouldn't really target

146
00:09:54,715 --> 00:09:57,845
Speaker 6:  like the bleeding edge new technology. So there are a few that do because

147
00:09:57,845 --> 00:10:01,245
Speaker 6:  they have to, because they're trying to do really complicated like 3D image

148
00:10:01,245 --> 00:10:04,685
Speaker 6:  rendering stuff in real time. That is just hard. And you can like feel it

149
00:10:04,685 --> 00:10:08,525
Speaker 6:  because the iPad gets warm as it's working. But for the most part,

150
00:10:08,635 --> 00:10:12,525
Speaker 6:  like even some of the most intense intensive

151
00:10:12,615 --> 00:10:16,525
Speaker 6:  games I'm using at max settings, you can tell they made

152
00:10:16,525 --> 00:10:20,365
Speaker 6:  this and they tested it on like an iPad mini. And so

153
00:10:20,365 --> 00:10:23,645
Speaker 6:  it's like if you're gonna make something that works across this whole lineup,

154
00:10:23,645 --> 00:10:27,485
Speaker 6:  you just can't target the really intense stuff, which is good news because

155
00:10:28,065 --> 00:10:31,165
Speaker 6:  by the, you know, by the end of a seven year lifespan of one of these things,

156
00:10:31,585 --> 00:10:35,205
Speaker 6:  it will be down at the bottom of that spectrum. But it'll still be supported.

157
00:10:35,945 --> 00:10:39,405
Speaker 6:  But for right now it's, it's even the M three is

158
00:10:39,525 --> 00:10:43,485
Speaker 6:  overkill for most things. Yeah. And that's next to the M four, which

159
00:10:43,745 --> 00:10:47,685
Speaker 6:  is now almost a year old and is still overkill for almost everything.

160
00:10:48,045 --> 00:10:51,725
Speaker 5:  I wanna issue a very specific feature request, bug

161
00:10:51,825 --> 00:10:52,245
Speaker 5:  report

162
00:10:53,925 --> 00:10:57,835
Speaker 5:  accusation of pure hypocrisy, whatever it is. However you wanna, the

163
00:10:57,835 --> 00:11:00,875
Speaker 5:  game Dream Light Valley, which I don't think your child is old enough to

164
00:11:00,875 --> 00:11:03,635
Speaker 5:  play, but which is a very big game for 6-year-old girls.

165
00:11:05,585 --> 00:11:06,715
Speaker 5:  They say it works and thus

166
00:11:06,795 --> 00:11:06,955
Speaker 6:  You,

167
00:11:07,945 --> 00:11:11,875
Speaker 5:  It's my whole life. It's a popular game. It's

168
00:11:11,995 --> 00:11:15,515
Speaker 5:  supposed to work on bass model iPad and it does not, you know, it does work

169
00:11:15,515 --> 00:11:16,355
Speaker 5:  on my phone.

170
00:11:19,745 --> 00:11:20,965
Speaker 6:  Oh, you're screwed. That sucks.

171
00:11:20,965 --> 00:11:23,725
Speaker 5:  Lemme tell you how plane rides with my child have gone recently.

172
00:11:25,305 --> 00:11:29,045
Speaker 5:  She is playing Dream Wide Valley on my phone and I am using YouTube

173
00:11:29,075 --> 00:11:30,085
Speaker 5:  kids on her app

174
00:11:32,155 --> 00:11:35,325
Speaker 5:  just watching whatever weird stuff we've downloaded in the background.

175
00:11:35,955 --> 00:11:39,645
Speaker 5:  It's great and I love it. And if the whole point of Apple having total

176
00:11:39,645 --> 00:11:43,285
Speaker 5:  control over that store is making sure that the

177
00:11:43,285 --> 00:11:47,085
Speaker 5:  listings are accurate and this listing says it works on the baseball

178
00:11:47,155 --> 00:11:50,925
Speaker 5:  iPad and it absolutely doesn't. And you can find very confused parents

179
00:11:50,945 --> 00:11:53,245
Speaker 5:  on forum across the internet saying, why did you lie to me?

180
00:11:53,355 --> 00:11:55,085
Speaker 6:  Yeah. There's a lot of that going around right now. I

181
00:11:55,195 --> 00:11:59,095
Speaker 5:  Mean, listeners out there at Apple or Disney, two of America's most

182
00:11:59,095 --> 00:12:01,575
Speaker 5:  important corporations, just help me out guys,

183
00:12:01,845 --> 00:12:02,975
Speaker 6:  Just fix this one thing.

184
00:12:03,325 --> 00:12:06,335
Speaker 5:  Just make it run on the base model iPad or, or change the listing so

185
00:12:07,385 --> 00:12:10,905
Speaker 5:  other people don't end up like me on a plane watching YouTube kids

186
00:12:11,285 --> 00:12:12,825
Speaker 5:  on a base model iPad and a Rainbow case.

187
00:12:12,865 --> 00:12:15,665
Speaker 6:  I mean the Wiggles are doing stuff, it's fine. They're, they're around.

188
00:12:16,515 --> 00:12:18,865
Speaker 5:  Let's talk about the studio. The studio's really interesting. Like I said,

189
00:12:18,925 --> 00:12:22,545
Speaker 5:  I'm just goading myself into paying 2200 a computer on the theory

190
00:12:22,815 --> 00:12:26,665
Speaker 5:  that the marginal cost, which at this in this case is like

191
00:12:26,705 --> 00:12:30,425
Speaker 5:  a thousand dollars more than I would spend on a Mac Mini will make that

192
00:12:30,705 --> 00:12:34,635
Speaker 5:  computer last five more years. That's what I'm convincing myself of

193
00:12:34,635 --> 00:12:38,035
Speaker 5:  because I do keep my Macs for a very long time once I get 'em set up. I don't

194
00:12:38,035 --> 00:12:40,795
Speaker 5:  like to monkey with them. Yeah. It's very hard to perceive the difference

195
00:12:40,795 --> 00:12:43,955
Speaker 5:  year to year with Mac, as we can tell from MacBook Air. But what's really

196
00:12:44,115 --> 00:12:48,035
Speaker 5:  interesting is Chris Welch has the M three Ultra, which is the top config,

197
00:12:48,815 --> 00:12:52,555
Speaker 5:  the M three Ultra means it just has a lot of GPUs. It's basically four M

198
00:12:52,555 --> 00:12:56,475
Speaker 5:  threes all put together using their interweaving technology to make the

199
00:12:56,475 --> 00:13:00,315
Speaker 5:  chips work as one Ultra fusion I think it's called. And it's really interesting

200
00:13:00,315 --> 00:13:03,875
Speaker 5:  because the single core performance of the M four max is higher than the

201
00:13:03,875 --> 00:13:07,675
Speaker 5:  single core performance of the M three Ultra. But If you need all the GPUs

202
00:13:07,935 --> 00:13:11,235
Speaker 5:  or the multi-core performance, obviously the M three Ultra is gonna gonna

203
00:13:11,235 --> 00:13:15,145
Speaker 5:  do it for you. And that, that's fairly unusual for

204
00:13:15,165 --> 00:13:16,225
Speaker 5:  an Apple product line.

205
00:13:16,425 --> 00:13:20,185
Speaker 6:  I, I'm sort of torn on it because on the one hand, the people who are specking

206
00:13:20,185 --> 00:13:24,145
Speaker 6:  this thing out at that level are going to know which one

207
00:13:24,145 --> 00:13:28,025
Speaker 6:  they need more, right? Like if, if I'm doing a lot

208
00:13:28,025 --> 00:13:31,865
Speaker 6:  of graphical heavy image rendering or like

209
00:13:32,125 --> 00:13:35,825
Speaker 6:  one of the examples Chris Walch used is, is crushing huge

210
00:13:35,855 --> 00:13:39,385
Speaker 6:  data sets of medical information. Like whatever, that's the kind of stuff

211
00:13:39,385 --> 00:13:42,305
Speaker 6:  you're like, okay, I need the GPU cores and the sort of single thread CPU

212
00:13:42,305 --> 00:13:45,545
Speaker 6:  cores are less important, but he makes the point in his piece and I think

213
00:13:45,545 --> 00:13:49,415
Speaker 6:  he's right. That minute to minute fastness

214
00:13:49,415 --> 00:13:53,175
Speaker 6:  of your computer actually depends a lot on the single

215
00:13:53,175 --> 00:13:57,015
Speaker 6:  core performance of your CPU except this stuff

216
00:13:57,015 --> 00:14:00,935
Speaker 6:  is so beyond what most, what any of that will

217
00:14:00,935 --> 00:14:04,855
Speaker 6:  require anyway, that it does feel like this is an interesting benchmark.

218
00:14:04,855 --> 00:14:08,815
Speaker 6:  But I suspect even If you were to flip the results, most people would not

219
00:14:09,095 --> 00:14:12,735
Speaker 6:  perceive any difference at all. But it is, I think I I I made a joke

220
00:14:12,925 --> 00:14:16,815
Speaker 6:  last week about Apple sort of muddying understanding of this

221
00:14:16,815 --> 00:14:20,655
Speaker 6:  by making the M three Ultra more powerful than the M four max. And I

222
00:14:20,655 --> 00:14:23,855
Speaker 6:  got a bunch of people who are like, well the last generation pro models are

223
00:14:23,855 --> 00:14:26,935
Speaker 6:  more powerful than the current generation regular models. I'm like, sure,

224
00:14:27,175 --> 00:14:30,975
Speaker 6:  whatever. This is confusing. Like there, there is a, this, this

225
00:14:30,975 --> 00:14:34,935
Speaker 6:  is not a simple thing that you can just ladder up in the buttons

226
00:14:35,035 --> 00:14:37,975
Speaker 6:  of apple's buy process and figure it out that way.

227
00:14:38,925 --> 00:14:41,655
Speaker 6:  It's, it's, it is, it's an interesting quirk of how Apple puts these things

228
00:14:41,815 --> 00:14:45,455
Speaker 6:  together that this is the case, that what they seem to be able to ramp is

229
00:14:45,655 --> 00:14:49,645
Speaker 6:  GPU more easily and sort of linearly with more

230
00:14:49,645 --> 00:14:52,365
Speaker 6:  chips than C, which is kind of fascinating

231
00:14:52,365 --> 00:14:55,205
Speaker 5:  Because they are just fusing them together. Well,

232
00:14:55,205 --> 00:14:55,885
Speaker 6:  Right. It

233
00:14:55,885 --> 00:14:59,765
Speaker 5:  Still, I mean, and that's, I'm not saying that's easy, that's very

234
00:14:59,765 --> 00:15:02,405
Speaker 5:  hard and they haven't yet been able to really do it with the force. Right.

235
00:15:02,505 --> 00:15:06,445
Speaker 5:  But it is the case that what they're, they're doing is they're creating one

236
00:15:06,895 --> 00:15:10,365
Speaker 5:  giant virtual C-P-U-G-P-U monster out of

237
00:15:10,365 --> 00:15:14,085
Speaker 5:  individual ones, which is a lot. I mean that's a lot of how the ship

238
00:15:14,245 --> 00:15:18,045
Speaker 5:  industry has developed over time. But it makes sense that the big

239
00:15:18,295 --> 00:15:21,605
Speaker 5:  multi-core parallel processing workloads would benefit from that approach,

240
00:15:22,115 --> 00:15:25,885
Speaker 5:  whereas it just doesn't seem like they're, they're motivated to do it on

241
00:15:25,885 --> 00:15:28,245
Speaker 5:  the M four side yet, or, or they figured it out.

242
00:15:28,435 --> 00:15:31,285
Speaker 6:  Yeah. It also just strikes me as a slightly harder problem, right? Like if

243
00:15:31,305 --> 00:15:34,965
Speaker 6:  to take, to take one thing that is designed to work in

244
00:15:35,205 --> 00:15:39,045
Speaker 6:  parallel and shove more parallel at it is just

245
00:15:39,045 --> 00:15:42,725
Speaker 6:  an easier math problem to solve than like how do you make the thing spin

246
00:15:42,725 --> 00:15:46,485
Speaker 6:  faster? Right? Which is not what it's doing, but is like still the metaphor

247
00:15:46,485 --> 00:15:49,365
Speaker 6:  in my head of how A CPU actually works. It just spins around really fast.

248
00:15:49,395 --> 00:15:51,645
Speaker 5:  There's a hamster in there just running, just running

249
00:15:51,645 --> 00:15:51,885
Speaker 6:  Inside. Yeah. It

250
00:15:51,885 --> 00:15:55,485
Speaker 5:  Just spins around. It just juiced the hamster man. Just pour some prime on

251
00:15:55,485 --> 00:15:56,125
Speaker 5:  it and see what happens.

252
00:15:56,395 --> 00:15:59,925
Speaker 6:  Yeah. So Chris Welch tested a, what was it, a $9,000 eight

253
00:15:59,935 --> 00:16:03,845
Speaker 6:  $8,000 studio. Did it make you want a studio more?

254
00:16:04,625 --> 00:16:08,285
Speaker 5:  It made me very confident that the M four max

255
00:16:08,395 --> 00:16:12,085
Speaker 5:  base configuration with only one upgrade, which is to get a

256
00:16:12,085 --> 00:16:15,485
Speaker 5:  terabyte of storage, is almost a perfect price

257
00:16:15,485 --> 00:16:19,145
Speaker 5:  performance computer. I see that. That's 2200. I am not saying it's cheap.

258
00:16:19,145 --> 00:16:22,985
Speaker 5:  Yeah. It's a very expensive computer. Especially 'cause the base M

259
00:16:22,985 --> 00:16:26,945
Speaker 5:  four mini is like $600, right? Yeah. So

260
00:16:26,945 --> 00:16:30,265
Speaker 5:  it's a huge jump. But am I convinced that that computer will sit at my desk

261
00:16:30,265 --> 00:16:33,945
Speaker 5:  for a decade and I won't be mad about it for a very long time? Yeah. I'm

262
00:16:33,945 --> 00:16:37,185
Speaker 5:  pretty convinced of that. Yep. And it has a faster SD card slot, which matters

263
00:16:37,185 --> 00:16:40,985
Speaker 5:  to me. It has Thunderbolt five ports, which I don't think the mini

264
00:16:40,985 --> 00:16:43,945
Speaker 5:  has. Like there's just a bunch of like future proofy stuff

265
00:16:45,245 --> 00:16:49,055
Speaker 5:  that I, you know, is it worth that much more money? Maybe not.

266
00:16:49,235 --> 00:16:53,015
Speaker 5:  But if I end up buying a new computer every four years instead of

267
00:16:53,265 --> 00:16:56,175
Speaker 5:  every 10, like maybe that adds up. Yeah, it probably doesn't. It probably

268
00:16:56,175 --> 00:16:59,715
Speaker 5:  still doesn't. But you know, there's inflation in tariffs, the prices go

269
00:16:59,715 --> 00:17:01,475
Speaker 5:  up, you gotta get in there while you can.

270
00:17:02,065 --> 00:17:05,515
Speaker 6:  Yeah. How many Mac mini, like how quickly would you have to rev your Mac

271
00:17:05,545 --> 00:17:09,345
Speaker 6:  mini before it hits the price? I guess it's like four

272
00:17:09,405 --> 00:17:11,545
Speaker 6:  Mac minis If you just keep buying base Mac Minis.

273
00:17:12,885 --> 00:17:16,455
Speaker 5:  Yeah. But to buy, you have to assume that Apple is going to, someone should

274
00:17:16,455 --> 00:17:20,215
Speaker 5:  help us. Someone make a model, someone make like an Excel model of this.

275
00:17:20,955 --> 00:17:23,575
Speaker 5:  Of what, 'cause you I'm never gonna buy the base model Mac

276
00:17:23,575 --> 00:17:24,295
Speaker 6:  Mini. That's true.

277
00:17:24,545 --> 00:17:28,495
Speaker 5:  Right? I'm, I'm gonna add to the Ram, I'm, I'm probably gonna add to

278
00:17:28,495 --> 00:17:32,095
Speaker 5:  the storage. I want the 10 gigabit nick.

279
00:17:32,365 --> 00:17:35,095
Speaker 6:  Yeah. So you're buying at least the a thousand dollars Mac mini. Yeah.

280
00:17:35,095 --> 00:17:37,935
Speaker 5:  And then you're like, well I'm just gonna buy, yeah. I wanna buy a 22 Mac

281
00:17:37,935 --> 00:17:40,655
Speaker 5:  studio to run email. It's gonna be great.

282
00:17:41,775 --> 00:17:45,335
Speaker 5:  Occasionally turn the D Haze slider up in Lightroom and we'll call it a day.

283
00:17:45,395 --> 00:17:46,335
Speaker 6:  That's the stuff right there.

284
00:17:46,935 --> 00:17:50,725
Speaker 5:  I will say the only AI workload I, I regularly do is the new

285
00:17:50,785 --> 00:17:54,605
Speaker 5:  AI powered de-noise and Lightroom. Hmm. And it is magic and it is

286
00:17:54,605 --> 00:17:58,405
Speaker 5:  very slow on my current Intel powered iMac. And so even just

287
00:17:58,525 --> 00:18:01,285
Speaker 5:  speeding it up is like worth it. Yeah. Do I need this computer to speed it

288
00:18:01,285 --> 00:18:05,125
Speaker 5:  up? I do not, but do I do I think I can make the argument to myself.

289
00:18:05,855 --> 00:18:09,285
Speaker 5:  Let's, let's wait a couple more weeks and find out. The most interesting

290
00:18:09,285 --> 00:18:13,165
Speaker 5:  thing about the M three Ultra Max Studio is that it is powerful enough

291
00:18:13,185 --> 00:18:17,165
Speaker 5:  If you spec it with enough RAM to run an AI model, like deep seek R

292
00:18:17,165 --> 00:18:20,925
Speaker 5:  one locally, which we have noting really seen from other consumer

293
00:18:21,245 --> 00:18:24,565
Speaker 5:  computers that you have to, you can run some of these models locally, but

294
00:18:24,565 --> 00:18:27,205
Speaker 5:  you need to build a giant power hungry

295
00:18:28,355 --> 00:18:32,005
Speaker 5:  desktop PC with a giant power hungry card. And then to scale it, you need

296
00:18:32,005 --> 00:18:35,725
Speaker 5:  to network the cards together and you kind of just get very expensive, very

297
00:18:35,725 --> 00:18:38,725
Speaker 6:  Fast. Yeah. There was a bunch of stuff on Hacker News a couple of weeks ago

298
00:18:38,775 --> 00:18:41,965
Speaker 6:  about people sharing their, like somewhere between

299
00:18:42,055 --> 00:18:45,885
Speaker 6:  3030 $500 builds

300
00:18:46,105 --> 00:18:49,845
Speaker 6:  to run deep seek locally. And even that was like very exciting that they

301
00:18:49,845 --> 00:18:53,285
Speaker 6:  had figured out a way to do it relatively easily. The idea that this is just

302
00:18:53,285 --> 00:18:57,275
Speaker 6:  an off the shelf thing that can do it is a pretty big deal. Yeah.

303
00:18:57,335 --> 00:19:00,355
Speaker 6:  And, and like Nvidia just launched a whole line of computers designed to

304
00:19:00,355 --> 00:19:03,155
Speaker 6:  do this kind of stuff and I'm, I'm, I suspect that will be more powerful

305
00:19:03,495 --> 00:19:05,995
Speaker 6:  for some of this stuff because it's designed for this stuff. But like

306
00:19:07,335 --> 00:19:10,265
Speaker 6:  this is the kind of thing that Apple is doing in the AI world that I actually

307
00:19:10,265 --> 00:19:10,905
Speaker 6:  think is interesting.

308
00:19:11,385 --> 00:19:12,265
Speaker 5:  Yeah. But they're not doing it.

309
00:19:12,285 --> 00:19:13,865
Speaker 6:  Unlike everything else Apple is doing the

310
00:19:13,865 --> 00:19:16,505
Speaker 5:  AI world. They've just, they've just gotten themselves a computer with enough

311
00:19:16,505 --> 00:19:20,305
Speaker 5:  memory and enough processing cores to run a Chinese model

312
00:19:20,305 --> 00:19:22,305
Speaker 5:  that might be banned by the Trump administration locally.

313
00:19:22,455 --> 00:19:22,825
Speaker 6:  Love it.

314
00:19:23,215 --> 00:19:26,705
Speaker 5:  Perfect. So Apple's lead and ships have gotten to to point their lead in

315
00:19:26,985 --> 00:19:30,425
Speaker 5:  software AI development, Pok potentially sending them even farther back.

316
00:19:30,525 --> 00:19:33,745
Speaker 5:  So Chris is gonna finish reviewing the, the Mac studio.

317
00:19:34,545 --> 00:19:38,105
Speaker 5:  I will just con continue looking at this shopping cart with a 22 hour Mac

318
00:19:38,105 --> 00:19:41,305
Speaker 5:  studio in it for weeks. We'll keep covering that. There's not much to say

319
00:19:41,305 --> 00:19:44,505
Speaker 5:  about the macro care. You can just go look at the benchmarks and see If you

320
00:19:44,505 --> 00:19:47,225
Speaker 5:  wanna buy, like the only thing we're saying is jump by the base model, spend

321
00:19:47,225 --> 00:19:49,785
Speaker 5:  a little bit more money. Yeah. Like we're saying buy more RAM and more storage.

322
00:19:49,785 --> 00:19:52,985
Speaker 5:  It'll be fine. But the big news out of Apple

323
00:19:53,965 --> 00:19:57,825
Speaker 5:  is they officially announced in a name statement to John

324
00:19:57,885 --> 00:20:01,725
Speaker 5:  Gruber that they're gonna delay Siri or the AI

325
00:20:01,725 --> 00:20:04,485
Speaker 5:  powered Siri. That is the thing that everyone wants. And David, you have

326
00:20:04,485 --> 00:20:05,485
Speaker 5:  like a lot of thoughts about this.

327
00:20:05,965 --> 00:20:09,725
Speaker 6:  I do have a lot of thoughts about this. I think Apple

328
00:20:09,725 --> 00:20:13,205
Speaker 6:  deserves a lot more shit for this than they're getting to be completely honest.

329
00:20:13,825 --> 00:20:17,245
Speaker 6:  So let me, let me just read you the whole quote. This is John Gruber got

330
00:20:17,245 --> 00:20:19,725
Speaker 6:  this I think over the weekend. Oh, can

331
00:20:19,725 --> 00:20:22,565
Speaker 5:  I just say this, by the way, John's a friend. People know we go in each other's

332
00:20:22,565 --> 00:20:26,125
Speaker 5:  shows, we've talked for years, we've known each other forever. Initially

333
00:20:26,125 --> 00:20:28,565
Speaker 5:  he was like, why are you doing this background policy where you insist on

334
00:20:28,745 --> 00:20:32,445
Speaker 5:  naming all the spokespeople? And he has totally come around recently. So

335
00:20:32,445 --> 00:20:35,045
Speaker 5:  he has a statement from Apple, it's named, which I'd just say little victory,

336
00:20:35,345 --> 00:20:37,645
Speaker 5:  little victory for journalism here. Anyway, carry

337
00:20:37,645 --> 00:20:41,005
Speaker 6:  On. So this is from Jacqueline Roy at Apple who we all

338
00:20:41,865 --> 00:20:44,845
Speaker 6:  know. And she says, Siri helps our users find what they need and get things

339
00:20:44,845 --> 00:20:48,130
Speaker 6:  done quickly. And in just the past six months, we've made made Siri more

340
00:20:48,130 --> 00:20:50,845
Speaker 6:  conversational, introduce new features like type two Siri and product knowledge

341
00:20:50,845 --> 00:20:54,445
Speaker 6:  and added an integration with chat GPT. We've also been working on a more

342
00:20:54,475 --> 00:20:56,965
Speaker 6:  personalized Siri, giving it more awareness of your personal context as well

343
00:20:56,965 --> 00:20:59,925
Speaker 6:  as the ability to take action for you within and across your apps. It's going

344
00:20:59,925 --> 00:21:02,885
Speaker 6:  to take us longer than we thought to deliver on these features. And we anticipate

345
00:21:02,885 --> 00:21:06,805
Speaker 6:  rolling them out in the coming year. That is essentially Apple saying,

346
00:21:06,805 --> 00:21:10,485
Speaker 6:  we've been lying to you since last May. Yep. Like that just is what it is.

347
00:21:10,485 --> 00:21:14,245
Speaker 6:  Like the, this is the, the flagship feature of the

348
00:21:14,245 --> 00:21:18,085
Speaker 6:  iPhone 16 was Apple intelligence and the flagship feature of Apple

349
00:21:18,085 --> 00:21:20,605
Speaker 6:  Intelligence was this new series we've been saying all along that there's

350
00:21:20,605 --> 00:21:23,725
Speaker 6:  a bunch of like window dressing and stuff going on. There's Jen Moji, there's

351
00:21:23,725 --> 00:21:26,925
Speaker 6:  like the writing tools, there's the terrible notification summaries, but

352
00:21:26,925 --> 00:21:30,725
Speaker 6:  like the thing, the thing that everybody thinks of when they think about

353
00:21:30,945 --> 00:21:34,805
Speaker 6:  AI period and Apple Intelligence specifically, is this better, sir,

354
00:21:34,825 --> 00:21:37,645
Speaker 6:  the Siri that can use your apps for you, the Siri that knows more about you,

355
00:21:37,645 --> 00:21:40,485
Speaker 6:  this like multimodal Siri that can search the world and understand about

356
00:21:40,485 --> 00:21:44,165
Speaker 6:  you. And Apple is basically like, oh, nevermind, we didn't do that.

357
00:21:44,385 --> 00:21:48,285
Speaker 6:  Buy our phones next year. Maybe I'll get it then. Like, this sucks. And this,

358
00:21:48,345 --> 00:21:52,245
Speaker 6:  and like Apple, apple pulled an ad from its YouTube channel that it

359
00:21:52,245 --> 00:21:55,925
Speaker 6:  had with Bella Ramsey that was showing a feature on an iPhone 16 that

360
00:21:55,925 --> 00:21:59,125
Speaker 6:  doesn't exist. Like I don't, I don't know how to be clearer about that. Like

361
00:21:59,125 --> 00:22:02,845
Speaker 6:  that phone could not do that thing in that ad. And

362
00:22:02,945 --> 00:22:04,645
Speaker 6:  it is like, it is wild to me.

363
00:22:04,905 --> 00:22:08,845
Speaker 5:  By the way. It was, she asks it, who did I have like coffee or lunch

364
00:22:08,845 --> 00:22:09,765
Speaker 5:  with at this restaurant?

365
00:22:09,915 --> 00:22:12,965
Speaker 6:  Yeah. She's at a party and somebody waves to her and she's like, oh, it's

366
00:22:12,965 --> 00:22:15,365
Speaker 6:  that. And she like goes around the corner and she's like, who did I have

367
00:22:15,365 --> 00:22:17,885
Speaker 6:  coffee with a couple of weeks ago at whatever place? And it gives her the

368
00:22:17,885 --> 00:22:20,885
Speaker 6:  name and then she goes around and says hi to the person. You know what can't

369
00:22:20,885 --> 00:22:24,725
Speaker 6:  do that is Siri. And so, and this is just like this, it's

370
00:22:24,945 --> 00:22:28,885
Speaker 6:  so indicative of everything that is happening right now in all of

371
00:22:29,385 --> 00:22:32,645
Speaker 6:  the Apple universe, but really the gadget universe in general, like

372
00:22:33,805 --> 00:22:37,485
Speaker 6:  everyone made this bet that AI was going to just magically make

373
00:22:37,995 --> 00:22:41,845
Speaker 6:  your whole technological life better. And that all they had to do

374
00:22:42,185 --> 00:22:46,085
Speaker 6:  was give you a thing with a chip that was powerful enough to do a the

375
00:22:46,225 --> 00:22:49,885
Speaker 6:  AI stuff. And then the AI stuff would sell the gadgets. And

376
00:22:50,305 --> 00:22:54,245
Speaker 6:  we are so, so, so very far away from that world existing. And

377
00:22:55,325 --> 00:22:59,005
Speaker 6:  I, I mean, if I were a betting man, I don't think the coming year is even

378
00:22:59,005 --> 00:23:02,725
Speaker 6:  gonna come true for Apple here. We anticipate rolling them out in the coming

379
00:23:02,725 --> 00:23:06,525
Speaker 6:  year is not a thing Apple says on the record, really ever Apple,

380
00:23:06,715 --> 00:23:10,645
Speaker 6:  like generally refuses to acknowledge that it's making

381
00:23:10,725 --> 00:23:12,525
Speaker 6:  products in the future. Like,

382
00:23:13,195 --> 00:23:16,285
Speaker 5:  Well, they've already announced this one. They can't say it's in delayed

383
00:23:16,285 --> 00:23:17,685
Speaker 6:  Indefinitely. That is true. We

384
00:23:17,685 --> 00:23:20,325
Speaker 5:  Anticipate rolling this out in the coming year is about as indefinite

385
00:23:20,325 --> 00:23:24,165
Speaker 6:  As it gets. Right. But also the, the mere existence of this

386
00:23:24,235 --> 00:23:28,205
Speaker 6:  statement to anyone is a thing Apple

387
00:23:28,205 --> 00:23:31,085
Speaker 6:  traditionally doesn't do. And this is like for, for Apple to

388
00:23:32,675 --> 00:23:36,485
Speaker 6:  acknowledge that it is having problems and is delaying

389
00:23:36,485 --> 00:23:40,245
Speaker 6:  something, is a big deal and is indicative of something going deeply,

390
00:23:40,305 --> 00:23:43,205
Speaker 6:  deeply wrong. Yeah. With Siri. So

391
00:23:43,205 --> 00:23:46,085
Speaker 5:  I agree with you that they, we should be more critical of this. And don't

392
00:23:46,085 --> 00:23:49,645
Speaker 5:  worry, we, we will be, I I'll just point out the timing does make a little

393
00:23:49,645 --> 00:23:53,515
Speaker 5:  bit of sense because it's March WWC comes

394
00:23:53,515 --> 00:23:56,195
Speaker 5:  up in June, they gotta get the invites out. They gotta prep everybody. They

395
00:23:56,195 --> 00:23:58,795
Speaker 5:  gotta figure out whatever they're gonna announce. And if what they don't

396
00:23:58,795 --> 00:24:02,625
Speaker 5:  deliver is any set of hooks

397
00:24:02,625 --> 00:24:05,585
Speaker 5:  for developers to participate in the new series, they're called App intents.

398
00:24:05,805 --> 00:24:09,585
Speaker 5:  If this stuff isn't ready, they need to be well clear of it by

399
00:24:09,885 --> 00:24:13,815
Speaker 5:  wwc. So you, you throw this out in March, you can spin up whatever's

400
00:24:13,815 --> 00:24:14,855
Speaker 5:  gonna happen in June. Sure.

401
00:24:14,955 --> 00:24:18,455
Speaker 6:  But think ahead to ww DC one of two things is gonna happen. Either

402
00:24:18,785 --> 00:24:22,295
Speaker 6:  Apple is going to essentially pretend that none of this exists because

403
00:24:22,635 --> 00:24:26,095
Speaker 6:  it doesn't, which is weird because they launched it all a year ago.

404
00:24:26,995 --> 00:24:30,455
Speaker 6:  Or Apple is going to relaunch the same thing it launched a year ago.

405
00:24:30,475 --> 00:24:31,335
Speaker 5:  That's what they're gonna do.

406
00:24:31,795 --> 00:24:32,575
Speaker 6:  That's so weird.

407
00:24:32,885 --> 00:24:35,455
Speaker 5:  It's gonna be but ever so slightly more real. Right? Like last year they

408
00:24:35,455 --> 00:24:38,735
Speaker 5:  were showing concept videos, which Apple never does this year. They're gonna

409
00:24:38,735 --> 00:24:42,655
Speaker 5:  be like, we've worked with, there are Shazam which

410
00:24:42,655 --> 00:24:43,415
Speaker 5:  they own, or like

411
00:24:44,045 --> 00:24:44,575
Speaker 6:  Open DoorDash.

412
00:24:44,645 --> 00:24:48,255
Speaker 5:  It's always DoorDash, it's always poor DoorDash. The most commoditized company

413
00:24:48,875 --> 00:24:52,655
Speaker 5:  in history is gonna be DoorDash. Right. We've worked with Uber

414
00:24:52,715 --> 00:24:55,335
Speaker 5:  and we've done all this stuff the same as Amazon just did. And actually the,

415
00:24:55,335 --> 00:24:59,055
Speaker 5:  the comparison that should make Apple feel bad is the

416
00:24:59,055 --> 00:25:02,855
Speaker 5:  comparison to Amazon. Yeah. Which had exactly the same problem and

417
00:25:02,855 --> 00:25:06,535
Speaker 5:  exactly the same perception in the market of its voice assistant. It's four

418
00:25:06,535 --> 00:25:10,415
Speaker 5:  timers in music and then they hired Panos Fane. They've

419
00:25:10,415 --> 00:25:13,015
Speaker 5:  had their own share of problems along the way that's been well reported.

420
00:25:13,475 --> 00:25:17,415
Speaker 5:  But, you know, Panos launched the product, he showed it to

421
00:25:17,415 --> 00:25:21,095
Speaker 5:  people, Jen Tui talked to it, it's gonna That's true. Arrive in some way,

422
00:25:21,095 --> 00:25:24,775
Speaker 5:  shape or form. And they've talked about what they needed to do to build it,

423
00:25:24,775 --> 00:25:28,655
Speaker 5:  which is create this big orchestration layer where

424
00:25:28,675 --> 00:25:32,095
Speaker 5:  you talk to Alexa with natural language and it figures out what to do and

425
00:25:32,095 --> 00:25:36,055
Speaker 5:  then it can do, it will see to some level of execution.

426
00:25:36,585 --> 00:25:40,575
Speaker 5:  Apple doesn't appear to have built any of that yet. Or if they have,

427
00:25:40,725 --> 00:25:43,575
Speaker 5:  they just took a hard look at it and said, this isn't ready. We're delaying

428
00:25:43,575 --> 00:25:43,655
Speaker 5:  it.

429
00:25:44,145 --> 00:25:47,975
Speaker 6:  Right. Well, and I mean, you look at the first half of

430
00:25:49,035 --> 00:25:52,575
Speaker 6:  the statement and it's, it's like in just the past six months we've made

431
00:25:52,575 --> 00:25:55,335
Speaker 6:  Siri more conversational, introduced new features like type two sir and product

432
00:25:55,455 --> 00:25:58,895
Speaker 6:  knowledge and added an integration to chat GT Do you know anyone who thinks

433
00:25:58,965 --> 00:26:00,495
Speaker 6:  Siri is better today than it was six months

434
00:26:00,495 --> 00:26:01,975
Speaker 5:  Ago? No. Siri is substantially worse

435
00:26:02,395 --> 00:26:06,135
Speaker 6:  Before. I totally agree. I honestly believe it has, it has gone significantly

436
00:26:06,365 --> 00:26:10,335
Speaker 6:  backwards in both its ability to even understand you,

437
00:26:10,715 --> 00:26:14,375
Speaker 6:  but also like to do useful things.

438
00:26:14,795 --> 00:26:18,375
Speaker 6:  It it punts to chat GPT for things that don't make any sense. Yeah. And like,

439
00:26:18,375 --> 00:26:22,215
Speaker 6:  and it's, it's a, that integration is kind of flaky in my experience. Like

440
00:26:22,215 --> 00:26:26,135
Speaker 6:  it just, the whole thing sucks. And so to the extent that we're seeing this,

441
00:26:27,125 --> 00:26:30,895
Speaker 6:  it's bad, which makes it not surprising that it might even be worse than

442
00:26:30,895 --> 00:26:31,855
Speaker 6:  we know. So,

443
00:26:31,875 --> 00:26:34,975
Speaker 5:  You know, it's really interesting is to just think about this on, on the

444
00:26:35,005 --> 00:26:38,765
Speaker 5:  long arc, right? Siri launched when we

445
00:26:38,765 --> 00:26:42,005
Speaker 5:  started The Verge. A weird thing Oh yeah. To think about. Yeah.

446
00:26:42,965 --> 00:26:46,565
Speaker 5:  iPhone four s with Siri came out in 2011. That's when we were sitting around

447
00:26:46,565 --> 00:26:50,085
Speaker 5:  our first office in, in Union Square

448
00:26:50,085 --> 00:26:53,925
Speaker 5:  basically in Manhattan. It was tiny. The bathrooms were right next

449
00:26:53,925 --> 00:26:56,725
Speaker 5:  to the office. It wasn't great. And I remember sitting in that conference

450
00:26:56,725 --> 00:26:58,885
Speaker 5:  room, the first Siri launch, and we were like covering as fast as we could.

451
00:26:59,425 --> 00:27:03,325
Speaker 5:  And If you were, remember how that series solved problems?

452
00:27:03,555 --> 00:27:06,885
Speaker 5:  They had done the voice assistant so that you could talk to it.

453
00:27:07,425 --> 00:27:11,085
Speaker 5:  And then they had actually built like what amounts to a very primitive

454
00:27:11,405 --> 00:27:15,365
Speaker 5:  orchestration layer. So sometimes Siri is gonna do the math locally. Sometimes

455
00:27:15,435 --> 00:27:18,685
Speaker 5:  it's gonna kick out to Wolf from Alpha. Right. Do you remember how often

456
00:27:18,755 --> 00:27:22,165
Speaker 5:  Siri to kick to Wolf and Alpha? Oh yeah. And sometimes it would kick to other

457
00:27:22,445 --> 00:27:25,925
Speaker 5:  services and they had built this like, you know, If you just like sort of

458
00:27:25,925 --> 00:27:29,845
Speaker 5:  look at it abstractly, they had built primitive versions

459
00:27:29,845 --> 00:27:33,565
Speaker 5:  of all the things that they need now. Like, we're gonna accept the

460
00:27:33,565 --> 00:27:36,805
Speaker 5:  input, we're gonna figure out what to do with it. We're gonna go out to another

461
00:27:36,805 --> 00:27:40,045
Speaker 5:  service and we're gonna come back to you with some kind of answer or response

462
00:27:40,045 --> 00:27:43,845
Speaker 5:  or something. And it, it worked, it didn't work as well as it

463
00:27:43,845 --> 00:27:47,245
Speaker 5:  should, but kind of the promise was they would add more and more services

464
00:27:47,265 --> 00:27:49,965
Speaker 5:  on the backend and that orchestration layer would get smarter and smarter

465
00:27:50,345 --> 00:27:53,965
Speaker 5:  and then voice recognition would improve and all that would just sort of

466
00:27:53,965 --> 00:27:56,165
Speaker 5:  get better over time. And instead what Apple did was they kind of just like

467
00:27:56,185 --> 00:28:00,165
Speaker 5:  let it go. Like I don't know why they just let it go, but they just

468
00:28:00,165 --> 00:28:04,125
Speaker 5:  let it go. This is also basically what happened with Alexa. Here's

469
00:28:04,125 --> 00:28:07,805
Speaker 5:  this voice assistant, we're gonna build all these skills. You're gonna talk

470
00:28:07,805 --> 00:28:10,285
Speaker 5:  to it. The skills are gonna fire or you're gonna learn how to talk to the

471
00:28:10,285 --> 00:28:12,885
Speaker 5:  skills and they just let it go. Like it just didn't happen for them.

472
00:28:14,525 --> 00:28:18,205
Speaker 5:  I think what everyone got confused about was one part of that

473
00:28:18,405 --> 00:28:22,205
Speaker 5:  equation got so much better. Right. AI and LLMs made the

474
00:28:22,205 --> 00:28:25,925
Speaker 5:  natural language input so much better. Yes. That everyone else

475
00:28:25,925 --> 00:28:28,965
Speaker 5:  assumed that all the other parts were had also gotten better. Yep.

476
00:28:29,715 --> 00:28:33,335
Speaker 5:  And then they didn't like, they just didn't like

477
00:28:34,075 --> 00:28:37,975
Speaker 5:  the LLMs hallucinate. They get things wrong. They, they go haywire.

478
00:28:37,975 --> 00:28:41,535
Speaker 5:  So you have this system where the input has

479
00:28:41,535 --> 00:28:45,095
Speaker 5:  substantially changed and everyone sees a paradigm shift. That's what all

480
00:28:45,095 --> 00:28:48,255
Speaker 5:  the CEOs have told man cutter. It's a paradigm shift. 'cause the input has

481
00:28:48,255 --> 00:28:51,735
Speaker 5:  changed. And the history of computing is these big inputs that change

482
00:28:52,155 --> 00:28:55,735
Speaker 5:  or input methodologies that change. And then computers change. We eat mice

483
00:28:55,735 --> 00:28:59,575
Speaker 5:  and keyboards, scroll wheels. Everyone knows the Digital Crown was a

484
00:28:59,735 --> 00:29:03,295
Speaker 5:  revolutionary computer on the Apple Watch. That's why they announced the

485
00:29:03,295 --> 00:29:05,735
Speaker 5:  Digital Crown the way they did with the Apple watch. Yeah. Apple knows that

486
00:29:05,855 --> 00:29:08,935
Speaker 5:  changing the input changes the nature of your relationship to computers.

487
00:29:09,195 --> 00:29:12,175
Speaker 5:  So they fake it even when they don't have it, they, they make sure to mention

488
00:29:12,175 --> 00:29:16,015
Speaker 5:  it. Yep. Multi-touch. Obviously everyone thinks

489
00:29:16,015 --> 00:29:19,975
Speaker 5:  it's voice now. 'cause LMS can do voice at this level, but underneath that

490
00:29:20,035 --> 00:29:23,855
Speaker 5:  is nothing. Right. And so they haven't built this layer where you can

491
00:29:24,015 --> 00:29:26,535
Speaker 5:  actually, where where it's good at going to order the Uber, they have to

492
00:29:26,535 --> 00:29:29,695
Speaker 5:  do a bunch of business deals basically. Or they have to build an agent

493
00:29:30,595 --> 00:29:33,575
Speaker 5:  or in the case of Rabbit fake having an agent until they actually build an

494
00:29:33,575 --> 00:29:37,495
Speaker 5:  agent. Yeah. And click around on a website. And I don't think, I, I wonder

495
00:29:37,555 --> 00:29:41,055
Speaker 5:  if the problem for Apple is as much the building, the

496
00:29:41,565 --> 00:29:44,805
Speaker 5:  orchestrator or the API hooks or whatever as it is getting

497
00:29:45,425 --> 00:29:48,725
Speaker 5:  all of the app developers to participate in a way that makes everybody money.

498
00:29:49,325 --> 00:29:52,045
Speaker 6:  I think Apple's theory was that

499
00:29:52,805 --> 00:29:56,555
Speaker 6:  developers would solve this for them. Right. That by virtue

500
00:29:56,615 --> 00:29:59,115
Speaker 6:  of Apple being Apple. And we talked about this when, when

501
00:30:00,485 --> 00:30:03,755
Speaker 6:  Fancy Siri first came out, when Apple Intelligence was first launched at

502
00:30:04,185 --> 00:30:07,675
Speaker 6:  wwdc was like, if if there's any company on earth

503
00:30:08,185 --> 00:30:12,075
Speaker 6:  that can marshal enough of its developers to play this particular

504
00:30:12,145 --> 00:30:15,835
Speaker 6:  game, it's Apple. Right? And so I actually, I actually think it is, it is

505
00:30:16,055 --> 00:30:19,795
Speaker 6:  yet again, more damning the fact that Apple has not been able to pull this

506
00:30:19,795 --> 00:30:23,755
Speaker 6:  off because Apple is able to point at its developers and

507
00:30:23,755 --> 00:30:27,275
Speaker 6:  say, Hey, we put this weird thing on the home screen, you have to support

508
00:30:27,275 --> 00:30:30,515
Speaker 6:  it. And they do. That is what Apple has done forever. And it keeps working

509
00:30:30,585 --> 00:30:34,235
Speaker 6:  like the dynamic Island exists because Apple is like, look, here's a,

510
00:30:34,235 --> 00:30:38,195
Speaker 6:  here's a round thing. You figure out what to do with it and people do.

511
00:30:38,575 --> 00:30:42,195
Speaker 6:  And so Apple's big idea was I think was that

512
00:30:42,465 --> 00:30:45,955
Speaker 6:  this would solve itself because they would give people app intense and

513
00:30:46,335 --> 00:30:50,195
Speaker 6:  and they would plug in and everything would be fine. That again,

514
00:30:50,615 --> 00:30:53,795
Speaker 6:  misses that orchestration middle that you're talking about. That is actually

515
00:30:53,795 --> 00:30:57,635
Speaker 6:  very complicated. But I think also, this is

516
00:30:57,635 --> 00:31:01,515
Speaker 6:  just anecdotal having talked to developers, but I've talked to a lot of developers

517
00:31:01,575 --> 00:31:04,555
Speaker 6:  who don't understand and are not excited about the idea of

518
00:31:05,385 --> 00:31:07,595
Speaker 6:  Siri just abstracting their app away. Yeah.

519
00:31:07,875 --> 00:31:10,235
Speaker 5:  I mean I keep calling this the DoorDash problem. And you can actually understand

520
00:31:10,235 --> 00:31:14,155
Speaker 5:  by thinking about why these companies support the dynamic island and why

521
00:31:14,155 --> 00:31:17,635
Speaker 5:  they're not excited to support a sir that makes their app

522
00:31:17,635 --> 00:31:21,395
Speaker 5:  disappear. So let, let's say you're the CEO of, of Uber, David, Mr.

523
00:31:21,835 --> 00:31:23,755
Speaker 5:  Steve Uber please.

524
00:31:23,815 --> 00:31:24,395
Speaker 6:  He, my father.

525
00:31:26,865 --> 00:31:29,395
Speaker 5:  It's obvious why you would support the dynamic island. 'cause somebody uses

526
00:31:29,395 --> 00:31:33,275
Speaker 5:  your app and then they close it and then the operating system

527
00:31:33,375 --> 00:31:34,515
Speaker 5:  is like, remember that app?

528
00:31:34,685 --> 00:31:35,035
Speaker 6:  Right?

529
00:31:35,415 --> 00:31:35,955
Speaker 5:  And it's, it's

530
00:31:35,955 --> 00:31:36,715
Speaker 6:  The logo sits there.

531
00:31:37,015 --> 00:31:40,595
Speaker 5:  The logo sits there. Yeah. And there's a constant status

532
00:31:41,335 --> 00:31:44,795
Speaker 5:  con communicated about your app. And then the only thing that a user can

533
00:31:44,795 --> 00:31:48,195
Speaker 5:  do with that is open your app again. So there's a perfect

534
00:31:48,875 --> 00:31:52,475
Speaker 5:  feedback loop, a perfect incentive match between Yep. I want to communicate

535
00:31:52,755 --> 00:31:56,675
Speaker 5:  constant status and when the user wants to do anything, they can just bop

536
00:31:56,675 --> 00:31:59,715
Speaker 5:  back into my app and I can show them another ad or upsell them on Uber Eats

537
00:31:59,715 --> 00:32:03,235
Speaker 5:  or whatever it is I wanna do. Great. I I wish

538
00:32:03,775 --> 00:32:07,115
Speaker 5:  any CEOs of any airline companies would like understand this message. Yep.

539
00:32:07,655 --> 00:32:11,435
Speaker 5:  But like it's a perfect incentive match between the needs of the

540
00:32:11,435 --> 00:32:13,475
Speaker 5:  operating system, the needs of the user, and the needs of the app develop.

541
00:32:14,535 --> 00:32:18,235
Speaker 5:  You say to Siri, I need a car ride to the airport and

542
00:32:18,465 --> 00:32:22,395
Speaker 5:  Siri just decides to like, fire off the Uber request. Well, you

543
00:32:22,395 --> 00:32:26,115
Speaker 5:  haven't touched the app at all. Right? Right. Like the app intent has abstracted

544
00:32:26,115 --> 00:32:29,635
Speaker 5:  your app away. And so you run Uber, you run DoorDash, suddenly you don't

545
00:32:29,635 --> 00:32:33,075
Speaker 5:  get an ole opportunity. You don't get the chance to

546
00:32:33,385 --> 00:32:36,995
Speaker 5:  show an ad or say put something else in your cart or even remind people that

547
00:32:36,995 --> 00:32:40,625
Speaker 5:  you exist. And then your rates start to fall. Like the amount of revenue

548
00:32:40,625 --> 00:32:43,505
Speaker 5:  you're making falls because now you're just, the only thing you're competing

549
00:32:43,505 --> 00:32:47,305
Speaker 5:  on is telling Siri how cheap your service is. And that's great for the user

550
00:32:47,305 --> 00:32:51,065
Speaker 5:  perfect incentive match for the user. My robot Butler has picked the

551
00:32:51,065 --> 00:32:54,225
Speaker 5:  cheapest car to the airport for me. Right. But none of the app developers

552
00:32:54,225 --> 00:32:57,265
Speaker 5:  wanna be in that game. And I, I think this is, this is true of the Apple

553
00:32:57,265 --> 00:33:00,385
Speaker 5:  model, but it's true of the Amazon model. I asked Panis about it, you didn't

554
00:33:00,385 --> 00:33:03,225
Speaker 5:  have a great answer for it. I asked the CO of rabbit about it and he was

555
00:33:03,225 --> 00:33:06,745
Speaker 5:  like, well no one's paying attention to us. Which is actually a great answer,

556
00:33:06,745 --> 00:33:09,825
Speaker 5:  right? Sure. In its way a great answer. Like he's like, we're not big enough

557
00:33:09,825 --> 00:33:11,985
Speaker 5:  to be a threat, we're just gonna build the thing until no one can say no

558
00:33:11,985 --> 00:33:15,775
Speaker 5:  to us in its way a great answer. But everybody has the

559
00:33:15,775 --> 00:33:19,575
Speaker 5:  DoorDash problem, which is why would DoorDash play this game that eventually

560
00:33:19,575 --> 00:33:22,415
Speaker 5:  results in their destruction? I don't think Apple has a great answer for

561
00:33:22,415 --> 00:33:26,395
Speaker 5:  developers right now at all. For anything. Yeah. Right. Their answer is put

562
00:33:26,395 --> 00:33:30,355
Speaker 5:  in-app purchases in your app so we can take 30%. Yeah. And like that's,

563
00:33:30,355 --> 00:33:31,595
Speaker 5:  no one's happy about that. Right?

564
00:33:31,705 --> 00:33:35,595
Speaker 6:  Yeah. Apple has become a very extractive

565
00:33:35,595 --> 00:33:38,995
Speaker 6:  company and I actually think all of that is, is stacked together. Right?

566
00:33:38,995 --> 00:33:42,595
Speaker 6:  Like I think Apple has burned a lot of its goodwill with the way that it

567
00:33:42,595 --> 00:33:46,555
Speaker 6:  has thought about things like in-app payments that has cost

568
00:33:46,575 --> 00:33:50,275
Speaker 6:  it trust with developers who are now wondering about things like app

569
00:33:50,275 --> 00:33:54,195
Speaker 6:  intents where they're like, okay, I I I

570
00:33:54,355 --> 00:33:56,995
Speaker 6:  just talk to developers all the time who are less and less convinced every

571
00:33:56,995 --> 00:34:00,925
Speaker 6:  day that Apple is actually caring about what is good

572
00:34:00,925 --> 00:34:04,405
Speaker 6:  for them as a developer. And there is a sense that Apple is now in this

573
00:34:04,705 --> 00:34:08,365
Speaker 6:  to get what it feels it deserves from the success of its devices.

574
00:34:08,785 --> 00:34:12,445
Speaker 6:  And that is 30% of every single thing that happens. And so you,

575
00:34:12,625 --> 00:34:15,885
Speaker 6:  you burn all that goodwill and then you say abstract your app away, don't

576
00:34:15,885 --> 00:34:19,165
Speaker 6:  worry. We'll take care of it for you. And that just that sales pitch becomes

577
00:34:19,165 --> 00:34:21,165
Speaker 6:  really hard to make to developers.

578
00:34:21,375 --> 00:34:24,125
Speaker 5:  Right. And it doesn't track at all with the idea that this is a paradigm

579
00:34:24,125 --> 00:34:27,445
Speaker 5:  shift where we'll reset the balance of power and everyone will make more

580
00:34:27,445 --> 00:34:31,005
Speaker 5:  money and there'll be new winners and losers and now it's, I think, I think

581
00:34:31,125 --> 00:34:32,405
Speaker 5:  it's just a tough sell all the way around.

582
00:34:32,625 --> 00:34:35,445
Speaker 6:  It also doesn't work. Like I feel like I have to, I, I feel like I'm taking

583
00:34:35,445 --> 00:34:39,325
Speaker 6:  crazy pills. Not saying this more often. It doesn't work. This technology

584
00:34:39,425 --> 00:34:43,285
Speaker 6:  is bad. There are like things that are cool and interesting about it,

585
00:34:43,285 --> 00:34:46,565
Speaker 6:  but the fact that the most sophisticated thing anyone has developed is this

586
00:34:46,565 --> 00:34:50,125
Speaker 6:  thing will go click around a Chrome browser for you is not

587
00:34:50,195 --> 00:34:54,165
Speaker 6:  success. This thing is these things are bad. And I

588
00:34:54,165 --> 00:34:57,805
Speaker 6:  think I am absolutely fascinated to see what the new Alexa

589
00:34:57,945 --> 00:35:01,685
Speaker 6:  is going to be because to its credit, I think Amazon has actually done a

590
00:35:01,685 --> 00:35:04,965
Speaker 6:  lot of the work that we're talking about. They've made the deals, they have

591
00:35:05,025 --> 00:35:08,845
Speaker 6:  worked very hard it seems on this orchestration layer of figuring out what

592
00:35:08,845 --> 00:35:12,125
Speaker 6:  goes where they're integrating different models, they're integrating with

593
00:35:12,125 --> 00:35:15,245
Speaker 6:  different partners. Like they ha they have pulled all the right pieces

594
00:35:16,075 --> 00:35:19,245
Speaker 6:  into one place in a way that I think is, is potentially very exciting.

595
00:35:21,135 --> 00:35:24,155
Speaker 6:  It might still be bad. Yeah. Like it really might still be bad because this

596
00:35:24,155 --> 00:35:28,115
Speaker 6:  is a really hard problem and no one yet is close to making

597
00:35:28,115 --> 00:35:31,555
Speaker 6:  this work. Like forget all the business incentives. It just doesn't work.

598
00:35:31,985 --> 00:35:35,395
Speaker 5:  Yeah. I mean Amazon might have the right pieces, but they might all be misshapen

599
00:35:35,405 --> 00:35:38,765
Speaker 5:  might not fit together and then the picture is bad. Like that's

600
00:35:39,235 --> 00:35:41,925
Speaker 5:  sort of what that puzzle might be like. We don't know. We have to use it.

601
00:35:42,465 --> 00:35:46,205
Speaker 5:  But you know, I asked Pantos in the same conversation, do you think the orchestration

602
00:35:46,205 --> 00:35:49,845
Speaker 5:  layer is something that everyone will land on the same solution? Or is this

603
00:35:49,845 --> 00:35:53,125
Speaker 5:  like a moat? Like is this an advantage that you have? And he was very confident.

604
00:35:53,515 --> 00:35:56,605
Speaker 5:  This is an advantage. Like we have spent our time

605
00:35:57,805 --> 00:36:01,325
Speaker 5:  figuring this thing out because it's what we need to make everything else

606
00:36:01,325 --> 00:36:04,085
Speaker 5:  work. And you can just see that everyone else to figure like Google could

607
00:36:04,085 --> 00:36:07,885
Speaker 5:  pull on stuff like the, who did I have a meeting with at this cafe a week

608
00:36:07,905 --> 00:36:11,405
Speaker 5:  ago? That's, that's information that's in my Google calendar. Yeah. Right.

609
00:36:11,705 --> 00:36:15,675
Speaker 5:  Like Gemini should, by all rights, be able to just do that on

610
00:36:15,675 --> 00:36:19,595
Speaker 5:  a pixel phone. And Google hasn't flipped that switch yet. They're very close

611
00:36:19,695 --> 00:36:23,635
Speaker 5:  to flipping that switch. Yeah. Very, very close. You can, you can see

612
00:36:23,635 --> 00:36:26,195
Speaker 5:  that they're coming right up on it because they do have all of your data.

613
00:36:26,545 --> 00:36:30,515
Speaker 5:  They are less worried about you talking to the cloud than Apple

614
00:36:30,575 --> 00:36:31,835
Speaker 5:  in like very specific ways.

615
00:36:33,385 --> 00:36:36,355
Speaker 5:  They're, they're Google. They're like, ask us a question. Here's an answer.

616
00:36:36,355 --> 00:36:39,115
Speaker 5:  Maybe the robot made it up or maybe this is actually a person you met with

617
00:36:39,115 --> 00:36:41,675
Speaker 5:  at the cafe a week ago. Who knows. But we're gonna all gonna have a good

618
00:36:41,675 --> 00:36:45,115
Speaker 5:  time. They haven't flipped the switch yet 'cause I don't think they think

619
00:36:45,115 --> 00:36:48,275
Speaker 5:  it's good enough yet. And I, I'm just looking at this and I'm saying everyone

620
00:36:48,275 --> 00:36:52,255
Speaker 5:  is confused by this input method. Everyone is confused by the fact that

621
00:36:52,255 --> 00:36:55,295
Speaker 5:  you can talk to the computer and the computer can do a reasonably good job

622
00:36:55,295 --> 00:36:59,155
Speaker 5:  of talking back to you. And now we all think the paradigm shift is here.

623
00:36:59,155 --> 00:37:03,075
Speaker 5:  Yep. And it's like, oh wait, the computer lies a lot. So like Sam

624
00:37:03,275 --> 00:37:06,955
Speaker 5:  Altman was saying, Che has gotten better at creative writing this week and

625
00:37:06,955 --> 00:37:09,635
Speaker 5:  maybe it has, like I I read some of the, the demos and it's like, yeah, it's

626
00:37:09,635 --> 00:37:13,395
Speaker 5:  a little less stilted than me for, it's still not good at like running

627
00:37:13,495 --> 00:37:17,475
Speaker 5:  my life. Right? Like I think Addie Robertson on our

628
00:37:17,475 --> 00:37:20,755
Speaker 5:  team said, it writes like a 2010s blogger, which hits me to my core

629
00:37:21,735 --> 00:37:23,235
Speaker 5:  is because that that is what I am

630
00:37:23,415 --> 00:37:26,035
Speaker 6:  To be fair, that's probably what it's trained on. Yeah.

631
00:37:26,035 --> 00:37:29,555
Speaker 5:  That's the most, I mean, I've written millions of words in the 2010s.

632
00:37:30,325 --> 00:37:32,235
Speaker 5:  There you go. Good. Thank you. You're welcome everybody.

633
00:37:33,985 --> 00:37:37,725
Speaker 5:  But like that's improving the part where it's age agentic is not

634
00:37:37,725 --> 00:37:41,605
Speaker 5:  improving. Right. I saw my, at the, at the Amazon event, I saw

635
00:37:41,605 --> 00:37:44,885
Speaker 5:  Mike Krieger from philanthropic, formerly Instagram, former me of Artifact.

636
00:37:45,255 --> 00:37:49,125
Speaker 5:  We've talked a bunch and he was laughing. He's like, it's very

637
00:37:49,125 --> 00:37:52,325
Speaker 5:  funny that every time someone says agentic to you, you just say, you mean

638
00:37:52,485 --> 00:37:56,245
Speaker 5:  clicking around on a website? Because that's, they all know that's what

639
00:37:56,245 --> 00:37:56,845
Speaker 5:  they're doing. Yeah.

640
00:37:56,845 --> 00:37:57,445
Speaker 6:  That's what it is.

641
00:37:59,355 --> 00:38:02,365
Speaker 5:  It's very good. Are there any products you, I mean, I know you talked a bunch

642
00:38:02,365 --> 00:38:05,885
Speaker 5:  of hardware makers. Are there any any products that are close outside of

643
00:38:06,025 --> 00:38:07,805
Speaker 5:  Amazon sounding like they're close?

644
00:38:08,225 --> 00:38:11,805
Speaker 6:  No. Like, and, and I think this is the thing that I have come to find so

645
00:38:12,115 --> 00:38:16,045
Speaker 6:  sort of alarming is like, there's, there's one set of AI

646
00:38:16,685 --> 00:38:20,405
Speaker 6:  features that I I I would think of as like features. You'd never notice

647
00:38:20,435 --> 00:38:24,325
Speaker 6:  that just make things better in your devices. Like we saw a

648
00:38:24,365 --> 00:38:28,325
Speaker 6:  ton of this at CES, right? That it was like, what if we used generative AI

649
00:38:28,465 --> 00:38:28,685
Speaker 6:  to

650
00:38:30,945 --> 00:38:34,765
Speaker 6:  better map your living room so that your Roomba can get around a little faster.

651
00:38:34,995 --> 00:38:38,885
Speaker 6:  Like that's a terrific and real use of ai. They can use it to like

652
00:38:39,355 --> 00:38:43,165
Speaker 6:  your, your lights can do a better job of matching the mood of the

653
00:38:43,165 --> 00:38:46,205
Speaker 6:  music that you're listening to. That's like a real thing AI can do. And that's

654
00:38:46,205 --> 00:38:49,885
Speaker 6:  a good use of it. That's not AI as a product. That's like

655
00:38:50,105 --> 00:38:53,925
Speaker 6:  AI as an underlying technology enabling a feature feature.

656
00:38:54,535 --> 00:38:58,325
Speaker 6:  Everything I see that is like AI as a top line reason

657
00:38:58,425 --> 00:39:02,365
Speaker 6:  for this thing to exist is a problem. And, and I, this is like, that

658
00:39:02,365 --> 00:39:04,285
Speaker 6:  was the thing that made me write this piece is like, we're at this point

659
00:39:04,285 --> 00:39:08,205
Speaker 6:  now where everyone has decided that AI is finished and they're building

660
00:39:08,235 --> 00:39:12,205
Speaker 6:  gadgets. That would be great if AI was finished and AI is not

661
00:39:12,405 --> 00:39:16,245
Speaker 6:  finished and AI mostly sucks and thus so do these gadgets. And,

662
00:39:16,265 --> 00:39:19,805
Speaker 6:  and so I mean you you look at like the, it's the smart home stuff. I think

663
00:39:19,805 --> 00:39:22,525
Speaker 6:  that is probably the easiest, right? We were like, we've talked on the show

664
00:39:22,525 --> 00:39:25,565
Speaker 6:  a million times. Ambient computing is the thing, right? This is all anybody

665
00:39:25,565 --> 00:39:29,285
Speaker 6:  talks about like the, and that is purely AI

666
00:39:29,285 --> 00:39:32,245
Speaker 6:  enabled, right? Like that's how we get there. Tons of data, tons of context

667
00:39:32,795 --> 00:39:36,085
Speaker 6:  sensors abound. And it just like understands who I am and where I am and

668
00:39:36,085 --> 00:39:39,645
Speaker 6:  what I'm doing and I can just have a computer and an assistant that's around

669
00:39:39,645 --> 00:39:42,085
Speaker 6:  me all the time. That is pure ai.

670
00:39:44,225 --> 00:39:48,085
Speaker 6:  Do any of those things exist or work? And so what you've had instead is

671
00:39:48,305 --> 00:39:52,205
Speaker 6:  Amazon basically hasn't launched like a meaningfully new

672
00:39:52,795 --> 00:39:56,525
Speaker 6:  Echo product in at least a year and a half, maybe

673
00:39:56,525 --> 00:40:00,245
Speaker 6:  longer because this company has been so captured by this idea that

674
00:40:00,305 --> 00:40:04,245
Speaker 6:  we have to do AI in order to make any gadgets any good

675
00:40:04,245 --> 00:40:07,605
Speaker 6:  because AI is the only reason gadgets should exist. And Apple just keeps

676
00:40:07,765 --> 00:40:10,685
Speaker 6:  shipping shit that they're like, eh, it does Apple intelligence. Like we

677
00:40:10,685 --> 00:40:13,685
Speaker 6:  get like briefings to explain new Apple devices every time there's a new

678
00:40:13,685 --> 00:40:17,085
Speaker 6:  Apple device. And I'm sure you've gotten them too, but like over and over

679
00:40:17,155 --> 00:40:20,165
Speaker 6:  it's just the same Apple intelligence demos on different screens. Like

680
00:40:21,145 --> 00:40:25,035
Speaker 6:  this is a problem. It all of these things exist in service

681
00:40:25,055 --> 00:40:28,995
Speaker 6:  of AI that doesn't exist. So what is the point of any of these gadgets right

682
00:40:28,995 --> 00:40:31,275
Speaker 6:  now? And it's just starting to drive me insane. Yeah,

683
00:40:31,665 --> 00:40:35,595
Speaker 5:  It's funny 'cause AI driving the gadgets again, I would, I

684
00:40:35,595 --> 00:40:39,475
Speaker 5:  would put that in the category of we made Multitouch and now we

685
00:40:39,475 --> 00:40:42,115
Speaker 5:  think smartphones should all look this way. So the whole industry has built

686
00:40:42,115 --> 00:40:42,955
Speaker 5:  Blackberry storms,

687
00:40:44,725 --> 00:40:47,395
Speaker 5:  right? Like that's kind of what this feels like. Like we're new Windows Mobile

688
00:40:47,455 --> 00:40:51,075
Speaker 5:  6.5, so it it's a resistant touchscreen and that honeycomb

689
00:40:51,225 --> 00:40:55,075
Speaker 5:  grid, but it's still Windows mobile. Yeah. It's not even Windows phone. You

690
00:40:55,075 --> 00:40:58,805
Speaker 5:  know, it's like this was by the way in the annals of like

691
00:40:59,045 --> 00:41:02,805
Speaker 5:  VERGE and Eng Gadget history, some nuclear stuff where we were like,

692
00:41:02,805 --> 00:41:06,565
Speaker 5:  this is still Windows mobile. They just added resistive touchscreen support.

693
00:41:06,805 --> 00:41:06,885
Speaker 5:  Like

694
00:41:08,625 --> 00:41:11,525
Speaker 5:  that's where we're at, right? Yeah. Like we made this new interface where

695
00:41:11,525 --> 00:41:15,245
Speaker 5:  someone OpenAI showed off a new interface and everyone was like, we can build,

696
00:41:15,345 --> 00:41:19,245
Speaker 5:  we, what the consumers want is poking these screens. And no one

697
00:41:19,245 --> 00:41:22,205
Speaker 5:  thought about the software underneath it except for Apple. And then a little

698
00:41:22,365 --> 00:41:26,045
Speaker 5:  bit later Google and then you had iOS standard and we don't have those

699
00:41:26,045 --> 00:41:29,565
Speaker 5:  products yet, right? We have chatt, which people love, and then we have a

700
00:41:29,565 --> 00:41:32,965
Speaker 5:  bunch of coding products and I, we, we've gotten some notes from people who

701
00:41:33,045 --> 00:41:35,885
Speaker 5:  are like, you're not paying attention to what's happening on the software

702
00:41:35,885 --> 00:41:38,645
Speaker 5:  development side. The these are very useful tools in software development.

703
00:41:38,645 --> 00:41:42,565
Speaker 5:  Great. But the consumer paradigm shift

704
00:41:42,955 --> 00:41:45,725
Speaker 5:  that all of these companies are betting on does not exist yet.

705
00:41:46,135 --> 00:41:49,165
Speaker 6:  Right? I, yeah, I, the, the thing I keep saying to people when I talk to

706
00:41:49,165 --> 00:41:52,405
Speaker 6:  is like, I think the, the B2B

707
00:41:52,405 --> 00:41:55,885
Speaker 6:  implications of AI are huge and real and,

708
00:41:56,305 --> 00:42:00,125
Speaker 6:  and present, right? Like there are so many ways in which

709
00:42:01,165 --> 00:42:04,805
Speaker 6:  companies are using AI to do interesting stuff. Some of it I find hugely

710
00:42:04,805 --> 00:42:08,445
Speaker 6:  problematic, but some of it is really interesting. None of that is

711
00:42:09,605 --> 00:42:13,405
Speaker 6:  regular people things. And I'm like, I am here asking

712
00:42:13,425 --> 00:42:17,005
Speaker 6:  you about regular people things and those are just

713
00:42:17,625 --> 00:42:20,965
Speaker 6:  the lies that people tell to make themselves sound more interesting than

714
00:42:20,965 --> 00:42:22,485
Speaker 6:  they are. Yeah. That's what this is right now.

715
00:42:22,795 --> 00:42:25,685
Speaker 5:  I'll say as we've been talking, another part of the story that we were gonna

716
00:42:25,685 --> 00:42:27,405
Speaker 5:  talk about his flip flopped.

717
00:42:27,625 --> 00:42:28,045
Speaker 6:  Oh Lord.

718
00:42:28,585 --> 00:42:32,485
Speaker 5:  So Apple announced this delay of Siri or AI powered Siri

719
00:42:32,795 --> 00:42:36,645
Speaker 5:  that led to some rumors that their smart home display, which

720
00:42:36,995 --> 00:42:40,965
Speaker 5:  felt like an iPad on a stick, would also be delayed. Because

721
00:42:41,235 --> 00:42:45,045
Speaker 5:  what enables that product is being able to just talk to it, right? And

722
00:42:45,045 --> 00:42:48,605
Speaker 5:  now there's rumors that it could still ship this year,

723
00:42:49,035 --> 00:42:52,925
Speaker 5:  okay? But instead of having the new Siri, it will have this rumored big design

724
00:42:52,965 --> 00:42:56,765
Speaker 5:  overhaul for iOS and macOS that people have been talking about.

725
00:42:57,845 --> 00:43:01,725
Speaker 6:  Interesting. So instead of the thing that would make it useful,

726
00:43:01,725 --> 00:43:05,005
Speaker 6:  they're gonna ship it with the thing that makes it pretty and call it an

727
00:43:05,005 --> 00:43:05,365
Speaker 6:  upgrade.

728
00:43:07,555 --> 00:43:08,815
Speaker 5:  You know, I don't wanna, this

729
00:43:08,815 --> 00:43:12,695
Speaker 6:  Is what we do here. I will say everything that I have heard about the

730
00:43:12,755 --> 00:43:15,775
Speaker 6:  new iOS designs, I'm actually very excited about. Like there are all these,

731
00:43:15,835 --> 00:43:19,495
Speaker 6:  all the reporting from Mark Erman and others is that it's gonna be more vision

732
00:43:19,805 --> 00:43:22,895
Speaker 6:  ProE, which means much more sort of colorful and glassy and

733
00:43:23,565 --> 00:43:27,535
Speaker 6:  spatial and kind of three dimensional. And I'm into that iOS,

734
00:43:27,635 --> 00:43:31,335
Speaker 6:  the iOS seven aesthetic is long in the tooth and deserves to

735
00:43:31,475 --> 00:43:35,175
Speaker 6:  die. So fine. That is not the same thing as

736
00:43:35,645 --> 00:43:35,935
Speaker 6:  Siri,

737
00:43:37,265 --> 00:43:40,575
Speaker 5:  Right? The paradigm shift is not translucency, it's not making

738
00:43:41,215 --> 00:43:45,135
Speaker 5:  swinging windows. Windows arrow glass is very much the aesthetic of

739
00:43:45,135 --> 00:43:45,415
Speaker 5:  the mission

740
00:43:45,415 --> 00:43:46,375
Speaker 6:  Product. Yep.

741
00:43:47,365 --> 00:43:50,305
Speaker 5:  But look, the kids today don't even know what I'm talking about. All right.

742
00:43:50,805 --> 00:43:53,505
Speaker 5:  You didn't have to live through Windows Vista and it's fine. You're gonna

743
00:43:53,505 --> 00:43:54,065
Speaker 5:  think it's beautiful.

744
00:43:54,445 --> 00:43:58,265
Speaker 6:  My hottest take is Aass w was not all wrong. Yeah.

745
00:43:58,615 --> 00:44:02,025
Speaker 5:  Aass vindicated will be our headline. Three people will understand it,

746
00:44:03,045 --> 00:44:05,985
Speaker 5:  Tom Warren, it will explode. And then we'll just move on with our lives.

747
00:44:06,545 --> 00:44:08,865
Speaker 5:  Alright, we gotta take a break. We've, we've talked about this to death.

748
00:44:09,325 --> 00:44:13,025
Speaker 5:  If you have a, a solid use case

749
00:44:13,565 --> 00:44:17,185
Speaker 5:  for how AI has changed a consumer gadget, you let us know. I, I'll offer

750
00:44:17,185 --> 00:44:20,705
Speaker 5:  you just one. I think my daughter is very into space recently

751
00:44:21,125 --> 00:44:24,385
Speaker 5:  and we just sit there with my iPhone talking to chat GP about space almost

752
00:44:24,385 --> 00:44:28,155
Speaker 5:  every night. It's fun. But that is not the gadget, right?

753
00:44:28,255 --> 00:44:30,275
Speaker 5:  That's just a, it's just an app on a phone,

754
00:44:30,645 --> 00:44:34,565
Speaker 6:  Right? Yeah. That's that's the thing, right? Like what,

755
00:44:34,755 --> 00:44:38,405
Speaker 6:  what in here goes beyond app on a phone or

756
00:44:38,555 --> 00:44:42,045
Speaker 6:  chatbot in my browser? Beat that and I will have a really fun

757
00:44:42,045 --> 00:44:44,245
Speaker 6:  conversation with you about AI gadgets

758
00:44:44,635 --> 00:44:47,005
Speaker 5:  Also. None of this companies make any money. All right, we gotta take a break.

759
00:44:47,395 --> 00:44:50,725
Speaker 5:  Hopefully by the time we come back, all the AI companies will figure out

760
00:44:50,725 --> 00:44:53,885
Speaker 5:  a revenue model. But in the meantime, you're gonna listen to these ads. We'll

761
00:44:53,885 --> 00:44:54,165
Speaker 5:  be right back.

762
00:48:29,775 --> 00:48:32,585
Speaker 5:  What is going on with this company. You wrote a story, the headline is just,

763
00:48:32,585 --> 00:48:36,545
Speaker 5:  Is Tesla cooked? It's a good headline. And just based on

764
00:48:36,545 --> 00:48:39,865
Speaker 5:  the reader reaction to it, it seems like a lot of people would like the answer

765
00:48:39,865 --> 00:48:43,705
Speaker 5:  to be yes. And a significant number of people believe the answer

766
00:48:43,725 --> 00:48:47,665
Speaker 5:  is yes. Yes. What's happening here? Well, I think sort of the,

767
00:48:47,765 --> 00:48:51,545
Speaker 5:  the, the top line issue that, that, that

768
00:48:51,545 --> 00:48:55,265
Speaker 5:  we're dealing with here is that the, the, the company had a

769
00:48:55,335 --> 00:48:59,265
Speaker 5:  huge spike in its share price. Immediately after the election. It went

770
00:48:59,265 --> 00:49:03,225
Speaker 5:  up like something, like a ridiculous amount to a point where I think in

771
00:49:03,425 --> 00:49:07,145
Speaker 5:  December, individual stock shares were selling for like over

772
00:49:07,375 --> 00:49:11,105
Speaker 5:  four 50 bucks in incredible, right? The, the

773
00:49:11,385 --> 00:49:15,265
Speaker 5:  investors were clearly rewarding Elon Musk for making what they saw was

774
00:49:15,265 --> 00:49:19,025
Speaker 5:  the, the, the right bet in the election. Trump was, Trump won.

775
00:49:19,125 --> 00:49:22,705
Speaker 5:  And so therefore Tesla needed to be, and Elon Musk

776
00:49:23,105 --> 00:49:26,985
Speaker 5:  specifically needed to be rewarded. But then we started to see

777
00:49:28,025 --> 00:49:31,785
Speaker 5:  a couple of things. First, the, the company reported its end of the year

778
00:49:32,065 --> 00:49:35,945
Speaker 5:  earnings. And it was kind of shocking and pretty sobering

779
00:49:36,505 --> 00:49:39,345
Speaker 5:  that their sales were down. Not a lot, but

780
00:49:40,295 --> 00:49:44,225
Speaker 5:  essentially they were flat. And for a company that is

781
00:49:44,385 --> 00:49:47,905
Speaker 5:  supposed to be on this exponential growth projection,

782
00:49:48,305 --> 00:49:52,185
Speaker 5:  I think that that was pretty surprising to a lot of people. And then the

783
00:49:52,215 --> 00:49:56,145
Speaker 5:  Elon of it all as Neli, you like to say, sort of came crashing

784
00:49:56,145 --> 00:49:59,945
Speaker 5:  down and he was put in charge of this Doge project and

785
00:50:00,295 --> 00:50:02,745
Speaker 5:  just basically started vandalizing the federal government

786
00:50:04,225 --> 00:50:08,145
Speaker 5:  shutting agencies down, firing people, you know, barging into

787
00:50:08,625 --> 00:50:11,945
Speaker 5:  places where he wasn't allowed to go and, and sort of

788
00:50:12,195 --> 00:50:14,945
Speaker 5:  trampoline the constitution in, in the process.

789
00:50:16,365 --> 00:50:20,345
Speaker 5:  And that sort of gave rise to obviously a groundswell of

790
00:50:20,355 --> 00:50:24,345
Speaker 5:  anger and opposition. I think a lot of people, especially people who

791
00:50:24,465 --> 00:50:27,685
Speaker 5:  consider themselves progressives and, and democrats and liberals were sort

792
00:50:27,685 --> 00:50:31,485
Speaker 5:  of, kind of despondent and depressed after the

793
00:50:31,605 --> 00:50:35,205
Speaker 5:  election really kind of found this, the a way to focal fo

794
00:50:35,385 --> 00:50:36,725
Speaker 5:  fo focus their anger

795
00:50:38,745 --> 00:50:42,405
Speaker 5:  in January. And then in February we saw this protest

796
00:50:42,845 --> 00:50:46,765
Speaker 5:  movement take root and people were demonstrating outside of Tesla showrooms.

797
00:50:46,905 --> 00:50:50,125
Speaker 5:  And then sort of separately to that, you know, all those protests were pretty

798
00:50:50,365 --> 00:50:53,285
Speaker 5:  peaceful. But separate to that, there's been lots of reports of vandalism

799
00:50:53,675 --> 00:50:57,525
Speaker 5:  cars being vandalized, superchargers being set

800
00:50:57,525 --> 00:51:01,485
Speaker 5:  on fire. Someone took a, a few shots at a, a Tesla showroom

801
00:51:01,545 --> 00:51:05,365
Speaker 5:  in, in Oregon. I took a few shots. You mean fired a gun at

802
00:51:05,665 --> 00:51:09,645
Speaker 5:  Yes. Bullets were fired at the showroom in Oregon. They didn't like go on

803
00:51:09,645 --> 00:51:12,765
Speaker 5:  Instagram live and start talking shit. They had fired a gun at the show.

804
00:51:12,765 --> 00:51:16,685
Speaker 5:  Okay. Shots fired as Musk himself said in an interview recently, he talked,

805
00:51:16,685 --> 00:51:19,765
Speaker 5:  he said that he, he with a, with a, a big grin on his face. He thought that

806
00:51:19,765 --> 00:51:23,685
Speaker 5:  that was a really good joke when he said shots fired. So then

807
00:51:23,785 --> 00:51:27,045
Speaker 5:  the, the stock started to slide. It had already been going down since January.

808
00:51:27,705 --> 00:51:31,565
Speaker 5:  It took a steep drop earlier this week. One of the, one of the

809
00:51:31,565 --> 00:51:35,405
Speaker 5:  biggest drops that we'd seen in over five years to the point that

810
00:51:35,445 --> 00:51:39,125
Speaker 5:  I think had its Nader, that that, you know, it had essentially shed 50% of

811
00:51:39,125 --> 00:51:43,085
Speaker 5:  its value. The company itself lost around

812
00:51:43,085 --> 00:51:46,965
Speaker 5:  $800 billion in valuation, which is just

813
00:51:46,965 --> 00:51:50,925
Speaker 5:  a staggering number when you consider how highly valued Tesla was at that

814
00:51:51,705 --> 00:51:55,005
Speaker 5:  point. And Musk himself lost around a hundred billion dollars off of his

815
00:51:55,005 --> 00:51:55,765
Speaker 5:  net worth. Poor guy.

816
00:51:55,765 --> 00:51:56,085
Speaker 6:  Still

817
00:51:56,085 --> 00:51:58,565
Speaker 5:  The richest man in the world. Don't worry about him, he's gonna be fine.

818
00:51:59,325 --> 00:52:03,165
Speaker 5:  But what I think we're, what we're seeing now and, and is, is now

819
00:52:03,205 --> 00:52:06,925
Speaker 5:  a concerted effort by the government and namely by, by

820
00:52:06,925 --> 00:52:10,865
Speaker 5:  Trump to prop Tesla up. He's, he's,

821
00:52:11,325 --> 00:52:14,665
Speaker 5:  you know, sort of bringing the cars to the White House and they're having

822
00:52:14,665 --> 00:52:18,505
Speaker 5:  themselves, whatever that that was, that we saw

823
00:52:18,605 --> 00:52:21,985
Speaker 5:  on the lawn outside. So some have called it, you know, sort of like an

824
00:52:21,985 --> 00:52:24,865
Speaker 5:  infomercial for Tesla, essentially on government property.

825
00:52:25,845 --> 00:52:27,145
Speaker 5:  And, and he's talking about,

826
00:52:29,045 --> 00:52:32,865
Speaker 5:  you know, going after people who vandalize or deface

827
00:52:32,965 --> 00:52:36,905
Speaker 5:  Teslas with terrorism charges now. So it's clear that, you know,

828
00:52:36,915 --> 00:52:39,785
Speaker 5:  Trump and the administration are interested in bringing sort of the full

829
00:52:39,785 --> 00:52:43,185
Speaker 5:  force of the federal government behind Tesla to protect Tesla

830
00:52:43,645 --> 00:52:47,585
Speaker 5:  and to make sure that it is not subject to the whims of, of the market.

831
00:52:47,785 --> 00:52:47,985
Speaker 5:  I guess,

832
00:52:48,485 --> 00:52:51,185
Speaker 6:  You know, what's fascinating about this to me, Andy, you and I have talked

833
00:52:51,185 --> 00:52:53,265
Speaker 6:  a few times, I think we've actually, the three of us have talked a few times

834
00:52:53,265 --> 00:52:57,145
Speaker 6:  on this show about the, one of the strange things about Tesla is trying

835
00:52:57,145 --> 00:53:00,505
Speaker 6:  to figure out what of the Tesla

836
00:53:00,875 --> 00:53:04,785
Speaker 6:  vibes are about Tesla and what is the Elon of it all. And that

837
00:53:04,785 --> 00:53:07,545
Speaker 6:  those two things have always been really hard to pull apart. Like there's

838
00:53:07,545 --> 00:53:10,065
Speaker 6:  a company that for a long time was way ahead of the game and very successful

839
00:53:10,245 --> 00:53:12,785
Speaker 6:  and has kind of lost its lead over time. And then there is the Elon of it

840
00:53:12,785 --> 00:53:16,745
Speaker 6:  all. And I think it seems very clear to me that the thing that has happened

841
00:53:16,745 --> 00:53:20,665
Speaker 6:  over the last 10 days in particular is that it is just about the Elon of

842
00:53:20,665 --> 00:53:21,745
Speaker 6:  it all now. Oh,

843
00:53:21,745 --> 00:53:25,700
Speaker 5:  Wait, no, I disagree. No, I, I disagree. Not in like a big way.

844
00:53:25,795 --> 00:53:29,605
Speaker 5:  Okay. But, but just on one element, which is that the Elon of it all

845
00:53:29,665 --> 00:53:33,405
Speaker 5:  for Tesla was what propped up the meme stock bubble

846
00:53:33,465 --> 00:53:37,405
Speaker 5:  of the stock price, right? Sure. So Elon says all the cars

847
00:53:37,405 --> 00:53:40,885
Speaker 5:  will drive themselves, I'm gonna do a robo taxi, and everyone believes him

848
00:53:40,885 --> 00:53:43,685
Speaker 5:  or they don't believe him, or they think, well, the man landed two rockets

849
00:53:43,885 --> 00:53:47,125
Speaker 5:  at the same time. Of course he's gonna pull this off and then the stock price

850
00:53:47,125 --> 00:53:50,485
Speaker 5:  goes up because people think it's gonna pay off. Right? And I think what

851
00:53:50,485 --> 00:53:54,125
Speaker 5:  has happened very recently is the bloom is so fully off the rose.

852
00:53:54,345 --> 00:53:57,685
Speaker 5:  And even If you want to believe Elon, it's

853
00:53:58,375 --> 00:54:01,045
Speaker 5:  undeniable that he's not paying attention to the company

854
00:54:01,915 --> 00:54:05,765
Speaker 5:  because he's, he's set up in the Secretary of

855
00:54:05,825 --> 00:54:09,805
Speaker 5:  War suite at the Eisenhower executive office building with a gaming PC with

856
00:54:09,805 --> 00:54:13,285
Speaker 5:  RGB lights. That's a real thing. You can go look at the picture. It is very

857
00:54:13,285 --> 00:54:15,245
Speaker 5:  funny to see that computer in that office,

858
00:54:16,985 --> 00:54:20,125
Speaker 5:  and there's no way he's paying attention to Tesla. And so even people who

859
00:54:20,125 --> 00:54:23,845
Speaker 5:  are nominally like pro Elon or impressed by Elon

860
00:54:24,465 --> 00:54:28,325
Speaker 5:  are like, dude, pay attention to your company and the cars aren't gonna

861
00:54:28,325 --> 00:54:31,165
Speaker 5:  drive themselves unless you pay attention to your company. And then you can

862
00:54:31,165 --> 00:54:34,765
Speaker 5:  see the multiple is coming down off the stock, and then you can see the sales

863
00:54:34,765 --> 00:54:37,565
Speaker 5:  are falling. And then you can see the sales are falling even more sharply

864
00:54:37,565 --> 00:54:40,565
Speaker 5:  in Europe, for example, where doing

865
00:54:41,275 --> 00:54:45,245
Speaker 5:  heel Hitler gestures is not taken with the same amount of, he's just trolling

866
00:54:45,245 --> 00:54:48,925
Speaker 5:  sort of responses in this country in this moment for whatever insane reason.

867
00:54:49,225 --> 00:54:52,885
Speaker 5:  So you've just got this, like the Elon of it all has

868
00:54:52,885 --> 00:54:56,325
Speaker 5:  always been the dreams will come true.

869
00:54:57,745 --> 00:55:00,925
Speaker 5:  And I think now those things are just, they're, they're pulling apart. So

870
00:55:00,985 --> 00:55:03,325
Speaker 5:  I'm not saying I disagree with you, David, I'm just saying like,

871
00:55:04,495 --> 00:55:07,545
Speaker 5:  there's nothing inside of Tesla that makes it more than a car company anymore.

872
00:55:07,925 --> 00:55:11,745
Speaker 5:  The best example of this I can give you is Mark Kelly,

873
00:55:11,745 --> 00:55:15,605
Speaker 5:  Senator Mark Kelly Elon called him a traitor the other day

874
00:55:15,985 --> 00:55:19,645
Speaker 5:  on Twitter. So Senator Kelly went to Ukraine, he said, we stand with Ukraine,

875
00:55:19,645 --> 00:55:23,445
Speaker 5:  this is all about democracy. Elon responds to that by saying, you are a trader.

876
00:55:23,615 --> 00:55:27,325
Speaker 5:  And then today in the capitol building, reporters

877
00:55:27,325 --> 00:55:31,175
Speaker 5:  asked Senator Kelly, are you gonna sell your Tesla? And he said, well, it's

878
00:55:31,195 --> 00:55:35,095
Speaker 5:  a great car. It's pretty cheap on the inside, though. I love the acceleration.

879
00:55:35,095 --> 00:55:38,695
Speaker 5:  I don't get to drive much. I'm, I'm looking into selling it. And

880
00:55:39,035 --> 00:55:42,455
Speaker 5:  he was just able to evaluate the car, not everything the car

881
00:55:42,815 --> 00:55:46,655
Speaker 5:  represents or everything the car might mean, or robo

882
00:55:46,825 --> 00:55:50,255
Speaker 5:  taxis. He just said the truest thing. I'm presuming this is a model three,

883
00:55:50,475 --> 00:55:54,055
Speaker 5:  the truest thing you can say about a model three, which is it accelerates

884
00:55:54,055 --> 00:55:57,635
Speaker 5:  really fast and on the inside it's a little bit cheap there

885
00:55:57,865 --> 00:56:01,515
Speaker 5:  that that stock price, you don't get 1200 times

886
00:56:01,785 --> 00:56:05,355
Speaker 5:  your valuation and stock price against. It's very fast and a little cheap.

887
00:56:05,855 --> 00:56:07,395
Speaker 5:  That's a Camaro. We

888
00:56:07,395 --> 00:56:11,235
Speaker 6:  Are barreling towards a moment where buying a Tesla is

889
00:56:11,235 --> 00:56:14,995
Speaker 6:  like buying stock in truth social. Sure. That it is. Like,

890
00:56:15,015 --> 00:56:18,995
Speaker 6:  it is, it is such a political animal now. And I think, I mean

891
00:56:19,065 --> 00:56:21,235
Speaker 6:  this was true when, when the election happened, like you're talking about

892
00:56:21,235 --> 00:56:24,645
Speaker 6:  Indy, like this company hit a record high after the election, not

893
00:56:24,835 --> 00:56:28,805
Speaker 6:  because it sold more cars, but because Elon Musk won

894
00:56:28,805 --> 00:56:31,805
Speaker 6:  the election. Like that, that is just a thing that happened. Yeah. And, and

895
00:56:31,805 --> 00:56:35,565
Speaker 6:  everybody assumed he would use that to Tesla's benefit and he didn't. He

896
00:56:35,565 --> 00:56:39,485
Speaker 6:  used it to destroy America. But that's, that, that was the, that

897
00:56:39,485 --> 00:56:43,205
Speaker 6:  was the assumption then. And I think, and for me that was the moment

898
00:56:43,205 --> 00:56:47,125
Speaker 6:  that any question of like, is this, is this company or is the perception

899
00:56:47,125 --> 00:56:50,925
Speaker 6:  of this company about cars or is it about politics just

900
00:56:50,925 --> 00:56:54,565
Speaker 6:  flipped entirely like this, this is a company about politics

901
00:56:54,865 --> 00:56:57,525
Speaker 6:  and it shouldn't be. And it is, and it's weird that it's, I think

902
00:56:57,525 --> 00:57:00,685
Speaker 5:  What's also really fascinating too is that, you know, sort of like trying

903
00:57:00,705 --> 00:57:04,605
Speaker 5:  to make a bet as an investor or someone who wants to play the stock

904
00:57:04,605 --> 00:57:08,485
Speaker 5:  market on Elon Musk used to be a pretty easy bet that

905
00:57:08,485 --> 00:57:12,085
Speaker 5:  would, that would pay off for, for a number of years. You could

906
00:57:12,145 --> 00:57:15,845
Speaker 5:  invest in Tesla and assume and see returns on that investment because

907
00:57:16,765 --> 00:57:20,565
Speaker 5:  of the way that the stock market treated that company. Not as a regular car

908
00:57:20,565 --> 00:57:24,285
Speaker 5:  company as what Eli was saying, but as something that's

909
00:57:24,315 --> 00:57:28,205
Speaker 5:  sort of, you know, about robotics and artificial

910
00:57:28,205 --> 00:57:32,165
Speaker 5:  intelligence and self-driving cars and energy management and, and

911
00:57:32,445 --> 00:57:35,605
Speaker 5:  honestly saving the world. Right? For a long time he was framing the, the,

912
00:57:35,625 --> 00:57:39,565
Speaker 5:  the mission of Tesla as being one about saving the world.

913
00:57:39,945 --> 00:57:41,245
Speaker 5:  And I remember the last

914
00:57:43,365 --> 00:57:46,605
Speaker 5:  investor day that they had a couple years ago, he talked about very plainly

915
00:57:46,605 --> 00:57:50,485
Speaker 5:  about how it's not that hard to, to take all of

916
00:57:50,485 --> 00:57:54,205
Speaker 5:  these gas powered devices off the, off the road and replace them with

917
00:57:54,255 --> 00:57:58,205
Speaker 5:  clean energy powered devices. And he framed it very clearly as

918
00:57:58,205 --> 00:58:01,445
Speaker 5:  an effort to save the world. At the same time that that was going on. He

919
00:58:01,445 --> 00:58:05,245
Speaker 5:  was also in the process of trying to buy Twitter. And we,

920
00:58:05,265 --> 00:58:09,005
Speaker 5:  we saw sort of like throughout that whole process about how his, his

921
00:58:09,005 --> 00:58:12,725
Speaker 5:  viewpoint and his worldview became slowly very much informed by

922
00:58:12,725 --> 00:58:16,605
Speaker 5:  conspiracy theories and, and, and hard right politics. And

923
00:58:16,605 --> 00:58:19,525
Speaker 5:  then it became sort of clear after a while After that that he wasn't really

924
00:58:19,525 --> 00:58:22,165
Speaker 5:  interested in running Tesla anymore. He didn't, he didn't, he didn't want

925
00:58:22,165 --> 00:58:25,085
Speaker 5:  to just be like a car salesman. He wanted to be

926
00:58:25,875 --> 00:58:29,765
Speaker 5:  sort of the guy who was on the vanguard of, of ai this AI revolution that

927
00:58:29,765 --> 00:58:33,605
Speaker 5:  we're seeing. And then now it seems like that's not really even

928
00:58:34,185 --> 00:58:37,445
Speaker 5:  of interest to him anymore. Now he wants to be the co-president, which, I

929
00:58:37,445 --> 00:58:41,005
Speaker 5:  mean, like, can you blame the guy, like who wants to go from being a car

930
00:58:41,285 --> 00:58:45,045
Speaker 5:  salesman to like, maybe I'll make robots to now like I am, like co in charge

931
00:58:45,105 --> 00:58:48,245
Speaker 5:  of like the, the biggest richest country in the world. Sure. Like, I can't

932
00:58:48,245 --> 00:58:52,125
Speaker 5:  really see like, you know, how that that argument doesn't really

933
00:58:52,145 --> 00:58:56,005
Speaker 5:  pan out for him. So, you know, maybe he's not interested in Tesla anymore.

934
00:58:56,005 --> 00:58:58,725
Speaker 5:  Maybe he's not even really interested in robots. Maybe he's more interested

935
00:58:59,785 --> 00:59:03,525
Speaker 5:  in, in just being sort of like this iron fisted ruler of the country.

936
00:59:04,125 --> 00:59:06,685
Speaker 5:  I just don't see how that's gonna sell them anymore. Cars. Like at the end

937
00:59:06,685 --> 00:59:10,085
Speaker 5:  of the day, Tesla, the, I think the reason that Tesla take down protests

938
00:59:10,085 --> 00:59:13,925
Speaker 5:  have succeeded and I think they are a success. I don't think you end

939
00:59:13,925 --> 00:59:17,845
Speaker 5:  up doing an infomercial for Teslas and the White House lawn unless the

940
00:59:17,845 --> 00:59:20,885
Speaker 5:  protests are having impact. I don't think you see the stock price dropping

941
00:59:21,005 --> 00:59:24,965
Speaker 5:  unless the protests are having an impact. The reason is

942
00:59:24,965 --> 00:59:28,765
Speaker 5:  that's an incredible point of leverage, right? You, you make these cars toxic

943
00:59:28,785 --> 00:59:32,645
Speaker 5:  to own. The cyber truck in particular has become a toxic car to own.

944
00:59:32,645 --> 00:59:36,565
Speaker 5:  Yeah. And some people are quite happy about that. Like I'm as somebody

945
00:59:36,565 --> 00:59:39,965
Speaker 5:  who has a big, loud, stupid car, like, I get it, I understand why people

946
00:59:39,965 --> 00:59:41,005
Speaker 5:  like big, loud, stupid cars,

947
00:59:42,545 --> 00:59:46,335
Speaker 5:  but you see the videos of people spray painting them

948
00:59:46,355 --> 00:59:49,775
Speaker 5:  and putting stickers on them. There's a great video I sent to Andy, which

949
00:59:49,775 --> 00:59:53,095
Speaker 5:  is pure Andy Hawkins bait today, which was somebody parked a cyber truck

950
00:59:53,095 --> 00:59:56,695
Speaker 5:  in a bike lane in New York City and a guy picked up a city bike

951
00:59:56,805 --> 01:00:00,575
Speaker 5:  and rode it off the cyber truck like a ramp, like down the

952
01:00:00,875 --> 01:00:04,095
Speaker 5:  windshield to just, because it was in the bike lane in the way in. That's

953
01:00:04,095 --> 01:00:06,695
Speaker 5:  very good. Like there's something on that. That's that's beautiful. Great.

954
01:00:06,815 --> 01:00:10,055
Speaker 5:  I I I appreciate some funny protests in that

955
01:00:10,715 --> 01:00:13,175
Speaker 5:  way, but the products themselves, to your point, David, they now symbolize

956
01:00:13,175 --> 01:00:17,005
Speaker 5:  a politics, right? And that's not gonna keep sales up.

957
01:00:17,025 --> 01:00:20,765
Speaker 5:  No. And so you end up with this weird situation

958
01:00:21,015 --> 01:00:24,925
Speaker 5:  where Trump is at the White House sort of like

959
01:00:24,925 --> 01:00:27,805
Speaker 5:  dunking on Joe Biden complaining about the economy and then turning around

960
01:00:27,805 --> 01:00:31,485
Speaker 5:  and being like, this car is beautiful. And it was just a weird scene.

961
01:00:31,805 --> 01:00:34,965
Speaker 5:  I will say that I watched it, it's about, it was 35 minutes long, somewhere

962
01:00:34,965 --> 01:00:38,605
Speaker 5:  around that. And just to get through it, I, I watched it two x speed on YouTube

963
01:00:38,985 --> 01:00:42,805
Speaker 5:  and watching Elon and Trump talk at two x speed is like an out of body experience.

964
01:00:43,965 --> 01:00:46,925
Speaker 5:  I, I don't recommend it, but I also think everybody should experience at

965
01:00:46,925 --> 01:00:49,565
Speaker 5:  one time, didn't he say everything is computer?

966
01:00:50,755 --> 01:00:53,685
Speaker 5:  What a, what a good tee up. That just was. Andy, I have three clips I would

967
01:00:53,685 --> 01:00:57,525
Speaker 5:  like to play for you three Perfect. From this perfect. Just, there

968
01:00:57,525 --> 01:01:01,245
Speaker 5:  were so many moments during this, but I just, I just pulled out a couple

969
01:01:01,275 --> 01:01:04,245
Speaker 5:  that I would just like to play for you very quickly that I think neatly summarized

970
01:01:04,245 --> 01:01:06,765
Speaker 5:  the deep strangeness of this event. Here's the first one.

971
01:01:08,225 --> 01:01:08,445
Speaker 13:  Wow.

972
01:01:11,735 --> 01:01:15,605
Speaker 13:  Thank goodness. I was side that's beautiful down front. This is a different

973
01:01:15,605 --> 01:01:17,605
Speaker 13:  panel than I've had. Everything's computer.

974
01:01:18,985 --> 01:01:22,405
Speaker 5:  So that's Donald Trump getting into the car. He sits down in the driver's

975
01:01:22,405 --> 01:01:25,885
Speaker 5:  seat after like 10 times a red model. S pla it's a red model s right? And

976
01:01:25,905 --> 01:01:29,725
Speaker 5:  he, he says many times that Joe Biden could never basically, like, he couldn't

977
01:01:29,725 --> 01:01:32,965
Speaker 5:  get into this car, he doesn't even know what Teslas are. And then he gets

978
01:01:32,985 --> 01:01:36,045
Speaker 5:  in and he just, he sort of waves around and he goes, everything's

979
01:01:36,945 --> 01:01:40,605
Speaker 5:  computer. And I really believe the verges official tagline now should be

980
01:01:40,725 --> 01:01:44,205
Speaker 5:  everything's computer. I feel very validated because years ago when we hired

981
01:01:44,205 --> 01:01:47,725
Speaker 5:  Andy to cover cars, I was like, here's the deal. Everything's computer. Can

982
01:01:47,725 --> 01:01:51,565
Speaker 5:  we make t-shirts that say everything's computer? Like why is The Verge cover

983
01:01:51,565 --> 01:01:54,925
Speaker 5:  cars? Because everything's computer. I, I feel like I have to note though

984
01:01:55,165 --> 01:01:58,965
Speaker 5:  that a big reason why Musk sup reportedly turned away

985
01:01:59,025 --> 01:02:02,725
Speaker 5:  from Joe Biden and the Democrats is 'cause he didn't get invited to a White

986
01:02:02,725 --> 01:02:05,405
Speaker 5:  House summit during the Biden administration that was supposed to bring all

987
01:02:05,405 --> 01:02:09,125
Speaker 5:  the automakers in to talk about electric vehicle policy. And, and they

988
01:02:09,245 --> 01:02:12,765
Speaker 5:  snubbed Musk because supposedly because he doesn't allow unions in his

989
01:02:13,385 --> 01:02:17,365
Speaker 5:  at Tesla and Biden was a very pro-union president. So, and

990
01:02:17,365 --> 01:02:20,325
Speaker 5:  that was something that he really kind of wore as like a chip on his shoulder.

991
01:02:21,075 --> 01:02:24,005
Speaker 5:  Musk finally got his, his White House summit and he got it all to himself.

992
01:02:24,025 --> 01:02:27,725
Speaker 5:  And I think that I, I hope he feels good about that. No, I I think he felt

993
01:02:27,725 --> 01:02:31,245
Speaker 5:  like Donald Trump went wandering towards the model y and he had to be like,

994
01:02:31,245 --> 01:02:34,605
Speaker 5:  no, no, no, come back. Look at the cyber trunk. Which is a real thing that

995
01:02:35,155 --> 01:02:38,365
Speaker 5:  happened. Okay. I have a, I have another clip to play for you. This is, they're

996
01:02:38,385 --> 01:02:42,245
Speaker 5:  sitting in the car and Trump continues to just sort of marvel at the existence

997
01:02:42,525 --> 01:02:46,045
Speaker 5:  of a car. It seems like, like you get the real sense that Donald Trump may

998
01:02:46,045 --> 01:02:47,125
Speaker 5:  never have driven a car in his life.

999
01:02:47,675 --> 01:02:51,165
Speaker 13:  It's, it's, it's like, it's like driving a golf car basically. It's very

1000
01:02:51,165 --> 01:02:54,525
Speaker 13:  simple. It's very simple. So it's, it's literal like boat park that goes

1001
01:02:54,525 --> 01:02:58,365
Speaker 13:  really fast. There's no gears. This is really amazing.

1002
01:02:59,795 --> 01:03:03,085
Speaker 5:  It's like driving a golf cart that goes really fast, I think is like not

1003
01:03:03,385 --> 01:03:07,005
Speaker 5:  the sales pitch. Elon Musk thinks it might be. I also have to say there's

1004
01:03:07,005 --> 01:03:10,805
Speaker 5:  no gears is a ridiculous thing to say in 2025.

1005
01:03:10,915 --> 01:03:14,445
Speaker 5:  It's hard to buy a car worth a manual transition in 2025, calling it a golf

1006
01:03:14,445 --> 01:03:16,925
Speaker 5:  cart. I mean, that's just talking to Trump in his language, right? I mean,

1007
01:03:16,925 --> 01:03:19,685
Speaker 5:  that that is probably the only vehicle that he drives that's so crazy. His

1008
01:03:19,685 --> 01:03:22,485
Speaker 5:  life. You don't think Trump has gas powered golf carts at in Mar-a-Lago?

1009
01:03:23,745 --> 01:03:26,605
Speaker 5:  No. They're, they're too loud. You gotta you gotta have quiet when you're,

1010
01:03:26,605 --> 01:03:29,725
Speaker 5:  when you're hitting your terrible bunker shots. David, I will say that I

1011
01:03:29,725 --> 01:03:33,645
Speaker 5:  have to register a, a fact check on you. I know Donald Trump has driven

1012
01:03:33,645 --> 01:03:37,045
Speaker 5:  a car because there is at least one video of Donald Trump driving

1013
01:03:37,755 --> 01:03:40,845
Speaker 5:  a car that I Was it the one where tell he was sitting in the firetruck and

1014
01:03:40,845 --> 01:03:43,365
Speaker 5:  did the woo woo gesture? No, no, no, no. Okay. Because that doesn't count.

1015
01:03:43,875 --> 01:03:47,445
Speaker 5:  It's him. I believe the video was taken by Barron Trump, a young Barron Trump.

1016
01:03:47,755 --> 01:03:51,165
Speaker 5:  He's riding around in a Rolls Royce driven by Donald Trump. Melania is in

1017
01:03:51,165 --> 01:03:53,725
Speaker 5:  the passenger seat and they're listening to Blank Space by Taylor

1018
01:03:54,905 --> 01:03:58,195
Speaker 5:  Swift. This is a real video. You can go look it. Amazing. Interesting. But

1019
01:03:58,195 --> 01:04:00,635
Speaker 5:  I will say that rolls, I'm looking at the video right now. It ha it does

1020
01:04:00,655 --> 01:04:03,475
Speaker 5:  have analog gauges. So everything is not

1021
01:04:04,855 --> 01:04:08,795
Speaker 5:  computer, but now it is. Everything's so that was Donald Trump drove that

1022
01:04:08,795 --> 01:04:12,635
Speaker 5:  car and then this car, and that's a, it's a big change from a, from a rolls

1023
01:04:12,795 --> 01:04:14,875
Speaker 5:  to this. I could see how that would, that would blow mind. Do you think?

1024
01:04:14,875 --> 01:04:18,475
Speaker 5:  I don't, there is a, a sequence of that video where people keep telling him

1025
01:04:18,475 --> 01:04:21,275
Speaker 5:  to start the car and then you hear one of the photographers say, start the

1026
01:04:20,995 --> 01:04:24,915
Speaker 5:  engine. And like, I couldn't see Elon's face, but I could see Trump's

1027
01:04:24,915 --> 01:04:28,715
Speaker 5:  face and he just didn't like, none of that made any sense. Like, you

1028
01:04:28,715 --> 01:04:32,675
Speaker 5:  can't start a Tesla. There's no, there's no key to turn,

1029
01:04:33,305 --> 01:04:37,195
Speaker 5:  there's no engine. Someone somewhat famously, no engine.

1030
01:04:37,675 --> 01:04:39,915
Speaker 5:  I would, the whole situation was confused. All right, what's the third one?

1031
01:04:39,915 --> 01:04:42,035
Speaker 5:  All right, I have one more, I'm just gonna play it for you. Thank

1032
01:04:42,035 --> 01:04:44,035
Speaker 14:  You all very much. I love Tesla.

1033
01:04:44,895 --> 01:04:45,955
Speaker 5:  That's it. That's the whole clip.

1034
01:04:48,585 --> 01:04:49,765
Speaker 5:  That's not great.

1035
01:04:52,345 --> 01:04:56,205
Speaker 5:  Did you say teslar Tesla? Yeah. And that's right. I spelled it TI think

1036
01:04:56,365 --> 01:05:00,005
Speaker 5:  S-L-U-R-R is combining Tesla with the word slur, I think is very appropriate

1037
01:05:00,005 --> 01:05:02,165
Speaker 5:  in this moment. Yeah, that's about right. Straight. You did not run any of

1038
01:05:02,165 --> 01:05:06,085
Speaker 5:  clips of Donald Trump just sort of behold the cyber truck.

1039
01:05:06,085 --> 01:05:10,045
Speaker 5:  He was like, can you imagine what kind of brains in this guy's head? I know

1040
01:05:10,045 --> 01:05:13,445
Speaker 5:  he, he at one point like double tapped the side of it and was like, what

1041
01:05:13,445 --> 01:05:17,045
Speaker 5:  a great deal. Yeah, because Yolan was like, it's bulletproof and Trump goes

1042
01:05:17,165 --> 01:05:21,125
Speaker 5:  as though he's gonna test it out. Yeah. It was really something. But

1043
01:05:21,125 --> 01:05:23,845
Speaker 5:  if your test of something, whether or not something is bulletproof is like

1044
01:05:23,845 --> 01:05:26,525
Speaker 5:  wrapping on it twice. You're gonna believe everything is bulletproof.

1045
01:05:28,375 --> 01:05:31,955
Speaker 5:  It was weird. It was a weird event, a weird moment. It was again,

1046
01:05:31,985 --> 01:05:35,635
Speaker 5:  scattered with questions about whether there'd be a recession,

1047
01:05:36,125 --> 01:05:40,115
Speaker 5:  about whether Trump needed the notes in his

1048
01:05:40,115 --> 01:05:43,995
Speaker 5:  own hand that had the prices of Teslas listed on it. Weird

1049
01:05:44,015 --> 01:05:44,515
Speaker 5:  all around.

1050
01:05:44,775 --> 01:05:48,195
Speaker 6:  He went on a long rant about Columbia University at one point. Like yeah,

1051
01:05:48,195 --> 01:05:48,475
Speaker 6:  it's

1052
01:05:48,475 --> 01:05:51,035
Speaker 5:  Another first Amendment disaster that's unfolding. But that's

1053
01:05:51,035 --> 01:05:54,635
Speaker 6:  Kind of my point. All this is so tied up together now that it is like,

1054
01:05:54,975 --> 01:05:58,715
Speaker 6:  and maybe this was the inevitable outcome of Elon Musk becoming so

1055
01:05:59,075 --> 01:06:02,475
Speaker 6:  entrenched in our government, but like, I don't know. I I look around my

1056
01:06:02,475 --> 01:06:06,115
Speaker 6:  neighborhood now and there there are everyone who has a Tesla.

1057
01:06:06,355 --> 01:06:09,275
Speaker 6:  I live in a very like liberal area and

1058
01:06:09,575 --> 01:06:13,555
Speaker 6:  overwhelmingly I'm starting to see Teslas with some version of the, I

1059
01:06:13,555 --> 01:06:17,435
Speaker 6:  bought this before Elon Musk went crazy sticker, including on cyber

1060
01:06:17,435 --> 01:06:19,435
Speaker 6:  trucks, which debatable. Yeah, that's

1061
01:06:19,435 --> 01:06:22,795
Speaker 5:  Not a choice for you. Although they did announce the cyber truck 500 years

1062
01:06:22,795 --> 01:06:23,675
Speaker 5:  ago. That's fair.

1063
01:06:24,305 --> 01:06:28,035
Speaker 6:  That is, it was the first car ever invented and then they shipped it. But

1064
01:06:28,185 --> 01:06:32,075
Speaker 6:  yeah, I just, I don't see how this goes back either.

1065
01:06:32,295 --> 01:06:36,275
Speaker 6:  It really feels like we are at a place where the protests feel

1066
01:06:36,275 --> 01:06:39,435
Speaker 6:  like they're gonna continue to get worse because this thing is becoming increasingly

1067
01:06:39,435 --> 01:06:43,195
Speaker 6:  politicized and that what Trump and must give decided is that

1068
01:06:43,395 --> 01:06:45,195
Speaker 6:  actually politicizing it is a way to, to

1069
01:06:45,315 --> 01:06:45,835
Speaker 5:  Ban it. No,

1070
01:06:45,835 --> 01:06:49,435
Speaker 6:  It's, it's, it's either to sell more cars to Republicans ideally who

1071
01:06:49,435 --> 01:06:53,115
Speaker 6:  traditionally have not been the people who buy electric cars or who

1072
01:06:53,115 --> 01:06:57,035
Speaker 6:  cares juice the stock price, right? Like it, it it, you turn Tesla into a

1073
01:06:57,035 --> 01:07:00,955
Speaker 6:  meme stock for Republicans, which has made Donald Trump an awful lot

1074
01:07:00,955 --> 01:07:02,315
Speaker 6:  of money over the years. Yeah,

1075
01:07:02,715 --> 01:07:06,675
Speaker 5:  I I think Tesla like Neil, I said it's been over inflated. It's a

1076
01:07:06,675 --> 01:07:10,235
Speaker 5:  meme stock, it's overvalued, it's, it's, it's traded more,

1077
01:07:10,615 --> 01:07:14,275
Speaker 5:  you know, sort of at a similar level as, as tech stocks are and not as a

1078
01:07:14,275 --> 01:07:18,035
Speaker 5:  car car stock. And I think that a lot of people assumed

1079
01:07:18,065 --> 01:07:21,715
Speaker 5:  that taking a face plant on robot taxis or the

1080
01:07:21,715 --> 01:07:25,635
Speaker 5:  optimist robots, you know, falling down a flight of stairs or something

1081
01:07:25,635 --> 01:07:28,715
Speaker 5:  like that was gonna be what sort of ultimately deflated. And I don't think

1082
01:07:28,715 --> 01:07:31,795
Speaker 5:  anyone really assumed that it was gonna be this sort of like

1083
01:07:31,895 --> 01:07:35,595
Speaker 5:  politicization that we're seeing in Musk taking such a prominent role in

1084
01:07:35,595 --> 01:07:38,795
Speaker 5:  the administration. But I think that that's, that is ultimately what is going

1085
01:07:38,795 --> 01:07:42,275
Speaker 5:  to bring, bring Tesla sort of back, back down to earth is this this hyper

1086
01:07:42,275 --> 01:07:44,755
Speaker 5:  political environment that we're in now. Yeah. You never thought it would

1087
01:07:44,755 --> 01:07:47,835
Speaker 5:  be the fundamentals of the car sales would bring it back down to earth. Right.

1088
01:07:47,835 --> 01:07:51,395
Speaker 5:  Like that, that seemed insulated because of the

1089
01:07:51,395 --> 01:07:54,715
Speaker 5:  promises about robot robotaxis and all that other stuff. By the way, the,

1090
01:07:54,735 --> 01:07:58,675
Speaker 5:  the best sticker on a cyber truck situation is the couple

1091
01:07:58,815 --> 01:08:01,915
Speaker 5:  who wrapped their cyber truck white and put a Rivian logo on the back of

1092
01:08:01,915 --> 01:08:02,035
Speaker 5:  it.

1093
01:08:02,375 --> 01:08:02,795
Speaker 6:  So good.

1094
01:08:03,055 --> 01:08:06,475
Speaker 5:  Oh my god, that was so good. And then they discovered that they became a

1095
01:08:06,475 --> 01:08:10,395
Speaker 5:  meme and had to go on Reddit and like try to like laugh it off and explain

1096
01:08:10,395 --> 01:08:11,915
Speaker 5:  themselves and nobody bought

1097
01:08:11,915 --> 01:08:14,995
Speaker 6:  It. Well and their explanation was we sold our other Tesla,

1098
01:08:16,145 --> 01:08:18,165
Speaker 6:  but we can't sell this one. No one will take it.

1099
01:08:18,315 --> 01:08:22,085
Speaker 5:  Yeah. I've seen videos. Yeah. I have a weird TikTok algorithm. I

1100
01:08:22,285 --> 01:08:26,205
Speaker 5:  I I have a lot of like car dealerships on the phone negotiating

1101
01:08:26,205 --> 01:08:30,125
Speaker 5:  deals on my TikTok feed and I've watched a lot of car dealership

1102
01:08:30,155 --> 01:08:34,045
Speaker 5:  guys like totally make low ball offers for cyber trucks. Mm.

1103
01:08:34,345 --> 01:08:37,325
Speaker 5:  And then basically, you know, the person's like, no. And they're like, call

1104
01:08:37,325 --> 01:08:39,605
Speaker 5:  me back. This is the number you're gonna get. Like at, at some point you're

1105
01:08:39,605 --> 01:08:41,965
Speaker 5:  gonna call me back and I'm gonna give, I'm gonna give you $60,000 to the

1106
01:08:41,965 --> 01:08:45,905
Speaker 5:  cyber truck. And that is, that's just bad news. Now are a

1107
01:08:45,905 --> 01:08:48,065
Speaker 5:  bunch of car dealerships trying to artificially lower the price of cyber

1108
01:08:48,065 --> 01:08:52,025
Speaker 5:  trucks by making TikTok videos? Potentially. But you can, you

1109
01:08:52,145 --> 01:08:55,665
Speaker 5:  can see the dynamic for that car in particular is getting worse.

1110
01:08:56,845 --> 01:09:00,425
Speaker 5:  And I think some people like the attention, there's a cyber truck in Westchester

1111
01:09:01,475 --> 01:09:04,625
Speaker 5:  where I live that is spray painted and a lot of people believe the owner

1112
01:09:04,625 --> 01:09:05,705
Speaker 5:  spray painted it himself

1113
01:09:06,825 --> 01:09:09,085
Speaker 6:  Oh wow. As a, as a like defense mechanism.

1114
01:09:09,185 --> 01:09:12,165
Speaker 5:  As a defense mechanism as a way to get pictures of his truck on Instagram.

1115
01:09:12,425 --> 01:09:16,045
Speaker 5:  No one knows. Yeah. But like that we're entering the second phase, you know,

1116
01:09:16,045 --> 01:09:19,005
Speaker 5:  where people are like, oh, you're doing it for clout. And it's like, that's

1117
01:09:19,005 --> 01:09:22,845
Speaker 5:  weird. That's a weird outcome. Yeah. A lot of, I know a lot of small business

1118
01:09:22,845 --> 01:09:26,765
Speaker 5:  owners bought cyber trucks to like wrap with like their, the name of

1119
01:09:26,765 --> 01:09:30,605
Speaker 5:  their business if like they had like a, like a small solar company or like

1120
01:09:30,685 --> 01:09:34,285
Speaker 5:  a, a coffee shop or something like that. And, and now we're starting to see

1121
01:09:34,285 --> 01:09:37,725
Speaker 5:  a lot of them sort of reverse on that and you know, take the wrapping, take

1122
01:09:37,725 --> 01:09:39,045
Speaker 5:  the wrapping up because they know put

1123
01:09:39,045 --> 01:09:40,645
Speaker 6:  Their competitors' logo on it instead. Yeah.

1124
01:09:41,905 --> 01:09:43,925
Speaker 5:  We should talk just briefly, we, we talk a lot about the first amendment

1125
01:09:43,925 --> 01:09:47,245
Speaker 5:  on the show, Tesla take down is the name of the protest. It's pretty loosely

1126
01:09:47,245 --> 01:09:51,085
Speaker 5:  organized. Like I don't, there's not a head of Tesla take down, you know,

1127
01:09:52,475 --> 01:09:56,285
Speaker 5:  it's certainly not like command, it's just like a command system, you know,

1128
01:09:56,285 --> 01:09:59,165
Speaker 5:  it's like an army. People are just showing up Tesla dealerships and protesting

1129
01:09:59,165 --> 01:10:03,045
Speaker 5:  at certain times, like organized on social media like you do. Trump is basically

1130
01:10:03,045 --> 01:10:05,685
Speaker 5:  saying this is gonna be terrorism, we're gonna prosecute this. Mike Johnson,

1131
01:10:05,685 --> 01:10:09,565
Speaker 5:  the speaker of the house said the house would start investigating these protests.

1132
01:10:09,565 --> 01:10:12,925
Speaker 5:  The police are out in force at Tesla dealerships. Now there's an incredible

1133
01:10:13,685 --> 01:10:17,525
Speaker 5:  picture, I believe a store in Chicago with just a line of

1134
01:10:17,525 --> 01:10:21,405
Speaker 5:  police officers in front of it last weekend, which is just incredible, right?

1135
01:10:21,405 --> 01:10:25,085
Speaker 5:  There's a video of a cyber truck in New York being guarded by six

1136
01:10:25,885 --> 01:10:29,805
Speaker 5:  police officers, which is very funny in its way the politicization

1137
01:10:29,805 --> 01:10:32,645
Speaker 5:  is running right into the weird first amendment environment, right? Where

1138
01:10:32,945 --> 01:10:36,285
Speaker 5:  yes, we talk a lot about free speech. Elon says he is a free speech absolutist,

1139
01:10:36,585 --> 01:10:40,165
Speaker 5:  but If you protest a Tesla, the dealership, the full power of the

1140
01:10:40,165 --> 01:10:43,895
Speaker 5:  state's police force will be there to greet you. There's something

1141
01:10:44,015 --> 01:10:47,935
Speaker 5:  weird there. I it hasn't broken yet, right? Like there aren't

1142
01:10:47,935 --> 01:10:51,175
Speaker 5:  you, no one's been arrested for protesting at Tesla dealership yet. And I

1143
01:10:51,175 --> 01:10:55,095
Speaker 5:  don't think you should burn down the charging stations, but we're in a

1144
01:10:55,095 --> 01:10:57,735
Speaker 5:  real fuzzy place. How do you think that's playing out, Eddie? Well, I mean

1145
01:10:57,735 --> 01:11:01,695
Speaker 5:  we've already saw this week ice agents detain and disappear

1146
01:11:01,815 --> 01:11:05,695
Speaker 5:  a pro-Palestinian activist for, you know, basically for no

1147
01:11:05,695 --> 01:11:09,535
Speaker 5:  crime at all, but for, you know, speaking out in support of, of Gaza. So

1148
01:11:09,845 --> 01:11:13,715
Speaker 5:  it's, it's not a very huge leap to

1149
01:11:13,715 --> 01:11:17,595
Speaker 5:  go and, and start doing the same for people who are speaking out against

1150
01:11:17,595 --> 01:11:21,315
Speaker 5:  Tesla. I mean, I I I think that, you know, what, what Trump is saying specifically

1151
01:11:21,335 --> 01:11:25,275
Speaker 5:  is people who are vandalizing and are doing

1152
01:11:25,275 --> 01:11:29,195
Speaker 5:  things that are considered to be violent and and dangerous are,

1153
01:11:29,195 --> 01:11:32,515
Speaker 5:  are potentially going to face some of these charges. Whether or not that

1154
01:11:32,515 --> 01:11:35,315
Speaker 5:  extends to the people who are peacefully protesting, I don't think we've

1155
01:11:35,315 --> 01:11:37,875
Speaker 5:  seen yet. I don't, I don't think that that was necessarily what he was saying.

1156
01:11:38,305 --> 01:11:41,955
Speaker 5:  It's hard to parse what, what Trump says too much. And I know that

1157
01:11:42,745 --> 01:11:46,355
Speaker 5:  Musk has made claims on X about how these

1158
01:11:46,355 --> 01:11:49,555
Speaker 5:  protests are, are AstroTurf and are being funded by,

1159
01:11:51,255 --> 01:11:55,035
Speaker 5:  you know, Soros or whomever else, you know, sort of are the, the, the enemies

1160
01:11:55,035 --> 01:11:58,835
Speaker 5:  that lurk in his brain. So I don't really know how this is, I I think like

1161
01:11:58,835 --> 01:12:02,755
Speaker 5:  if anything, the protesters are probably now even more motivated to turn

1162
01:12:02,755 --> 01:12:06,035
Speaker 5:  out at the locations now that they know that they're on

1163
01:12:06,845 --> 01:12:10,515
Speaker 5:  Trump and, and Musk's radar, you know, I think that a lot of this was about

1164
01:12:10,515 --> 01:12:13,275
Speaker 5:  getting their attention and now that they know that they have his attention,

1165
01:12:13,915 --> 01:12:17,115
Speaker 5:  I I think we'll see something of an escalation at least in numbers,

1166
01:12:17,965 --> 01:12:21,835
Speaker 5:  which I think is going to cause I think a lot of disruption and, you know,

1167
01:12:21,895 --> 01:12:22,795
Speaker 5:  police overtime,

1168
01:12:25,155 --> 01:12:28,755
Speaker 5:  salaries are gonna go up. So, you know, it's, it's gonna be really kind of

1169
01:12:28,995 --> 01:12:31,395
Speaker 5:  interesting to watch. And I know that the, you know, in talking to some of

1170
01:12:31,395 --> 01:12:34,835
Speaker 5:  the, the local organizers and some of the people who are promoting the protests

1171
01:12:34,835 --> 01:12:38,675
Speaker 5:  online on Blue Sky are, are adamant about, you know,

1172
01:12:38,675 --> 01:12:41,915
Speaker 5:  this is a peaceful protest. You know, we, we might occasionally like get

1173
01:12:42,235 --> 01:12:45,915
Speaker 5:  arrested peacefully for occupying space, but we're never going to be defacing

1174
01:12:46,095 --> 01:12:49,075
Speaker 5:  or vandalizing. That's not the, the mission of this movement. The mission

1175
01:12:49,135 --> 01:12:53,035
Speaker 5:  is to cause Tesla's sales numbers to go down and to

1176
01:12:53,035 --> 01:12:56,715
Speaker 5:  hurt Elon Musk's net worth and stock price. That's all that they're interested

1177
01:12:56,715 --> 01:13:00,675
Speaker 5:  in doing. So I think if they can sort of hold that line, it'll

1178
01:13:00,675 --> 01:13:04,435
Speaker 5:  really, I think, sort of be on the, on the other side to really

1179
01:13:04,715 --> 01:13:07,835
Speaker 5:  kind of escalate things if they want to. I will know that Trump has called

1180
01:13:08,415 --> 01:13:12,355
Speaker 5:  the boycott movement an illegal boycott, which is not a thing which tracks

1181
01:13:12,355 --> 01:13:15,395
Speaker 5:  right, which is not a thing also tracks with Elon saying it's illegal to

1182
01:13:15,395 --> 01:13:19,345
Speaker 5:  not advertise on x I'm just saying the police are coming to your house and

1183
01:13:19,345 --> 01:13:22,985
Speaker 5:  you're gonna buy a Tesla that seems very, it's the, the end

1184
01:13:23,265 --> 01:13:26,905
Speaker 5:  result of America that what, what color do you want

1185
01:13:27,645 --> 01:13:30,065
Speaker 5:  and how much of your personal income do you have to give up to the government

1186
01:13:30,065 --> 01:13:33,345
Speaker 5:  in order to receive your Tesla? Is the only question that's, that's how,

1187
01:13:33,345 --> 01:13:37,125
Speaker 5:  that's the end state of Doge. We're gonna, we're gonna fund social security

1188
01:13:37,125 --> 01:13:40,445
Speaker 5:  by forcing a brand to buy Tesla somehow now it's gonna be good. Alright,

1189
01:13:40,445 --> 01:13:43,045
Speaker 5:  we're gonna see what happens this weekend. It feels like the protests are

1190
01:13:43,045 --> 01:13:46,765
Speaker 5:  getting louder, right? Like the protesters have gotten the validation they

1191
01:13:46,765 --> 01:13:50,405
Speaker 5:  need from the White House, like it's working. They're, they're, they're bothering

1192
01:13:50,405 --> 01:13:53,405
Speaker 5:  the people in charge. That usually means it gets louder.

1193
01:13:54,185 --> 01:13:57,085
Speaker 5:  I'm very worried about the free speech environment of America, as every listener

1194
01:13:57,085 --> 01:14:00,525
Speaker 5:  of the show knows that dynamic is something we're watching very closely.

1195
01:14:00,785 --> 01:14:04,605
Speaker 5:  But in the meantime, let us know If you Tesla starts driving itself

1196
01:14:05,225 --> 01:14:07,765
Speaker 5:  or If you are the person who spray painted your own cyber truck for attention.

1197
01:14:07,905 --> 01:14:11,685
Speaker 5:  I'm dying to talk to you Andy. Thank you so much man. Thanks.

1198
01:14:11,685 --> 01:14:12,285
Speaker 5:  Thanks guys.

1199
01:17:22,185 --> 01:17:24,305
Speaker 5:  recording, we recorded this on a Wednesday, Wednesday earlier than usual

1200
01:17:24,745 --> 01:17:28,345
Speaker 5:  for various calendar reasons, but as we were recording, Chris Welch broke

1201
01:17:28,345 --> 01:17:32,065
Speaker 5:  the news that Sonos in an all hands meeting has canceled its

1202
01:17:32,065 --> 01:17:35,315
Speaker 5:  streaming video player, which was called Pinewood.

1203
01:17:35,535 --> 01:17:37,155
Speaker 6:  Oh that's sad. Pinewood. Yeah.

1204
01:17:37,375 --> 01:17:41,035
Speaker 5:  So this was Sonos big push, right? It's next big

1205
01:17:41,035 --> 01:17:44,915
Speaker 5:  market under the previous administration was streaming video. They had

1206
01:17:45,035 --> 01:17:47,955
Speaker 5:  a deal with some advertising company, they were to link everything together.

1207
01:17:48,715 --> 01:17:52,435
Speaker 5:  Presumably there would be some AI talk that's just the way things go. And

1208
01:17:52,585 --> 01:17:56,395
Speaker 5:  they would have a stream video player. And now the new interim CEO,

1209
01:17:56,415 --> 01:18:00,315
Speaker 5:  who I suspect will become the permanent CEO Tom Conrad says

1210
01:18:01,155 --> 01:18:04,675
Speaker 5:  a push in the video is off the table for now and the team is being reassigned

1211
01:18:04,675 --> 01:18:08,235
Speaker 5:  to other projects because they gotta turn around the company. This

1212
01:18:08,235 --> 01:18:11,755
Speaker 6:  One's really interesting 'cause I would say clearly the correct call

1213
01:18:12,095 --> 01:18:15,955
Speaker 6:  for Sonos, Sonos has had a brutal year. And what

1214
01:18:15,955 --> 01:18:19,835
Speaker 6:  it needs more than anything is to get back to proving

1215
01:18:19,935 --> 01:18:23,675
Speaker 6:  it can do the thing that it does really well. And so

1216
01:18:23,675 --> 01:18:27,555
Speaker 6:  like forgetting everything else and being like, oh, do you remember how we

1217
01:18:27,555 --> 01:18:30,115
Speaker 6:  made speakers that you love for 20 years? We're gonna get back to making

1218
01:18:30,115 --> 01:18:32,595
Speaker 6:  speakers that you love is the right call.

1219
01:18:33,875 --> 01:18:36,165
Speaker 6:  This is a bummer though. Like I think,

1220
01:18:37,895 --> 01:18:40,935
Speaker 6:  I wouldn't say I had super high hopes for this thing working the way that

1221
01:18:41,745 --> 01:18:45,535
Speaker 6:  Chris in particular has reported that it was gonna work. The,

1222
01:18:45,555 --> 01:18:49,455
Speaker 6:  the like all encompassing universal TV guide

1223
01:18:49,545 --> 01:18:53,415
Speaker 6:  thing. Really hard to pull off. Sonos has done a really

1224
01:18:53,775 --> 01:18:57,535
Speaker 6:  interesting job of trying to bring various voice assistants together

1225
01:18:57,565 --> 01:19:01,055
Speaker 6:  over the years and has not really had a ton of success with that. Like

1226
01:19:01,455 --> 01:19:05,015
Speaker 6:  I just, I I would've been very curious to see

1227
01:19:05,265 --> 01:19:08,295
Speaker 6:  Sonos try this. And I'm a little sad that we're not gonna get to see them

1228
01:19:08,315 --> 01:19:11,885
Speaker 6:  try, but I think Tom Conrad is probably right to kill this project.

1229
01:19:12,455 --> 01:19:16,245
Speaker 5:  Sonos has a statement in the story. We don't comment on our

1230
01:19:16,245 --> 01:19:19,725
Speaker 5:  roadmap, but as been previously announced, we have a longstanding relationship

1231
01:19:19,725 --> 01:19:23,565
Speaker 5:  with the Trade Desk, which was the software provider for this

1232
01:19:23,565 --> 01:19:26,485
Speaker 5:  rumored stream box. We have a longstanding relationship with the Trade Desk

1233
01:19:26,505 --> 01:19:30,105
Speaker 5:  and that relationship continues. W weird, weird statement.

1234
01:19:32,015 --> 01:19:34,975
Speaker 5:  I don't know what to make of that. Yeah, maybe there'll be some advertising

1235
01:19:34,975 --> 01:19:38,335
Speaker 5:  and other Sonos products, but I agree with you. They need to focus, they

1236
01:19:38,335 --> 01:19:41,975
Speaker 5:  need to make that app great. You can see how launching another product to

1237
01:19:42,095 --> 01:19:45,975
Speaker 5:  a hostile user base was not a great idea. Also, I think

1238
01:19:45,975 --> 01:19:49,095
Speaker 5:  the headphones don't pan out the way they want it to. The, I think they're

1239
01:19:49,095 --> 01:19:50,845
Speaker 5:  just, they're just buttoning up.

1240
01:19:51,395 --> 01:19:54,845
Speaker 6:  Yeah, and I think if I'm Sonos, the thing to focus on

1241
01:19:56,145 --> 01:20:00,025
Speaker 6:  a is obviously software first, but I think Sonos should go out

1242
01:20:00,025 --> 01:20:03,745
Speaker 6:  and like rev the headphones and try to make the ace a real

1243
01:20:04,325 --> 01:20:08,285
Speaker 6:  hit because I think they could have been like, by all accounts, they're good.

1244
01:20:08,475 --> 01:20:11,325
Speaker 6:  They were a little too expensive, they didn't really have a thing, but they're

1245
01:20:11,325 --> 01:20:13,925
Speaker 6:  very good headphones. Every time we talk about it, I hear from people who

1246
01:20:13,925 --> 01:20:17,765
Speaker 6:  are like, I have the ace and I love them, but because the Ace

1247
01:20:17,765 --> 01:20:21,485
Speaker 6:  shipped at the same time as this terrible app, all Goodwill that

1248
01:20:21,485 --> 01:20:24,925
Speaker 6:  might've come to the headphones just got eaten alive by the bad stuff that

1249
01:20:25,085 --> 01:20:28,365
Speaker 6:  happened with the app. So if I'm Sonos, it's like, okay, this product wasn't

1250
01:20:28,885 --> 01:20:32,365
Speaker 6:  a miss this thing we, we weren't wrong about this. We just have to get back

1251
01:20:32,365 --> 01:20:36,325
Speaker 6:  to doing this correctly and then go worry about other

1252
01:20:36,325 --> 01:20:39,845
Speaker 6:  stuff. But there's like, there's room to go try and do headphones well

1253
01:20:40,145 --> 01:20:43,485
Speaker 6:  and successfully before you go try and do video,

1254
01:20:43,815 --> 01:20:47,445
Speaker 6:  which is a much more competitive, maybe not more

1255
01:20:47,445 --> 01:20:49,885
Speaker 6:  competitive, but also very competitive and very different market.

1256
01:20:50,275 --> 01:20:54,005
Speaker 5:  Yeah. This dumb feedback on the Ace, I think it's very hard to market

1257
01:20:54,005 --> 01:20:56,045
Speaker 5:  headphones. It looks so much like every other headphones.

1258
01:20:56,515 --> 01:21:00,415
Speaker 6:  Yeah, I think that's right. Like I But but like If you were putting

1259
01:21:00,985 --> 01:21:04,895
Speaker 6:  Sonos odds of doing a very good job over time, wouldn't you say it's

1260
01:21:04,895 --> 01:21:07,775
Speaker 6:  more likely that Sonos will eventually figure out how to make genuinely great

1261
01:21:07,775 --> 01:21:10,095
Speaker 6:  differentiated headphones than a set top box?

1262
01:21:12,155 --> 01:21:14,815
Speaker 5:  Yes. But my caveat is I don't think I'm

1263
01:21:14,815 --> 01:21:16,335
Speaker 6:  So surprised you even had to think about that.

1264
01:21:16,895 --> 01:21:19,975
Speaker 5:  I think it is really, really hard to make genuinely great differentiated

1265
01:21:19,975 --> 01:21:23,855
Speaker 5:  headphones when most of those headphones connect to

1266
01:21:23,915 --> 01:21:27,895
Speaker 5:  an iPhone. And Apple makes it very, very, very hard to

1267
01:21:27,895 --> 01:21:30,415
Speaker 5:  out innovate any of the AirPods products on the iPhone.

1268
01:21:30,765 --> 01:21:31,655
Speaker 6:  Yeah, I'll give you that.

1269
01:21:32,435 --> 01:21:36,295
Speaker 5:  That's, that was my hesitation is like, yeah, there's a, there's a natural

1270
01:21:36,535 --> 01:21:39,895
Speaker 5:  instinctive answer and then there's the reality, which is the TV

1271
01:21:40,265 --> 01:21:44,245
Speaker 5:  space is space. There's more opportunity in it. Yeah. It's more of a free

1272
01:21:44,245 --> 01:21:44,365
Speaker 5:  for

1273
01:21:44,365 --> 01:21:47,325
Speaker 6:  All. Yeah, that's fair. I'll give you I, but like, it's not like TV is a

1274
01:21:47,325 --> 01:21:49,565
Speaker 6:  wide open space with easy games to play.

1275
01:21:51,645 --> 01:21:54,965
Speaker 5:  Well hopefully they just focus on the speakers. Tom Conrad interim, CEO,

1276
01:21:54,965 --> 01:21:57,925
Speaker 5:  who again, I think we all suspect we come to the, the full-time CEO Welcome

1277
01:21:58,145 --> 01:22:01,605
Speaker 5:  on these shows. Any anytime you want, Tom. We, we've known Tom forever,

1278
01:22:02,625 --> 01:22:06,325
Speaker 5:  so come on. We'll, we'll we'll talk Pandora for a while and then we'll move

1279
01:22:06,325 --> 01:22:09,405
Speaker 5:  on to Sonos. How's that? Yeah. Used to anytime used to be at Pandora. All

1280
01:22:09,405 --> 01:22:11,445
Speaker 5:  right, it's time. It's time. David.

1281
01:22:12,025 --> 01:22:14,605
Speaker 6:  Oh my God. America's favorite podcast within a podcast.

1282
01:22:15,395 --> 01:22:17,365
Speaker 5:  This one's gonna be wonkier than, than Normal.

1283
01:22:17,795 --> 01:22:19,565
Speaker 6:  That is a high bar, my friend.

1284
01:22:20,155 --> 01:22:23,775
Speaker 5:  It's time for Brendan Carr's dummy. Everyone, everyone's favorite.

1285
01:22:24,555 --> 01:22:28,015
Speaker 5:  So Brendan Carr, as some of you know, I don't know why you're listening to

1286
01:22:28,015 --> 01:22:31,775
Speaker 5:  this video now. Brendan Carr is the chairman of the FCC under Donald

1287
01:22:32,655 --> 01:22:36,535
Speaker 5:  Trump, a notoriously hostile presence

1288
01:22:36,535 --> 01:22:39,575
Speaker 5:  for the First Amendment in freedom of speech in this country. This man wants

1289
01:22:39,855 --> 01:22:43,815
Speaker 5:  to regulate speech on every wire and wireless transmission he can

1290
01:22:43,835 --> 01:22:47,655
Speaker 5:  get his hands on. It's not subtle and he does it by

1291
01:22:47,655 --> 01:22:51,615
Speaker 5:  wrapping himself up in the cloak of defending free speech, which is just

1292
01:22:51,615 --> 01:22:54,575
Speaker 5:  pure hypocrisy. I will say this at the top of this segment. I'll say it at

1293
01:22:54,575 --> 01:22:58,215
Speaker 5:  the end of the segment. I know Brendan listens to our show. I know he gets

1294
01:22:58,315 --> 01:23:02,015
Speaker 5:  Google alerts for his name. I know it. You're welcome.

1295
01:23:02,205 --> 01:23:05,405
Speaker 5:  Come on Brendan, come on the show. Try to defend yourself. You won't 'cause

1296
01:23:05,405 --> 01:23:09,125
Speaker 5:  you're a coward. But the, we've sent the emails, you've been invited on

1297
01:23:09,125 --> 01:23:12,935
Speaker 5:  decoder show up. I'm just, I'm just saying. So this

1298
01:23:12,935 --> 01:23:13,855
Speaker 5:  week Brendan,

1299
01:23:15,905 --> 01:23:18,925
Speaker 5:  our little man, Brendan sent a letter to YouTube

1300
01:23:19,835 --> 01:23:23,615
Speaker 5:  asking if YouTube TV discriminates against faith based programming.

1301
01:23:24,195 --> 01:23:27,735
Speaker 5:  And then he on XI have received complaints that Google's YouTube

1302
01:23:28,075 --> 01:23:31,735
Speaker 5:  TV is discriminating and it's faith based programming. These concerning

1303
01:23:31,735 --> 01:23:34,655
Speaker 5:  allegations come at a time when American Public Discourse has experienced

1304
01:23:34,655 --> 01:23:38,055
Speaker 5:  an unprecedented and unacceptable surge in censorship.

1305
01:23:38,575 --> 01:23:42,455
Speaker 5:  I am asking Google for answers. So there's like four things that

1306
01:23:42,455 --> 01:23:45,975
Speaker 5:  just aren't true in that by using the power of the state

1307
01:23:46,475 --> 01:23:50,455
Speaker 5:  to censor Google. Yeah. So this is all based on what appears to be

1308
01:23:50,455 --> 01:23:51,575
Speaker 5:  one complaint from one channel,

1309
01:23:54,735 --> 01:23:58,595
Speaker 5:  great American family, which apparently is a face based channel.

1310
01:23:58,665 --> 01:24:01,475
Speaker 5:  It's distributed on FUBU and slinging on DirecTV Stream on Hulu.

1311
01:24:02,255 --> 01:24:06,095
Speaker 5:  Here's the thing about this. You can get

1312
01:24:06,405 --> 01:24:09,615
Speaker 5:  some of these, you can get some content from this company on YouTube,

1313
01:24:10,825 --> 01:24:14,705
Speaker 5:  right? YouTube is just wide open. You just, you just put stuff on

1314
01:24:14,705 --> 01:24:18,545
Speaker 5:  YouTube. People do all the time. They're not on YouTube

1315
01:24:18,685 --> 01:24:21,945
Speaker 5:  TV because YouTube TV is a cable company.

1316
01:24:22,645 --> 01:24:26,385
Speaker 5:  And to get on YouTube tv, you have to negotiate rates and carriage

1317
01:24:26,415 --> 01:24:29,065
Speaker 5:  with YouTube the same way that you would've to negotiate rates and carriage

1318
01:24:29,535 --> 01:24:33,025
Speaker 5:  with DirecTV proper, with Comcast,

1319
01:24:33,535 --> 01:24:36,815
Speaker 5:  with Spectrum, with any other cable company you can think of.

1320
01:24:37,315 --> 01:24:40,095
Speaker 5:  By the way, I should disclose here that Comcast is an investor in rock media,

1321
01:24:40,135 --> 01:24:43,415
Speaker 5:  a parent company. I do not have great relationships with cable companies.

1322
01:24:44,715 --> 01:24:48,215
Speaker 5:  So take that for what it's worth. But I know how cable companies work

1323
01:24:48,555 --> 01:24:52,255
Speaker 5:  and my coverage of them over the past decade has led them to hate me.

1324
01:24:52,795 --> 01:24:55,695
Speaker 5:  So yeah, that's about right. That's how it goes. But I do know how they work

1325
01:24:55,855 --> 01:24:59,815
Speaker 5:  'cause I've covered them a lot. Here's the thing about, about Brendan Carr.

1326
01:25:00,195 --> 01:25:03,695
Speaker 5:  He has no power over YouTube TV zero.

1327
01:25:04,115 --> 01:25:07,175
Speaker 5:  He doesn't have power over YouTube either. Even though he keeps fronting

1328
01:25:07,175 --> 01:25:10,815
Speaker 5:  like he wants it, he keeps saying he's gonna, he personally will

1329
01:25:10,975 --> 01:25:14,135
Speaker 5:  reinterpret section two 30, which he has no authority to do.

1330
01:25:15,035 --> 01:25:18,055
Speaker 5:  But he keeps saying it keeps threatening it and now he's threatening YouTube

1331
01:25:18,115 --> 01:25:22,015
Speaker 5:  tv. And the lack of power over YouTube TV

1332
01:25:22,275 --> 01:25:24,335
Speaker 5:  is actually even more obvious,

1333
01:25:25,985 --> 01:25:29,975
Speaker 5:  right? His lack of power over the internet is you have to,

1334
01:25:29,975 --> 01:25:33,255
Speaker 5:  you have to jump through a bunch of hoops to explain it, right? You have

1335
01:25:33,255 --> 01:25:36,895
Speaker 5:  to say, well, yes, it's a federal communications commission. Yes, they have

1336
01:25:37,135 --> 01:25:40,735
Speaker 5:  some authority to regulate wireless services, they

1337
01:25:41,055 --> 01:25:44,255
Speaker 5:  allocate spectrum to star, like all this stuff, all this internety stuff.

1338
01:25:45,435 --> 01:25:48,215
Speaker 5:  But they don't have the authority to regulate the content on Instagram, which

1339
01:25:48,215 --> 01:25:51,335
Speaker 5:  is why it wants to reinterpret section two three, right? You have to like

1340
01:25:51,565 --> 01:25:54,815
Speaker 5:  wind your way to it, right? You have a difference. Yes, they regulate the

1341
01:25:55,085 --> 01:25:58,455
Speaker 5:  ISPs, but not really 'cause they got rid of net neutrality. Like you have

1342
01:25:58,455 --> 01:26:02,055
Speaker 5:  to construct this argument for why he doesn't have the power. But he,

1343
01:26:02,475 --> 01:26:06,295
Speaker 5:  the answer is because the FCC gave away the power here. The FCC

1344
01:26:06,295 --> 01:26:10,095
Speaker 5:  never had the power before. So If you think about why the FCC regulates cable

1345
01:26:10,375 --> 01:26:14,275
Speaker 5:  companies at all, there's a very wonky word for cable companies and satellite

1346
01:26:14,635 --> 01:26:18,495
Speaker 5:  companies, MVPs, multiple video programming distributors. I'm sorry,

1347
01:26:18,575 --> 01:26:22,455
Speaker 5:  I told you it was gonna get wonky. So the cable companies at the

1348
01:26:22,455 --> 01:26:25,895
Speaker 5:  outset, at the very beginning of cable, you had all these people in like

1349
01:26:25,895 --> 01:26:29,695
Speaker 5:  rural America who were getting crap network

1350
01:26:29,825 --> 01:26:32,575
Speaker 5:  broadcasts at their house. They would put up big antennas and then like,

1351
01:26:32,915 --> 01:26:35,975
Speaker 5:  you know, the CBS affiliate from the big city would like kind of come in

1352
01:26:36,275 --> 01:26:39,855
Speaker 5:  and it would be bad. So the original cable companies were kind of like

1353
01:26:40,215 --> 01:26:43,975
Speaker 5:  renegades, right? They would set up their own big antennas and then

1354
01:26:43,995 --> 01:26:47,455
Speaker 5:  run wires to all the houses in these rural areas. And they were basically

1355
01:26:47,615 --> 01:26:51,055
Speaker 5:  stealing the signals. And the history of cable is full of these big characters

1356
01:26:51,115 --> 01:26:54,815
Speaker 5:  who are basically doing piracy at scale, right? Weird.

1357
01:26:54,885 --> 01:26:58,575
Speaker 5:  Like that's just a weird history. And now they're big monopoly monoliths

1358
01:26:58,575 --> 01:27:02,335
Speaker 5:  and they hate me. But the history there is kind of like these like

1359
01:27:02,375 --> 01:27:05,575
Speaker 5:  Wildcats, like big, big colorful characters

1360
01:27:06,005 --> 01:27:09,935
Speaker 5:  setting up like community cable systems. Do you know how sometimes they

1361
01:27:09,935 --> 01:27:13,375
Speaker 5:  call cable cat tv? Yeah. Like, do you ever see that on the input on all tv?

1362
01:27:13,695 --> 01:27:16,415
Speaker 5:  That's community access television. And that's because is it really? I didn't

1363
01:27:16,415 --> 01:27:19,215
Speaker 5:  know that. That's fun fact. And that's because some guys would be like, screw

1364
01:27:19,215 --> 01:27:21,535
Speaker 5:  it. We're setting up a big antenna and running wires to everyone's house.

1365
01:27:22,505 --> 01:27:26,325
Speaker 5:  So this is where it came from. And the FCC is like, wait,

1366
01:27:26,385 --> 01:27:30,265
Speaker 5:  we regulate broadcast. And so the broadcast stations

1367
01:27:30,265 --> 01:27:33,345
Speaker 5:  are saying, hold on, you're, you're free writing on us. You're charging people

1368
01:27:33,345 --> 01:27:37,265
Speaker 5:  for access to our signals. The FCC gets involved and we end up in

1369
01:27:37,265 --> 01:27:41,065
Speaker 5:  this huge system where the FCC manages things. Like who

1370
01:27:41,065 --> 01:27:44,985
Speaker 5:  gets to retransmit, what stations, who gets to

1371
01:27:44,985 --> 01:27:48,305
Speaker 5:  bundle, what stuff? A big arbitration framework for

1372
01:27:48,765 --> 01:27:52,585
Speaker 5:  if some cable network wants to rerun a b, C programming, but A B, C

1373
01:27:52,585 --> 01:27:55,785
Speaker 5:  won't give them a license to it unless they pick up like a, B, c family and

1374
01:27:55,785 --> 01:27:59,625
Speaker 5:  the Disney channel. Now we have like a weird contract dispute. The FCC manages

1375
01:27:59,625 --> 01:28:03,615
Speaker 5:  all that, and that's all built out of these Wildcats basically

1376
01:28:03,775 --> 01:28:06,015
Speaker 5:  stealing broadcast signals and running them over wires to people's houses.

1377
01:28:06,595 --> 01:28:10,405
Speaker 5:  So you have this whole framework for all this built up. Okay,

1378
01:28:10,675 --> 01:28:14,485
Speaker 5:  fine. And that's, so the FCC has some authority over like traditional

1379
01:28:15,795 --> 01:28:19,085
Speaker 5:  MVPs, your direct TVs, your dish networks, your cable companies.

1380
01:28:20,155 --> 01:28:24,065
Speaker 5:  YouTube is not that. YouTube TV very

1381
01:28:24,545 --> 01:28:28,505
Speaker 5:  specifically is not that, right? They're, they're, they're a virtual MVPD,

1382
01:28:28,505 --> 01:28:30,705
Speaker 5:  which is a horrible name, but it basically means they're a cloud service,

1383
01:28:30,875 --> 01:28:34,825
Speaker 5:  right? So YouTube, the internet. The internet. So YouTube, so YouTube and

1384
01:28:34,825 --> 01:28:38,505
Speaker 5:  Google start YouTube tv and they're like, well, If you want to be

1385
01:28:38,605 --> 01:28:41,825
Speaker 5:  on our thing that feels like cable, you can be show up at our door. We we'll

1386
01:28:41,825 --> 01:28:45,065
Speaker 5:  cut you a deal. And the reason they were so cheap to begin with is they didn't

1387
01:28:45,065 --> 01:28:48,785
Speaker 5:  have all of this baggage of the traditional cable companies, right? All these

1388
01:28:48,785 --> 01:28:52,545
Speaker 5:  like pre-negotiated deals and they had immediate national

1389
01:28:52,825 --> 01:28:56,065
Speaker 5:  distribution, right? They didn't have to dig trenches and set up antennas,

1390
01:28:56,065 --> 01:28:59,505
Speaker 5:  right? They were running over the internet, right? So the FCC never had authority

1391
01:28:59,505 --> 01:29:03,195
Speaker 5:  over it. Like, it just is not the thing, like

1392
01:29:03,505 --> 01:29:07,195
Speaker 5:  there's, there's no part of YouTube TV where they're like capturing

1393
01:29:07,195 --> 01:29:10,875
Speaker 5:  signals from the air and rebroadcasting them. And you need this whole retransmission

1394
01:29:10,875 --> 01:29:14,715
Speaker 5:  consent regime. This is all like complicated telecom law

1395
01:29:14,715 --> 01:29:18,035
Speaker 5:  stuff, right? That no one cared about. 'cause YouTube TV is different and

1396
01:29:18,035 --> 01:29:21,635
Speaker 5:  new and they're allowed to pick and choose what channels they put on their

1397
01:29:21,635 --> 01:29:25,395
Speaker 5:  cable service the same way that, I don't know, whatever preloaded

1398
01:29:25,395 --> 01:29:28,995
Speaker 5:  Samsung fast TV service is allowed to pick and choose whatever

1399
01:29:28,995 --> 01:29:32,035
Speaker 5:  channels show up when you turn on Samsung TV for the first time. And that's

1400
01:29:32,035 --> 01:29:35,915
Speaker 5:  the market at work, right? In the, in the most direct way that is the free

1401
01:29:35,915 --> 01:29:38,875
Speaker 5:  market at work. How, what channels do you get for your 80 bucks a month for

1402
01:29:38,875 --> 01:29:42,635
Speaker 5:  YouTube TV that goes up every month is a decision YouTube gets to make in

1403
01:29:42,635 --> 01:29:45,875
Speaker 5:  the free market and consumers can decide whether or not to pay for it. So

1404
01:29:46,295 --> 01:29:49,955
Speaker 5:  you end up with should great American family

1405
01:29:50,775 --> 01:29:54,595
Speaker 5:  be on cable systems? In a time when cable systems were

1406
01:29:54,615 --> 01:29:58,595
Speaker 5:  the dominant provider of video services, the FCC

1407
01:29:58,595 --> 01:30:02,115
Speaker 5:  had this like interest, it wasn't really played out, it wasn't really flushed

1408
01:30:02,115 --> 01:30:06,075
Speaker 5:  out, right? The interest was based on how do people get the broadcast networks,

1409
01:30:06,075 --> 01:30:09,435
Speaker 5:  it's the cable systems, are the cable systems running well because they,

1410
01:30:09,505 --> 01:30:13,435
Speaker 5:  they're such a monopoly provider of information. The FCC is like, all right,

1411
01:30:13,435 --> 01:30:16,155
Speaker 5:  we're gonna make sure the bundles are equal, blah, blah, blah. YouTube is

1412
01:30:16,155 --> 01:30:20,035
Speaker 5:  not that. YouTube operates in the YouTube TV operates in the, the biggest,

1413
01:30:20,545 --> 01:30:24,275
Speaker 5:  most vibrant market of video programming services that has ever existed

1414
01:30:24,335 --> 01:30:27,995
Speaker 5:  in world history. If you want great American family, you know what you can

1415
01:30:27,995 --> 01:30:31,035
Speaker 5:  do? You can leave YouTube TV and sign up for fubu, any of

1416
01:30:31,035 --> 01:30:31,515
Speaker 6:  The other ones

1417
01:30:31,515 --> 01:30:35,355
Speaker 5:  Like that, right? Like in one second on your phone, you can just do it.

1418
01:30:35,355 --> 01:30:38,755
Speaker 5:  You can sign up for Sling or Hulu. You can maybe pay them directly.

1419
01:30:39,105 --> 01:30:42,515
Speaker 5:  There's no, there's no plausible interest for the

1420
01:30:42,535 --> 01:30:46,475
Speaker 5:  United States government to regulate the market in this case. And what

1421
01:30:46,475 --> 01:30:50,305
Speaker 5:  makes it particularly galling is at the same, in

1422
01:30:50,305 --> 01:30:54,125
Speaker 5:  the same breath, Brendan Carr is saying, list

1423
01:30:54,125 --> 01:30:57,565
Speaker 5:  every regulation I should remove. So the market is more vibrant. You know

1424
01:30:57,565 --> 01:31:01,285
Speaker 5:  what regulation you should remove Brendan yourself, you should

1425
01:31:01,325 --> 01:31:04,405
Speaker 5:  stop meddling in the free market of information on the

1426
01:31:05,145 --> 01:31:06,085
Speaker 5:  internet. You should go away.

1427
01:31:06,395 --> 01:31:09,525
Speaker 6:  Well, and he's not even pretending in any meaningful way that this is about

1428
01:31:10,355 --> 01:31:14,245
Speaker 6:  free markets, it's just about speech. Yeah. Like the whole YouTube

1429
01:31:14,345 --> 01:31:18,085
Speaker 6:  TV thing is not, he's not accusing YouTube TV of being a monopoly or

1430
01:31:18,555 --> 01:31:22,365
Speaker 6:  abusing its power against, its just pure censorship discussion.

1431
01:31:22,595 --> 01:31:26,005
Speaker 5:  Yeah. He's, he wants to put pressure on Google to moderate YouTube,

1432
01:31:26,315 --> 01:31:29,765
Speaker 5:  like big YouTube the way that he wants. And so the way he's gonna do that

1433
01:31:30,105 --> 01:31:33,405
Speaker 5:  is by saying Google is unfairly discriminating against its faith based programming

1434
01:31:33,405 --> 01:31:37,045
Speaker 5:  on YouTube TV over which he has zero and I mean

1435
01:31:37,175 --> 01:31:41,005
Speaker 5:  truly zero authority, right? In a way that it is

1436
01:31:41,005 --> 01:31:44,805
Speaker 5:  easier to make an argument that he has authority over the internet. I

1437
01:31:45,075 --> 01:31:48,315
Speaker 5:  don't, he doesn't. But it is actually easier to make that argument

1438
01:31:48,785 --> 01:31:52,515
Speaker 5:  because he had, he could in another world, would have had

1439
01:31:52,515 --> 01:31:56,475
Speaker 5:  authority over the ISPs. But YouTube TV is a thing that

1440
01:31:56,475 --> 01:32:00,405
Speaker 5:  exists outside of the f SEC's, historic frameworks for

1441
01:32:00,405 --> 01:32:04,165
Speaker 5:  how cable companies are regulated in a way that he, he should, and there's

1442
01:32:04,165 --> 01:32:07,715
Speaker 5:  competition, right? Like you, you can just get Comcast,

1443
01:32:07,905 --> 01:32:11,555
Speaker 5:  dude, like, it, it exists. Like it's there, it's right there for consumers.

1444
01:32:11,555 --> 01:32:15,235
Speaker 5:  If they want these channels, they can switch away from YouTube tv. And if

1445
01:32:15,235 --> 01:32:18,275
Speaker 5:  there exists any of that market competition, it is completely

1446
01:32:18,545 --> 01:32:21,995
Speaker 5:  inappropriate for the government to step in and say, I want information,

1447
01:32:22,075 --> 01:32:25,865
Speaker 5:  I want you to answer to me. Especially at the same time where

1448
01:32:25,965 --> 01:32:29,785
Speaker 5:  it just, in like in a different tweet, he's like, what regulations do I need

1449
01:32:29,785 --> 01:32:31,305
Speaker 5:  to get rid of to make the market more competitive?

1450
01:32:32,575 --> 01:32:33,505
Speaker 6:  Fire yourself.

1451
01:32:34,535 --> 01:32:38,105
Speaker 5:  Like I, it's just, it is, it is the most blinding

1452
01:32:38,105 --> 01:32:41,505
Speaker 5:  hypocrisy from this fan week in and week out, and all of it is

1453
01:32:41,505 --> 01:32:45,265
Speaker 5:  incoherent and all of it only serves to increase his

1454
01:32:45,285 --> 01:32:48,825
Speaker 5:  own power as opposed to making the markets more efficient, to making the

1455
01:32:48,825 --> 01:32:52,025
Speaker 5:  networks more trusted. That would be a, that, that's a good goal, right?

1456
01:32:52,285 --> 01:32:55,905
Speaker 5:  You want more Americans to perceive that the information networks that they

1457
01:32:55,955 --> 01:32:59,865
Speaker 5:  exist in are unbiased or delivering more fair or accurate information. Sure.

1458
01:32:59,965 --> 01:33:03,745
Speaker 5:  Or that the processes by which content is taken down or removed or has

1459
01:33:04,105 --> 01:33:07,105
Speaker 5:  fuddled are fair and understandable. Like those are all good things,

1460
01:33:08,235 --> 01:33:11,335
Speaker 5:  but he's just about power. And you can see it in the course of two tweets.

1461
01:33:11,605 --> 01:33:14,495
Speaker 5:  He's like, I'm demanding this private company over which I have no authority

1462
01:33:15,915 --> 01:33:19,495
Speaker 5:  answer to me. Also, I think the market should be more open and have less

1463
01:33:19,495 --> 01:33:23,335
Speaker 5:  regulation. Well, dude, solve your problem. Get rid of yourself, or come

1464
01:33:23,335 --> 01:33:24,895
Speaker 5:  on decoder, I'll fire you on decoder.

1465
01:33:25,655 --> 01:33:28,975
Speaker 6:  I will say I really enjoyed, I very rarely enjoy a company

1466
01:33:29,575 --> 01:33:33,335
Speaker 6:  response to something. But this one I very much enjoyed from

1467
01:33:33,915 --> 01:33:37,775
Speaker 6:  Audrey Lopez at YouTube who said, we welcome the opportunity to brief the

1468
01:33:37,775 --> 01:33:41,095
Speaker 6:  f CCC on YouTube TV's subscription service and the strategic business decisions

1469
01:33:41,095 --> 01:33:44,535
Speaker 6:  we make, we make based on factors like user demand, operational costs, and

1470
01:33:44,535 --> 01:33:47,175
Speaker 6:  financial terms that a bunch of other stuff, which is just a long way of

1471
01:33:47,175 --> 01:33:48,975
Speaker 6:  saying we don't have this because no one wants it.

1472
01:33:50,205 --> 01:33:50,495
Speaker 5:  Like

1473
01:33:51,715 --> 01:33:55,255
Speaker 6:  If, if there were a market reason for us to have this channel, we'd have

1474
01:33:55,255 --> 01:33:58,055
Speaker 6:  this channel. I mean, this is like every time we get a carriage dispute,

1475
01:33:58,055 --> 01:34:00,655
Speaker 6:  right? Like I find carriage disputes really fascinating for exactly this

1476
01:34:00,655 --> 01:34:04,615
Speaker 6:  reason, because it is purely about a company

1477
01:34:04,805 --> 01:34:08,455
Speaker 6:  with content that people want trying to get a

1478
01:34:08,455 --> 01:34:11,575
Speaker 6:  distributor to pay as much as possible for it. And the distributor, it's

1479
01:34:11,575 --> 01:34:15,415
Speaker 6:  like perfect supply and demand economic bargaining. And I find

1480
01:34:15,415 --> 01:34:18,575
Speaker 6:  it so fascinating. And in this case, like it's actually just YouTube is like,

1481
01:34:18,795 --> 01:34:21,455
Speaker 6:  no one wants this and we'd have to pay them for it. Why would we pay them

1482
01:34:21,455 --> 01:34:22,855
Speaker 6:  for it? Yeah. It's just that simple.

1483
01:34:23,115 --> 01:34:26,695
Speaker 5:  And it's funny 'cause in a different, if I described to you how cable company

1484
01:34:26,695 --> 01:34:30,655
Speaker 5:  negotiations work up at the FCC, I think most of our younger

1485
01:34:30,885 --> 01:34:34,815
Speaker 5:  listeners or viewers on YouTube would be utterly perplexed

1486
01:34:35,255 --> 01:34:38,815
Speaker 5:  that the government is involved. Yeah. Right? That they're o there used to

1487
01:34:38,815 --> 01:34:42,375
Speaker 5:  only be three major broadcast networks the entire country and people set

1488
01:34:42,375 --> 01:34:45,775
Speaker 5:  up antennas, and then when the cable company showed up, the government showed

1489
01:34:45,775 --> 01:34:48,335
Speaker 5:  up and said, you have to carry the broadcast networks.

1490
01:34:49,425 --> 01:34:53,335
Speaker 5:  Weird. That's just a weird thing that's embedded in the history of our telecom

1491
01:34:53,355 --> 01:34:56,575
Speaker 5:  law, that we have these things called must carry provisions. And because

1492
01:34:56,575 --> 01:34:59,705
Speaker 5:  of the must carry provisions, the broadcast networks can get bigger and have

1493
01:34:59,705 --> 01:35:03,345
Speaker 5:  more channels and demand other channels get carried by these cable companies.

1494
01:35:03,405 --> 01:35:07,385
Speaker 5:  And you end up in this situation where the United States government is resolving

1495
01:35:07,385 --> 01:35:11,145
Speaker 5:  a dispute about the tennis channel. This is a real thing

1496
01:35:11,345 --> 01:35:11,865
Speaker 5:  that happened. That's

1497
01:35:11,865 --> 01:35:11,985
Speaker 6:  Awesome.

1498
01:35:12,405 --> 01:35:14,745
Speaker 5:  And that just doesn't happen on the internet.

1499
01:35:14,985 --> 01:35:18,105
Speaker 6:  I do think everyone should be required to watch tennis. So I'm, I'm, I'm

1500
01:35:18,225 --> 01:35:18,585
Speaker 6:  actually good with

1501
01:35:18,585 --> 01:35:21,705
Speaker 5:  That one. But you just, you see that kind of stuff play out in the history

1502
01:35:21,705 --> 01:35:25,285
Speaker 5:  of telecom because there was so much scarcity, right? So the government had

1503
01:35:25,285 --> 01:35:28,525
Speaker 5:  this interest in saying, okay, we've, we've got these three big national

1504
01:35:28,525 --> 01:35:32,165
Speaker 5:  broadcast networks, we know they touch everyone in the country. The cable

1505
01:35:32,485 --> 01:35:36,085
Speaker 5:  companies have to carry them, right? That's a lot. Like, that's a big

1506
01:35:36,555 --> 01:35:40,125
Speaker 5:  step into what the government says about the information you receive.

1507
01:35:40,545 --> 01:35:44,525
Speaker 5:  And that made sense in the, in the previous era. It makes no sense in the

1508
01:35:44,525 --> 01:35:48,405
Speaker 5:  modern era. And I, I think most people, if, if we showed up and said

1509
01:35:48,425 --> 01:35:52,365
Speaker 5:  to YouTube, you have to carry Mr. Beast. Like most people

1510
01:35:52,365 --> 01:35:55,205
Speaker 5:  are like, what are you talking about? Right? Like, that doesn't make any

1511
01:35:55,205 --> 01:35:58,765
Speaker 5:  sense. Right. You can go, I just see Brendan trying to bring us back to that

1512
01:35:58,785 --> 01:36:02,715
Speaker 5:  era, but doing it incoherently and without any

1513
01:36:02,805 --> 01:36:06,035
Speaker 5:  point except his own power. Yep. So like I said, Brendan, I know you listen,

1514
01:36:06,155 --> 01:36:09,355
Speaker 5:  I know you're gonna get the Google alerts. Here's one for you Brendan. Brendan

1515
01:36:09,355 --> 01:36:12,795
Speaker 5:  Carr is a coward. That's just the thing I say on the show every week. You

1516
01:36:12,795 --> 01:36:14,955
Speaker 5:  can come onto coder, you can defend this stuff. You can try to make it make

1517
01:36:14,955 --> 01:36:18,635
Speaker 5:  sense. I'll give you the shot. I, I'm just well prepared

1518
01:36:19,445 --> 01:36:23,385
Speaker 5:  and I know you so good luck. But you're welcome anytime you want.

1519
01:36:24,815 --> 01:36:28,115
Speaker 5:  All right. We we got a, we need a, we need a pal Clean David.

1520
01:36:28,625 --> 01:36:31,555
Speaker 6:  Yeah. All right. I have, I have three more for you and then we're gonna get

1521
01:36:31,555 --> 01:36:35,475
Speaker 6:  outta here. Yeah. Thing number one, TikTok did a

1522
01:36:35,475 --> 01:36:39,395
Speaker 6:  thing I think is sort of interesting, which is everybody is forever

1523
01:36:39,735 --> 01:36:43,635
Speaker 6:  trying to come up with ways to like make their platforms less

1524
01:36:43,955 --> 01:36:47,835
Speaker 6:  horrible for teenagers. And basically TikTok now

1525
01:36:47,975 --> 01:36:51,955
Speaker 6:  has a sort of, it's a parental control thing that essentially

1526
01:36:51,955 --> 01:36:55,475
Speaker 6:  starts to wind you down off of TikTok starting at 10:00

1527
01:36:56,255 --> 01:36:59,955
Speaker 6:  PM So it gives teens a reminder that's basically like it's late get off and

1528
01:37:00,295 --> 01:37:03,835
Speaker 6:  then starts to play you out. Essentially. It's like the Oscar's music where

1529
01:37:03,835 --> 01:37:07,795
Speaker 6:  it just like plays you off the stage of TikTok. I think this is a great idea

1530
01:37:07,915 --> 01:37:11,395
Speaker 6:  and I think this is a thing that I would also, like for me, an adult who

1531
01:37:11,395 --> 01:37:15,315
Speaker 6:  should not be looking at TikTok after 10:00 PM but I think,

1532
01:37:15,315 --> 01:37:18,955
Speaker 6:  like, I've been talking to a lot of people about the, the sort

1533
01:37:19,025 --> 01:37:22,075
Speaker 6:  of regulatory environment about this stuff for years. And Lauren Finer does

1534
01:37:22,075 --> 01:37:23,675
Speaker 6:  a really good job of covering a lot of that stuff for us and

1535
01:37:25,475 --> 01:37:29,235
Speaker 6:  watching all of these platforms, just like flail to figure out features

1536
01:37:29,415 --> 01:37:33,155
Speaker 6:  to make themselves a slightly better experience, especially for young

1537
01:37:33,155 --> 01:37:36,395
Speaker 6:  users, is just really complicated and really interesting. And I actually

1538
01:37:36,395 --> 01:37:39,635
Speaker 6:  think this is like a smart idea from TikTok that it's just like, we're just

1539
01:37:39,635 --> 01:37:42,915
Speaker 6:  going to make it harder and harder for you to use this app because you should

1540
01:37:42,915 --> 01:37:43,475
Speaker 6:  go to bed.

1541
01:37:44,465 --> 01:37:46,235
Speaker 5:  It's time for bed. Totally hard,

1542
01:37:46,575 --> 01:37:49,795
Speaker 6:  Not totally hard, but harder. And I'll, I'll take that.

1543
01:37:49,875 --> 01:37:53,635
Speaker 5:  I think a lot of parents would accept the hard 10:00 PM curfew on, on

1544
01:37:53,635 --> 01:37:54,155
Speaker 5:  a TikTok account

1545
01:37:54,795 --> 01:37:54,875
Speaker 6:  Probably.

1546
01:37:56,665 --> 01:38:00,565
Speaker 5:  But Casey Newton had this great line about TikTok this week, writing

1547
01:38:00,565 --> 01:38:03,805
Speaker 5:  about this. He said, TikTok is now in quantum super positioned,

1548
01:38:04,555 --> 01:38:06,405
Speaker 5:  there's a TikTok that's illegal. That's

1549
01:38:06,405 --> 01:38:06,845
Speaker 6:  Good. Yeah.

1550
01:38:07,515 --> 01:38:10,415
Speaker 5:  And then there's a TikTok that exists in is shipping features for teens in

1551
01:38:10,415 --> 01:38:10,655
Speaker 5:  America.

1552
01:38:11,295 --> 01:38:14,415
Speaker 6:  I would say, I forget about the TikTok band like every three days, you know

1553
01:38:14,415 --> 01:38:17,135
Speaker 6:  what I mean? Yeah. It's like I just, I just sort of look around and I'm like,

1554
01:38:17,135 --> 01:38:19,375
Speaker 6:  oh, right. TikTok iss gonna get banned. Like it's

1555
01:38:19,375 --> 01:38:21,335
Speaker 5:  Banned. It's well, it's banned.

1556
01:38:21,435 --> 01:38:22,495
Speaker 6:  That's true. It's technically

1557
01:38:22,495 --> 01:38:25,415
Speaker 5:  Banned. The laws passed. Yeah. The Supreme Court said it was constitutional.

1558
01:38:26,035 --> 01:38:27,815
Speaker 5:  Donald Trump is just not enforcing it.

1559
01:38:28,335 --> 01:38:31,735
Speaker 6:  I know we've talked about this already, but the, the first week of April

1560
01:38:32,045 --> 01:38:35,415
Speaker 6:  when all the tariff stuff comes crashing back down and the TikTok ban

1561
01:38:36,475 --> 01:38:40,225
Speaker 6:  delay ends is like, it's gonna be weird times in America.

1562
01:38:40,365 --> 01:38:44,025
Speaker 6:  We might not, the government might be closed by the, like, who stuff's gonna

1563
01:38:44,025 --> 01:38:47,505
Speaker 6:  get real weird here. Thing number two that I just think is really interesting

1564
01:38:47,505 --> 01:38:51,425
Speaker 6:  is Niantic, the company that makes Pokemon Go and a bunch of other

1565
01:38:51,425 --> 01:38:55,305
Speaker 6:  stuff sold all of its gaming business to Scopely,

1566
01:38:55,305 --> 01:38:59,145
Speaker 6:  which is a like old social gaming company that I think is now owned by

1567
01:39:00,315 --> 01:39:04,245
Speaker 6:  some Saudi government company thing that

1568
01:39:04,285 --> 01:39:08,245
Speaker 6:  I don't pretend to totally understand, but I, I just have been

1569
01:39:08,405 --> 01:39:12,325
Speaker 6:  obsessed with Niantic for like years. Pokemon Go, I think remains like the

1570
01:39:12,325 --> 01:39:16,045
Speaker 6:  most interesting ar experiment anyone has done yet and was a huge

1571
01:39:16,045 --> 01:39:19,645
Speaker 6:  giant hit. And then they tried to do it a bunch more times and none of it

1572
01:39:19,645 --> 01:39:22,485
Speaker 6:  worked. Yeah. No one cared. There was like the Harry Potter game that people

1573
01:39:22,485 --> 01:39:25,965
Speaker 6:  were really excited about. There was the, the one with the characters with

1574
01:39:25,965 --> 01:39:29,925
Speaker 6:  the flowers coming outta their head that I can't remember the name of, but

1575
01:39:30,475 --> 01:39:34,085
Speaker 6:  like Niantic was like way out in front of this idea of like, what, how do

1576
01:39:34,085 --> 01:39:37,965
Speaker 6:  we make stuff that is fun on top of the real world and just never,

1577
01:39:37,965 --> 01:39:41,365
Speaker 6:  it turns out it was just Pokemon and they just never, they just never found

1578
01:39:41,365 --> 01:39:41,605
Speaker 6:  the next thing.

1579
01:39:41,635 --> 01:39:43,645
Speaker 5:  Well, they never found the next thing and they never figured out what to

1580
01:39:43,645 --> 01:39:47,245
Speaker 5:  do with the enormous amount of data they collected from all those PokemonGo

1581
01:39:47,245 --> 01:39:50,965
Speaker 5:  users. Like Right. Nantec was building a world map and they were clever

1582
01:39:51,025 --> 01:39:54,605
Speaker 5:  to the point where if they found a place where they didn't have

1583
01:39:54,805 --> 01:39:58,585
Speaker 5:  sufficient data, they would put Pokemon there and then people

1584
01:39:58,585 --> 01:40:01,945
Speaker 5:  would go and map that location. And I don't think that anyone figured out

1585
01:40:01,945 --> 01:40:04,985
Speaker 5:  what that was for. Like it was very clever, like in that way it's like, do

1586
01:40:04,985 --> 01:40:08,825
Speaker 5:  you know Go is secretly data collection? And it's like, yes, what's gonna

1587
01:40:08,825 --> 01:40:09,425
Speaker 5:  happen? And

1588
01:40:09,425 --> 01:40:12,985
Speaker 6:  There's some of that stuff. Niantic still owns some of that. Yeah. Like it,

1589
01:40:12,985 --> 01:40:16,785
Speaker 6:  it kept a couple of its games and a bunch of the mapping stuff. So

1590
01:40:16,855 --> 01:40:19,705
Speaker 6:  it's the Yeah. The thing they've been saying, which is basically where like

1591
01:40:19,905 --> 01:40:23,865
Speaker 6:  building an ar map of the world is now their

1592
01:40:24,065 --> 01:40:28,025
Speaker 6:  only move left, which is really interesting. Like I, there was a

1593
01:40:28,375 --> 01:40:31,825
Speaker 6:  Pokemon Go was just like floated forever until they figured out the next

1594
01:40:31,825 --> 01:40:35,025
Speaker 6:  thing and now they like really have to go figure out this next thing. Yeah.

1595
01:40:35,405 --> 01:40:38,625
Speaker 6:  And I, I don't know what it's gonna be, but we'll see. All right. I have

1596
01:40:38,625 --> 01:40:42,225
Speaker 6:  one more for you. Well, I have one and a half. Okay.

1597
01:40:43,325 --> 01:40:43,825
Speaker 6:  The one

1598
01:40:45,355 --> 01:40:48,215
Speaker 6:  is that home assistant now supports matter, and I know this is big for you,

1599
01:40:48,315 --> 01:40:51,375
Speaker 6:  so I just wanted to give you a moment. I'm very this, to really talk about

1600
01:40:51,375 --> 01:40:51,495
Speaker 6:  this.

1601
01:40:51,885 --> 01:40:55,825
Speaker 5:  Well, it's certified. They, I think it was, it was like

1602
01:40:55,885 --> 01:40:58,625
Speaker 5:  not officially supported before. I mean that's basically what Paul was telling

1603
01:40:58,625 --> 01:41:02,305
Speaker 5:  us and he said it's now officially supported. The certification was

1604
01:41:02,305 --> 01:41:04,545
Speaker 5:  complicated. It's a cherry on the cake. That's the quote.

1605
01:41:06,215 --> 01:41:09,905
Speaker 5:  This is good. I I have a home assistant green box now just sitting here.

1606
01:41:10,005 --> 01:41:13,385
Speaker 5:  I'm, I'm thinking about swapping out my home bridge for home assistant only

1607
01:41:13,385 --> 01:41:17,185
Speaker 5:  because we have these very complicated smart vents that open

1608
01:41:17,185 --> 01:41:20,065
Speaker 5:  and close to try to make all the rooms in the house the same temperature.

1609
01:41:20,415 --> 01:41:23,865
Speaker 5:  It's like the podcast studio I'm sitting here isn't, is in our attic. So

1610
01:41:23,885 --> 01:41:26,745
Speaker 5:  in the winter it's very cold up here, but I don't wanna run the heat and

1611
01:41:27,055 --> 01:41:30,665
Speaker 5:  burn out the family. So we have these vents that open and close and home

1612
01:41:30,785 --> 01:41:33,265
Speaker 5:  assistant can run them locally instead of going to the cloud.

1613
01:41:33,725 --> 01:41:34,505
Speaker 6:  Oh, all right.

1614
01:41:34,815 --> 01:41:38,265
Speaker 5:  Yeah, none of this has anything to do with matter. I'm just saying you can

1615
01:41:38,265 --> 01:41:41,945
Speaker 5:  see how Home Assistant is like, there's a server in my house that runs everything.

1616
01:41:42,325 --> 01:41:45,305
Speaker 5:  Having official matter integration, that's all of that stuff run locally

1617
01:41:45,325 --> 01:41:46,305
Speaker 5:  and I think that's cool, right?

1618
01:41:46,695 --> 01:41:49,425
Speaker 6:  Yeah. Home assistant continues to be

1619
01:41:50,415 --> 01:41:53,105
Speaker 6:  more impressive, I think, than I gave it credit for for a long time. I was

1620
01:41:53,105 --> 01:41:56,705
Speaker 6:  always like, home assistant is like the raspberry pie of the smart home world.

1621
01:41:56,735 --> 01:42:00,345
Speaker 6:  It's like, it's a thing for people who want to tinker and that's about it.

1622
01:42:00,345 --> 01:42:03,545
Speaker 6:  And they're like pushing further and further down into just like, put this

1623
01:42:03,545 --> 01:42:05,705
Speaker 6:  in your house, that'll be fine. I think that's pretty

1624
01:42:06,025 --> 01:42:09,385
Speaker 5:  Powerful. You wanna, I I I, we talked about Amazon and

1625
01:42:09,755 --> 01:42:13,465
Speaker 5:  Apple and all their smart home stuff and on AI stuff and a all of that kind

1626
01:42:13,465 --> 01:42:17,225
Speaker 5:  of requires you just believe that those services will run in the cloud and

1627
01:42:17,225 --> 01:42:19,865
Speaker 5:  be reliable for you, right. For a long time. And home assistance. Like what

1628
01:42:19,865 --> 01:42:22,345
Speaker 5:  If you just had a computer in your house that was there?

1629
01:42:22,615 --> 01:42:25,985
Speaker 6:  Yeah. That just only did those things. Yeah. Yeah. I'm into that.

1630
01:42:26,605 --> 01:42:30,345
Speaker 6:  And then last one, did you see Jay Grabber's t-shirt? I

1631
01:42:30,515 --> 01:42:32,385
Speaker 6:  truly the greatest thing that happened all week

1632
01:42:32,585 --> 01:42:35,665
Speaker 5:  And now that I think Blue Sky's gonna sell it. So Zuckerberg wore a shirt

1633
01:42:35,885 --> 01:42:37,385
Speaker 5:  at Meta Connect, right? That said,

1634
01:42:37,625 --> 01:42:38,225
Speaker 6:  I believe so. Yeah.

1635
01:42:38,805 --> 01:42:42,785
Speaker 5:  It said Zucker nothing in Latin. And so Jay Grabber's shirt at at South

1636
01:42:42,785 --> 01:42:46,705
Speaker 5:  by Southwest said, man C which mean a world without Caesars.

1637
01:42:46,705 --> 01:42:48,665
Speaker 5:  And now they are fully selling that shirt.

1638
01:42:48,695 --> 01:42:51,905
Speaker 6:  Spectacular. I have no notes. They were giving away stickers. I think that

1639
01:42:51,905 --> 01:42:55,025
Speaker 6:  said the same thing at South By Extremely Good

1640
01:42:55,645 --> 01:42:58,865
Speaker 5:  Is good. We're still working at Feder years. It's very complicated.

1641
01:43:00,095 --> 01:43:03,905
Speaker 5:  Accepting the fire hose of incoming social media content.

1642
01:43:04,045 --> 01:43:05,305
Speaker 5:  If you federate a quick post,

1643
01:43:07,055 --> 01:43:10,425
Speaker 5:  it's not small. It turns out turning your, your website into a social network

1644
01:43:11,155 --> 01:43:14,745
Speaker 5:  moderation challenge is abound. Yeah, but we're we're, we are still focused

1645
01:43:14,745 --> 01:43:15,585
Speaker 5:  on it. Yeah.

1646
01:43:15,745 --> 01:43:19,185
Speaker 6:  There's something that And Blue Sky One, I will say one deeply fascinating

1647
01:43:19,185 --> 01:43:21,385
Speaker 6:  thing that happened this week was X had a huge outage

1648
01:43:23,125 --> 01:43:26,025
Speaker 6:  and everybody went to Blue Sky. Yeah. Like all the, it was

1649
01:43:27,145 --> 01:43:30,865
Speaker 6:  X went down right as NFL Free Agency started, and it just

1650
01:43:31,015 --> 01:43:34,945
Speaker 6:  like that flipped to Blue Sky. And I thought that was so interesting that

1651
01:43:34,945 --> 01:43:38,825
Speaker 6:  like my threads did not get more exciting, but all of a sudden, like a million

1652
01:43:38,825 --> 01:43:42,145
Speaker 6:  sports reporters I know were just appearing in Blue Sky.

1653
01:43:42,845 --> 01:43:46,345
Speaker 6:  And Mina Kimes, who works at ESPN, had this like starter pack of

1654
01:43:46,575 --> 01:43:50,425
Speaker 6:  blue sky sports people and that blew up. And it was like, yet another, like

1655
01:43:50,425 --> 01:43:54,285
Speaker 6:  Blue Sky has, has the juice kind of moments that it's like every time X gets

1656
01:43:54,325 --> 01:43:57,405
Speaker 6:  a little worse, blue sky gets a little better and X gets a little worse a

1657
01:43:57,405 --> 01:44:01,205
Speaker 6:  lot. And so it was, it was just another one that

1658
01:44:01,205 --> 01:44:02,925
Speaker 6:  it's like Blue sky's. Blue Sky's for real.

1659
01:44:03,545 --> 01:44:06,325
Speaker 5:  All right. Can I add one? It it's Trump related, but in the funniest way.

1660
01:44:06,585 --> 01:44:07,165
Speaker 6:  All right. I'll allow,

1661
01:44:08,785 --> 01:44:12,245
Speaker 5:  Mia wrote about this this week. There's a Trump official

1662
01:44:12,915 --> 01:44:16,485
Speaker 5:  ibel, I believe in one of the offices that's firing everybody, like in the

1663
01:44:16,485 --> 01:44:20,365
Speaker 5:  Office of Personal Management. She is also a very, very bad

1664
01:44:20,365 --> 01:44:23,925
Speaker 5:  fashion influencer. And she's been doing Get Ready with me

1665
01:44:24,305 --> 01:44:26,765
Speaker 5:  in the Office while she's firing people.

1666
01:44:28,055 --> 01:44:31,705
Speaker 5:  It's very bad, but like very bad in a way that is just

1667
01:44:31,705 --> 01:44:33,265
Speaker 5:  indicative of how everything else is bad.

1668
01:44:33,495 --> 01:44:36,865
Speaker 6:  Yeah. She's like, I need, she needs a side hustle too. She's like, I don't

1669
01:44:36,865 --> 01:44:40,585
Speaker 6:  know, maybe I'm gonna get fired by Doge one of these days, so I gotta got

1670
01:44:40,585 --> 01:44:43,305
Speaker 6:  outta side hustle. But it's very good. It's, it's pretty bad. It's, it's

1671
01:44:43,305 --> 01:44:47,145
Speaker 5:  Pretty bad. And Mia's Post is, is scathing and, and the best,

1672
01:44:47,165 --> 01:44:49,585
Speaker 5:  in the best possible VERGE way. So I encourage people to read.

1673
01:44:49,695 --> 01:44:52,905
Speaker 6:  This is the thing that I saw somebody just like posted a link in Slack and

1674
01:44:52,905 --> 01:44:56,505
Speaker 6:  it was like, you, you could tell the, like the Mia Siren had just been activated

1675
01:44:56,745 --> 01:45:00,705
Speaker 6:  and Mia just came in and was like, I know what to do with this. That's

1676
01:45:00,705 --> 01:45:01,025
Speaker 6:  good stuff.

1677
01:45:01,585 --> 01:45:05,305
Speaker 5:  M had a great line. She referred to her outfits as Sears catalog esque.

1678
01:45:06,045 --> 01:45:09,985
Speaker 5:  Oof. It's rough. Brutal. That's rough. Every

1679
01:45:10,005 --> 01:45:13,585
Speaker 5:  now and in our policy desk just let's, let's let's it out and you can see

1680
01:45:13,585 --> 01:45:17,505
Speaker 5:  it. All right. That's it. We've gone way over. This episode's been six hours

1681
01:45:17,505 --> 01:45:20,985
Speaker 5:  long. I think I was in a fugue state talking to Brendan car this week. That

1682
01:45:20,985 --> 01:45:21,705
Speaker 5:  was yesterday. That's

1683
01:45:21,705 --> 01:45:22,345
Speaker 6:  What the people come for.

1684
01:45:22,805 --> 01:45:25,225
Speaker 5:  That's, that's what we saw here. Brendan, you're you're welcome. Anytime.

1685
01:45:25,395 --> 01:45:29,145
Speaker 5:  Thank you to Andy. Poor Andy. Every time I talk to him lately I'm like, so

1686
01:45:30,255 --> 01:45:33,665
Speaker 5:  what disaster are we talking about? Thanks Andy, for coming on.

1687
01:45:34,185 --> 01:45:35,585
Speaker 5:  That's it. That's for Cast Rockwell.

1688
01:45:40,765 --> 01:45:44,145
Speaker 7:  And that's it for The Verge Cast this week. And hey, we'd love to hear from

1689
01:45:44,145 --> 01:45:47,745
Speaker 7:  you. Give us a call at eight six six VERGE

1690
01:45:47,925 --> 01:45:51,425
Speaker 7:  one one. The Vergecast is a production of The Verge and the Vox Media

1691
01:45:51,765 --> 01:45:55,625
Speaker 7:  podcast network. Our show is produced by Will Por, Eric Gomez and

1692
01:45:55,625 --> 01:45:56,785
Speaker 7:  Brandon Keefer. And that's it. We'll see you next week.

