1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 32bdeb18-b91b-44c8-8a74-2cb7e0b8d231
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-3233055384296376916/2643788504243560110/s93290-US-5287s-1736855475.mp3
Description: In five days, TikTok as we know it could be finished in the US. The Verge's Lauren Feiner joins the show to discuss last week's Supreme Court arguments over the ban, why things don't look good for TikTok, and what's likely to happen in the next five days. After that, Kickstarter CEO Everette Taylor talks about the state of the gadget inventor, and what it means to be part of the creator economy in 2025. Finally, we answer a question from the Vergecast Hotline about magic-link logins, and why passwords remain such a disaster.

2
00:00:03,345 --> 00:00:07,195
Speaker 2:  Welcome To The Vergecast, the flagship podcast of Crowdfunded

3
00:00:07,335 --> 00:00:11,315
Speaker 2:  Sox. I'm your friend David Pierce, and it is five 30 in the morning and I

4
00:00:11,315 --> 00:00:15,155
Speaker 2:  am in the Charlotte, North Carolina airport on my way home from CES.

5
00:00:15,375 --> 00:00:18,955
Speaker 2:  It was really fun, CES this year actually. It wasn't like the Newsiest or

6
00:00:19,085 --> 00:00:23,075
Speaker 2:  Splashiest CES of all time, but AI was everywhere. Even though no

7
00:00:23,075 --> 00:00:26,955
Speaker 2:  one knows what to do with ai, there were tons of wearables. The health

8
00:00:26,955 --> 00:00:30,835
Speaker 2:  tech I actually thought was really interesting. Pool robots for some reason

9
00:00:31,225 --> 00:00:34,915
Speaker 2:  were absolutely everywhere. I don't know how much interesting

10
00:00:34,915 --> 00:00:38,235
Speaker 2:  technology there is in the pool robot space. If you're into that, let me

11
00:00:38,235 --> 00:00:42,075
Speaker 2:  know. I'd love to hear it. But they were absolutely everywhere. Super fun

12
00:00:42,075 --> 00:00:45,475
Speaker 2:  show. And by the way, thank you to everybody who came out to our live vergecast

13
00:00:45,895 --> 00:00:49,795
Speaker 2:  at CES. It was super fun just to get to hang out with all of you and talk

14
00:00:49,795 --> 00:00:52,875
Speaker 2:  about tech and CES and all of our feelings about everything. We're gonna

15
00:00:52,875 --> 00:00:56,635
Speaker 2:  do more shows like that too. So If you miss this one, keep an eye out because

16
00:00:56,845 --> 00:00:59,715
Speaker 2:  we're, we wanna do more live stuff. It's just fun getting to do this with

17
00:00:59,815 --> 00:01:02,915
Speaker 2:  all of you guys. For now, we have some

18
00:01:03,555 --> 00:01:07,235
Speaker 2:  CES adjacent stuff to talk about. I would say we're gonna do two things

19
00:01:07,335 --> 00:01:11,035
Speaker 2:  on today's show. First, we're gonna talk to Lauren Finer about the TikTok

20
00:01:11,035 --> 00:01:14,835
Speaker 2:  Band and the looming changes coming at meta

21
00:01:15,295 --> 00:01:19,235
Speaker 2:  and basically the huge social landscape change that

22
00:01:19,235 --> 00:01:23,075
Speaker 2:  feels like it's coming potentially like in the next few days

23
00:01:23,175 --> 00:01:26,515
Speaker 2:  and weeks. It's gonna be a really interesting moment in this space, and we're

24
00:01:26,515 --> 00:01:29,595
Speaker 2:  gonna talk about it. Then I'm gonna talk to Everett Taylor, who's the CEO

25
00:01:29,595 --> 00:01:33,195
Speaker 2:  of Kickstarter. Kickstarter was at CES last week, but I talked to Everett

26
00:01:33,195 --> 00:01:36,915
Speaker 2:  right before CES about what it means to be

27
00:01:37,025 --> 00:01:40,275
Speaker 2:  Kickstarter right now. We, I just spent the week talking to startups who

28
00:01:40,275 --> 00:01:44,195
Speaker 2:  are desperately trying to figure out how to make and ship and get

29
00:01:44,195 --> 00:01:47,755
Speaker 2:  products in front of people, and he had some really interesting thoughts

30
00:01:47,755 --> 00:01:51,555
Speaker 2:  on what it means to be a tech creator right now and what it means to make

31
00:01:51,635 --> 00:01:55,515
Speaker 2:  products in 2025 and how this landscape is

32
00:01:55,715 --> 00:01:59,555
Speaker 2:  changing for people who just want to be out there making things and

33
00:01:59,555 --> 00:02:02,395
Speaker 2:  selling them to people. Really interesting talking to him about it. I've

34
00:02:02,395 --> 00:02:05,355
Speaker 2:  had sort of mixed feelings about Kickstarter for the whole time I've been

35
00:02:05,555 --> 00:02:08,635
Speaker 2:  covering tech, and it was fun to process that with some of it. We also have

36
00:02:08,635 --> 00:02:11,835
Speaker 2:  a really fun question from the first cast hotline. Lots to get to this week.

37
00:02:11,835 --> 00:02:14,955
Speaker 2:  It's gonna be a really fun show. All of that is coming up in just a second,

38
00:02:15,175 --> 00:02:19,035
Speaker 2:  But first, I just, while I was doing this, walked completely the wrong direction

39
00:02:19,145 --> 00:02:22,995
Speaker 2:  from my gate, and now I have to turn around and not miss my flight. This

40
00:02:22,995 --> 00:02:24,355
Speaker 2:  is The Vergecast. We'll be right back.

41
00:03:09,175 --> 00:03:12,745
Speaker 4:  Welcome back. All right, let's get into this. So today, if you're listening

42
00:03:12,745 --> 00:03:16,625
Speaker 4:  to this on Tuesday is January 14th. On January 19th,

43
00:03:16,925 --> 00:03:20,425
Speaker 4:  we will hit the deadline imposed by a bill that says either TikTok has to

44
00:03:20,425 --> 00:03:23,665
Speaker 4:  be divested from by dance or will be banned in the United States.

45
00:03:24,175 --> 00:03:27,865
Speaker 4:  It's actually not exactly that simple, and we're gonna talk about the ways

46
00:03:27,865 --> 00:03:31,465
Speaker 4:  in which it's not exactly that simple, but it is kind of that simple.

47
00:03:31,645 --> 00:03:35,305
Speaker 4:  TikTok as we know it, as the thing that you use now either

48
00:03:35,415 --> 00:03:39,145
Speaker 4:  will or will not still be here In five days. And I think

49
00:03:39,245 --> 00:03:43,025
Speaker 4:  we are getting an increasingly clear sense of which of those two things

50
00:03:43,235 --> 00:03:47,025
Speaker 4:  might actually happen, especially after the bill that

51
00:03:47,025 --> 00:03:50,345
Speaker 4:  originally banned TikTok and would do so on January 19th

52
00:03:51,395 --> 00:03:54,095
Speaker 4:  was argued in front of the Supreme Court. We have new information, we have

53
00:03:54,095 --> 00:03:57,695
Speaker 4:  a sense of what's gonna happen. I don't think it looks great for TikTok,

54
00:03:57,995 --> 00:04:01,975
Speaker 4:  but let's get into all of what's to come. Lauren Finer has been

55
00:04:02,175 --> 00:04:05,775
Speaker 4:  covering all of this for us and is having an extremely chill beginning to

56
00:04:05,775 --> 00:04:09,655
Speaker 4:  2025, and she's here now to help us walk through all of it. Lauren Finer,

57
00:04:09,655 --> 00:04:10,375
Speaker 4:  welcome back.

58
00:04:10,515 --> 00:04:11,815
Speaker 5:  Thanks for having me. Just

59
00:04:11,895 --> 00:04:13,815
Speaker 4:  A super chill way to start the year, I would

60
00:04:13,815 --> 00:04:15,455
Speaker 5:  Say. Totally. Very, very normal.

61
00:04:16,325 --> 00:04:19,615
Speaker 4:  It's just, and it's just gonna keep happening. We're, you're gonna be on

62
00:04:19,615 --> 00:04:22,175
Speaker 4:  this show a lot in the next few months, so I'm really sorry in advance.

63
00:04:22,365 --> 00:04:23,495
Speaker 5:  Looking forward to it.

64
00:04:24,195 --> 00:04:27,775
Speaker 4:  So let's just rewind the TikTok story very slightly. I mostly wanna talk

65
00:04:27,775 --> 00:04:30,215
Speaker 4:  about kind of where we are now and what's happening in the next week, but

66
00:04:30,215 --> 00:04:34,095
Speaker 4:  like, give me the, the sort of CliffNotes version of how we ended

67
00:04:34,095 --> 00:04:35,895
Speaker 4:  up in the Supreme Court last Friday.

68
00:04:36,725 --> 00:04:40,175
Speaker 5:  Yeah, so if we wanna start from like the very beginning, we gotta go back

69
00:04:40,215 --> 00:04:43,535
Speaker 5:  a few years to when Donald Trump was president the first time

70
00:04:44,035 --> 00:04:47,895
Speaker 5:  and he tried to do a TikTok ban through an executive order that

71
00:04:47,895 --> 00:04:51,815
Speaker 5:  ends up getting shot down in the court because of some kinda legal reasons.

72
00:04:52,525 --> 00:04:56,215
Speaker 5:  Then, you know, everyone kind of forgets about it. There's a committee

73
00:04:56,635 --> 00:05:00,615
Speaker 5:  of in the federal government that's looking into a possible

74
00:05:00,615 --> 00:05:04,095
Speaker 5:  sale or what could be done to mitigate the risks that they see of

75
00:05:04,435 --> 00:05:07,895
Speaker 5:  TikTok being owned by a China-based parent company by dance.

76
00:05:08,555 --> 00:05:12,415
Speaker 5:  But all things considered, everyone kind of forgets that this is

77
00:05:12,415 --> 00:05:15,535
Speaker 5:  happening and we don't really hear that much about it. Then

78
00:05:16,275 --> 00:05:20,175
Speaker 5:  go back to last year and all of a sudden

79
00:05:20,235 --> 00:05:23,935
Speaker 5:  we see all of this momentum around a bill that could ban

80
00:05:23,955 --> 00:05:27,815
Speaker 5:  TikTok and there'd been things like this before, but none of them have

81
00:05:27,815 --> 00:05:31,455
Speaker 5:  really caught on. And all of a sudden this one is just like

82
00:05:31,485 --> 00:05:35,215
Speaker 5:  rocketing with support and we end up seeing

83
00:05:35,575 --> 00:05:39,335
Speaker 5:  a vote, an overwhelming vote in the house to pass this bill

84
00:05:39,425 --> 00:05:43,295
Speaker 5:  after lawmakers got briefed on classified information.

85
00:05:44,115 --> 00:05:47,975
Speaker 5:  And then we see it kind of quickly move through the Senate and

86
00:05:48,035 --> 00:05:52,015
Speaker 5:  we see broad bipartisan support for this bill. And President Biden

87
00:05:52,015 --> 00:05:55,975
Speaker 5:  quickly signs it into law. So that starts the clock on

88
00:05:56,405 --> 00:05:59,405
Speaker 5:  this band deadline, which is now January 19th.

89
00:06:00,265 --> 00:06:04,165
Speaker 5:  So that's where we were at. And then TikTok all along has

90
00:06:04,165 --> 00:06:08,045
Speaker 5:  been fighting this. They've given by dance, their parent company has

91
00:06:08,045 --> 00:06:11,045
Speaker 5:  given no indication that they actually would be interested in selling the

92
00:06:11,045 --> 00:06:15,005
Speaker 5:  app. Meanwhile, we've seen a few kind of people

93
00:06:15,005 --> 00:06:18,045
Speaker 5:  come outta the woodwork saying, we would love to buy the app,

94
00:06:19,145 --> 00:06:23,085
Speaker 5:  but it's still not clear that it is for sale or that China would allow it

95
00:06:23,085 --> 00:06:26,565
Speaker 5:  to be for sale, even if bike dance wanted it to be. And

96
00:06:27,315 --> 00:06:30,685
Speaker 5:  that ends up landing us in the Supreme Court. You know, first

97
00:06:31,145 --> 00:06:34,765
Speaker 5:  the case went to the DC Circuit Court, which had

98
00:06:34,875 --> 00:06:38,805
Speaker 5:  exclusive jurisdiction per the text of the law to

99
00:06:39,585 --> 00:06:43,285
Speaker 5:  see this. And they decided, a three judge panel

100
00:06:43,715 --> 00:06:47,645
Speaker 5:  decided, all three judges said that this is a constitutional

101
00:06:47,645 --> 00:06:51,445
Speaker 5:  law, it does not violate the First Amendment, even though it could result

102
00:06:51,465 --> 00:06:54,925
Speaker 5:  in the ousting of a speech platform. Then

103
00:06:55,225 --> 00:06:58,925
Speaker 5:  TikTok appeals the ruling we end up in the Supreme Court, and that's where

104
00:06:58,925 --> 00:07:02,845
Speaker 5:  we were on Friday when the Supreme Court heard oral arguments in this case.

105
00:07:03,115 --> 00:07:07,045
Speaker 4:  Okay. And it's, I I would say it had been barreling toward the Supreme Court

106
00:07:07,075 --> 00:07:10,725
Speaker 4:  kind of from day one, right? Like we, we, I remember talking about this when

107
00:07:10,945 --> 00:07:14,605
Speaker 4:  the law was first even being debated, that it was like this is gonna end

108
00:07:14,605 --> 00:07:17,245
Speaker 4:  up in front of the Supreme Court in one way or another. So this is kind of,

109
00:07:17,395 --> 00:07:20,325
Speaker 4:  this is the capstone we had been waiting for for months.

110
00:07:20,875 --> 00:07:24,365
Speaker 5:  Exactly. This was a long time coming. This was always gonna be a fight between

111
00:07:24,905 --> 00:07:28,765
Speaker 5:  two really fundamental interests of the US government, which are

112
00:07:30,165 --> 00:07:33,965
Speaker 5:  national security and free expression. So this was always kind of barreling

113
00:07:33,965 --> 00:07:34,925
Speaker 5:  to toward this place.

114
00:07:35,195 --> 00:07:38,685
Speaker 4:  Okay. And it seems like one of the things that happened a lot

115
00:07:39,505 --> 00:07:43,365
Speaker 4:  in the arguments on Friday was the question of is this

116
00:07:43,365 --> 00:07:47,205
Speaker 4:  even a thing about free speech? Which surprised

117
00:07:47,205 --> 00:07:50,045
Speaker 4:  me, and it seemed like surprised some people that that was even

118
00:07:50,985 --> 00:07:54,485
Speaker 4:  up for debate about are we even having a conversation about free speech?

119
00:07:55,515 --> 00:07:56,645
Speaker 4:  Walk me through that a little bit.

120
00:07:57,475 --> 00:08:00,925
Speaker 5:  Yeah, I think, I honestly wasn't surprised by that framing

121
00:08:01,485 --> 00:08:04,565
Speaker 5:  that we saw by a lot of the justices, because If you just look

122
00:08:05,605 --> 00:08:09,125
Speaker 5:  directly at the text of the law as it's written, it's

123
00:08:09,125 --> 00:08:12,085
Speaker 5:  written to talk about the

124
00:08:13,045 --> 00:08:17,005
Speaker 5:  foreign adversary control of a social media app.

125
00:08:18,385 --> 00:08:21,965
Speaker 5:  So, you know, in the text of the law, it doesn't say anything about

126
00:08:22,345 --> 00:08:26,165
Speaker 5:  speech, about like who says what or, you know, what kinds of

127
00:08:26,685 --> 00:08:30,605
Speaker 5:  speech is allowed. It's purely about who is allowed to

128
00:08:30,665 --> 00:08:34,525
Speaker 5:  own a social media app. And you know, we have like foreign

129
00:08:34,525 --> 00:08:38,445
Speaker 5:  ownership rules over, you know, certain kinds of

130
00:08:38,445 --> 00:08:42,285
Speaker 5:  other kinds of media. So it's not a wholly different

131
00:08:42,285 --> 00:08:46,205
Speaker 5:  concept, but you know, obviously no law like this has ever

132
00:08:46,205 --> 00:08:48,565
Speaker 5:  really gotten to this point before.

133
00:08:49,105 --> 00:08:52,525
Speaker 4:  But then how do you, how do you square that with the fact that simultaneously

134
00:08:53,545 --> 00:08:56,965
Speaker 4:  in Congress and elsewhere, we've been endlessly litigating

135
00:08:57,575 --> 00:09:00,685
Speaker 4:  propaganda on TikTok and the kinds of things that people are seeing. And

136
00:09:00,685 --> 00:09:03,765
Speaker 4:  there were, there were huge arguments and there's been some suggestion that

137
00:09:03,785 --> 00:09:06,685
Speaker 4:  one of the things that people got in this infamous briefing

138
00:09:07,515 --> 00:09:11,125
Speaker 4:  last year was about pro-Palestine posts on

139
00:09:11,265 --> 00:09:14,605
Speaker 4:  TikTok and the way that the algorithm is shaping public opinion. Like

140
00:09:15,285 --> 00:09:18,405
Speaker 4:  I understand that it's not in the law, but it, it feels like if you're looking

141
00:09:18,425 --> 00:09:21,605
Speaker 4:  at this, we have to be talking about content a little bit, right?

142
00:09:22,435 --> 00:09:26,205
Speaker 5:  Yeah, I mean, I think that's definitely all, all things that the court

143
00:09:26,275 --> 00:09:29,445
Speaker 5:  will be thinking about. Okay. I think, you know,

144
00:09:30,275 --> 00:09:34,005
Speaker 5:  part of what seems to mitigate that, at least in

145
00:09:34,005 --> 00:09:37,045
Speaker 5:  during the arguments for some of the justices might be that

146
00:09:37,555 --> 00:09:41,485
Speaker 5:  there's both, there's kind of these like two justifications that the government

147
00:09:41,485 --> 00:09:44,965
Speaker 5:  has given for this law, which is both the fear that China

148
00:09:45,375 --> 00:09:48,805
Speaker 5:  could somehow influence by dance to

149
00:09:49,335 --> 00:09:53,085
Speaker 5:  alter the algorithm that TikTok relies on to push

150
00:09:53,245 --> 00:09:57,125
Speaker 5:  a certain narrative to American users. Yeah. And I think

151
00:09:57,205 --> 00:10:00,685
Speaker 5:  a lot of lawmakers saw the very

152
00:10:00,685 --> 00:10:04,525
Speaker 5:  pro-Palestinian content on TikTok as an example of what could be

153
00:10:04,525 --> 00:10:08,485
Speaker 5:  done, whether or not that was actually coming from China or not. And obviously,

154
00:10:08,625 --> 00:10:12,205
Speaker 5:  you know, there's plenty of reasons why, you know, more content

155
00:10:12,295 --> 00:10:16,005
Speaker 5:  might be skewed one way or another on a certain platform based on

156
00:10:16,055 --> 00:10:19,925
Speaker 5:  who's there or whatever. But I think that was an example to them

157
00:10:20,025 --> 00:10:23,645
Speaker 5:  of if China wanted to use this for nefarious reasons to say,

158
00:10:24,105 --> 00:10:27,465
Speaker 5:  you know, to push like anti Taiwan

159
00:10:27,695 --> 00:10:31,425
Speaker 5:  content or something like that. I think that was an example to them of how

160
00:10:31,425 --> 00:10:34,865
Speaker 5:  it might be used. So I think there's that, and then there's also the second

161
00:10:35,255 --> 00:10:38,945
Speaker 5:  reasoning that I think might be even more compelling to

162
00:10:39,245 --> 00:10:43,065
Speaker 5:  the Supreme Court about data security. And that

163
00:10:43,165 --> 00:10:47,145
Speaker 5:  is something that I think is less touches speech a little bit

164
00:10:47,145 --> 00:10:50,265
Speaker 5:  less than, you know, talking about like propaganda

165
00:10:51,125 --> 00:10:53,945
Speaker 5:  and you know, how an algorithm could be used to push that kind of content.

166
00:10:54,655 --> 00:10:57,625
Speaker 4:  Okay. Yeah, I, I do think it, it seemed interesting,

167
00:10:58,775 --> 00:11:01,425
Speaker 4:  even just watching the live stream, this is the most closely I've ever paid

168
00:11:01,425 --> 00:11:05,345
Speaker 4:  attention to a Supreme Court thing, and they

169
00:11:05,345 --> 00:11:09,225
Speaker 4:  do a good job of just kind of calling bullshit on everybody, which is sort

170
00:11:09,225 --> 00:11:12,945
Speaker 4:  of fun that it's like everybody comes up for their turn being told they're

171
00:11:12,945 --> 00:11:16,545
Speaker 4:  liars by the nine justices, which is a dynamic, I actually really appreciate

172
00:11:16,545 --> 00:11:20,265
Speaker 4:  it. But it was, it, there was a certain sense in which the, the

173
00:11:20,265 --> 00:11:22,905
Speaker 4:  TikTok lawyers come up and they're like, okay, this is about free speech.

174
00:11:23,085 --> 00:11:26,425
Speaker 4:  And they're like, Hmm, not really. And then the government lawyers come up

175
00:11:26,425 --> 00:11:29,705
Speaker 4:  and they're like, this is about corporate ownership. And they're like, is

176
00:11:29,705 --> 00:11:33,505
Speaker 4:  it? So it's just, it's kind of mind bending, but I guess the, the

177
00:11:33,505 --> 00:11:36,825
Speaker 4:  idea here is they're, they're just poking at everybody trying to figure out

178
00:11:37,055 --> 00:11:38,665
Speaker 4:  what makes the most sense to them.

179
00:11:39,115 --> 00:11:42,705
Speaker 5:  Right, exactly. And I think you hear them kind of asking questions where

180
00:11:42,705 --> 00:11:45,945
Speaker 5:  they're prodding, like, what are the outer bounds of this? If we were to

181
00:11:45,945 --> 00:11:49,065
Speaker 5:  write something like this, what would that mean? Or how would we do this?

182
00:11:49,205 --> 00:11:49,425
Speaker 5:  So

183
00:11:49,725 --> 00:11:51,745
Speaker 4:  That's a good, sorry, I don't mean to interrupt. Yeah, but you just brought

184
00:11:51,745 --> 00:11:53,805
Speaker 4:  up the thing I wanna talk about that I was, was gonna forget about, which

185
00:11:53,805 --> 00:11:57,645
Speaker 4:  is Jeff Bezos who kept coming up. Ian, I think

186
00:11:57,645 --> 00:12:01,485
Speaker 4:  the way that you're describing what, how, why, why did poor Jeff Bezos

187
00:12:01,485 --> 00:12:03,205
Speaker 4:  keep getting pulled into this whole thing?

188
00:12:03,685 --> 00:12:04,805
Speaker 5:  Oh yeah. Okay. So

189
00:12:06,335 --> 00:12:10,205
Speaker 5:  Bezos kept being brought up by, in these arguments as

190
00:12:10,205 --> 00:12:14,045
Speaker 5:  kind of anal an analogy because obviously Bezos founder

191
00:12:14,105 --> 00:12:17,685
Speaker 5:  of Amazon, who also now owns the Washington Post,

192
00:12:19,105 --> 00:12:22,645
Speaker 5:  you know, I think what they were using him as kind of

193
00:12:23,045 --> 00:12:26,285
Speaker 5:  a foil or of like what would happen if like,

194
00:12:26,825 --> 00:12:30,165
Speaker 5:  you know, there was some kind of influence on, on

195
00:12:30,715 --> 00:12:34,445
Speaker 5:  this owner of a US-based media company

196
00:12:35,545 --> 00:12:39,245
Speaker 5:  by a foreign adversary. And h how is that any different from the

197
00:12:39,245 --> 00:12:42,845
Speaker 5:  ownership structure that we see with TikTok? Like for example,

198
00:12:43,865 --> 00:12:47,805
Speaker 5:  one at one point they talked about what if the Chinese government had

199
00:12:48,165 --> 00:12:52,085
Speaker 5:  like kidnapped Bezos's children and held them hostage

200
00:12:52,145 --> 00:12:55,965
Speaker 5:  so that he would print prop propaganda. Like how is that any different than,

201
00:12:56,345 --> 00:13:00,005
Speaker 5:  you know, a media company that's owned by a foreign adversary versus

202
00:13:00,075 --> 00:13:03,965
Speaker 5:  like one that's being, having a lot of influence by

203
00:13:03,965 --> 00:13:06,725
Speaker 5:  foreign adversary through perhaps nefarious means?

204
00:13:07,275 --> 00:13:11,205
Speaker 4:  What is the point of that analogy? Like what's, what's in the, the, I think

205
00:13:11,205 --> 00:13:15,125
Speaker 4:  it was, was it Sonya Sotomayor who brought that up? I think it

206
00:13:15,125 --> 00:13:18,685
Speaker 4:  was whoever, whichever justice it was. What is the point of that analogy

207
00:13:18,745 --> 00:13:19,605
Speaker 4:  in this case, do you think?

208
00:13:20,565 --> 00:13:24,525
Speaker 5:  I think the idea is that, you know, I think there's this question

209
00:13:24,585 --> 00:13:28,565
Speaker 5:  of what's the kind of like the starting point of

210
00:13:28,565 --> 00:13:32,245
Speaker 5:  the influence and the negative influence that Congress wants to root out.

211
00:13:32,275 --> 00:13:35,885
Speaker 5:  Like is it this like foreign ownership

212
00:13:36,145 --> 00:13:39,885
Speaker 5:  or is it, you know, this influence that could happen on even an

213
00:13:40,125 --> 00:13:43,885
Speaker 5:  American company through some other means. So I

214
00:13:44,165 --> 00:13:47,685
Speaker 5:  think it's kind of trying to find where is that line?

215
00:13:48,435 --> 00:13:52,045
Speaker 4:  Okay, and then I guess as a result, what is the

216
00:13:52,045 --> 00:13:55,925
Speaker 4:  government's role in that moment, right? Like, at what

217
00:13:55,925 --> 00:13:59,885
Speaker 4:  point is the government supposed to get involved here? Seems to be one

218
00:13:59,885 --> 00:14:01,485
Speaker 4:  of the open questions.

219
00:14:02,455 --> 00:14:06,405
Speaker 5:  Right? Right. Okay. And, and like who is allowed to print propaganda

220
00:14:06,875 --> 00:14:10,605
Speaker 5:  because of what influence? And you know, I think those are kind of the main

221
00:14:10,805 --> 00:14:11,205
Speaker 5:  questions there.

222
00:14:11,555 --> 00:14:15,525
Speaker 4:  Okay, that makes sense. So I, it seemed like coming out of these

223
00:14:15,805 --> 00:14:19,285
Speaker 4:  arguments, the, the odds of TikTok

224
00:14:19,395 --> 00:14:23,285
Speaker 4:  winning and, and we should talk about what winning means, but the odds of

225
00:14:23,285 --> 00:14:27,085
Speaker 4:  TikTok winning seemed to go down in a lot of

226
00:14:27,085 --> 00:14:28,645
Speaker 4:  people's minds. Was that your read too?

227
00:14:29,235 --> 00:14:33,045
Speaker 5:  That was my read. I think, you know, I think the only

228
00:14:33,045 --> 00:14:36,405
Speaker 5:  justice who stood out to me as potentially on TikTok side was

229
00:14:37,085 --> 00:14:40,685
Speaker 5:  Justice Gorsuch, who seemed to have concerns about,

230
00:14:40,985 --> 00:14:44,645
Speaker 5:  you know, the evidence in this case. And just,

231
00:14:45,265 --> 00:14:48,645
Speaker 5:  you know, I think a lot of the, the big questions that TikTok has brought

232
00:14:48,645 --> 00:14:52,245
Speaker 5:  up here, but I don't think we saw a clear, you know,

233
00:14:52,515 --> 00:14:56,245
Speaker 5:  vote of support for TikTok for many of the other justices. I think it's

234
00:14:56,445 --> 00:15:00,365
Speaker 5:  possible they get some more on their side, but I think it was, you

235
00:15:00,365 --> 00:15:04,215
Speaker 5:  know, less clear there. And I think my feeling

236
00:15:04,235 --> 00:15:07,855
Speaker 5:  was that the, the questioning was harder on

237
00:15:07,855 --> 00:15:11,495
Speaker 5:  TikTok or seemed to be that they, their thinking was more in line with the

238
00:15:11,515 --> 00:15:15,455
Speaker 5:  US government, but of course, you know, it, it can be hard to just say

239
00:15:15,455 --> 00:15:19,135
Speaker 5:  because they're always talking in hypotheticals and aren't completely tipping

240
00:15:19,135 --> 00:15:19,575
Speaker 5:  their hands.

241
00:15:20,025 --> 00:15:22,855
Speaker 4:  Right. Yeah, I mean, I keep coming back to this question of

242
00:15:23,995 --> 00:15:27,695
Speaker 4:  how real versus theoretical the threat actually

243
00:15:27,795 --> 00:15:31,735
Speaker 4:  is. And it seems like we are still very much in this

244
00:15:31,735 --> 00:15:35,695
Speaker 4:  place of China could do things and TikTok could do things

245
00:15:35,695 --> 00:15:39,615
Speaker 4:  and the algorithm could be doing things. And the,

246
00:15:39,715 --> 00:15:43,255
Speaker 4:  the most real piece of it, I think seems to be the data collection piece.

247
00:15:43,255 --> 00:15:47,215
Speaker 4:  And I wonder if that's why the lawyers continue to focus on it,

248
00:15:47,215 --> 00:15:50,935
Speaker 4:  because that is one thing that is definitely happening and, and is, is provably

249
00:15:50,935 --> 00:15:54,575
Speaker 4:  happening, is that TikTok and by extension, by dance and by extension potentially

250
00:15:54,575 --> 00:15:58,255
Speaker 4:  the Chinese government are collecting vast quantities of data about

251
00:15:59,295 --> 00:16:02,375
Speaker 4:  whatever, it's like almost 200 million people in the United States. That

252
00:16:02,505 --> 00:16:06,415
Speaker 4:  seems bad. Sure. But I, I still, I'm so hung

253
00:16:06,415 --> 00:16:09,495
Speaker 4:  up on this thing that like, I think it was in the spring that a, a bunch

254
00:16:09,495 --> 00:16:13,335
Speaker 4:  of, a bunch of people in Congress got a briefing that was classified

255
00:16:13,665 --> 00:16:17,535
Speaker 4:  about something, some threat the TikTok posed, and then they

256
00:16:17,535 --> 00:16:21,055
Speaker 4:  came out of that briefing and voted 50 to zero to ban it, right? So like

257
00:16:21,245 --> 00:16:24,495
Speaker 4:  that seems bad. And then it, it passed through the house, it passed through

258
00:16:24,495 --> 00:16:27,615
Speaker 4:  the, like, everybody who has seen something

259
00:16:28,085 --> 00:16:31,815
Speaker 4:  appears to come out on the other side saying, this is a problem, we have

260
00:16:31,815 --> 00:16:35,295
Speaker 4:  to get rid of TikTok. But we have never been told what that something is,

261
00:16:35,325 --> 00:16:38,855
Speaker 4:  what was in the briefing, what we actually know. And at this point, even,

262
00:16:39,085 --> 00:16:42,935
Speaker 4:  even the Supreme Court and these lawyers seem to be arguing

263
00:16:42,995 --> 00:16:46,815
Speaker 4:  mostly in theory as opposed to about like

264
00:16:46,835 --> 00:16:50,415
Speaker 4:  the the real stuff that is really happening on the ground right now.

265
00:16:50,915 --> 00:16:54,255
Speaker 4:  Did I miss anything? Are there, are there concrete things going on that we're

266
00:16:54,255 --> 00:16:57,655
Speaker 4:  talking about now that we haven't been in the past or are we still kind of

267
00:16:58,485 --> 00:17:00,735
Speaker 4:  just talking about what TikTok might be?

268
00:17:01,785 --> 00:17:05,745
Speaker 5:  I mean, I think that's true as far as we're publicly aware. I

269
00:17:05,745 --> 00:17:09,625
Speaker 5:  think, you know, we don't really know what was said behind

270
00:17:09,625 --> 00:17:13,345
Speaker 5:  closed doors, what sort of classified information the government does

271
00:17:13,375 --> 00:17:16,785
Speaker 5:  possess. So I don't think we can say for sure that there're

272
00:17:17,165 --> 00:17:20,905
Speaker 5:  not aware of any actual ongoing or,

273
00:17:21,005 --> 00:17:24,745
Speaker 5:  you know, past action that the Chinese government has taken with regards

274
00:17:24,745 --> 00:17:28,145
Speaker 5:  to TikTok. But, you know, I, I think

275
00:17:28,565 --> 00:17:32,185
Speaker 5:  the way that it's been discussed from people who've seen the information,

276
00:17:33,045 --> 00:17:36,705
Speaker 5:  at least doesn't seem to me that there was necessarily

277
00:17:36,815 --> 00:17:40,745
Speaker 5:  that kind of thing going on, although, you know, hard to say, you

278
00:17:40,745 --> 00:17:43,545
Speaker 5:  know, maybe they just can't even allude to it. Right.

279
00:17:44,805 --> 00:17:48,265
Speaker 5:  But I think it at least seems like there

280
00:17:49,825 --> 00:17:53,605
Speaker 5:  us intelligence officials feel like there is enough possibility

281
00:17:53,655 --> 00:17:56,965
Speaker 5:  there or access for the Chinese government to

282
00:17:57,155 --> 00:18:01,045
Speaker 5:  potentially gain to bite dance and thereby to

283
00:18:01,145 --> 00:18:05,085
Speaker 5:  TikTok and American users that they feel like it's a sufficient enough threat

284
00:18:05,085 --> 00:18:08,925
Speaker 5:  to guard against. And I think maybe feel that, why

285
00:18:08,925 --> 00:18:12,525
Speaker 5:  should we wait for an attack to happen to take actions against it,

286
00:18:13,055 --> 00:18:16,965
Speaker 4:  Right? Yeah. And I I'm so conflicted on that line of thinking and

287
00:18:16,965 --> 00:18:20,085
Speaker 4:  it, it does feel like it underpins a lot of this where it goes back to the

288
00:18:20,085 --> 00:18:23,405
Speaker 4:  what are we even arguing about question, right? And I think there is either

289
00:18:23,405 --> 00:18:27,365
Speaker 4:  something that we're arguing about that we the public don't

290
00:18:27,365 --> 00:18:31,165
Speaker 4:  yet know about or we are arguing in theory

291
00:18:31,385 --> 00:18:34,525
Speaker 4:  and, and it feels, it feels very different to me which one of those it turns

292
00:18:34,525 --> 00:18:37,405
Speaker 4:  out to be. And I'm not sure we're ever gonna know. And that drives me insane.

293
00:18:37,635 --> 00:18:41,165
Speaker 4:  Yeah. But so the, the other thing that kept coming up is the question of

294
00:18:41,165 --> 00:18:45,045
Speaker 4:  basically why hasn't TikTok just sold yet? Like why, why

295
00:18:45,045 --> 00:18:48,525
Speaker 4:  even go through all of this hassle? Just let somebody write you a check for

296
00:18:48,595 --> 00:18:52,165
Speaker 4:  many tens of billions of dollars and move on with your life. And I think

297
00:18:52,235 --> 00:18:55,725
Speaker 4:  tiktoks argument seems to be that it's not actually that simple that actually

298
00:18:55,725 --> 00:18:59,445
Speaker 4:  selling isn't really an option. Can you explain that a little bit? What,

299
00:18:59,445 --> 00:19:03,245
Speaker 4:  what is, what is the argument that selling is not only not a good idea, but

300
00:19:03,245 --> 00:19:04,005
Speaker 4:  sort of impossible?

301
00:19:04,805 --> 00:19:08,615
Speaker 5:  Yeah, So I think even before that I would say, you know, any business

302
00:19:08,675 --> 00:19:12,455
Speaker 5:  that's in active litigation, they're not going to

303
00:19:12,485 --> 00:19:16,055
Speaker 5:  want to kind of give the court a sense that, you know,

304
00:19:16,735 --> 00:19:19,615
Speaker 5:  a sale is possible. That you know what the, what the government wants them

305
00:19:19,615 --> 00:19:22,335
Speaker 5:  to do, they're gonna be able to just do easily.

306
00:19:22,875 --> 00:19:25,615
Speaker 4:  That's fair. If they could just go take the money, they, they have every

307
00:19:25,615 --> 00:19:27,735
Speaker 4:  reason to not tell you they can do that. That is fair,

308
00:19:27,945 --> 00:19:31,695
Speaker 5:  Right? I think it's in TikTok and by dance's interest to exhaust every legal

309
00:19:31,745 --> 00:19:35,735
Speaker 5:  route before they really pursue a sale. At the

310
00:19:35,735 --> 00:19:39,335
Speaker 5:  same time, I think tiktoks argument is that this is really

311
00:19:39,755 --> 00:19:43,535
Speaker 5:  not super feasible to just separate from by dance.

312
00:19:43,635 --> 00:19:47,535
Speaker 5:  You know, there's so much like code intermixed like that we're relying

313
00:19:47,595 --> 00:19:51,295
Speaker 5:  on this algorithm, you know, just to extract

314
00:19:51,395 --> 00:19:55,135
Speaker 5:  is like really an arduous task. It's not as simple as just like,

315
00:19:55,475 --> 00:19:59,255
Speaker 5:  you know, cutting off at one point. So I think that's probably true. You

316
00:19:59,255 --> 00:20:02,575
Speaker 5:  know, a a lot of this is like years of

317
00:20:03,305 --> 00:20:06,895
Speaker 5:  technology being built and I don't think it's gonna be that simple

318
00:20:07,085 --> 00:20:10,735
Speaker 5:  just to separate. At the same time, I think another

319
00:20:10,885 --> 00:20:14,855
Speaker 5:  part of the argument is just that China won't sell the app.

320
00:20:15,155 --> 00:20:19,055
Speaker 5:  And I think that's something that the DC circuit said, well that's not our

321
00:20:19,055 --> 00:20:19,295
Speaker 5:  problem.

322
00:20:21,355 --> 00:20:24,775
Speaker 5:  And you know, I think basically China's able to

323
00:20:25,025 --> 00:20:28,735
Speaker 5:  block the sale if they want to. They are able to,

324
00:20:29,085 --> 00:20:32,895
Speaker 5:  they consider the algorithm and export. So they could definitely clamp down

325
00:20:32,895 --> 00:20:36,295
Speaker 5:  on that and say, by dance you cannot sell this algorithm

326
00:20:37,515 --> 00:20:41,415
Speaker 5:  beyond that, you know, groups like Project Liberty

327
00:20:41,515 --> 00:20:44,455
Speaker 5:  are interested in just buying the app without the algorithm, which would

328
00:20:44,455 --> 00:20:48,325
Speaker 5:  mean like, you know, the the underlying platform, the user

329
00:20:48,395 --> 00:20:52,205
Speaker 5:  base, the content, things like that. But even then

330
00:20:52,655 --> 00:20:56,645
Speaker 5:  China could kind of exert its influence on ance and say, you can't

331
00:20:56,645 --> 00:21:00,565
Speaker 5:  do that. And you know, an an expert in, you know,

332
00:21:00,565 --> 00:21:03,465
Speaker 5:  kind of China business told me that

333
00:21:04,615 --> 00:21:08,585
Speaker 5:  this is something that might be in the country's interest to hang on to

334
00:21:08,585 --> 00:21:12,505
Speaker 5:  TikTok, both because they have markets in other parts of the

335
00:21:12,505 --> 00:21:16,345
Speaker 5:  country where TikTok could still be active and they also

336
00:21:16,345 --> 00:21:19,745
Speaker 5:  might be betting, hey, you know, someday maybe TikTok will be allowed back

337
00:21:19,745 --> 00:21:23,705
Speaker 5:  in the US and then we wanna be the ones able to capitalize

338
00:21:23,905 --> 00:21:24,185
Speaker 5:  on that.

339
00:21:25,055 --> 00:21:29,025
Speaker 4:  Yeah, it's, it's a really interesting sort of parallel universe.

340
00:21:29,185 --> 00:21:33,145
Speaker 4:  I don't think it's gonna happen. It seems very unlikely to me that TikTok

341
00:21:33,855 --> 00:21:37,665
Speaker 4:  changes hands in some meaningful way in the next five days. I could be wrong,

342
00:21:37,865 --> 00:21:40,225
Speaker 4:  I sort of hope I'm wrong because I think it'll be fascinating to see what

343
00:21:40,225 --> 00:21:43,825
Speaker 4:  that looks like. But one of the things that, that one of the lawyers is saying

344
00:21:43,825 --> 00:21:47,705
Speaker 4:  in those arguments is that even If you allow TikTok to

345
00:21:47,725 --> 00:21:51,465
Speaker 4:  be sold or or exchange hands in some way, it

346
00:21:51,465 --> 00:21:54,425
Speaker 4:  completely changes what TikTok is. Which is the thing I find

347
00:21:55,345 --> 00:21:58,385
Speaker 4:  absolutely true. That seems right to me. That right under new owners with

348
00:21:58,385 --> 00:22:02,185
Speaker 4:  a new team, with a new code base, you have a thing that looks like TikTok

349
00:22:02,185 --> 00:22:05,865
Speaker 4:  but is in every real practical way, not TikTok. And I think

350
00:22:06,405 --> 00:22:10,305
Speaker 4:  the question of what that would look like is just as a person who is

351
00:22:10,305 --> 00:22:13,745
Speaker 4:  interested in products and like how we interact with technology, I find that

352
00:22:13,745 --> 00:22:16,585
Speaker 4:  so fascinating because it's never really happened before that. Like, what

353
00:22:16,585 --> 00:22:20,025
Speaker 4:  If you took the thing everyone cared about and just like

354
00:22:20,625 --> 00:22:24,265
Speaker 4:  ship a thesis it and just like changed all the parts, would it still be TikTok?

355
00:22:24,825 --> 00:22:27,385
Speaker 4:  I think the answer is no, but it would be really, it, it would be really

356
00:22:27,585 --> 00:22:30,185
Speaker 4:  interesting to find out. But I, I do find that argument that even If you,

357
00:22:31,085 --> 00:22:34,705
Speaker 4:  If you sort of keep a thing called TikTok alive, but change everything about

358
00:22:34,705 --> 00:22:38,665
Speaker 4:  it, it kills TikTok. I think, I kind of think that's right. That feels right

359
00:22:38,665 --> 00:22:38,905
Speaker 4:  to me.

360
00:22:40,145 --> 00:22:44,025
Speaker 5:  I I'm, yeah, I I think it's hard to say. I think there is

361
00:22:44,385 --> 00:22:47,265
Speaker 5:  a huge benefit of having 170 million

362
00:22:48,265 --> 00:22:52,025
Speaker 5:  American users on the app already that can't be discounted and for sure all

363
00:22:52,025 --> 00:22:55,105
Speaker 5:  the content that already exists. I mean, that's a lot to work with.

364
00:22:56,495 --> 00:23:00,105
Speaker 5:  Even If you don't have, you know, this like secret sauce

365
00:23:00,105 --> 00:23:03,585
Speaker 5:  algorithm that fight dance has come up with, I think, you know,

366
00:23:04,345 --> 00:23:07,865
Speaker 5:  I could see how it might be possible to overlay another algorithm in here

367
00:23:07,975 --> 00:23:11,385
Speaker 5:  that is able to do something pretty good.

368
00:23:12,195 --> 00:23:15,885
Speaker 4:  Yeah, no, I, I, again, I like this is sort of the future I'm hoping for because

369
00:23:15,965 --> 00:23:18,805
Speaker 4:  I think it would just be fascinating. I would just love to see all of that

370
00:23:18,805 --> 00:23:21,725
Speaker 4:  play out, but I don't think it's gonna happen. What do you think is gonna

371
00:23:21,725 --> 00:23:25,245
Speaker 4:  happen here? Like the, we have five days from when this episode publishes

372
00:23:25,385 --> 00:23:28,845
Speaker 4:  to the, the January 19th deadline of some kind.

373
00:23:29,585 --> 00:23:33,525
Speaker 4:  It seems like to me the two most likely possibilities are

374
00:23:33,875 --> 00:23:37,575
Speaker 4:  that either the Supreme Court issue, some kind of

375
00:23:37,845 --> 00:23:41,695
Speaker 4:  stay, the, the, the ban is a day before the

376
00:23:41,695 --> 00:23:45,350
Speaker 4:  Trump inauguration and it seems reasonably logical that the, the Supreme

377
00:23:45,350 --> 00:23:47,870
Speaker 4:  Court might say we're just gonna let the next administration decide what

378
00:23:47,870 --> 00:23:49,205
Speaker 4:  it wants to do with this, or

379
00:23:51,035 --> 00:23:54,405
Speaker 4:  some kind of mix of those things will happen that

380
00:23:55,035 --> 00:23:57,845
Speaker 4:  like, and and you raised this possibility in a story you wrote about it that

381
00:23:57,845 --> 00:24:01,725
Speaker 4:  like the ban might happen, but then Trump might come in and decide not to

382
00:24:01,725 --> 00:24:05,605
Speaker 4:  care. But then that has some weird implications. Like what, what is

383
00:24:05,605 --> 00:24:08,085
Speaker 4:  your sense of fast forward seven days from now, what do you think's going

384
00:24:08,085 --> 00:24:08,245
Speaker 4:  on?

385
00:24:08,715 --> 00:24:12,485
Speaker 5:  Yeah, So I mean my best educated guess is

386
00:24:12,515 --> 00:24:16,485
Speaker 5:  that the ban does go into effect on January 19th.

387
00:24:16,545 --> 00:24:19,725
Speaker 5:  The Supreme Court lets it happen and then

388
00:24:20,415 --> 00:24:24,405
Speaker 5:  Trump gets inaugurated the next day. Perhaps he instructs

389
00:24:24,405 --> 00:24:26,245
Speaker 5:  his DOJ not to enforce it,

390
00:24:27,905 --> 00:24:31,485
Speaker 5:  but probably Google and Apple still follow it because

391
00:24:32,065 --> 00:24:35,605
Speaker 5:  as was pointed out in oral arguments, there's a

392
00:24:35,605 --> 00:24:39,445
Speaker 5:  five-year statute of limitation on this law. So if those

393
00:24:39,885 --> 00:24:43,805
Speaker 5:  companies break the law now, they could still be prosecuted for it

394
00:24:43,805 --> 00:24:47,645
Speaker 5:  later on unless, you know, they're able to argue that we were

395
00:24:48,095 --> 00:24:51,845
Speaker 5:  doing this under the, you know, promise that we wouldn't be

396
00:24:51,845 --> 00:24:55,805
Speaker 5:  prosecuted and perhaps they'll win that argument. But it

397
00:24:55,825 --> 00:24:58,325
Speaker 5:  is still risky for those companies. Right.

398
00:24:58,345 --> 00:25:01,965
Speaker 4:  So and the, and the, the two sort of practical pieces of the ban, if I have

399
00:25:01,965 --> 00:25:05,765
Speaker 4:  this right, are app stores can't host the app. So that,

400
00:25:05,765 --> 00:25:08,005
Speaker 4:  that's like what you're saying where Google and App will come in and I think

401
00:25:08,005 --> 00:25:11,805
Speaker 4:  they get fined for every person who downloads the app after the 19th

402
00:25:11,945 --> 00:25:12,965
Speaker 4:  is the idea. Yeah.

403
00:25:12,965 --> 00:25:16,845
Speaker 5:  They get fined $5,000 per user that accesses the app.

404
00:25:16,905 --> 00:25:18,845
Speaker 5:  Wow. So that really adds up. Oh

405
00:25:18,845 --> 00:25:22,645
Speaker 4:  Wow. Yeah. So, okay. So the theory then is even If you make it through the

406
00:25:22,645 --> 00:25:26,445
Speaker 4:  four years, some new president comes in in four

407
00:25:26,445 --> 00:25:30,125
Speaker 4:  years and says, just kidding, I'm going to enforce all four

408
00:25:30,125 --> 00:25:33,605
Speaker 4:  years of $5,000 per person fines. Right.

409
00:25:33,605 --> 00:25:37,485
Speaker 5:  Or Trump gets mad at Tim Cook or Sunup Chai.

410
00:25:37,905 --> 00:25:40,885
Speaker 4:  Oh sure. And then he just changes his mind, hold this over his Interesting,

411
00:25:40,995 --> 00:25:41,285
Speaker 4:  okay.

412
00:25:41,285 --> 00:25:45,245
Speaker 5:  Yeah. Although, you know, I think again it, what came up during oral arguments

413
00:25:45,265 --> 00:25:48,965
Speaker 5:  is perhaps they'd have some sort of due process claim to say,

414
00:25:49,345 --> 00:25:52,725
Speaker 5:  you know, we were operating under this promise of non-enforcement and maybe

415
00:25:52,725 --> 00:25:56,525
Speaker 5:  they would win that. But again, risky given how much they

416
00:25:56,675 --> 00:25:58,725
Speaker 5:  have at stake in penalties.

417
00:25:59,115 --> 00:26:03,005
Speaker 4:  Okay. Yeah. So best case scenario, that's a giant mess. And then the

418
00:26:03,005 --> 00:26:06,645
Speaker 4:  other sort of practical side of it is US

419
00:26:06,885 --> 00:26:10,125
Speaker 4:  providers are banned from hosting TikTok in any correct sort of meaningful

420
00:26:10,125 --> 00:26:13,925
Speaker 4:  way, right? So it's not like illegal to use TikTok

421
00:26:13,975 --> 00:26:17,925
Speaker 4:  after January 19th. It's just that essentially everyone who

422
00:26:17,925 --> 00:26:21,605
Speaker 4:  provides TikTok to you is no longer allowed to, so it has the effect of a

423
00:26:21,685 --> 00:26:24,805
Speaker 4:  ban, but like it's, it's not against the law to have TikTok on your phone

424
00:26:24,855 --> 00:26:26,205
Speaker 4:  after January 19th. Right,

425
00:26:26,355 --> 00:26:29,485
Speaker 5:  Exactly. Okay. And the app isn't just gonna like poof and disappear from

426
00:26:29,485 --> 00:26:33,285
Speaker 5:  your phone. It'll still be there just If you haven't downloaded it, you

427
00:26:33,285 --> 00:26:37,245
Speaker 5:  won't be able to. And If you have downloaded it, it's probably

428
00:26:37,245 --> 00:26:41,085
Speaker 5:  within a few weeks, months, we don't really know, we'll just

429
00:26:41,085 --> 00:26:43,805
Speaker 5:  start to degrade to a point that it becomes basically unusable.

430
00:26:43,995 --> 00:26:47,765
Speaker 4:  Yeah, I think anyone who has ever like had an old iPad and like app

431
00:26:47,825 --> 00:26:51,005
Speaker 4:  by app, it just sort of stops working because they don't update anymore 'cause

432
00:26:51,005 --> 00:26:53,605
Speaker 4:  they don't get the security updates or whatever. Like that's what'll happen

433
00:26:53,605 --> 00:26:57,245
Speaker 4:  to TikTok. Right. And it'll be sometime yeah, in the, in the weeks or months

434
00:26:57,245 --> 00:27:01,125
Speaker 4:  afterwards, like every individual feature will just start to break and then

435
00:27:01,125 --> 00:27:04,325
Speaker 4:  there won't be any more videos and then, and then that'll just be the end.

436
00:27:06,065 --> 00:27:09,885
Speaker 4:  So. Okay, so you think something, something this will happen on

437
00:27:09,885 --> 00:27:13,365
Speaker 4:  January 19th. What do you, what do you think happens on

438
00:27:13,665 --> 00:27:17,565
Speaker 4:  say January 21st, we'll, we'll stop for inauguration day 'cause you know,

439
00:27:17,995 --> 00:27:21,845
Speaker 4:  there's a whole thing that's gotta happen. What, what's your

440
00:27:21,845 --> 00:27:25,045
Speaker 4:  read on what might happen After that? What is kind of the, the betting favorite

441
00:27:25,545 --> 00:27:27,245
Speaker 4:  for, you know, the week after?

442
00:27:28,465 --> 00:27:31,705
Speaker 5:  I mean, I think it's possible that Trump then does

443
00:27:31,905 --> 00:27:35,545
Speaker 5:  instruct his DOJ not to enforce the law and then that just,

444
00:27:36,085 --> 00:27:40,025
Speaker 5:  you know, because at least for him that would give him a chance

445
00:27:40,025 --> 00:27:43,905
Speaker 5:  to say, look, I tried to save TikTok and if Apple and Google

446
00:27:44,035 --> 00:27:47,505
Speaker 5:  don't want to let you have it, then that's on them. Hmm.

447
00:27:48,205 --> 00:27:51,945
Speaker 5:  So I think it's possible we see something like that and then it's on those

448
00:27:52,225 --> 00:27:55,625
Speaker 5:  companies to decide what risks they're willing to take. I don't know that

449
00:27:55,625 --> 00:27:59,225
Speaker 5:  they're gonna be willing to stick their necks out for a, another company

450
00:28:00,645 --> 00:28:04,465
Speaker 5:  one with which Google, for example, competes with directly

451
00:28:04,465 --> 00:28:06,105
Speaker 5:  through YouTube shorts. So

452
00:28:07,785 --> 00:28:11,305
Speaker 5:  I think we will see some form of a ban. I think After

453
00:28:11,575 --> 00:28:15,545
Speaker 5:  that point, maybe we see some discussions about

454
00:28:16,505 --> 00:28:20,305
Speaker 5:  a deal. I think maybe Trump, instead of trying to get

455
00:28:20,305 --> 00:28:23,905
Speaker 5:  the DJ not to enforce the law, tries to use it as leverage to

456
00:28:24,095 --> 00:28:27,705
Speaker 5:  extract some kind of deal to end up making

457
00:28:27,805 --> 00:28:31,745
Speaker 5:  TikTok in compliance with the law. But like we were discussing earlier,

458
00:28:31,985 --> 00:28:35,665
Speaker 5:  I think it seems unlikely that China would actually be willing to sell the

459
00:28:35,665 --> 00:28:39,585
Speaker 5:  app. And that's really, that's really the bottom line is it's

460
00:28:39,585 --> 00:28:42,945
Speaker 5:  up to China to decide to sell it. And I think that's a big part of why we

461
00:28:42,945 --> 00:28:44,385
Speaker 5:  haven't seen a sale up to this point.

462
00:28:44,795 --> 00:28:48,625
Speaker 4:  Right, right. And do you think, If you were to tell 12 months

463
00:28:48,685 --> 00:28:51,545
Speaker 4:  ago you that this is the point that we've landed on

464
00:28:51,615 --> 00:28:55,425
Speaker 4:  January 14th, 2025, would you have been surprised?

465
00:28:55,705 --> 00:28:56,505
Speaker 4:  I would've been surprised,

466
00:28:57,855 --> 00:29:01,705
Speaker 5:  Yeah. I guess that would've been before this bill was even introduced.

467
00:29:01,885 --> 00:29:05,825
Speaker 5:  I'm pretty sure I would've been surprised. Mostly because not

468
00:29:05,825 --> 00:29:09,545
Speaker 5:  much happens to, you know, to the point of

469
00:29:09,835 --> 00:29:13,505
Speaker 5:  being introduced into law and,

470
00:29:14,085 --> 00:29:17,985
Speaker 5:  you know, going to the Supreme Court in tech policy, you know, we've tried

471
00:29:17,985 --> 00:29:21,665
Speaker 5:  to get much more, you know, basic things passed

472
00:29:21,765 --> 00:29:25,665
Speaker 5:  in tech policy, like privacy legislation, you know, basic privacy

473
00:29:25,815 --> 00:29:29,745
Speaker 5:  protections. And that has been just held up

474
00:29:30,085 --> 00:29:33,865
Speaker 5:  in Congress for years and years and years and somehow they were able to

475
00:29:34,445 --> 00:29:38,145
Speaker 5:  get, you know, hundreds of lawmakers behind this law

476
00:29:38,285 --> 00:29:42,155
Speaker 5:  in very short order. And we're now at the point that the Supreme

477
00:29:42,155 --> 00:29:45,995
Speaker 5:  Court is about to give a thumbs up or a thumbs down on it,

478
00:29:45,995 --> 00:29:46,435
Speaker 5:  basically.

479
00:29:46,985 --> 00:29:50,195
Speaker 4:  Yeah. If you've trained me on one thing in the time that I've known you,

480
00:29:50,195 --> 00:29:54,115
Speaker 4:  it's that the speed of this is insane. Yeah. Like a, the fact

481
00:29:54,115 --> 00:29:57,835
Speaker 4:  that it happened that it managed to go through this whole process in a

482
00:29:57,835 --> 00:30:01,755
Speaker 4:  relatively bipartisan way is remarkable given what happens to the tech. But

483
00:30:02,265 --> 00:30:05,795
Speaker 4:  also the fact that we did it in essentially like eight months is just

484
00:30:05,795 --> 00:30:09,715
Speaker 4:  unheard of. Like it's, yeah, it's, and given the fact that we had tried

485
00:30:09,715 --> 00:30:13,235
Speaker 4:  this before and it failed and everybody was mad for a long time, but kind

486
00:30:13,235 --> 00:30:16,795
Speaker 4:  of nothing happened and then just all of a sudden like poof out of nowhere

487
00:30:17,255 --> 00:30:21,235
Speaker 4:  and it just runs through this whole process in eight months and might actually

488
00:30:21,235 --> 00:30:25,155
Speaker 4:  finish on January 19th, is, is just procedurally

489
00:30:25,385 --> 00:30:25,675
Speaker 4:  wild.

490
00:30:26,105 --> 00:30:29,995
Speaker 5:  Yeah. Yeah. I mean this is extremely unusual for tech policy

491
00:30:30,255 --> 00:30:33,395
Speaker 5:  for Congress in general. It's very much unprecedented.

492
00:30:33,625 --> 00:30:36,955
Speaker 4:  Yeah. Alright, before I let you go, let's just talk for five minutes about

493
00:30:37,025 --> 00:30:40,835
Speaker 4:  meta. Sure. We talked a little bit about this on the show last week in Vegas.

494
00:30:41,735 --> 00:30:45,515
Speaker 4:  The, the moderation changes the company's been making. Mark Zuckerberg went

495
00:30:45,515 --> 00:30:47,995
Speaker 4:  on Joe Rogan and had a lot of thoughts about masculinity.

496
00:30:50,045 --> 00:30:52,475
Speaker 4:  We'll leave that to the site. I think there are a couple of stories we wrote

497
00:30:52,475 --> 00:30:54,875
Speaker 4:  that are very good that I'll put in the show notes that you should go read.

498
00:30:54,875 --> 00:30:58,395
Speaker 4:  But I'm particularly curious for you as a person covering like

499
00:30:58,715 --> 00:31:02,555
Speaker 4:  politics and policy, what do you, what do you make of all of

500
00:31:02,555 --> 00:31:05,795
Speaker 4:  these moves that are making, this is happening right before we inaugurate

501
00:31:05,795 --> 00:31:08,875
Speaker 4:  a new president, a new, a new administration is about to come in.

502
00:31:09,865 --> 00:31:12,435
Speaker 4:  What are you seeing in the, the politicking of all of this?

503
00:31:13,265 --> 00:31:17,235
Speaker 5:  Yeah, So I think I kind of separat it into two buckets in

504
00:31:17,235 --> 00:31:21,155
Speaker 5:  my mind, the first bucket is like what normally happens when there's

505
00:31:21,155 --> 00:31:25,115
Speaker 5:  a change in administration and businesses realize, alright, we

506
00:31:25,115 --> 00:31:27,555
Speaker 5:  gotta, we gotta figure out how we're gonna deal with this for the next four

507
00:31:27,555 --> 00:31:31,035
Speaker 5:  years. So, you know, I think things like having Joel

508
00:31:31,215 --> 00:31:34,875
Speaker 5:  Kaplan take over a lot of their policy operations

509
00:31:35,465 --> 00:31:39,395
Speaker 5:  make sense. I think that's a very kind of standard move to kind of have

510
00:31:39,395 --> 00:31:43,195
Speaker 5:  someone who's more in line with the current administration lead your policy

511
00:31:43,195 --> 00:31:44,035
Speaker 5:  office. Yeah.

512
00:31:44,235 --> 00:31:47,595
Speaker 4:  I also put the, everybody donating to the inauguration fund in that same

513
00:31:47,595 --> 00:31:49,635
Speaker 4:  bucket. Totally. That it's like totally, you could be cynical about that

514
00:31:49,635 --> 00:31:52,155
Speaker 4:  all you want and you can be mad that companies don't live out their values,

515
00:31:52,515 --> 00:31:56,475
Speaker 4:  whatever. But like that is the most straightforward transactional. We would

516
00:31:56,475 --> 00:32:00,275
Speaker 4:  like to be in a room with the new president more often move and

517
00:32:00,275 --> 00:32:01,555
Speaker 4:  every company is going to do it

518
00:32:01,805 --> 00:32:05,155
Speaker 5:  Right. I think no one's gonna, none of these companies are going to

519
00:32:05,625 --> 00:32:09,355
Speaker 5:  just say, you know what? On principle we're gonna sit this one

520
00:32:09,555 --> 00:32:13,475
Speaker 5:  out. We're gonna like, I don't think that's really in any of their interests.

521
00:32:13,475 --> 00:32:17,395
Speaker 5:  They want to have a seat at the table, they wanna have a good starting point.

522
00:32:18,535 --> 00:32:22,075
Speaker 5:  And, you know, I don't think it's that big of a deal to them to

523
00:32:22,295 --> 00:32:26,115
Speaker 5:  donate a million dollars to these like multi-billion dollar corporations.

524
00:32:27,575 --> 00:32:31,475
Speaker 5:  So I think yeah, that's definitely in the same bucket to me. And

525
00:32:31,515 --> 00:32:35,395
Speaker 5:  I think there's also the fact that Elon Musk is right in Trump's ear.

526
00:32:35,545 --> 00:32:38,995
Speaker 5:  Yeah. And I think they realize if we're not at the table, then the only person

527
00:32:39,085 --> 00:32:42,965
Speaker 5:  they're hearing from in tech is Elon Musk and Yep. Do we wanna go along

528
00:32:42,965 --> 00:32:46,525
Speaker 5:  with all the policies that only he is representing to Trump? So

529
00:32:47,045 --> 00:32:50,805
Speaker 5:  I think they all know like, we need to, we need to be in play here. And I

530
00:32:50,805 --> 00:32:54,565
Speaker 5:  think a lot of the moves are about that. I think there's also, you know,

531
00:32:54,565 --> 00:32:57,725
Speaker 5:  things like the end of fact checking at meta

532
00:32:58,335 --> 00:33:01,525
Speaker 5:  seems like something that maybe Mark Zuckerberg wanted to do for a while,

533
00:33:01,745 --> 00:33:05,565
Speaker 5:  and this is a, you know, a good way for him to do it while also

534
00:33:05,565 --> 00:33:09,485
Speaker 5:  kind of gaining some points with Trump. Then I think there's like this other

535
00:33:09,485 --> 00:33:13,165
Speaker 5:  bucket where it's, you know, things that are really geared at

536
00:33:13,255 --> 00:33:16,925
Speaker 5:  Trump in particular at, you know, this full Republican

537
00:33:17,055 --> 00:33:20,285
Speaker 5:  sweep across the government that we're going to see take over.

538
00:33:22,025 --> 00:33:25,805
Speaker 5:  And I think, you know, it's a recognition that the times have changed. We

539
00:33:25,805 --> 00:33:29,765
Speaker 5:  have to really change how we go about things. And also

540
00:33:29,765 --> 00:33:32,965
Speaker 5:  maybe perhaps a sense from within Zuckerberg himself that

541
00:33:34,355 --> 00:33:38,165
Speaker 5:  he's felt like we've gone too far or, you know, this

542
00:33:38,165 --> 00:33:41,165
Speaker 5:  isn't the way that I want to run this company. I think we've always seen

543
00:33:41,185 --> 00:33:45,165
Speaker 5:  him kind of say, he doesn't wanna be the speech police, he doesn't wanna

544
00:33:45,165 --> 00:33:48,805
Speaker 5:  decide what's right and wrong. And I think we've seen that

545
00:33:48,915 --> 00:33:52,165
Speaker 5:  impulse take different iterations, whether it's the oversight board

546
00:33:52,945 --> 00:33:56,885
Speaker 5:  or something else. And now we're seeing it take shape with him trying

547
00:33:56,905 --> 00:34:00,285
Speaker 5:  to not involve fact checkers and to really loosen

548
00:34:00,545 --> 00:34:04,045
Speaker 5:  speech policies on his platforms. And I think

549
00:34:04,505 --> 00:34:08,405
Speaker 5:  the, the fact checking again, I think seems like something he wanted

550
00:34:08,405 --> 00:34:11,645
Speaker 5:  to do for a long time. I think the changes to,

551
00:34:12,705 --> 00:34:16,005
Speaker 5:  you know, what sort of speech is allowed on meta platforms

552
00:34:16,505 --> 00:34:20,445
Speaker 5:  is probably like the more overall impactful thing because there's

553
00:34:20,445 --> 00:34:23,005
Speaker 5:  just gonna be a wider range of the kinds of

554
00:34:24,025 --> 00:34:27,965
Speaker 5:  speech that you're going to see on those platforms that I think a lot

555
00:34:27,965 --> 00:34:29,165
Speaker 5:  of users probably won't wanna see.

556
00:34:29,915 --> 00:34:33,845
Speaker 4:  Yeah. I think one version of his

557
00:34:33,845 --> 00:34:37,045
Speaker 4:  thinking, he being Mark Zuckerberg that I actually find

558
00:34:38,545 --> 00:34:42,525
Speaker 4:  if not good then at least sort of reasonable, is that I think

559
00:34:42,525 --> 00:34:45,685
Speaker 4:  he has spent a long time learning that

560
00:34:46,105 --> 00:34:49,965
Speaker 4:  trying to be out front of speech policy is a total waste of time That

561
00:34:49,965 --> 00:34:53,725
Speaker 4:  Yep. That caring about this stuff politically is

562
00:34:53,865 --> 00:34:57,805
Speaker 4:  all downside. And, and it has, it has gained him nothing. And I think after

563
00:34:57,835 --> 00:35:00,485
Speaker 4:  four years of fighting with the Biden administration about all the bad things

564
00:35:00,485 --> 00:35:03,605
Speaker 4:  that are happening on meta platforms, he is now just like, you know what?

565
00:35:03,605 --> 00:35:06,285
Speaker 4:  Screw it. Like, I, I don't care. There is now a president who doesn't care.

566
00:35:07,025 --> 00:35:10,645
Speaker 4:  Why on earth would I continue to fight this fight? All it does is cause me

567
00:35:10,675 --> 00:35:14,565
Speaker 4:  pain. And I think a, that is a

568
00:35:14,565 --> 00:35:18,005
Speaker 4:  perfectly reasonable place for him to have landed. And BI think that sucks,

569
00:35:18,135 --> 00:35:21,765
Speaker 4:  right? Like, that is a, that is a real problem for a lot of people on a lot

570
00:35:21,765 --> 00:35:25,525
Speaker 4:  of platforms, but I also kind of understand how he got there and it, it,

571
00:35:25,525 --> 00:35:28,965
Speaker 4:  like, it says a lot about our political environment that both of those things

572
00:35:28,985 --> 00:35:32,165
Speaker 4:  can be true at the same time. But I do wonder, like, are we just at a point

573
00:35:32,265 --> 00:35:36,205
Speaker 4:  now where we're just gonna stop talking about speech policy because it's

574
00:35:36,205 --> 00:35:38,045
Speaker 4:  just a total waste of everybody's time and energy?

575
00:35:39,085 --> 00:35:42,045
Speaker 5:  I think that's highly possible. I think it feels so bleak

576
00:35:42,045 --> 00:35:44,285
Speaker 4:  To say out loud, but I honestly feel like that's where we are.

577
00:35:45,165 --> 00:35:49,145
Speaker 5:  No, I think So I think, you know, we went from this world of like, you

578
00:35:49,145 --> 00:35:52,945
Speaker 5:  know, oh, social media platforms are so new and you know, it's just the

579
00:35:52,945 --> 00:35:56,545
Speaker 5:  wild West and everyone says whatever they want. And then

580
00:35:56,615 --> 00:36:00,425
Speaker 5:  realizing, okay, well we can't get advertisers on here if we just have

581
00:36:00,525 --> 00:36:04,105
Speaker 5:  actual Nazis here and people don't wanna see that stuff.

582
00:36:05,125 --> 00:36:08,305
Speaker 5:  And I think, you know, we went through kind of a big reckoning where we went

583
00:36:08,705 --> 00:36:12,345
Speaker 5:  a lot in the other direction, and then I think the

584
00:36:12,585 --> 00:36:16,065
Speaker 5:  companies realized, oh, actually by actively doing

585
00:36:16,065 --> 00:36:19,345
Speaker 5:  something around speech policies,

586
00:36:19,875 --> 00:36:23,425
Speaker 5:  we're getting a lot of flack because we're both being told we're not going

587
00:36:23,445 --> 00:36:27,185
Speaker 5:  far enough and we're being told we're going too far. Right? And so we can't

588
00:36:27,185 --> 00:36:30,545
Speaker 5:  win. And So I think this is kind of, you know, mark Zuckerberg throwing up

589
00:36:30,545 --> 00:36:34,425
Speaker 5:  his hand saying like, all right, you know, more than half the

590
00:36:34,425 --> 00:36:35,825
Speaker 5:  country voted for Trump this time

591
00:36:37,445 --> 00:36:41,425
Speaker 5:  and, you know, whatever. Like, let's like not do

592
00:36:41,425 --> 00:36:43,865
Speaker 5:  something instead of doing something and we'll still get yelled at either

593
00:36:43,885 --> 00:36:44,105
Speaker 5:  way.

594
00:36:44,745 --> 00:36:47,425
Speaker 4:  Right. Yeah. How much do you think this is about

595
00:36:48,745 --> 00:36:52,675
Speaker 4:  Mark Zuckerberg in particular? Because, you know, a lot has been made

596
00:36:52,675 --> 00:36:56,115
Speaker 4:  of, of Trump's prognostications about throwing Zuckerberg in jail for the

597
00:36:56,115 --> 00:37:00,035
Speaker 4:  rest of his life. And there has obviously been some tension here. But

598
00:37:00,035 --> 00:37:03,555
Speaker 4:  then on the flip side, I I agree with you that watching him

599
00:37:04,055 --> 00:37:07,395
Speaker 4:  sit there with Joe Rogan, it felt like he was unloading a bunch of stuff

600
00:37:07,395 --> 00:37:10,875
Speaker 4:  that has been sitting on his chest for a very long time. So

601
00:37:11,555 --> 00:37:14,795
Speaker 4:  I, I guess this is sort of an impossible question to answer, but like, to

602
00:37:14,795 --> 00:37:17,795
Speaker 4:  what extent do you think this is him playing politics with a new president

603
00:37:18,015 --> 00:37:21,835
Speaker 4:  versus like freed by a new president to just say the things he

604
00:37:21,835 --> 00:37:24,065
Speaker 4:  already believed? And I'm sure it's some of both.

605
00:37:24,425 --> 00:37:28,305
Speaker 5:  I, yeah, I definitely think it's both. I think, you know, if,

606
00:37:28,445 --> 00:37:32,385
Speaker 5:  if you're threatened by Donald Trump with being thrown in jail, you know,

607
00:37:32,805 --> 00:37:36,785
Speaker 5:  he, he says a lot of things and maybe he's not actually gonna try to do that,

608
00:37:36,805 --> 00:37:40,625
Speaker 5:  but like maybe he will. And I think you would wanna get on his good side.

609
00:37:41,565 --> 00:37:45,505
Speaker 5:  So I'm, I'd imagine that's a factor in his thinking. At

610
00:37:45,505 --> 00:37:49,225
Speaker 5:  the same time, I think from a lot of recent interviews that Mark Zuckerberg

611
00:37:49,245 --> 00:37:52,865
Speaker 5:  has done, I think there's this sense that he is like sick of apologizing

612
00:37:53,045 --> 00:37:56,945
Speaker 5:  and he's like sick of having always been the bad guy

613
00:37:57,245 --> 00:38:01,185
Speaker 5:  and, you know, having to try to do the right thing and everyone

614
00:38:01,185 --> 00:38:04,865
Speaker 5:  yells at him no matter what. So I think it, it seems like it is somewhat

615
00:38:04,865 --> 00:38:08,505
Speaker 5:  a personal change in thinking of like, well, I can't please

616
00:38:08,865 --> 00:38:12,745
Speaker 5:  everyone, so let me please the person who has the

617
00:38:12,745 --> 00:38:15,185
Speaker 5:  most power here for the next four years. Right.

618
00:38:15,415 --> 00:38:18,625
Speaker 4:  Just to be clear, we don't feel bad for Mark Zuckerberg No. Having, having

619
00:38:18,645 --> 00:38:21,665
Speaker 4:  to have spent all this time apologizing for the thing that you built. I don't

620
00:38:21,665 --> 00:38:25,625
Speaker 4:  feel that bad. Sorry, buddy. But, but yeah. And I, I,

621
00:38:25,625 --> 00:38:28,705
Speaker 4:  what I wonder is how much

622
00:38:29,335 --> 00:38:32,465
Speaker 4:  fallout that is going to have, right? Because he is like, we are in a moment

623
00:38:32,465 --> 00:38:36,245
Speaker 4:  where it is now really easy to say the things that people

624
00:38:36,245 --> 00:38:39,765
Speaker 4:  have been saying quietly for years loudly. And I think

625
00:38:40,065 --> 00:38:43,325
Speaker 4:  the, the, we're starting to see those policies start to shift and we're starting

626
00:38:43,325 --> 00:38:46,885
Speaker 4:  to see that the, like forced culture shift back to

627
00:38:47,075 --> 00:38:50,965
Speaker 4:  some things that had started to change but now are being unwound

628
00:38:50,965 --> 00:38:54,645
Speaker 4:  again. And the question of like, is this

629
00:38:54,715 --> 00:38:58,525
Speaker 4:  just Mark, is this just meta or is

630
00:38:58,525 --> 00:39:02,485
Speaker 4:  there a broader sort of Silicon Valley culture change coming in? All of

631
00:39:02,485 --> 00:39:05,885
Speaker 4:  that to me is like one of the big questions of the next few months. And

632
00:39:06,565 --> 00:39:10,445
Speaker 4:  I got the sense even just talking to folks After that Rogan podcast

633
00:39:10,955 --> 00:39:13,685
Speaker 4:  that like, I think we're gonna look back at that as a moment where like,

634
00:39:13,685 --> 00:39:17,365
Speaker 4:  it, it, somebody said the quiet parts really, really, really, really loud

635
00:39:18,145 --> 00:39:20,325
Speaker 4:  and got away with it, and now here we are.

636
00:39:21,035 --> 00:39:24,085
Speaker 5:  Yeah. I mean I think we've definitely seen this culture shift in Silicon

637
00:39:24,105 --> 00:39:27,765
Speaker 5:  Valley and I think there's always been maybe some underpinning of that

638
00:39:27,905 --> 00:39:31,885
Speaker 5:  in kind of this more libertarian slant that, you know,

639
00:39:31,885 --> 00:39:35,725
Speaker 5:  Silicon Valley tech people have tended to have for a long

640
00:39:35,725 --> 00:39:39,405
Speaker 5:  time. At the same time, I think it, you always have to look

641
00:39:39,665 --> 00:39:43,285
Speaker 5:  at like, what's gonna go on with the actual businesses. And If you look at

642
00:39:43,345 --> 00:39:47,245
Speaker 5:  Meta's business, you know, to tie back to the TikTok thing, if TikTok is

643
00:39:47,245 --> 00:39:51,165
Speaker 5:  banned, Meta's gonna be like almost the only game in town

644
00:39:51,265 --> 00:39:55,245
Speaker 5:  for Yeah. Like these short form videos. Obviously there's also YouTube shorts,

645
00:39:56,025 --> 00:39:59,925
Speaker 5:  but you know, that's a TikTok is a huge competitor and then you

646
00:39:59,925 --> 00:40:03,405
Speaker 5:  think about their meta's also involved in a

647
00:40:03,515 --> 00:40:06,725
Speaker 5:  anti-monopoly suit from the FTC.

648
00:40:07,385 --> 00:40:11,165
Speaker 5:  And you know, part of the thinking behind that is that,

649
00:40:11,745 --> 00:40:14,885
Speaker 5:  you know, meta has become so big and stayed so big because

650
00:40:15,395 --> 00:40:18,485
Speaker 5:  they're one of the only places to go and they've made that,

651
00:40:19,515 --> 00:40:22,605
Speaker 5:  they've made sure that's the case. Those are the allegations that the FTC

652
00:40:22,605 --> 00:40:26,445
Speaker 5:  would have. So I think, you know, are

653
00:40:26,445 --> 00:40:30,045
Speaker 5:  people really going to leave Facebook and Instagram if they

654
00:40:30,245 --> 00:40:34,045
Speaker 5:  disagree with these policies? Some might, but probably not

655
00:40:34,045 --> 00:40:37,565
Speaker 5:  enough to really warrant Zuckerberg, you know, doing another

656
00:40:37,625 --> 00:40:38,725
Speaker 5:  180 on his thinking

657
00:40:38,725 --> 00:40:41,925
Speaker 4:  Here. Yeah. Historically speaking the answer is no. Some people leave very

658
00:40:41,925 --> 00:40:45,845
Speaker 4:  loudly and most people don't. Exactly. And, and I think more and

659
00:40:45,845 --> 00:40:49,245
Speaker 4:  more people are getting more and more willing to make that small trade in

660
00:40:49,245 --> 00:40:52,725
Speaker 4:  favor of some of these other things like hoping that Trump will not try and

661
00:40:52,725 --> 00:40:55,445
Speaker 4:  break your company up, which is a real thing that's sitting in front of Mark

662
00:40:55,445 --> 00:40:55,885
Speaker 4:  Zuckerberg.

663
00:40:56,355 --> 00:40:57,085
Speaker 5:  Yeah, exactly.

664
00:40:57,485 --> 00:41:01,205
Speaker 4:  I just wanna say that if the end of 2025 is I have to use

665
00:41:01,205 --> 00:41:05,125
Speaker 4:  Instagram reels exclusively, then this sucks. I

666
00:41:05,125 --> 00:41:08,685
Speaker 4:  will, I will, I want any outcome that does not end with me having to use

667
00:41:08,685 --> 00:41:10,285
Speaker 4:  Instagram reels. That's all

668
00:41:10,285 --> 00:41:14,205
Speaker 5:  I want. Yeah. I mean, if the end of 2025 is anything like the end

669
00:41:14,205 --> 00:41:17,765
Speaker 5:  of 2024, I think we, we don't know what's gonna happen this year. Yeah,

670
00:41:17,765 --> 00:41:20,605
Speaker 4:  That's, that's, that's very real. All right, Lauren, thank you as always.

671
00:41:20,765 --> 00:41:24,085
Speaker 4:  I suspect we are going to do this Oh so many times and I suspect at some

672
00:41:24,085 --> 00:41:26,445
Speaker 4:  point you and I are gonna be in a courtroom together this year and I'm very

673
00:41:26,445 --> 00:41:27,245
Speaker 4:  much looking forward to it.

674
00:41:27,535 --> 00:41:28,045
Speaker 5:  Can't wait.

675
00:41:28,555 --> 00:41:29,485
Speaker 4:  Alright, see ya.

676
00:41:30,225 --> 00:41:30,445
Speaker 5:  Bye.

677
00:41:31,515 --> 00:41:34,400
Speaker 4:  Alright, we gotta take a break and then we're gonna come back and we're gonna

678
00:41:34,400 --> 00:41:36,005
Speaker 4:  talk Kickstarter. We'll be right back.

679
00:42:56,875 --> 00:43:00,805
Speaker 4:  Alright, we're back. So I was at CES last week and one of the

680
00:43:00,805 --> 00:43:04,125
Speaker 4:  things that you see at CES is just an infinite supply

681
00:43:04,745 --> 00:43:08,525
Speaker 4:  of new ideas about technology. You also see an infinite

682
00:43:08,525 --> 00:43:12,485
Speaker 4:  supply of copycat ideas about new technology. One of the amazing things

683
00:43:12,485 --> 00:43:16,125
Speaker 4:  about CES is how quickly you see ideas percolate. Somebody

684
00:43:16,125 --> 00:43:19,765
Speaker 4:  invents a thing and then it just spreads like wildfire among every other

685
00:43:19,765 --> 00:43:23,525
Speaker 4:  company because things are mostly easy to make now. And I think that's

686
00:43:23,725 --> 00:43:27,525
Speaker 4:  fascinating, but to me it's the new stuff that I think is most interesting.

687
00:43:27,525 --> 00:43:31,485
Speaker 4:  You see so many booze that are just one person standing there

688
00:43:31,555 --> 00:43:35,325
Speaker 4:  with a thing that they made and they're there to show it to people, but

689
00:43:35,325 --> 00:43:38,725
Speaker 4:  also to try to get funding and to try to make partnerships. And it is very

690
00:43:38,725 --> 00:43:42,605
Speaker 4:  much a trade show in that sense. And so much of what

691
00:43:42,625 --> 00:43:46,525
Speaker 4:  we see in the world comes from like a person standing in a booth with

692
00:43:46,525 --> 00:43:50,365
Speaker 4:  a thing that they made. And those are the people. Kickstarter has always

693
00:43:50,535 --> 00:43:54,485
Speaker 4:  tried to help. Kickstarter has been around for many years now and

694
00:43:54,485 --> 00:43:57,645
Speaker 4:  has gotten lots of interesting products off the ground. There's a decent

695
00:43:57,645 --> 00:44:01,445
Speaker 4:  chance that a lot of gadgets that you use start on Kickstarter.

696
00:44:01,465 --> 00:44:05,165
Speaker 4:  The Aura Ring, I think was a Kickstarter, pebble was a Kickstarter. Lots

697
00:44:05,165 --> 00:44:07,605
Speaker 4:  of things have grown really huge out of Kickstarter,

698
00:46:01,315 --> 00:46:05,035
Speaker 6:  new into the world, then I go to Kickstarter. Kickstarter has evolved

699
00:46:05,495 --> 00:46:08,915
Speaker 6:  to the point where now we still have tons of creators who

700
00:46:10,105 --> 00:46:13,715
Speaker 6:  need to get, get the money to get things off the ground, but

701
00:46:14,535 --> 00:46:17,795
Speaker 6:  as the company has evolved

702
00:46:18,495 --> 00:46:21,875
Speaker 6:  now we have, you know, billion dollar multinational

703
00:46:22,155 --> 00:46:25,235
Speaker 6:  corporations, big tech companies, big creators

704
00:46:26,385 --> 00:46:30,315
Speaker 6:  that are well established, that values the community and the

705
00:46:30,315 --> 00:46:33,875
Speaker 6:  millions of people within the Kickstarter community where it's like, Hey,

706
00:46:33,935 --> 00:46:37,475
Speaker 6:  If you wanna launch anything new, no matter where you are in your career,

707
00:46:37,725 --> 00:46:41,715
Speaker 6:  where you are in the life cycle as a creator or entrepreneur or as

708
00:46:41,715 --> 00:46:45,355
Speaker 6:  a business, Kickstarter is a valuable community because we have

709
00:46:45,465 --> 00:46:49,435
Speaker 6:  such incredible backers that want to just support new

710
00:46:49,435 --> 00:46:52,955
Speaker 6:  things. And I think what's beautiful about Kickstarter, especially over the

711
00:46:52,955 --> 00:46:56,675
Speaker 6:  past couple years, is that we've evolved past just a crowdfunding

712
00:46:56,995 --> 00:47:00,715
Speaker 6:  platform. Mm. We're building new products and features, new

713
00:47:00,955 --> 00:47:04,635
Speaker 6:  business lines to support creators throughout the

714
00:47:04,695 --> 00:47:08,675
Speaker 6:  entire lifecycle of, you know, their creator journey or

715
00:47:08,675 --> 00:47:12,195
Speaker 6:  their, their entrepreneurial journey. So it's not just about, hey, you know,

716
00:47:12,195 --> 00:47:14,635
Speaker 6:  before it was like, Hey, I'm gonna raise some money on Kickstarter, and then

717
00:47:14,635 --> 00:47:18,355
Speaker 6:  it was like, good luck. Now Kickstarter is building this ecosystem of

718
00:47:18,355 --> 00:47:22,235
Speaker 6:  products, features, and services that help you throughout the entire lifecycle

719
00:47:22,295 --> 00:47:22,875
Speaker 6:  as a creator.

720
00:47:23,575 --> 00:47:26,075
Speaker 4:  So, okay, I was gonna get to this later, but you, you just brought up one

721
00:47:26,075 --> 00:47:30,045
Speaker 4:  of the things that I most wanted to talk about, which is that shift

722
00:47:30,155 --> 00:47:33,805
Speaker 4:  from like, I've made a thing and I need some money to make more of them

723
00:47:34,305 --> 00:47:37,765
Speaker 4:  to big established companies launching stuff on

724
00:47:37,765 --> 00:47:41,565
Speaker 4:  Kickstarter. And Yeah, candidly, I've always wondered if that's a thing Kickstarter

725
00:47:41,565 --> 00:47:45,205
Speaker 4:  like secretly hates that it, it like, it, it like breaks the vibe of the

726
00:47:45,605 --> 00:47:48,765
Speaker 4:  platform for like a multinational corporation to come show up and try to

727
00:47:48,765 --> 00:47:52,125
Speaker 4:  crowdfund something. Yeah. But there is something about

728
00:47:52,995 --> 00:47:56,925
Speaker 4:  that that continues to work for these companies. And I've never

729
00:47:56,925 --> 00:48:00,685
Speaker 4:  been able to put my finger on exactly why. And even as we cover it, it's

730
00:48:00,685 --> 00:48:03,485
Speaker 4:  a challenge because like, it is that whole gamut of things and it's like,

731
00:48:03,485 --> 00:48:07,085
Speaker 4:  okay, here is a product that's being launched. It could be either

732
00:48:07,195 --> 00:48:10,965
Speaker 4:  like a dude who made a thing with a 3D printer and now wants to figure

733
00:48:10,985 --> 00:48:14,405
Speaker 4:  out how to go make millions of them. Yeah. But it could also be a company

734
00:48:14,405 --> 00:48:17,165
Speaker 4:  that's done this 20 times and is perfectly reputable and this thing is gonna

735
00:48:17,165 --> 00:48:20,845
Speaker 4:  launch no matter what happens. And I think trying to figure out how

736
00:48:20,845 --> 00:48:24,725
Speaker 4:  Kickstarter sort of can be all of those things is,

737
00:48:25,305 --> 00:48:28,405
Speaker 4:  has, has just always been tricky for me as somebody like covering these gadgets

738
00:48:28,405 --> 00:48:32,205
Speaker 4:  and talking about them. Can, can Kickstarter be all those things

739
00:48:32,225 --> 00:48:33,005
Speaker 4:  to all those people?

740
00:48:33,795 --> 00:48:37,725
Speaker 6:  Yeah, I, I think So. I mean, I think first of all, I will, I

741
00:48:37,725 --> 00:48:41,325
Speaker 6:  will say this, when larger creators or larger companies with larger

742
00:48:41,805 --> 00:48:45,605
Speaker 6:  audiences come onto the platform, like it just brings eyes

743
00:48:45,625 --> 00:48:49,445
Speaker 6:  and attention to other things that's on the platform, it grows the

744
00:48:49,445 --> 00:48:53,005
Speaker 6:  community. And so yes, is there always gonna be a subset of people

745
00:48:53,275 --> 00:48:57,085
Speaker 6:  like, you know, vocal minority, that's like, Hey, I don't like that L'Oreal

746
00:48:57,085 --> 00:49:00,645
Speaker 6:  just dropped something on Kickstarter or whatever, which

747
00:49:00,835 --> 00:49:02,685
Speaker 6:  they drop something very awesome. But

748
00:49:04,265 --> 00:49:08,065
Speaker 6:  yes, we're gonna continue to have that, right? But the numbers

749
00:49:08,115 --> 00:49:11,945
Speaker 6:  don't lie, the data doesn't lie. Them coming to the platform

750
00:49:12,465 --> 00:49:16,305
Speaker 6:  actually helps smaller creators tremendously because of the visibility

751
00:49:16,305 --> 00:49:20,265
Speaker 6:  that it brings to the platform and to other projects that are

752
00:49:20,465 --> 00:49:24,065
Speaker 6:  currently on the platform. So we see an uptick for other projects

753
00:49:24,495 --> 00:49:28,145
Speaker 6:  when those big creators or those big companies come to the platform.

754
00:49:28,325 --> 00:49:32,145
Speaker 6:  So it's actually helpful. And one thing that I think is beautiful

755
00:49:32,145 --> 00:49:36,105
Speaker 6:  about our community, specifically for design and technology and

756
00:49:36,105 --> 00:49:39,865
Speaker 6:  new innovation, they're less attached to,

757
00:49:40,005 --> 00:49:43,985
Speaker 6:  or they, they tend to be less attached to who is doing it and more

758
00:49:43,985 --> 00:49:47,865
Speaker 6:  about what it is. Like they just want the, the coolest,

759
00:49:48,125 --> 00:49:51,945
Speaker 6:  newest in most innovative thing. They're not so

760
00:49:52,015 --> 00:49:55,905
Speaker 6:  tied to who that person is, which is a little bit

761
00:49:55,905 --> 00:49:59,545
Speaker 6:  different when you get to categories like film and music and more

762
00:49:59,785 --> 00:50:03,745
Speaker 6:  creative categories, right? And so to me, I think we can, we can

763
00:50:03,745 --> 00:50:07,185
Speaker 6:  serve both because we have an audience of people that just want

764
00:50:07,325 --> 00:50:10,425
Speaker 6:  really, really cool products right? At the end of the day.

765
00:50:10,885 --> 00:50:14,755
Speaker 4:  That's really interesting. Yeah, and I think one of the questions I

766
00:50:14,755 --> 00:50:18,395
Speaker 4:  think Kickstarter has always tried to reckon with is do we treat these things

767
00:50:18,625 --> 00:50:22,275
Speaker 4:  like sort of transactional businesses or do we treat them

768
00:50:22,345 --> 00:50:25,915
Speaker 4:  like content creators, right? Because like, I think there, it's a really

769
00:50:25,915 --> 00:50:29,365
Speaker 4:  complicated balance, right? Because on the one hand it's like, I buy,

770
00:50:30,285 --> 00:50:34,245
Speaker 4:  I, I pre-order a cooler, I expect that cooler to ship to my house,

771
00:50:34,245 --> 00:50:36,365
Speaker 4:  right? Yes. Like that's a pretty straightforward transaction that we're all

772
00:50:36,365 --> 00:50:40,165
Speaker 4:  used to all the time. But if I back a creator that I like, the,

773
00:50:40,545 --> 00:50:42,525
Speaker 4:  the thing that I ask for in return is more

774
00:50:44,165 --> 00:50:47,645
Speaker 4:  squishy and nebulous. Like, if they don't make anything, that's probably

775
00:50:47,665 --> 00:50:51,325
Speaker 4:  bad, but I don't expect like complete control and specificity over what they're

776
00:50:51,325 --> 00:50:55,285
Speaker 4:  gonna make. So like that, that relationship is just really different. But,

777
00:50:55,985 --> 00:50:59,285
Speaker 4:  but it also sounds like the way you're seeing it, maybe it's not that different

778
00:50:59,285 --> 00:51:02,485
Speaker 4:  that maybe even if I'm buying the cooler and I expect the cooler to ship

779
00:51:02,485 --> 00:51:05,925
Speaker 4:  to my house, there is still some of that like content

780
00:51:05,995 --> 00:51:09,685
Speaker 4:  creator, personality, relationship stuff going on.

781
00:51:09,835 --> 00:51:13,405
Speaker 6:  Yeah, I think it depends on the person, David. I think you're a very rational,

782
00:51:13,725 --> 00:51:17,685
Speaker 6:  sensible human being. And so you're looking at it that way

783
00:51:17,855 --> 00:51:20,965
Speaker 6:  where there's other people that come, you know, we, we talk about this all

784
00:51:20,965 --> 00:51:23,965
Speaker 6:  the time at Kickstarter. When you pledge on Kickstarter, it says right there

785
00:51:23,965 --> 00:51:27,525
Speaker 6:  in bold, Kickstarter is not a store. Meaning that,

786
00:51:27,865 --> 00:51:31,765
Speaker 6:  hey, this, we're not guarantee guarantee you're gonna get this

787
00:51:31,765 --> 00:51:34,925
Speaker 6:  product. We're not guaranteeing you're gonna get something that you like,

788
00:51:35,225 --> 00:51:38,205
Speaker 6:  you know, even close to maybe what you, what you thought you were gonna get.

789
00:51:38,435 --> 00:51:41,645
Speaker 6:  This stuff is hard, especially for first time creators and things like that.

790
00:51:41,995 --> 00:51:45,965
Speaker 6:  Over 90% of creators actually do fulfill. I'm very happy about that.

791
00:51:46,105 --> 00:51:49,845
Speaker 6:  I'm very proud of that number. But it doesn't always happen,

792
00:51:50,015 --> 00:51:53,805
Speaker 6:  right? There's unforeseen things that happen all the time with creators

793
00:51:53,825 --> 00:51:57,765
Speaker 6:  and entrepreneurs. And So I think there

794
00:51:57,985 --> 00:52:01,965
Speaker 6:  are some backers who are like very, just like, almost

795
00:52:01,965 --> 00:52:05,805
Speaker 6:  like e-commerce shoppers. Like I see a thing, I see a product, I

796
00:52:05,835 --> 00:52:09,405
Speaker 6:  want it, I don't care if it's John or Sue or whoever

797
00:52:10,055 --> 00:52:13,085
Speaker 6:  doing it. I don't care about the backstory, I just want that product. And

798
00:52:13,085 --> 00:52:16,805
Speaker 6:  then you have some backers who are like really emotionally

799
00:52:17,365 --> 00:52:21,205
Speaker 6:  invested in that creator, their story, what they're trying to

800
00:52:21,205 --> 00:52:24,925
Speaker 6:  do. I love those backers by the way, because that is, I think that's

801
00:52:24,925 --> 00:52:28,845
Speaker 6:  what's special about Kickstarter, that that emotional connection

802
00:52:28,845 --> 00:52:32,755
Speaker 6:  that you have to somebody, because doing something

803
00:52:32,755 --> 00:52:35,595
Speaker 6:  new or putting something new out, new out into the world is a very brave

804
00:52:35,595 --> 00:52:39,195
Speaker 6:  thing to do. And I think those people that emotionally connect to that, I

805
00:52:39,195 --> 00:52:43,155
Speaker 6:  think that's a very beautiful thing. But we have some people like that and

806
00:52:43,155 --> 00:52:46,715
Speaker 6:  then we also have some people who just want the product. Neither are wrong.

807
00:52:47,005 --> 00:52:50,075
Speaker 6:  Right. But there's just two different experiences on the platform.

808
00:52:50,665 --> 00:52:54,635
Speaker 4:  Well, I, I agree that neither are wrong, but it does seem like on

809
00:52:54,665 --> 00:52:58,275
Speaker 4:  some level you have to pick one. Right? Because like you said, you know,

810
00:52:58,335 --> 00:53:02,315
Speaker 4:  90% of creators ship is both a very high number and a very low number.

811
00:53:02,315 --> 00:53:04,995
Speaker 4:  Yeah. Kind of all at the same time, right? Yeah. Like if, if if

812
00:53:05,865 --> 00:53:09,315
Speaker 4:  Samsung only shipped 90% of the stuff that they launched, like, that'd be,

813
00:53:09,315 --> 00:53:10,435
Speaker 4:  that's a problem. Yeah. Yeah,

814
00:53:10,505 --> 00:53:11,315
Speaker 6:  Yeah, yeah. For

815
00:53:11,315 --> 00:53:15,075
Speaker 4:  Sure. And so, and I, I do feel like, I think a thing that I,

816
00:53:15,185 --> 00:53:19,155
Speaker 4:  I've noticed over the years is I think Kickstarter has gone out of

817
00:53:19,155 --> 00:53:21,875
Speaker 4:  its way to act less and less like a shopping mall.

818
00:53:23,095 --> 00:53:26,335
Speaker 4:  But is is that, has, has that been deliberate on your side? Like, If you

819
00:53:26,335 --> 00:53:30,135
Speaker 4:  had to pick one of those two approaches, it seems like you, you're much happier

820
00:53:30,275 --> 00:53:34,015
Speaker 4:  on the side of like, be part of a community working

821
00:53:34,115 --> 00:53:37,575
Speaker 4:  on something together, rather than show up by a thing and don't check on

822
00:53:37,575 --> 00:53:39,415
Speaker 4:  it until it appears at your house in some months.

823
00:53:39,725 --> 00:53:43,535
Speaker 6:  Yeah, but that's because I'm like an empath and I'm a pro empathy

824
00:53:43,535 --> 00:53:46,935
Speaker 6:  person, you know? Sure. You know, like at the end of the day, I'm an

825
00:53:46,935 --> 00:53:50,215
Speaker 6:  entrepreneur myself, I'm a creator myself, So I understand

826
00:53:50,905 --> 00:53:54,615
Speaker 6:  everything that goes into it. All the unforeseen things that could

827
00:53:54,615 --> 00:53:56,575
Speaker 6:  potentially happen that can derail you,

828
00:53:58,115 --> 00:54:01,735
Speaker 6:  you know? And so for me, I just have that level of empathy

829
00:54:01,935 --> 00:54:05,535
Speaker 6:  and understanding. There's some projects that don't deliver for a year,

830
00:54:05,605 --> 00:54:09,495
Speaker 6:  sometimes two years, right? Like the, these things have, and then you

831
00:54:09,495 --> 00:54:13,455
Speaker 6:  have some more experienced creators who are like, they're cranking

832
00:54:13,455 --> 00:54:16,375
Speaker 6:  these things out like clockwork, right? Like they already have the manufacturing

833
00:54:17,285 --> 00:54:20,615
Speaker 6:  down pat, they know what they're doing, et cetera, et cetera. They'll launch

834
00:54:20,655 --> 00:54:24,255
Speaker 6:  a Kickstarter and we'll literally release the product that that next week,

835
00:54:24,255 --> 00:54:27,895
Speaker 6:  right? Right. So there's different types of creators on the

836
00:54:28,095 --> 00:54:31,815
Speaker 6:  platform. But I do think what makes Kickstarter fundamentally

837
00:54:31,815 --> 00:54:35,655
Speaker 6:  different from, you know, an Amazon or someone else like that in e-commerce,

838
00:54:35,955 --> 00:54:39,735
Speaker 6:  is that these are people who are, who are genuinely

839
00:54:39,735 --> 00:54:43,415
Speaker 6:  trying to get an idea out there. And I do think that emotional connection

840
00:54:43,415 --> 00:54:47,295
Speaker 6:  and that sense of community and coming together is

841
00:54:47,715 --> 00:54:51,055
Speaker 6:  really special. And I think that's why also the bigger

842
00:54:51,055 --> 00:54:54,295
Speaker 6:  corporations still like to launch on Kickstarter. 'cause

843
00:54:54,955 --> 00:54:58,615
Speaker 6:  the people are so passionate, and they'll give you that feedback and they'll

844
00:54:58,615 --> 00:55:02,535
Speaker 6:  be real with you. And they'll also, if they feel very happy with

845
00:55:02,535 --> 00:55:05,895
Speaker 6:  what you, what you do, they will be advocates for that product and that brand,

846
00:55:06,815 --> 00:55:10,575
Speaker 6:  I think it first starts with the creator. I know we just talked about the

847
00:55:10,575 --> 00:55:13,055
Speaker 6:  whole thing about like, you know, there are people that treat it more like

848
00:55:13,055 --> 00:55:15,015
Speaker 6:  e-commerce, but I think

849
00:55:17,475 --> 00:55:20,935
Speaker 6:  it always starts with the creator man. Like the creator,

850
00:55:21,585 --> 00:55:25,015
Speaker 6:  their story, their passion, their drive,

851
00:55:26,435 --> 00:55:29,735
Speaker 6:  how people resonate with their story and whatever they're trying to produce,

852
00:55:30,195 --> 00:55:33,495
Speaker 6:  but also who they are as a person. I tell people all the time,

853
00:55:33,565 --> 00:55:37,295
Speaker 6:  Kickstarter is no cakewalk. Like people will come on the

854
00:55:37,495 --> 00:55:41,175
Speaker 6:  platform and fail because they think, oh, I just put a project on Kickstarter

855
00:55:41,355 --> 00:55:44,615
Speaker 6:  and then people are just going to give me money. No, you have to have a true

856
00:55:44,675 --> 00:55:48,615
Speaker 6:  go to market strategy. You gotta have a plan, you gotta have great storytelling.

857
00:55:49,125 --> 00:55:49,415
Speaker 6:  Okay.

858
00:55:49,715 --> 00:55:52,415
Speaker 4:  So I, if you're thinking about it that way, right? If it, if you're sort

859
00:55:52,415 --> 00:55:54,335
Speaker 4:  of putting the creator at the center of it,

860
00:55:55,995 --> 00:55:59,295
Speaker 4:  you can, I can sort of imagine a world where very quickly you're like, okay,

861
00:55:59,295 --> 00:56:03,255
Speaker 4:  well the thing we have to do is build like a content platform for those creators

862
00:56:03,355 --> 00:56:07,095
Speaker 4:  to make things outside of being sort of specifically project based.

863
00:56:07,195 --> 00:56:10,655
Speaker 4:  And then it's like two more very small steps. And now you're TikTok, right?

864
00:56:10,655 --> 00:56:14,055
Speaker 4:  Like it's, it's like, because this is where everybody has landed, right?

865
00:56:14,055 --> 00:56:17,135
Speaker 4:  Yeah. Everybody, everybody else that is in this space has come at it from

866
00:56:17,135 --> 00:56:20,335
Speaker 4:  the opposite direction, which is we have given creators a place to build

867
00:56:20,335 --> 00:56:24,245
Speaker 4:  an audience, and then we've given those creators ways to sell stuff. And

868
00:56:25,645 --> 00:56:29,365
Speaker 4:  I, I think in a lot of ways that path has sort of

869
00:56:29,365 --> 00:56:33,325
Speaker 4:  ruined those platforms. Like the TikTok shop, at least in my own

870
00:56:33,325 --> 00:56:37,005
Speaker 4:  experience, has made TikTok essentially unusable. It is. It is. It's, I mean,

871
00:56:37,005 --> 00:56:39,645
Speaker 4:  it is. It's like, it's a shopping mall now. Yeah. And that's fine for what

872
00:56:39,645 --> 00:56:43,445
Speaker 4:  it is, but it is that is, it is like unrecognizable from what TikTok was

873
00:56:43,465 --> 00:56:47,365
Speaker 4:  before the shop existed. Yeah. But it works. And so

874
00:56:47,395 --> 00:56:51,365
Speaker 4:  what I wonder for you as the CEO is like, you've built the

875
00:56:51,365 --> 00:56:55,285
Speaker 4:  second half of that equation already, and I can imagine there's a lot

876
00:56:55,285 --> 00:56:59,205
Speaker 4:  of like, pressure and good reasons potentially, but

877
00:56:59,205 --> 00:57:03,005
Speaker 4:  also maybe psychotic reasons given the competitive landscape

878
00:57:03,105 --> 00:57:06,965
Speaker 4:  to go the other way and basically be like, okay, how do we become a like

879
00:57:06,965 --> 00:57:10,565
Speaker 4:  creator first platform and do vertical video and

880
00:57:10,915 --> 00:57:14,685
Speaker 4:  like make a thing that gives us all of the power of a creator

881
00:57:14,965 --> 00:57:18,685
Speaker 4:  audience on Kickstarter? Like, is that, yeah. Is that a path that

882
00:57:18,805 --> 00:57:19,925
Speaker 4:  makes sense? Is that where you're headed?

883
00:57:20,605 --> 00:57:24,365
Speaker 6:  I mean, well, a couple things that it makes Kickstarter unique.

884
00:57:24,365 --> 00:57:27,245
Speaker 6:  Number one, we're not a publicly traded company, right?

885
00:57:28,295 --> 00:57:32,045
Speaker 6:  We're a private and we're a public benefit corporation. And so

886
00:57:32,275 --> 00:57:35,125
Speaker 6:  some of these things that these, you know, larger

887
00:57:36,115 --> 00:57:39,485
Speaker 6:  tech companies, the pressure of them to make,

888
00:57:40,025 --> 00:57:43,205
Speaker 6:  you know, billions and billions of more revenue, they're always under pressure.

889
00:57:43,205 --> 00:57:45,925
Speaker 6:  We gotta get the stock price up. We gotta do this, we gotta do that.

890
00:57:46,555 --> 00:57:50,365
Speaker 6:  Kickstarter doesn't have that, right? Like, you know, Kickstarter was

891
00:57:50,365 --> 00:57:54,125
Speaker 6:  profitable in year two of its existence, and

892
00:57:54,125 --> 00:57:57,405
Speaker 6:  we've continued to scale and become bigger and more successful.

893
00:57:58,025 --> 00:58:01,965
Speaker 6:  But we've done things our way and we've done things without the

894
00:58:02,245 --> 00:58:05,885
Speaker 6:  pressures of, of feeling like we needed to

895
00:58:05,885 --> 00:58:09,085
Speaker 6:  monetize everything. I'm trying to do the things that are the most

896
00:58:09,595 --> 00:58:13,525
Speaker 6:  genuinely impactful to our audience. And my first couple

897
00:58:13,525 --> 00:58:17,125
Speaker 6:  years here, I've been hyper-focused on giving

898
00:58:17,525 --> 00:58:21,205
Speaker 6:  creators the tools, the products, and the services that they've been asking

899
00:58:21,345 --> 00:58:25,325
Speaker 6:  for Kickstarter for years. So even before even

900
00:58:25,325 --> 00:58:29,125
Speaker 6:  getting to anything like that, like we still have a long

901
00:58:29,125 --> 00:58:32,965
Speaker 6:  road. And also sometimes you gotta understand where your

902
00:58:32,965 --> 00:58:36,885
Speaker 6:  bread is buttered man, like, you know, and, and, and be really, really great

903
00:58:37,385 --> 00:58:40,965
Speaker 6:  at what you do. With that being said, one of the things that we're

904
00:58:40,965 --> 00:58:44,925
Speaker 6:  hyperfocused on this year is also backer development, right? And, and, and,

905
00:58:44,925 --> 00:58:48,605
Speaker 6:  and developing better products and features for our backers. We've been very

906
00:58:48,995 --> 00:58:52,845
Speaker 6:  focused on creators, but now we're like, how can we create

907
00:58:52,965 --> 00:58:56,925
Speaker 6:  a more engaging, sticky experience for

908
00:58:56,955 --> 00:59:00,165
Speaker 6:  backers on the platform? So I'm more focused on that

909
00:59:00,715 --> 00:59:04,525
Speaker 6:  than necessarily, you know, trying to turn

910
00:59:04,525 --> 00:59:08,445
Speaker 6:  Kickstarter into a TikTok like, you know, vertical

911
00:59:08,805 --> 00:59:10,045
Speaker 6:  platform or anything like that.

912
00:59:10,785 --> 00:59:14,695
Speaker 4:  There, there's definitely a world in which Kickstarter could sort of

913
00:59:14,695 --> 00:59:18,375
Speaker 4:  choose to be more actively involved in the, like, here's how to help you

914
00:59:18,375 --> 00:59:22,285
Speaker 4:  make stuff, process percent and printing services for people wanting

915
00:59:22,285 --> 00:59:25,445
Speaker 4:  to make content and like that kind of thing. Is that, is that interesting

916
00:59:25,445 --> 00:59:27,605
Speaker 4:  to you? Like, is that a space you think Kickstarter has stuff to do

917
00:59:27,865 --> 00:59:31,405
Speaker 6:  That's more interesting to me than Kickstarter becoming like TikTok

918
00:59:31,635 --> 00:59:35,565
Speaker 6:  Okay. To me personally, I think platforms like TikTok

919
00:59:35,945 --> 00:59:39,885
Speaker 6:  and Instagram and Twitter and all of that have always played a role

920
00:59:40,985 --> 00:59:44,045
Speaker 6:  in Kickstarter, right? In terms of how people market.

921
00:59:44,865 --> 00:59:48,805
Speaker 6:  We now have our own marketing services, performance

922
00:59:48,805 --> 00:59:52,085
Speaker 6:  marketing services called Kickstarter performance, which is like killing

923
00:59:52,145 --> 00:59:55,245
Speaker 6:  it. Where we're, we're utilizing those platforms. So those platforms are

924
00:59:55,245 --> 00:59:59,165
Speaker 6:  always going to be more important, but what can we uniquely

925
00:59:59,185 --> 01:00:02,485
Speaker 6:  do? Like we try to go out there and be better than TikTok, that's really,

926
01:00:02,485 --> 01:00:06,225
Speaker 6:  really hard to do, right? Yes. But I think we could be

927
01:00:06,225 --> 01:00:09,985
Speaker 6:  potentially the best at white glove service with manufacturing and stuff

928
01:00:09,985 --> 01:00:12,185
Speaker 6:  like that. Like that could be something that we could do. I'm not saying

929
01:00:12,185 --> 01:00:14,865
Speaker 6:  that's what we're gonna do, but that's something that we know

930
01:00:16,105 --> 01:00:19,985
Speaker 6:  uniquely our creators need that they might not be able to

931
01:00:19,985 --> 01:00:22,105
Speaker 6:  get elsewhere. Instead of focusing on

932
01:00:23,535 --> 01:00:27,505
Speaker 6:  competing with people at what they absolutely do

933
01:00:27,505 --> 01:00:31,385
Speaker 6:  best. I'd rather focus on what Kickstarter absolutely does, does best, and

934
01:00:31,385 --> 01:00:35,305
Speaker 6:  then filling the gaps for our creators where they need it.

935
01:00:36,185 --> 01:00:39,595
Speaker 4:  Okay. Yeah. What are those gaps? I mean, you, you see it a lot and I, I would

936
01:00:39,595 --> 01:00:43,555
Speaker 4:  assume it, it varies pretty widely in terms of what folks need, but like,

937
01:00:43,775 --> 01:00:46,995
Speaker 4:  you know, you mentioned wanting to do the stuff creators have been asking

938
01:00:47,015 --> 01:00:49,555
Speaker 4:  for, for years. Like what's, what's your sense of what's at the top of that

939
01:00:49,555 --> 01:00:49,715
Speaker 4:  list?

940
01:00:50,655 --> 01:00:54,515
Speaker 6:  One of them we're doing or we're about to launch, and that's

941
01:00:55,035 --> 01:00:58,835
Speaker 6:  a pledge manager and post-campaign tools, right? So, you know, before it

942
01:00:58,835 --> 01:01:02,475
Speaker 6:  was like you raise money on Kickstarter, and then it was like, congrats,

943
01:01:02,475 --> 01:01:06,155
Speaker 6:  here's your $50,000. Good luck. Sure. Go out into the world, you know?

944
01:01:07,015 --> 01:01:10,715
Speaker 6:  And now, you know, we're launching these post-campaign tools. Last year we

945
01:01:10,835 --> 01:01:14,395
Speaker 6:  launched late pledges, which now allows you to, If you raise

946
01:01:14,395 --> 01:01:18,355
Speaker 6:  $50,000, but hey, you might have another few hundred people that you

947
01:01:18,355 --> 01:01:22,115
Speaker 6:  might raise another 10, $20,000 over the last, over

948
01:01:22,115 --> 01:01:26,035
Speaker 6:  another week If you had it. Right? And so now you have late pledges, now

949
01:01:26,035 --> 01:01:29,275
Speaker 6:  you're gonna have pledge management, CRM, all of those things

950
01:01:29,975 --> 01:01:33,915
Speaker 6:  to help you, you know, your taxes, shipping, et cetera,

951
01:01:34,055 --> 01:01:37,515
Speaker 6:  et cetera. So helping people fill the gaps of that post

952
01:01:37,955 --> 01:01:41,875
Speaker 6:  campaign process, which is gonna be extremely important. We're gonna

953
01:01:41,875 --> 01:01:45,395
Speaker 6:  have, you know, add-ons and cross sells and all different types of things

954
01:01:45,725 --> 01:01:49,395
Speaker 6:  after a Kickstarter is over that a lot of these entrepreneurs

955
01:01:49,615 --> 01:01:53,315
Speaker 6:  and creators need that we've never been able to provide for them,

956
01:01:53,325 --> 01:01:56,355
Speaker 6:  which I'm really, really excited about. And that's already, we have someone

957
01:01:56,355 --> 01:02:00,035
Speaker 6:  in data right now, and that's gonna be rolling out early part of

958
01:02:00,185 --> 01:02:04,115
Speaker 6:  this year, which we're really, really excited for. The other

959
01:02:04,115 --> 01:02:07,635
Speaker 6:  thing on the, on the other side is pre-launch, right? So we revamped a lot

960
01:02:07,795 --> 01:02:11,315
Speaker 6:  of our pre-launch this past year, but there's so many

961
01:02:11,545 --> 01:02:15,235
Speaker 6:  more things that creators need before actually launching a

962
01:02:15,235 --> 01:02:18,755
Speaker 6:  Kickstarter, to be honest. Like depending on what you do

963
01:02:19,105 --> 01:02:22,645
Speaker 6:  before, a Kickstarter will determine how successful your

964
01:02:22,645 --> 01:02:26,365
Speaker 6:  Kickstarter even will be. Right? Totally. And so what can we do

965
01:02:27,115 --> 01:02:31,005
Speaker 6:  more in that pre-launch process of filling those

966
01:02:31,035 --> 01:02:34,485
Speaker 6:  gaps, supporting creators, helping them set realistic goals.

967
01:02:34,735 --> 01:02:38,445
Speaker 6:  Maybe it's some of the manufacturing stuff, you know, all of these things,

968
01:02:38,745 --> 01:02:42,525
Speaker 6:  making sure that they have the right pricing, et cetera, et cetera. AB testing.

969
01:02:43,155 --> 01:02:46,365
Speaker 6:  There's a lot of things that we could be doing on the pre-launch side that

970
01:02:46,365 --> 01:02:50,085
Speaker 6:  we're currently not doing that I think that we can provide for

971
01:02:50,285 --> 01:02:54,135
Speaker 6:  creators. And So I think the first steps is pre-launch and

972
01:02:54,135 --> 01:02:57,935
Speaker 6:  post campaign and continuing to build out a suite of tools and

973
01:02:58,175 --> 01:03:02,015
Speaker 6:  services for creators on both sides. So then you have this

974
01:03:02,015 --> 01:03:05,855
Speaker 6:  kind of loop where it's like pre-launch Kickstarter post-campaign,

975
01:03:05,855 --> 01:03:09,615
Speaker 6:  and then come back to pre-launch and continue Mm. To launch products.

976
01:03:10,045 --> 01:03:12,895
Speaker 4:  Okay. You're, you're kind of confirming a thing I've always suspected about

977
01:03:12,895 --> 01:03:16,855
Speaker 4:  Kickstarter, which is that the, the people who aren't like, you know,

978
01:03:16,905 --> 01:03:19,935
Speaker 4:  large companies using it as a, as a kind of marketing pre-sale platform,

979
01:03:21,445 --> 01:03:25,175
Speaker 4:  many of these people are like just people who made a thing. Yeah. And

980
01:03:25,265 --> 01:03:29,015
Speaker 4:  don't know, haven't run businesses like this, don't know how

981
01:03:29,115 --> 01:03:33,015
Speaker 4:  to manage large quantities of money like this.

982
01:03:33,015 --> 01:03:36,015
Speaker 4:  They're just like, I made a thing and I think people might like it and

983
01:03:37,445 --> 01:03:40,455
Speaker 4:  they get some money, right? And I think the idea of like needing money to

984
01:03:40,455 --> 01:03:44,255
Speaker 4:  do that stuff is, is part of it. But it is, I think

985
01:03:44,255 --> 01:03:47,815
Speaker 4:  maybe a smaller slice of the, like how to actually successfully

986
01:03:47,815 --> 01:03:51,695
Speaker 4:  accomplish your goals pie than anyone would like it to be. And all

987
01:03:51,775 --> 01:03:55,615
Speaker 4:  the rest of the stuff is like less sexy to talk about and less

988
01:03:55,925 --> 01:03:59,855
Speaker 4:  sort of creative and beautiful and artsy, but is like, that's the stuff

989
01:03:59,855 --> 01:04:02,415
Speaker 4:  that falls apart. And I found this with the tech folks. It's not because

990
01:04:02,415 --> 01:04:04,695
Speaker 4:  the thing didn't work, it's because they couldn't figure out how to ship

991
01:04:04,695 --> 01:04:07,535
Speaker 4:  it, like over and over. It's that kind of stuff that falls apart

992
01:04:07,875 --> 01:04:11,415
Speaker 6:  Is that piece. And now you have these big content creators that have an audience

993
01:04:11,415 --> 01:04:14,935
Speaker 6:  where they can go on Kickstarter today and raise four or five, 10 million

994
01:04:15,035 --> 01:04:18,815
Speaker 6:  or whatever it is, but do they even have the tools and resources

995
01:04:19,635 --> 01:04:21,295
Speaker 6:  to actually make the thing

996
01:04:22,325 --> 01:04:22,745
Speaker 4:  Happen?

997
01:04:22,995 --> 01:04:26,745
Speaker 6:  Right? Right. And do it successfully. And so those are the gaps that we

998
01:04:26,925 --> 01:04:30,785
Speaker 6:  see that we're trying to fill. And I think we're doing a good job thus

999
01:04:30,785 --> 01:04:30,945
Speaker 6:  far.

1000
01:04:31,725 --> 01:04:34,985
Speaker 4:  You mentioned AI and I, I wanna, I I was, I'm gonna forget to talk about

1001
01:04:34,985 --> 01:04:38,625
Speaker 4:  it if I don't bring it back up now. I think like I'm a

1002
01:04:38,665 --> 01:04:42,465
Speaker 4:  CES right now. You're gonna be at CES this week. Literally all anyone wants

1003
01:04:42,465 --> 01:04:46,025
Speaker 4:  to talk about is ai. Yeah. And, and what you're saying is right, that like

1004
01:04:46,815 --> 01:04:50,065
Speaker 4:  some companies are doing interesting things and other companies are just

1005
01:04:50,065 --> 01:04:54,025
Speaker 4:  doing old things and calling them ai and that just is what it is. And that's

1006
01:04:54,025 --> 01:04:57,825
Speaker 4:  fine. But I think the, the potential of AI

1007
01:04:59,235 --> 01:05:02,815
Speaker 4:  within a Kickstarter universe is super interesting, right? Like the, the,

1008
01:05:02,915 --> 01:05:06,495
Speaker 4:  if AI is everything it is cracked up to be, and like, spoiler alert, it isn't,

1009
01:05:06,835 --> 01:05:10,055
Speaker 4:  but if it is, it, it's going to make a lot of things

1010
01:05:11,095 --> 01:05:14,275
Speaker 4:  easier for people. It's gonna make it easier to design things, it's gonna

1011
01:05:14,275 --> 01:05:16,675
Speaker 4:  make it easier to build things, it's gonna make it easier to do your taxes,

1012
01:05:16,825 --> 01:05:19,845
Speaker 4:  it's gonna make it easier to like do all the legal paperwork around this

1013
01:05:19,845 --> 01:05:23,725
Speaker 4:  stuff. And So I can imagine a world in which you're, you're like

1014
01:05:23,865 --> 01:05:27,855
Speaker 4:  baking a lot of that stuff into Kickstarter itself to

1015
01:05:27,855 --> 01:05:31,815
Speaker 4:  say like, these are tools that can automate and simplify some of

1016
01:05:31,815 --> 01:05:35,015
Speaker 4:  this stuff. And, you know, everybody talks about democratizing everything.

1017
01:05:35,015 --> 01:05:38,975
Speaker 4:  Like AI could do some of that, right? Like if, if I don't have to write code

1018
01:05:38,975 --> 01:05:42,575
Speaker 4:  in order to be able to do a project, I wanna do like the, the gap between

1019
01:05:43,175 --> 01:05:47,135
Speaker 4:  I have an idea and I can sell that idea to, people might get much

1020
01:05:47,135 --> 01:05:47,535
Speaker 4:  smaller.

1021
01:05:49,235 --> 01:05:53,055
Speaker 4:  It also might just be a bunch of snake oil nonsense and

1022
01:05:53,395 --> 01:05:57,375
Speaker 4:  may not come to anything. But were, you're,

1023
01:05:57,405 --> 01:06:00,815
Speaker 4:  like you said, you're, you're a company that doesn't have to chase anything

1024
01:06:00,815 --> 01:06:03,855
Speaker 4:  that looks like growth just for the sake of something that looks like growth.

1025
01:06:03,915 --> 01:06:06,015
Speaker 4:  But where's your head with AI stuff right now?

1026
01:06:06,645 --> 01:06:10,335
Speaker 6:  Yeah. I, first I wanna say is that, listen, I'm pro technology.

1027
01:06:10,555 --> 01:06:14,015
Speaker 6:  I'm pro the advancement of technology. I know that

1028
01:06:14,995 --> 01:06:18,495
Speaker 6:  you can't just sit there and be scared and fearful of, of, of

1029
01:06:18,495 --> 01:06:22,175
Speaker 6:  technology. With that being said, I think there's something powerful

1030
01:06:22,355 --> 01:06:25,695
Speaker 6:  and beautiful about human made work and creativity.

1031
01:06:26,915 --> 01:06:30,295
Speaker 6:  And Kickstarter wants to be at the forefront of supporting that,

1032
01:06:30,625 --> 01:06:34,295
Speaker 6:  right? Supporting creators first and foremost,

1033
01:06:34,435 --> 01:06:38,375
Speaker 6:  before we even touch ai. And we wanna make sure

1034
01:06:38,375 --> 01:06:42,295
Speaker 6:  that the creators on our platform feel supported by the work that they

1035
01:06:42,295 --> 01:06:46,215
Speaker 6:  do. I see some platforms that are completely just, I mean,

1036
01:06:46,375 --> 01:06:50,255
Speaker 6:  I just saw meta as like creating fake AI

1037
01:06:50,365 --> 01:06:53,655
Speaker 6:  influencers. Yep. And it's like, dude, do you realize that

1038
01:06:54,125 --> 01:06:57,615
Speaker 6:  this, this, this is taking away from the

1039
01:06:57,615 --> 01:07:01,455
Speaker 6:  hardworking influencers and creators on your platform and why they use it,

1040
01:07:01,755 --> 01:07:03,935
Speaker 6:  and you already know where they're going with it. It's like, if they can

1041
01:07:03,935 --> 01:07:06,495
Speaker 6:  build these creators and make money off of them themselves,

1042
01:07:07,895 --> 01:07:11,595
Speaker 6:  but that's hurting your audience, we will never do anything that's gonna

1043
01:07:11,665 --> 01:07:15,435
Speaker 6:  hurt our community. Right? And so we wanna make sure there's so many people,

1044
01:07:16,015 --> 01:07:19,595
Speaker 6:  so many comic book creators and artists and musicians

1045
01:07:19,945 --> 01:07:23,875
Speaker 6:  that are hard at work to create things without the use of ai. And so we wanna

1046
01:07:23,875 --> 01:07:27,595
Speaker 6:  make sure that we're protecting those people and protecting their hard work

1047
01:07:27,605 --> 01:07:31,275
Speaker 6:  first and foremost. If there are ways where we can incorporate

1048
01:07:31,535 --> 01:07:35,195
Speaker 6:  AI to help make their lives easier or make creators more

1049
01:07:35,195 --> 01:07:38,595
Speaker 6:  successful on a platform, I'm 100% open to

1050
01:07:38,905 --> 01:07:42,595
Speaker 6:  exploring that. But I don't want to go too

1051
01:07:42,695 --> 01:07:44,915
Speaker 6:  far where it's hurting our community.

1052
01:07:45,625 --> 01:07:49,035
Speaker 4:  That line's gonna get really blurry though. Like, you're, you're, if it's

1053
01:07:49,035 --> 01:07:52,555
Speaker 4:  not happening already, it's gonna happen soon that you're gonna get musicians

1054
01:07:52,555 --> 01:07:55,595
Speaker 4:  who wanna kickstart an album of AI generated music, or Oh,

1055
01:07:55,595 --> 01:07:59,475
Speaker 6:  Yeah. And they can, right now, they just have to be honest that

1056
01:07:59,475 --> 01:08:03,435
Speaker 6:  they've used AI and what they're doing. We have an AI

1057
01:08:03,435 --> 01:08:06,955
Speaker 6:  policy and we just ask that, Hey, If you use ai,

1058
01:08:07,905 --> 01:08:11,555
Speaker 6:  just say that you used ai. Right? And then If you are using

1059
01:08:11,565 --> 01:08:13,355
Speaker 6:  other people's work through ai,

1060
01:08:14,915 --> 01:08:18,075
Speaker 6:  identify those people and compensate those people when you can.

1061
01:08:18,745 --> 01:08:22,715
Speaker 4:  Okay. Yeah. But I, I like, does that, is there a risk in that for

1062
01:08:22,715 --> 01:08:25,715
Speaker 4:  Kickstarter? Like the, we talk about this all the time at The Verge, the

1063
01:08:25,715 --> 01:08:28,755
Speaker 4:  idea that like, the internet is just going to be flooded with

1064
01:08:29,535 --> 01:08:33,515
Speaker 4:  AI content, you open up, like, if, if I'm just wanting

1065
01:08:33,515 --> 01:08:37,235
Speaker 4:  to kickstart a new album of AI generated

1066
01:08:37,235 --> 01:08:40,555
Speaker 4:  music every day on Kickstarter, that's not gonna work,

1067
01:08:41,175 --> 01:08:45,075
Speaker 4:  but it's gonna make the platform worse, right? Like, and,

1068
01:08:45,075 --> 01:08:48,355
Speaker 4:  and So I wonder like If you get to a point where 80% of the stuff on Kickstarter

1069
01:08:48,695 --> 01:08:52,475
Speaker 4:  is not interesting to most people because it's AI generated Yeah.

1070
01:08:52,895 --> 01:08:54,355
Speaker 4:  How that changes Kickstarter.

1071
01:08:54,955 --> 01:08:58,715
Speaker 6:  I think at the end of the day, our community does a great job of like

1072
01:08:59,065 --> 01:09:02,955
Speaker 6:  kind of pointing out what is interesting and what's not. I think if

1073
01:09:02,955 --> 01:09:06,555
Speaker 6:  someone came on today and tried to do a bunch of music that was AI generated,

1074
01:09:06,555 --> 01:09:09,875
Speaker 6:  they wouldn't be that successful and they're not gonna continue to do that.

1075
01:09:10,195 --> 01:09:13,915
Speaker 6:  I think the good thing about Kickstarter is that it almost

1076
01:09:14,025 --> 01:09:17,875
Speaker 6:  polices itself in a sense, right? Like, if the community isn't

1077
01:09:17,895 --> 01:09:21,755
Speaker 6:  for or supports it, you'll know because you're not getting

1078
01:09:22,515 --> 01:09:26,355
Speaker 6:  anything for it. And so I'm very open to see

1079
01:09:26,355 --> 01:09:30,275
Speaker 6:  how things evolve. I'm not someone that lives in the black or

1080
01:09:30,275 --> 01:09:33,995
Speaker 6:  the white. I very much live in the gray. I just understand right now

1081
01:09:34,505 --> 01:09:38,435
Speaker 6:  that human made things and human made work and creativity is

1082
01:09:38,435 --> 01:09:42,275
Speaker 6:  at the core of what we do today. And I do understand

1083
01:09:42,275 --> 01:09:45,235
Speaker 6:  the power of AI and how that could be supportive to creators

1084
01:09:45,755 --> 01:09:49,515
Speaker 6:  implementing that and what they do. But we wanna make sure that we

1085
01:09:49,515 --> 01:09:53,355
Speaker 6:  don't lose sight of what really makes Kickstarter special at the end of the

1086
01:09:53,355 --> 01:09:53,475
Speaker 6:  day.

1087
01:09:53,945 --> 01:09:57,315
Speaker 4:  Okay. This might be a stupid realization to be having this far into this

1088
01:09:57,315 --> 01:09:58,795
Speaker 4:  conversation. Yeah. But it also strikes me that

1089
01:10:00,475 --> 01:10:04,115
Speaker 4:  starting the whole thing with an exchange of money changes

1090
01:10:04,295 --> 01:10:08,155
Speaker 4:  the dynamic in a really useful way. Like I think I think about the, the AI

1091
01:10:08,155 --> 01:10:12,035
Speaker 4:  music that's suddenly all over Spotify. Yeah. And nobody really

1092
01:10:12,045 --> 01:10:15,715
Speaker 4:  likes it. I wouldn't, like nobody's seeking it out. It's not no super popular,

1093
01:10:16,055 --> 01:10:19,795
Speaker 4:  but there's so much of it that at volume it still works, right? Like if,

1094
01:10:19,795 --> 01:10:23,675
Speaker 4:  if, if I can, I can put out so much music that hardly any of it has to

1095
01:10:23,675 --> 01:10:27,635
Speaker 4:  be successful in order for it to still be a, a, an

1096
01:10:27,655 --> 01:10:31,635
Speaker 4:  in aggregate success for me. But that's a totally different relationship

1097
01:10:31,705 --> 01:10:35,395
Speaker 4:  than you have paid me for a thing. Yes. And I feel like there's,

1098
01:10:35,755 --> 01:10:39,515
Speaker 4:  I can't imagine the path to get to that kind of success

1099
01:10:39,905 --> 01:10:41,955
Speaker 4:  when first you have to pay me for a thing.

1100
01:10:42,775 --> 01:10:46,195
Speaker 6:  And what I said before, yes, we do have people that are

1101
01:10:46,825 --> 01:10:50,595
Speaker 6:  very much like, Hey, I am just getting a thing. They're thinking they're,

1102
01:10:50,735 --> 01:10:53,755
Speaker 6:  we never use the words buy, right? We don't see ourselves as a marketplace

1103
01:10:53,755 --> 01:10:57,195
Speaker 6:  in that way Sure. That are are using that. But still at the core,

1104
01:10:57,975 --> 01:11:01,835
Speaker 6:  the majority of our audience is wanting to support creators, new

1105
01:11:02,115 --> 01:11:05,755
Speaker 6:  things, new products. There is this like emotional

1106
01:11:05,755 --> 01:11:09,555
Speaker 6:  component to it, to it. And So I I, I think

1107
01:11:09,555 --> 01:11:13,365
Speaker 6:  people who want to behave in that way on the platform are

1108
01:11:13,365 --> 01:11:14,685
Speaker 6:  not gonna find a lot of success.

1109
01:11:15,485 --> 01:11:18,005
Speaker 4:  Hmm. Okay. All right. Last thing and then I'll let you go. I've kept you

1110
01:11:18,005 --> 01:11:21,965
Speaker 4:  long time here. Yeah. What, what do you tell creators about

1111
01:11:22,145 --> 01:11:26,085
Speaker 4:  how to talk to their audience that way? Because I think every bad

1112
01:11:26,085 --> 01:11:28,885
Speaker 4:  experience I hear about that somebody has on Kickstarter is about being ghosted

1113
01:11:28,985 --> 01:11:32,405
Speaker 4:  in one way or another. Yeah. Yeah. Like the, the experience of

1114
01:11:32,885 --> 01:11:36,765
Speaker 4:  I backed a thing and it didn't work. Yep. Is is frustrating,

1115
01:11:36,765 --> 01:11:40,645
Speaker 4:  but I backed a thing and then they disappeared is worse and feels

1116
01:11:40,745 --> 01:11:44,725
Speaker 4:  bad. And like that's the thing that breaks the thing. And so yeah.

1117
01:11:44,765 --> 01:11:47,405
Speaker 4:  I mean, I assume this is the thing you spend a lot of time thinking and talking

1118
01:11:47,405 --> 01:11:50,885
Speaker 4:  about, but I am curious, like as you talk to these folks who are wanting

1119
01:11:50,885 --> 01:11:53,085
Speaker 4:  to build that relationship, what do you tell them?

1120
01:11:53,985 --> 01:11:55,315
Speaker 6:  Well, first and foremost,

1121
01:11:57,105 --> 01:12:00,355
Speaker 6:  they know what they're doing. Right? Like, let's, like these are adults,

1122
01:12:00,355 --> 01:12:04,195
Speaker 6:  these are creators, these are entrepreneurs. And what I'm very excited

1123
01:12:04,195 --> 01:12:08,075
Speaker 6:  about, and we already started rolling it, rolling it out, is we're

1124
01:12:08,075 --> 01:12:11,675
Speaker 6:  going after these, these potentially fraudulent creators or these

1125
01:12:11,675 --> 01:12:14,955
Speaker 6:  ghosting creators. Hmm. Never in Kickstarter's history have we done that.

1126
01:12:15,005 --> 01:12:18,395
Speaker 6:  We've kind of had this like, Hey, Kickstarter's not a store.

1127
01:12:18,625 --> 01:12:21,835
Speaker 6:  There's no guarantee that you're gonna get the thing. Like

1128
01:12:22,075 --> 01:12:24,835
Speaker 4:  I always compare it to the chat GPT thing where it's like, chat GPT might

1129
01:12:24,835 --> 01:12:28,315
Speaker 4:  lie to you. And it's like a total abdication of responsibility to say that.

1130
01:12:28,855 --> 01:12:32,555
Speaker 6:  100%. Yeah. And to me, I just like,

1131
01:12:33,335 --> 01:12:37,275
Speaker 6:  listen David, I stand on business, man, and like I come from South

1132
01:12:37,275 --> 01:12:40,955
Speaker 6:  Side Richmond, I, I'm all about

1133
01:12:40,955 --> 01:12:44,595
Speaker 6:  holding people accountable and making sure that we do the right thing. So

1134
01:12:44,665 --> 01:12:48,515
Speaker 6:  this year we're rolling out new things where we're going to be

1135
01:12:48,515 --> 01:12:52,315
Speaker 6:  going after these creators. We're gonna be banning them from the platform.

1136
01:12:52,315 --> 01:12:55,595
Speaker 6:  We're gonna be communicating back to their, to their backers, letting them

1137
01:12:55,595 --> 01:12:59,075
Speaker 6:  know that we're holding them accountable. We're gonna be putting people in

1138
01:12:59,075 --> 01:13:02,755
Speaker 6:  collections, going after the money to get it back for our

1139
01:13:02,865 --> 01:13:06,635
Speaker 6:  backers. Like we're not playing any more games anymore. And so, yes,

1140
01:13:06,695 --> 01:13:10,595
Speaker 6:  we can go and go to every creator and be like, Hey, make sure you're

1141
01:13:10,755 --> 01:13:14,635
Speaker 6:  communicating with your audience. Do the right thing. But we both know

1142
01:13:14,865 --> 01:13:18,755
Speaker 6:  that people that aren't trying to do the right thing is going to ignore that.

1143
01:13:19,175 --> 01:13:23,115
Speaker 6:  The one place where I do find empathy and like where we need to help more

1144
01:13:23,355 --> 01:13:27,075
Speaker 6:  creators are those like first time creators that they failed

1145
01:13:27,255 --> 01:13:30,835
Speaker 6:  and they're like under the weight of failure.

1146
01:13:31,085 --> 01:13:34,755
Speaker 6:  Right. And I don't wanna go after them. I just wanna make sure they get to

1147
01:13:34,755 --> 01:13:38,745
Speaker 6:  the point where they can at least communicate that to

1148
01:13:38,745 --> 01:13:42,585
Speaker 6:  their audience. I think that's gonna be so important. 'cause there are some

1149
01:13:42,825 --> 01:13:46,585
Speaker 6:  creators that just under the weight of the pressure, they're not

1150
01:13:46,585 --> 01:13:50,545
Speaker 6:  trying to ghost, but they have that social anxiety of like, I, I don't know

1151
01:13:50,545 --> 01:13:54,305
Speaker 6:  what to do. And I really empathize with that, but they still have to go and

1152
01:13:54,585 --> 01:13:58,225
Speaker 6:  communicate with that audience. And so the balance of helping those

1153
01:13:58,825 --> 01:14:02,345
Speaker 6:  creators, but also actually going after the creators that are being

1154
01:14:02,345 --> 01:14:02,905
Speaker 6:  fraudulent.

1155
01:14:03,375 --> 01:14:07,345
Speaker 4:  Yeah. Yeah. And I think the, the folks who give it a real

1156
01:14:07,445 --> 01:14:10,625
Speaker 4:  try and then just kind of admit defeat, I think. Yeah, I think you're right

1157
01:14:10,625 --> 01:14:14,445
Speaker 4:  that Kickstarter is unusual as a place in that

1158
01:14:14,505 --> 01:14:17,325
Speaker 4:  it has a lot of space for those people. Yeah. Right? Like that is percent,

1159
01:14:17,355 --> 01:14:21,205
Speaker 4:  that is a thing that is part of the system. Yep. It's the people

1160
01:14:21,265 --> 01:14:22,965
Speaker 4:  who just take your money and run that.

1161
01:16:27,805 --> 01:16:30,945
Speaker 4:  All right, we're back. Let's get to the hotline as always. The number is

1162
01:16:30,945 --> 01:16:34,505
Speaker 4:  8 6 6 VERGE one one. The email is vergecast at The Verge dot com.

1163
01:16:34,885 --> 01:16:38,145
Speaker 4:  We love all of your questions. We try to answer at least one on the show

1164
01:16:38,145 --> 01:16:41,625
Speaker 4:  every week, but I have some ideas about how to do even more than that

1165
01:16:41,855 --> 01:16:45,225
Speaker 4:  this year. We're also working on some big stuff that started as hotline questions.

1166
01:16:45,565 --> 01:16:49,105
Speaker 4:  Please keep hitting off the hotline with all of your weirdest questions.

1167
01:16:49,415 --> 01:16:53,385
Speaker 4:  It's my favorite thing. This week's question is about passwords, or

1168
01:16:53,465 --> 01:16:56,745
Speaker 4:  I guess more specifically not passwords. Listen to this.

1169
01:16:58,445 --> 01:17:02,105
Speaker 7:  Hi David slash Vergecast. My name is John

1170
01:17:02,365 --> 01:17:06,225
Speaker 7:  in New York, and I have a question about sort of

1171
01:17:06,225 --> 01:17:09,925
Speaker 7:  related to The Verge creating a subscription

1172
01:17:10,225 --> 01:17:14,165
Speaker 7:  and more about sign-ins on websites.

1173
01:17:15,125 --> 01:17:18,925
Speaker 7:  A lot of websites I feel like these days do prompt

1174
01:17:18,985 --> 01:17:22,405
Speaker 7:  you to sign in via a link and an email.

1175
01:17:23,465 --> 01:17:27,425
Speaker 7:  I sort of understand that, but what is the, what is the reason

1176
01:17:27,945 --> 01:17:31,865
Speaker 7:  websites are moving, it seems like in that direction more.

1177
01:17:32,365 --> 01:17:36,345
Speaker 7:  Is it because people can't do passwords properly? It seems like

1178
01:17:36,425 --> 01:17:40,105
Speaker 7:  a, a lot of websites are just removing the ability to do

1179
01:17:40,385 --> 01:17:44,265
Speaker 7:  passwords at all. Is that the way of the future? Just

1180
01:17:44,735 --> 01:17:47,305
Speaker 7:  wondering what the process there is.

1181
01:17:48,225 --> 01:17:51,995
Speaker 4:  Okay, so this question actually sent me down a really interesting rabbit

1182
01:17:52,025 --> 01:17:55,915
Speaker 4:  hole because I frankly hate Magic Links as

1183
01:17:55,995 --> 01:17:59,675
Speaker 4:  a login mechanism. Basically the way Magic Links work, If you don't know,

1184
01:17:59,695 --> 01:18:02,555
Speaker 4:  is you go to log into something, you type into your username and you hit

1185
01:18:02,555 --> 01:18:05,595
Speaker 4:  submit. And instead of popping up another field that's like, Hey, what's

1186
01:18:05,595 --> 01:18:09,515
Speaker 4:  your password? It says, you know, we've sent you an email, go click on the

1187
01:18:09,515 --> 01:18:12,755
Speaker 4:  link in your email. So you go, you open your email, you get an email from

1188
01:18:12,755 --> 01:18:15,835
Speaker 4:  whoever you're trying to log into that says, click this link to finish your

1189
01:18:15,835 --> 01:18:19,555
Speaker 4:  login or something like that. You click that link and then it opens up to

1190
01:18:19,775 --> 01:18:23,075
Speaker 4:  the thing that you were reading. This is in theory

1191
01:18:24,105 --> 01:18:27,555
Speaker 4:  fine, right? I think that that idea works, and I'll tell you the reason

1192
01:18:27,775 --> 01:18:30,595
Speaker 4:  people do it, just to directly answer the question. The reason for Magic

1193
01:18:30,645 --> 01:18:34,635
Speaker 4:  Links is because they're better than passwords. I think everything

1194
01:18:34,635 --> 01:18:38,515
Speaker 4:  is better than passwords. And one thing that we've seen over time is there

1195
01:18:38,515 --> 01:18:42,235
Speaker 4:  is a big push away from if I run a

1196
01:18:42,235 --> 01:18:46,075
Speaker 4:  website storing your passwords. I just don't want them anymore.

1197
01:18:46,455 --> 01:18:49,795
Speaker 4:  The folks at 4 0 4 Media wrote a really great post about this a couple of

1198
01:18:49,795 --> 01:18:52,995
Speaker 4:  weeks ago about why they use Magic Links. And the thrust of it is essentially,

1199
01:18:53,335 --> 01:18:56,515
Speaker 4:  we don't want your passwords because as soon as you store somebody's passwords,

1200
01:18:56,975 --> 01:19:00,635
Speaker 4:  you become a security risk. And because most people have

1201
01:19:00,775 --> 01:19:04,635
Speaker 4:  bad password hygiene, they reuse passwords, they use bad passwords.

1202
01:19:05,295 --> 01:19:09,075
Speaker 4:  If I leak your password to my website, there is a

1203
01:19:09,395 --> 01:19:12,555
Speaker 4:  surprisingly good chance that what actually happened is I just leaked the

1204
01:19:12,675 --> 01:19:15,475
Speaker 4:  password to your email and your bank account and everything else. So

1205
01:19:16,145 --> 01:19:19,835
Speaker 4:  essentially what a lot of companies are starting to say is

1206
01:19:19,865 --> 01:19:23,795
Speaker 4:  just, we do not want your password. We don't want your data at all. This

1207
01:19:23,795 --> 01:19:27,235
Speaker 4:  is a thing you hear from a lot of privacy based companies like DuckDuckGo

1208
01:19:27,235 --> 01:19:30,915
Speaker 4:  has been saying this for years, is their privacy policy is just to not have

1209
01:19:30,915 --> 01:19:34,835
Speaker 4:  any data at all. Because the less you collect, the fewer risks there are

1210
01:19:35,295 --> 01:19:39,195
Speaker 4:  for that data and passwords I think are the number one

1211
01:19:40,115 --> 01:19:43,795
Speaker 4:  security vector there. And so that is one big reason to use Magic Links.

1212
01:19:43,895 --> 01:19:47,755
Speaker 4:  It, it offloads all of the worry about security to

1213
01:19:47,905 --> 01:19:51,835
Speaker 4:  just, as long as my email address is secure, which is my job

1214
01:19:51,835 --> 01:19:52,235
Speaker 4:  as a person,

1215
01:19:53,855 --> 01:19:57,795
Speaker 4:  it will work. This system stays secure as long as my email stays secure.

1216
01:19:57,895 --> 01:20:01,715
Speaker 4:  And I think for us as people, that's a reasonable

1217
01:20:01,805 --> 01:20:05,275
Speaker 4:  trade, right? Like it is just true that if your email address gets compromised,

1218
01:20:05,615 --> 01:20:09,325
Speaker 4:  you're hosed. Like, I hate to put it in quite those terms, but

1219
01:20:09,945 --> 01:20:13,885
Speaker 4:  If you do one single thing on earth that is good for you on

1220
01:20:13,885 --> 01:20:17,805
Speaker 4:  the internet, it is have a complicated and two factor backed

1221
01:20:18,145 --> 01:20:21,685
Speaker 4:  and unique password for your email that's just, just

1222
01:20:22,225 --> 01:20:25,485
Speaker 4:  do it. Or else you are just on borrowed time until something truly terrible

1223
01:20:25,485 --> 01:20:29,025
Speaker 4:  happens. Okay? So anyway, the upside of

1224
01:20:29,155 --> 01:20:32,665
Speaker 4:  Magic links is that it offloads a lot of that process.

1225
01:20:33,525 --> 01:20:36,625
Speaker 4:  The downside of Magic Links is that it's kind of crappy

1226
01:20:37,415 --> 01:20:40,065
Speaker 4:  user experience, right? So in a, in a certain world, like if I'm sitting

1227
01:20:40,065 --> 01:20:43,865
Speaker 4:  at my computer for instance, and it's easy for me to switch

1228
01:20:44,065 --> 01:20:47,105
Speaker 4:  from the tab of the website to the tab of my email,

1229
01:20:47,805 --> 01:20:50,865
Speaker 4:  that's relatively simple, right? And then I click the link and it opens the

1230
01:20:50,865 --> 01:20:54,625
Speaker 4:  same thing in another tab and I'm back to where I was. That's

1231
01:20:55,025 --> 01:20:57,665
Speaker 4:  slightly annoying just because it's a bunch of tabs switching and clicking

1232
01:20:57,765 --> 01:21:01,505
Speaker 4:  and it opens in another tabs. And now I have two tabs of the same thing.

1233
01:21:01,645 --> 01:21:05,425
Speaker 4:  One where I'm not logged in and one where I am that's slightly messy,

1234
01:21:05,925 --> 01:21:09,745
Speaker 4:  but is, I would say broadly fine. Where this really breaks down

1235
01:21:09,885 --> 01:21:13,185
Speaker 4:  for me, at least as a user, is on mobile, right? Where I

1236
01:21:13,685 --> 01:21:17,305
Speaker 4:  log into something, I go to my email,

1237
01:21:17,355 --> 01:21:20,265
Speaker 4:  which involves usually, you know, closing and opening other app or opening

1238
01:21:20,265 --> 01:21:24,185
Speaker 4:  the multitasking thing and you swipe for a while. That takes a minute and

1239
01:21:24,185 --> 01:21:27,265
Speaker 4:  then clicking the link and then when I click that link,

1240
01:21:28,485 --> 01:21:31,585
Speaker 4:  God only knows where it goes. This is the problem, right? On mobile, especially

1241
01:21:31,585 --> 01:21:35,425
Speaker 4:  on iOS, which is just awful about this, you have in-app browsers,

1242
01:21:35,885 --> 01:21:39,545
Speaker 4:  you have Safari, which a lot of apps just wanna open by default. And then

1243
01:21:39,545 --> 01:21:43,185
Speaker 4:  you have whatever you've picked as your default browser. So when you

1244
01:21:43,365 --> 01:21:47,265
Speaker 4:  are in a place reading a, an article and you wanna log in and read that

1245
01:21:47,265 --> 01:21:51,105
Speaker 4:  article, you get the magic link and it may or may not open

1246
01:21:51,245 --> 01:21:55,025
Speaker 4:  in the place where you were originally reading that article. This is a platform

1247
01:21:55,535 --> 01:21:59,385
Speaker 4:  mess and it it, it is everyone's fault, especially Apple's for the way that

1248
01:21:59,385 --> 01:22:03,145
Speaker 4:  it handles web browsers. But what it means is that you are just not

1249
01:22:03,205 --> 01:22:06,385
Speaker 4:  in the place that you expect to be and logged in in the places you expect

1250
01:22:06,385 --> 01:22:10,105
Speaker 4:  to be logged in. I have a theory that lots of people

1251
01:22:10,165 --> 01:22:13,305
Speaker 4:  who hate subscriptions, one thing we've heard frankly on The Verge is that

1252
01:22:13,445 --> 01:22:17,145
Speaker 4:  saying logged in is a challenge. And a lot of that comes from the fact

1253
01:22:17,375 --> 01:22:21,105
Speaker 4:  that when you use a browser on iOS, again in particular,

1254
01:22:21,645 --> 01:22:25,385
Speaker 4:  you're actually using several different kinds of browsers that do not talk

1255
01:22:25,385 --> 01:22:28,825
Speaker 4:  to each other. You're not just using like the iPhone browser.

1256
01:22:28,895 --> 01:22:31,545
Speaker 4:  Sometimes you're in Safari, sometimes you might be in Chrome, sometimes you're

1257
01:22:31,545 --> 01:22:34,305
Speaker 4:  in an in-app browser, sometimes you're in a different in-app browser. It's

1258
01:22:34,305 --> 01:22:37,505
Speaker 4:  a mess. My my one thing by the way is

1259
01:22:38,325 --> 01:22:41,905
Speaker 4:  try your very best not to use in-app browsers. Set the browser you want as

1260
01:22:41,905 --> 01:22:45,265
Speaker 4:  the default and then get in the habit of like pressing the button and saying

1261
01:22:45,265 --> 01:22:49,185
Speaker 4:  open and default browser. It is annoying to do that extra step

1262
01:22:49,185 --> 01:22:53,065
Speaker 4:  every time you open a webpage, but it makes all the login and magic linky

1263
01:22:53,065 --> 01:22:56,905
Speaker 4:  stuff a little bit easier. So all of this is

1264
01:22:56,905 --> 01:23:00,345
Speaker 4:  to say, I've been asking around a little bit, and I don't think anyone

1265
01:23:00,605 --> 01:23:04,545
Speaker 4:  agrees that magic links are perfect. There's

1266
01:23:04,545 --> 01:23:08,165
Speaker 4:  no sort of magically great thing about them,

1267
01:23:08,905 --> 01:23:12,685
Speaker 4:  but they do work, right? You probably have access to your email just about

1268
01:23:12,685 --> 01:23:15,765
Speaker 4:  everywhere. There's a chance that you have access to email more places than

1269
01:23:15,765 --> 01:23:18,685
Speaker 4:  you have access to your passwords. Most people, again, have bad password

1270
01:23:18,685 --> 01:23:21,725
Speaker 4:  hygienes and have them like written down on a sticky note on their desk.

1271
01:23:21,835 --> 01:23:25,325
Speaker 4:  There's a good chance your email is more accessible to you than

1272
01:23:25,665 --> 01:23:29,565
Speaker 4:  the list of passwords that you have. It also means things like

1273
01:23:30,235 --> 01:23:34,085
Speaker 4:  when you're on a new device that you've never used before, you can

1274
01:23:34,185 --> 01:23:38,045
Speaker 4:  use the magic link and still be relatively secure without risks

1275
01:23:38,045 --> 01:23:41,725
Speaker 4:  of things like, you know, keyboard capture and all that stuff.

1276
01:23:42,835 --> 01:23:46,365
Speaker 4:  It's a better, simpler system with fewer problems

1277
01:23:47,235 --> 01:23:50,525
Speaker 4:  than just asking people to type in their password all the time. All of that

1278
01:23:50,525 --> 01:23:53,605
Speaker 4:  is true. But when I talk to people about this, they say

1279
01:23:54,395 --> 01:23:58,165
Speaker 4:  what we should have is something more like pass keys. Pass keys

1280
01:23:58,345 --> 01:24:02,165
Speaker 4:  are really interesting and we've talked about them a bunch

1281
01:24:02,165 --> 01:24:05,805
Speaker 4:  on the show, but Passkey basically intercept this whole system

1282
01:24:06,305 --> 01:24:10,085
Speaker 4:  and just let you declare yourself to a

1283
01:24:10,085 --> 01:24:13,965
Speaker 4:  website with yourself. You use the Byron Metric security

1284
01:24:13,965 --> 01:24:17,525
Speaker 4:  on your phone to log into websites. I would argue that is the correct answer

1285
01:24:17,525 --> 01:24:20,045
Speaker 4:  and that is absolutely how it should work. None of these systems are perfect,

1286
01:24:20,465 --> 01:24:23,845
Speaker 4:  but they're very good and I think they're great. You can also solve a lot

1287
01:24:23,845 --> 01:24:26,365
Speaker 4:  of these problems by just having good password hygiene, right? Like If you

1288
01:24:26,365 --> 01:24:29,645
Speaker 4:  have a password manager, you can solve some of this problem, particularly

1289
01:24:29,705 --> 01:24:33,445
Speaker 4:  the user experience part of the problem by just having these things

1290
01:24:33,445 --> 01:24:37,245
Speaker 4:  auto-filled themselves more easily. Then you don't have to know your passwords,

1291
01:24:37,245 --> 01:24:40,765
Speaker 4:  you can have your passwords everywhere. It doesn't solve the specific security

1292
01:24:40,765 --> 01:24:44,565
Speaker 4:  risks of just inputting passwords, which are an

1293
01:24:44,725 --> 01:24:48,485
Speaker 4:  inherent security risk. But If you have, you know, unique complicated passwords

1294
01:24:48,585 --> 01:24:52,405
Speaker 4:  across every website that you use, the worries about

1295
01:24:52,525 --> 01:24:56,245
Speaker 4:  a specific one being leaked, at least go down. There are,

1296
01:24:56,405 --> 01:24:59,965
Speaker 4:  I should also say trade-offs to the magic link thing

1297
01:25:00,355 --> 01:25:04,125
Speaker 4:  with security. One other thing you see is the, the

1298
01:25:04,255 --> 01:25:08,205
Speaker 4:  codes that people get sent in emails or the codes that you can

1299
01:25:08,205 --> 01:25:11,365
Speaker 4:  get sent by text message, like six digit code that you use to log into stuff.

1300
01:25:11,895 --> 01:25:15,845
Speaker 4:  Those are also better than asking people to input passwords, but they

1301
01:25:15,845 --> 01:25:19,765
Speaker 4:  take time too. SMS in particular has its own

1302
01:25:20,085 --> 01:25:23,965
Speaker 4:  security risks. It you run the risk of having issues If you

1303
01:25:23,965 --> 01:25:27,925
Speaker 4:  have service problems. Look, none of these systems are perfect. This

1304
01:25:27,925 --> 01:25:30,645
Speaker 4:  is the thing I keep hearing from people is like, oh, we really should have

1305
01:25:30,645 --> 01:25:34,365
Speaker 4:  solved passwords by now. And passkey are probably the closest thing we've

1306
01:25:34,365 --> 01:25:37,925
Speaker 4:  ever come up with to solving passwords. But for right now we have this

1307
01:25:38,465 --> 01:25:41,805
Speaker 4:  big kind of mealy mess of different ways

1308
01:25:43,025 --> 01:25:46,725
Speaker 4:  to do better than having you just type your password into a text field

1309
01:25:46,945 --> 01:25:49,605
Speaker 4:  and everybody agrees that that is the single worst thing you can possibly

1310
01:25:49,605 --> 01:25:53,565
Speaker 4:  do. So magic links, they're not great, they're not

1311
01:25:53,565 --> 01:25:57,405
Speaker 4:  anybody's favorite thing, but they are definitely unequivocally

1312
01:25:57,405 --> 01:26:00,925
Speaker 4:  better than making people type in their passwords. And for that reason alone,

1313
01:26:01,805 --> 01:26:04,645
Speaker 4:  I will, I will keep using them. I will get annoyed every time I have to use

1314
01:26:04,645 --> 01:26:08,485
Speaker 4:  them on 4 0 4 and other places, but I will keep using

1315
01:26:08,485 --> 01:26:11,965
Speaker 4:  them. I hope that helps. Passwords are a mess

1316
01:26:12,305 --> 01:26:16,085
Speaker 4:  is essentially where it lands. None of this is good. Use pass

1317
01:26:16,085 --> 01:26:16,725
Speaker 4:  keys when you can.

1318
01:26:18,955 --> 01:26:21,805
Speaker 4:  Alright, that is it for the first cast today. Thank you to everybody who

1319
01:26:21,805 --> 01:26:24,925
Speaker 4:  came on the show, and thank you as always for listening. There's lots more

1320
01:26:24,945 --> 01:26:28,405
Speaker 4:  on everything we talked about at The Verge dot com. We're covering all of

1321
01:26:28,425 --> 01:26:32,365
Speaker 4:  the run up to the will. They won't they TikTok ban really aggressively.

1322
01:26:32,985 --> 01:26:36,445
Speaker 4:  So keep it locked on the website. I think there's a lot left to happen in

1323
01:26:36,465 --> 01:26:40,205
Speaker 4:  the next five days, so keep it locked. Let us know what you think.

1324
01:26:40,305 --> 01:26:42,885
Speaker 4:  I'd love to hear all of your thoughts on whether it should be banned, shouldn't

1325
01:26:42,885 --> 01:26:45,725
Speaker 4:  be banned. I know this is a thing we've been talking about for literally

1326
01:26:45,815 --> 01:26:49,445
Speaker 4:  years at this point, but I'd love to hear your thoughts and I'd love to hear

1327
01:26:49,445 --> 01:26:52,645
Speaker 4:  your thoughts and questions on everything. Email us Vergecast at The Verge

1328
01:26:52,645 --> 01:26:56,605
Speaker 4:  dot com. Call the hotline, eight six six VERGE one one. We absolutely love

1329
01:26:56,605 --> 01:27:00,285
Speaker 4:  hearing from you. We are gonna do even more hotline stuff

1330
01:27:00,545 --> 01:27:04,485
Speaker 4:  in 2025 than we did last year, so please keep all of your questions coming.

1331
01:27:05,155 --> 01:27:08,725
Speaker 4:  This show is produced by Liam James, Wil Poor and Eric Gomez. Vergecast is

1332
01:27:08,725 --> 01:27:12,045
Speaker 4:  a VERGE production and part of the Vox Media podcast network. Neil, and I'll

1333
01:27:12,045 --> 01:27:15,925
Speaker 4:  be back on Friday to talk about presumably the TikTok Band, plus everything

1334
01:27:15,925 --> 01:27:19,605
Speaker 4:  going on at Meta, all of the open AI stuff and lots more.

1335
01:27:19,775 --> 01:27:21,045
Speaker 4:  We'll see you then. Rock and roll

