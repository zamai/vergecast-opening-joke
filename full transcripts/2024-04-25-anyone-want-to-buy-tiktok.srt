1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: d1a6255c-eb19-4205-9f31-35804975dc37
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/5111220222872133655/818653159107941639/s93290-US-6221s-1714348639.mp3
Description: The Verge's Nilay Patel, David Pierce, and Alex Cranz discuss President Biden signing the TikTok ban bill, Apple's May 7th iPad event, Tesla's flop era, and more.

2
00:00:29,655 --> 00:00:31,605
Speaker 1:  state Farm is there. Talk to

3
00:01:07,165 --> 00:01:11,105
Speaker 3:  anniversary Tour Captivating thousands of fans at each and every show.

4
00:01:11,105 --> 00:01:14,925
Speaker 3:  Stream art beats and lyrics, Now on Hulu, please drink

5
00:01:14,925 --> 00:01:18,885
Speaker 3:  responsibly. Whiskey specialty, 35% Alcohol by Valium Jack, Daniels

6
00:01:18,885 --> 00:01:22,005
Speaker 3:  Distillery Lynchburg Tennessee Jack Daniels and Tennessee Honey are registered

7
00:01:22,005 --> 00:01:24,325
Speaker 3:  trademarks 2024 Jack Daniels All Rights

8
00:01:24,325 --> 00:01:29,015
Speaker 3:  Reserve.

9
00:01:29,015 --> 00:01:29,365
Speaker 2:  Hello

10
00:01:29,365 --> 00:01:31,635
Speaker 4:  And Welcome To, the Rich House, the flagship podcast of saying, we're gonna

11
00:01:31,635 --> 00:01:35,525
Speaker 4:  burn your house down unless you sell it. That's the metaphor

12
00:01:35,525 --> 00:01:38,585
Speaker 4:  everyone's using at TikTok.

13
00:01:38,585 --> 00:01:41,195
Speaker 5:  If you don't listen to The Vergecast, we will burn your house down.

14
00:01:41,195 --> 00:01:44,965
Speaker 4:  Yeah, that's, those are your choices. You can sell your house, or Crans will

15
00:01:44,965 --> 00:01:47,125
Speaker 4:  come to it and torch it. Yeah.

16
00:01:47,125 --> 00:01:48,425
Speaker 6:  I, I've got a lighter and everything.

17
00:01:48,425 --> 00:01:52,345
Speaker 4:  Hi, I'm your friend Eli. I'm, I'm good. Crans is here. Alex Kranz

18
00:01:52,345 --> 00:01:52,835
Speaker 4:  is here.

19
00:01:52,835 --> 00:01:55,035
Speaker 6:  Yeah. I'm here to hear all the scorching takes.

20
00:01:55,035 --> 00:01:58,245
Speaker 4:  Yeah. She's got a lighter and she's not afraid to use it. David Pierce is

21
00:01:58,245 --> 00:01:58,775
Speaker 4:  here.

22
00:01:58,775 --> 00:02:02,645
Speaker 5:  Hello. We were all so close to being in the same city for

23
00:02:02,645 --> 00:02:06,205
Speaker 5:  like 10 minutes yesterday. Yeah. And we managed to not record a VERGE cast,

24
00:02:06,205 --> 00:02:07,285
Speaker 5:  and it was very upsetting. Yeah.

25
00:02:07,285 --> 00:02:10,245
Speaker 4:  It's funny that we've, we've gone 180, like usually at least two of us are

26
00:02:10,245 --> 00:02:13,205
Speaker 4:  together. We were all very close to all three of us being together, and now

27
00:02:13,205 --> 00:02:16,545
Speaker 4:  we're all three of us remote, but it's for good

28
00:02:16,545 --> 00:02:19,315
Speaker 4:  reason. David has the Rabbit R one in

29
00:02:19,315 --> 00:02:23,205
Speaker 4:  hand. I do. I can't tell you how much I wanna talk about the Rabbit

30
00:02:23,205 --> 00:02:26,205
Speaker 4:  R one and all the things it can or mostly cannot do. So that's very exciting.

31
00:02:26,205 --> 00:02:28,605
Speaker 4:  We're gonna talk about that. We gotta talk about the electric gwa. That's

32
00:02:28,605 --> 00:02:32,065
Speaker 4:  another hour of The Vergecast. Apple announced new iPads. Tesla

33
00:02:32,065 --> 00:02:35,485
Speaker 4:  had earnings. Elon threatened once again to turn every Tesla on the road

34
00:02:35,485 --> 00:02:39,285
Speaker 4:  into some sort of distributed AWS situation. Very weird. We got a lightning

35
00:02:39,285 --> 00:02:42,235
Speaker 4:  round at the end. But we have to start, we have to start with breaking

36
00:02:42,235 --> 00:02:45,965
Speaker 4:  news. Joe Biden to just before we began recording

37
00:02:45,965 --> 00:02:49,755
Speaker 4:  today on Wednesday, signed the bill

38
00:02:49,755 --> 00:02:53,725
Speaker 4:  that would force TikTok to either divest itself to sell itself to

39
00:02:53,725 --> 00:02:56,805
Speaker 4:  some other company in the United States, or shut down. Those are the two

40
00:02:56,805 --> 00:03:00,785
Speaker 4:  choices it passed as part of an aid package

41
00:03:00,785 --> 00:03:04,325
Speaker 4:  to Ukraine, Israel. There's some humanitarian aid for Gaza in that

42
00:03:04,325 --> 00:03:08,045
Speaker 4:  package. The house passed it as part of that aid bill. They extended

43
00:03:08,045 --> 00:03:10,685
Speaker 4:  the timeline and the divestiture, which was the big holdup in the Senate

44
00:03:10,685 --> 00:03:14,565
Speaker 4:  before. So now there's, now TikTok has nine months to, to

45
00:03:14,565 --> 00:03:17,925
Speaker 4:  figure out a sale process. And if they're making progress, whoever is the

46
00:03:17,925 --> 00:03:21,405
Speaker 4:  president has, can add three months per the president's

47
00:03:21,405 --> 00:03:24,385
Speaker 4:  discretion, bringing the total to a year. So by chance, basically has a year

48
00:03:24,385 --> 00:03:28,115
Speaker 4:  to figure this out. The clock is now ticking. The the bill is signed.

49
00:03:28,115 --> 00:03:31,955
Speaker 4:  It's the law, and no one knows what's gonna happen next.

50
00:03:31,955 --> 00:03:35,805
Speaker 5:  Yeah. I like, there's so many strange

51
00:03:35,805 --> 00:03:39,705
Speaker 5:  unknowns about this. Things like, who is going to be president when we hit

52
00:03:39,705 --> 00:03:43,245
Speaker 5:  the nine month gap? Like it's, it's, it's so obvious to me that a big part

53
00:03:43,245 --> 00:03:47,185
Speaker 5:  of the sticking point was to move this past the election, right. That whatever

54
00:03:47,185 --> 00:03:50,505
Speaker 5:  is going to happen should have to happen after election day, and it'll either

55
00:03:50,505 --> 00:03:54,165
Speaker 5:  be our problem after we've been reelected if you're the Democrats,

56
00:03:54,165 --> 00:03:58,045
Speaker 5:  or it'll be their problem. Yeah. If you're the Republicans, right. Like that

57
00:03:58,045 --> 00:04:01,605
Speaker 6:  Was in Lauren's reporting too, is is that a lot of these senators

58
00:04:01,605 --> 00:04:05,485
Speaker 6:  signed on to, to approve this bill because it pushed it

59
00:04:05,485 --> 00:04:08,505
Speaker 6:  past the deadline because they gave him a little bit more space to do it.

60
00:04:08,505 --> 00:04:09,425
Speaker 6:  So, yeah.

61
00:04:09,425 --> 00:04:13,325
Speaker 5:  No, I I think it's, it's, it, it's such an easy maneuver at such

62
00:04:13,325 --> 00:04:16,775
Speaker 5:  an odd moment. And we've talked so much about the politics of this,

63
00:04:16,775 --> 00:04:20,285
Speaker 5:  especially among young people in the United States and all the weird ways

64
00:04:20,285 --> 00:04:24,005
Speaker 5:  that's gonna go. And all of the stuff I've been reading recently has been

65
00:04:24,005 --> 00:04:27,665
Speaker 5:  very strange that like intellectually overwhelmingly, it seems like if you

66
00:04:27,665 --> 00:04:31,165
Speaker 5:  ask people, is TikTok sort of bad in whatever, like

67
00:04:31,165 --> 00:04:34,965
Speaker 5:  mysterious way you wanna define bad people say yes. Like all of the

68
00:04:34,965 --> 00:04:38,705
Speaker 5:  polls are basically like, yes, most people believe TikTok is a net

69
00:04:38,705 --> 00:04:42,445
Speaker 5:  bad. But then I think the, the reality of like

70
00:04:42,445 --> 00:04:46,405
Speaker 5:  waking up in TikTok suddenly being gone is a, is a thing in

71
00:04:46,405 --> 00:04:50,245
Speaker 5:  an election season that nobody actually wants to deal with. Yeah. It's

72
00:04:50,245 --> 00:04:53,385
Speaker 5:  very strange. I also don't think that part is ever actually going to happen.

73
00:04:53,385 --> 00:04:55,155
Speaker 5:  But we we can talk about that.

74
00:04:55,155 --> 00:04:58,725
Speaker 4:  Look, I love eating handfuls of m MSS at midnight, which is a thing I

75
00:04:58,725 --> 00:05:02,005
Speaker 4:  love. I know it's bad. I know I shouldn't do that.

76
00:05:02,005 --> 00:05:05,715
Speaker 4:  Yeah, super do it all the time. I,

77
00:05:05,715 --> 00:05:08,885
Speaker 4:  that feels like our relationship to social media is a country right now,

78
00:05:08,885 --> 00:05:12,685
Speaker 4:  and maybe TikTok in particular, but in general, our relationship to social

79
00:05:12,685 --> 00:05:16,445
Speaker 4:  media is like, eh, this making us feel bad. And and maybe it's measurable

80
00:05:16,445 --> 00:05:19,445
Speaker 4:  or maybe it's not. Or maybe this guy's just a grifter trying to sell a book,

81
00:05:19,445 --> 00:05:23,365
Speaker 4:  whatever it is, some ambient sense of, eh, I shouldn't eat m and ms at

82
00:05:23,365 --> 00:05:27,085
Speaker 4:  midnight. Is there, and then everyone's just like, give them to me.

83
00:05:27,085 --> 00:05:30,335
Speaker 4:  Yeah. Like, let me have him, the thing that's really interesting, right?

84
00:05:30,335 --> 00:05:33,455
Speaker 4:  It, it just got signed today. It was inev, it felt inevitable all week that

85
00:05:33,455 --> 00:05:37,145
Speaker 4:  this would get signed. That was the momentum was there. Lauren

86
00:05:37,145 --> 00:05:41,085
Speaker 4:  finer, her reporting suggested the deadlines were coming ever faster.

87
00:05:41,085 --> 00:05:43,775
Speaker 4:  Like usually with bills, there's delays and last minute changed and this

88
00:05:43,775 --> 00:05:46,455
Speaker 4:  was just happening and it actually happened, I think, a little faster than

89
00:05:46,455 --> 00:05:50,045
Speaker 4:  we anticipated it would happen, like a day faster. Now it's done.

90
00:05:50,045 --> 00:05:53,315
Speaker 4:  There's no more argument whether you should ban on TikTok. Like they, they

91
00:05:53,315 --> 00:05:56,675
Speaker 4:  did it. They passed the bill. Joe Biden signed it. It's the law.

92
00:05:56,675 --> 00:06:00,645
Speaker 5:  I mean, I, I do think you, you could ask the

93
00:06:00,645 --> 00:06:04,445
Speaker 5:  question of I is what Joe Biden signed,

94
00:06:04,445 --> 00:06:08,225
Speaker 5:  intended to be a ban of TikTok. Like it's not nothing to me that

95
00:06:08,225 --> 00:06:12,145
Speaker 5:  in, in his statement about signing the bill and his excitement and enthusiasm

96
00:06:12,145 --> 00:06:15,715
Speaker 5:  for the fact that this got done after all this time, didn't mention TikTok

97
00:06:15,715 --> 00:06:19,565
Speaker 5:  once or any of this stuff once it's buried like

98
00:06:19,565 --> 00:06:23,285
Speaker 5:  halfway down this long bill after I, I

99
00:06:23,285 --> 00:06:27,165
Speaker 5:  forget the exact heading of the thing, but it's like miscellaneous

100
00:06:27,165 --> 00:06:30,885
Speaker 5:  and then TikTok like this is not the point of the bill. Yeah. Right. which

101
00:06:30,885 --> 00:06:34,725
Speaker 5:  I think is, is a strange thing that is going to play out potentially in some

102
00:06:34,725 --> 00:06:38,115
Speaker 5:  interesting ways as we go through the inevitable chaos of the next nine months.

103
00:06:38,115 --> 00:06:42,075
Speaker 5:  This got passed in service of passing something

104
00:06:42,075 --> 00:06:45,985
Speaker 5:  else. And I think what everybody decided along this process is passing

105
00:06:45,985 --> 00:06:49,955
Speaker 5:  this other thing is so important that sure will ban TikTok. And

106
00:06:49,955 --> 00:06:52,835
Speaker 5:  so I think, I don't know if that changes anything about the way this actually

107
00:06:52,835 --> 00:06:56,515
Speaker 5:  plays out. I think that the bill is still law, like, it, it did happen, but

108
00:06:56,515 --> 00:07:00,425
Speaker 5:  it's a strange way that we got here that makes me wonder,

109
00:07:00,425 --> 00:07:03,855
Speaker 5:  like, does Joe Biden actually want to ban

110
00:07:03,855 --> 00:07:07,555
Speaker 5:  TikTok or is that just a price everyone is willing to pay in order to get

111
00:07:07,555 --> 00:07:10,195
Speaker 5:  this important aid bill? Oh,

112
00:07:10,195 --> 00:07:13,585
Speaker 6:  It's a hundred percent of price everybody was willing to pay. Right. Like,

113
00:07:13,585 --> 00:07:17,475
Speaker 6:  like this was a really, this, the whole bill was hard, was a hard fought

114
00:07:17,475 --> 00:07:20,675
Speaker 6:  battle for everybody involved. And, and this was just like, you know

115
00:07:20,675 --> 00:07:24,155
Speaker 6:  what? We just need to get this bill out the door. If somebody wants to put

116
00:07:24,155 --> 00:07:27,835
Speaker 6:  this. And this is like, so, so at the back of most of our list, it's

117
00:07:27,835 --> 00:07:31,495
Speaker 6:  fine. which I thought was really, really interesting to go from like

118
00:07:31,495 --> 00:07:35,035
Speaker 6:  TikTok being like this huge center of discussion for everybody to being

119
00:07:35,035 --> 00:07:38,905
Speaker 6:  like a f essentially a footnote and a much larger bill.

120
00:07:38,905 --> 00:07:41,755
Speaker 4:  Yeah. I mean, they did have, the house did have the up down vote on the standalone

121
00:07:41,755 --> 00:07:44,555
Speaker 4:  TikTok bill, which had a much shorter timeline. And I think a lot of people

122
00:07:44,555 --> 00:07:47,155
Speaker 4:  had problems with that shorter timeline, and that just sort of arrived in

123
00:07:47,155 --> 00:07:50,875
Speaker 4:  the Senate with nothing. So at least one part of our government had

124
00:07:50,875 --> 00:07:53,955
Speaker 4:  the straight up down vote. That's true. Right. And after the house voted

125
00:07:53,955 --> 00:07:57,075
Speaker 4:  to pass that version of the Bill, Biden said, I'm gonna sign it. Like I'll

126
00:07:57,075 --> 00:08:00,835
Speaker 4:  sign it. Did you get it to me? And I'll sign it. Whether or not they skirted

127
00:08:00,835 --> 00:08:04,635
Speaker 4:  it through the Senate by attaching it to a bill that everyone

128
00:08:04,635 --> 00:08:08,575
Speaker 4:  wanted to get done. Yeah. I mean like on the margins. But that's like how

129
00:08:08,575 --> 00:08:12,475
Speaker 4:  so many things get done. Totally. But I think you have, you had

130
00:08:12,475 --> 00:08:15,035
Speaker 4:  the house, just the straight uptown vote and you had Biden saying, I'm gonna

131
00:08:15,035 --> 00:08:18,915
Speaker 4:  sign it. So the motivations I think are clear whether

132
00:08:18,915 --> 00:08:21,875
Speaker 4:  or not Biden wants to run around crowing that he banned TikTok I think is

133
00:08:21,875 --> 00:08:24,755
Speaker 4:  very different, like politically very different. The White House, for example,

134
00:08:24,755 --> 00:08:27,675
Speaker 4:  announced today that's gonna keep campaigning on

135
00:08:27,675 --> 00:08:31,315
Speaker 4:  TikTok. They're just gonna, they're gonna be

136
00:08:31,315 --> 00:08:34,945
Speaker 4:  like, I don't know if anyone's ready for that ratio that is gonna, in the

137
00:08:34,945 --> 00:08:38,555
Speaker 4:  history of ratios on the internet, every post, the White House now

138
00:08:38,555 --> 00:08:42,265
Speaker 4:  makes, every post Joe Biden now makes on TikTok is gonna get

139
00:08:42,265 --> 00:08:45,675
Speaker 4:  Ratioed to Helen back and it's gonna be delightful. And that's

140
00:08:45,675 --> 00:08:46,275
Speaker 4:  fine.

141
00:08:46,275 --> 00:08:50,155
Speaker 5:  I was actually thinking about that as sort of, it's like a perfect microcosm

142
00:08:50,155 --> 00:08:53,595
Speaker 5:  of this whole thing. And I think the, the thing that I have come around

143
00:08:53,595 --> 00:08:57,525
Speaker 5:  to is in, in the months that we've been talking about this, I

144
00:08:57,525 --> 00:09:01,285
Speaker 5:  think at the beginning of all these conversations, I underrated how

145
00:09:01,285 --> 00:09:04,905
Speaker 5:  important TikTok is as an information source, particularly to young people.

146
00:09:04,905 --> 00:09:08,285
Speaker 5:  But now you see the stats that are like, it is a, it is a growing search

147
00:09:08,285 --> 00:09:12,165
Speaker 5:  engine. It's a, it's a huge source of news, particularly for like Gen

148
00:09:12,165 --> 00:09:15,925
Speaker 5:  Z and younger. It matters a lot. And so for the White

149
00:09:15,925 --> 00:09:19,845
Speaker 5:  House to a wanna ban TikTok but also understand that if we wanna

150
00:09:19,845 --> 00:09:23,485
Speaker 5:  reach people, this is the literal only way is actually like a

151
00:09:23,485 --> 00:09:27,445
Speaker 5:  perfect summation of the TikTok problem. Right. TikTok is so

152
00:09:27,445 --> 00:09:31,315
Speaker 5:  important that you can ban it and yet you have to use it.

153
00:09:31,315 --> 00:09:35,165
Speaker 5:  It's so strange. But that is like, that is where we are with

154
00:09:35,165 --> 00:09:36,445
Speaker 5:  what TikTok means to people. Right

155
00:09:36,445 --> 00:09:38,805
Speaker 4:  Now, somewhere in the TikTok office, there's the knob that just throttles

156
00:09:38,805 --> 00:09:42,705
Speaker 4:  you and like shows each you the CEO of TikTok is just like Biden Harris

157
00:09:42,705 --> 00:09:43,995
Speaker 4:  hq

158
00:09:43,995 --> 00:09:45,825
Speaker 5:  Goodbye. Yeah. Their engagement's gonna go way up.

159
00:09:45,825 --> 00:09:49,765
Speaker 4:  No, from orbit. Good night everybody. So it's done right, that the

160
00:09:49,765 --> 00:09:52,285
Speaker 4:  point I'm trying to make is it's done. There are only three options now.

161
00:09:52,285 --> 00:09:55,965
Speaker 4:  TikTok has said it's gonna sue, it's gonna file some sort of

162
00:09:55,965 --> 00:09:59,845
Speaker 4:  legal complaint to say, this is not allowed. We

163
00:09:59,845 --> 00:10:03,725
Speaker 4:  don't know what that looks like. They showed Chu actually put up a TikTok

164
00:10:03,725 --> 00:10:07,565
Speaker 4:  himself saying, make no mistake, this is a ban, which is interesting. We'll

165
00:10:07,565 --> 00:10:10,365
Speaker 4:  come back to that and then we're gonna go to court and wanna fight for your

166
00:10:10,365 --> 00:10:13,715
Speaker 4:  rights as Americans under the Constitution because you can't be silenced.

167
00:10:13,715 --> 00:10:17,575
Speaker 4:  Also a very interesting thing to say. And then he said,

168
00:10:17,575 --> 00:10:20,805
Speaker 4:  don't worry TikTok, we'll continue as before like we're, we'll keep running

169
00:10:20,805 --> 00:10:23,505
Speaker 4:  TikTok, we're gonna keep investing in TikTok. Yeah. You just hold tight.

170
00:10:23,505 --> 00:10:26,755
Speaker 4:  I'm gonna go defend the Constitution against the United States government.

171
00:10:26,755 --> 00:10:27,045
Speaker 4:  Yeah.

172
00:10:27,045 --> 00:10:31,005
Speaker 6:  It's, it's super funny to see the guy who made

173
00:10:31,005 --> 00:10:34,745
Speaker 6:  like unli a word because you're not allowed to say dead on

174
00:10:34,745 --> 00:10:38,565
Speaker 6:  TikTok. The, the bastion of free speech. Like that's a really weird

175
00:10:38,565 --> 00:10:41,765
Speaker 6:  stance for him to take because it's not, it's, it's PG

176
00:10:41,765 --> 00:10:45,685
Speaker 6:  rated social media, right? Yeah. Like, like it's, it's social media for kids,

177
00:10:45,685 --> 00:10:49,645
Speaker 6:  which is why the kids use it and why part of

178
00:10:49,645 --> 00:10:52,665
Speaker 6:  the reason people don't want the kids using it. Like, come on dude,

179
00:10:52,665 --> 00:10:55,655
Speaker 4:  I'm never gonna look at a corner emoji the same way Right after being on

180
00:10:55,655 --> 00:10:59,645
Speaker 4:  OnOne. That's, you went from very, very innocent to very weird very

181
00:10:59,645 --> 00:11:02,425
Speaker 4:  quickly. So there's that element. There's also the fact that it's not the

182
00:11:02,425 --> 00:11:05,925
Speaker 4:  user's speech that is being regulated here, right? It's TikTok, the company

183
00:11:05,925 --> 00:11:09,825
Speaker 4:  that distributes the speech of users and the notion that

184
00:11:09,825 --> 00:11:13,355
Speaker 4:  its control of the AL algorithm presents some sort of national security risk.

185
00:11:13,355 --> 00:11:17,205
Speaker 4:  That there is some longstanding issue with having foreign powers

186
00:11:17,205 --> 00:11:19,955
Speaker 4:  control a significant part of our media. That's a very old policy issue.

187
00:11:19,955 --> 00:11:23,685
Speaker 4:  There's some issue with concentration of media ownership. So you just

188
00:11:23,685 --> 00:11:27,435
Speaker 4:  look at option one, we're gonna file a lawsuit, we're gonna win pure

189
00:11:27,435 --> 00:11:31,195
Speaker 4:  coin flip. We just don't know how that's gonna go. We don't know what tiktoks

190
00:11:31,195 --> 00:11:34,795
Speaker 4:  lawsuit is gonna be. It could hinge all on free speech or it could just hinge

191
00:11:34,795 --> 00:11:38,755
Speaker 4:  on like a technical drafting error where the government did

192
00:11:38,755 --> 00:11:41,865
Speaker 4:  not point to the correct statutory

193
00:11:41,865 --> 00:11:45,795
Speaker 4:  authority from 1805 to enact. We don't, like, we

194
00:11:45,795 --> 00:11:49,335
Speaker 4:  have to see it. So that's option one. We're gonna fight a lawsuit and win.

195
00:11:49,335 --> 00:11:53,205
Speaker 4:  Option two is they shut down and leave. They could do that. That's

196
00:11:53,205 --> 00:11:56,805
Speaker 4:  the ban, right? We, we've exhausted our other options and we are, we're outta

197
00:11:56,805 --> 00:12:00,765
Speaker 4:  here. Goodbye. You ban TikTok. Weird. I I think that, I

198
00:12:00,765 --> 00:12:04,465
Speaker 4:  think that is that that is a choice that by chance has to make under

199
00:12:04,465 --> 00:12:07,645
Speaker 4:  duress. Yeah. Right. That's the, we're gonna burn your house down unless

200
00:12:07,645 --> 00:12:10,125
Speaker 4:  you sell it. And they could be like, ah, we lit the, we lit the match. Look,

201
00:12:10,125 --> 00:12:13,845
Speaker 4:  see you later. We shut it down Option two, option three is that they sell

202
00:12:13,845 --> 00:12:17,005
Speaker 4:  it and you know, they got a year to figure it out. And option three has a

203
00:12:17,005 --> 00:12:19,245
Speaker 4:  bunch of weirdness in it because most of the companies that would want to

204
00:12:19,245 --> 00:12:23,205
Speaker 4:  buy TikTok, it feels like our own DOJ would prevent them from doing it

205
00:12:23,205 --> 00:12:27,195
Speaker 4:  for antitrust reasons. So that's option three. So it, it's not

206
00:12:27,195 --> 00:12:31,075
Speaker 4:  an easy road from here at all. I don't know what the

207
00:12:31,075 --> 00:12:34,635
Speaker 4:  creators are gonna do. The creators have a year to figure out how much they

208
00:12:34,635 --> 00:12:38,555
Speaker 4:  want to trust TikTok while TikTok is trying to turn itself into the home

209
00:12:38,555 --> 00:12:42,085
Speaker 4:  shopping network anyway. And like it's not, and you know, universal music

210
00:12:42,085 --> 00:12:44,555
Speaker 4:  isn't on there anymore. Like there's a whole bunch of stuff over there that

211
00:12:44,555 --> 00:12:47,215
Speaker 4:  creators are gonna have to react to. I, I think we're in for just a whole

212
00:12:47,215 --> 00:12:50,995
Speaker 4:  bucket of changes much in the same way that when, you know, Elon bought

213
00:12:50,995 --> 00:12:53,825
Speaker 4:  Twitter and started making changes over there, the social media landscape

214
00:12:53,825 --> 00:12:57,355
Speaker 4:  just started refracting around it. Like things started changing all around

215
00:12:57,355 --> 00:13:01,235
Speaker 4:  that energy. I think we're gonna see the same thing with, with TikTok,

216
00:13:01,235 --> 00:13:04,115
Speaker 4:  but though there's only three options. They fight and win a lawsuit, which

217
00:13:04,115 --> 00:13:06,275
Speaker 4:  we haven't seen. And we don't know what that lawsuit will be based on. So

218
00:13:06,275 --> 00:13:10,175
Speaker 4:  we, we don't know. They leave or they sell it.

219
00:13:10,175 --> 00:13:10,595
Speaker 4:  That's

220
00:13:10,595 --> 00:13:13,665
Speaker 5:  It. Okay. I just wanna float a fourth option. Yeah. Which is they

221
00:13:13,665 --> 00:13:17,595
Speaker 5:  stay and the app stores pay a fine, which in case you're

222
00:13:17,595 --> 00:13:21,075
Speaker 5:  wondering, I calculated it would be $850 billion.

223
00:13:21,615 --> 00:13:24,395
Speaker 5:  So that's an option. Just throwing it out there. Apple can do

224
00:13:24,395 --> 00:13:27,105
Speaker 4:  That. That's 8.5 car projects for Apple.

225
00:13:27,105 --> 00:13:30,875
Speaker 5:  Yeah. It's like, not even a big deal. It's fine. That's fine. But I

226
00:13:30,875 --> 00:13:34,795
Speaker 5:  think to me the, the strange thing that's gonna happen in the middle of

227
00:13:34,795 --> 00:13:38,555
Speaker 5:  all of that is just uncertainty. Right? And I've, I've been reading and talking

228
00:13:38,555 --> 00:13:42,275
Speaker 5:  to folks about this just in the last few hours and there is this

229
00:13:42,275 --> 00:13:46,155
Speaker 5:  overwhelming sense from a lot of people that TikTok

230
00:13:46,155 --> 00:13:50,055
Speaker 5:  is sort of screwed no matter what happens because this is like, it just

231
00:13:50,055 --> 00:13:53,575
Speaker 5:  got completely thrown up in the air, everything about TikTok

232
00:13:53,575 --> 00:13:57,115
Speaker 5:  and there is no indication it's going to

233
00:13:57,115 --> 00:14:00,675
Speaker 5:  settle down quickly. Right. And like even if it gets a new owner, there will

234
00:14:00,675 --> 00:14:03,825
Speaker 5:  be lots of changes. If it disappears,

235
00:14:03,825 --> 00:14:07,315
Speaker 5:  obviously it'll be gone. And if it fights a lawsuit, that's gonna take a

236
00:14:07,315 --> 00:14:11,155
Speaker 5:  long time. And so if you're a creator, if you're an advertiser, if you're

237
00:14:11,155 --> 00:14:14,815
Speaker 5:  anyone who has any kind of investment in this platform,

238
00:14:14,815 --> 00:14:18,355
Speaker 5:  the simplest thing to do is going to be immediately start investing your

239
00:14:18,355 --> 00:14:21,125
Speaker 5:  time and energy and money somewhere else. Yep. And that is just going to

240
00:14:21,125 --> 00:14:24,995
Speaker 5:  bleed TikTok so fast. And to the

241
00:14:24,995 --> 00:14:28,855
Speaker 5:  point where even if a year from now TikTok sells to

242
00:14:28,855 --> 00:14:32,795
Speaker 5:  Oracle, like what are we sure TikTok is going to still be

243
00:14:32,795 --> 00:14:36,405
Speaker 5:  TikTok in a year because it's, I I like this stuff moves fast,

244
00:14:36,405 --> 00:14:39,705
Speaker 4:  Right? And then the, the actual mechanism of sale is

245
00:14:39,705 --> 00:14:43,235
Speaker 4:  confusing 'cause it appears by ance would not sell the

246
00:14:43,235 --> 00:14:45,035
Speaker 4:  algorithm that underlies TikTok. Right?

247
00:14:45,035 --> 00:14:48,755
Speaker 5:  Right. Well, by dance has been pretty clear this whole time that it has no

248
00:14:48,755 --> 00:14:51,565
Speaker 5:  interest in selling. Like I, the, if if you believe

249
00:14:51,565 --> 00:14:54,395
Speaker 5:  ance divesting is not an option.

250
00:14:54,395 --> 00:14:57,655
Speaker 6:  Well yeah. 'cause then we have to see if TikTok actually makes money,

251
00:14:57,655 --> 00:15:00,405
Speaker 4:  Right? I mean like Yeah. Do they want a bunch of American tech companies

252
00:15:00,405 --> 00:15:03,485
Speaker 4:  poking around the books of TikTok? Like they certainly do not. Do they have

253
00:15:03,485 --> 00:15:07,125
Speaker 4:  to say just as a negotiating tactic, we will never sell in order

254
00:15:07,125 --> 00:15:11,005
Speaker 4:  to ward off a ban? They sure do. But if you're just a responsible

255
00:15:11,005 --> 00:15:14,805
Speaker 4:  executive and now you're here and you have the three choices or

256
00:15:14,805 --> 00:15:18,458
Speaker 4:  choice four to be fair to David, which is ask Apple to pay $850 billion

257
00:15:18,765 --> 00:15:21,685
Speaker 4:  a year in fines for having TikTok remain in the app

258
00:15:21,685 --> 00:15:25,645
Speaker 4:  store. Yeah. I dunno. Like I, it it feels like you, you gotta run down two

259
00:15:25,645 --> 00:15:26,915
Speaker 4:  of them, right?

260
00:15:26,915 --> 00:15:30,605
Speaker 5:  Yeah. I mean at some point your option is either $0 or a hundred billion

261
00:15:30,605 --> 00:15:34,305
Speaker 5:  dollars. Yeah. And you just, you sort of have no choice but to take that.

262
00:15:34,305 --> 00:15:38,205
Speaker 5:  But if that is the game that you're playing, you have to play that

263
00:15:38,205 --> 00:15:39,835
Speaker 5:  basically until the very last minute.

264
00:15:39,835 --> 00:15:43,525
Speaker 4:  Look, the millionaire Chinese teens buying GWAS all over Los

265
00:15:43,525 --> 00:15:47,075
Speaker 4:  Angeles, it's gotta come from somewhere, you know?

266
00:15:47,075 --> 00:15:50,925
Speaker 4:  Exactly like the children of the ccp, they need their gwas. That's all

267
00:15:50,925 --> 00:15:53,165
Speaker 4:  I'm saying. I'm just put, I'm just putting that out there somewhere and like

268
00:15:53,165 --> 00:15:57,065
Speaker 4:  money, money talks and like that's real. And I think having some dollars

269
00:15:57,065 --> 00:16:00,365
Speaker 4:  is better than no dollars. Whether or not it's fair that the price is

270
00:16:00,365 --> 00:16:04,185
Speaker 4:  depressed because the thing has to be sold. Good

271
00:16:04,185 --> 00:16:07,795
Speaker 4:  question. There's just not a world in which the

272
00:16:07,795 --> 00:16:11,575
Speaker 4:  evaluation doesn't come down to, are we gonna be successful in court?

273
00:16:11,575 --> 00:16:15,405
Speaker 4:  What number can we get? Because that middle road of, we pulled out

274
00:16:15,405 --> 00:16:19,305
Speaker 4:  of the United States market and now we have nothing to show for all of our

275
00:16:19,305 --> 00:16:23,105
Speaker 4:  investment in building the TikTok user base. It just seems it's some, that's

276
00:16:23,105 --> 00:16:24,095
Speaker 4:  a lawsuit too.

277
00:16:24,095 --> 00:16:27,185
Speaker 5:  It's also just straight up bad business. Like that is just straightforwardly

278
00:16:27,185 --> 00:16:30,615
Speaker 5:  like a stupid capitalism decision at some point.

279
00:16:30,615 --> 00:16:34,495
Speaker 4:  Notably the Chinese government not so capitalist putting that out there.

280
00:16:34,495 --> 00:16:38,265
Speaker 5:  Well, and again, like there are the question of who ultimately makes

281
00:16:38,265 --> 00:16:42,225
Speaker 5:  this decision on that side very hard to

282
00:16:42,225 --> 00:16:45,955
Speaker 5:  know, would tell you a lot about Yeah. How this will turn out,

283
00:16:45,955 --> 00:16:49,825
Speaker 5:  right? Like if, if Chuchu, the CEO of TikTok is the person who ultimately

284
00:16:49,825 --> 00:16:53,725
Speaker 5:  makes the decision, that will be very different than if TikTok

285
00:16:53,725 --> 00:16:56,705
Speaker 5:  is connected to ance, is connected to the Chinese Communist Party, which

286
00:16:56,705 --> 00:16:59,025
Speaker 5:  ultimately means the Chinese Communist Party makes that decision, that would

287
00:16:59,025 --> 00:17:02,235
Speaker 5:  go very differently. Like there's so many things we don't know

288
00:17:02,235 --> 00:17:03,215
Speaker 5:  still.

289
00:17:03,215 --> 00:17:06,705
Speaker 6:  It's an exciting time, honestly. Like I love when a social media platform

290
00:17:06,705 --> 00:17:10,665
Speaker 6:  changes hands or has this big moment because then you see, see

291
00:17:10,665 --> 00:17:14,325
Speaker 6:  things like Adam Ari today was it on Instagram neli, I think you you

292
00:17:14,325 --> 00:17:17,635
Speaker 6:  you clocked the video of him just explaining to creators how to get

293
00:17:17,635 --> 00:17:21,585
Speaker 6:  engagement Yeah. On the platform. And it's like that probably wouldn't have

294
00:17:21,585 --> 00:17:23,775
Speaker 6:  happened if there wasn't a TikTok

295
00:17:23,775 --> 00:17:26,945
Speaker 4:  Adam and Sarah being like, so okay, you're at work. I'm gonna set some goals

296
00:17:26,945 --> 00:17:29,785
Speaker 4:  for you. We're gonna check in in six months to see how they're going and

297
00:17:29,785 --> 00:17:32,225
Speaker 4:  you know, we'll see how it's going. And it's like, dude, why does this all

298
00:17:32,225 --> 00:17:35,025
Speaker 4:  feel like work? Yeah. Like I actually think that's like the bigger story.

299
00:17:35,025 --> 00:17:38,945
Speaker 4:  Here's like, this feels like a work for an awful lot of people across all

300
00:17:38,945 --> 00:17:42,665
Speaker 4:  of these platforms. Yeah. And like maybe some people are gonna be like, I

301
00:17:42,665 --> 00:17:45,465
Speaker 4:  don't wanna work for TikTok anymore 'cause it came to nothing. And that will

302
00:17:45,465 --> 00:17:47,245
Speaker 4:  just create energy somewhere else. We'll see

303
00:17:47,245 --> 00:17:51,205
Speaker 5:  One of the funniest memes to me on Instagram is all the people who are

304
00:17:51,205 --> 00:17:54,685
Speaker 5:  like, oh, I had a call with Meta and we talked about, you know, strategies

305
00:17:54,685 --> 00:17:58,125
Speaker 5:  for how to succeed and it like, it has become a meme of people making jokes

306
00:17:58,125 --> 00:18:01,285
Speaker 5:  about it. But it started as a real thing and it's like, it's a big win to

307
00:18:01,285 --> 00:18:04,525
Speaker 5:  have a business call with meta executives about your Instagram presence.

308
00:18:04,525 --> 00:18:04,915
Speaker 5:  Wait,

309
00:18:04,915 --> 00:18:08,765
Speaker 6:  Wait. Did social media become the new Mary Kay?

310
00:18:08,765 --> 00:18:11,055
Speaker 4:  Yeah. Oh it's been there for a long time. I don't

311
00:18:11,055 --> 00:18:11,615
Speaker 6:  Realize, have you seen the

312
00:18:11,615 --> 00:18:15,535
Speaker 4:  People, the Hydrow water bottles? Yes. The

313
00:18:15,535 --> 00:18:18,415
Speaker 4:  bottles just have a blue LED in the bottom and they're like, this adds hydrogen

314
00:18:18,415 --> 00:18:21,075
Speaker 4:  to your water. That's a lie. It's very

315
00:18:21,075 --> 00:18:24,895
Speaker 4:  bad. And if you don't understand why it's bad, I'm just telling you that

316
00:18:24,895 --> 00:18:26,815
Speaker 4:  water is made of hydrogen.

317
00:18:26,815 --> 00:18:28,025
Speaker 5:  Yeah. It's already in there. It's

318
00:18:28,025 --> 00:18:30,495
Speaker 4:  Don't need more. There's two of 'em for every oxygen

319
00:18:30,495 --> 00:18:33,135
Speaker 4:  famously you get, you get two of

320
00:18:33,135 --> 00:18:36,995
Speaker 4:  them double your hydrogens.

321
00:18:36,995 --> 00:18:40,175
Speaker 4:  And it's like, what are you doing? Like how is this happening on this platform?

322
00:18:40,175 --> 00:18:42,635
Speaker 4:  And they're all selling 'em a TikTok shop. And I just think that platform,

323
00:18:42,635 --> 00:18:46,455
Speaker 4:  the revenue pressure on all the social platforms is so high, but

324
00:18:46,455 --> 00:18:48,915
Speaker 4:  all these companies need to make money. They show profitability, they're

325
00:18:48,915 --> 00:18:52,115
Speaker 4:  doing layoffs and they're just turning the screws. I'm like, can we, how

326
00:18:52,115 --> 00:18:55,955
Speaker 4:  do we make money? And they just landed on the home shopping network. I think

327
00:18:55,955 --> 00:18:59,475
Speaker 4:  it was headed towards a cliff anyway. Like there was a bubble in Video Creator

328
00:18:59,475 --> 00:19:02,115
Speaker 4:  economy. Taylor Lawrence has actually talked about

329
00:19:02,115 --> 00:19:05,765
Speaker 4:  it. And you can just see like to me the Hydrow

330
00:19:05,765 --> 00:19:09,715
Speaker 4:  water bottle is like, oh that bubble's getting pretty big. Yeah. Like

331
00:19:09,715 --> 00:19:12,115
Speaker 4:  it's, it's not good. All right, so here's the exercise. I wanna

332
00:19:12,115 --> 00:19:15,595
Speaker 4:  do three options, right? Lawsuit

333
00:19:15,595 --> 00:19:18,955
Speaker 4:  succeeds by chance, burns it down, or they get

334
00:19:18,955 --> 00:19:22,915
Speaker 4:  sold. TikTok is a prize, right? It is the thing that

335
00:19:22,915 --> 00:19:26,275
Speaker 4:  no one can get. It is a scaled social network with an active user base of

336
00:19:26,275 --> 00:19:29,875
Speaker 4:  young people. That's what everybody wants. It's really hard to get the way

337
00:19:29,875 --> 00:19:33,755
Speaker 4:  that TikTok got it right? They acquired Musically and then by dance started

338
00:19:33,755 --> 00:19:37,715
Speaker 4:  spending billions upon billions of dollars on Facebook and Instagram ads

339
00:19:37,715 --> 00:19:41,275
Speaker 4:  to convert people into downloading the app. You can't really do that. You

340
00:19:41,275 --> 00:19:44,465
Speaker 4:  can't even run that playbook anymore because of Apple's app tracking transparency.

341
00:19:44,465 --> 00:19:48,335
Speaker 4:  Like they made the ad changes. And so the market for app install ads

342
00:19:48,335 --> 00:19:51,195
Speaker 4:  is basically gone. You have to pay Apple for them in the app store. Now a

343
00:19:51,195 --> 00:19:54,375
Speaker 4:  different conversation. But the point is you can't just run the playbook

344
00:19:54,375 --> 00:19:57,835
Speaker 4:  by Chance did. And they ran that playbook to the tune of billions upon billions

345
00:19:57,835 --> 00:20:01,615
Speaker 4:  of dollars. Right? So here's this thing that was really hard to

346
00:20:01,615 --> 00:20:05,315
Speaker 4:  do that the conditions under which Ance did it have

347
00:20:05,315 --> 00:20:08,345
Speaker 4:  dramatically changed and it was very expensive even when they could do it.

348
00:20:08,345 --> 00:20:11,835
Speaker 4:  It's what everybody wants. It will be expensive, right? This

349
00:20:11,835 --> 00:20:15,655
Speaker 4:  isn't, this isn't like Twitter fire sale and even that was expensive

350
00:20:15,655 --> 00:20:19,535
Speaker 4:  as we've all discovered. Like that was overpriced. This is the thing, like

351
00:20:19,535 --> 00:20:22,755
Speaker 4:  it is a scaled video advertising platform with a bunch of young people on

352
00:20:22,755 --> 00:20:26,635
Speaker 4:  it that love it, that defines the culture all the time. So who

353
00:20:26,635 --> 00:20:29,595
Speaker 4:  can afford it? I just looked up the list of the largest American companies

354
00:20:29,595 --> 00:20:33,195
Speaker 4:  by market cap, all of the ones that are measured in trillions or tech

355
00:20:33,195 --> 00:20:36,615
Speaker 4:  companies. So I figured we could just go down that list and then we can go

356
00:20:36,615 --> 00:20:39,875
Speaker 4:  to the companies that are measured in billions, which are much more amusing

357
00:20:39,875 --> 00:20:43,115
Speaker 4:  to think about as owners of by ance. But that is very fun. I think we should,

358
00:20:43,115 --> 00:20:46,205
Speaker 4:  we should start with the tech companies. 'cause they seem like the most likely

359
00:20:46,205 --> 00:20:48,575
Speaker 4:  group to at least have some interest

360
00:20:48,575 --> 00:20:52,325
Speaker 5:  Clarifying question. How much should we

361
00:20:52,325 --> 00:20:56,185
Speaker 5:  think TikTok is worth? I have an idea in mind, but I'm curious if,

362
00:20:56,185 --> 00:21:00,085
Speaker 5:  if there is a like assumed number that I have not heard for what

363
00:21:00,085 --> 00:21:02,285
Speaker 5:  TikTok is valued at, do we know?

364
00:21:02,285 --> 00:21:05,925
Speaker 4:  So the number that's I have just picked out of the blue is a hundred billion

365
00:21:05,925 --> 00:21:09,385
Speaker 4:  dollars. Okay. 'cause that is more than double what Twitter was worth. Okay.

366
00:21:09,385 --> 00:21:11,925
Speaker 4:  And it's a huge, I'm good with that. It's a huge number. Most companies can't

367
00:21:11,925 --> 00:21:12,285
Speaker 4:  just do that.

368
00:21:12,285 --> 00:21:14,905
Speaker 5:  Right? I would've actually gone a little higher. Yeah. Like the, there was

369
00:21:14,905 --> 00:21:18,645
Speaker 5:  the, the estimate recently that YouTube is worth $400 billion on its

370
00:21:18,645 --> 00:21:21,245
Speaker 5:  own. So I was gonna say like 200, let's go. Once

371
00:21:21,245 --> 00:21:23,555
Speaker 4:  You're out here, it's just like whatever number you want another a hundred

372
00:21:23,555 --> 00:21:24,005
Speaker 4:  bill

373
00:21:24,005 --> 00:21:25,705
Speaker 5:  Like that. I'm good with a hundred bill. Oh no,

374
00:21:25,705 --> 00:21:28,685
Speaker 6:  I'm good. TikTok doesn't, doesn't have like the numbers of YouTube though,

375
00:21:28,685 --> 00:21:29,655
Speaker 6:  right? Like I'm, I'm at

376
00:21:29,655 --> 00:21:33,005
Speaker 5:  50 or the money or the Yeah, no, you're right. I I'm good with a hundred

377
00:21:33,005 --> 00:21:34,425
Speaker 5:  billion. This works

378
00:21:34,425 --> 00:21:37,045
Speaker 4:  By the way. And I'm picking that number just 'cause it, it is this, it's

379
00:21:37,045 --> 00:21:41,015
Speaker 4:  a small hard number. Yeah, right. Like 44 billion for Twitter

380
00:21:41,015 --> 00:21:44,515
Speaker 4:  was like overpriced, but not even then a lot of companies can just like do

381
00:21:44,515 --> 00:21:45,115
Speaker 4:  it.

382
00:21:45,115 --> 00:21:48,865
Speaker 5:  I don't think there's any world in which TikTok is in a, in a

383
00:21:48,865 --> 00:21:52,655
Speaker 5:  regular pure market sense worth less than a hundred billion.

384
00:21:52,655 --> 00:21:54,055
Speaker 5:  So I feel, I feel pretty good about this

385
00:21:54,055 --> 00:21:57,862
Speaker 4:  And I'll, I'll just for some comparison. As of December,

386
00:21:57,995 --> 00:22:01,755
Speaker 4:  2023, apple had $73 billion in cash on hand, which is an

387
00:22:01,755 --> 00:22:05,275
Speaker 4:  insane amount of cash. Like Apple's one of the most cash rich companies out

388
00:22:05,275 --> 00:22:07,755
Speaker 4:  there and that's how much, so I, I picked a hundred 'cause it's, it would

389
00:22:07,755 --> 00:22:10,675
Speaker 4:  be hard even for an Apple to pull off. Yeah, yeah. Anyway, here's the

390
00:22:10,675 --> 00:22:14,255
Speaker 4:  list. Apple and Microsoft jockeying back and forth

391
00:22:14,255 --> 00:22:17,675
Speaker 4:  for biggest market cap. So we'll start with

392
00:22:17,675 --> 00:22:21,635
Speaker 4:  Microsoft today. Microsoft, I actually

393
00:22:21,635 --> 00:22:24,515
Speaker 4:  feels like Microsoft should be in the running for TikTok. They have been

394
00:22:24,515 --> 00:22:27,395
Speaker 4:  in the running before when Trump tried to ban

395
00:22:27,395 --> 00:22:31,315
Speaker 4:  TikTok. Ella got pulled into those conversations. He has

396
00:22:31,315 --> 00:22:34,275
Speaker 4:  repeatedly described it as some of the weirdest business dealings he's ever

397
00:22:34,275 --> 00:22:38,165
Speaker 4:  been a part of. Then it just went away and we got Project Texas

398
00:22:38,165 --> 00:22:41,355
Speaker 4:  where Oracle took over the data, blah, blah, blah, blah, blah. Which case

399
00:22:41,355 --> 00:22:45,145
Speaker 4:  nothing appears to have been mostly a, a front

400
00:22:45,145 --> 00:22:46,655
Speaker 5:  Convinced no one of anything.

401
00:22:46,655 --> 00:22:48,575
Speaker 4:  No, no one cares about Project Texas

402
00:22:48,575 --> 00:22:52,545
Speaker 5:  And Microsoft has been desperate for like a true consumer

403
00:22:52,545 --> 00:22:56,065
Speaker 5:  play for a long time. I mean, it it wasn't it Microsoft that

404
00:22:56,065 --> 00:22:59,755
Speaker 5:  sniffed around discord in a pretty big way. Yep. Like it wants something

405
00:22:59,755 --> 00:23:01,235
Speaker 5:  like this very badly.

406
00:23:01,235 --> 00:23:05,035
Speaker 6:  I I disagree. This is, this is like a big old hot potato

407
00:23:05,035 --> 00:23:08,995
Speaker 6:  Microsoft wants no, part of like the big power of Microsoft nowadays is that

408
00:23:08,995 --> 00:23:12,635
Speaker 6:  we don't talk about Microsoft that often. And, and that

409
00:23:12,635 --> 00:23:15,115
Speaker 6:  would change immediately with TikTok.

410
00:23:15,115 --> 00:23:18,395
Speaker 4:  Yeah. A good question for all this is does your CEO want to get hauled in

411
00:23:18,395 --> 00:23:22,075
Speaker 4:  front of Congress to talk about content moderation, right? Yeah. And mi

412
00:23:22,075 --> 00:23:25,995
Speaker 4:  Microsoft No. The answer appears to be no. That said, there is

413
00:23:25,995 --> 00:23:29,955
Speaker 4:  a lot of scrutiny around Microsoft Steel with open ai like a

414
00:23:29,955 --> 00:23:32,355
Speaker 4:  lot of antitrust scrutiny. And this is gonna come up, the idea of antitrust

415
00:23:32,355 --> 00:23:35,755
Speaker 4:  scrutiny is gonna come up as we go through this list. And there's, I think

416
00:23:35,755 --> 00:23:38,115
Speaker 4:  Microsoft could run a play where they say, look, here's what we're gonna

417
00:23:38,115 --> 00:23:41,875
Speaker 4:  do. We're gonna do a partnership with like snap, which can definitely Snap

418
00:23:41,875 --> 00:23:45,685
Speaker 4:  is not on the list of biggest American companies by any, by any

419
00:23:45,685 --> 00:23:49,605
Speaker 4:  means. Like not even in the top 100. Like, no, it's not even sniffing

420
00:23:49,605 --> 00:23:53,125
Speaker 4:  this, but you could say Microsoft. But you could see Microsoft say, okay,

421
00:23:53,125 --> 00:23:56,205
Speaker 4:  we're gonna do this weird kind of partnership with Snap, where they will

422
00:23:56,205 --> 00:23:59,465
Speaker 4:  fund them buying TikTok will like be their backend provider. They'll run

423
00:23:59,465 --> 00:24:02,445
Speaker 4:  AI and Azure for recommendations and it'll be the same kind of structure

424
00:24:02,445 --> 00:24:06,405
Speaker 4:  as ai. And if that's fine over here, 'cause it solves a big problem. I bet

425
00:24:06,405 --> 00:24:08,155
Speaker 4:  it's fine over here with OpenAI.

426
00:24:08,155 --> 00:24:11,725
Speaker 6:  Lena Kahn will drop, kick that deal

427
00:24:11,725 --> 00:24:15,525
Speaker 4:  Right out the door. I mean, but this is the, this is the game, right? Right.

428
00:24:15,525 --> 00:24:18,445
Speaker 4:  All these companies are, it's an op, this is a problem that needs to get

429
00:24:18,445 --> 00:24:22,345
Speaker 4:  solved. So I'm gonna ask to buy this thing. And if Lena Khan is like,

430
00:24:22,345 --> 00:24:26,325
Speaker 4:  I'm not gonna let anyone buy it, then it is a ban. And so you have to at

431
00:24:26,325 --> 00:24:28,405
Speaker 4:  least run the process and you have to create some leverage somewhere.

432
00:24:28,405 --> 00:24:31,635
Speaker 5:  I think Microsoft has like three meetings but ultimately walks

433
00:24:31,635 --> 00:24:32,655
Speaker 5:  away

434
00:24:32,655 --> 00:24:35,965
Speaker 4:  Again, they came close before. Also, Microsoft doesn't have a dead on antitrust

435
00:24:35,965 --> 00:24:38,405
Speaker 4:  problem because it doesn't run any social networks that's said from Xbox

436
00:24:38,405 --> 00:24:42,165
Speaker 4:  Live. And so it, you know, they, they could just buy

437
00:24:42,165 --> 00:24:46,145
Speaker 4:  it. I dunno if they'd want to, but I, I think using it as leverage

438
00:24:46,145 --> 00:24:49,935
Speaker 4:  to turn down the heat on open AI might be interesting. That's Microsoft

439
00:24:49,935 --> 00:24:53,365
Speaker 4:  Apple one or two, the biggest companies in the world. Microsoft and Apple

440
00:24:53,365 --> 00:24:56,965
Speaker 4:  always going back and forth. Apple no way is my answer to this

441
00:24:56,965 --> 00:24:59,885
Speaker 4:  question. 0%. Then Timco wants to sit in front of Congress and talk about

442
00:24:59,885 --> 00:25:01,425
Speaker 4:  content moderation. Ever.

443
00:25:01,425 --> 00:25:05,245
Speaker 5:  The funniest possible outcome of this whole thing is that Apple buys

444
00:25:05,245 --> 00:25:09,125
Speaker 5:  TikTok and makes it a feature of Apple TV plus. That is the, that

445
00:25:09,125 --> 00:25:13,085
Speaker 5:  is the single best thing that could possibly happen. That this is, this

446
00:25:13,085 --> 00:25:15,705
Speaker 5:  is their content play for Apple TV plus.

447
00:25:15,705 --> 00:25:18,115
Speaker 6:  Oh it would be, it would be Apple Music.

448
00:25:18,115 --> 00:25:21,045
Speaker 4:  Yeah, apple Music, right. Apple runs a music service. TikTok is huge in music.

449
00:25:21,045 --> 00:25:24,485
Speaker 4:  They have great relationships with all the labels because they're the big

450
00:25:24,485 --> 00:25:28,445
Speaker 4:  hedging against Spotify. Apple importantly has an incredible

451
00:25:28,445 --> 00:25:31,365
Speaker 4:  relationship with the Chinese government that is extremely well managed by

452
00:25:31,365 --> 00:25:35,275
Speaker 4:  Tim Cook. So they're, they're a known partner that would

453
00:25:35,275 --> 00:25:38,565
Speaker 4:  find a way to blah, blah, blah interoperate, you know,

454
00:25:38,565 --> 00:25:42,525
Speaker 4:  with ance globally, you, you could see the arguments. I'm just saying,

455
00:25:42,525 --> 00:25:44,645
Speaker 4:  I don't think Tim Cook wants to sit in front of Congress and talk about content

456
00:25:44,645 --> 00:25:45,285
Speaker 4:  moderation. I

457
00:25:45,285 --> 00:25:49,205
Speaker 6:  I think Neli, they're gonna use that exact quote you just said. When

458
00:25:49,205 --> 00:25:52,145
Speaker 6:  they pull Tim Cook in front of Congress for buying

459
00:25:52,145 --> 00:25:53,705
Speaker 6:  TikTok,

460
00:25:53,705 --> 00:25:57,125
Speaker 5:  You have a good relationship with the Chinese government is precisely the

461
00:25:57,125 --> 00:26:00,385
Speaker 5:  reason not to buy TikTok. If you're Tim Cook,

462
00:26:00,385 --> 00:26:04,205
Speaker 4:  All right, moving on. IIII think we can all, it would be the shock of all

463
00:26:04,205 --> 00:26:07,925
Speaker 4:  shocks of Apple buys TikTok, Nvidia, third biggest market cap in the country

464
00:26:07,925 --> 00:26:11,745
Speaker 4:  right now. It feels a bit a field.

465
00:26:11,745 --> 00:26:15,325
Speaker 6:  No, no, no. Jenssen's. Like he's a smart

466
00:26:15,325 --> 00:26:19,005
Speaker 6:  dude, right? Like he, he started that company from the ground up. He's still

467
00:26:19,005 --> 00:26:22,865
Speaker 6:  running it now. He made his big bet on ai.

468
00:26:22,865 --> 00:26:26,845
Speaker 6:  He, like, they think very measured over there. Like everything

469
00:26:26,845 --> 00:26:30,445
Speaker 6:  they do has a purpose and a point even when it's a screw up. So I'd be

470
00:26:30,445 --> 00:26:32,835
Speaker 6:  like very surprised.

471
00:26:32,835 --> 00:26:36,765
Speaker 5:  Okay, allow me to make the counter case. Yeah. I love it. I'm Jensen Wong.

472
00:26:36,765 --> 00:26:40,285
Speaker 5:  I have somewhat intentionally, somewhat

473
00:26:40,285 --> 00:26:43,875
Speaker 5:  accidentally stumbled into a, just an unbelievable gold

474
00:26:43,875 --> 00:26:47,735
Speaker 5:  mine that is the AI revolution. This will not last forever.

475
00:26:47,735 --> 00:26:51,705
Speaker 5:  Other people are going to figure out how to make GPUs as good as mine. And

476
00:26:51,705 --> 00:26:54,965
Speaker 5:  I'm not going to be able to sell H one hundreds for however much money I

477
00:26:54,965 --> 00:26:57,675
Speaker 5:  want to whoever I want forever. I need another

478
00:26:57,675 --> 00:27:00,985
Speaker 5:  move. That other move is

479
00:27:00,985 --> 00:27:03,365
Speaker 5:  TikTok.

480
00:27:03,365 --> 00:27:06,885
Speaker 4:  I want, I want that someone is writing that memo at Nvidia right now. Yes.

481
00:27:06,885 --> 00:27:09,365
Speaker 4:  And then at the end of it, it's like question mark, question mark, question

482
00:27:09,365 --> 00:27:13,285
Speaker 4:  mark, profit. You know, like, this is the move that's

483
00:27:13,285 --> 00:27:16,565
Speaker 4:  as big as H 100. It's like, ah, I dunno about that. No.

484
00:27:16,565 --> 00:27:20,405
Speaker 5:  The, the other, the other reason is there, there is a real version of

485
00:27:20,405 --> 00:27:23,915
Speaker 5:  this that is TikTok as training data.

486
00:27:23,915 --> 00:27:27,805
Speaker 5:  Yeah. which I think is, is not worth a hundred billion dollars, but is

487
00:27:27,805 --> 00:27:31,525
Speaker 5:  also not worth nothing. And I think one reason a lot of these companies will

488
00:27:31,525 --> 00:27:35,085
Speaker 5:  take a good hard look at TikTok is not because they want to operate a social

489
00:27:35,085 --> 00:27:39,035
Speaker 5:  network forever, but because operating a social network gets them

490
00:27:39,035 --> 00:27:42,765
Speaker 5:  basically an infinite supply of good training data for AI

491
00:27:42,765 --> 00:27:43,385
Speaker 5:  systems

492
00:27:43,385 --> 00:27:45,225
Speaker 6:  For now. Very. Right.

493
00:27:45,225 --> 00:27:47,925
Speaker 5:  That's just what it is. I mean, this is what Mark Zuckerberg has been talking

494
00:27:47,925 --> 00:27:51,085
Speaker 5:  about with Facebook. Like, they're, they're touting the fact that they have

495
00:27:51,085 --> 00:27:53,085
Speaker 5:  this vast supply of stuff that people,

496
00:27:53,085 --> 00:27:55,965
Speaker 4:  All right, so Jensen swoops in and he is like, look, I'm already in the middle

497
00:27:55,965 --> 00:27:59,885
Speaker 4:  of geopolitical hot zones. Yeah. 'cause I'm, you know, I'm

498
00:27:59,885 --> 00:28:03,565
Speaker 4:  building ships with TSMC in Taiwan and the whole universe is organized

499
00:28:03,565 --> 00:28:07,365
Speaker 4:  around H one H 100 production in Taiwan. What if I had a little TikTok to

500
00:28:07,365 --> 00:28:11,245
Speaker 4:  the mix, I could do it all right. That's, that's Nvidia. I I I'm putting

501
00:28:11,245 --> 00:28:13,505
Speaker 4:  that sub 50%

502
00:28:13,505 --> 00:28:14,725
Speaker 5:  Way sub 50, but

503
00:28:14,725 --> 00:28:18,545
Speaker 4:  I sub 10. But we made the argument alphabet

504
00:28:18,545 --> 00:28:22,465
Speaker 4:  or as the people know it, Google,

505
00:28:22,465 --> 00:28:26,035
Speaker 6:  I mean, I think that no one wants them to buy it.

506
00:28:26,035 --> 00:28:29,605
Speaker 4:  Don't, if you wanna ban TikTok, you let Google buy it and just

507
00:28:29,605 --> 00:28:31,505
Speaker 4:  slowly kill it until they shut it down.

508
00:28:31,505 --> 00:28:35,185
Speaker 6:  Yeah. Like, like that's what'll happen. That that is effectively a

509
00:28:35,185 --> 00:28:37,285
Speaker 6:  ban. So no.

510
00:28:37,285 --> 00:28:39,105
Speaker 4:  Do you think they're having a conversation?

511
00:28:39,105 --> 00:28:41,825
Speaker 6:  I think Google's totally having that conversation though. Like they, they

512
00:28:41,825 --> 00:28:45,625
Speaker 6:  love a social media platform that they kill a few years later. This is

513
00:28:45,625 --> 00:28:46,495
Speaker 6:  just like

514
00:28:46,495 --> 00:28:49,225
Speaker 4:  Yeah, but so to David's point, this is a rich source of training data for

515
00:28:49,225 --> 00:28:49,825
Speaker 4:  Google. Yeah.

516
00:28:49,825 --> 00:28:50,665
Speaker 6:  I think that's why they're, they're actually

517
00:28:50,665 --> 00:28:54,545
Speaker 4:  Talking. It is a long time ago when I asked Sundar about the

518
00:28:54,545 --> 00:28:57,465
Speaker 4:  web and what SEO has done to the web and where you would start a new thing

519
00:28:57,465 --> 00:29:00,265
Speaker 4:  if you were a new creator. He said, well, we have, we have YouTube, right?

520
00:29:00,265 --> 00:29:04,225
Speaker 4:  So they know that all the sort of organic content that is made by

521
00:29:04,225 --> 00:29:07,665
Speaker 4:  human beings is happening on video platforms. This is a rich source of that.

522
00:29:07,665 --> 00:29:10,265
Speaker 4:  They're already searching TikTok. You can search for tiktoks and Google search.

523
00:29:10,265 --> 00:29:13,605
Speaker 5:  Yeah. Don't forget, Google has been saying loudly for two years now that

524
00:29:13,605 --> 00:29:15,805
Speaker 5:  one of the biggest threats to Google search is TikTok.

525
00:29:15,805 --> 00:29:16,995
Speaker 4:  Yep.

526
00:29:16,995 --> 00:29:20,125
Speaker 6:  Which is again, why they're not gonna

527
00:29:20,125 --> 00:29:23,065
Speaker 4:  Buy this is the real Lena Con hands on hips one, right? Yeah, absolutely.

528
00:29:23,065 --> 00:29:27,025
Speaker 5:  No Alphabet would do this. I, I believe Absolutely. Yes. Alphabet would do

529
00:29:27,025 --> 00:29:30,975
Speaker 5:  this. It would be sued to death

530
00:29:30,975 --> 00:29:34,785
Speaker 5:  once Lean Kahn is like already standing outside of the Google plex

531
00:29:34,785 --> 00:29:38,745
Speaker 5:  and Mountain View with a lawsuit and just ready to like huck

532
00:29:38,745 --> 00:29:42,585
Speaker 5:  it into soon Aisha's office the minute this happens. I like if

533
00:29:42,585 --> 00:29:46,305
Speaker 5:  I'm, if I'm student hai, I would do this in one

534
00:29:46,305 --> 00:29:49,005
Speaker 5:  second, but there's absolutely no chance that they will.

535
00:29:49,005 --> 00:29:51,405
Speaker 4:  Alright, so that's Google and the next one is really

536
00:29:51,405 --> 00:29:55,375
Speaker 4:  interesting. Amazon, I think

537
00:29:55,375 --> 00:29:58,875
Speaker 4:  Amazon looks at TikTok slowly turning into the home shopping

538
00:29:58,875 --> 00:30:02,835
Speaker 4:  network and moving an awful lot of records and

539
00:30:02,835 --> 00:30:05,785
Speaker 4:  is like this, we, this is what we want. This is the future of shopping.

540
00:30:05,785 --> 00:30:09,695
Speaker 5:  Yeah. Yep. Amazon has been gently trying to do this on

541
00:30:09,695 --> 00:30:12,585
Speaker 5:  Amazon properties for a while. Yeah. They've had

542
00:30:12,585 --> 00:30:16,555
Speaker 5:  creator brand things that they've done, they've brought people in, they've

543
00:30:16,555 --> 00:30:20,395
Speaker 5:  done video stuff. None of it has really worked. But yeah,

544
00:30:20,395 --> 00:30:23,955
Speaker 5:  I, I think, I think Amazon of these is the one that makes the most sense

545
00:30:23,955 --> 00:30:27,665
Speaker 5:  and also probably the one that is most likely to be plausible.

546
00:30:27,665 --> 00:30:30,875
Speaker 4:  Yeah. I don't think, they don't run a social platform now in way, shape,

547
00:30:30,875 --> 00:30:34,775
Speaker 4:  or form. So the antitrust issues don't seem so bad. That said, you know,

548
00:30:34,775 --> 00:30:38,475
Speaker 4:  the Europeans just blocked Amazon from buying iRobot because they were worried

549
00:30:38,475 --> 00:30:41,985
Speaker 4:  about concentration on the robotic vacuum market. And Annie Jesse looked

550
00:30:41,985 --> 00:30:45,575
Speaker 4:  furious when he was talking about that on CBC. Just

551
00:30:45,575 --> 00:30:49,235
Speaker 4:  so mad. Yeah. He's like, we're well beyond the law now. Like are

552
00:30:49,235 --> 00:30:51,115
Speaker 4:  we, I dunno, it sounds like

553
00:30:51,115 --> 00:30:52,015
Speaker 6:  You were right by the law,

554
00:30:52,015 --> 00:30:55,735
Speaker 4:  But they don't, but they don't have a social platform. And TikTok really

555
00:30:55,735 --> 00:30:58,635
Speaker 4:  is a big advertising play and Amazon is actually one of the biggest advertisers

556
00:30:58,635 --> 00:31:02,235
Speaker 4:  out there. I could see it. I think this would probably turn TikTok into something

557
00:31:02,235 --> 00:31:03,495
Speaker 4:  worse.

558
00:31:03,495 --> 00:31:07,275
Speaker 6:  Oh yeah, yeah. This is like Google where you don't want, if you're a TikTok

559
00:31:07,275 --> 00:31:09,985
Speaker 6:  Yu you don't want this purchase. Yeah.

560
00:31:09,985 --> 00:31:13,675
Speaker 4:  Like where can you imagine if you just combine Amazon alphabet soup

561
00:31:13,675 --> 00:31:16,405
Speaker 4:  brands with TikTok shops, just general

562
00:31:16,405 --> 00:31:20,395
Speaker 6:  Aesthetics. Oh my. Got Amazon Basics just nonstop

563
00:31:20,395 --> 00:31:21,075
Speaker 6:  in your feed.

564
00:31:21,075 --> 00:31:24,895
Speaker 4:  I would 100% calling, start calling that group of TikTok creators Amazon

565
00:31:24,895 --> 00:31:28,875
Speaker 4:  Basics. You, you know who I'm talking about? Oh yeah, yeah.

566
00:31:28,875 --> 00:31:31,635
Speaker 4:  Like the Amazon basics. It would be bad for

567
00:31:31,635 --> 00:31:35,435
Speaker 4:  America. Okay. So that's Amazon. That feels very

568
00:31:35,435 --> 00:31:39,315
Speaker 4:  likely of this list. So far, Microsoft and Amazon feel like the, the most

569
00:31:39,315 --> 00:31:43,275
Speaker 4:  likely to, to at least try. Then there's Meta, which feels like a

570
00:31:43,275 --> 00:31:47,075
Speaker 4:  immediate hard no. Yeah, yeah. And I think the TikTok user base would

571
00:31:47,075 --> 00:31:48,745
Speaker 4:  revolt and leave if they tried

572
00:31:48,745 --> 00:31:51,495
Speaker 5:  Meta would do it. It wouldn't be allowed to do it.

573
00:31:51,495 --> 00:31:54,715
Speaker 4:  Oh, sure. What? Mark Zuckerberg's a killer. Yeah. He'd be like a hundred

574
00:31:54,715 --> 00:31:58,075
Speaker 4:  million dollars. Like how many people do I have to kill? I'll just, it's

575
00:31:58,075 --> 00:31:59,415
Speaker 4:  it's done. It's been done.

576
00:31:59,415 --> 00:32:03,255
Speaker 5:  And then at that point, I think Meadow would own the five most popular apps

577
00:32:03,255 --> 00:32:03,895
Speaker 5:  in existence.

578
00:32:03,895 --> 00:32:05,795
Speaker 4:  And also the regulators have a really good argument from Meta right now,

579
00:32:05,795 --> 00:32:09,735
Speaker 4:  which, hey, you just made threads from scratch and it's doing great

580
00:32:09,735 --> 00:32:13,275
Speaker 4:  by some, you know, fake accounting. It's bigger than

581
00:32:13,275 --> 00:32:16,185
Speaker 4:  Twitter. And I only say fake because Twitter's numbers are fake. And then

582
00:32:16,185 --> 00:32:18,695
Speaker 4:  it's like sensor tower numbers, which are weird. Like

583
00:32:18,695 --> 00:32:19,955
Speaker 6:  No one's numbers are real. Yeah.

584
00:32:19,955 --> 00:32:22,455
Speaker 4:  You just, you just mash together a bunch of very truthy feeling numbers,

585
00:32:22,455 --> 00:32:25,235
Speaker 4:  you know, like Threads is bigger than Twitter. Fine. But the argument would

586
00:32:25,235 --> 00:32:28,175
Speaker 4:  be, well, you can do it on your own. You don't need, you don't need this.

587
00:32:28,175 --> 00:32:31,375
Speaker 4:  So we'll see. So that's okay. That's all the companies with valuations in

588
00:32:31,375 --> 00:32:35,165
Speaker 4:  the Ts. Notably, they're all tech companies. Then you

589
00:32:35,165 --> 00:32:39,145
Speaker 4:  slide down one notch, you go from six to seven, the valuations are

590
00:32:39,145 --> 00:32:42,805
Speaker 4:  now in the bees and the billions. And I would just say these are much

591
00:32:42,805 --> 00:32:45,545
Speaker 4:  funnier companies to consider Berkshire Hathaway.

592
00:32:45,545 --> 00:32:48,345
Speaker 6:  Yes. Yes. That's the most likely, honestly.

593
00:32:48,345 --> 00:32:49,785
Speaker 4:  Warren Buffet,

594
00:32:49,785 --> 00:32:51,645
Speaker 6:  Warren Buffet, Warren Buffet's, like social media, Warren

595
00:32:51,645 --> 00:32:54,405
Speaker 5:  Buffet, let's go out Warren Buffet, like Warren Buffet buying TikTok so that

596
00:32:54,405 --> 00:32:58,085
Speaker 5:  he could become like the ultimate TikTok in the way that Elon Musk bought

597
00:32:58,085 --> 00:33:00,915
Speaker 5:  Twitter. So he could just be the tweeter. Yeah. Like perfect.

598
00:33:00,915 --> 00:33:03,625
Speaker 4:  When I think of Warren Buffet, I love for, I think of the phrase burnout

599
00:33:03,625 --> 00:33:07,395
Speaker 4:  not fade away and buying TikTok. Really

600
00:33:07,395 --> 00:33:10,845
Speaker 4:  just light of fire, baby. Just get out there. You got guy you

601
00:33:10,845 --> 00:33:14,605
Speaker 5:  Got driving his old car to McDonald's every morning. Just vlogging on TikTok.

602
00:33:14,605 --> 00:33:16,985
Speaker 5:  Are you kidding? Come on.

603
00:33:16,985 --> 00:33:19,365
Speaker 4:  It would be great. I could see it. It, I don't know how it fits in the, in

604
00:33:19,365 --> 00:33:23,025
Speaker 4:  the portfolio. It would be good.

605
00:33:23,025 --> 00:33:25,955
Speaker 4:  Eli Lilly. It feels like a no

606
00:33:25,955 --> 00:33:27,415
Speaker 4:  Visa.

607
00:33:27,415 --> 00:33:28,885
Speaker 6:  Yeah.

608
00:33:28,885 --> 00:33:31,605
Speaker 4:  JP Morgan Chase. Why not have a bank owned

609
00:33:31,605 --> 00:33:33,265
Speaker 4:  TikTok? What

610
00:33:33,265 --> 00:33:37,205
Speaker 5:  If TikTok was just payments processing

611
00:33:37,205 --> 00:33:40,905
Speaker 4:  At the end of the day? Tesla is here at number 12 on market cap list. Although

612
00:33:40,905 --> 00:33:44,105
Speaker 4:  that valuation fluctuating wildly with every breath Elon

613
00:33:44,105 --> 00:33:48,065
Speaker 4:  takes. That feels like an obvious No. Although the man does

614
00:33:48,065 --> 00:33:50,255
Speaker 4:  love a social network. So I mean,

615
00:33:50,255 --> 00:33:53,855
Speaker 5:  Yeah. Is is Elon Musk himself a totally

616
00:33:53,855 --> 00:33:54,775
Speaker 5:  bonkers poss

617
00:33:54,775 --> 00:33:57,785
Speaker 4:  Here? Elon, I will say Elon, you know, he's doing whatever. He is doing Twitter

618
00:33:57,785 --> 00:34:00,805
Speaker 4:  and he is got Linda out there being like, Twitter's a video first platform.

619
00:34:00,805 --> 00:34:04,625
Speaker 4:  And then Elon is the most text forward person in the entire world. That's

620
00:34:04,625 --> 00:34:06,105
Speaker 4:  it. I don't think so. Yeah, he's

621
00:34:06,105 --> 00:34:06,425
Speaker 6:  Sent you a

622
00:34:06,425 --> 00:34:10,285
Speaker 4:  TikTok. This one's interesting. Walmart, which actually tried

623
00:34:10,285 --> 00:34:14,185
Speaker 4:  to enter the TikTok sweepstakes long ago. That's great. On, on the list.

624
00:34:14,185 --> 00:34:17,325
Speaker 4:  A huge American company would be fascinating. I think for the same reasons

625
00:34:17,325 --> 00:34:20,905
Speaker 4:  as Amazon, right? Can we, can we build a new kind of

626
00:34:20,905 --> 00:34:24,695
Speaker 4:  shopping distribution? I don't know. It doesn't, it does not seem likely.

627
00:34:24,695 --> 00:34:26,515
Speaker 4:  It does not seem like that's what America

628
00:34:26,515 --> 00:34:30,015
Speaker 6:  Wants. They, they have so many ambitions and a lot of money, but like

629
00:34:30,015 --> 00:34:31,775
Speaker 6:  Amazon, I don't want it.

630
00:34:31,775 --> 00:34:35,395
Speaker 4:  All right. I'm just gonna read the, the, the next five and as an exercise

631
00:34:35,395 --> 00:34:38,475
Speaker 4:  for the reader, just like silently consider them and send us an email over

632
00:34:38,475 --> 00:34:42,355
Speaker 4:  which ones you think should buy TikTok of

633
00:34:42,355 --> 00:34:45,405
Speaker 4:  this list. ExxonMobil? Yes.

634
00:34:45,405 --> 00:34:48,755
Speaker 4:  MasterCard, Proctor and Gamble. Home

635
00:34:48,755 --> 00:34:52,545
Speaker 4:  Depot. Costco, bank of America.

636
00:34:52,545 --> 00:34:54,135
Speaker 5:  Okay. Costco is something.

637
00:34:54,135 --> 00:34:54,795
Speaker 6:  Costco. There

638
00:34:54,795 --> 00:34:58,715
Speaker 5:  We go. I just wanna pause on Costco for one second. You know, what is a

639
00:34:58,715 --> 00:35:00,665
Speaker 5:  brand that everybody loves?

640
00:35:00,665 --> 00:35:02,515
Speaker 4:  Cost. Yeah. People love Costco, but if

641
00:35:02,515 --> 00:35:06,305
Speaker 6:  They have to start paying influencers, a living wage

642
00:35:06,305 --> 00:35:10,135
Speaker 6:  like they do with their, their regular staff. No, that's,

643
00:35:10,135 --> 00:35:10,875
Speaker 6:  that's too much

644
00:35:10,875 --> 00:35:13,755
Speaker 4:  Money. Yeah. Costco is like, well, you know, it's a well run company in that

645
00:35:13,755 --> 00:35:17,275
Speaker 4:  way. Then there's the two tech companies I skipped over here, Oracle, which

646
00:35:17,275 --> 00:35:20,935
Speaker 4:  is already in the mix. You could see it, right? They're already in the mix

647
00:35:20,935 --> 00:35:24,855
Speaker 4:  for a reason. And then Salesforce, which I, I think we should end

648
00:35:24,855 --> 00:35:28,055
Speaker 4:  with Salesforce. Oh. Because that is the darkest outcome for

649
00:35:28,055 --> 00:35:30,235
Speaker 4:  TikTok.

650
00:35:30,235 --> 00:35:34,095
Speaker 5:  So, so Salesforce buys TikTok and tries to turn it

651
00:35:34,095 --> 00:35:37,815
Speaker 5:  into what LinkedIn became for Microsoft, basically. Yeah. Yeah. Like

652
00:35:37,815 --> 00:35:40,705
Speaker 5:  Salesforce just goes all in on like business

653
00:35:40,705 --> 00:35:41,945
Speaker 5:  TikTok,

654
00:35:41,945 --> 00:35:45,165
Speaker 4:  Why not? This is the future of American small businesses happening on

655
00:35:45,165 --> 00:35:48,365
Speaker 4:  TikTok. Small business. TikTok is still my favorite thing. They're pressure

656
00:35:48,365 --> 00:35:51,805
Speaker 4:  washer guys out there today. I mean, like, it's spring baby light it up and

657
00:35:51,805 --> 00:35:54,805
Speaker 4:  then they're immediately making TikTok shop content where they're trying

658
00:35:54,805 --> 00:35:58,725
Speaker 4:  to convince me to buy an extremely obviously cheap surface

659
00:35:58,725 --> 00:36:02,605
Speaker 4:  cleaner where like they plug it in and you see the whole thing dent in as

660
00:36:02,605 --> 00:36:06,245
Speaker 4:  they plug in the w I'm like, what are we doing here? Anyway, sorry. I have

661
00:36:06,245 --> 00:36:09,025
Speaker 4:  a lot of feelings about TikTok right now.

662
00:36:09,025 --> 00:36:11,765
Speaker 5:  You you might watch too many ads on TikTok. I just, the

663
00:36:11,765 --> 00:36:12,305
Speaker 4:  Whole thing is

664
00:36:12,305 --> 00:36:14,645
Speaker 5:  You just scroll past them, you know that, right? Like you just scroll past

665
00:36:14,645 --> 00:36:17,145
Speaker 5:  them. I'm just saying, I just scroll until I get bloopers from the office.

666
00:36:17,145 --> 00:36:19,005
Speaker 5:  So I don't even know what you're talking about.

667
00:36:19,005 --> 00:36:22,005
Speaker 4:  Have you started seeing they're, they're doing like the shimmer effect across

668
00:36:22,005 --> 00:36:25,585
Speaker 4:  it to prevent the, the content id. It's very good. Yeah.

669
00:36:25,585 --> 00:36:28,985
Speaker 4:  TikTok, honestly, Disney should buy TikTok because TikTok

670
00:36:28,985 --> 00:36:32,565
Speaker 4:  is the most impressive laboratory of copyright infringement that

671
00:36:32,565 --> 00:36:35,625
Speaker 4:  exists in the world today. And, and maybe in world history.

672
00:36:35,625 --> 00:36:38,845
Speaker 5:  So I was actually gonna bring up Disney as a, as a wild card here. I don't

673
00:36:38,845 --> 00:36:42,785
Speaker 5:  think Disney can afford to do this, but I think like Disney kicked the tires

674
00:36:42,785 --> 00:36:46,765
Speaker 5:  on Twitter a bunch of years ago. Disney is interested in

675
00:36:46,765 --> 00:36:50,305
Speaker 5:  a new media startup in a really big

676
00:36:50,305 --> 00:36:53,765
Speaker 5:  way. I think TikTok is probably too big to be that thing for Disney. Yes.

677
00:36:53,765 --> 00:36:57,445
Speaker 5:  But I, I, if I'm Bob Iger, like I bet, I bet there is a

678
00:36:57,445 --> 00:36:59,065
Speaker 5:  memo in that boardroom.

679
00:36:59,065 --> 00:37:02,905
Speaker 6:  Is Disney still interested? 'cause I think when they kicked the tires

680
00:37:02,905 --> 00:37:06,285
Speaker 6:  on Twitter, that was also around the same time they launched Fusion, which

681
00:37:06,285 --> 00:37:09,035
Speaker 6:  was like their, their digital media play. Yeah.

682
00:37:09,035 --> 00:37:11,755
Speaker 4:  That was the wasting money of in Disney era.

683
00:37:11,755 --> 00:37:14,275
Speaker 6:  Yeah. I I think they're beyond this point now.

684
00:37:14,275 --> 00:37:17,915
Speaker 5:  Yeah. IDI don't think so. I think Disney is in the business of

685
00:37:17,915 --> 00:37:21,865
Speaker 5:  getting young people to watch its stuff. And that the answer

686
00:37:21,865 --> 00:37:23,285
Speaker 5:  to that is TikTok.

687
00:37:23,285 --> 00:37:26,305
Speaker 4:  I want everyone pull over in a car and just imagine with a TikTok

688
00:37:26,305 --> 00:37:29,105
Speaker 4:  themed part of Walt Disney World look like,

689
00:37:29,105 --> 00:37:29,325
Speaker 5:  Oh

690
00:37:29,325 --> 00:37:31,735
Speaker 4:  My God, close that loop.

691
00:37:31,735 --> 00:37:35,645
Speaker 5:  Every ride is 60 seconds long and you just leap

692
00:37:35,645 --> 00:37:38,045
Speaker 4:  From somewhat unsatisfying unless you do it a hundred times in a

693
00:37:38,045 --> 00:37:41,965
Speaker 4:  row. I don't think Bob Iger wants to talk about content moderation

694
00:37:41,965 --> 00:37:45,245
Speaker 4:  in front of Congress. I think that destroys Disney's brand right? To be anywhere

695
00:37:45,245 --> 00:37:48,965
Speaker 4:  close to there is evidence that teenage girls are feeling

696
00:37:48,965 --> 00:37:52,905
Speaker 4:  depressed because of our product. Not, not Disney Zone,

697
00:37:52,905 --> 00:37:56,845
Speaker 4:  but it's inter it's interesting to consider because it is where, you know,

698
00:37:56,845 --> 00:37:59,685
Speaker 4:  like Disney missed out on Coco Melon, which is a YouTube phenomenon and it's

699
00:37:59,685 --> 00:38:03,535
Speaker 4:  now a Netflix phenomenon. They, they don't have a pipeline for that stuff.

700
00:38:03,535 --> 00:38:06,735
Speaker 4:  And TikTok might be that pipeline. I just, I don't think they have the money

701
00:38:06,735 --> 00:38:10,695
Speaker 4:  and I don't think they have the, the mental stamina based

702
00:38:10,695 --> 00:38:12,965
Speaker 4:  on all the other things. They're going Disney. All right, that's the list.

703
00:38:12,965 --> 00:38:15,935
Speaker 4:  There's other stuff you can talk about a MD and Pepsi and Netflix, but I

704
00:38:15,935 --> 00:38:19,095
Speaker 4:  feel like that's the list and you gotta end with Salesforce. 'cause I, I

705
00:38:19,095 --> 00:38:22,655
Speaker 4:  just want everyone to consider the darkest timeline. We'll see what

706
00:38:22,655 --> 00:38:26,615
Speaker 4:  happens. You know, a bunch of forge reporters are out in the world

707
00:38:26,615 --> 00:38:29,215
Speaker 4:  pounding the pavement to see who wants to buy things. What Alex, he told

708
00:38:29,215 --> 00:38:31,455
Speaker 4:  me yesterday when I, when I was like, Hey, let's go through your list. He's

709
00:38:31,455 --> 00:38:34,415
Speaker 4:  like, it's crickets. 'cause they're all afraid of Lean Con. And I think that

710
00:38:34,415 --> 00:38:38,045
Speaker 4:  is, that was how they were talking before Biden signed the

711
00:38:38,045 --> 00:38:41,405
Speaker 4:  bill. And I think that will change in the weeks to come, but there's gonna

712
00:38:41,405 --> 00:38:45,245
Speaker 4:  be a lawsuit. We'll see how it goes. Kind of a wild time though. I like

713
00:38:45,245 --> 00:38:48,485
Speaker 4:  I if you've been paying attention to the rich chest, you know that we, we

714
00:38:48,485 --> 00:38:51,935
Speaker 4:  generally think like all of social media and the internet, it's being like

715
00:38:51,935 --> 00:38:55,915
Speaker 4:  table flipped upheaval and like things are shaken out in different ways.

716
00:38:55,915 --> 00:38:58,115
Speaker 4:  This is one pretty big table flip.

717
00:38:58,115 --> 00:39:01,675
Speaker 5:  Yeah, I think it's, it's gonna be really interesting to see how

718
00:39:01,675 --> 00:39:05,205
Speaker 5:  this radiates outward too, because like there's been a lot of talk in the

719
00:39:05,205 --> 00:39:08,765
Speaker 5:  last couple of days about what this is gonna mean for Instagram and for

720
00:39:08,765 --> 00:39:12,245
Speaker 5:  YouTube shorts and for Snap and there's this sense

721
00:39:12,245 --> 00:39:15,765
Speaker 5:  of a handful of companies in the US that really stand to benefit from the

722
00:39:15,765 --> 00:39:19,545
Speaker 5:  downfall of TikTok. And I think where people go

723
00:39:19,545 --> 00:39:23,405
Speaker 5:  if they go and how those platforms start to change is going

724
00:39:23,405 --> 00:39:26,865
Speaker 5:  to yet again upend the rest of everything. Like, if, if

725
00:39:26,865 --> 00:39:30,805
Speaker 5:  TikTok suddenly floods into YouTube, it will

726
00:39:30,805 --> 00:39:32,505
Speaker 5:  change YouTube completely. Yeah.

727
00:39:32,505 --> 00:39:36,125
Speaker 6:  Oh, there's gonna be a land grab. A hundred percent. Yeah. Between like the

728
00:39:36,125 --> 00:39:39,835
Speaker 6:  QVC nature of TikTok and this all those like

729
00:39:39,835 --> 00:39:42,645
Speaker 6:  Edge case people, the people who aren't really really into it are gonna be

730
00:39:42,645 --> 00:39:45,045
Speaker 6:  like, yeah, I'll just, I'll go somewhere else. 'cause at least I'm, it's,

731
00:39:45,045 --> 00:39:46,155
Speaker 6:  I'm not getting sold to.

732
00:39:46,155 --> 00:39:47,085
Speaker 4:  Yeah, I mean and this is

733
00:42:42,245 --> 00:42:43,485
Speaker 1:  neighbor. State Farm is

734
00:42:43,485 --> 00:42:49,125
Speaker 1:  there.

735
00:42:49,125 --> 00:42:51,845
Speaker 4:  We are back. I just wanna say if at and t bought

736
00:42:51,845 --> 00:42:55,615
Speaker 4:  TikTok, imagine what Zach Snyder would get up to.

737
00:42:55,615 --> 00:42:59,345
Speaker 5:  Well it would immediately be spun off into some other, David Zaslav would

738
00:42:59,345 --> 00:43:01,815
Speaker 5:  own it six months later, so would be, it would be fine.

739
00:43:01,815 --> 00:43:05,195
Speaker 4:  Four three grayscale tiktoks for everyone. Extremely dark.

740
00:43:05,195 --> 00:43:08,425
Speaker 5:  We've been talking a lot about terrible movies on this podcast recently.

741
00:43:08,425 --> 00:43:10,105
Speaker 5:  Should we talk about Rebel Moon?

742
00:43:10,105 --> 00:43:13,745
Speaker 4:  I refuse. I That one's like very bad. Like it's, it's so

743
00:43:13,745 --> 00:43:14,305
Speaker 4:  obviously

744
00:43:14,305 --> 00:43:16,425
Speaker 6:  Bad. Yeah, I haven't even looked at it.

745
00:43:16,425 --> 00:43:19,865
Speaker 4:  I saw, I don't think this is a spoiler. I saw a screenshot of one of the

746
00:43:19,865 --> 00:43:23,455
Speaker 4:  final scenes where the ship is revealed to be a woman who was hog tied. Oh,

747
00:43:23,455 --> 00:43:24,215
Speaker 5:  Good stuff.

748
00:43:24,215 --> 00:43:26,295
Speaker 4:  Doesn't seem like my bag

749
00:43:26,295 --> 00:43:29,585
Speaker 5:  Also. That's almost certainly a spoiler. And I just don't care. So I'm sorry

750
00:43:29,585 --> 00:43:30,505
Speaker 5:  to everyone who No,

751
00:43:30,505 --> 00:43:33,665
Speaker 6:  I mean it does make me kind of wanna watch it, but just so I can be mad while

752
00:43:33,665 --> 00:43:34,685
Speaker 6:  watching it.

753
00:43:34,685 --> 00:43:38,305
Speaker 4:  That's how I felt about hard to be

754
00:43:38,305 --> 00:43:42,185
Speaker 4:  clear. Just raise watch. All right. Enough enough of the Zach Steiner

755
00:43:42,185 --> 00:43:45,585
Speaker 4:  talk. Yeah, look, the man took his bag from at and t and he made a square

756
00:43:45,585 --> 00:43:48,715
Speaker 4:  movie in Grayscale where? Where Superman is super

757
00:43:48,715 --> 00:43:49,705
Speaker 4:  weird.

758
00:43:49,705 --> 00:43:52,725
Speaker 5:  Yeah. And you bring it up like three out of every four podcasts.

759
00:43:52,725 --> 00:43:55,385
Speaker 4:  You know the thing, the policy thing that we're not about, we don't have

760
00:43:55,385 --> 00:43:58,185
Speaker 4:  time to talk about is soon and net neutrality will become the law of land

761
00:43:58,185 --> 00:44:00,305
Speaker 4:  again. And everyone's gonna talk about how net neutrality didn't mean anything,

762
00:44:00,305 --> 00:44:04,225
Speaker 4:  blah blah. And I'm just gonna be like, justice League happened to you

763
00:44:04,225 --> 00:44:07,785
Speaker 4:  because you repealed net neutrality. That's a real, that was a real

764
00:44:07,785 --> 00:44:11,585
Speaker 4:  outcome of repealing net neutrality. You don't believe me, but it's a

765
00:44:11,585 --> 00:44:15,065
Speaker 4:  hundred percent true. Alright, I, I wanna talk about the thing that I, I've

766
00:44:15,065 --> 00:44:18,965
Speaker 4:  been most excited to talk about all week. I, David, you

767
00:44:18,965 --> 00:44:22,605
Speaker 4:  went to a party at the TWA Hotel at JFK in New York, which is

768
00:44:22,605 --> 00:44:26,065
Speaker 4:  a wild place to have a gadget launch. You

769
00:44:26,065 --> 00:44:30,005
Speaker 4:  saw Rabbit happen, there was a demo on stage, which we

770
00:44:30,005 --> 00:44:32,925
Speaker 4:  should talk about 'cause I have a lot of feelings about that demo. And now

771
00:44:32,925 --> 00:44:35,145
Speaker 4:  you are holding a Rabbit R one. You have a review

772
00:44:35,145 --> 00:44:38,045
Speaker 5:  Can show it. I have it right here. It's just so orange. It's mine. I bought

773
00:44:38,045 --> 00:44:39,825
Speaker 5:  this with my own money. Yeah.

774
00:44:39,825 --> 00:44:40,945
Speaker 4:  Oh that's yours. It's our

775
00:44:40,945 --> 00:44:44,805
Speaker 5:  Own unit. It's not, they didn't do review units, huh? This was, so what I

776
00:44:44,805 --> 00:44:48,685
Speaker 5:  went to was the, the pickup party for

777
00:44:48,685 --> 00:44:52,505
Speaker 5:  the first, I think it was 300 R ones that came out.

778
00:44:52,505 --> 00:44:56,205
Speaker 5:  So they, they invited a bunch of media but we had to buy our own in order

779
00:44:56,205 --> 00:44:59,765
Speaker 5:  to get into the event, which is fine. That's very good. I should say to people

780
00:44:59,765 --> 00:45:02,405
Speaker 5:  like for 200 bucks, don't know how this process normally works. Often for

781
00:45:02,405 --> 00:45:04,365
Speaker 5:  reviews. People will ship us something and we'll test it and review it and

782
00:45:04,365 --> 00:45:07,565
Speaker 5:  then we ship it back. That's usually how it works. Because if I had to buy

783
00:45:07,565 --> 00:45:11,505
Speaker 5:  every single thing that I wrote about, I would be homeless.

784
00:45:11,505 --> 00:45:13,685
Speaker 5:  So that's usually how it works. But in this case, we had to buy the thing.

785
00:45:13,685 --> 00:45:17,565
Speaker 5:  So now I, I own this thing. Luckily it was only $200, but so we get to the

786
00:45:17,565 --> 00:45:21,405
Speaker 5:  TWA hotel, which is amazing. I had never been, it's like it's

787
00:45:21,405 --> 00:45:25,325
Speaker 5:  an a very old terminal at JFK that has since been

788
00:45:25,325 --> 00:45:28,375
Speaker 5:  converted into this very swanky kind of old fashioned

789
00:45:28,375 --> 00:45:32,325
Speaker 5:  hotel. It's awesome. Highly recommend. I had never been there before. I will

790
00:45:32,325 --> 00:45:33,985
Speaker 5:  probably never go again, but it was super cool.

791
00:45:33,985 --> 00:45:37,525
Speaker 6:  You should only go if you're having to fly in or out of

792
00:45:37,525 --> 00:45:38,355
Speaker 6:  JFK.

793
00:45:38,355 --> 00:45:41,725
Speaker 5:  Yeah. Oh God. It took me two trains in an Uber to get there. Like I don't

794
00:45:41,725 --> 00:45:45,685
Speaker 5:  recommend this plan otherwise. But yeah, so it

795
00:45:45,685 --> 00:45:49,525
Speaker 5:  was, it was me and 300 or so other people along with a bunch of

796
00:45:49,525 --> 00:45:53,365
Speaker 5:  rapid employees in this space. They had done lots of, you know,

797
00:45:53,365 --> 00:45:57,325
Speaker 5:  work to overhaul it. It had a big stage in the middle. They had a 360 photo

798
00:45:57,325 --> 00:46:01,005
Speaker 5:  booth and a speakeasy upstairs. There was a bar with signature drinks. They

799
00:46:01,005 --> 00:46:04,705
Speaker 5:  were doing all kinds of merchy stuff. It was very much like

800
00:46:04,705 --> 00:46:08,285
Speaker 5:  an old school tech party. Like I haven't been to one of those since before

801
00:46:08,285 --> 00:46:12,125
Speaker 5:  the pandemic where it's just like a company with too much money that's just

802
00:46:12,125 --> 00:46:15,725
Speaker 5:  like, what if we just blew a bunch of it on this large event

803
00:46:15,725 --> 00:46:19,645
Speaker 5:  space. And then Jesse Lou, the founder and

804
00:46:19,645 --> 00:46:23,245
Speaker 5:  CEO got up and spent like an hour basically just

805
00:46:23,245 --> 00:46:27,045
Speaker 5:  doing demos. And he's been doing this for the last couple of

806
00:46:27,045 --> 00:46:30,785
Speaker 5:  months, kind of with increasing frequency, showing off how this thing works

807
00:46:30,785 --> 00:46:34,605
Speaker 5:  and what it can do and all this stuff. And he just sort of stood on stage

808
00:46:34,605 --> 00:46:37,885
Speaker 5:  and did a bunch of demos that were ostensibly live and I have many questions

809
00:46:37,885 --> 00:46:41,715
Speaker 5:  about all of them. And then

810
00:46:41,715 --> 00:46:45,365
Speaker 5:  gave them out to the, that first group of, you know,

811
00:46:45,365 --> 00:46:49,285
Speaker 5:  300 people. And so it was, everybody there had like literally bought

812
00:46:49,285 --> 00:46:52,485
Speaker 5:  a thing to be there. So the room was very excited. Yeah. And there were a

813
00:46:52,485 --> 00:46:56,165
Speaker 5:  lot of people who had been in the discord for months sort of reading about

814
00:46:56,165 --> 00:47:00,045
Speaker 5:  the humane reviews and figuring out what was going on and trying to get

815
00:47:00,045 --> 00:47:02,945
Speaker 5:  details on what this thing would do and how it would work. And lots of people,

816
00:47:02,945 --> 00:47:06,925
Speaker 5:  it was very funny like being in line for a bar while people are behind me

817
00:47:06,925 --> 00:47:10,605
Speaker 5:  debating how the large language model works. And there was a guy who was

818
00:47:10,605 --> 00:47:14,325
Speaker 5:  like, yeah, every time you ask a question, you're eating into that $199

819
00:47:14,325 --> 00:47:18,245
Speaker 5:  price. And I was just like, these are my people. It was great. I had, I had

820
00:47:18,245 --> 00:47:22,125
Speaker 5:  a delightful time except that it was at 7:00 PM on a Tuesday night. And

821
00:47:22,125 --> 00:47:23,875
Speaker 5:  I'm very old and I can't hang like that anymore.

822
00:47:23,875 --> 00:47:25,845
Speaker 4:  Yeah, yeah. So you've got the thing, now

823
00:47:25,845 --> 00:47:27,985
Speaker 5:  I have the thing, it's right here.

824
00:47:27,985 --> 00:47:30,645
Speaker 4:  You've only had it for days day. I, I don't think this is a review. Yeah.

825
00:47:30,645 --> 00:47:34,285
Speaker 4:  But I was watching the demo that he'd done on stage and two things struck

826
00:47:34,285 --> 00:47:38,105
Speaker 4:  me with that demo one, there was a little disclaimer on the stream

827
00:47:38,105 --> 00:47:41,715
Speaker 4:  and he showed himself turning off the wifi. The entire demo was done over

828
00:47:41,715 --> 00:47:45,645
Speaker 4:  4G LTE, not 5G. The one that is famously claimed to

829
00:47:45,645 --> 00:47:49,525
Speaker 4:  have very low latency, a good old 4G LT, which is an

830
00:47:49,525 --> 00:47:52,965
Speaker 4:  interesting choice, but that's 199 bucks. And then he kept pointing out how

831
00:47:52,965 --> 00:47:56,825
Speaker 4:  fast everything was. At one point he took a picture and

832
00:47:56,825 --> 00:48:00,185
Speaker 4:  you know, the thing did the thing where the AI told you it was in the picture.

833
00:48:00,185 --> 00:48:04,045
Speaker 4:  And I was like, I don't, I don't think that uploaded over 4G

834
00:48:04,045 --> 00:48:07,885
Speaker 4:  LT that fast. Like literally just the basics of it didn't seem like it

835
00:48:07,885 --> 00:48:08,905
Speaker 4:  was making sense.

836
00:48:08,905 --> 00:48:12,805
Speaker 5:  So two things on that one, none of it was

837
00:48:12,805 --> 00:48:16,385
Speaker 5:  fast. Like go back and watch it again. He did a very good

838
00:48:16,385 --> 00:48:20,205
Speaker 5:  job of sort of talking through his demos so that while it was waiting

839
00:48:20,205 --> 00:48:23,165
Speaker 5:  for stuff to happen, it would work. And there were, there were a few times

840
00:48:23,165 --> 00:48:25,645
Speaker 5:  where he would do something and it would pretty instantly do it. But what

841
00:48:25,645 --> 00:48:29,365
Speaker 5:  it does very well is it, it it signposts as it's doing

842
00:48:29,365 --> 00:48:32,005
Speaker 5:  stuff. So like you'll ask it a question and it'll respond and say, let me

843
00:48:32,005 --> 00:48:34,205
Speaker 5:  go get that for you. And then it'll say, I'm gonna get that for you. And

844
00:48:34,205 --> 00:48:37,285
Speaker 5:  then it gets it for you. And what you've, what it doesn't do is just sort

845
00:48:37,285 --> 00:48:39,845
Speaker 5:  of leave you hanging in awkward silence for several seconds, which feels

846
00:48:39,845 --> 00:48:43,765
Speaker 5:  like an eternity, but it does take a while to

847
00:48:43,765 --> 00:48:47,635
Speaker 5:  do a lot of things. And with the photo having now tested

848
00:48:47,635 --> 00:48:51,595
Speaker 5:  this a bunch, what it does when you like hold up the thing and say, you know,

849
00:48:51,595 --> 00:48:55,325
Speaker 5:  look at this and tell me what you see, which is like the, the sort

850
00:48:55,325 --> 00:48:58,405
Speaker 5:  of computer vision thing that a lot of these gadgets do. It's not taking

851
00:48:58,405 --> 00:49:02,285
Speaker 5:  a good picture. It takes an awful picture. And I can show

852
00:49:02,285 --> 00:49:06,275
Speaker 5:  you the awful pictures I've been taking, but it literally, it just uploads

853
00:49:06,275 --> 00:49:10,045
Speaker 5:  just the tiniest little bit of data in order to be able to answer

854
00:49:10,045 --> 00:49:13,865
Speaker 5:  the question, is there a crowd full of people

855
00:49:13,865 --> 00:49:17,485
Speaker 5:  or like a begonia in front of you, right? Like that is the fidelity that

856
00:49:17,485 --> 00:49:20,965
Speaker 5:  it needs and that is all of the fidelity that it gets. So I actually think

857
00:49:20,965 --> 00:49:23,725
Speaker 5:  that particular one seems plausible to me.

858
00:49:23,725 --> 00:49:27,625
Speaker 4:  I guess I, I do need to watch it again. 'cause I was just struck by the speed

859
00:49:27,625 --> 00:49:31,515
Speaker 4:  at which things appeared to be happening over a

860
00:49:31,515 --> 00:49:35,035
Speaker 4:  4G connection, not even a 5G connection over a 4G connection. Yeah. Like,

861
00:49:35,035 --> 00:49:37,915
Speaker 4:  I'm not even putting this on rabbit. I'm just like, I've used LTE connections

862
00:49:37,915 --> 00:49:41,205
Speaker 4:  before. They're not fast.

863
00:49:41,205 --> 00:49:44,435
Speaker 4:  Especially now, right? Whenever all the bandwidth is being prioritized to

864
00:49:44,435 --> 00:49:47,435
Speaker 4:  the 5G connections, all the spectrum is being prioritized over there. That

865
00:49:47,435 --> 00:49:50,195
Speaker 4:  was one. And then there's the other thing that struck me was how much stuff

866
00:49:50,195 --> 00:49:54,035
Speaker 4:  it can't do that we were shown at doing at the, at the first launch of

867
00:49:54,035 --> 00:49:57,985
Speaker 4:  event N Cs, where that stuff is just nowhere close. Like everything.

868
00:49:57,985 --> 00:50:01,955
Speaker 5:  It's weird. And even after being at that launch event where he got up

869
00:50:01,955 --> 00:50:05,915
Speaker 5:  on stage, Jesse and said out loud, I am going to demo all of

870
00:50:05,915 --> 00:50:09,495
Speaker 5:  the things that it can do from day one. And I have been testing those things

871
00:50:09,495 --> 00:50:13,475
Speaker 5:  and it can't do some of them. So the, one of

872
00:50:13,475 --> 00:50:15,955
Speaker 5:  the big things that Rabbit has been talking about is this thing called the

873
00:50:15,955 --> 00:50:19,175
Speaker 5:  large action model, right? And the idea is that it can actually like learn

874
00:50:19,175 --> 00:50:23,075
Speaker 5:  how to use apps on your behalf. That's like, that's its whole pitch. Not,

875
00:50:23,075 --> 00:50:27,025
Speaker 5:  it's not just like a thing for chat GPT, it's a thing where you can say,

876
00:50:27,025 --> 00:50:30,475
Speaker 5:  go do Spotify for me, right? Or like, go interact with

877
00:50:30,475 --> 00:50:32,635
Speaker 5:  Photoshop. For me, that's literally one of the things they've talked about.

878
00:50:32,635 --> 00:50:35,985
Speaker 5:  Like it, you can teach it how to use Photoshop for you. That

879
00:50:35,985 --> 00:50:39,805
Speaker 5:  is not coming soon. It's not. It's, it's like a thing

880
00:50:39,805 --> 00:50:42,885
Speaker 5:  that somebody had the idea to do. It's like when we talk about car renders,

881
00:50:42,885 --> 00:50:46,715
Speaker 5:  right? It's like it's at the render stage as far as I can tell. And then

882
00:50:46,715 --> 00:50:50,505
Speaker 5:  there's a bunch of stuff that seems very basic. Like I gave

883
00:50:50,505 --> 00:50:54,275
Speaker 5:  humane a lot of crap for not supporting things

884
00:50:54,275 --> 00:50:58,125
Speaker 5:  like alarms and reminders and these very basic things. And you know what

885
00:50:58,125 --> 00:51:01,445
Speaker 5:  the Rabbit R one doesn't support is alarms and

886
00:51:01,445 --> 00:51:05,085
Speaker 5:  reminders. And I, I ironically like

887
00:51:05,085 --> 00:51:08,425
Speaker 5:  humane, like the deja vu of all of this is bananas for me. Like, like

888
00:51:08,425 --> 00:51:12,365
Speaker 5:  Humane Jesse stood on stage and put up a big slide with here's

889
00:51:12,365 --> 00:51:16,245
Speaker 5:  all the cool stuff we're shipping in summer of 2024. And it's things

890
00:51:16,245 --> 00:51:19,225
Speaker 5:  like alarm, calendar, contacts, GPS, memory

891
00:51:19,225 --> 00:51:23,115
Speaker 5:  recall, travel planning, Yelp,

892
00:51:23,115 --> 00:51:27,005
Speaker 5:  like basic things. These are, these are, these are things that you should

893
00:51:27,005 --> 00:51:30,885
Speaker 5:  have from the beginning and there's just not really

894
00:51:30,885 --> 00:51:34,805
Speaker 5:  a good reason not to have it. So right now, again, I've been testing this

895
00:51:34,805 --> 00:51:38,685
Speaker 5:  thing for a grand total of like 16 hours, some of which I

896
00:51:38,685 --> 00:51:42,565
Speaker 5:  was asleep, right? Like I, none of this is final yet, but like a lot

897
00:51:42,565 --> 00:51:45,505
Speaker 5:  of things about this device do not work very well. Yeah.

898
00:51:45,505 --> 00:51:49,315
Speaker 6:  And it only has four apps, right? Yeah.

899
00:51:49,315 --> 00:51:52,965
Speaker 5:  Yeah. So I, I will say the, the biggest, most

900
00:51:52,965 --> 00:51:56,735
Speaker 5:  complicated question about the rabbit is how this large action model

901
00:51:56,735 --> 00:52:00,725
Speaker 5:  works and thus what you're giving it access to. So when you log into the

902
00:52:00,725 --> 00:52:03,965
Speaker 5:  website, which is called Rabbit Hole, which I enjoy very much, the branding

903
00:52:03,965 --> 00:52:07,725
Speaker 5:  on this thing is on point. They've done a very good job when you're playing

904
00:52:07,725 --> 00:52:10,765
Speaker 5:  music, there's a little rabbit guy with headphones on, like it's

905
00:52:10,765 --> 00:52:14,685
Speaker 5:  great, excellent branding exercise, well done. But you log

906
00:52:14,685 --> 00:52:18,565
Speaker 5:  into Rabbit Hole and you go to, there's a tab called Connections and

907
00:52:18,565 --> 00:52:21,485
Speaker 5:  it like lists all the apps you can connect to. And right now it's, it's four,

908
00:52:21,485 --> 00:52:23,845
Speaker 5:  like you said, it's Spotify, DoorDash, Uber, and

909
00:52:23,845 --> 00:52:27,325
Speaker 5:  Midjourney, which is a strange four, but

910
00:52:27,325 --> 00:52:31,015
Speaker 5:  whatever. And then so you, you

911
00:52:31,015 --> 00:52:34,675
Speaker 5:  click on the connect button and what it does is open up a virtual

912
00:52:34,675 --> 00:52:38,605
Speaker 5:  machine on Rabbit servers through

913
00:52:38,605 --> 00:52:42,365
Speaker 5:  which you just log into the Spotify web interface or the

914
00:52:42,365 --> 00:52:45,625
Speaker 5:  DoorDash web interface. So like I click on the DoorDash button and literally

915
00:52:45,625 --> 00:52:49,485
Speaker 5:  it opens the DoorDash website, just the homepage of

916
00:52:49,485 --> 00:52:53,335
Speaker 5:  doordash.com on the thing. And then I had to go click sign in, I had to

917
00:52:53,335 --> 00:52:57,205
Speaker 5:  enter in my credentials and then I clicked continue like I'm signing into

918
00:52:57,205 --> 00:53:00,485
Speaker 5:  DoorDash normally. And then it closes that window because now it has stored

919
00:53:00,485 --> 00:53:04,185
Speaker 5:  my credentials. And what Rabbit says is it doesn't store your credentials,

920
00:53:04,185 --> 00:53:07,945
Speaker 5:  it just stores like an authentication token so that you stay logged in.

921
00:53:07,945 --> 00:53:11,345
Speaker 5:  And to that, I say like, have you ever tried to stay logged in to a service

922
00:53:11,345 --> 00:53:14,485
Speaker 5:  on the internet? Like it's not possible. You can't, the keep me logged in

923
00:53:14,485 --> 00:53:18,265
Speaker 5:  button doesn't work. So there is something else going on here.

924
00:53:18,265 --> 00:53:20,685
Speaker 5:  And there are a lot of people who are like, oh, what you're doing is you're

925
00:53:20,685 --> 00:53:24,045
Speaker 5:  just exposing all of your login credentials to a virtual machine that's just

926
00:53:24,045 --> 00:53:26,200
Speaker 5:  sitting on rabbit's, computer, computer. Like you're just uploading your

927
00:53:26,200 --> 00:53:28,715
Speaker 5:  life to rabbit servers. That's stupid. Well,

928
00:53:28,715 --> 00:53:31,955
Speaker 4:  There's also one step beyond that, which is you have now logged

929
00:53:31,955 --> 00:53:35,815
Speaker 4:  into DoorDash on Rabbit servers and it's logged in,

930
00:53:35,815 --> 00:53:38,445
Speaker 4:  right? So it doesn't matter if you have the credential or not you, well,

931
00:53:38,445 --> 00:53:41,465
Speaker 4:  right. You have perfect logged in access to DoorDash.

932
00:53:41,465 --> 00:53:44,755
Speaker 5:  Yes. And I think for me, I

933
00:53:44,755 --> 00:53:48,145
Speaker 5:  like, I'm logging into all of these things because I have to test this thing,

934
00:53:48,145 --> 00:53:52,085
Speaker 5:  but like even logging into Spotify felt strange. Like

935
00:53:52,085 --> 00:53:55,735
Speaker 5:  this is like, this is actually kind of a lot of access to information

936
00:53:55,735 --> 00:53:58,985
Speaker 5:  about me that you just have now. And that's

937
00:53:58,985 --> 00:54:02,565
Speaker 5:  odd. But anyway, the interface for that sucks. The

938
00:54:02,565 --> 00:54:06,085
Speaker 5:  system isn't very good. I have not yet successfully used DoorDash. Every

939
00:54:06,085 --> 00:54:09,085
Speaker 5:  single time I try to do it, I like, I, you know, you press the button on

940
00:54:09,085 --> 00:54:12,225
Speaker 5:  the side and you say, order me some food. And every single time it says DoorDash

941
00:54:12,225 --> 00:54:15,845
Speaker 5:  may take a while to load on Rabbit os, which is very funny. And then it just

942
00:54:15,845 --> 00:54:17,485
Speaker 5:  immediately fails every single time. Yeah.

943
00:54:17,485 --> 00:54:21,235
Speaker 4:  So what's happening in the background there, from what I gather,

944
00:54:21,235 --> 00:54:25,155
Speaker 4:  what the heart of the large action model is,

945
00:54:25,155 --> 00:54:27,845
Speaker 4:  it's gonna click around on the DoorDash website for

946
00:54:27,845 --> 00:54:29,245
Speaker 4:  you.

947
00:54:29,245 --> 00:54:33,205
Speaker 5:  I believe that's correct. Yeah. I think the, the long term plan here is to

948
00:54:33,205 --> 00:54:36,485
Speaker 5:  have more, let's say, robust

949
00:54:36,485 --> 00:54:39,805
Speaker 5:  integrations that they can actually, like, there's way to you do that with

950
00:54:39,805 --> 00:54:42,725
Speaker 5:  like structured data that you can get to some of that stuff. But, but

951
00:54:42,725 --> 00:54:45,805
Speaker 4:  That's the old way, right? Like DoorDash has an API and we've built a weird

952
00:54:45,805 --> 00:54:49,725
Speaker 4:  interface for DoorDash in our little orange square. You could, you

953
00:54:49,725 --> 00:54:51,065
Speaker 4:  don't need a bunch of AI for that.

954
00:54:51,065 --> 00:54:54,425
Speaker 5:  No, you don't. But it works. And right.

955
00:54:54,425 --> 00:54:58,245
Speaker 4:  So, but this is like you're logged into DoorDash and we're gonna show you

956
00:54:58,245 --> 00:55:02,205
Speaker 4:  pictures of the, we're gonna understand the DoorDash interface for you, and

957
00:55:02,205 --> 00:55:05,805
Speaker 4:  then we're going to let, you're gonna say, buy me this food and we're just

958
00:55:05,805 --> 00:55:09,085
Speaker 4:  gonna use the DoorDash website on your behalf. Like that's the, that that

959
00:55:09,085 --> 00:55:11,635
Speaker 4:  is my understanding of what the large action model should do.

960
00:55:11,635 --> 00:55:14,845
Speaker 5:  Yeah, no, that, that's, that's exactly right. And part of the process that

961
00:55:14,845 --> 00:55:18,685
Speaker 5:  they make, that they're in theory one day someday when this launch is gonna

962
00:55:18,685 --> 00:55:22,525
Speaker 5:  make you go through is training the apps that you use. Like this

963
00:55:22,525 --> 00:55:26,485
Speaker 5:  is where you click to do X and this is where you click to do Y and you

964
00:55:26,485 --> 00:55:30,325
Speaker 5:  scroll down to get to the other thing. And that is, that is how you teach

965
00:55:30,325 --> 00:55:32,685
Speaker 5:  these models how to do this stuff. And the reason they've worked with these

966
00:55:32,685 --> 00:55:36,515
Speaker 5:  four apps now is because their people have done that training

967
00:55:36,515 --> 00:55:38,085
Speaker 5:  with these four apps. So like literally

968
00:55:38,085 --> 00:55:41,155
Speaker 4:  Do there have deals with the four apps, have deals with Spotify and, and

969
00:55:41,155 --> 00:55:44,035
Speaker 4:  Uber and DoorDash, you know, Uber and DoorDash are competitors. Like Uber

970
00:55:44,035 --> 00:55:45,245
Speaker 4:  Eats exists. Yeah.

971
00:55:45,245 --> 00:55:48,445
Speaker 5:  I, I don't agree about this. Don't, I don't know, but I sure doubt it. I

972
00:55:48,445 --> 00:55:48,685
Speaker 5:  have

973
00:55:48,685 --> 00:55:52,405
Speaker 6:  A more basic question. Okay. I, I know you've only spent what,

974
00:55:52,405 --> 00:55:56,155
Speaker 6:  16 hours with it, but in that time,

975
00:55:56,155 --> 00:56:00,045
Speaker 6:  have you had an experience with it where you're like, oh wow,

976
00:56:00,045 --> 00:56:03,625
Speaker 6:  I would willingly train this model when I get more

977
00:56:03,625 --> 00:56:06,585
Speaker 6:  access to it to have these kind of experience with another

978
00:56:06,585 --> 00:56:08,185
Speaker 6:  app?

979
00:56:08,185 --> 00:56:11,285
Speaker 5:  The Spotify integration is the one to me that I'm like, this is the thing

980
00:56:11,285 --> 00:56:15,035
Speaker 5:  I really want to work. Does it? No,

981
00:56:15,035 --> 00:56:19,005
Speaker 5:  it's awful. Oh, okay. It is so, so bad you guys. I can't, I

982
00:56:19,005 --> 00:56:21,405
Speaker 5:  can't even tell you how bad it is. Like let me, I'll just give you a bunch

983
00:56:21,405 --> 00:56:25,245
Speaker 5:  of examples. I say to the thing, play my Discover Weekly

984
00:56:25,245 --> 00:56:29,065
Speaker 5:  playlist and it plays every single time a song called Can You Discover

985
00:56:29,065 --> 00:56:32,715
Speaker 5:  by a Band's Discovery? That's good. I say

986
00:56:32,715 --> 00:56:36,485
Speaker 5:  Play Beyonce's new album and it played like a, a lullaby

987
00:56:36,485 --> 00:56:40,365
Speaker 5:  version of Crazy In Love. Yeah. And it's weird because it's not even

988
00:56:40,365 --> 00:56:42,805
Speaker 5:  like, it's just searching and playing the first result. Because if you go

989
00:56:42,805 --> 00:56:46,765
Speaker 5:  to Spotify and Search Discover Weekly, it shows you

990
00:56:46,765 --> 00:56:50,165
Speaker 5:  your Discovery Weekly playlist. So in theory, that shouldn't be that hard

991
00:56:50,165 --> 00:56:53,785
Speaker 5:  a problem. It's doing some weird thing that I can't figure out

992
00:56:53,785 --> 00:56:57,445
Speaker 5:  yet and almost always does it wrong. So if I ask like a very basic

993
00:56:57,445 --> 00:57:01,045
Speaker 5:  question like play Justin

994
00:57:01,045 --> 00:57:05,005
Speaker 5:  Timberlake that works. It'll play a Justin Timberlake song. And I have

995
00:57:05,005 --> 00:57:08,285
Speaker 5:  done that many, many times. But anything more

996
00:57:08,285 --> 00:57:12,185
Speaker 5:  complicated, at least so far, it has fallen apart on me every single time.

997
00:57:12,185 --> 00:57:16,005
Speaker 4:  See, this is why I don't understand about how it's working. If you're

998
00:57:16,005 --> 00:57:19,525
Speaker 4:  saying you can go to Spotify's website and type in Crazy in

999
00:57:19,525 --> 00:57:22,675
Speaker 4:  Love and it shows you the first result is correct,

1000
00:57:22,675 --> 00:57:26,335
Speaker 4:  theoretically that is all the large action model is doing on the backend,

1001
00:57:26,335 --> 00:57:29,075
Speaker 4:  right? It's looking at the web interface, it's identifying the search box,

1002
00:57:29,075 --> 00:57:32,165
Speaker 4:  it's entering the string. It's saying here's the first result and it's double

1003
00:57:32,165 --> 00:57:36,095
Speaker 4:  clicking on it. by the way, this is not some radically new idea,

1004
00:57:36,095 --> 00:57:39,135
Speaker 4:  right? Like big businesses deploy robotic process

1005
00:57:39,135 --> 00:57:43,018
Speaker 4:  automation to run their billing systems on Windows. $98 billion

1006
00:57:43,445 --> 00:57:44,765
Speaker 4:  companies exist to deploy this at the

1007
00:57:44,765 --> 00:57:47,325
Speaker 5:  Enterprise scale. And Rabbit has more or less acknowledged that that is what

1008
00:57:47,325 --> 00:57:49,325
Speaker 5:  it's doing. by the way, there was this weird thing, I don't know if you saw

1009
00:57:49,325 --> 00:57:52,995
Speaker 5:  that there somebody, it was called like Rabbit

1010
00:57:52,995 --> 00:57:56,795
Speaker 5:  scam on GitHub. GitHub sort of said they had found a bunch of

1011
00:57:56,795 --> 00:58:00,725
Speaker 5:  code showing that All Rabbit was doing was

1012
00:58:00,725 --> 00:58:04,605
Speaker 5:  just lifting Yeah. Stuff off of webpages and running the same systems

1013
00:58:04,605 --> 00:58:08,085
Speaker 5:  that everybody else runs in order to like understand what's going on on a

1014
00:58:08,085 --> 00:58:12,045
Speaker 5:  website. And they were like, this isn't as scary

1015
00:58:12,045 --> 00:58:14,595
Speaker 5:  as you think it is. Like yeah, that's, that's what we do. That's our public

1016
00:58:14,595 --> 00:58:17,905
Speaker 5:  code. So like they're acknowledging that this is what is going on and I think,

1017
00:58:17,905 --> 00:58:21,635
Speaker 4:  But it's not working like, yeah, no, if you were, again, if you're like some

1018
00:58:21,635 --> 00:58:25,285
Speaker 4:  midsize hospital system and you hire UiPath to show up and do

1019
00:58:25,285 --> 00:58:29,245
Speaker 4:  RPA and it's like we're doing the lullaby versions, you're like fire the

1020
00:58:29,245 --> 00:58:32,805
Speaker 4:  mid, it's like get rid of 'em, right? UiPath is a billion dollar company.

1021
00:58:32,805 --> 00:58:36,585
Speaker 4:  'cause it can do robotic process automation reliably at scale. Like

1022
00:58:36,585 --> 00:58:37,325
Speaker 4:  why Rabbit

1023
00:58:37,325 --> 00:58:38,645
Speaker 6:  Costs $200, well

1024
00:58:38,645 --> 00:58:42,205
Speaker 4:  It costs $200. But even the thing, like the basic thing, we entered a string

1025
00:58:42,205 --> 00:58:45,945
Speaker 4:  of text into a search box and we played the first result. Like

1026
00:58:45,945 --> 00:58:49,805
Speaker 4:  the industry, the robotic process automation industry knows

1027
00:58:49,805 --> 00:58:53,685
Speaker 4:  how to do that. So why can't it do that? Like it feels like it's doing

1028
00:58:53,685 --> 00:58:54,445
Speaker 4:  something else. Is

1029
00:58:54,445 --> 00:58:58,325
Speaker 6:  It like inserting a little clippy in there? It's like, is it

1030
00:58:58,325 --> 00:59:00,305
Speaker 6:  trying to like be smart for you?

1031
00:59:00,305 --> 00:59:03,725
Speaker 5:  It might be, it's also possible that it's doing something different with

1032
00:59:03,725 --> 00:59:07,485
Speaker 5:  Spotify because Spotify Yeah, like has an actual sort of

1033
00:59:07,485 --> 00:59:10,745
Speaker 5:  corpus of data that it lets other systems access.

1034
00:59:10,745 --> 00:59:14,165
Speaker 5:  So I can't speak to Spotify in particular, but at least from the demos that

1035
00:59:14,165 --> 00:59:17,085
Speaker 5:  I've seen, again, I haven't been able to get DoorDash to work once. But from

1036
00:59:17,085 --> 00:59:20,805
Speaker 5:  Jesse's demo of DoorDash, that seemed very clearly to

1037
00:59:20,805 --> 00:59:24,165
Speaker 5:  be the thing using the website because the way that he showed what was

1038
00:59:24,165 --> 00:59:27,865
Speaker 5:  working was he kept refreshing doordash.com on his

1039
00:59:27,865 --> 00:59:31,785
Speaker 5:  laptop and it would show that something had been added to the cart

1040
00:59:31,785 --> 00:59:35,675
Speaker 5:  on the website. That's not like a thing that happens if you use

1041
00:59:35,675 --> 00:59:38,885
Speaker 5:  like a third party API to do all of this stuff. That is just a thing using

1042
00:59:38,885 --> 00:59:40,305
Speaker 5:  the web app for you.

1043
00:59:40,305 --> 00:59:43,605
Speaker 4:  So I, this is the part that I'm just like most interested in because DoorDash

1044
00:59:43,605 --> 00:59:46,805
Speaker 4:  is the slowest one and they said it's the slowest one. And there comes a

1045
00:59:46,805 --> 00:59:50,765
Speaker 4:  point at which all this like just horsepower through the interface with

1046
00:59:50,765 --> 00:59:54,625
Speaker 4:  computer vision, it just hits the wall of like, what if you

1047
00:59:54,625 --> 00:59:58,505
Speaker 4:  just had an API? Right? What if you could just, instead of trying to

1048
00:59:58,505 --> 01:00:02,305
Speaker 4:  have a robot figure out what's happening on an interface made for

1049
01:00:02,305 --> 01:00:05,925
Speaker 4:  humans, what if you just let the robot talk to the application directly using

1050
01:00:05,925 --> 01:00:09,785
Speaker 4:  actual API commands the example that I'll give people, one of

1051
01:00:09,785 --> 01:00:13,625
Speaker 4:  my favorite companies that I I wished had succeeded was Cavo, the universal

1052
01:00:13,625 --> 01:00:17,225
Speaker 4:  remote company that I hyped up on the show over and over again. They were

1053
01:00:17,225 --> 01:00:20,135
Speaker 4:  doing exactly this to build a universal remote. You plugged all of your devices

1054
01:00:20,135 --> 01:00:23,705
Speaker 4:  into the cavo and the CAVO is doing computer vision to watch your Apple TV

1055
01:00:23,705 --> 01:00:26,585
Speaker 4:  interface or whatever and click around on your behalf. So you could just

1056
01:00:26,585 --> 01:00:29,305
Speaker 4:  say the name of a show and the name of a service and it would just like bang

1057
01:00:29,305 --> 01:00:33,065
Speaker 4:  around your TV and use it for you. And this shit was awesome when it

1058
01:00:33,065 --> 01:00:36,745
Speaker 4:  worked. It was very slow and it was extraordinarily

1059
01:00:36,745 --> 01:00:38,465
Speaker 4:  brittle when it broke.

1060
01:00:38,465 --> 01:00:42,255
Speaker 6:  Yeah. It never worked. Like the win is very generous.

1061
01:00:42,255 --> 01:00:45,245
Speaker 4:  Yeah. It, it sometimes it worked, you know,

1062
01:00:45,245 --> 01:00:48,185
Speaker 6:  And it was cool. It was very cool in those moments it worked, but most of

1063
01:00:48,185 --> 01:00:49,155
Speaker 6:  the time it didn't.

1064
01:00:49,155 --> 01:00:52,025
Speaker 4:  Right. And then the thing that like really got you was it wouldn't even show

1065
01:00:52,025 --> 01:00:55,465
Speaker 4:  you the clicking around. Like it would put up the Cavo screen and you would

1066
01:00:55,465 --> 01:00:57,785
Speaker 4:  hear it like booping in the background. You'd be like, can I just see if

1067
01:00:57,785 --> 01:01:00,265
Speaker 4:  you're getting this right? I would love to check your work. And then you'd

1068
01:01:00,265 --> 01:01:03,045
Speaker 4:  be like, that is not what I wanted to happen at all. Or it would just error

1069
01:01:03,045 --> 01:01:06,265
Speaker 4:  out. But the idea that like you've got a bunch of devices plugged into a

1070
01:01:06,265 --> 01:01:10,045
Speaker 4:  central HDMI switcher and you're like, watch this show and it knows

1071
01:01:10,045 --> 01:01:12,865
Speaker 4:  that's the Apple tv and you're like, I wanna play PlayStation. And it switches

1072
01:01:12,865 --> 01:01:16,555
Speaker 4:  the input and bangs around play. Like all of that was awesome, but

1073
01:01:16,555 --> 01:01:20,465
Speaker 4:  it, it failed because fundamentally the approach is brittle,

1074
01:01:20,465 --> 01:01:23,855
Speaker 4:  right? It just, it there, there, there are known ways for it to break when

1075
01:01:23,855 --> 01:01:26,735
Speaker 4:  the computer cannot understand what's seeing it's

1076
01:01:26,735 --> 01:01:30,615
Speaker 4:  $199. Like yeah, can they overcome this problem or do they actually

1077
01:01:30,615 --> 01:01:33,135
Speaker 4:  just need to build a bunch of APIs? And then you've got something that looks

1078
01:01:33,135 --> 01:01:35,935
Speaker 4:  like a, I think you have in your piece that's just a mid-range. Android,

1079
01:01:35,935 --> 01:01:37,685
Speaker 4:  Android smartphone with weird apps.

1080
01:01:37,685 --> 01:01:41,455
Speaker 5:  Yeah. The answer is ultimately both. Right. And I think, I

1081
01:01:41,455 --> 01:01:45,135
Speaker 5:  think Humane has said this about what it's working on. Rabbit has alluded

1082
01:01:45,135 --> 01:01:48,955
Speaker 5:  to this too. Like they eventually want to build

1083
01:01:48,955 --> 01:01:52,595
Speaker 5:  big enough systems that others will actually integrate with. 'cause the reason

1084
01:01:52,595 --> 01:01:56,295
Speaker 5:  to not rely on APIs is that you're a tiny startup and nobody cares about

1085
01:01:56,295 --> 01:01:59,415
Speaker 5:  you and nobody will make the deals with you. Yeah. So you do hacky computer

1086
01:01:59,415 --> 01:02:03,235
Speaker 5:  vision stuff so that you don't have to get the deals because

1087
01:02:03,235 --> 01:02:07,135
Speaker 5:  by and large, they can't really stop you from doing that. They can, they

1088
01:02:07,135 --> 01:02:10,335
Speaker 5:  can get mad and they have some ways, but like that's, it's a more winnable

1089
01:02:10,335 --> 01:02:13,855
Speaker 5:  game in that particular respect. But the way for them to do this, they all

1090
01:02:13,855 --> 01:02:17,815
Speaker 5:  acknowledge, is to eventually have those more

1091
01:02:17,815 --> 01:02:20,785
Speaker 5:  official partnerships that just give, give them access to the DoorDash API

1092
01:02:20,785 --> 01:02:24,765
Speaker 5:  and then like, this doesn't all have to be ai, right? Like

1093
01:02:24,765 --> 01:02:27,785
Speaker 5:  I, I actually think we, we like run into a trap when we assume that the only

1094
01:02:27,785 --> 01:02:31,605
Speaker 5:  way to do AI things is for all of it to be ai. Like some of it shouldn't

1095
01:02:31,605 --> 01:02:35,125
Speaker 5:  be, we've solved a lot of problems actually. Like we're, we're pretty good

1096
01:02:35,125 --> 01:02:38,965
Speaker 5:  at a lot of things that don't require pinging a large language models to

1097
01:02:38,965 --> 01:02:42,085
Speaker 5:  order McDonald's. Like that's like ordering McDonald's on the internet is

1098
01:02:42,085 --> 01:02:45,845
Speaker 5:  like a solved problem. We're very good at it now. And so I think we will

1099
01:02:45,845 --> 01:02:48,845
Speaker 5:  land there with a lot of stuff. But one nice thing you can do with these

1100
01:02:48,845 --> 01:02:52,765
Speaker 5:  models is you can hack together a kind of n

1101
01:02:52,765 --> 01:02:56,725
Speaker 5:  solution to a lot of those business deals without needing those business

1102
01:02:56,725 --> 01:02:59,865
Speaker 5:  deals. And I think that's what all of these companies are doing. At first,

1103
01:02:59,865 --> 01:03:02,485
Speaker 4:  The question is what DoorDash is gonna say, this is a legal scraping of our

1104
01:03:02,485 --> 01:03:05,235
Speaker 4:  website. Like there's another whole set of problems that you kind of walk,

1105
01:03:05,235 --> 01:03:05,525
Speaker 4:  walk

1106
01:03:05,525 --> 01:03:07,845
Speaker 5:  Into immediately. I mean the good news for DoorDash is DoorDash just wants

1107
01:03:07,845 --> 01:03:11,085
Speaker 5:  you to order McDonald's. Right? Like, I I, and, and I think that's the, the

1108
01:03:11,085 --> 01:03:14,565
Speaker 5:  assumption that they're making, right? Like Uber wants me and an Uber and

1109
01:03:14,565 --> 01:03:18,045
Speaker 5:  is very happy anything that happens that gets me in an Uber, same with DoorDash

1110
01:03:18,045 --> 01:03:19,165
Speaker 5:  and me or McDonald's.

1111
01:03:19,165 --> 01:03:22,965
Speaker 4:  Does Spotify wanna stream copyrighted music to an

1112
01:03:22,965 --> 01:03:24,155
Speaker 4:  orange rectangle?

1113
01:03:24,155 --> 01:03:26,755
Speaker 5:  Yeah, I, yeah it did. I don't know.

1114
01:03:26,755 --> 01:03:28,805
Speaker 4:  They did. But how are buttons list of things that are coming? It's Apple

1115
01:03:28,805 --> 01:03:32,045
Speaker 4:  music and it's like, is it, Is that one

1116
01:03:32,045 --> 01:03:35,965
Speaker 4:  coming? Have you met them? Like Yeah, they

1117
01:03:35,965 --> 01:03:38,805
Speaker 4:  don't like competitors. They're not, you know, even Apple Music, which is

1118
01:03:38,805 --> 01:03:42,725
Speaker 4:  theoretically the, you know, horizontal play across. Like have you tried

1119
01:03:42,725 --> 01:03:46,405
Speaker 4:  Apple Music on Android? You think your weird little robot is

1120
01:03:46,405 --> 01:03:50,285
Speaker 4:  gonna have to use Apple Music Web that way? I don't know. We'll see, I'm

1121
01:03:50,285 --> 01:03:54,085
Speaker 4:  very excited for you to review this thing. I think that that central question

1122
01:03:54,085 --> 01:03:57,865
Speaker 4:  of like at $199 with no recurring fee,

1123
01:03:57,865 --> 01:04:01,805
Speaker 4:  can you make this a business that needs to improve on

1124
01:04:01,805 --> 01:04:05,285
Speaker 4:  a, some of the core AI features that is reliant on, look at it this way.

1125
01:04:05,285 --> 01:04:08,245
Speaker 4:  The thing you're saying, the bunch of these are solved problems,

1126
01:04:08,245 --> 01:04:12,185
Speaker 4:  right? Okay, that's great. The, the things that are sort of easiest

1127
01:04:12,185 --> 01:04:15,695
Speaker 4:  to do or solve problems, order some food, call a ride plate

1128
01:04:15,695 --> 01:04:19,445
Speaker 4:  songs, all API stuff that means you're relying on the AI to

1129
01:04:19,445 --> 01:04:23,035
Speaker 4:  solve all of the edge cases. Go to

1130
01:04:23,035 --> 01:04:26,085
Speaker 4:  Photoshop and draw a cropping square around a thing

1131
01:04:26,085 --> 01:04:29,885
Speaker 4:  like that is not a solved problem. You

1132
01:04:29,885 --> 01:04:32,725
Speaker 4:  cannot API your way into doing that in a Photoshop in the general case, you

1133
01:04:32,725 --> 01:04:36,685
Speaker 4:  can do it maybe in some specialized ways. Okay, you're now,

1134
01:04:36,685 --> 01:04:40,585
Speaker 4:  it's $199. No, no recurring revenue. Can you make an

1135
01:04:40,585 --> 01:04:43,685
Speaker 4:  AI that can solve for the general case of using a computer is the question

1136
01:04:43,685 --> 01:04:46,325
Speaker 4:  that this thing is asking. And I just like, dunno the answer.

1137
01:04:46,325 --> 01:04:49,565
Speaker 6:  I feel the answer answer's probably no. But David, I just need you to do

1138
01:04:49,565 --> 01:04:53,525
Speaker 6:  one thing for me. Can you hold it up to the mic and like click one of the

1139
01:04:53,525 --> 01:04:56,015
Speaker 6:  buttons? I just need to know how cliquey they are.

1140
01:04:56,015 --> 01:04:57,355
Speaker 4:  Kranz, like do some ASMR shit.

1141
01:04:57,355 --> 01:04:58,905
Speaker 5:  It's pretty quiet. Yeah.

1142
01:04:58,905 --> 01:04:59,485
Speaker 6:  Oh, it's so

1143
01:04:59,485 --> 01:05:02,165
Speaker 4:  Quiet. That's nothing. Yeah, that's it's clicking right now. Pull over in

1144
01:05:02,165 --> 01:05:06,135
Speaker 4:  your car, turn off the engine, roll up the windows. Click,

1145
01:05:06,135 --> 01:05:07,925
Speaker 5:  Click, click. That's what it sounds like that

1146
01:05:07,925 --> 01:05:10,245
Speaker 4:  Was No, do it without the clicks. They're they're pulled over now. Oh

1147
01:05:10,245 --> 01:05:12,825
Speaker 5:  Yeah.

1148
01:05:12,825 --> 01:05:16,045
Speaker 4:  Ah, that sounds so bad. Yeah, the people in the electric cars are like, what

1149
01:05:16,045 --> 01:05:18,345
Speaker 4:  Engine?

1150
01:05:18,345 --> 01:05:21,665
Speaker 5:  No, but to me the thing is like the, the big open question for me with both

1151
01:05:21,665 --> 01:05:25,645
Speaker 5:  the humane pin and this was like, what is like the one

1152
01:05:25,645 --> 01:05:29,025
Speaker 5:  thing that this is actually for, and I keep hoping it's gonna be music and

1153
01:05:29,025 --> 01:05:32,205
Speaker 5:  Humane almost got there except for all the ways it was

1154
01:05:32,205 --> 01:05:36,105
Speaker 5:  awful. And this, like, I was excited because it's Spotify and Spotify

1155
01:05:36,105 --> 01:05:39,005
Speaker 5:  is what I and hundreds of millions of other people use to listen to

1156
01:05:39,005 --> 01:05:42,755
Speaker 5:  music just not there. But so far

1157
01:05:42,755 --> 01:05:46,365
Speaker 5:  it's a pretty good like, question and answer machine, which I'm happy about.

1158
01:05:46,365 --> 01:05:49,365
Speaker 5:  Rabbit has a big integration with perplexity, the AI search

1159
01:05:49,365 --> 01:05:52,765
Speaker 5:  engine. So for like relatively real

1160
01:05:52,765 --> 01:05:56,565
Speaker 5:  time questions like the, the NFL draft is tomorrow as

1161
01:05:56,565 --> 01:05:59,225
Speaker 5:  we're recording this. And I was asking it a bunch of questions about like

1162
01:05:59,225 --> 01:06:03,005
Speaker 5:  who is likely to go where in the NFL draft and it had good UpToDate

1163
01:06:03,005 --> 01:06:06,845
Speaker 5:  information about the NFL draft. Like that's cool. Cue

1164
01:06:06,845 --> 01:06:09,525
Speaker 5:  all the people saying, why can't I just do it on my smartphone? Like, you

1165
01:06:09,525 --> 01:06:13,365
Speaker 5:  super duper can. But what's weird to me about this so far, and

1166
01:06:13,365 --> 01:06:16,385
Speaker 5:  again I have a lot of testing and stuff left to do, is like this little thing,

1167
01:06:16,385 --> 01:06:20,065
Speaker 5:  the gadget itself feels right for this moment

1168
01:06:20,065 --> 01:06:23,265
Speaker 5:  in ai. Like it's pretty cheap. It's not that ambitious. It's sort of silly

1169
01:06:23,265 --> 01:06:27,205
Speaker 5:  and fun. It's like worst case scenario, it's just

1170
01:06:27,205 --> 01:06:30,875
Speaker 5:  like, will look cool on my desk. Yeah. People pay a lot more for

1171
01:06:30,875 --> 01:06:34,755
Speaker 5:  cool things on their desk, right? But

1172
01:06:34,755 --> 01:06:38,445
Speaker 5:  they're also at the same time talking about this

1173
01:06:38,445 --> 01:06:42,245
Speaker 5:  massive world changing vision for where it will all go. And

1174
01:06:42,245 --> 01:06:45,965
Speaker 5:  Jesse, to his credit, is constantly sort of tamping that down

1175
01:06:45,965 --> 01:06:48,565
Speaker 5:  saying we're just at the, at the very beginning, we haven't solved most of

1176
01:06:48,565 --> 01:06:52,485
Speaker 5:  these problems. He said something at the beginning of his speech last night

1177
01:06:52,485 --> 01:06:56,155
Speaker 5:  that was like, I'm gonna try all these demos and if

1178
01:06:56,155 --> 01:07:00,085
Speaker 5:  they don't work, I'll try 'em again. And if they still don't work, we'll

1179
01:07:00,085 --> 01:07:03,205
Speaker 5:  fix it. And I was like, what a, what a perfect summation of like the time

1180
01:07:03,205 --> 01:07:06,735
Speaker 5:  we're in for ai. And so I think all of that is right and I, I

1181
01:07:06,735 --> 01:07:10,585
Speaker 5:  appreciate kind of the like realism of what Rabbit is doing

1182
01:07:10,585 --> 01:07:14,445
Speaker 5:  as opposed to like humane, which is like, you know, sort of yeah. Brought

1183
01:07:14,445 --> 01:07:18,075
Speaker 5:  from the earth fully formed. We have solved this, but

1184
01:07:18,075 --> 01:07:22,045
Speaker 5:  then there's still like wildly overstating what this thing can actually do

1185
01:07:22,045 --> 01:07:23,555
Speaker 5:  in a way that I find very frustrating.

1186
01:07:23,555 --> 01:07:26,205
Speaker 4:  There's a bunch of comments on your hands on posts, like why are you being

1187
01:07:26,205 --> 01:07:28,985
Speaker 4:  nice to this inhumane? And it's like, well one, it's not actually the review

1188
01:07:28,985 --> 01:07:32,875
Speaker 4:  yet important note, like we're just holding the thing and two, it's

1189
01:07:32,875 --> 01:07:36,435
Speaker 4:  like it's $200. Yeah. Yeah. And that's just different. But

1190
01:07:36,435 --> 01:07:40,295
Speaker 4:  I I I am very curious to see as you go through this three review process,

1191
01:07:40,295 --> 01:07:43,315
Speaker 4:  how much it needs to lean on the computer

1192
01:07:43,315 --> 01:07:47,305
Speaker 4:  revision piece. Because the more it has to do that,

1193
01:07:47,305 --> 01:07:51,265
Speaker 4:  which is the AI of it all the worse it's gonna be. Yes.

1194
01:07:51,265 --> 01:07:55,065
Speaker 4:  I I feel that very keenly. All right. Some more things we should talk about

1195
01:07:55,065 --> 01:07:58,985
Speaker 4:  in this section. Apple announced a May 7th event for new iPads. Two

1196
01:07:58,985 --> 01:08:01,505
Speaker 4:  things about this one, it's just an infomercial. There's just like tune in

1197
01:08:01,505 --> 01:08:04,865
Speaker 4:  to watch their stream. No one's going anywhere. Yeah. And then they sp they,

1198
01:08:04,865 --> 01:08:08,025
Speaker 4:  they're calling it let it loose. And our friend Joanna Stern pointed this

1199
01:08:08,025 --> 01:08:11,305
Speaker 4:  out, the s in loose looks like a G so it's let it luge, which

1200
01:08:11,305 --> 01:08:15,295
Speaker 4:  is, if you want to think about what that means in the context of new

1201
01:08:15,295 --> 01:08:19,275
Speaker 4:  iPads, I welcome you. I personally believe Apple is announcing

1202
01:08:19,275 --> 01:08:20,915
Speaker 4:  luge oriented

1203
01:08:20,915 --> 01:08:23,835
Speaker 6:  IPad.

1204
01:08:23,835 --> 01:08:24,635
Speaker 4:  It's very weird.

1205
01:08:24,635 --> 01:08:27,365
Speaker 5:  It's an i it's a huge like boogie board size, iPad's,

1206
01:08:27,365 --> 01:08:30,885
Speaker 4:  IPad. It's a cursive capital S so it's like weird. And so like in context

1207
01:08:30,885 --> 01:08:33,725
Speaker 4:  it looks like a lowercase G. Very good. It's

1208
01:08:33,725 --> 01:08:37,615
Speaker 4:  pretty, it feels like we're gonna get an noad iPad.

1209
01:08:37,615 --> 01:08:40,845
Speaker 4:  Right? That's the rumor. It feels like they'll just chip, bump everything

1210
01:08:40,845 --> 01:08:44,425
Speaker 4:  else. I'm trying very hard not to buy an noad iPad.

1211
01:08:44,425 --> 01:08:46,205
Speaker 6:  Mm. But you're gonna

1212
01:08:46,205 --> 01:08:48,265
Speaker 4:  I why? Like I don't use the one I have

1213
01:08:48,265 --> 01:08:51,365
Speaker 6:  So that I'm not the only one. Like I need, I need other people making bad

1214
01:08:51,365 --> 01:08:52,085
Speaker 6:  person. We're

1215
01:08:52,085 --> 01:08:54,725
Speaker 4:  Gonna do, do a group buy. We're gonna call Tim Cook and we're like, we get

1216
01:08:54,725 --> 01:08:56,975
Speaker 4:  a group rate on Ill-conceived

1217
01:08:56,975 --> 01:09:00,915
Speaker 4:  iPads. It, it just feels like this.

1218
01:09:00,915 --> 01:09:03,925
Speaker 4:  What they actually need to do is announce new software for the iPad, not

1219
01:09:03,925 --> 01:09:04,365
Speaker 4:  new hardware.

1220
01:09:04,365 --> 01:09:06,565
Speaker 5:  There were a bunch of people talking about this that I really enjoyed. That

1221
01:09:06,565 --> 01:09:10,485
Speaker 5:  was like, after this came out everybody was like, relax the real iPad

1222
01:09:10,485 --> 01:09:14,005
Speaker 5:  event is ww DC in June. Like this, this doesn't matter. Right. And I think

1223
01:09:14,005 --> 01:09:17,585
Speaker 5:  that's probably true. Like the strangest thing about the iPad is

1224
01:09:17,585 --> 01:09:21,565
Speaker 5:  the hardware has been really good for a really long time. I

1225
01:09:21,565 --> 01:09:25,405
Speaker 5:  would say other than please move the camera from the bad spot to the

1226
01:09:25,405 --> 01:09:29,305
Speaker 5:  good spot. I have very few issues with the iPad's hardware

1227
01:09:29,305 --> 01:09:33,125
Speaker 5:  and have not had issues for a long time. I have a million issues

1228
01:09:33,125 --> 01:09:35,545
Speaker 5:  with what it's like to actually use the damn thing.

1229
01:09:35,545 --> 01:09:38,805
Speaker 6:  That's why I'm kind of curious about, one of the big rumors is that they're

1230
01:09:38,805 --> 01:09:42,445
Speaker 6:  gonna do a new magic keyboard that's like aluminum or

1231
01:09:42,445 --> 01:09:46,035
Speaker 6:  something. It's more like a just a laptop case.

1232
01:09:46,035 --> 01:09:48,335
Speaker 5:  Yeah. With a bigger track pad. Like that would be cool.

1233
01:09:48,335 --> 01:09:51,565
Speaker 4:  David, I'm pointing out the 10th gen iPad moved. They moved the camera.

1234
01:09:51,565 --> 01:09:54,365
Speaker 5:  I know, but they haven't, they haven't on the other ones. Move it on all

1235
01:09:54,365 --> 01:09:54,835
Speaker 5:  the other places.

1236
01:09:54,835 --> 01:09:58,365
Speaker 6:  They're gonna probably do it on, on the pro in the air this time around.

1237
01:09:58,365 --> 01:10:01,595
Speaker 4:  At some point they're, they have to admit that the pro is just a weird laptop.

1238
01:10:01,595 --> 01:10:02,215
Speaker 4:  Yeah.

1239
01:10:02,215 --> 01:10:03,195
Speaker 6:  Maybe this is the time.

1240
01:10:03,195 --> 01:10:06,925
Speaker 4:  Look, I've been, I've been using my ancient now 11 inch iPad Pro is

1241
01:10:06,925 --> 01:10:10,245
Speaker 4:  like a tablet. Like this is dumb. Like it's just laptop all the time.

1242
01:10:10,245 --> 01:10:14,025
Speaker 4:  Yeah. I want to use it as tablet. Boy do I wanna read stereo review

1243
01:10:14,025 --> 01:10:17,245
Speaker 4:  in p in PDF form on my iPad as God

1244
01:10:17,245 --> 01:10:21,195
Speaker 4:  intended. But it's just like the, the thing,

1245
01:10:21,195 --> 01:10:23,555
Speaker 4:  it's just like yearns to be in. Its its laptop.

1246
01:10:23,555 --> 01:10:26,955
Speaker 5:  Yeah. You're also, you I I've noticed you started sending a lot of Apple

1247
01:10:26,955 --> 01:10:30,685
Speaker 5:  News plus links around, which makes me think you, you are becoming more of

1248
01:10:30,685 --> 01:10:32,305
Speaker 5:  an iPad user.

1249
01:10:32,305 --> 01:10:36,245
Speaker 4:  I'm just a boomer now. I'm a dad. I live in the suburbs. Sold

1250
01:10:36,245 --> 01:10:39,885
Speaker 4:  my truck. I haven't sold the truck yet. It's heartbreaking. It's selling

1251
01:10:39,885 --> 01:10:43,625
Speaker 4:  my stupid truck. It's, this is just me trying to not use Twitter

1252
01:10:43,625 --> 01:10:47,325
Speaker 4:  and Wall Street Journal and Conde NAS publications are Apple News plus I

1253
01:10:47,325 --> 01:10:49,815
Speaker 4:  got suckered in the deal. Great, fine.

1254
01:10:49,815 --> 01:10:53,725
Speaker 4:  Right. But do I love it? Do I

1255
01:10:53,725 --> 01:10:56,805
Speaker 4:  think Apple News? I just, I'm not gonna pass any judgments on Apple News

1256
01:10:56,805 --> 01:11:00,485
Speaker 4:  plus I'm just gonna ask anybody who has the product go and look at the list

1257
01:11:00,485 --> 01:11:04,065
Speaker 4:  of trending stories and be like, who do we think this audience

1258
01:11:04,065 --> 01:11:08,045
Speaker 4:  is? You just make that

1259
01:11:08,045 --> 01:11:11,205
Speaker 4:  distinction all in your I don't, I'm not gonna pass any judgment, but I'm

1260
01:11:11,205 --> 01:11:14,865
Speaker 4:  like that they're not getting younger, is it what I would

1261
01:11:14,865 --> 01:11:17,685
Speaker 4:  say it doesn't appear that they're getting younger with

1262
01:11:17,685 --> 01:11:21,525
Speaker 4:  time. But anyway, I I, yeah, I'm trying to use the iPad as a

1263
01:11:21,525 --> 01:11:25,445
Speaker 4:  consumption device and the iPad Pro in particular, it, it kind

1264
01:11:25,445 --> 01:11:28,005
Speaker 4:  of yearns to be in the keyboard case and I hope they just go for it. Be like,

1265
01:11:28,005 --> 01:11:31,825
Speaker 4:  we have a weird mini laptop, it's fine. You know, but they,

1266
01:11:31,825 --> 01:11:34,912
Speaker 4:  the software has to change. So that's, that's coming very soon. May 7th,

1267
01:11:35,165 --> 01:11:38,765
Speaker 4:  a couple weeks from now, The Ray Band, meta Smart Glasses got a big update.

1268
01:11:38,765 --> 01:11:42,445
Speaker 4:  They have multimodal AI now they announced some new colors and it's in various

1269
01:11:42,445 --> 01:11:46,065
Speaker 4:  three designs that they have. I feel like I'm like about to buy one of these.

1270
01:11:46,065 --> 01:11:50,045
Speaker 4:  You should. A meta also announced that it's making headsets with other

1271
01:11:50,045 --> 01:11:53,845
Speaker 4:  people. An attempt to make sort of Quest os the Open VR

1272
01:11:53,845 --> 01:11:57,715
Speaker 4:  headset, which Zuckerberg has talked about a lot. They're gonna make an

1273
01:11:57,715 --> 01:12:01,445
Speaker 4:  Xbox VR headset. It's a limited edition Meta Quest. So you can see

1274
01:12:01,445 --> 01:12:04,805
Speaker 4:  Zuckerberg is like, we're gonna be the Android of vr. Well, Apple's doing

1275
01:12:04,805 --> 01:12:06,245
Speaker 4:  whatever it's doing over here. Can

1276
01:12:06,245 --> 01:12:10,205
Speaker 6:  We, we call out the fact that it is so funny to watch Microsoft go from being

1277
01:12:10,205 --> 01:12:13,275
Speaker 6:  like, we are gonna create the VR head

1278
01:12:13,275 --> 01:12:16,805
Speaker 6:  like the VR space. We are, we're gonna do it all. Mixed

1279
01:12:16,805 --> 01:12:20,685
Speaker 6:  reality. We're gonna own this place to, we're gonna do a

1280
01:12:20,685 --> 01:12:23,645
Speaker 6:  rebranded Meta Quest three.

1281
01:12:23,645 --> 01:12:27,315
Speaker 4:  I mean if you're Microsoft and you're out there being like the future is

1282
01:12:27,315 --> 01:12:30,845
Speaker 4:  Xbox Game streaming, you might as well look an ab it and run. Yeah. Like

1283
01:12:30,845 --> 01:12:33,795
Speaker 4:  I it's the Quest is basically like an Android phone right on your face.

1284
01:12:33,795 --> 01:12:37,205
Speaker 5:  Yeah. Take the free ads. I mean, and the, the way they described it. Yeah,

1285
01:12:37,205 --> 01:12:40,785
Speaker 5:  it's a journey is so funny. It's like, it's a, it's a Quest three inspired

1286
01:12:40,785 --> 01:12:44,345
Speaker 5:  by Xbox or something, which just makes me think like somebody

1287
01:12:44,345 --> 01:12:48,285
Speaker 5:  at Microsoft like sent over the hex codes for the Xbox Green and

1288
01:12:48,285 --> 01:12:51,245
Speaker 5:  we're like, do whatever you want. Leave us alone.

1289
01:12:51,245 --> 01:12:55,205
Speaker 6:  I hope it is like just huge. I hope it is so chunky. Like the

1290
01:12:55,205 --> 01:12:55,725
Speaker 6:  original Xbox,

1291
01:12:55,725 --> 01:12:57,105
Speaker 5:  It's just a full on like master

1292
01:12:57,105 --> 01:13:00,445
Speaker 6:  Helmet. I it OG Xbox Controller. That'd be so, yeah. Yeah, just over the

1293
01:13:00,445 --> 01:13:01,045
Speaker 6:  top.

1294
01:13:01,045 --> 01:13:04,165
Speaker 4:  So the os the question s is being

1295
01:13:04,165 --> 01:13:07,845
Speaker 4:  rebranded I guess to Meta Horizon os which is just a lot of

1296
01:13:07,845 --> 01:13:11,145
Speaker 5:  Words. Yeah. Yeah. It's weird. There was was like Horizon

1297
01:13:11,145 --> 01:13:15,085
Speaker 5:  Worlds and then there was Horizon Work Rooms. So that was kind

1298
01:13:15,085 --> 01:13:17,965
Speaker 5:  of always gonna be their thing. But now they're trying to make it even bigger.

1299
01:13:17,965 --> 01:13:21,855
Speaker 5:  I will say Horizon. Great name for an operating system. Yeah.

1300
01:13:21,855 --> 01:13:24,235
Speaker 5:  Great job. The names are insane.

1301
01:13:24,235 --> 01:13:28,075
Speaker 4:  It's just a lot of words. So H Horizon os runs on the Quest hardware and

1302
01:13:28,075 --> 01:13:30,365
Speaker 4:  Xbox is making it Xbox inspired. That's a

1303
01:13:30,365 --> 01:13:34,245
Speaker 4:  lot good news though. More

1304
01:13:34,245 --> 01:13:37,165
Speaker 4:  companies that are known for their good names will be participating in this

1305
01:13:37,165 --> 01:13:41,105
Speaker 4:  ecosystem, including Ass Republic of Gamers. Very excited

1306
01:13:41,105 --> 01:13:45,075
Speaker 4:  for the names to come from them. Lenovo will make

1307
01:13:45,075 --> 01:13:47,355
Speaker 4:  something that will be, it'll

1308
01:13:47,355 --> 01:13:48,995
Speaker 6:  Have Legion in it somewhere.

1309
01:13:48,995 --> 01:13:50,655
Speaker 4:  A a word salad. Yep.

1310
01:13:50,655 --> 01:13:53,775
Speaker 5:  Lenovo Legion Quest Flip 13.

1311
01:13:53,775 --> 01:13:57,635
Speaker 4:  Yep. And, and then all of these are gonna run on Qualcomm chips.

1312
01:13:57,635 --> 01:14:01,515
Speaker 4:  Qualcomm also well known for stretching the boundaries of

1313
01:14:01,515 --> 01:14:04,955
Speaker 4:  tracking beyond all human recognition. So that's interesting. We'll see how

1314
01:14:04,955 --> 01:14:08,875
Speaker 4:  that goes. Right. They're the players. They have the momentum, the Quest,

1315
01:14:08,875 --> 01:14:12,525
Speaker 4:  quest three itself got an update where the pass through videos of higher

1316
01:14:12,525 --> 01:14:16,045
Speaker 4:  quality and looks better when you look at phones. There's momentum over

1317
01:14:16,045 --> 01:14:19,085
Speaker 4:  there. I want to come back actually to the The Ray band

1318
01:14:19,085 --> 01:14:23,045
Speaker 4:  glasses, which are a hit. Like they feel like a quiet hit. I

1319
01:14:23,045 --> 01:14:25,565
Speaker 4:  know a lot of people who have them. Our friend Joanna Stern says she doesn't

1320
01:14:25,565 --> 01:14:29,145
Speaker 4:  travel or go on field video shoots without them anymore.

1321
01:14:29,145 --> 01:14:29,995
Speaker 4:  Wow.

1322
01:14:29,995 --> 01:14:33,825
Speaker 6:  They're really good. I've got a pair. I, I should wear mine more. I'm,

1323
01:14:33,825 --> 01:14:37,285
Speaker 6:  I'm legit thinking about going and getting prescription lenses put in it.

1324
01:14:37,285 --> 01:14:40,405
Speaker 6:  'cause I, I always have to put my contacts in and it's like that friction's

1325
01:14:40,405 --> 01:14:43,325
Speaker 6:  too much. But every time I wear 'em I'm like, why don't I wear my contacts

1326
01:14:43,325 --> 01:14:45,115
Speaker 6:  more often? These like are awesome.

1327
01:14:45,115 --> 01:14:48,425
Speaker 4:  They're cheap, they're 300 bucks. I've got a friend who in the pandemic,

1328
01:14:48,425 --> 01:14:51,365
Speaker 4:  she just became one of those people who doesn't live anywhere. She's just

1329
01:14:51,365 --> 01:14:53,725
Speaker 4:  like, literally last week she's like, I'm working from a boat. And I was

1330
01:14:53,725 --> 01:14:57,385
Speaker 4:  like, I hate you. You seem great. All of her photos are from the Meta quest

1331
01:14:57,385 --> 01:14:57,725
Speaker 4:  now on

1332
01:14:57,725 --> 01:15:01,265
Speaker 5:  Instagram. Well and or The Ray band. The thing meta got really right, was

1333
01:15:01,265 --> 01:15:05,085
Speaker 5:  it, it went the correct direction in terms of saying like,

1334
01:15:05,085 --> 01:15:08,865
Speaker 5:  we're gonna pick a very small number of things for this device to do

1335
01:15:08,865 --> 01:15:12,745
Speaker 5:  and it's gonna do them pretty well. And then we're going to slowly

1336
01:15:12,745 --> 01:15:16,475
Speaker 5:  add things that it can do. Like it, when it started it was like, okay,

1337
01:15:16,475 --> 01:15:20,285
Speaker 5:  it's a pretty good speaker system if you like wanna listen to music

1338
01:15:20,285 --> 01:15:22,835
Speaker 5:  or podcast or whatever. That's mostly what I use it for. It's become like,

1339
01:15:22,835 --> 01:15:26,725
Speaker 5:  when I'm out on a walk or whatever, I wear it instead I wear the glasses

1340
01:15:26,725 --> 01:15:30,325
Speaker 5:  instead of headphones now, which is awesome. Pretty good

1341
01:15:30,325 --> 01:15:34,245
Speaker 5:  Camera people really like taking photos and videos that way. And now they're

1342
01:15:34,245 --> 01:15:37,665
Speaker 5:  adding on, they're like, okay, now we can do, they had the, you could like

1343
01:15:37,665 --> 01:15:40,565
Speaker 5:  ask meta AI questions, but now they're adding the multimodal stuff and so

1344
01:15:40,565 --> 01:15:44,405
Speaker 5:  they're like, they're sequencing this stuff really smartly instead of

1345
01:15:44,405 --> 01:15:48,275
Speaker 5:  like promising the world from the very beginning and then not

1346
01:15:48,275 --> 01:15:51,285
Speaker 5:  meeting people's expectations, which I think is really the key. These are

1347
01:15:51,285 --> 01:15:54,715
Speaker 5:  better than people expected them to be, which is so, so, so

1348
01:15:54,715 --> 01:15:57,705
Speaker 5:  rare in this moment with hardware. Yeah.

1349
01:15:57,705 --> 01:16:00,245
Speaker 4:  And again, the first thing they just had to be was some nice looking Ray

1350
01:16:00,245 --> 01:16:02,405
Speaker 4:  bands. Yeah. And it's like, all right, you get a pair of Wayfairs, you get

1351
01:16:02,405 --> 01:16:05,125
Speaker 4:  these other two designs. Like people just like those designs. Whether or

1352
01:16:05,125 --> 01:16:07,205
Speaker 4:  not the battery lasts the camera works is like, oh no, there's just a pair

1353
01:16:07,205 --> 01:16:09,325
Speaker 4:  of Wayfairs. Like maybe it'll be cool. And now they're deciding all this

1354
01:16:09,325 --> 01:16:09,845
Speaker 4:  cool stuff. Well

1355
01:16:09,845 --> 01:16:12,265
Speaker 5:  It's like that old Mitch Hedberg joke, right? That like when an escalator,

1356
01:16:12,265 --> 01:16:15,925
Speaker 5:  an escalator doesn't break, it just becomes stairs. Like that's, that's these

1357
01:16:15,925 --> 01:16:19,045
Speaker 5:  glasses. Right. Like the worst case scenario is you just have a nice pair

1358
01:16:19,045 --> 01:16:19,795
Speaker 5:  of sunglasses.

1359
01:16:19,795 --> 01:16:23,485
Speaker 4:  Yeah. And, and honestly 300 bucks for a pay pair of ribands is like a little

1360
01:16:23,485 --> 01:16:26,565
Speaker 4:  bit of a premium, but it's not crazy. No. And now the multimodal ai, you

1361
01:16:26,565 --> 01:16:28,965
Speaker 4:  can do the thing, what am I looking at? And it tells you Right, right. That's

1362
01:16:28,965 --> 01:16:32,565
Speaker 4:  the big trick. That's the, it's emerging as the party trick of these AI

1363
01:16:32,565 --> 01:16:33,185
Speaker 4:  devices

1364
01:16:33,185 --> 01:16:36,605
Speaker 5:  And it's as messy as anything else. Like V Song did a bunch of testing with

1365
01:16:36,605 --> 01:16:40,525
Speaker 5:  it and it was like hilariously wrong about cars and all that stuff. And it's

1366
01:16:40,525 --> 01:16:43,965
Speaker 5:  always like all these systems, it's very confident and just lies to your

1367
01:16:43,965 --> 01:16:44,805
Speaker 5:  face.

1368
01:16:44,805 --> 01:16:48,565
Speaker 4:  I actually, I'm, I'm starting to be of the mind that we need to push

1369
01:16:48,565 --> 01:16:51,965
Speaker 4:  back strongly against calling any of this ai. We just need to call them what

1370
01:16:51,965 --> 01:16:55,645
Speaker 4:  language models. 'cause they just make up words.

1371
01:16:55,645 --> 01:16:59,385
Speaker 4:  There's no intelligence artificial or otherwise happening here.

1372
01:16:59,385 --> 01:17:01,685
Speaker 4:  That's gonna be a hard fight. I don't think we're gonna, I'm not gonna win

1373
01:17:01,685 --> 01:17:03,685
Speaker 4:  that fight. There's a lot of fights I've won. I'm not gonna win that fight.

1374
01:17:03,685 --> 01:17:07,525
Speaker 4:  Support you. But the conflation of can you talk with, are you smart? Is in

1375
01:17:07,525 --> 01:17:11,325
Speaker 4:  a real weird moment on the internet right now. Turns out you talk

1376
01:17:11,325 --> 01:17:15,245
Speaker 4:  maybe less smart. You're the, I talk a lot that just, I'm

1377
01:17:15,245 --> 01:17:19,125
Speaker 4:  not trying to burn anybody just putting that out there. Fascinating

1378
01:17:19,125 --> 01:17:22,805
Speaker 4:  to me though. Put just add all this up, right? You've got meta doing this

1379
01:17:22,805 --> 01:17:26,465
Speaker 4:  sort of open stuff with Lenovo and all these other companies. You've got

1380
01:17:26,465 --> 01:17:30,195
Speaker 4:  the glasses which are sort of a sneaky hit that people like

1381
01:17:30,195 --> 01:17:33,925
Speaker 4:  next to, okay. Analyst reports the vision Pro demand is

1382
01:17:33,925 --> 01:17:37,845
Speaker 4:  suffering. Right. And it's like, did Apple just get outgunned by a pair

1383
01:17:37,845 --> 01:17:39,545
Speaker 4:  of Raybans? Yes.

1384
01:17:39,545 --> 01:17:40,305
Speaker 5:  Yes.

1385
01:17:40,305 --> 01:17:41,195
Speaker 4:  That's crazy.

1386
01:17:41,195 --> 01:17:41,715
Speaker 5:  It's nuts.

1387
01:17:41,715 --> 01:17:45,325
Speaker 6:  It's not crazy though. It was a $3,500 bet against a

1388
01:17:45,325 --> 01:17:46,525
Speaker 6:  $300 bed.

1389
01:17:46,525 --> 01:17:50,145
Speaker 5:  I don't even think it's that. I think Apple just miscalculated. Like I, the,

1390
01:17:50,145 --> 01:17:54,005
Speaker 5:  the longer I use these devices, the more I can't

1391
01:17:54,005 --> 01:17:57,885
Speaker 5:  believe Apple didn't make the smart glasses. Like I I if in

1392
01:17:57,885 --> 01:18:01,485
Speaker 5:  the thing that Apple has traditionally done, which is like build a thing

1393
01:18:01,485 --> 01:18:03,885
Speaker 5:  and then build the more complicated thing and then build the more complicated.

1394
01:18:03,885 --> 01:18:07,525
Speaker 5:  Like Apple is actually very good at laddering that stuff up over time. And

1395
01:18:07,525 --> 01:18:11,365
Speaker 5:  in this case, just way overshot it was like, it, it it was like

1396
01:18:11,365 --> 01:18:15,345
Speaker 5:  building four generations too soon and trying

1397
01:18:15,345 --> 01:18:18,635
Speaker 5:  to convince people to buy it. And what if, if they had just built like the

1398
01:18:18,635 --> 01:18:22,625
Speaker 5:  iPod version of it, which is just like a nice thing for listening to music

1399
01:18:22,625 --> 01:18:26,165
Speaker 5:  and talking to an assistant. People would've gone nuts for it. And it is

1400
01:18:26,165 --> 01:18:30,135
Speaker 5:  like, it, it continues to blow my mind that Apple just, I think picked

1401
01:18:30,135 --> 01:18:30,635
Speaker 5:  wrong.

1402
01:18:30,635 --> 01:18:34,145
Speaker 6:  They could still do it. We could still get the Apple vision Air.

1403
01:18:34,145 --> 01:18:37,585
Speaker 5:  Oh I'm sure we will. I I'm, I'm sure that's where it's headed. But like I,

1404
01:18:37,585 --> 01:18:40,685
Speaker 5:  the, what the Humane folks told me is they were like, okay, well when we

1405
01:18:40,685 --> 01:18:44,325
Speaker 5:  built this, we decided to build the hardest thing first based on the idea

1406
01:18:44,325 --> 01:18:47,165
Speaker 5:  that then it's much easier to sort of ratchet our ambition down and sell

1407
01:18:47,165 --> 01:18:49,845
Speaker 5:  cheaper, simpler versions of the thing. But it turns out if you blow the

1408
01:18:49,845 --> 01:18:53,485
Speaker 5:  expensive one, you don't get the chance to do the next things. Yeah. And

1409
01:18:53,485 --> 01:18:57,285
Speaker 5:  I think Apple has kind of dug itself a hole here by so aggressively

1410
01:18:57,285 --> 01:19:00,865
Speaker 5:  overshooting. I also like all these supply chain numbers

1411
01:19:00,865 --> 01:19:04,365
Speaker 5:  should be taken with like a giant heap of salt all the time. But I will say

1412
01:19:04,365 --> 01:19:07,635
Speaker 5:  anecdotally nobody talks about the Vision Pro anymore.

1413
01:19:07,635 --> 01:19:08,105
Speaker 4:  Yeah.

1414
01:19:08,105 --> 01:19:09,805
Speaker 5:  It has totally faded.

1415
01:19:09,805 --> 01:19:13,345
Speaker 4:  I spend a lot of time looking in the subreddit and it

1416
01:19:13,345 --> 01:19:16,365
Speaker 4:  is, a lot of people are like, what are, what are we using this thing for?

1417
01:19:16,365 --> 01:19:18,445
Speaker 4:  Yeah. You know, and then there's like one app comes out and it's a hit and

1418
01:19:18,445 --> 01:19:21,575
Speaker 4:  people really like it, but it's a little little dire in

1419
01:19:21,575 --> 01:19:25,055
Speaker 4:  there. I'm just gonna say, I was writing in the review. Yep. Let's putting

1420
01:19:25,055 --> 01:19:26,455
Speaker 4:  that out there. It took a lot of heat for that one.

1421
01:19:26,455 --> 01:19:27,285
Speaker 5:  It's better out here.

1422
01:19:27,285 --> 01:19:30,255
Speaker 4:  Yeah, it's better. Right. The question is like, is it worth putting it on?

1423
01:19:30,255 --> 01:19:34,135
Speaker 4:  Yeah. And there isn't anything that makes it worth putting on. There's a

1424
01:19:34,135 --> 01:19:37,335
Speaker 4:  few things sometimes, but even Mark Gerberman in his newsletter where he

1425
01:19:37,335 --> 01:19:39,495
Speaker 4:  was talking about some of these results, he's like, I'm wearing this thing

1426
01:19:39,495 --> 01:19:42,755
Speaker 4:  less and less like it's lonely. Like he's like, I don't wanna watch basketball.

1427
01:19:42,755 --> 01:19:46,735
Speaker 4:  And I it is weird. It's just like a weird moment in hardware.

1428
01:19:46,735 --> 01:19:50,635
Speaker 4:  Yeah. Where the big expensive stuff didn't go and the the sort of cheap stuff

1429
01:19:50,635 --> 01:19:54,375
Speaker 4:  that's making small promises. It's gaining a new kind of momentum. I think

1430
01:19:54,375 --> 01:19:57,475
Speaker 4:  I'm gonna buy 'em, I I don't know why I have too many glasses. I lose them.

1431
01:19:57,475 --> 01:20:00,295
Speaker 4:  It, I have a rule to not buy glasses that are more than 50 bucks. Not buy

1432
01:20:00,295 --> 01:20:03,295
Speaker 4:  sunglasses are more than 50 bucks. 'cause they're gone. That's good. I might

1433
01:20:03,295 --> 01:20:06,215
Speaker 4:  as well flush the $50 down the toilet. You know what I mean? But there's

1434
01:20:06,215 --> 01:20:08,145
Speaker 4:  a part it's like what if

1435
01:20:08,145 --> 01:20:12,025
Speaker 5:  The good news is these, these ones are very heavy so

1436
01:20:12,025 --> 01:20:14,465
Speaker 5:  it will be hard to lose them. They did like,

1437
01:20:14,465 --> 01:20:18,445
Speaker 6:  And the the charging case is really nice. So you're gonna be like,

1438
01:20:18,445 --> 01:20:22,125
Speaker 6:  oh I can't lose my charging case because it's so nice. And then you'll never

1439
01:20:22,125 --> 01:20:22,955
Speaker 6:  lose your glasses,

1440
01:20:22,955 --> 01:20:24,505
Speaker 4:  Alex, you've never underestimate

1441
01:20:24,505 --> 01:20:28,385
Speaker 6:  I'm just, I'm filled with optimism today. Yeah. Just

1442
01:20:28,385 --> 01:20:29,265
Speaker 6:  all optimism.

1443
01:20:29,265 --> 01:20:31,245
Speaker 4:  All right, we're gonna take a break. I'm gonna look on the meta website and

1444
01:20:31,245 --> 01:20:31,425
Speaker 4:  see

1445
01:23:01,525 --> 01:23:05,405
Speaker 4:  one. Just to recap, Tesla has laid off more than 10% of its workforce, like

1446
01:23:05,405 --> 01:23:09,245
Speaker 4:  14,000 people. Bunch of executives are leaving, including

1447
01:23:09,245 --> 01:23:12,885
Speaker 4:  the guy who was in charge of the powertrain and energy division. And then

1448
01:23:12,885 --> 01:23:16,795
Speaker 4:  the head of policy who's the guy who gets autonomy like approved also

1449
01:23:16,795 --> 01:23:20,745
Speaker 4:  gone a lot going on with Tesla, right? There's a rumor that they're gonna

1450
01:23:20,745 --> 01:23:24,065
Speaker 4:  cancel the cheap EV and then they kind of said they weren't gonna cancel

1451
01:23:24,065 --> 01:23:27,085
Speaker 4:  it. But it also sounds like what they're really gonna do is make the model

1452
01:23:27,085 --> 01:23:30,065
Speaker 4:  Y cheaper. They've, they've recalled all

1453
01:23:30,065 --> 01:23:33,285
Speaker 4:  3,800 cyber trucks, 3,878 cyber

1454
01:23:33,285 --> 01:23:37,125
Speaker 4:  trucks. But they talked, Elon said

1455
01:23:37,125 --> 01:23:40,785
Speaker 4:  optimist would be a fully sentient robot that would quote

1456
01:23:40,785 --> 01:23:44,275
Speaker 4:  expand the economy, the world economy infinitely. Oh

1457
01:23:44,275 --> 01:23:44,675
Speaker 5:  Sick.

1458
01:23:44,675 --> 01:23:47,075
Speaker 4:  They'll be selling that at the end of next year. Yeah,

1459
01:23:47,075 --> 01:23:47,665
Speaker 5:  Sure.

1460
01:23:47,665 --> 01:23:49,605
Speaker 4:  So a classic Elon bump there. I

1461
01:23:49,605 --> 01:23:53,005
Speaker 5:  Think he even said in that announce in that like in that sentence I think

1462
01:23:53,005 --> 01:23:55,125
Speaker 5:  he said, but I'm just guessing. It's like alright

1463
01:23:55,125 --> 01:23:56,695
Speaker 4:  Cool. Yeah

1464
01:23:56,695 --> 01:23:57,795
Speaker 5:  Great investor call,

1465
01:23:57,795 --> 01:24:01,725
Speaker 4:  There's a new model three performance. Great. But they

1466
01:24:01,725 --> 01:24:05,565
Speaker 4:  don't have his new cars. There's not really a plan to have new cars. They're

1467
01:24:05,565 --> 01:24:09,445
Speaker 4:  gonna announce some robax plan on August 8th. And then there's this

1468
01:24:09,445 --> 01:24:12,165
Speaker 4:  thing that they've been talking about, which he brought up again on the earnings

1469
01:24:12,165 --> 01:24:14,845
Speaker 4:  call today, which I just wanna talk about for five seconds 'cause it is bonkers

1470
01:24:14,845 --> 01:24:17,725
Speaker 4:  to me. He was talking about how many H one hundreds Tesla has, he went on

1471
01:24:17,725 --> 01:24:20,285
Speaker 4:  his very funny side about how he doesn't like calling them GPUs because they

1472
01:24:20,285 --> 01:24:23,125
Speaker 4:  don't have any graphics but whatever it's, and you can hear the investors

1473
01:24:23,125 --> 01:24:27,085
Speaker 4:  being like, what? And then he got to, we

1474
01:24:27,085 --> 01:24:30,885
Speaker 4:  have all these H one hundreds and we are doing inference AI inference

1475
01:24:30,885 --> 01:24:33,485
Speaker 4:  more efficiently 'cause we had to learn how to do it in the car which is

1476
01:24:33,485 --> 01:24:36,085
Speaker 4:  constrained. Great. That makes sense. It's a good argument. Why not? You

1477
01:24:36,085 --> 01:24:38,765
Speaker 4:  can measure it whether that makes sense. And then he is like, we've got this

1478
01:24:38,765 --> 01:24:42,685
Speaker 4:  like AWS play, which they've hinted at before, but he was like, what we're

1479
01:24:42,685 --> 01:24:46,585
Speaker 4:  gonna do is run it on all the Teslas that are just sitting around.

1480
01:24:46,585 --> 01:24:50,358
Speaker 4:  So quote, if you can imagine in the future perhaps there's a fleet of 100

1481
01:24:50,358 --> 01:24:54,325
Speaker 4:  million Teslas and on average they've gotten like maybe a kilowatt of inference

1482
01:24:54,325 --> 01:24:58,205
Speaker 4:  compute that's a hundred gigawatts of inference compute distributed all

1483
01:24:58,205 --> 01:25:00,845
Speaker 4:  around the world. It's pretty hard to put together a hundred gigawatts of

1484
01:25:00,845 --> 01:25:04,685
Speaker 4:  AI compute. So, and perhaps maybe instead of using the car 10

1485
01:25:04,685 --> 01:25:06,965
Speaker 4:  hours a week, we use it 50 hours a week while it's sitting there. That leaves

1486
01:25:06,965 --> 01:25:09,565
Speaker 4:  over a hundred hours a week where the car inference computer can be doing

1487
01:25:09,565 --> 01:25:12,605
Speaker 4:  something else and it seems like it would be a waste to not use it. My man

1488
01:25:12,605 --> 01:25:15,755
Speaker 4:  is describing set at home for Teslas.

1489
01:25:15,755 --> 01:25:19,135
Speaker 6:  Yeah. What do those terms of service look like,

1490
01:25:19,135 --> 01:25:22,935
Speaker 4:  Right? It's just like you do you wanna run compute models on your car

1491
01:25:22,935 --> 01:25:26,635
Speaker 4:  while it's like sitting in the driveway your car, which by the way famously

1492
01:25:26,635 --> 01:25:28,235
Speaker 4:  runs on electricity

1493
01:25:28,235 --> 01:25:28,875
Speaker 5:  Like,

1494
01:25:28,875 --> 01:25:31,165
Speaker 4:  Like where's that electricity, where's that power bill coming from? Are you

1495
01:25:31,165 --> 01:25:34,685
Speaker 4:  gonna get it cheaper? She buy a car and now Elon can use it to do whatever

1496
01:25:34,685 --> 01:25:38,125
Speaker 4:  inference to run whatever robax fleet that he thinks he's gonna need to run

1497
01:25:38,125 --> 01:25:42,045
Speaker 4:  it. Also, I dunno if you know about AWS, they like knowing where the computers

1498
01:25:42,045 --> 01:25:43,825
Speaker 4:  are

1499
01:25:43,825 --> 01:25:47,605
Speaker 5:  And and typically those computers are not driving somewhere between 20 and

1500
01:25:47,605 --> 01:25:49,565
Speaker 5:  a hundred miles an hour while they're being

1501
01:25:49,565 --> 01:25:52,405
Speaker 4:  Used. Yeah's like, you know, I've interviewed the C of a Wix. I I would say

1502
01:25:52,405 --> 01:25:56,325
Speaker 4:  a a core assumption of that conversation was that he knew where the servers

1503
01:25:56,325 --> 01:26:00,205
Speaker 4:  were and they were not ever at risk of crashing into

1504
01:26:00,205 --> 01:26:01,515
Speaker 4:  other servers.

1505
01:26:01,515 --> 01:26:05,125
Speaker 5:  This feels like such a classic Elon Musk thing. 'cause even as you were reading

1506
01:26:05,125 --> 01:26:09,025
Speaker 5:  that it's like okay, this sort of makes sense like

1507
01:26:09,025 --> 01:26:12,365
Speaker 5:  big fleet, lots of compute sitting around, what if we use the compute and

1508
01:26:12,365 --> 01:26:14,925
Speaker 5:  then it's like you raise your hand and you go like how is any of that gonna

1509
01:26:14,925 --> 01:26:18,755
Speaker 5:  work? And it's like, ah, don't worry about that. Like

1510
01:26:18,755 --> 01:26:19,395
Speaker 4:  It's fine.

1511
01:26:19,395 --> 01:26:23,165
Speaker 6:  He's doing it at the same time that like Chevy is is

1512
01:26:23,165 --> 01:26:26,805
Speaker 6:  getting a lot of flack because they've been using their computers to spy

1513
01:26:26,805 --> 01:26:30,045
Speaker 6:  on people and report it to their insurance companies. Yeah. Like maybe not

1514
01:26:30,045 --> 01:26:32,765
Speaker 6:  the time to be like, yeah we you've got a computer in there and I want to

1515
01:26:32,765 --> 01:26:33,995
Speaker 6:  use it.

1516
01:26:33,995 --> 01:26:37,365
Speaker 4:  Yeah. It's like it's mine now. Yeah. I just think this is the one where it's

1517
01:26:37,365 --> 01:26:41,275
Speaker 4:  like what what Elon is searching for is arguments that Tesla

1518
01:26:41,275 --> 01:26:45,125
Speaker 4:  will have massive margins, right? Software company style margins instead

1519
01:26:45,125 --> 01:26:48,005
Speaker 4:  of car company margins. Right. And the thing that's hammering Tesla right

1520
01:26:48,005 --> 01:26:51,085
Speaker 4:  now is they have absolutely car company margins again. 'cause they dropped

1521
01:26:51,085 --> 01:26:54,125
Speaker 4:  the price so much and they don't have any new cars. So the competition is

1522
01:26:54,125 --> 01:26:57,685
Speaker 4:  here and you can see the sales fell like 55%. Like they, they're just not

1523
01:26:57,685 --> 01:27:01,165
Speaker 4:  doing it anymore. And so he is, he's concocting these arguments

1524
01:27:01,165 --> 01:27:05,045
Speaker 4:  where a sentient optimist robot will expand the

1525
01:27:05,045 --> 01:27:08,725
Speaker 4:  world economy by infinity. That's a pretty good margin. Yeah, that's

1526
01:27:08,725 --> 01:27:09,435
Speaker 5:  Good.

1527
01:27:09,435 --> 01:27:11,965
Speaker 4:  It's, I mean if you know more power to you if you pull that off and then

1528
01:27:11,965 --> 01:27:15,405
Speaker 4:  he is like, and I'm gonna build this like distributed data center so I now

1529
01:27:15,405 --> 01:27:19,165
Speaker 4:  I'm running AWS instead of having to build a data center in Texas or wherever

1530
01:27:19,165 --> 01:27:23,065
Speaker 4:  you might need to build it and it's like this is the, the truth

1531
01:27:23,065 --> 01:27:26,995
Speaker 4:  is outing here, right? Like it is very hard to get

1532
01:27:26,995 --> 01:27:30,885
Speaker 4:  from here to, I'm running a distributed AI supercomputer

1533
01:27:30,885 --> 01:27:34,605
Speaker 4:  in every Tesla in the world. It's like, is this

1534
01:27:34,605 --> 01:27:35,595
Speaker 4:  very hard?

1535
01:27:35,595 --> 01:27:38,815
Speaker 6:  It kind of feels a little like a peloton moment for

1536
01:27:38,815 --> 01:27:42,655
Speaker 6:  him. You know, where Peloton, everybody and everybody got a Peloton

1537
01:27:42,655 --> 01:27:46,235
Speaker 6:  because they wanted one and it feels like maybe everyone who wanted the Tesla

1538
01:27:46,235 --> 01:27:46,845
Speaker 6:  got one.

1539
01:27:46,845 --> 01:27:49,285
Speaker 4:  Well lemme just ask you this question about this distributed difference computer.

1540
01:27:49,285 --> 01:27:51,085
Speaker 4:  What happens at rush hour?

1541
01:27:51,085 --> 01:27:51,465
Speaker 6:  Yeah.

1542
01:27:51,465 --> 01:27:55,205
Speaker 4:  Right. The, the total capacity of the computer just like blunts like, like

1543
01:27:55,205 --> 01:27:59,175
Speaker 4:  hour by hour. Like it's always five o'clock somewhere like every hour. There's

1544
01:27:59,175 --> 01:28:02,775
Speaker 4:  just like huge dip in capacity like starts and it comes, starts coming back

1545
01:28:02,775 --> 01:28:06,575
Speaker 4:  online at 7:00 PM like literally the sun sets on Tesla's

1546
01:28:06,575 --> 01:28:09,935
Speaker 4:  compute capacity across the United States every single day. Like it's very

1547
01:28:09,935 --> 01:28:13,835
Speaker 4:  hard to, to pull this through. I think. I think that Tesla

1548
01:28:13,835 --> 01:28:16,125
Speaker 4:  is in a like fascinating moment.

1549
01:28:16,125 --> 01:28:17,095
Speaker 5:  They,

1550
01:28:17,095 --> 01:28:20,475
Speaker 4:  I am not sure it five years from now it looks anything like this company.

1551
01:28:20,475 --> 01:28:24,325
Speaker 5:  No. Yeah. It, it seems hard to imagine. I mean I think

1552
01:28:24,325 --> 01:28:28,215
Speaker 5:  this company has already gone through so many weirder iterations than

1553
01:28:28,215 --> 01:28:31,935
Speaker 5:  anybody would've expected and continues to sort of chug

1554
01:28:31,935 --> 01:28:35,895
Speaker 5:  along. Like Tesla feels very much like a cockroach at this point. That sort

1555
01:28:35,895 --> 01:28:38,695
Speaker 5:  of nothing could happen to Tesla that would surprise me. And also it will

1556
01:28:38,695 --> 01:28:41,915
Speaker 5:  be the last company that exists on planet earth.

1557
01:28:41,915 --> 01:28:45,295
Speaker 6:  Oh I disagree but I I I like it feels like it's

1558
01:28:45,295 --> 01:28:48,165
Speaker 6:  going to crap.

1559
01:28:48,165 --> 01:28:52,085
Speaker 4:  Yeah. Even like a bunch of Tesla fans were like, I dunno about this anymore.

1560
01:28:52,085 --> 01:28:54,575
Speaker 5:  Well that's, I mean that, that's one of the big questions to me. I was talking

1561
01:28:54,575 --> 01:28:58,415
Speaker 5:  about this with Andy Hawkins yesterday. Like thi this

1562
01:28:58,415 --> 01:29:02,025
Speaker 5:  question of kind of the Elon Musk effect that

1563
01:29:02,025 --> 01:29:05,985
Speaker 5:  the people who are predisposed to want

1564
01:29:05,985 --> 01:29:09,445
Speaker 5:  Teslas for a lot of the reasons that Tesla promotes them being good for the

1565
01:29:09,445 --> 01:29:13,045
Speaker 5:  world and all that are also people who are likely to not be psyched

1566
01:29:13,045 --> 01:29:16,645
Speaker 5:  about Elon Musk's shenanigans, particularly as he

1567
01:29:16,645 --> 01:29:20,445
Speaker 5:  runs X. And so trying to figure out how to

1568
01:29:20,445 --> 01:29:24,365
Speaker 5:  quantify how much of this is about the, the challenges in

1569
01:29:24,365 --> 01:29:27,325
Speaker 5:  the EV market, how much this is about plugin hybrids, which I thought was

1570
01:29:27,325 --> 01:29:29,565
Speaker 5:  a really interesting thing that Mus said during the earnings call. Yeah.

1571
01:29:29,565 --> 01:29:32,285
Speaker 5:  He blamed a lot of the struggle on the rise in plugin

1572
01:29:32,285 --> 01:29:35,905
Speaker 5:  hybrids and how much of this is just

1573
01:29:35,905 --> 01:29:39,845
Speaker 5:  people voting with their dollars and voting against Elon Musk is

1574
01:29:39,845 --> 01:29:43,185
Speaker 5:  really hard to know. And I think it's gonna be super obvious in retrospect

1575
01:29:43,185 --> 01:29:44,995
Speaker 5:  and I'm very curious how it's gonna shake out.

1576
01:29:44,995 --> 01:29:48,885
Speaker 6:  There's also the fact that if you're just going to buy a car and

1577
01:29:48,885 --> 01:29:51,205
Speaker 6:  you're going out in the world and you're like, I'm gonna buy a car and you

1578
01:29:51,205 --> 01:29:55,125
Speaker 6:  don't buy a car based on I, then you go and you look and

1579
01:29:55,125 --> 01:29:58,715
Speaker 6:  you say, okay, Teslas have really bad reliability.

1580
01:29:58,715 --> 01:30:02,325
Speaker 6:  They're really hard to repair, they're really hard to just get an appointment.

1581
01:30:02,325 --> 01:30:06,305
Speaker 6:  And oftentimes that appointment's horrible. The build quality is crap

1582
01:30:06,305 --> 01:30:10,275
Speaker 6:  to the point that like they keep having to do recalls on the cyber truck.

1583
01:30:10,275 --> 01:30:14,245
Speaker 6:  Like those are all just signs of a badly run company. And I think,

1584
01:30:14,245 --> 01:30:18,035
Speaker 6:  I think this company had a lot of advantage 'cause it was first mover and

1585
01:30:18,035 --> 01:30:21,925
Speaker 6:  Elon Musk is an incredible salesman but now like the bloom is off that

1586
01:30:21,925 --> 01:30:25,705
Speaker 6:  rose Twitter x, whatever you wanna call it, ripped that right off.

1587
01:30:25,705 --> 01:30:28,545
Speaker 6:  And now it's like okay, we see that this guy is just a really good salesman

1588
01:30:28,545 --> 01:30:32,515
Speaker 6:  and he pulls it all out of his butt and he is not some genius. And actually

1589
01:30:32,515 --> 01:30:36,465
Speaker 6:  he's not running a very good company because he is running 12 at once and

1590
01:30:36,465 --> 01:30:38,515
Speaker 6:  no one can do that. Even Elon Musk.

1591
01:30:38,515 --> 01:30:41,805
Speaker 4:  Alex is Alex Crans. The Verge with a K. Yeah, just email

1592
01:30:41,805 --> 01:30:43,685
Speaker 4:  that hit me up. I'm

1593
01:30:43,685 --> 01:30:45,635
Speaker 6:  Doing you a favor. I'm here to debate you.

1594
01:30:45,635 --> 01:30:49,445
Speaker 4:  Yeah, debate Alex with a K please. It's gonna be great. Connie

1595
01:30:49,445 --> 01:30:53,325
Speaker 4:  potty Tesla trolls. I don't think you're

1596
01:30:53,325 --> 01:30:56,845
Speaker 4:  wrong. I just think, I think the fundamentals of the auto business, he has

1597
01:30:56,845 --> 01:31:00,545
Speaker 4:  to not be a car company and it, the thing that is happening is it's getting

1598
01:31:00,545 --> 01:31:01,665
Speaker 4:  sucked into being a car company

1599
01:31:01,665 --> 01:31:02,895
Speaker 5:  Because it is one and

1600
01:31:02,895 --> 01:31:05,585
Speaker 4:  Because it, yeah, because it is one you make cars and the blaming the hybrid

1601
01:31:05,585 --> 01:31:08,465
Speaker 4:  thing is super funny to me. Like yes, I own a hybrid, but like you're basically

1602
01:31:08,465 --> 01:31:12,405
Speaker 4:  telling your customers they're wrong. Right? And how do you get

1603
01:31:12,405 --> 01:31:15,685
Speaker 4:  across, how do you get past the market making a decision? I'm regulate the

1604
01:31:15,685 --> 01:31:19,245
Speaker 4:  market. Joe Biden, will you make hybrids illegal is like kind of the only

1605
01:31:19,245 --> 01:31:22,685
Speaker 4:  answer to that. Or you can yell at everyone that they're wrong and like yelling

1606
01:31:22,685 --> 01:31:25,165
Speaker 4:  at the market that it's wrong is like not great. That

1607
01:31:25,165 --> 01:31:28,245
Speaker 6:  That always famously works for everyone who does it.

1608
01:31:28,245 --> 01:31:32,125
Speaker 4:  This is famously why Betamax beat VHS. Yeah. Everyone

1609
01:31:32,125 --> 01:31:34,685
Speaker 4:  knows it. I don't think hybrid. I think hybrid's, everyone I know who has

1610
01:31:34,685 --> 01:31:37,965
Speaker 4:  hybrid knows it's like some short term solution to the infrastructure not

1611
01:31:37,965 --> 01:31:40,485
Speaker 4:  being there. Yeah. And they, like everyone prefers to drive around in the

1612
01:31:40,485 --> 01:31:41,345
Speaker 4:  battery.

1613
01:31:41,345 --> 01:31:44,785
Speaker 5:  My dad just, you're all wrong, recently bought a Prius after spending

1614
01:31:44,785 --> 01:31:48,645
Speaker 5:  months looking for an EV because he just like, they just

1615
01:31:48,645 --> 01:31:52,285
Speaker 5:  couldn't find one that made sense and decided that in their lives at this

1616
01:31:52,285 --> 01:31:56,245
Speaker 5:  point, like the next car should be an electric car.

1617
01:31:56,245 --> 01:31:59,045
Speaker 5:  Yeah. The car right now should not be, and I think a lot of people are making

1618
01:31:59,045 --> 01:32:00,435
Speaker 5:  that decision.

1619
01:32:00,435 --> 01:32:03,265
Speaker 4:  Yeah. Also the new Prius, it doesn't look like an angry robot anymore.

1620
01:32:03,265 --> 01:32:04,985
Speaker 5:  No, it kind, it's kind of great.

1621
01:32:04,985 --> 01:32:08,635
Speaker 4:  It kind kinda looks great. Yeah. We'll see. All right.

1622
01:32:08,635 --> 01:32:10,785
Speaker 4:  Lightning round. What you got David?

1623
01:32:10,785 --> 01:32:14,565
Speaker 5:  So while we're talking about Apple TV plus soon to be augmented

1624
01:32:14,565 --> 01:32:18,485
Speaker 5:  by the purchase of TikTok, there was, there was a report

1625
01:32:18,485 --> 01:32:22,195
Speaker 5:  this week that Apple has been negotiating with

1626
01:32:22,195 --> 01:32:25,165
Speaker 5:  fifa, which is the, the governing body of soccer around the

1627
01:32:25,165 --> 01:32:28,905
Speaker 5:  world to do a new

1628
01:32:28,905 --> 01:32:32,315
Speaker 5:  global tournament exclusively on Apple tv.

1629
01:32:32,315 --> 01:32:36,255
Speaker 5:  Plus I find this fascinating for a bunch of reasons. One,

1630
01:32:36,255 --> 01:32:40,205
Speaker 5:  apple is like increasingly deep into the sports world. They have this

1631
01:32:40,205 --> 01:32:43,825
Speaker 5:  thing with Major League soccer that's going very well it seems in part because,

1632
01:32:43,825 --> 01:32:47,805
Speaker 5:  you know, lion O Messi decided to play for the MLS but the numbers

1633
01:32:47,805 --> 01:32:51,215
Speaker 5:  that have been thrown around are upwards of a billion dollars from

1634
01:32:51,215 --> 01:32:54,965
Speaker 5:  Apple to be the one to stream this tournament. Which is

1635
01:32:54,965 --> 01:32:58,565
Speaker 5:  like, we've spent a lot of time talking about Apple TV plus as kind of

1636
01:32:58,565 --> 01:33:02,325
Speaker 5:  a somewhere between sort of a

1637
01:33:02,325 --> 01:33:06,085
Speaker 5:  lark and a side project that it was never going to be really material to

1638
01:33:06,085 --> 01:33:09,445
Speaker 5:  Apple. It was just kind of a thing it did on the side in order to sell more

1639
01:33:09,445 --> 01:33:13,085
Speaker 5:  subscriptions to iCloud, right? Like that was always the play. This seems

1640
01:33:13,085 --> 01:33:16,445
Speaker 5:  to me to be the sort of thing that you only do if you're actually serious

1641
01:33:16,445 --> 01:33:20,235
Speaker 5:  about turning this into a real thing. And Apple is

1642
01:33:20,235 --> 01:33:24,205
Speaker 5:  just further and further and further into sports in a way that I

1643
01:33:24,205 --> 01:33:28,125
Speaker 5:  continue to find surprising and sort of fascinating. And they wanna

1644
01:33:28,125 --> 01:33:32,065
Speaker 5:  invent a completely new thing with some of the biggest

1645
01:33:32,065 --> 01:33:35,945
Speaker 5:  soccer clubs in the world, which would be huge and is immediately

1646
01:33:35,945 --> 01:33:39,585
Speaker 5:  the kind of thing that would draw potentially millions of new people to Apple

1647
01:33:39,585 --> 01:33:43,135
Speaker 5:  TV plus. But this is like there, there's no

1648
01:33:43,135 --> 01:33:45,885
Speaker 5:  indication, I think it was a New York Times story that first reported this,

1649
01:33:45,885 --> 01:33:49,365
Speaker 5:  that this is like a done deal, but they wanna do it next summer, which

1650
01:33:49,365 --> 01:33:52,685
Speaker 5:  means like, this is a big thing that could happen very quickly. And

1651
01:33:52,685 --> 01:33:56,665
Speaker 5:  like, I, I don't know, apple TV plus just continues to

1652
01:33:56,665 --> 01:33:59,525
Speaker 5:  be a bigger thing than I think I've given it credit for.

1653
01:33:59,525 --> 01:34:03,325
Speaker 6:  I think it kind of makes sense though right now for Apple to do it

1654
01:34:03,325 --> 01:34:06,645
Speaker 6:  because Hollywood is in a state of flux, right? Like, like

1655
01:34:06,645 --> 01:34:10,485
Speaker 6:  streaming is completely changing the game there. Everybody's trying to

1656
01:34:10,485 --> 01:34:14,275
Speaker 6:  figure out where the revenue streams are and the tech companies are

1657
01:34:14,275 --> 01:34:17,365
Speaker 6:  kind of leading the forefront. The tech Kuo companies are running Hollywood

1658
01:34:17,365 --> 01:34:21,165
Speaker 6:  in a way they haven't previously. And Apple is doing

1659
01:34:21,165 --> 01:34:24,605
Speaker 6:  it really, really well. It's a smaller play than everybody else, but it's

1660
01:34:24,605 --> 01:34:28,565
Speaker 6:  it's doing it intelligently and it's like, yeah, this, this makes sense for

1661
01:34:28,565 --> 01:34:32,265
Speaker 6:  them to go in and just like, take a couple of streaming services

1662
01:34:32,265 --> 01:34:35,765
Speaker 6:  out. Yeah. Just body a few with money and, and

1663
01:34:35,765 --> 01:34:39,525
Speaker 6:  then buy, snap up the, the dregs of that later, right?

1664
01:34:39,525 --> 01:34:41,765
Speaker 6:  Like make a deal with Skydance or whatever. But

1665
01:34:41,765 --> 01:34:45,565
Speaker 5:  If that's the play, apple could just walk into the offices of any

1666
01:34:45,565 --> 01:34:49,445
Speaker 5:  streaming service it wanted to and just write a check for its valuation

1667
01:34:49,445 --> 01:34:50,085
Speaker 5:  and then some. Yeah.

1668
01:34:50,085 --> 01:34:52,605
Speaker 6:  But they don't wanna do that. They wanna buy like they want, they want cheap

1669
01:34:52,605 --> 01:34:56,005
Speaker 6:  licenses and stuff like that. That's what runs these services. But

1670
01:34:56,005 --> 01:34:59,185
Speaker 5:  This is what I'm saying, a billion dollars to create a new soccer tournament

1671
01:34:59,185 --> 01:35:02,855
Speaker 5:  is not that thing. Like the MLS thing. I understood. That's a relatively

1672
01:35:02,855 --> 01:35:06,805
Speaker 5:  small, relatively safe bet. And they got to essentially take

1673
01:35:06,805 --> 01:35:10,565
Speaker 5:  over that whole project. This is a mu this is like negotiating for

1674
01:35:10,565 --> 01:35:14,445
Speaker 5:  NFL rights, which Apple like famously has not one because it became

1675
01:35:14,445 --> 01:35:15,435
Speaker 4:  Close for Sunday ticket.

1676
01:35:15,435 --> 01:35:18,845
Speaker 5:  Yeah. But it wanted, what has been reported is that it wanted like complete

1677
01:35:18,845 --> 01:35:21,365
Speaker 5:  control over this thing. And you're not getting that from the NFL and you're

1678
01:35:21,365 --> 01:35:23,785
Speaker 5:  not getting it from fifa and they're still willing to throw billions of dollars

1679
01:35:23,785 --> 01:35:24,705
Speaker 5:  at it. It's fascinating.

1680
01:35:24,705 --> 01:35:26,945
Speaker 6:  But this would drive subscriptions in a way.

1681
01:35:26,945 --> 01:35:27,405
Speaker 4:  Oh, for short

1682
01:35:27,405 --> 01:35:28,335
Speaker 5:  Is stick. Yeah.

1683
01:35:28,335 --> 01:35:30,305
Speaker 4:  Eddie Hugs smart. He's also huge sports

1684
01:35:30,305 --> 01:35:30,765
Speaker 5:  Fan. Yeah, he

1685
01:35:30,765 --> 01:35:34,665
Speaker 4:  Is. And he knows sports sort the stickiest thing. We'll, see, I

1686
01:35:34,665 --> 01:35:38,595
Speaker 4:  I'm, I I think Apple has to get good at broadcasting sports.

1687
01:35:38,595 --> 01:35:41,605
Speaker 4:  Yeah. If they're not great at it right now. Yeah. So the, the more they get

1688
01:35:41,605 --> 01:35:45,085
Speaker 4:  into it, the more they have to com. Does app, like, does Tim Cook want to

1689
01:35:45,085 --> 01:35:47,765
Speaker 4:  sit in Congress and talk about content moderation? I don't know. Does Tim

1690
01:35:47,765 --> 01:35:51,755
Speaker 4:  Cook wanna sit in front of a bunch of soccer fans and talk about penalties?

1691
01:35:51,755 --> 01:35:52,745
Speaker 4:  Like, I don't know about

1692
01:35:52,745 --> 01:35:53,365
Speaker 6:  Leader, he's

1693
01:35:53,365 --> 01:35:56,065
Speaker 5:  Issue for that. But does Tim Cook want to go like sit in a box at the World

1694
01:35:56,065 --> 01:35:58,065
Speaker 5:  Cup, like Yeah, absolutely.

1695
01:35:58,065 --> 01:36:01,525
Speaker 4:  That's true. All right. Crans. What? You got

1696
01:36:01,525 --> 01:36:04,385
Speaker 6:  Qualcomm. They're back baby. We'll see,

1697
01:36:04,385 --> 01:36:04,605
Speaker 4:  We

1698
01:36:04,605 --> 01:36:07,125
Speaker 12:  Say that immediate every once in while. Undercut Just immediate, immediate.

1699
01:36:07,125 --> 01:36:10,285
Speaker 6:  Undercut. Undercut. Just immediate. Yeah. So Qualcomm has announced,

1700
01:36:10,285 --> 01:36:13,985
Speaker 6:  they previously announced some new processors

1701
01:36:13,985 --> 01:36:17,485
Speaker 6:  and these are their kind of responses to the X 86

1702
01:36:17,485 --> 01:36:21,085
Speaker 6:  processors from Intel and a MD. This is meant to go in Windows

1703
01:36:21,085 --> 01:36:24,965
Speaker 6:  machines meant to compete with Apple. They're saying they're as

1704
01:36:24,965 --> 01:36:28,665
Speaker 6:  fast as the M three and it's gonna blow it out of the water.

1705
01:36:28,665 --> 01:36:32,555
Speaker 6:  Joanna Nees are our new laptop reviewer. Went and checked

1706
01:36:32,555 --> 01:36:35,935
Speaker 6:  some of them out in some very, very, very, very

1707
01:36:35,935 --> 01:36:39,885
Speaker 6:  controlled demos. And she was like, there could be something there. She

1708
01:36:39,885 --> 01:36:43,365
Speaker 6:  was saying it was slower than the M three in some cases faster in

1709
01:36:43,365 --> 01:36:44,045
Speaker 6:  others.

1710
01:36:44,045 --> 01:36:47,995
Speaker 5:  I mean, if it's even in the ballpark of the M three, that's a huge deal.

1711
01:36:47,995 --> 01:36:48,365
Speaker 5:  Yeah.

1712
01:36:48,365 --> 01:36:51,045
Speaker 6:  That's a huge deal. Right. And I think there's, there's some really interesting

1713
01:36:51,045 --> 01:36:53,965
Speaker 6:  stuff, particularly around architecture. They're not doing the big little

1714
01:36:53,965 --> 01:36:57,055
Speaker 6:  core deal that everybody else does, where they're like, these are performance

1715
01:36:57,055 --> 01:37:00,285
Speaker 6:  cores, these are efficiency cores. They're like, yeah, these are all performance

1716
01:37:00,285 --> 01:37:04,245
Speaker 6:  cores. Sure. 'cause they're just that efficient. Oh God, that was me doing

1717
01:37:04,245 --> 01:37:07,985
Speaker 6:  a Qualcomm impressions. Sorry. So

1718
01:37:07,985 --> 01:37:11,775
Speaker 6:  it's the, the Snapdragon X Elite was the ones previously announced

1719
01:37:11,775 --> 01:37:14,855
Speaker 6:  and now we have the Snapdragon X plus.

1720
01:37:14,855 --> 01:37:15,885
Speaker 4:  Oh good.

1721
01:37:15,885 --> 01:37:19,425
Speaker 6:  Which is slower the, because it's not elite.

1722
01:37:19,425 --> 01:37:21,755
Speaker 4:  They're gonna throw a premium in there. No one's gonna know what's going

1723
01:37:21,755 --> 01:37:22,235
Speaker 4:  on. Yeah. Yeah.

1724
01:37:22,235 --> 01:37:23,315
Speaker 6:  Nobody will know.

1725
01:37:23,315 --> 01:37:26,755
Speaker 5:  I appreciate that. When you, when you try to match Apple's performance, you

1726
01:37:26,755 --> 01:37:30,455
Speaker 5:  also try to match Apple's Insane name scheme. This is good.

1727
01:37:30,455 --> 01:37:34,235
Speaker 6:  And it's, it's all bad. They're all, they're all the names are bad, but we

1728
01:37:34,235 --> 01:37:36,475
Speaker 6:  don't know when. These are probably gonna come this year. We'll probably

1729
01:37:36,475 --> 01:37:40,275
Speaker 6:  start seeing 'em in some Windows devices this year. And I am really,

1730
01:37:40,275 --> 01:37:44,155
Speaker 6:  really curious to see it because like if Arm and Windows can work for

1731
01:37:44,155 --> 01:37:47,945
Speaker 6:  once, that would be huge. Yeah. But they famously kinda like

1732
01:37:47,945 --> 01:37:49,195
Speaker 6:  screwed it up the last time.

1733
01:37:49,195 --> 01:37:51,715
Speaker 5:  So, and the time before that. And the time before that. And

1734
01:37:51,715 --> 01:37:52,435
Speaker 6:  The time before that. Yeah, the time

1735
01:37:52,435 --> 01:37:53,215
Speaker 5:  Before that.

1736
01:37:53,215 --> 01:37:57,065
Speaker 6:  That's why I immediately undercut Qualcomm's like back at it again

1737
01:37:57,065 --> 01:37:58,225
Speaker 6:  at the Krispy Kreme.

1738
01:37:58,225 --> 01:38:02,125
Speaker 5:  The Microsoft event is May 20th or 21st or something. And they're gonna

1739
01:38:02,125 --> 01:38:05,985
Speaker 5:  announce new surfaces that we think by all indications

1740
01:38:05,985 --> 01:38:08,365
Speaker 5:  are going to run these things. So we're gonna, we're gonna see this sooner

1741
01:38:08,365 --> 01:38:11,445
Speaker 5:  rather than later. But Tom's been reporting about how excited Microsoft

1742
01:38:11,445 --> 01:38:15,435
Speaker 5:  is. Qualcomm seems very excited. This could be something.

1743
01:38:15,435 --> 01:38:15,725
Speaker 5:  Well,

1744
01:38:15,725 --> 01:38:19,585
Speaker 6:  We've got Compex coming in. That's May 31st. Oh yeah, my birthday.

1745
01:38:19,585 --> 01:38:19,905
Speaker 6:  Hey.

1746
01:38:19,905 --> 01:38:23,085
Speaker 5:  Oh, it's gonna be like laptop explosion here. That's gonna be

1747
01:38:23,085 --> 01:38:26,245
Speaker 6:  Great. Yeah. So, so we're gonna get a lot of laptops soon. Yeah. And I suspect

1748
01:38:26,245 --> 01:38:29,405
Speaker 6:  a lot of them are gonna have these, these new processors in them. Will these

1749
01:38:29,405 --> 01:38:30,715
Speaker 6:  processors be good?

1750
01:38:30,715 --> 01:38:33,725
Speaker 4:  It's a big move away from Intel if there's a lot of laptops with these weird

1751
01:38:33,725 --> 01:38:35,245
Speaker 4:  tracking and chips in 'em. We'll see. Yeah.

1752
01:38:35,245 --> 01:38:38,725
Speaker 6:  Well, we'll also have to see. 'cause historically the laptop makers don't

1753
01:38:38,725 --> 01:38:42,545
Speaker 6:  like to ship the, the stuff besides Intel be

1754
01:38:42,545 --> 01:38:46,445
Speaker 6:  to, to reviewers to check out because they want you to check out the thing

1755
01:38:46,445 --> 01:38:49,795
Speaker 6:  that people actually buy. And that's usually the Intel products. Yeah. So

1756
01:38:49,795 --> 01:38:51,465
Speaker 6:  it's, it's gonna be a fun one.

1757
01:38:51,465 --> 01:38:55,435
Speaker 4:  All right. Mine is very simple. So now has a new app. Looks

1758
01:38:55,435 --> 01:38:59,275
Speaker 4:  very good on mobile. They've sort of gotten rid of all the tabs and it's

1759
01:38:59,275 --> 01:39:02,235
Speaker 4:  just all just widgets. It's cool. They said it's gonna be faster. It's coming

1760
01:39:02,235 --> 01:39:04,435
Speaker 4:  out May 7th. We'll see if the mobile app is faster. This is not the thing

1761
01:39:04,435 --> 01:39:07,195
Speaker 4:  I actually wanna talk about. They are getting rid of their desktop apps,

1762
01:39:07,195 --> 01:39:10,615
Speaker 4:  which they've had forever. Oh wow. On Mac and Windows. And they're going

1763
01:39:10,615 --> 01:39:14,155
Speaker 4:  all to web apps and you can now, because it's web app, you can control your

1764
01:39:14,155 --> 01:39:17,635
Speaker 4:  Sonos from anywhere, which is interesting. I'm just pointing out that the

1765
01:39:17,635 --> 01:39:21,515
Speaker 4:  move to distribute applications on desktop computers to the

1766
01:39:21,515 --> 01:39:25,265
Speaker 4:  web instead of in native binaries is like

1767
01:39:25,265 --> 01:39:29,035
Speaker 4:  full speed ahead. Like it's over like, you know,

1768
01:39:29,035 --> 01:39:31,875
Speaker 4:  Dylan Field, the CO of Figma was like, why would you distribute an app on

1769
01:39:31,875 --> 01:39:34,755
Speaker 4:  an desktop computer any other way except the web. And like yeah, there's

1770
01:39:34,755 --> 01:39:36,875
Speaker 4:  electronic and some other stuff where you package it up and it like looks

1771
01:39:36,875 --> 01:39:40,475
Speaker 4:  native and da da da. But I saw this and I was like, oh, this is just ha

1772
01:39:40,475 --> 01:39:44,395
Speaker 4:  like this is a huge shift in computers that is like reaching

1773
01:39:44,395 --> 01:39:48,235
Speaker 4:  a point where it's, it's like no one even talks about it. Like

1774
01:39:48,235 --> 01:39:51,955
Speaker 4:  it just assumed that if you're gonna make a new app for desktop computers,

1775
01:39:51,955 --> 01:39:55,715
Speaker 4:  what you are actually shipping as a web app. Yeah. And I, the thing I point

1776
01:39:55,715 --> 01:39:59,675
Speaker 4:  to is the Vision Pro, the high end of computers, the cutting edge of

1777
01:39:59,675 --> 01:40:03,635
Speaker 4:  what a computer can be mounted directly to your face. All of the most

1778
01:40:03,635 --> 01:40:07,515
Speaker 4:  interesting apps was on the Vision Pro, the Netflix app, the YouTube app,

1779
01:40:07,515 --> 01:40:09,665
Speaker 4:  whatever are just custom web browsers.

1780
01:40:09,665 --> 01:40:12,935
Speaker 5:  Yeah. We really called that. by the way. I feel like we, we deserve credit

1781
01:40:12,935 --> 01:40:16,275
Speaker 5:  for saying over and over that the thing that the only thing that might save

1782
01:40:16,275 --> 01:40:20,175
Speaker 5:  the Vision Pro is, is web apps. Yeah. That has been absolutely correct.

1783
01:40:20,175 --> 01:40:23,935
Speaker 4:  Anyway, I'm excited for the news thing. 'cause the old app is Indeed Slow.

1784
01:40:23,935 --> 01:40:27,695
Speaker 5:  Wasn't the old app supposed to fix the fact that the app before that

1785
01:40:27,695 --> 01:40:29,135
Speaker 5:  was slow and bad?

1786
01:40:29,135 --> 01:40:31,995
Speaker 4:  No. So they, this is like a long story. We had Patrick Spence on the show,

1787
01:40:31,995 --> 01:40:34,265
Speaker 4:  I think to explain himself to us when they did, I know

1788
01:40:34,265 --> 01:40:34,715
Speaker 5:  They had the

1789
01:40:34,715 --> 01:40:38,275
Speaker 4:  Old, old platform, which they now call S one. Right. Which was like

1790
01:40:38,275 --> 01:40:41,565
Speaker 4:  ancient. And they re-architected everything for the future and to support

1791
01:40:41,565 --> 01:40:45,315
Speaker 4:  Atmos and all this other stuff they wanted to do. And that's

1792
01:40:45,315 --> 01:40:49,215
Speaker 4:  called S two. So that was just an architecture update. It was not a,

1793
01:40:49,215 --> 01:40:50,355
Speaker 4:  we need to make it in faster

1794
01:40:50,355 --> 01:40:53,885
Speaker 5:  Update. Got it. So they kept their slow app but made it work on the new

1795
01:40:53,885 --> 01:40:54,395
Speaker 5:  architecture.

1796
01:40:54,395 --> 01:40:57,005
Speaker 4:  Yeah. There's a lot of arguments about like what the best way to run Sonos

1797
01:40:57,005 --> 01:41:00,745
Speaker 4:  is now. Like do you want run Sonos net, which is like a custom 2.4 gigs network.

1798
01:41:00,745 --> 01:41:04,125
Speaker 4:  You just wanna run everything on wifi, which Sonos says you should do good

1799
01:41:04,125 --> 01:41:06,365
Speaker 4:  times in these, in these subreddits.

1800
01:41:06,365 --> 01:41:10,105
Speaker 5:  I just use Spotify Connect and it works fine. Yeah,

1801
01:41:10,105 --> 01:41:11,565
Speaker 4:  That's fine.

1802
01:41:11,565 --> 01:41:15,205
Speaker 5:  I wish I had a more complicated, interesting idea. Not super works. Yeah.

1803
01:41:15,205 --> 01:41:17,965
Speaker 5:  I never ever touched the Sonos app and I'm very happy about it. Air, I've

1804
01:41:17,965 --> 01:41:20,885
Speaker 4:  Used Airplay for years now. It's great. It works just fine. And you can group

1805
01:41:20,885 --> 01:41:24,405
Speaker 4:  things in airplay. You can group unlike Speakers in Airplay, which is a very

1806
01:41:24,405 --> 01:41:27,925
Speaker 4:  interesting, but I don't know, I still got a soft shot for it. All right.

1807
01:41:27,925 --> 01:41:31,845
Speaker 4:  That's, we are way over. We've touched on everything from web apps to

1808
01:41:31,845 --> 01:41:35,605
Speaker 4:  the future of Free Speech in America. Busy week to, to

1809
01:41:35,605 --> 01:41:38,325
Speaker 4:  whatever's going on with Tesla. It's a lot, it was a big, it was a busy week

1810
01:41:38,325 --> 01:41:41,645
Speaker 4:  and we got more of 'em coming. 'cause we are, we are head first into developer

1811
01:41:41,645 --> 01:41:45,065
Speaker 4:  conference season now. Yep. All right. I'm gonna start a GoFundMe for this

1812
01:41:45,065 --> 01:41:47,885
Speaker 4:  Oola iPad. You can hit me up. I'm so true.

1813
01:41:47,885 --> 01:41:50,335
Speaker 4:  Not

1814
01:41:50,335 --> 01:41:53,195
Speaker 5:  Tell Alex all your favorite things about your Tesla, if you have one. Yeah,

1815
01:41:53,195 --> 01:41:54,225
Speaker 5:  she'd love to hear 'em. Oh, I'm

1816
01:41:54,225 --> 01:41:56,265
Speaker 4:  Super excited. We need to say excited. Utterly forgot to say this because

1817
01:41:56,265 --> 01:42:00,205
Speaker 4:  we're so bad at this. We won Webby Awards. Thank you so much

1818
01:42:00,205 --> 01:42:02,625
Speaker 4:  for all the people who voted for us and the people's choice of the Vergecast.

1819
01:42:02,625 --> 01:42:06,305
Speaker 4:  Thank you. The judges who gave the, the same award to the Dakota

1820
01:42:06,305 --> 01:42:10,265
Speaker 4:  podcast. We, we really do appreciate it. It's, it's very cool that

1821
01:42:10,265 --> 01:42:13,345
Speaker 4:  we have been doing the show for as long as we're do doing it and people stroll

1822
01:42:13,345 --> 01:42:17,305
Speaker 4:  voting for us for these awards. I truly appreciate it. Sponsor

1823
01:42:42,185 --> 01:42:48,955
Speaker 7:  week.

