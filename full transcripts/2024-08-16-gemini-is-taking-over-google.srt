1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: aa829817-e125-4015-a78b-a6a5cbf7b007
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/6305909932565309563/1558328392375371473/s93290-US-6182s-1723821578.mp3
Description: The Verge's Nilay Patel, David Pierce, and Alex Cranz discuss AI tools announced at this weeks Pixel 9 event, Nilay's TV competition, tech regulatory news, and more.

2
00:01:47,485 --> 00:01:51,115
Speaker 3:  Hello and welcome to Our Chest, the flagship podcast of our fancy new

3
00:01:51,115 --> 00:01:53,115
Speaker 3:  studio. Look at this guys.

4
00:01:54,145 --> 00:01:55,515
Speaker 1:  It's sick. It's so fancy.

5
00:01:55,995 --> 00:01:59,195
Speaker 4:  I wish I was there to see it in person. Does it smell nice?

6
00:01:59,695 --> 00:02:03,075
Speaker 3:  You know, many times this studio smells like weed when I walk into it, when

7
00:02:03,075 --> 00:02:06,355
Speaker 3:  Alex and I have sat down to record this, the show. Yeah, many times we've

8
00:02:06,355 --> 00:02:09,075
Speaker 3:  commented it smells like weed in here. Yeah, we don't know if that's from

9
00:02:09,975 --> 00:02:13,915
Speaker 3:  our colleagues@vox.com. We don't know if that is from Liam.

10
00:02:14,375 --> 00:02:17,395
Speaker 3:  We don't know if that is from the other people of the podcast here. But today

11
00:02:17,395 --> 00:02:21,035
Speaker 3:  it does not smell like weed. It smells fresh and new. It's good.

12
00:02:21,335 --> 00:02:23,715
Speaker 3:  If you're listening to the show, it's gonna be the same show. It was just

13
00:02:23,815 --> 00:02:27,275
Speaker 3:  our, the space that we recorded has been dramatically

14
00:02:27,315 --> 00:02:31,035
Speaker 3:  upgraded. David was gone for two weeks and they, our amazing

15
00:02:31,035 --> 00:02:34,155
Speaker 3:  studio team took the time to, to rebuild the thing while we were kind of

16
00:02:34,155 --> 00:02:37,275
Speaker 3:  out and about and traveling and recording remotely. and it's just real fancy

17
00:02:37,335 --> 00:02:37,675
Speaker 3:  in here.

18
00:02:37,815 --> 00:02:41,595
Speaker 5:  It does look awesome and truly, even if you're just listening like you won't

19
00:02:41,595 --> 00:02:43,835
Speaker 5:  see it, but like the vibes will be better. It's very moody, you know what

20
00:02:43,835 --> 00:02:47,635
Speaker 5:  I mean? It's like the Neli is like a happier, more

21
00:02:47,635 --> 00:02:50,115
Speaker 5:  optimistic person now that we're in this studio.

22
00:02:50,675 --> 00:02:54,075
Speaker 3:  I mean, I got a giant TV behind me that's the largest frame TV they make,

23
00:02:54,075 --> 00:02:54,835
Speaker 3:  ladies and gentlemen.

24
00:02:56,495 --> 00:03:00,085
Speaker 3:  And there's like a hangout zone, like where sidekicks on podcasts

25
00:03:00,305 --> 00:03:00,525
Speaker 3:  go.

26
00:03:01,385 --> 00:03:05,205
Speaker 5:  Oh, the like retired NFL player who just like only says two things in every

27
00:03:05,205 --> 00:03:07,565
Speaker 5:  episode. Yeah, I love that. That's the job I want.

28
00:03:07,875 --> 00:03:11,805
Speaker 3:  Look, the AJ Hawk corner is right over there. If you're a Pat Maxi

29
00:03:11,805 --> 00:03:11,965
Speaker 3:  fan

30
00:03:11,965 --> 00:03:12,405
Speaker 5:  That I

31
00:03:12,405 --> 00:03:12,685
Speaker 3:  Was thinking,

32
00:03:14,945 --> 00:03:18,125
Speaker 3:  I'm gonna do every segment of today's show from a different spot in this

33
00:03:18,125 --> 00:03:21,805
Speaker 3:  room. But it is beautiful. It's very nice. It's funny, you know, we share

34
00:03:21,825 --> 00:03:25,725
Speaker 3:  the studio with other Vox Media podcast network shows. So Andre, I

35
00:03:25,945 --> 00:03:29,925
Speaker 3:  and Evan Turner record in here. And then we have a new show with Megan

36
00:03:29,955 --> 00:03:32,525
Speaker 3:  Rapinoe and Sue Bird that also records in here. And the first time I saw

37
00:03:32,525 --> 00:03:35,325
Speaker 3:  pictures of it was all set up for them. And I was like, where's our game

38
00:03:35,325 --> 00:03:39,085
Speaker 3:  cube? Don't worry. It turns out they just changed the studio

39
00:03:39,305 --> 00:03:40,725
Speaker 3:  around for every show.

40
00:03:42,365 --> 00:03:45,445
Speaker 5:  I do think though, we should find a way to anchor our webby to the shelves

41
00:03:45,905 --> 00:03:49,765
Speaker 5:  so that no one can get rid of our webby. Anytime you do a podcast, you'll

42
00:03:49,765 --> 00:03:51,765
Speaker 5:  see The, Verge cast's webby. That's, those are the rules. I

43
00:03:51,765 --> 00:03:55,445
Speaker 3:  Think that's, I think our YouTube play button is permanently matched all

44
00:03:55,445 --> 00:03:59,245
Speaker 3:  over there. Oh, there go. So if you are an Ex NFL player sidekick, you know,

45
00:03:59,425 --> 00:04:03,245
Speaker 3:  we have a million subscribers. You know it in your heart. You gotta sit under

46
00:04:03,245 --> 00:04:06,405
Speaker 3:  that. That's the mark everybody. Forever.

47
00:04:07,085 --> 00:04:09,845
Speaker 3:  Anyway, I'm your friend Eli. Welcome. David. Pierce is back from vacation.

48
00:04:09,845 --> 00:04:10,405
Speaker 3:  Welcome David.

49
00:04:10,665 --> 00:04:14,285
Speaker 5:  Hi. I picked the worst two weeks of all time to be gone, but I'm very happy

50
00:04:14,285 --> 00:04:14,485
Speaker 5:  to be

51
00:04:14,485 --> 00:04:16,805
Speaker 3:  Back. Yeah, nothing happened while you were on vacation. No.

52
00:04:16,805 --> 00:04:20,645
Speaker 5:  Including not the like culmination of a trial that I covered for months and

53
00:04:20,645 --> 00:04:22,885
Speaker 5:  cared deeply about. and it seems very important to the end of the internet.

54
00:04:22,885 --> 00:04:24,925
Speaker 5:  Like, yeah, super chill. Really.

55
00:04:25,025 --> 00:04:27,965
Speaker 3:  Hey, does anybody know anything about the search engine? Neva? Oh, I guess

56
00:04:27,985 --> 00:04:30,685
Speaker 3:  the guy who wrote the profile of it isn't here at all. Yeah,

57
00:04:30,995 --> 00:04:34,285
Speaker 5:  Real bummer. I only reported on them for like a year and a half and

58
00:04:34,665 --> 00:04:37,565
Speaker 5:  didn't get to talk about that at the end. But the good news is that case

59
00:04:37,585 --> 00:04:41,005
Speaker 5:  is gonna go on for six to seven more decades, so Yeah. Yeah. We'll have more

60
00:04:41,005 --> 00:04:41,885
Speaker 5:  chances. It'll be all right.

61
00:04:41,915 --> 00:04:44,965
Speaker 3:  Yeah, there's a long period. And then Alex, you were on Las Rege, you've

62
00:04:44,965 --> 00:04:48,805
Speaker 3:  been on vacation and then you immediately went away to cover The Pixel event

63
00:04:49,065 --> 00:04:49,925
Speaker 3:  in San Francisco.

64
00:04:50,195 --> 00:04:53,765
Speaker 4:  Yeah, I'm, I'm currently on, on the West Coast and not in the room with you

65
00:04:53,765 --> 00:04:57,685
Speaker 4:  otherwise. So we're gonna use a Pixel to just do the add me feature and put

66
00:04:57,685 --> 00:05:00,805
Speaker 4:  me in there with you. But, but otherwise it's, it's a good time out here.

67
00:05:01,235 --> 00:05:03,565
Speaker 4:  It's very nice temperature wise. Yeah.

68
00:05:03,745 --> 00:05:06,605
Speaker 3:  The theme of this episode is can you believe your lying eyes and the answer

69
00:05:07,415 --> 00:05:10,845
Speaker 3:  fully, fully? No. So let's start with The. Pixel. There's a lot to talk about.

70
00:05:10,845 --> 00:05:13,445
Speaker 3:  There's there always The Pixel event, which you guys, David, I think you

71
00:05:13,445 --> 00:05:17,045
Speaker 3:  covered a little bit on the Tuesday show. Yep. I want to talk about TVs.

72
00:05:17,045 --> 00:05:20,645
Speaker 3:  So I love talking about TVs. So, so a lot of gadgets to open the show. Then

73
00:05:20,645 --> 00:05:24,285
Speaker 3:  we got a bunch of just stuff in the app store in the EU

74
00:05:24,355 --> 00:05:27,165
Speaker 3:  happening, and then of course we have a lightning round,

75
00:05:28,385 --> 00:05:31,005
Speaker 3:  the deeply controversial lightning round.

76
00:05:31,565 --> 00:05:34,245
Speaker 5:  I can't believe I left. And you still didn't get the lightning round sponsored,

77
00:05:34,245 --> 00:05:37,565
Speaker 5:  like that's, I wanted to come back from vacation. And you were like, congratulations,

78
00:05:37,565 --> 00:05:41,405
Speaker 5:  David. Here is the lightning round yacht that we all bought. We did it, we

79
00:05:41,405 --> 00:05:43,245
Speaker 4:  Spent the money actually on the set. I've

80
00:05:43,245 --> 00:05:46,725
Speaker 3:  Gotten all the way to, in my head, leaving the various

81
00:05:47,105 --> 00:05:50,085
Speaker 3:  Vox Media corporate meetings that I have to go to with like,

82
00:05:50,875 --> 00:05:54,205
Speaker 3:  what if I ended every meeting with, don't talk to me until the Lightning

83
00:05:54,205 --> 00:05:55,005
Speaker 3:  Round is sponsored.

84
00:05:56,745 --> 00:06:00,645
Speaker 3:  I'm not sure this would go well. I'm not sure that it would

85
00:06:00,875 --> 00:06:04,805
Speaker 3:  achieve any goals really, or even my continued employment, but rest

86
00:06:04,825 --> 00:06:06,125
Speaker 3:  assure I've thought about it.

87
00:06:07,785 --> 00:06:08,725
Speaker 4:  You feel really cool.

88
00:06:09,075 --> 00:06:12,245
Speaker 3:  Yeah. Like why are you talking to me with an unsponsored?

89
00:06:12,805 --> 00:06:13,085
Speaker 3:  Yeah,

90
00:06:14,025 --> 00:06:16,885
Speaker 4:  You sachet out just like a little scarf.

91
00:06:17,725 --> 00:06:21,565
Speaker 3:  Yeah. This is what I think about my spare time is how to get

92
00:06:21,565 --> 00:06:25,445
Speaker 3:  myself hired. Okay. Let's talk about The Pixel. The Pixel itself. David,

93
00:06:25,445 --> 00:06:28,765
Speaker 3:  you talked about on the Tuesday show with everybody, there's like two parts

94
00:06:28,765 --> 00:06:32,725
Speaker 3:  of The Pixel event, though that I think are kind of important. One was the

95
00:06:32,775 --> 00:06:36,685
Speaker 3:  phone, and then the second is that the phone wasn't introduced

96
00:06:36,695 --> 00:06:40,645
Speaker 3:  until like 20 minutes into the event because what

97
00:06:40,645 --> 00:06:44,325
Speaker 3:  it really was was Rick Oslo who now runs

98
00:06:44,555 --> 00:06:48,125
Speaker 3:  Android and Pixel, talking about Android

99
00:06:48,645 --> 00:06:52,445
Speaker 3:  becoming the platform for Google's AI ambitions and

100
00:06:52,475 --> 00:06:56,045
Speaker 3:  even showing a bunch of AI features on Samsung phones. And I,

101
00:06:56,045 --> 00:06:59,165
Speaker 3:  there's something there that feels very worth talking about to me.

102
00:06:59,545 --> 00:07:03,285
Speaker 4:  The the what You mean the fact that we saw a Samsung phone and a Motorola

103
00:07:03,285 --> 00:07:05,445
Speaker 4:  phone before we saw a Pixel phone at The

104
00:07:05,445 --> 00:07:07,125
Speaker 3:  Pixel. Yeah. That's the simpler way of putting it. I think

105
00:07:09,355 --> 00:07:13,125
Speaker 3:  it's weird, right? There's something to that that I think is really interesting.

106
00:07:14,195 --> 00:07:18,085
Speaker 5:  It's weird and it isn't like it's, it's weird that

107
00:07:18,085 --> 00:07:21,885
Speaker 5:  it's not weird is actually where I'm at with this because like, there,

108
00:07:21,885 --> 00:07:25,325
Speaker 5:  there are three things going on here, right? One is that Rick Oslo

109
00:07:25,645 --> 00:07:29,605
Speaker 5:  oversees Android and Pixel, and that is a very

110
00:07:29,675 --> 00:07:33,565
Speaker 5:  hard job. We've talked about this, that for years Google

111
00:07:33,665 --> 00:07:37,045
Speaker 5:  was like, we have a very hard firewall between our own hardware efforts and

112
00:07:37,105 --> 00:07:41,085
Speaker 5:  our partner ecosystem with Android. Now it's just literally

113
00:07:41,105 --> 00:07:44,725
Speaker 5:  the same dude in charge of it. And that is a, that's a complicated thing

114
00:07:44,725 --> 00:07:48,685
Speaker 5:  to do, especially because for Google, the vast majority of everything

115
00:07:48,685 --> 00:07:52,205
Speaker 5:  that matters about Android does not happen on pixel phones, right? So for

116
00:07:52,205 --> 00:07:55,765
Speaker 5:  Google to come out and say, look, a Samsung phone that does all this stuff

117
00:07:55,865 --> 00:07:59,325
Speaker 5:  is purely just a recognition of what actually matters to Google, which is

118
00:07:59,385 --> 00:08:02,405
Speaker 5:  the Android business, not The Pixel business. Like that is just the fact

119
00:08:02,405 --> 00:08:06,165
Speaker 5:  of the matter. The other thing is, I think

120
00:08:06,325 --> 00:08:10,165
Speaker 5:  Google thinks AI as a thing and Gemini as a thing is

121
00:08:10,165 --> 00:08:13,485
Speaker 5:  more important than all of that, right? Like that is the big bet. So you

122
00:08:13,485 --> 00:08:15,965
Speaker 5:  have to lead with Gemini and you have to lead with Android and then like

123
00:08:17,175 --> 00:08:21,135
Speaker 5:  a while later, show everybody the phone that you made. And then if

124
00:08:21,135 --> 00:08:24,815
Speaker 5:  you, if you also believe as I, as I do, and I think as Google does that the

125
00:08:25,295 --> 00:08:28,735
Speaker 5:  hardware just exists in service of the software which exists in service of

126
00:08:28,735 --> 00:08:32,615
Speaker 5:  the ai. Like, it, it all ladders up. So it's weird

127
00:08:32,685 --> 00:08:36,655
Speaker 5:  that Google ostensibly launched a bunch of gadgets in what was

128
00:08:36,655 --> 00:08:40,455
Speaker 5:  not at all a gadget launch, but like increasingly, this was

129
00:08:40,455 --> 00:08:43,615
Speaker 5:  now two days ago as we're recording this, like it wasn't really a gadget

130
00:08:43,615 --> 00:08:47,375
Speaker 5:  launch. Like they launched some gadgets, but the main most

131
00:08:47,375 --> 00:08:51,095
Speaker 5:  important thing they talked about was not the gadgets, which is very strange.

132
00:08:51,485 --> 00:08:55,285
Speaker 4:  Yeah. It felt more like an io. I mean, not not in the room. It, it

133
00:08:55,285 --> 00:08:59,125
Speaker 4:  felt like a pixel event in the room, but the content felt like an

134
00:08:59,345 --> 00:09:03,165
Speaker 4:  IO keynote more than a a Pixel event. 'cause it was just, yeah,

135
00:09:03,165 --> 00:09:06,165
Speaker 4:  we're gonna talk about all these really great features that You can now use

136
00:09:06,385 --> 00:09:09,965
Speaker 4:  AI to generate adorable animals. And Kiki Palmer's here.

137
00:09:10,245 --> 00:09:10,525
Speaker 3:  Yeah,

138
00:09:10,525 --> 00:09:14,445
Speaker 5:  The Kiki Palmer thing. I'm still, I got nothing on on she there. What Kiki,

139
00:09:14,445 --> 00:09:18,325
Speaker 5:  she's there like between the Kiki Palmer thing here and the Sydney Sweeney

140
00:09:18,325 --> 00:09:21,125
Speaker 5:  thing at the facility. Can we just stop with the really awkward celebrity

141
00:09:21,225 --> 00:09:25,205
Speaker 5:  cameos? Nobody has fun. It's good for them. They get paid. That's

142
00:09:25,205 --> 00:09:28,805
Speaker 3:  Great. I say triple down more celebrity cames

143
00:09:28,915 --> 00:09:32,485
Speaker 3:  more random. Neil Patrick Harris at an Apple event.

144
00:09:32,675 --> 00:09:36,005
Speaker 3:  Just get out there, just whoever it is. All right. It's gonna

145
00:09:36,025 --> 00:09:39,805
Speaker 4:  Be Chris Evans at the Apple event. Let, let's, or, or Scar Joe.

146
00:09:39,825 --> 00:09:43,685
Speaker 4:  But no, like Sydnee Sweeney looked like a hostage. Kiki Palmer, like she

147
00:09:43,685 --> 00:09:44,365
Speaker 4:  got to move around.

148
00:09:45,225 --> 00:09:47,565
Speaker 3:  Hey, set the celebrities free. Yeah,

149
00:09:47,895 --> 00:09:50,365
Speaker 4:  Don't, don't just make him sit in a chair in awkwardly wave.

150
00:09:50,545 --> 00:09:53,245
Speaker 3:  She was there sort of at the very end, right? Like she was just there to

151
00:09:53,245 --> 00:09:55,285
Speaker 3:  be like, AI is great and there she

152
00:09:55,285 --> 00:09:56,285
Speaker 4:  Like Kool-Aid manned in

153
00:09:56,595 --> 00:09:57,525
Speaker 5:  Basically. Yeah.

154
00:09:57,905 --> 00:10:01,085
Speaker 3:  But the, but the thing you're discussing more broadly, which is

155
00:10:02,065 --> 00:10:05,965
Speaker 3:  Google believes it has a huge distribution advantage for,

156
00:10:05,985 --> 00:10:09,845
Speaker 3:  its for Gemini. That distribution advantage is Android

157
00:10:10,585 --> 00:10:14,285
Speaker 3:  and they're gonna put it everywhere and embed it into all of their

158
00:10:14,445 --> 00:10:17,165
Speaker 3:  platforms and services. We, Alex, you're right, we did see that coming in

159
00:10:17,185 --> 00:10:21,085
Speaker 3:  io. That's basically what they said. Yeah. And Rick's message was,

160
00:10:21,545 --> 00:10:25,245
Speaker 3:  now this stuff is here, it's shipping like You can get it. And then, you

161
00:10:25,245 --> 00:10:28,565
Speaker 3:  know, they showed it on a bunch of Samsung Motorola phones and then they're

162
00:10:28,565 --> 00:10:32,485
Speaker 3:  like, and here's The Pixel and then here's a tiny bit of stuff

163
00:10:32,485 --> 00:10:35,845
Speaker 3:  The Pixel can do that the others can't do, which is the Add me feature and

164
00:10:35,845 --> 00:10:39,525
Speaker 3:  the photos and all that, right? Yeah. But there's a sense that Google knows

165
00:10:39,785 --> 00:10:43,445
Speaker 3:  it is better at distributing AI than any of its competitors.

166
00:10:43,585 --> 00:10:47,525
Speaker 3:  It took a lot of digs at Apple, for example. Just secret,

167
00:10:47,985 --> 00:10:51,525
Speaker 3:  not even secret, just like quiet sideswipes

168
00:10:51,785 --> 00:10:55,525
Speaker 3:  at Apple throughout this whole event. Yeah, we're available in all the languages.

169
00:10:55,595 --> 00:10:59,365
Speaker 3:  Apple's intelligence isn't, we don't have to send your data to a third party.

170
00:11:00,275 --> 00:11:04,165
Speaker 3:  Apple's gonna send some of your stuff to open ai like down the line.

171
00:11:04,585 --> 00:11:08,485
Speaker 3:  It was, Google was just reinforcing that it is

172
00:11:08,645 --> 00:11:12,525
Speaker 3:  building the ai, like it has it, it controls it, it runs in the

173
00:11:12,525 --> 00:11:15,365
Speaker 3:  cloud and the best way to get it is through Android.

174
00:11:16,675 --> 00:11:19,235
Speaker 3:  I just don't know if that's gonna get anybody to switch from an iPhone. Like

175
00:11:19,335 --> 00:11:22,635
Speaker 3:  that's actually the thing that I think is the most interesting here. That

176
00:11:22,635 --> 00:11:25,835
Speaker 3:  they're like, Android is the place where you get your AI and everyone's kind

177
00:11:25,835 --> 00:11:28,065
Speaker 3:  of like, okay, now what?

178
00:11:28,415 --> 00:11:32,145
Speaker 4:  Well, I think, I think Gemini Live is probably a good example of that. 'cause

179
00:11:32,145 --> 00:11:36,065
Speaker 4:  that's coming to iOS later this year and that they spent a lot

180
00:11:36,065 --> 00:11:39,385
Speaker 4:  of time on Gemini live. It felt like that's, that's their like answer to

181
00:11:39,385 --> 00:11:43,305
Speaker 4:  chat GT's, voice assistant. And yeah,

182
00:11:43,365 --> 00:11:46,225
Speaker 4:  it really just felt like this moment of, okay, no, you don't actually just

183
00:11:46,225 --> 00:11:50,145
Speaker 4:  need to be on, on an Android device. And I, I personally, I just

184
00:11:50,145 --> 00:11:53,610
Speaker 4:  kept thinking of the fact that just last week they found out that they, something's

185
00:11:53,610 --> 00:11:56,965
Speaker 4:  gonna happen with Google and one of their biggest revenue drivers is their

186
00:11:56,965 --> 00:12:00,045
Speaker 4:  relationship with the iPhone. And so now it feels like their, their phone

187
00:12:00,595 --> 00:12:04,405
Speaker 4:  ecosystem is more important than ever and we just didn't

188
00:12:04,405 --> 00:12:08,325
Speaker 4:  hear a single thing about it besides ai. So yeah, it is a, and it is a little

189
00:12:08,325 --> 00:12:10,605
Speaker 4:  weird that everything hinges on this AI now.

190
00:12:10,985 --> 00:12:14,965
Speaker 3:  So in all the big AI companies have been saying is that they think AI

191
00:12:14,965 --> 00:12:18,945
Speaker 3:  is a platform shift. You can interpret that a lot of ways.

192
00:12:19,095 --> 00:12:23,025
Speaker 3:  Like I, I tried to get Sundar Phai to explain what that means to me. IS

193
00:12:23,025 --> 00:12:25,505
Speaker 5:  Trying to get, Pichai said it's as big as fire. I don't know that there's

194
00:12:25,505 --> 00:12:29,025
Speaker 5:  that many ways to interpret. That's just the one really. Yeah,

195
00:12:29,175 --> 00:12:32,945
Speaker 3:  He's, yeah. I mean, but it's true. But I I what the way I have interpreted

196
00:12:33,345 --> 00:12:37,105
Speaker 3:  platform shift is people are gonna use computers in a

197
00:12:37,105 --> 00:12:40,225
Speaker 3:  different way and that will create many more opportunities to build products

198
00:12:40,225 --> 00:12:44,185
Speaker 3:  and services, right? And, if you look back at the history of platform shifts,

199
00:12:44,605 --> 00:12:48,305
Speaker 3:  you go from, I don't know, dos and text-based

200
00:12:48,535 --> 00:12:52,385
Speaker 3:  computing to mice and keyboards, and then you go

201
00:12:52,535 --> 00:12:55,705
Speaker 3:  from local applications to the web and then

202
00:12:56,485 --> 00:12:59,985
Speaker 3:  you go to touchscreens on phones, right? Yeah. Those are the platforms.

203
00:13:00,255 --> 00:13:03,305
Speaker 3:  Yeah. If You can think of another way to think about the word platform shift,

204
00:13:03,725 --> 00:13:07,425
Speaker 3:  please let me know because I'm sort of dying to figure out how to

205
00:13:07,915 --> 00:13:11,665
Speaker 3:  understand the words platform shift as it relates to ai. And all

206
00:13:11,665 --> 00:13:15,545
Speaker 3:  I've come up with in that framework is, oh, you're gonna talk

207
00:13:15,545 --> 00:13:17,065
Speaker 3:  to the computer instead of typing,

208
00:13:17,505 --> 00:13:20,225
Speaker 4:  Which isn't a pla Well, like that's a platform shift we already had,

209
00:13:20,395 --> 00:13:23,745
Speaker 3:  Right? Except now can do it. Except, except, except now Gemini Live can just

210
00:13:23,745 --> 00:13:27,465
Speaker 3:  like listen to you and maybe take actions on your behalf and maybe you're

211
00:13:27,465 --> 00:13:30,745
Speaker 3:  gonna type to it. Maybe you're just gonna say, I don't know, like go make

212
00:13:30,745 --> 00:13:33,865
Speaker 3:  me an app that can do X and Gemini Live will spit it out and that'll be fine.

213
00:13:33,865 --> 00:13:37,785
Speaker 3:  Yeah. Or Siri on with Apple Intelligence will go use the apps for you,

214
00:13:37,785 --> 00:13:41,585
Speaker 3:  which is something that Apple has, you know, it's not gonna ship, but it's,

215
00:13:41,695 --> 00:13:45,585
Speaker 3:  it's what they previewed at wwc. That is, that's the platform

216
00:13:45,585 --> 00:13:46,345
Speaker 3:  shift. That's

217
00:13:46,345 --> 00:13:49,665
Speaker 5:  The platform shift. That last piece is the real platform shift. And this

218
00:13:49,665 --> 00:13:53,265
Speaker 5:  is, this is what I've been hearing from people forever. I think it was Paul Ford

219
00:13:53,905 --> 00:13:56,225
Speaker 5:  recently wrote a really good thing about this where he's, he said, right

220
00:13:56,225 --> 00:14:00,105
Speaker 5:  now we're in the, the like command line era of ai, which

221
00:14:00,105 --> 00:14:03,665
Speaker 5:  is like, the tech is kind of under there, but nobody has figured out how

222
00:14:03,665 --> 00:14:07,625
Speaker 5:  to use it yet. And the idea that you're going to be essentially use

223
00:14:07,665 --> 00:14:10,585
Speaker 5:  a command line to interact with it, which is essentially what writing an

224
00:14:10,685 --> 00:14:14,545
Speaker 5:  AI prompt is, is fine as far as it goes. But that's not

225
00:14:14,545 --> 00:14:17,185
Speaker 5:  the mainstream answer. And that actually what needs to happen is everybody

226
00:14:17,185 --> 00:14:20,705
Speaker 5:  needs to invent the interface on top of that. That makes it interesting and

227
00:14:21,335 --> 00:14:25,025
Speaker 5:  that we have not seen. But I think the, the thing that I hear from

228
00:14:25,025 --> 00:14:28,065
Speaker 5:  everybody is like, this starts to get really interesting when we get to the,

229
00:14:28,645 --> 00:14:32,585
Speaker 5:  it can use your apps for you phase of all of this, because that's

230
00:14:32,585 --> 00:14:36,465
Speaker 5:  where you actually do use your computer differently. Because right

231
00:14:36,465 --> 00:14:40,425
Speaker 5:  now it's like you Right. You can look up information by talking

232
00:14:40,495 --> 00:14:44,305
Speaker 5:  instead of by typing. And, and Alex, to your point A, that exists.

233
00:14:44,705 --> 00:14:48,625
Speaker 5:  B it's not better. Like it's not better. It's different. It's a little

234
00:14:48,625 --> 00:14:52,005
Speaker 5:  faster, but it's not better. And Alex, you've, you've used Gemini live a

235
00:14:52,005 --> 00:14:55,405
Speaker 5:  little, so I'm, I'm curious to hear what you think, but like we're still

236
00:14:55,465 --> 00:14:58,765
Speaker 5:  at this point where it it is, it is sort of a

237
00:14:58,895 --> 00:15:02,885
Speaker 5:  technology in search of a user interface. Yeah. And I

238
00:15:02,885 --> 00:15:06,645
Speaker 5:  think, I didn't like, you see a lot of Google like poking at that. I think

239
00:15:06,645 --> 00:15:08,965
Speaker 5:  The Pixel screenshots thing, which we should talk about, in which I am on

240
00:15:09,165 --> 00:15:12,205
Speaker 5:  record of being fascinated by is an interesting version of that. But like,

241
00:15:12,825 --> 00:15:16,645
Speaker 5:  how you actually push and pull with this thing is

242
00:15:16,645 --> 00:15:19,205
Speaker 5:  such an unanswered question in so, so many ways.

243
00:15:19,725 --> 00:15:22,285
Speaker 4:  I feel like they, they, they definitely haven't figured it out. Like, like

244
00:15:22,285 --> 00:15:26,045
Speaker 4:  I, I only spent a little time with Jim and I live, it was me and Sean, Hollister,

245
00:15:26,045 --> 00:15:29,885
Speaker 4:  Allison, all Johnson, all in our little room trying to talk to this thing.

246
00:15:30,325 --> 00:15:30,485
Speaker 4:  And

247
00:15:31,465 --> 00:15:34,565
Speaker 5:  Was it the same, I'm picturing a demo like the chat GPT one where it's phone

248
00:15:34,585 --> 00:15:35,845
Speaker 5:  on a table listening to

249
00:15:35,845 --> 00:15:38,285
Speaker 4:  You and you just chat. Yeah. Like you to hold the phone. Like, like I couldn't

250
00:15:38,285 --> 00:15:40,565
Speaker 4:  stand far away from the phone. You have to hold the phone really close to

251
00:15:40,725 --> 00:15:43,245
Speaker 4:  yourself. 'cause otherwise it'll be like, no, I'm not listening to you. But

252
00:15:43,285 --> 00:15:46,605
Speaker 4:  I really struggled with it. 'cause I tried to be very polite in

253
00:15:46,605 --> 00:15:50,365
Speaker 4:  conversations and like, oh, if you're talking, I'm gonna usually let you

254
00:15:50,365 --> 00:15:54,165
Speaker 4:  finish. Not always as Vergecast listeners can attest, but I'm usually

255
00:15:54,165 --> 00:15:57,565
Speaker 4:  gonna let you finish. And, and this one you're like encouraged to interrupt

256
00:15:57,565 --> 00:16:00,645
Speaker 4:  it and, and you're encouraged to interact with it in a way that would be

257
00:16:00,645 --> 00:16:04,525
Speaker 4:  like really rude if you were interacting with a person. And so

258
00:16:04,915 --> 00:16:08,565
Speaker 4:  it's at one point wants you to feel like it's more human and more

259
00:16:08,565 --> 00:16:12,515
Speaker 4:  realistic. And at the other point it's doing that and then like, I got

260
00:16:12,515 --> 00:16:15,515
Speaker 4:  in a fight with it 'cause it wouldn't shut up. Yes. And so I told her it

261
00:16:15,515 --> 00:16:18,435
Speaker 4:  was mansplaining me and it was like, oh, I'm sorry, do you want me to change

262
00:16:18,435 --> 00:16:21,315
Speaker 4:  my tone of my voice? And I was like, and it was a little sassy when it said

263
00:16:21,315 --> 00:16:25,075
Speaker 4:  it. I was just like, did I just get like talk clap

264
00:16:25,075 --> 00:16:29,035
Speaker 4:  back to that by ai? Yes. And then, yeah, this is incredible. Then, then

265
00:16:29,035 --> 00:16:31,595
Speaker 4:  Sean was like, I got this. And Sean just went in and was like, no, shut up.

266
00:16:31,675 --> 00:16:35,395
Speaker 4:  I have a question. And just immediately was just No, no, shush me now.

267
00:16:35,535 --> 00:16:38,755
Speaker 4:  Oh man. And, and it, so like, he was basically a dick to it and it worked

268
00:16:38,755 --> 00:16:39,955
Speaker 4:  perfectly. And I'm like, okay. Was he

269
00:16:39,955 --> 00:16:42,035
Speaker 3:  Like, who knows more about the steam deck? You were me.

270
00:16:43,975 --> 00:16:47,635
Speaker 4:  He might've asked that, but we, we main, he mainly asked it for to stock

271
00:16:47,635 --> 00:16:51,515
Speaker 4:  tips and that it was like, I, I wouldn't personally invest in Bitcoin,

272
00:16:51,895 --> 00:16:54,115
Speaker 4:  but You can do that if you want. It's just incredible. Very

273
00:16:54,115 --> 00:16:56,475
Speaker 3:  High risk. Incredible. Our very first Gemini scandal.

274
00:16:58,215 --> 00:17:02,155
Speaker 3:  No, that's not scandal. That's just good advice. Yeah. Here's my question.

275
00:17:02,215 --> 00:17:05,315
Speaker 3:  So you, you use it, you talk to it, it has some personality. This is,

276
00:17:06,345 --> 00:17:09,315
Speaker 3:  this is the thing, like this is how Google is talking about beating open

277
00:17:09,455 --> 00:17:13,075
Speaker 3:  ai, right? Right. Open AI is gonna put out its voice version.

278
00:17:13,585 --> 00:17:16,235
Speaker 3:  It's gonna sound like Scarlet Hanson or not. It's gonna have personality.

279
00:17:16,375 --> 00:17:20,035
Speaker 3:  It, it takes a breath in the middle of counting numbers as fast as it can.

280
00:17:20,035 --> 00:17:23,595
Speaker 3:  We've all seen that video. It's like they're competing on personality,

281
00:17:24,295 --> 00:17:25,355
Speaker 3:  not content.

282
00:17:26,045 --> 00:17:30,035
Speaker 4:  Right. They're com Yeah, because some stuff, it did really, really well for

283
00:17:30,035 --> 00:17:32,635
Speaker 4:  me. Like I, I, I asked it to fix something, it took me a while to fix on

284
00:17:32,635 --> 00:17:36,155
Speaker 4:  my car and it did it in 30 seconds. It was just great. And another stuff

285
00:17:36,155 --> 00:17:40,115
Speaker 4:  I really struggled with and it, it struggled to understand the questions

286
00:17:40,175 --> 00:17:43,975
Speaker 4:  and if like somebody compared it to being a, a

287
00:17:43,975 --> 00:17:47,695
Speaker 4:  kind of a friend and I wouldn't have friends

288
00:17:47,885 --> 00:17:51,685
Speaker 4:  like this thing because it it, it just talks. It doesn't

289
00:17:51,685 --> 00:17:55,525
Speaker 4:  listen to you. It doesn't respond to you in, in the way that

290
00:17:55,565 --> 00:17:59,525
Speaker 4:  a, a friend might and it's, but it's at the same

291
00:17:59,525 --> 00:18:02,365
Speaker 4:  time it's a computer. So you're just in this weird space where you're like,

292
00:18:02,505 --> 00:18:04,365
Speaker 4:  am I having to be nice to my computer?

293
00:18:06,605 --> 00:18:10,185
Speaker 4:  And I, I don't necessarily want that. I want it to just be my computer

294
00:18:10,575 --> 00:18:13,945
Speaker 3:  What you want. I think that the thesis of The Verge as a whole, as a publication

295
00:18:14,045 --> 00:18:16,425
Speaker 3:  is, do I have to be nice to my computer? Yeah.

296
00:18:17,165 --> 00:18:17,385
Speaker 4:  No,

297
00:18:17,565 --> 00:18:19,985
Speaker 3:  And we've been struggling to figure out that answer for quite some

298
00:18:19,985 --> 00:18:23,185
Speaker 5:  Time. But I do think in, in a way, those companies

299
00:18:23,815 --> 00:18:27,585
Speaker 5:  pushing that stuff are kind of telling on themselves about the actual state

300
00:18:27,585 --> 00:18:31,305
Speaker 5:  of the technology. Right. Because what has been true for 60 years

301
00:18:31,725 --> 00:18:35,585
Speaker 5:  is that if you give a computer any kind of personality, people will

302
00:18:35,585 --> 00:18:38,825
Speaker 5:  fall in love with it and try to have sex with it and tell it their deepest,

303
00:18:38,825 --> 00:18:41,625
Speaker 5:  darkest secrets. Like it's just true. Like you, you, we, we did a video about

304
00:18:41,625 --> 00:18:45,225
Speaker 5:  this a while ago that was very fun. And it's like in the seventies, this

305
00:18:45,225 --> 00:18:48,705
Speaker 5:  guy made a thing that basically all it did was say your commands back to

306
00:18:48,705 --> 00:18:52,465
Speaker 5:  you as a question. And so you'd be like, you know, my father was mean to

307
00:18:52,465 --> 00:18:54,545
Speaker 5:  me and it would be like your father was mean to you. And people were like,

308
00:18:54,545 --> 00:18:55,745
Speaker 5:  oh my God, it understands me. This

309
00:18:55,745 --> 00:18:56,385
Speaker 3:  Is Eliza.

310
00:18:56,385 --> 00:18:59,105
Speaker 5:  Right? Yes. That was Eliza. Yeah. And, and that's, that's actually a really

311
00:18:59,425 --> 00:19:03,065
Speaker 5:  powerful thing. And I think one other thing I miss while I was on vacation

312
00:19:03,085 --> 00:19:06,985
Speaker 5:  was all the friend drama. I wrote this story about this

313
00:19:07,005 --> 00:19:10,785
Speaker 5:  guy who launched an AI friend and it, everybody went nuts on the internet

314
00:19:10,785 --> 00:19:12,585
Speaker 5:  because there was drama about who owned it. It was the whole thing.

315
00:19:14,165 --> 00:19:18,105
Speaker 5:  I'm very happy I missed all of that drama. But one of the things that Avi,

316
00:19:18,105 --> 00:19:21,785
Speaker 5:  the, the CEO said to me was, he was like, the reason I'm doing this is because

317
00:19:21,785 --> 00:19:25,185
Speaker 5:  it's the only thing AI is any good at right now. And I think that's right.

318
00:19:25,615 --> 00:19:29,225
Speaker 5:  That there is, there is vast gaps

319
00:19:29,295 --> 00:19:32,945
Speaker 5:  between where we are right now with this technology and like true

320
00:19:33,015 --> 00:19:35,945
Speaker 5:  utility in people's lives. But it's pretty

321
00:19:36,775 --> 00:19:40,185
Speaker 5:  easy to make one of these like fun as hell to talk to. Yeah. Because it's

322
00:19:40,185 --> 00:19:42,985
Speaker 5:  not that hard to make them fun as hell to talk to. So what they're able to

323
00:19:42,985 --> 00:19:46,665
Speaker 5:  compete on right now is making them fun as hell to talk to because that will

324
00:19:46,665 --> 00:19:49,585
Speaker 5:  make people use them more, even if they can't do very much and the things

325
00:19:49,585 --> 00:19:52,945
Speaker 5:  that they do, they don't do very well. And so if you're just using this as

326
00:19:52,945 --> 00:19:56,905
Speaker 5:  like a rote, straightforward robotic task machine, you're

327
00:19:56,905 --> 00:20:00,425
Speaker 5:  gonna notice it's bad and you're gonna hate it. Yeah. But if you make it

328
00:20:00,645 --> 00:20:04,185
Speaker 5:  fun and cool and friendly and exciting, it doesn't have to do that much.

329
00:20:04,275 --> 00:20:08,145
Speaker 5:  Right. And I think that's a fine road to go down, but it is so not

330
00:20:08,145 --> 00:20:11,065
Speaker 5:  the same thing as like making it more useful to people.

331
00:20:11,365 --> 00:20:15,185
Speaker 3:  So lemme put that into the framework or the question I was asking

332
00:20:15,775 --> 00:20:19,505
Speaker 3:  Alex, when you were using Gemini Live, did any of it feel

333
00:20:19,775 --> 00:20:23,595
Speaker 3:  like the platform shift? Because that is the big

334
00:20:23,835 --> 00:20:26,395
Speaker 3:  question, right? If you're, if you're Microsoft and you're pouring billions

335
00:20:26,395 --> 00:20:30,155
Speaker 3:  of dollars into this because you missed mobile right? Then this is your

336
00:20:30,155 --> 00:20:33,995
Speaker 3:  chance to reclaim the primary user interface of computers. If you're Google

337
00:20:34,335 --> 00:20:38,235
Speaker 3:  and you're basically communicating that you're gonna bet the company on this,

338
00:20:39,255 --> 00:20:42,675
Speaker 3:  is it there, is it, is there evidence that that is real? Because I don't,

339
00:20:43,155 --> 00:20:44,755
Speaker 3:  I don't know. I I honestly don't know.

340
00:20:45,395 --> 00:20:49,005
Speaker 4:  I it's, no, no. I I think right now,

341
00:20:49,315 --> 00:20:52,525
Speaker 4:  yeah, I think, I think right now the the answer is no for me, I think it

342
00:20:52,525 --> 00:20:56,325
Speaker 4:  is a valuable tool. I was talking with people afterwards who don't even work

343
00:20:56,325 --> 00:20:59,685
Speaker 4:  at Google, work at other companies about the, these kind of things. And they

344
00:20:59,685 --> 00:21:02,525
Speaker 4:  were like, oh yeah, I really like it. 'cause it's a good brainstorming tool.

345
00:21:02,715 --> 00:21:06,645
Speaker 4:  It's a good way for me to like just figure some stuff out. And I, I'm

346
00:21:06,645 --> 00:21:07,965
Speaker 4:  not gonna brainstorm that way personally.

347
00:21:07,965 --> 00:21:09,845
Speaker 5:  That's, it's fun to talk to. Like that's the whole thing.

348
00:21:10,065 --> 00:21:13,165
Speaker 4:  Fun to talk. Yeah. It's not fun to talk to, but, but like, I didn't feel

349
00:21:13,165 --> 00:21:16,205
Speaker 4:  this urge to just, oh, I want this in my car. I did actually want it in my

350
00:21:16,205 --> 00:21:19,045
Speaker 4:  car immediately, so nevermind. I did feel that urge. So

351
00:21:19,045 --> 00:21:22,965
Speaker 3:  That's a platform shift. Yeah. I I slightly mansplaining to her. You're like,

352
00:21:22,965 --> 00:21:23,525
Speaker 3:  This is the future.

353
00:21:24,325 --> 00:21:27,845
Speaker 4:  Oh my God. It was like so mansplaining. It was very upsetting. But

354
00:21:28,275 --> 00:21:32,125
Speaker 4:  like as a, as a voice, as as if you think of it as part of the, the

355
00:21:32,125 --> 00:21:35,885
Speaker 4:  evolution of the voice assistant as the digital voice assistant, it's a lot

356
00:21:35,885 --> 00:21:39,245
Speaker 4:  better. It it is a huge improvement over assistant. It's a huge improvement

357
00:21:39,245 --> 00:21:42,845
Speaker 4:  over Siri and, and, and Alexa. But is it a

358
00:21:42,845 --> 00:21:46,085
Speaker 4:  replacement for computing general? Like general

359
00:21:46,435 --> 00:21:50,415
Speaker 4:  computing? No, absolutely not. It's not a platform shift

360
00:21:50,415 --> 00:21:52,975
Speaker 4:  for my phone. It's a platform shift for my Alexa. Yeah.

361
00:21:53,085 --> 00:21:56,815
Speaker 5:  Well I think even the question of is it better than Google

362
00:21:56,815 --> 00:22:00,135
Speaker 5:  Assistant or Siri or Alexa is a really interesting one because one of the

363
00:22:00,135 --> 00:22:03,775
Speaker 5:  things that's happening is Gemini is replacing Google Assistant kind of all

364
00:22:03,775 --> 00:22:06,655
Speaker 5:  over Android, which is a big deal. Like it wasn't that long ago that Google

365
00:22:06,715 --> 00:22:10,535
Speaker 5:  was out there being like, Google Assistant is the future of everything. And

366
00:22:10,535 --> 00:22:14,135
Speaker 5:  now it's very clearly Gemini and there have been a bunch of people out there

367
00:22:14,135 --> 00:22:16,855
Speaker 5:  testing early versions of this thing. Obviously there are early, we'll see

368
00:22:17,415 --> 00:22:21,135
Speaker 5:  and it just can't do some of the very, very basic timers, basic things

369
00:22:21,195 --> 00:22:23,815
Speaker 5:  you would expect. That's what, right? And so it's like, okay, you have this

370
00:22:23,815 --> 00:22:27,775
Speaker 5:  thing that is more fun to talk to, understands you better, does the

371
00:22:27,775 --> 00:22:31,415
Speaker 5:  sort of basic interface tasks way better, like orders of

372
00:22:31,655 --> 00:22:34,855
Speaker 5:  magnitude better than the stuff that we had before. But it can't do the things.

373
00:22:35,735 --> 00:22:38,495
Speaker 5:  I think it was Jared Newman at Fast Company wrote a thing where he was like,

374
00:22:38,495 --> 00:22:41,895
Speaker 5:  it can't tell me what the weather is. It can't play the

375
00:22:42,055 --> 00:22:45,095
Speaker 5:  podcasts that I have played because it doesn't have access to my apps. It

376
00:22:45,095 --> 00:22:48,215
Speaker 5:  doesn't do turn by turn directions very well. Just all these basic things.

377
00:22:48,245 --> 00:22:52,095
Speaker 5:  It's like, okay, what Google Assistant had is is access to the systems

378
00:22:52,095 --> 00:22:54,975
Speaker 5:  that you actually want on your phone, right? Like it was able to use your

379
00:22:54,975 --> 00:22:58,855
Speaker 5:  apps for you and Gemini can't use your apps for you, but we're

380
00:22:58,855 --> 00:23:02,295
Speaker 5:  replacing the one with the other before it can do both things.

381
00:23:02,705 --> 00:23:05,895
Speaker 5:  Which to me is just, it's like, it's so clear that that is what Google

382
00:23:06,395 --> 00:23:07,495
Speaker 5:  thinks is more important.

383
00:23:08,035 --> 00:23:11,885
Speaker 4:  It feels like a big rush, but I'm also, I feel not

384
00:23:11,885 --> 00:23:14,485
Speaker 4:  concerned about, I feel like that's the kind of thing that they can do a

385
00:23:14,805 --> 00:23:17,365
Speaker 4:  software update and be like, yeah, now it can do timers. Now it can tell

386
00:23:17,365 --> 00:23:21,005
Speaker 4:  you the weather. Like those should be relatively easy things to just pipe

387
00:23:21,065 --> 00:23:25,045
Speaker 4:  in. And I, I think they just haven't because they've been moving that quickly

388
00:23:25,145 --> 00:23:28,885
Speaker 4:  to churn this out and, and compete with Apple. Like to the point of

389
00:23:29,275 --> 00:23:33,205
Speaker 4:  they, this whole event happened a month before. What we assume is

390
00:23:33,205 --> 00:23:36,605
Speaker 4:  gonna be the Apple, the iPhone launch. And traditionally it's how in October.

391
00:23:36,825 --> 00:23:39,925
Speaker 4:  And that was very, I think everybody in the industry was just like, oh, that's

392
00:23:39,925 --> 00:23:42,965
Speaker 4:  just to get ahead of Apple intelligence. And so it definitely feels like

393
00:23:42,965 --> 00:23:46,245
Speaker 4:  they're ru they're, they're they're rushing it, it, but at the same time

394
00:23:46,955 --> 00:23:50,365
Speaker 4:  there's a level of polish there, but it's not perfect, right? Like, like

395
00:23:50,435 --> 00:23:53,525
Speaker 4:  there's with, with Siri and Assistant and stuff like that. You ask it a question

396
00:23:53,585 --> 00:23:57,005
Speaker 4:  and it'll pop up something contextually on the screen for you. So You can

397
00:23:57,005 --> 00:24:00,445
Speaker 4:  see it. There's, there's a visual component and there's zero visual component

398
00:24:00,445 --> 00:24:04,125
Speaker 4:  here. And I think that if anything was the most annoying

399
00:24:04,595 --> 00:24:08,165
Speaker 4:  element of it. 'cause you ask it for questions, you just expect to see some

400
00:24:08,165 --> 00:24:11,285
Speaker 4:  sort of result in front of you and instead you just see this little glowy

401
00:24:11,285 --> 00:24:15,205
Speaker 4:  screen and it's like, okay, cool. Like that'd be, that'd be cool in my

402
00:24:15,205 --> 00:24:18,445
Speaker 4:  meta glasses, that's just not cool on my phone. Yeah, that's a waste of my

403
00:24:18,445 --> 00:24:19,125
Speaker 4:  phone. Even

404
00:24:19,125 --> 00:24:23,045
Speaker 3:  When I use the chat GBT voice mode, which I think I've

405
00:24:23,045 --> 00:24:26,325
Speaker 3:  said this several times, I have mapped the action button on my iPhone

406
00:24:27,395 --> 00:24:30,645
Speaker 3:  halfway through it talking. I'm like, I just need to read this. Like, yeah,

407
00:24:30,755 --> 00:24:34,565
Speaker 3:  yeah. I'm tired of this. Like I can just read much

408
00:24:34,565 --> 00:24:38,525
Speaker 3:  faster than You can. You can machine talk to me robot. We're gonna get another

409
00:24:38,585 --> 00:24:41,485
Speaker 3:  run at this. When the phone's come out, we're obviously going to get a chance

410
00:24:41,485 --> 00:24:45,365
Speaker 3:  to use it more. I wanna talk for one second to wrap up

411
00:24:45,705 --> 00:24:49,535
Speaker 3:  the Android Pixel AI conversation and just talk about the,

412
00:24:49,535 --> 00:24:53,455
Speaker 3:  the photo stuff for half a second. I feel like I could spend five

413
00:24:53,465 --> 00:24:56,215
Speaker 3:  hours talking about what is a photo right now. I would say

414
00:24:56,455 --> 00:24:59,175
Speaker 5:  Historically speaking that that we've proven that several times.

415
00:24:59,675 --> 00:25:02,575
Speaker 3:  So, you know, the The Pixel nine's coming out, Becca's gotten a chance to

416
00:25:02,575 --> 00:25:05,415
Speaker 3:  use the Add Me feature in some of the other photo stuff. You can go watch

417
00:25:05,415 --> 00:25:08,615
Speaker 3:  that video. But we are just in a really weird spot

418
00:25:09,265 --> 00:25:12,615
Speaker 3:  where it seems like the phone makers

419
00:25:13,355 --> 00:25:17,095
Speaker 3:  in particular have utterly given up on the idea that the

420
00:25:17,095 --> 00:25:19,415
Speaker 3:  pictures they take should represent reality. What

421
00:25:19,415 --> 00:25:22,135
Speaker 5:  Was the line that you pulled out, Eli, where like Google was like, we're

422
00:25:22,135 --> 00:25:23,895
Speaker 5:  not even, we they don't, they don't do photos anymore.

423
00:25:24,285 --> 00:25:27,975
Speaker 3:  Yeah. So Julian at Wire did the piece on The Pixel camera this year,

424
00:25:28,275 --> 00:25:31,015
Speaker 3:  sat down with a bunch of Google folks, talked about the camera and new features

425
00:25:31,015 --> 00:25:33,975
Speaker 3:  and why it's better. And basically his thesis in this piece is Google is

426
00:25:33,975 --> 00:25:37,775
Speaker 3:  chasing memories, not photos. And so he talked to a Google PM named Isaac

427
00:25:38,015 --> 00:25:41,935
Speaker 3:  Reynolds who says, quote, it's about what you're remembering when you

428
00:25:41,935 --> 00:25:45,815
Speaker 3:  define a memory that has a fallibility to it. You can have a true and

429
00:25:45,815 --> 00:25:49,375
Speaker 3:  perfect representation of a moment that felt completely fake and wrong. What

430
00:25:49,375 --> 00:25:53,055
Speaker 3:  some of these edits do is help you create a moment that is the way you

431
00:25:53,655 --> 00:25:57,295
Speaker 3:  remember it, that is authentic to your memory and the greater context,

432
00:25:57,835 --> 00:26:01,295
Speaker 3:  but maybe isn't authentic to a particular millisecond.

433
00:26:02,385 --> 00:26:02,605
Speaker 5:  Wow.

434
00:26:02,915 --> 00:26:04,805
Speaker 3:  There's a, that's a PhD thesis.

435
00:26:05,155 --> 00:26:06,285
Speaker 5:  Seriously. It's

436
00:26:06,285 --> 00:26:09,605
Speaker 3:  Beautiful. That is a PhD thesis in philosophy right there.

437
00:26:10,115 --> 00:26:14,005
Speaker 3:  Like what is real? Is it what you remember or what actually

438
00:26:14,365 --> 00:26:14,525
Speaker 3:  happened?

439
00:26:16,135 --> 00:26:19,895
Speaker 3:  I don't a PhD thesis, I'm just telling you You can spend the rest

440
00:26:19,915 --> 00:26:23,575
Speaker 3:  of your life chasing down that question. And Google

441
00:26:23,715 --> 00:26:27,575
Speaker 3:  has just made a decision that what they want to do is help

442
00:26:27,575 --> 00:26:31,415
Speaker 3:  people create the memories they felt they were experiencing as opposed

443
00:26:31,475 --> 00:26:35,135
Speaker 3:  to capturing what actually happened. And they're just headed down that road

444
00:26:35,675 --> 00:26:37,055
Speaker 3:  and they have been for some time

445
00:26:37,415 --> 00:26:40,855
Speaker 5:  I think not just Google, that's everybody. Like that's a pretty good summation

446
00:26:40,855 --> 00:26:42,055
Speaker 5:  of the whole industry right now.

447
00:26:42,125 --> 00:26:42,415
Speaker 4:  Yeah.

448
00:26:42,675 --> 00:26:45,765
Speaker 3:  And it, it's, it's bananas to me because

449
00:26:46,585 --> 00:26:50,165
Speaker 3:  we live in a time when like synthetic and fake media

450
00:26:50,385 --> 00:26:54,205
Speaker 3:  is everywhere and You can even see that having

451
00:26:54,265 --> 00:26:58,045
Speaker 3:  it exist at all allows bad actors to call

452
00:26:58,045 --> 00:27:01,725
Speaker 3:  into question the significance or reality of real

453
00:27:01,735 --> 00:27:05,685
Speaker 3:  media. So Trump saying the Harris rally was quote

454
00:27:06,075 --> 00:27:08,125
Speaker 3:  AIed, which can we not make the crowd can

455
00:27:08,145 --> 00:27:10,925
Speaker 5:  Can, can you just pause real fast? Like can we not with the AI as a verb,

456
00:27:11,285 --> 00:27:15,005
Speaker 5:  like AI already means too many things. It's a, it's a huge

457
00:27:15,005 --> 00:27:18,845
Speaker 5:  catchall word that has become sort of meaning. Let's can we not make it other

458
00:27:18,845 --> 00:27:20,165
Speaker 5:  parts of speech too? I

459
00:27:20,165 --> 00:27:22,805
Speaker 3:  Agree. Just you, we should not use language like Donald Trump uses language,

460
00:27:23,545 --> 00:27:27,445
Speaker 3:  but what I'm getting at is you only get to do that if

461
00:27:27,445 --> 00:27:30,845
Speaker 3:  people believe the technology can do it. and it is true that people have

462
00:27:31,045 --> 00:27:34,925
Speaker 3:  believed the technology can do this stuff for years before can, but now they're

463
00:27:34,925 --> 00:27:38,845
Speaker 3:  gonna hold in their hands the capability on a

464
00:27:38,845 --> 00:27:42,765
Speaker 3:  Samsung phone to circle an empty field and say add a crowd, right? They

465
00:27:42,765 --> 00:27:46,685
Speaker 3:  can just do it. They are gonna hold in their hands the ability to add

466
00:27:46,685 --> 00:27:50,125
Speaker 3:  people to photos who weren't there before with add me on a Google Pixel

467
00:27:50,625 --> 00:27:53,925
Speaker 3:  and the companies are marketing this as this makes you more creative. It

468
00:27:54,195 --> 00:27:57,605
Speaker 3:  lets you take the photos you want and now for Google all the way to,

469
00:27:58,185 --> 00:28:01,925
Speaker 3:  we want you to create the memories of the things you thought were happening

470
00:28:02,185 --> 00:28:04,605
Speaker 3:  rather than the things that were happening. I mean,

471
00:28:05,235 --> 00:28:08,685
Speaker 4:  Haven't like Chinese filmmakers been doing that with, we wanna create

472
00:28:09,155 --> 00:28:12,685
Speaker 4:  what I think I look like versus what I actually look like with the face tuning.

473
00:28:12,755 --> 00:28:16,605
Speaker 4:  Like sure it's been happening a while. Like it's one of those

474
00:28:16,605 --> 00:28:20,545
Speaker 4:  things I think what was shocking to me is the ease of

475
00:28:20,565 --> 00:28:24,345
Speaker 4:  access of the tool itself. But I'm not like shocked at putting these

476
00:28:24,345 --> 00:28:28,185
Speaker 4:  tools on the phone, but it's weird that they put it in the camera app.

477
00:28:28,605 --> 00:28:32,585
Speaker 3:  The Add me feature is not like the most ai it's like

478
00:28:32,585 --> 00:28:36,545
Speaker 3:  generating you, right? But it's doing a bunch of cool stuff on a

479
00:28:36,545 --> 00:28:39,545
Speaker 3:  technical level. It's it's doing something cool, right? It's generating a

480
00:28:39,545 --> 00:28:43,105
Speaker 3:  depth map and then using the depth map to realign the multiple

481
00:28:43,125 --> 00:28:46,945
Speaker 3:  photos. That's all very cool. And I'm confident there's a bunch of AI in

482
00:28:46,945 --> 00:28:50,705
Speaker 3:  there that is helping to do that. But it on, at the most fundamental level,

483
00:28:50,705 --> 00:28:54,225
Speaker 3:  what it's doing is compositing two photos together, right? Like you look

484
00:28:54,225 --> 00:28:58,105
Speaker 3:  at the photos that the Hollywood magazines put out with like 500 stars

485
00:28:58,125 --> 00:29:01,225
Speaker 3:  on the cover. Those are often composite photos and we don't,

486
00:29:01,225 --> 00:29:04,985
Speaker 4:  Those are adme photos. Like, like every single poster movie poster you see

487
00:29:05,445 --> 00:29:07,665
Speaker 4:  is one of those adme photos. But like Right.

488
00:29:07,665 --> 00:29:10,985
Speaker 3:  But I'm never like, I wonder if this movie poster happened like

489
00:29:12,075 --> 00:29:15,975
Speaker 4:  Right. But I'll also say the, I got to

490
00:29:15,975 --> 00:29:19,855
Speaker 4:  try it out a little bit at the event. And, and Aby is certainly really

491
00:29:19,885 --> 00:29:23,775
Speaker 4:  cool, but also I would say it's like a, the royal family level

492
00:29:23,955 --> 00:29:26,415
Speaker 4:  of Photoshopping abilities. Ooh,

493
00:29:26,845 --> 00:29:28,615
Speaker 3:  Deep cut Alex. You see some,

494
00:29:28,755 --> 00:29:32,575
Speaker 4:  You see some like hands where hands should not be that sort of thing

495
00:29:32,845 --> 00:29:36,375
Speaker 4:  sometimes. So it's one of those things where it's like, yeah, it'll do it

496
00:29:36,395 --> 00:29:39,935
Speaker 4:  at a glance. It looks awesome, it looks really, really cool. You look closer

497
00:29:40,235 --> 00:29:43,365
Speaker 4:  and, and you see the edges on this stuff. Mm. And I haven't gotten to try

498
00:29:43,365 --> 00:29:47,285
Speaker 4:  it as all of these tools, but like even the, the AI one where you circle

499
00:29:47,285 --> 00:29:51,005
Speaker 4:  things and add like that messed up at the event, they

500
00:29:51,005 --> 00:29:53,005
Speaker 4:  scrolled through it really, really fast and they were like, they're like,

501
00:29:53,005 --> 00:29:54,925
Speaker 4:  here's a hot air balloon. And then they like did another one. It was like

502
00:29:54,925 --> 00:29:58,365
Speaker 4:  a blob and the guy like just speed scrolled past this horrible

503
00:29:58,365 --> 00:29:59,485
Speaker 4:  amorphous blob. It

504
00:29:59,645 --> 00:30:00,045
Speaker 5:  Was pretty great.

505
00:30:00,345 --> 00:30:03,805
Speaker 3:  All I'm getting at is those tools aren't great, but because they exist Yeah.

506
00:30:03,805 --> 00:30:07,685
Speaker 3:  And they are broadly accessible. It's not just that there's a bunch

507
00:30:07,685 --> 00:30:11,485
Speaker 3:  of synthetic photos we can point at and say those are fake bad

508
00:30:11,485 --> 00:30:15,445
Speaker 3:  actors are able to point at real photos and say they are fake and we

509
00:30:15,445 --> 00:30:19,205
Speaker 3:  are just barreling towards no one believes

510
00:30:19,365 --> 00:30:20,205
Speaker 3:  anything. They see. I,

511
00:30:20,285 --> 00:30:21,125
Speaker 4:  I think we're already there.

512
00:30:21,515 --> 00:30:23,805
Speaker 3:  There's a strong argument we're already there. But

513
00:30:23,945 --> 00:30:27,805
Speaker 5:  Do you guys remember a bunch of years ago, Farhad Manju,

514
00:30:27,805 --> 00:30:31,685
Speaker 5:  when he was at the New York Times wrote this really great column about selfie

515
00:30:31,685 --> 00:30:35,605
Speaker 5:  culture and his big sort of thinky

516
00:30:35,675 --> 00:30:38,445
Speaker 5:  thought that I've been thinking about ever since was basically like

517
00:30:39,415 --> 00:30:43,085
Speaker 5:  we've, we've entered into a place where everything that there is to be photographed

518
00:30:43,085 --> 00:30:46,285
Speaker 5:  has been photographed. And so now what's different is that I'm there and

519
00:30:46,285 --> 00:30:48,805
Speaker 5:  that's, it's, it's like a, it's a meaningful thing, right? It's like I'm,

520
00:30:48,955 --> 00:30:52,805
Speaker 5:  this picture is different because it has me in it. In the Grand Canyon, you've

521
00:30:52,805 --> 00:30:55,485
Speaker 5:  already seen pictures of the Grand Canyon, so people are putting themselves

522
00:30:55,585 --> 00:30:59,245
Speaker 5:  in it as like, this is a, this is a new way of seeing this because I'm here.

523
00:30:59,355 --> 00:31:03,165
Speaker 5:  Something like Add Me just breaks that in the most interesting way.

524
00:31:03,195 --> 00:31:07,085
Speaker 5:  It's like we talk about sort of the cultural meaning of photos and

525
00:31:07,245 --> 00:31:10,245
Speaker 5:  I, I was seeing a bunch of people during the Google event be like, how on

526
00:31:10,245 --> 00:31:13,805
Speaker 5:  earth can a photo first social network exist after this? Like

527
00:31:14,465 --> 00:31:17,925
Speaker 5:  if, if suddenly I can be anywhere at any time

528
00:31:18,375 --> 00:31:22,365
Speaker 5:  doing whatever I feel like just gets weird and I get that ame

529
00:31:22,365 --> 00:31:24,885
Speaker 5:  has some like limitations that make that challenging. I

530
00:31:24,885 --> 00:31:28,205
Speaker 4:  Mean, arguably the photo first social media has been weird for a while given

531
00:31:28,205 --> 00:31:32,125
Speaker 4:  that like influencers rent sets that look like planes

532
00:31:32,435 --> 00:31:34,565
Speaker 4:  Yeah. Fair to fake looking like they're sitting in a plane.

533
00:31:34,865 --> 00:31:38,005
Speaker 5:  But at least that like costs money and time and effort. Yeah.

534
00:31:38,545 --> 00:31:42,205
Speaker 4:  That's not really easy. I agree. Like, like what Pixel has done, what Google

535
00:31:42,305 --> 00:31:46,165
Speaker 4:  has done is just remove a ton of barriers that were

536
00:31:46,165 --> 00:31:49,245
Speaker 4:  already existed, right? Like Photoshop already existed. People faking photos

537
00:31:49,345 --> 00:31:53,325
Speaker 4:  has been happening forever. Yeah. But now it's just like, to to Neely's point

538
00:31:53,545 --> 00:31:55,245
Speaker 4:  really, really easy. Yeah.

539
00:31:55,245 --> 00:31:59,045
Speaker 5:  It's Samsung faking the moon, but it's you and it's everywhere. Like weird.

540
00:31:59,825 --> 00:32:03,005
Speaker 3:  Two things. One, I, we should have made this set look like a private chat.

541
00:32:03,115 --> 00:32:03,925
Speaker 3:  What were we thinking?

542
00:32:04,385 --> 00:32:05,365
Speaker 4:  Oh my God, we

543
00:32:05,865 --> 00:32:06,085
Speaker 5:  Fun.

544
00:32:06,085 --> 00:32:08,805
Speaker 3:  Fundamental airly. I, this should look like

545
00:32:08,805 --> 00:32:11,045
Speaker 5:  A PJ lying down in the PJ doing podcast.

546
00:32:11,225 --> 00:32:14,725
Speaker 3:  I'm so mad that this room doesn't look like the inside of a private jet.

547
00:32:15,785 --> 00:32:19,725
Speaker 3:  Second what we're talking about the the cost element that you bring up

548
00:32:19,725 --> 00:32:23,525
Speaker 3:  David is the thing. Yeah. It's the thing when when

549
00:32:23,765 --> 00:32:27,725
Speaker 3:  ILM made fake dinosaurs in Jurassic Park, there was not a

550
00:32:28,005 --> 00:32:31,965
Speaker 3:  widespread outcry about people believing dinosaurs are

551
00:32:31,965 --> 00:32:32,125
Speaker 3:  real.

552
00:32:32,765 --> 00:32:34,525
Speaker 4:  A small outcry somewhere. I'm sure.

553
00:32:34,995 --> 00:32:37,805
Speaker 3:  Yeah. Right. There's actually one line from that movie that should have gotten

554
00:32:37,875 --> 00:32:41,445
Speaker 3:  even more outcry, which is you were so busy wondering if you could

555
00:32:42,395 --> 00:32:43,345
Speaker 6:  Never Right? Yeah.

556
00:32:43,485 --> 00:32:47,225
Speaker 3:  I'm just pointing out. But when you make it so that everyone's

557
00:32:47,225 --> 00:32:51,065
Speaker 3:  phone, you put Velociraptors in every photo and they look real

558
00:32:51,165 --> 00:32:54,945
Speaker 3:  and you brought the cost to nothing, some people are gonna believe some dumb

559
00:32:54,945 --> 00:32:58,625
Speaker 3:  stuff and like we are just there. And I,

560
00:32:59,265 --> 00:33:03,065
Speaker 3:  I agree with you Alex. Like we might be way past the point of no return where

561
00:33:03,065 --> 00:33:06,265
Speaker 3:  people are just not gonna believe anything's true anymore. Yeah. Like the

562
00:33:06,265 --> 00:33:07,465
Speaker 3:  needle might just be in the red.

563
00:33:07,725 --> 00:33:09,025
Speaker 6:  I'm just deeply cynical. I'm

564
00:33:09,025 --> 00:33:12,345
Speaker 3:  Sorry. Wait. I think we wrote with The Pixel eight last year that we were

565
00:33:12,345 --> 00:33:15,105
Speaker 3:  at the, what is a photo apocalypse? Yeah. I'm just saying, I I'm looking

566
00:33:15,205 --> 00:33:19,105
Speaker 3:  at it now and there's no longer, when we wrote about The Pixel

567
00:33:19,105 --> 00:33:22,465
Speaker 3:  eight, there was some pushback like, we're not doing this, we're being careful

568
00:33:22,465 --> 00:33:24,945
Speaker 3:  you're overreacting. And then this year they're like, You can just put yourself

569
00:33:24,945 --> 00:33:27,105
Speaker 3:  in the right and it's like, oh, we're over it.

570
00:37:52,445 --> 00:37:55,125
Speaker 3:  bourbon and cigar advice. Alright, we should start that show.

571
00:37:56,425 --> 00:37:59,965
Speaker 3:  And my answer is have as much as you want. Yeah, that's, it'll be fine. Just

572
00:37:59,965 --> 00:38:03,285
Speaker 3:  enjoy it. Take one. Yeah, it's fine. It's two or three in. They're all the

573
00:38:03,285 --> 00:38:04,125
Speaker 3:  same. Really. Yeah.

574
00:38:06,145 --> 00:38:09,805
Speaker 3:  All right. That's enough. We, we've done enough philosophizing about AI and

575
00:38:10,005 --> 00:38:13,165
Speaker 3:  platform shifts and whether or not reality is real. Let's talk about

576
00:38:13,865 --> 00:38:17,475
Speaker 3:  the most important tech story of the week, which is that as

577
00:38:17,795 --> 00:38:21,355
Speaker 3:  promised, I published 2,500 words about

578
00:38:21,355 --> 00:38:24,595
Speaker 3:  judging the 2024 TV shootout.

579
00:38:25,615 --> 00:38:27,065
Speaker 3:  I've never been happier in my entire life

580
00:38:28,635 --> 00:38:32,585
Speaker 3:  doing the shootout, writing the words, avoiding the many other

581
00:38:32,585 --> 00:38:36,485
Speaker 3:  lawsuits that happened this week, because if you remember last

582
00:38:36,485 --> 00:38:39,445
Speaker 3:  week I was gonna do it and then the Google decision came out and the whole

583
00:38:39,445 --> 00:38:43,165
Speaker 3:  week got thrown away and I couldn't talk about TVs this week. I just ignored

584
00:38:43,655 --> 00:38:45,205
Speaker 3:  everything. Google

585
00:38:45,315 --> 00:38:48,445
Speaker 5:  Also really ruining everybody's life is what I'm hearing. Yeah, it's been,

586
00:38:48,445 --> 00:38:49,605
Speaker 5:  it's been a hard time on all of us.

587
00:38:50,165 --> 00:38:53,405
Speaker 3:  A thing we, and one assumes for Google,

588
00:38:54,705 --> 00:38:57,205
Speaker 3:  we should probably, we, there's some regulatory stuff talking about Google

589
00:38:57,225 --> 00:39:00,805
Speaker 3:  is in a world of her right now. We'll, we'll come to that later. But we did

590
00:39:00,805 --> 00:39:04,445
Speaker 3:  it again. We were gonna talk about TVs, we start talking about Google antitrust.

591
00:39:05,155 --> 00:39:08,005
Speaker 3:  Tell us about the TVs you like. These concepts are so inextricably linked

592
00:39:08,005 --> 00:39:09,005
Speaker 3:  for some bizarre reason

593
00:39:10,865 --> 00:39:11,085
Speaker 3:  why

594
00:39:12,665 --> 00:39:16,325
Speaker 3:  no TVs we're no TVs. There's a really high end boutique home theater

595
00:39:16,495 --> 00:39:20,165
Speaker 3:  store in Scarsdale, New York called Valley Electronics. They've been running

596
00:39:20,165 --> 00:39:24,005
Speaker 3:  the TV shootout for 20 years. This was the 20th one. You can go Google all

597
00:39:24,005 --> 00:39:27,805
Speaker 3:  the coverage from 20 years ago, 2004, like plasmas are it amazing. The whole

598
00:39:27,805 --> 00:39:28,245
Speaker 3:  thing's amazing.

599
00:39:29,885 --> 00:39:33,805
Speaker 3:  I bought my Sony a 95 L there because they have stock, it's actually

600
00:39:33,805 --> 00:39:36,645
Speaker 3:  pretty hard to get that tv, but they sell so many of them that Sony gives

601
00:39:36,645 --> 00:39:40,365
Speaker 3:  them special allocations. I went and bought one from them.

602
00:39:40,845 --> 00:39:43,845
Speaker 3:  I got to talk to, to the owner, Robert's son and his wife Wendy.

603
00:39:44,665 --> 00:39:48,125
Speaker 3:  And they were like, do you want to judge the shootout this year? And I

604
00:39:48,395 --> 00:39:52,205
Speaker 3:  just imagine, I was like, yes. Like more than anything, I'm just going to,

605
00:39:52,545 --> 00:39:56,285
Speaker 3:  my wife and daughter will be fine. I'll just wait here until the TV shootout

606
00:39:56,385 --> 00:40:00,325
Speaker 3:  begins. So they called me in to judge it. It was an incredible panel. Like

607
00:40:00,345 --> 00:40:04,125
Speaker 3:  the I You can look at the story. The pictures are adorable.

608
00:40:04,265 --> 00:40:08,205
Speaker 3:  It was just a bunch of nerds in a room like they

609
00:40:08,205 --> 00:40:10,805
Speaker 3:  cleaned. They cleared out the store and they set up

610
00:40:11,895 --> 00:40:15,845
Speaker 3:  three TVs, three OLEDs and three mini LDS from Samsung, Sony, and

611
00:40:16,005 --> 00:40:16,205
Speaker 3:  lg.

612
00:40:17,745 --> 00:40:21,445
Speaker 3:  And they put $40,000 Sony reference monitors,

613
00:40:21,755 --> 00:40:25,085
Speaker 3:  like the ones that used for coloring in Hollywood in front of them. And then

614
00:40:25,085 --> 00:40:28,405
Speaker 3:  the, the first day was quote the objective day

615
00:40:28,855 --> 00:40:32,005
Speaker 3:  where the, the task was

616
00:40:32,465 --> 00:40:36,165
Speaker 3:  across a number of clips that they were playing to judge how

617
00:40:36,515 --> 00:40:40,405
Speaker 3:  similar the TVs were to the reference displays. And the TVs had

618
00:40:40,405 --> 00:40:43,525
Speaker 3:  been professionally calibrated by like famous

619
00:40:44,325 --> 00:40:47,645
Speaker 3:  calibrators on the AAVs forums. Can you I was like in heaven. That's

620
00:40:47,645 --> 00:40:51,365
Speaker 5:  An amazing phrase you just said by the way. Yeah. Calibrated by famous

621
00:40:51,805 --> 00:40:52,845
Speaker 5:  calibrators. Like hell yeah.

622
00:40:52,955 --> 00:40:56,405
Speaker 3:  Like if you're an a VS forum nerd and you have ever just like gone and looked

623
00:40:56,425 --> 00:41:00,245
Speaker 3:  for the settings for a tv, it was probably Cecil need or Dwayne Davis.

624
00:41:00,585 --> 00:41:04,205
Speaker 3:  That's awesome. Who go by classy tech and denic. I was in heaven,

625
00:41:04,905 --> 00:41:08,445
Speaker 3:  heaven, heaven. Like

626
00:41:08,715 --> 00:41:11,445
Speaker 3:  just a bunch of nerds talking about TVs. 14 years. So,

627
00:41:11,665 --> 00:41:15,445
Speaker 5:  So where, where were you on the, on the list of like panelists and experts

628
00:41:16,075 --> 00:41:19,485
Speaker 5:  from most to least qualified? Where would you, you say you were fully deceased?

629
00:41:20,575 --> 00:41:24,245
Speaker 3:  Fully the least. Okay. All the other judges are basically like Hollywood

630
00:41:24,245 --> 00:41:28,085
Speaker 3:  types. Okay. So the director of encoding services at Warner

631
00:41:28,085 --> 00:41:31,685
Speaker 3:  Brothers Discovery, the senior director of technical operations at

632
00:41:31,685 --> 00:41:35,005
Speaker 3:  Paramount, a handful of professional cinema,

633
00:41:35,145 --> 00:41:39,125
Speaker 3:  cinematographers and directors, a handful of professional calibrators. So

634
00:41:39,405 --> 00:41:43,165
Speaker 3:  calibrators are, that's a real job in this industry. People set up their

635
00:41:43,165 --> 00:41:46,325
Speaker 3:  studios, they bring in the professional calibrators to make sure everything

636
00:41:46,325 --> 00:41:50,205
Speaker 3:  is displaying accurately at every point in the chain. So from

637
00:41:50,205 --> 00:41:53,845
Speaker 3:  your camera to your display to your mastering display, this is a real thing.

638
00:41:53,865 --> 00:41:57,685
Speaker 3:  And so those people have kind of the most knowledge of all of the

639
00:41:57,705 --> 00:42:01,695
Speaker 3:  quirks of all of the various displays because they're constantly trying

640
00:42:01,695 --> 00:42:05,575
Speaker 3:  to get them to display accurately. And so what was particularly

641
00:42:05,975 --> 00:42:09,815
Speaker 3:  interesting is they know these TVs really well

642
00:42:10,245 --> 00:42:13,935
Speaker 3:  because these TVs are showing up increasingly

643
00:42:14,395 --> 00:42:18,175
Speaker 3:  in professional operations because fancy studio executives like

644
00:42:18,415 --> 00:42:22,335
Speaker 3:  watching things on big TVs instead of little reference monitors. And

645
00:42:22,335 --> 00:42:25,215
Speaker 3:  they're like, yeah, these Sony A 95 Ls are showing up all over the place

646
00:42:25,675 --> 00:42:29,495
Speaker 3:  as reference displays for the executives. And so they just, and and

647
00:42:29,495 --> 00:42:31,895
Speaker 3:  obviously they do fancy home theaters and other viewing rooms and all this

648
00:42:31,895 --> 00:42:34,775
Speaker 3:  stuff. So it was really interesting to talk to them 'cause they're in the

649
00:42:34,785 --> 00:42:38,695
Speaker 3:  weeds of what these things can and can't do. Yes. Sort of divorced from

650
00:42:39,395 --> 00:42:43,295
Speaker 3:  any marketing or whatever. Like they're just trying to make them look

651
00:42:43,295 --> 00:42:47,215
Speaker 3:  good professionally and they're, they're completely aware of the limits

652
00:42:47,275 --> 00:42:50,855
Speaker 3:  of the TVs. So, and then there's me and I'm like, yeah, I've just been looking

653
00:42:50,855 --> 00:42:54,695
Speaker 3:  at screens for 15 years. I have a lot of opinions. And I thought that was,

654
00:42:54,695 --> 00:42:58,645
Speaker 3:  it was kind of interesting to be that person because it

655
00:42:59,285 --> 00:43:02,165
Speaker 3:  w like we weren't supposed to talk to each other so much, but in, in the

656
00:43:02,165 --> 00:43:04,965
Speaker 3:  conversations we had, it was kind of interesting how much

657
00:43:06,065 --> 00:43:10,045
Speaker 3:  my instincts were to compare things to like phones and tablets and You

658
00:43:10,045 --> 00:43:13,805
Speaker 3:  can see how the TVs relate to what these

659
00:43:14,085 --> 00:43:16,525
Speaker 3:  companies do on their phones and tablets. So I was looking at the Samsung

660
00:43:16,625 --> 00:43:20,085
Speaker 3:  and I was like, oh, that looks like a Samsung. Like I have looked at a lot

661
00:43:20,085 --> 00:43:23,845
Speaker 3:  of Samsung screens over the years and boy does Samsung like nuclear

662
00:43:23,865 --> 00:43:27,805
Speaker 3:  colors. Yeah, Samsung has a move for sure. Yeah. And it's like, oh, and

663
00:43:27,805 --> 00:43:29,605
Speaker 3:  they're, and they were like, why do they do that? I'm like, I don't know.

664
00:43:29,605 --> 00:43:33,405
Speaker 3:  They just always do that. Like every Samsung display ever looked at has just

665
00:43:33,405 --> 00:43:37,005
Speaker 3:  been incredibly bright and colorful even at the expense of accuracy.

666
00:43:37,425 --> 00:43:39,965
Speaker 3:  and it, that was, it was kinda interesting to just have that other perspective

667
00:43:39,965 --> 00:43:43,525
Speaker 3:  in the room. They obviously knew more on the technical

668
00:43:44,085 --> 00:43:47,925
Speaker 3:  elements of the displays. Like they were, they kept bringing up the reference

669
00:43:47,945 --> 00:43:51,765
Speaker 3:  curves on the reference display. Oh wow. And being like, see this? And I'd

670
00:43:51,765 --> 00:43:55,125
Speaker 3:  be like, it's a line, like make it brighter.

671
00:43:56,585 --> 00:43:58,925
Speaker 3:  And eventually, you know, you start to pick up on what they were showing

672
00:43:58,925 --> 00:44:02,085
Speaker 3:  you. But it was just like, it was interesting to have that other perspective.

673
00:44:02,465 --> 00:44:06,445
Speaker 3:  So the, the fascinating thing about all of this is this is

674
00:44:06,445 --> 00:44:10,325
Speaker 3:  the year that Sony made a big bet on many

675
00:44:10,525 --> 00:44:14,285
Speaker 3:  LED TVs as opposed to OLEDs. So Sony's still selling a bunch of

676
00:44:14,445 --> 00:44:18,365
Speaker 3:  OLEDs. Their flagship TV is still an oled. That's a 8 95 L that's a year

677
00:44:18,365 --> 00:44:21,805
Speaker 3:  old now. That came out last year, last September basically.

678
00:44:22,945 --> 00:44:26,725
Speaker 3:  But you know, we're basically a year into it. And the 8 95 L

679
00:44:26,825 --> 00:44:30,805
Speaker 3:  won again, like it just won the shootout. And last year's tv. Last year's

680
00:44:30,805 --> 00:44:34,255
Speaker 3:  TV won the shootout. Wow. That's a quantum ed. So it has a wider

681
00:44:34,825 --> 00:44:38,575
Speaker 3:  color gamut. We think it's a Samsung panel. It pretty much is a Samsung panel.

682
00:44:38,795 --> 00:44:42,775
Speaker 3:  And then this year's Samsung ed we think is

683
00:44:42,835 --> 00:44:46,575
Speaker 3:  the, like the next generation quantum ed, but Samsung is Samsung

684
00:44:46,835 --> 00:44:50,615
Speaker 3:  and they did some weird stuff with colors and like it

685
00:44:50,645 --> 00:44:54,575
Speaker 3:  lost by just like 0.1. Okay. Right. It was just a little bit behind in

686
00:44:54,575 --> 00:44:56,015
Speaker 3:  some things because, and

687
00:44:56,015 --> 00:44:57,175
Speaker 4:  Then the LG was at the back.

688
00:44:57,755 --> 00:45:01,135
Speaker 3:  And so this is a really weird thing is the

689
00:45:01,265 --> 00:45:05,255
Speaker 3:  65 inch LG G four performed much

690
00:45:05,255 --> 00:45:09,135
Speaker 3:  worse than the 83 inch LG G four and

691
00:45:09,135 --> 00:45:13,015
Speaker 3:  the calibrators in the room who have been like setting up these TVs for different

692
00:45:13,015 --> 00:45:16,815
Speaker 3:  people are like, this is the story with these TVs, the 55 and then

693
00:45:17,035 --> 00:45:21,015
Speaker 3:  the 77 and up. Weird all great. The 65 seems

694
00:45:21,015 --> 00:45:21,495
Speaker 3:  to be worse.

695
00:45:22,035 --> 00:45:24,335
Speaker 4:  Oh no, I have to go get a new tv. Well,

696
00:45:25,575 --> 00:45:28,695
Speaker 3:  I mean, look, one takeaway I'll give everyone is like the OLEDs were so close

697
00:45:28,695 --> 00:45:32,615
Speaker 3:  to each other that it was taking like three times the amount of time

698
00:45:32,955 --> 00:45:36,895
Speaker 3:  to score them as compared to the reference. 'cause you had to see where the

699
00:45:36,895 --> 00:45:40,815
Speaker 3:  differences are. Whereas on the mini LED side, you're like, okay, the LGS

700
00:45:40,815 --> 00:45:44,775
Speaker 3:  bad Sam, no one knows what SAM is doing. And then the Sony's pretty

701
00:45:44,775 --> 00:45:48,015
Speaker 3:  good, but I can see these big problems. Right. Yeah. And so the, the game

702
00:45:48,075 --> 00:45:51,655
Speaker 3:  on that first day was you had the reference display that was showing

703
00:45:52,645 --> 00:45:56,615
Speaker 3:  ideally what, you know, the studio or whoever wants you to see in

704
00:45:56,615 --> 00:45:58,735
Speaker 3:  the picture. That's the reference display.

705
00:45:58,765 --> 00:46:01,815
Speaker 5:  Wait, can I ask a really dumb question? Yeah. Is a reference display

706
00:46:02,685 --> 00:46:06,615
Speaker 5:  like the best one? Like is that Yes. Is that how we should

707
00:46:06,615 --> 00:46:09,455
Speaker 5:  think about reference display is? Like this is the perfect television?

708
00:46:09,595 --> 00:46:13,575
Speaker 3:  Yes. No. Yes. So yes and no. I, I'll

709
00:46:13,575 --> 00:46:17,295
Speaker 3:  agree with Alex partially, but n no, it's the most accurate representation

710
00:46:17,355 --> 00:46:18,975
Speaker 3:  of like the content. So

711
00:46:18,975 --> 00:46:22,895
Speaker 5:  It's the one that like changes the least through

712
00:46:22,935 --> 00:46:23,695
Speaker 5:  the whole pipeline,

713
00:46:24,415 --> 00:46:27,255
Speaker 3:  I guess. Yeah. It's like you have a display and

714
00:46:29,115 --> 00:46:32,895
Speaker 3:  it is ideally the same display as the person who did the color on the movie.

715
00:46:33,355 --> 00:46:34,975
Speaker 5:  Got it. Right. Okay. Or, and it feel like sometimes

716
00:46:34,975 --> 00:46:37,655
Speaker 3:  That's same or a display that performs identically to that display, but it's

717
00:46:37,655 --> 00:46:41,575
Speaker 4:  Also like, it does stuff that an OLA just can't do. Right?

718
00:46:42,085 --> 00:46:45,655
Speaker 4:  Like, like a reference display is gonna do a much smoother

719
00:46:45,655 --> 00:46:49,375
Speaker 4:  gradient of color than, than an ED'S capable of. You're gonna see those weird

720
00:46:49,655 --> 00:46:51,895
Speaker 4:  stepping, that stepping issue in an OLED and

721
00:46:51,895 --> 00:46:55,655
Speaker 3:  It, right. So these, these Sony BVMs were a dual layer LCD. So they, they

722
00:46:55,685 --> 00:46:58,895
Speaker 3:  were able to do it right. They had some capabilities, EDS didn't,

723
00:46:59,505 --> 00:47:03,375
Speaker 3:  sorry, they also have giant ass fans in them. So they could

724
00:47:03,395 --> 00:47:07,335
Speaker 3:  run really bright for a very long time. All the OLEDs were dimming

725
00:47:07,335 --> 00:47:07,695
Speaker 3:  you could see.

726
00:47:07,755 --> 00:47:09,255
Speaker 5:  And you said they're what, like $40,000?

727
00:47:09,425 --> 00:47:11,615
Speaker 3:  $40,000? Yeah. Cool. Okay. Interestingly,

728
00:47:11,955 --> 00:47:12,615
Speaker 4:  And they're also small

729
00:47:13,035 --> 00:47:15,535
Speaker 3:  And they're, they're smaller. But interestingly to your point, Alex, the

730
00:47:15,825 --> 00:47:19,695
Speaker 3:  cutie OLEDs have the capability of displaying more

731
00:47:19,695 --> 00:47:23,295
Speaker 3:  colors than these reference displays. So there's places where they

732
00:47:23,575 --> 00:47:27,415
Speaker 3:  actually aren't as capable as the televisions. Right. 'cause and so

733
00:47:27,415 --> 00:47:29,925
Speaker 3:  there were, there were scenes, I forget which movie it specifically was,

734
00:47:30,215 --> 00:47:34,005
Speaker 3:  where we were, it was, I think it was like the, the Saber fight in Rogue

735
00:47:34,025 --> 00:47:37,605
Speaker 3:  One or Darth Vader. Just like lightened people up. Yeah. Spoiler.

736
00:47:38,675 --> 00:47:40,035
Speaker 3:  I mean, rogue One is itself a spoiler. Oh, that's

737
00:47:40,075 --> 00:47:41,195
Speaker 4:  Actually a really good one for that.

738
00:47:41,425 --> 00:47:45,275
Speaker 3:  Yeah, it's great. Spoiler. Darth Vader kills people in a Star Wars movie.

739
00:47:45,595 --> 00:47:49,515
Speaker 3:  What? Oh no. But one of the questions there was like,

740
00:47:49,935 --> 00:47:53,795
Speaker 3:  is this accurate? Because the people who made the movie were just sort of

741
00:47:54,025 --> 00:47:57,835
Speaker 3:  mastering to whatever set of colors, but they couldn't see them.

742
00:47:58,335 --> 00:48:00,955
Speaker 3:  So then it's like, is it different? Is it bad? It was kind of, that was pretty

743
00:48:01,195 --> 00:48:04,835
Speaker 3:  interesting. Right? Yeah. And so the, the reason that the first day was objective,

744
00:48:05,615 --> 00:48:08,675
Speaker 3:  but the goal was one outta five. How much is this the same as the reference

745
00:48:08,675 --> 00:48:12,315
Speaker 3:  display? Which is a really interesting way of thinking about it, a picture.

746
00:48:13,035 --> 00:48:16,595
Speaker 3:  'cause sometimes you're like, this is better. I think this is better than

747
00:48:16,595 --> 00:48:20,275
Speaker 3:  the reference display, but it was different. So you knocked it down and that

748
00:48:20,275 --> 00:48:23,555
Speaker 3:  took a, a while to get your, your head around basically. This

749
00:48:23,555 --> 00:48:27,355
Speaker 4:  Is where like I just, accuracy is king for me in TVs. Yeah. Because I,

750
00:48:27,355 --> 00:48:31,075
Speaker 4:  I've done the calibration. Like I've, I went to to, to

751
00:48:31,155 --> 00:48:34,915
Speaker 4:  ISF and did like the week long course with them and everything. So I, I love

752
00:48:34,915 --> 00:48:38,715
Speaker 4:  the accuracy and so when I hear like, oh, the Samsung is probably doing more,

753
00:48:38,765 --> 00:48:42,755
Speaker 4:  displaying more reds, well those reds were never intended to be

754
00:48:42,785 --> 00:48:46,235
Speaker 4:  displayed according to the reference monitor. So is that actually better?

755
00:48:46,415 --> 00:48:47,355
Speaker 4:  No, because that's

756
00:48:47,695 --> 00:48:47,915
Speaker 3:  Yep.

757
00:48:48,495 --> 00:48:51,835
Speaker 4:  The, like the, the director could never have decided that, so therefore it's

758
00:48:51,835 --> 00:48:54,915
Speaker 4:  not better. Yeah. And we see that a lot with like classic film too. Like

759
00:48:55,375 --> 00:48:58,755
Speaker 4:  all of the, all the stuff they captured on Technicolor is so much more vibrant.

760
00:48:58,775 --> 00:49:01,915
Speaker 4:  And that was before we even had color spaces is like a concept.

761
00:49:02,615 --> 00:49:06,075
Speaker 4:  And, and, and so it's just totally different. and it,

762
00:49:06,345 --> 00:49:08,075
Speaker 4:  it's weird. It's just weird.

763
00:49:08,455 --> 00:49:11,915
Speaker 5:  So you're a real, like what did the, what did the founding fathers intend

764
00:49:11,945 --> 00:49:12,395
Speaker 5:  kind of

765
00:49:12,395 --> 00:49:16,235
Speaker 4:  Person? Yeah. I, I'm, I'm a founder's intent. I'm, me and Scalia are, are

766
00:49:16,235 --> 00:49:16,675
Speaker 4:  just over there.

767
00:49:17,345 --> 00:49:17,635
Speaker 5:  Yeah.

768
00:49:17,815 --> 00:49:21,275
Speaker 3:  You are truly the An and Scalia of TV calibrations. Whereas NE

769
00:49:21,535 --> 00:49:25,355
Speaker 5:  Is just like, what looks sick now? Like it's 2024 baby giving them reds

770
00:49:26,495 --> 00:49:28,955
Speaker 3:  Lo and I famously love a Samsung display.

771
00:49:30,655 --> 00:49:32,115
Speaker 5:  How many frame TVs do you own?

772
00:49:33,295 --> 00:49:36,915
Speaker 3:  Not even in the mix. I'm just put, I was just putting it out there. I'm sitting

773
00:49:36,915 --> 00:49:40,835
Speaker 3:  next to like a hundred inch frame tv and it's like the T TV

774
00:49:40,835 --> 00:49:43,515
Speaker 3:  quality of frame compared to all of these is like, nah.

775
00:49:43,655 --> 00:49:44,795
Speaker 4:  That's why your, your backs

776
00:49:44,895 --> 00:49:48,435
Speaker 3:  To it present. Can you describe a, a picture quality as present, because

777
00:49:48,435 --> 00:49:52,355
Speaker 3:  that is a Samsung frame TV appears, that's what a Samsung frame

778
00:49:52,355 --> 00:49:55,835
Speaker 3:  TV looks like. Well, fascinating. On the mini, oh, it's all really close.

779
00:49:55,905 --> 00:49:56,475
Speaker 3:  Alex, like

780
00:49:58,065 --> 00:50:01,315
Speaker 3:  some color stuff aside in this, like, you know, the fact that the cutie oles

781
00:50:01,465 --> 00:50:05,155
Speaker 3:  have a wider color gamut is like kind of interesting, but like

782
00:50:05,155 --> 00:50:08,035
Speaker 3:  outside of that context, it would be almost impossible to tell 'em apart.

783
00:50:08,105 --> 00:50:11,835
Speaker 3:  Yeah. And, and that, and honestly it was like, the way you could tell was

784
00:50:11,835 --> 00:50:15,715
Speaker 3:  it was taking so long for people to score them because

785
00:50:15,735 --> 00:50:18,635
Speaker 3:  the difference between a four and a five, it was like, am I seeing any, it

786
00:50:18,635 --> 00:50:22,515
Speaker 3:  was like, what is it? It was only the LG that was like, it just was really

787
00:50:22,645 --> 00:50:25,675
Speaker 3:  muddy in dark scenes. It just like didn't have the detail in dark scenes

788
00:50:25,675 --> 00:50:28,845
Speaker 3:  that the other one said weird on the mini LED side, everyone was like, all

789
00:50:28,845 --> 00:50:31,565
Speaker 3:  right, that one's bad. This one's good except for the Sony, because Sony

790
00:50:31,565 --> 00:50:34,925
Speaker 3:  is putting so much emphasis on mini LED this year.

791
00:50:35,315 --> 00:50:39,205
Speaker 3:  Like they're the Bravia nine, which apart from the 8, 9 5 is like the flagship.

792
00:50:39,205 --> 00:50:43,085
Speaker 3:  It's the one they're pushing all mini LEDs. They get hella bright

793
00:50:43,195 --> 00:50:46,245
Speaker 3:  because they're just LCD TVs with an LED backlight.

794
00:50:47,025 --> 00:50:49,845
Speaker 3:  And you're like, oh, this tech has a long way to go. and it could get there,

795
00:50:49,845 --> 00:50:53,205
Speaker 3:  but it's nowhere close. Yeah. Like they look kind of washed out. The colors

796
00:50:53,305 --> 00:50:57,045
Speaker 3:  are a little shifted. The detail isn't quite there. They're still a little

797
00:50:57,045 --> 00:51:00,365
Speaker 3:  blooming. So if you think about how a mini LED backlight works,

798
00:51:00,875 --> 00:51:04,045
Speaker 3:  it's just another screen of

799
00:51:04,465 --> 00:51:08,045
Speaker 3:  pixels behind the screen that light up. Like it's a lower

800
00:51:08,325 --> 00:51:11,965
Speaker 3:  res screen behind the screen that lights up to produce light and it has to

801
00:51:11,965 --> 00:51:15,605
Speaker 3:  match what's on the screen in real time so that you get true. So they're

802
00:51:15,605 --> 00:51:18,365
Speaker 3:  off when there's something black and they're lit when there's something on

803
00:51:18,365 --> 00:51:21,765
Speaker 3:  the screen. So if there's any latency you see blooming

804
00:51:22,335 --> 00:51:26,125
Speaker 3:  right, or if the zone is too big, because it's not one-to-one you see

805
00:51:26,125 --> 00:51:29,925
Speaker 3:  blooming. And so You can see, and the algorithms are like trying to manage

806
00:51:29,985 --> 00:51:33,725
Speaker 3:  all of this as fast as they can with as little latency as possible. The Samsung

807
00:51:33,865 --> 00:51:37,325
Speaker 3:  was like all over the place. Like sometimes like this just looks like a regular,

808
00:51:37,875 --> 00:51:41,605
Speaker 3:  like local dimming tv. The Sony was much better but still had the problems.

809
00:51:41,605 --> 00:51:45,485
Speaker 3:  And then all of 'em, because they're LCDs, their viewing angles aren't as

810
00:51:45,485 --> 00:51:49,345
Speaker 3:  good as the OLEDs and they're huge. Right? These 65

811
00:51:49,345 --> 00:51:52,785
Speaker 3:  inch, 83 inch TVs we're looking at. So if you were too close to them,

812
00:51:53,175 --> 00:51:56,585
Speaker 3:  even just moving an inch or two to the left or right, shifted all the color

813
00:51:56,585 --> 00:52:00,065
Speaker 3:  and brightness and you're like, oh, we're just not close. Like

814
00:52:00,805 --> 00:52:04,185
Speaker 3:  Sony's trying the hardest here, but we're not close. I,

815
00:52:04,265 --> 00:52:07,145
Speaker 4:  I just, I don't understand why we would go backwards on viewing angle

816
00:52:07,295 --> 00:52:10,345
Speaker 3:  Because they're cheaper. 'cause You can get 83 inch TV for much cheaper and

817
00:52:10,345 --> 00:52:12,945
Speaker 3:  it's very bright and it's very impressive. And outside of that room full

818
00:52:12,945 --> 00:52:16,745
Speaker 3:  of the most incredible display nerds I've ever met in my entire life, and

819
00:52:16,745 --> 00:52:19,945
Speaker 3:  I want all of them to come home with me tomorrow outside of that room, I

820
00:52:19,945 --> 00:52:23,825
Speaker 3:  think it would be very hard to tell these TVs apart. But it was like

821
00:52:24,375 --> 00:52:27,545
Speaker 3:  just that experience of paying such close attention

822
00:52:28,405 --> 00:52:32,345
Speaker 3:  to one quality of these products with other people

823
00:52:32,365 --> 00:52:35,785
Speaker 3:  who were doing that same task. It was like very refreshing to me.

824
00:52:36,325 --> 00:52:39,785
Speaker 3:  We weren't judging whether or not Tizen is any good compared to Web Os. We

825
00:52:39,785 --> 00:52:43,505
Speaker 3:  weren't judging how many HDMI 2.1 ports, the Sony TV has not enough,

826
00:52:43,995 --> 00:52:47,945
Speaker 3:  right? Like none of that stuff, game mode, all that. We were like, can this

827
00:52:48,135 --> 00:52:51,985
Speaker 3:  picture be calibrated to match a reference monitor and which one comes

828
00:52:51,985 --> 00:52:55,905
Speaker 3:  closer? And that I I I, there's just a part of that having reviewed

829
00:52:55,965 --> 00:52:59,745
Speaker 3:  so many products over the years and had to think about so many things, it's

830
00:52:59,745 --> 00:53:03,185
Speaker 3:  like, oh, this is actually a really interesting way of thinking about these

831
00:53:03,185 --> 00:53:04,065
Speaker 3:  products specifically.

832
00:53:04,525 --> 00:53:08,025
Speaker 5:  Was there a consistent agreement among the, what was it, eight panelists?

833
00:53:08,025 --> 00:53:11,545
Speaker 5:  That's a lot of people to all point at this same, like, it's both

834
00:53:11,545 --> 00:53:15,105
Speaker 5:  objective and subjective in a certain way. Like, did everybody tend to agree

835
00:53:15,105 --> 00:53:15,585
Speaker 5:  on everything?

836
00:53:16,365 --> 00:53:20,145
Speaker 3:  We weren't, we were also excited to be there when we started judging,

837
00:53:20,165 --> 00:53:23,945
Speaker 3:  we were all chattering and then we were like told to stop. Okay.

838
00:53:24,445 --> 00:53:26,965
Speaker 3:  So our score, I don't know what everybody else scored. You know, like a worry

839
00:53:26,965 --> 00:53:30,885
Speaker 3:  for me is like the consumer reviewer in the group was

840
00:53:30,885 --> 00:53:33,005
Speaker 3:  that I had no idea what I was talking about. I was like, man, I hope my scores

841
00:53:33,065 --> 00:53:36,685
Speaker 3:  are close. And they were in the end, you know, the the

842
00:53:36,955 --> 00:53:40,605
Speaker 3:  average, the, the averages that were released and the rankings that were

843
00:53:40,765 --> 00:53:44,405
Speaker 3:  released were exactly as I had thought them. Okay. So didn't see somebody

844
00:53:44,405 --> 00:53:48,245
Speaker 3:  like the mainstream. You know, I think most people's, the one

845
00:53:48,445 --> 00:53:50,445
Speaker 3:  LG stand in the room who's like, I love blooming

846
00:53:52,395 --> 00:53:56,365
Speaker 3:  that LG mini E is not good. Like, oh, it's like a half-hearted. And to

847
00:53:56,365 --> 00:54:00,285
Speaker 3:  be fair, it was the cheapest TV on display. Yeah. Thousands

848
00:54:00,285 --> 00:54:01,045
Speaker 3:  of dollars. So

849
00:54:01,315 --> 00:54:04,685
Speaker 4:  They put all their efforts into OLEDs anyway. Like Yeah. They just farted

850
00:54:04,685 --> 00:54:05,005
Speaker 4:  that out.

851
00:54:05,555 --> 00:54:08,165
Speaker 3:  Yeah. To have it, it is like, let's hedge our bet a little bit. Like maybe

852
00:54:08,165 --> 00:54:11,765
Speaker 3:  this is the thing. But yeah, they have the micro lens array, which

853
00:54:12,005 --> 00:54:15,325
Speaker 3:  increases the brightness on their OLEDs. Like I said, the, the three OLEDs

854
00:54:15,325 --> 00:54:18,965
Speaker 3:  were so close to each other. You can tell that it's a mature

855
00:54:19,175 --> 00:54:22,885
Speaker 3:  technology, right? It's, it's just hit a point of refinement

856
00:54:23,295 --> 00:54:26,285
Speaker 3:  where you have to care a lot about extremely

857
00:54:27,235 --> 00:54:31,125
Speaker 3:  like arcane picture details. And Alex, I think you, and you and I

858
00:54:31,125 --> 00:54:34,765
Speaker 3:  vibe on this, like yeah, I care a lot about arcane picture details. The many

859
00:54:34,915 --> 00:54:38,885
Speaker 3:  LEDs is like all over my, my notes on the color for the Sony Bravia nine

860
00:54:39,315 --> 00:54:42,845
Speaker 3:  were was just the single sentence colors all over the map.

861
00:54:43,915 --> 00:54:47,485
Speaker 3:  Like just all over the place. Like who knows what's going on here. So that

862
00:54:47,485 --> 00:54:50,485
Speaker 3:  was like the first day. The second day was much more subjective.

863
00:54:51,195 --> 00:54:54,645
Speaker 3:  They took down the 60 fives, they put up the biggest available

864
00:54:54,855 --> 00:54:58,445
Speaker 3:  sizes for all the TVs. So that was 77 for the

865
00:54:58,595 --> 00:55:01,885
Speaker 3:  Sony 83 for the LG 85 for the mini LEDs

866
00:55:02,665 --> 00:55:06,565
Speaker 3:  and the Robertson, the owner was like, I've never had more people ask

867
00:55:06,585 --> 00:55:10,125
Speaker 3:  for a head-to-head comparison of two TVs than people ask for the LG G

868
00:55:10,125 --> 00:55:14,085
Speaker 3:  4 83 versus the Sony Mini L led 85. Hmm. Because they're very, they're

869
00:55:14,085 --> 00:55:17,885
Speaker 3:  very price competitive. And one is obviously bigger, right? It's tds

870
00:55:17,985 --> 00:55:21,645
Speaker 3:  people love big, cheap screens. So he is like, this is what everyone wants

871
00:55:21,645 --> 00:55:24,485
Speaker 3:  to see. So those two are right next to each other and the LG just wiped the

872
00:55:24,485 --> 00:55:28,285
Speaker 3:  floor. Wow. Like so much better. Just incredibly better. And

873
00:55:28,285 --> 00:55:31,165
Speaker 3:  the fact that the LG 83 was so much better than 65, that's what everyone

874
00:55:31,165 --> 00:55:34,925
Speaker 3:  talked about. But we weren't doing the intense reference

875
00:55:35,005 --> 00:55:38,605
Speaker 3:  comparison. They took him, they, they set 'em up outta the box, they turned

876
00:55:38,605 --> 00:55:42,445
Speaker 3:  on filmmaker mode to turn off all the bullshit and they turn

877
00:55:42,445 --> 00:55:45,605
Speaker 3:  off energy saver because Energy Saver brings the brightness down.

878
00:55:46,565 --> 00:55:49,615
Speaker 4:  Yeah. E Energy Saver is the number one thing you should turn off on your

879
00:55:49,615 --> 00:55:53,375
Speaker 4:  display. I mean, destroy, destroy the environment. But

880
00:55:53,845 --> 00:55:56,775
Speaker 4:  just go turn. If you have it on right now, go turn it off. Right. We'll

881
00:55:56,775 --> 00:55:59,495
Speaker 3:  Wait. It just significantly reduces the brightest of your panel. So they

882
00:55:59,495 --> 00:56:01,975
Speaker 3:  turn off energy saver and they put 'em in filmmaker mode, or I think Sony

883
00:56:01,975 --> 00:56:04,735
Speaker 3:  calls it professional mode, just turns off all the stuff and they let 'em

884
00:56:04,735 --> 00:56:08,015
Speaker 3:  run outta the box. And that's where like Samsung was the most Samsung. Like

885
00:56:08,015 --> 00:56:09,415
Speaker 3:  your colors, do you like 'em?

886
00:56:12,035 --> 00:56:15,655
Speaker 3:  And I, you know, the, the lg the 83 inch LG just,

887
00:56:16,275 --> 00:56:19,455
Speaker 3:  it was just a great picture, right? Like it, it was right behind the Sony

888
00:56:19,455 --> 00:56:22,215
Speaker 3:  in that evaluation. But we weren't doing numbers. Yeah. We were just sort

889
00:56:22,215 --> 00:56:25,765
Speaker 3:  of ranking 1, 2, 3 for all the clips that we saw. And I, at the end,

890
00:56:26,825 --> 00:56:30,445
Speaker 3:  and we can just wrap it up here at the end, I was basically put the Samsung

891
00:56:31,295 --> 00:56:35,285
Speaker 3:  cutie ole, the S 95 D and the Sony

892
00:56:35,645 --> 00:56:39,205
Speaker 3:  LED were in a tie. For me it was hard, it was hard for me to decide 'cause

893
00:56:39,205 --> 00:56:42,565
Speaker 3:  the Samsung colors were so all over the place and the Sony's backlight was

894
00:56:42,565 --> 00:56:45,085
Speaker 3:  so all over the place and the view angles were weird and I couldn't decide.

895
00:56:45,085 --> 00:56:48,125
Speaker 3:  And in the end I was like, it's an OLED because I know the Samsung can be

896
00:56:48,325 --> 00:56:52,205
Speaker 3:  calibrated and I know the Sony can't. So that's how I picked again,

897
00:56:52,205 --> 00:56:56,165
Speaker 3:  like my takeaway from this was one, I should spend more time in rooms with

898
00:56:56,165 --> 00:56:59,525
Speaker 3:  huge nerds. Yes. 'cause those are my people. That's, and

899
00:56:59,525 --> 00:57:03,045
Speaker 5:  I would say what a hundred thousand dollars worth of TVs on

900
00:57:03,045 --> 00:57:05,445
Speaker 3:  A wall in front. More than that. I mean like, this store is out of control.

901
00:57:06,555 --> 00:57:09,685
Speaker 3:  Like that's just the TVs. We didn't even talk about the audio side of the

902
00:57:09,685 --> 00:57:13,605
Speaker 3:  store. Scarsdale is a wealthy town, this man,

903
00:57:13,605 --> 00:57:17,485
Speaker 3:  like we're moving product and it was great. And he sells, you know,

904
00:57:17,485 --> 00:57:19,885
Speaker 3:  over the country and they've been doing it for a long time. The room was

905
00:57:19,885 --> 00:57:23,645
Speaker 3:  full of Sony's actual mark, like product people, not just

906
00:57:23,885 --> 00:57:26,445
Speaker 5:  Ing people. But, so this like matters. This is not just like a small town

907
00:57:26,445 --> 00:57:27,925
Speaker 5:  bunch of nerds. This is like a big people

908
00:57:28,145 --> 00:57:30,445
Speaker 3:  TV shootout is a thing. There's a press release and like a whole thing. Oh

909
00:57:30,445 --> 00:57:33,205
Speaker 3:  wow. Like there are YouTubers there making YouTube videos. There are YouTubers

910
00:57:33,395 --> 00:57:37,085
Speaker 3:  live streaming with the calibrators. Just talking

911
00:57:37,385 --> 00:57:39,725
Speaker 3:  TVs in the back room. Yeah.

912
00:57:39,865 --> 00:57:42,445
Speaker 5:  Big deal. I already assigned me deal, like 10,000 words on the calibrators.

913
00:57:42,685 --> 00:57:43,365
Speaker 5:  So that's coming.

914
00:57:43,665 --> 00:57:46,925
Speaker 3:  That's actually a great name for a show. The calibrators.

915
00:57:47,185 --> 00:57:48,205
Speaker 5:  It is pretty good. I

916
00:57:48,205 --> 00:57:49,125
Speaker 4:  Would, I would watch her listen.

917
00:57:49,505 --> 00:57:52,485
Speaker 5:  And the picture over the course of every episode, the picture just gets slightly

918
00:57:52,485 --> 00:57:53,725
Speaker 5:  better. Yeah.

919
00:57:55,725 --> 00:57:58,685
Speaker 3:  Anyway, that's my TV story. I finally got to talk about it. It's on the site

920
00:57:58,685 --> 00:58:02,485
Speaker 3:  now. You should go read it. I'm sorry. If you have an LG G four and

921
00:58:02,505 --> 00:58:06,365
Speaker 3:  you, you, it's a great tv. You're fine. Don't listen to me. Just give it

922
00:58:06,365 --> 00:58:07,245
Speaker 3:  a 10. Just say you got it.

923
00:58:07,475 --> 00:58:08,405
Speaker 5:  Alex is so disappointed.

924
00:58:08,745 --> 00:58:12,205
Speaker 4:  I'm, I'm okay. I'm okay. I'm working through it. I'll be fine.

925
00:58:12,675 --> 00:58:16,605
Speaker 5:  Alex, if you want I'll take your crappy tv. Okay. Anyone who would like to

926
00:58:16,605 --> 00:58:20,045
Speaker 5:  give me their very good TVs, I will happily take them with no complaints

927
00:58:20,045 --> 00:58:20,765
Speaker 5:  whatsoever. You

928
00:58:20,765 --> 00:58:23,245
Speaker 4:  Just be like, oh, it's so crappy. Oh, it's terrible. No.

929
00:58:23,245 --> 00:58:26,205
Speaker 3:  Wait, can I say, can I say one more thing at the, oh, at the opening Soul

930
00:58:26,205 --> 00:58:29,405
Speaker 3:  event, they're talking about the TVs and like what they are and all this

931
00:58:29,405 --> 00:58:31,645
Speaker 3:  stuff. And they said two things. One,

932
00:58:33,435 --> 00:58:37,245
Speaker 3:  they were like TC and high sense aren't here. They asked not to be included

933
00:58:37,245 --> 00:58:38,005
Speaker 3:  in a competition

934
00:58:38,915 --> 00:58:40,205
Speaker 4:  Because they were gonna lose

935
00:58:40,385 --> 00:58:42,965
Speaker 3:  You can just, You can just read into that. And then later Robert was like,

936
00:58:42,965 --> 00:58:44,885
Speaker 3:  one year Vizio was here and it was embarrassing for them.

937
00:58:45,465 --> 00:58:45,885
Speaker 5:  Oh boy.

938
00:58:46,185 --> 00:58:49,525
Speaker 3:  So that's, did you read into that? Whatever you want Physio rough.

939
00:58:49,875 --> 00:58:53,605
Speaker 5:  It's a real like, I will not be running for president in 20, 24 kinds of

940
00:58:53,605 --> 00:58:54,365
Speaker 5:  vibes. Yeah.

941
00:58:56,915 --> 00:58:59,725
Speaker 3:  Okay. That was it. That was my TV adventure. Thank you for joining me on

942
00:58:59,725 --> 00:59:03,245
Speaker 3:  this journey. This is why I started The Verge so I could sit in a room full

943
00:59:03,245 --> 00:59:03,365
Speaker 3:  of

944
00:59:03,505 --> 00:59:05,685
Speaker 5:  TVs. Do you think they'll invite you back next year? Did you do a good enough

945
00:59:05,685 --> 00:59:06,645
Speaker 5:  job? I hope

946
00:59:06,745 --> 00:59:06,965
Speaker 3:  So.

947
00:59:07,725 --> 00:59:11,365
Speaker 4:  I hope can can can we come with you? Just, we'll, we'll be quiet. We'll just

948
00:59:11,365 --> 00:59:11,725
Speaker 4:  stand there

949
00:59:11,835 --> 00:59:13,365
Speaker 5:  Alex and I'll live stream it next year.

950
00:59:13,645 --> 00:59:16,405
Speaker 3:  I asked Chris Welch if he wanted to come with me next year and he goes, I

951
00:59:16,405 --> 00:59:17,725
Speaker 3:  don't want to get into that level of smoke.

952
00:59:20,365 --> 00:59:20,925
Speaker 5:  I respect that.

953
00:59:21,595 --> 00:59:24,725
Speaker 3:  Yeah, it was great. All right. We should talk about just a handful

954
00:59:25,705 --> 00:59:29,605
Speaker 3:  of, I don't know, regulatory things. What do you wanna call them? But

955
00:59:29,605 --> 00:59:32,045
Speaker 3:  the main one that I really want spend just a minute on

956
00:59:33,945 --> 00:59:37,925
Speaker 3:  is Apple. and it, it just can't give itself a

957
00:59:37,925 --> 00:59:41,725
Speaker 3:  break when it comes to the app store and fees. We gets trouble's, unfor error

958
00:59:41,905 --> 00:59:45,765
Speaker 3:  all over the world, right? It has an antitrust lawsuit in this country, in

959
00:59:45,765 --> 00:59:49,725
Speaker 3:  the eu, various charming European bureaucrats

960
00:59:49,725 --> 00:59:53,125
Speaker 3:  wake up every morning thinking about ways to troll, troll Tim Cook on Twitter.

961
00:59:53,515 --> 00:59:57,405
Speaker 3:  Like this company's under a lot of pressure. And then it won't

962
00:59:57,405 --> 01:00:01,045
Speaker 3:  just do things that make its life easier. I dunno how to describe this, but

963
01:00:01,515 --> 01:00:04,965
Speaker 3:  this is, I'm just, I'm gonna tell you this story and you,

964
01:00:05,505 --> 01:00:09,445
Speaker 3:  you, if people out there can figure out why Apple did this, let

965
01:00:09,445 --> 01:00:13,405
Speaker 3:  us know. So Patreon exists, right? You can,

966
01:00:13,405 --> 01:00:16,605
Speaker 3:  You can be a fan of someone. You can pay them some money to do whatever.

967
01:00:16,805 --> 01:00:20,645
Speaker 3:  People on Patreon do knit clothes, make video games, whatever. It's

968
01:00:20,755 --> 01:00:24,355
Speaker 3:  Patreon. They've been in a gray zone

969
01:00:24,625 --> 01:00:28,535
Speaker 3:  with the app store for years because You can

970
01:00:28,635 --> 01:00:31,895
Speaker 3:  pay people money in Patreon and they haven't been charging the fee,

971
01:00:32,425 --> 01:00:36,015
Speaker 3:  right? They haven't been giving Apple the 30%. And I actually had

972
01:00:36,125 --> 01:00:39,415
Speaker 3:  Patreon co Jack Conte on decoder a while ago and I said,

973
01:00:39,965 --> 01:00:42,455
Speaker 3:  have you ever talked to Apple about this? Like, are you an exception? And

974
01:00:42,455 --> 01:00:46,215
Speaker 3:  he was like, no, please stop talking about it. Yeah. Right.

975
01:00:46,215 --> 01:00:50,185
Speaker 3:  Like they know they're in this gray area, okay. And

976
01:00:50,185 --> 01:00:52,705
Speaker 3:  there, there have been other companies that wanna do Patreon, like things

977
01:00:52,705 --> 01:00:56,185
Speaker 3:  like this little company fan house, right? And they did a whole pressure

978
01:00:56,385 --> 01:01:00,215
Speaker 3:  campaign to say, why are you charging our creators 30%? Like

979
01:01:00,215 --> 01:01:02,495
Speaker 3:  this is unfair. You're providing no value to them. Right?

980
01:01:02,495 --> 01:01:05,935
Speaker 5:  And the 'cause the idea is if you sign up for a creator

981
01:01:06,295 --> 01:01:09,975
Speaker 5:  subscription inside of the app, apple will treat that as an in-app purchase

982
01:01:10,195 --> 01:01:14,175
Speaker 5:  and take its 30%, right? Yeah. Okay. So they, they see

983
01:01:14,325 --> 01:01:17,535
Speaker 5:  signing up for whatever my favorite podcast on Patreon

984
01:01:18,195 --> 01:01:22,095
Speaker 5:  at the same as signing up for Spotify through the app.

985
01:01:22,285 --> 01:01:26,255
Speaker 3:  Sure. And, if you wanna be a very pedantic, that is probably

986
01:01:26,435 --> 01:01:27,375
Speaker 3:  the correct interpretation,

987
01:01:27,375 --> 01:01:31,055
Speaker 5:  Except that for years it wasn't like, right. That feels important to keep

988
01:01:31,055 --> 01:01:31,295
Speaker 5:  saying

989
01:01:32,195 --> 01:01:36,175
Speaker 3:  Ex, particularly for Patreon, they have been in this gray area for

990
01:01:36,175 --> 01:01:40,015
Speaker 3:  years. You, you are a Patreon creator, you sign up

991
01:01:40,015 --> 01:01:43,935
Speaker 3:  for Patreon, you agree your Patreon is gonna take 8% and you're

992
01:01:43,935 --> 01:01:47,355
Speaker 3:  gonna take the rest of the money. That's, it's fine. That's a fine deal.

993
01:01:48,585 --> 01:01:52,275
Speaker 3:  Apple's like, we want 30% before Patreon takes 8%.

994
01:01:53,215 --> 01:01:56,715
Speaker 3:  So now it, someone did the math. Instead of needing a thousand true fans,

995
01:01:56,715 --> 01:02:00,395
Speaker 3:  which is the number everybody always says you need 1,554 fans

996
01:02:01,315 --> 01:02:05,075
Speaker 3:  like to make the same money that you were doing before. That's weird.

997
01:02:05,695 --> 01:02:09,635
Speaker 3:  and it is weird because Apple doesn't need this fight right now

998
01:02:10,065 --> 01:02:13,035
Speaker 3:  because it's under all of this pressure for whether or not these fees are

999
01:02:13,035 --> 01:02:15,835
Speaker 3:  fair. Whether the app store is fair, whether Apple has too much power in

1000
01:02:15,835 --> 01:02:18,555
Speaker 3:  the market overall antitrust lawsuit in this country. We,

1001
01:02:19,685 --> 01:02:23,565
Speaker 4:  I figured out why they did it. Yeah. So whoever sent the email and was

1002
01:02:23,565 --> 01:02:25,445
Speaker 4:  like, okay, we're gonna, we're gonna increase, we're gonna start charging

1003
01:02:25,445 --> 01:02:28,285
Speaker 4:  the 30% of Patreon is actually like,

1004
01:02:29,225 --> 01:02:33,205
Speaker 4:  was placed there by someone else to just make Apple give up

1005
01:02:33,725 --> 01:02:34,085
Speaker 4:  s like you

1006
01:02:34,735 --> 01:02:36,205
Speaker 3:  Department of Justice sleep agent.

1007
01:02:36,235 --> 01:02:39,245
Speaker 4:  Yeah. Yeah. Somebody like, like, like they're, they're just a spy or something.

1008
01:02:39,245 --> 01:02:43,045
Speaker 4:  And they were sitting because it just, it doesn't, why would you do that?

1009
01:02:43,105 --> 01:02:43,485
Speaker 4:  Why would you

1010
01:02:43,555 --> 01:02:44,885
Speaker 3:  Just tonight on the calibrators.

1011
01:02:46,395 --> 01:02:49,845
Speaker 4:  Yeah. The calibrators went in. They like, they, they like, they, they

1012
01:02:49,845 --> 01:02:53,285
Speaker 4:  parachute it in and they were like, okay, we're gonna do this. So that we

1013
01:02:53,285 --> 01:02:57,085
Speaker 4:  give even more ammunition for when we go after Apple for

1014
01:02:57,085 --> 01:02:59,405
Speaker 4:  all the things we're going after Apple for around the 30%.

1015
01:03:00,075 --> 01:03:03,925
Speaker 3:  Yeah. Maybe. It just seems like there are ways to make your life

1016
01:03:03,925 --> 01:03:07,125
Speaker 3:  easier and there are ways to make your life harder pissing off a bunch of

1017
01:03:07,125 --> 01:03:10,765
Speaker 3:  independent creators to whom you are providing no value.

1018
01:03:11,675 --> 01:03:15,305
Speaker 3:  Right. You can make the argument that Apple provides a lot of value to its

1019
01:03:15,315 --> 01:03:19,005
Speaker 3:  developers, right. They make the APIs, they ship the

1020
01:03:19,205 --> 01:03:22,725
Speaker 3:  platform, they run some of the services, they make X code.

1021
01:03:23,435 --> 01:03:27,325
Speaker 3:  Sure. It's very debatable. Like truly debatable. Yeah.

1022
01:03:27,825 --> 01:03:31,765
Speaker 3:  But You can make the argument and a lot of people have, if you are a Patreon

1023
01:03:31,765 --> 01:03:35,445
Speaker 3:  creator, no value is coming your way from Apple.

1024
01:03:36,185 --> 01:03:38,525
Speaker 3:  He probably actually comes from Patreon and you're already paying him money.

1025
01:03:38,735 --> 01:03:42,285
Speaker 3:  Right. So like why Apple's showing up and be like, we want 30%

1026
01:03:42,835 --> 01:03:46,125
Speaker 3:  that it's just like too much. Yeah. And I suspect a lot of these Patreon

1027
01:03:46,285 --> 01:03:49,725
Speaker 3:  creators are going to tell their audiences about it. And now Apple is right.

1028
01:03:50,185 --> 01:03:54,085
Speaker 3:  In a fight with creatives, did they sort of

1029
01:03:54,085 --> 01:03:57,085
Speaker 3:  keep walking into like there a crush ad that they had to apologize for? Yep.

1030
01:03:57,555 --> 01:04:01,285
Speaker 3:  Like why they just keep making their life harder with these creatives.

1031
01:04:01,985 --> 01:04:05,965
Speaker 3:  And I I just don't know for what money, like how like if you took 30%

1032
01:04:05,965 --> 01:04:09,165
Speaker 3:  of all of Patreon's revenue and you gave it to Tim Cook, he'd be like, get

1033
01:04:09,165 --> 01:04:11,325
Speaker 3:  outta my face. Yeah. Like this is nothing.

1034
01:04:11,915 --> 01:04:12,205
Speaker 4:  Yeah.

1035
01:04:12,675 --> 01:04:14,325
Speaker 3:  Like this isn't even gas for the jet.

1036
01:04:15,545 --> 01:04:19,205
Speaker 5:  It probably isn't. The only thing I can think is that

1037
01:04:19,935 --> 01:04:23,845
Speaker 5:  Apple is desperately trying to get to

1038
01:04:23,885 --> 01:04:26,805
Speaker 5:  a place where it can say with a straight face that it enforces all of its

1039
01:04:26,805 --> 01:04:30,725
Speaker 5:  rules equally. Because one of the things that has happened to

1040
01:04:30,725 --> 01:04:33,405
Speaker 5:  Apple over and over is that it keeps saying

1041
01:04:34,535 --> 01:04:37,525
Speaker 5:  these are the rules and we we're very clear about them and we apply them

1042
01:04:37,525 --> 01:04:41,205
Speaker 5:  to everybody and then every 15 minutes we hear about a

1043
01:04:41,205 --> 01:04:44,965
Speaker 5:  sweetheart deal that somebody has from Apple. Right.

1044
01:04:44,985 --> 01:04:48,765
Speaker 5:  And there, there are, the rules exist except for all of the exceptions to

1045
01:04:48,765 --> 01:04:52,725
Speaker 5:  the rules. And I think if, if you're Apple, one thing to do would

1046
01:04:52,725 --> 01:04:56,085
Speaker 5:  be to say, okay, we're gonna need to be able to stand up to regulators and

1047
01:04:56,085 --> 01:04:58,805
Speaker 5:  say, look, these are the rules. They exist for everybody. Everybody follows

1048
01:04:58,805 --> 01:05:02,565
Speaker 5:  them equally. I don't think that's a good strategy. I don't think it's gonna

1049
01:05:02,565 --> 01:05:05,805
Speaker 5:  work, but I think if you're Apple, it is at least one way to be able to say

1050
01:05:05,805 --> 01:05:08,085
Speaker 5:  with a straight face, look, these are the rules, we're clear about them.

1051
01:05:08,505 --> 01:05:11,525
Speaker 5:  You, you, you don't have to play by them anymore because You can go to alt

1052
01:05:11,525 --> 01:05:15,325
Speaker 5:  store or whatever. But these are the rules. I think

1053
01:05:16,235 --> 01:05:19,885
Speaker 5:  doing this, this way, and particularly in these very like

1054
01:05:20,035 --> 01:05:23,765
Speaker 5:  haphazard ways that Apple seems to be doing this is deeply

1055
01:05:23,835 --> 01:05:27,685
Speaker 5:  bizarre. Yes. But I think if, if you're Apple, I cannot think of

1056
01:05:27,685 --> 01:05:31,605
Speaker 5:  another reason to pick this particular fight with Patreon right now.

1057
01:05:32,175 --> 01:05:33,005
Speaker 5:  Other than that.

1058
01:05:33,515 --> 01:05:36,445
Speaker 3:  Well, so just to be clear on some of the timing they told Patreon this was

1059
01:05:36,445 --> 01:05:39,285
Speaker 3:  gonna happen a while ago. Yeah. And now it's just happening, but there's

1060
01:05:39,285 --> 01:05:42,245
Speaker 3:  no reason that it should be happening. So that's like, it's not that they

1061
01:05:42,245 --> 01:05:44,965
Speaker 3:  woke up yesterday and were like, Patreon's gonna pay us. They said, here's

1062
01:05:44,965 --> 01:05:47,445
Speaker 3:  a big notice period and now it's happening. And now Patreon is communicating

1063
01:05:47,445 --> 01:05:50,925
Speaker 3:  about it. Right. So a more delayed timeline, but still,

1064
01:05:52,035 --> 01:05:54,885
Speaker 3:  even if you wanna make the argument, we have perfect enforcement of these

1065
01:05:54,885 --> 01:05:58,765
Speaker 3:  rules and there are no exceptions. You're still walking into, and we've pissed

1066
01:05:59,005 --> 01:06:02,925
Speaker 3:  everyone off along the way. I'll give you another example. Apple is going

1067
01:06:02,925 --> 01:06:06,125
Speaker 3:  to allow Spotify to show pricing in its app in the eu.

1068
01:06:08,895 --> 01:06:12,825
Speaker 3:  Just the, the thing that is happening is that

1069
01:06:12,825 --> 01:06:16,665
Speaker 3:  Spotify is gonna put numbers in its app. You still can't buy Spotify

1070
01:06:16,805 --> 01:06:17,225
Speaker 3:  in the app

1071
01:06:17,915 --> 01:06:21,505
Speaker 5:  There. There's a, there's, I I really encourage everyone, if you're not driving

1072
01:06:21,645 --> 01:06:25,545
Speaker 5:  to, we'll put this link in the show notes, but open it up and look

1073
01:06:25,545 --> 01:06:29,465
Speaker 5:  at the side-by-side screenshots because it is this like big dramatic regulatory

1074
01:06:29,565 --> 01:06:33,345
Speaker 5:  moment in this long-term fight between Apple and

1075
01:06:33,345 --> 01:06:36,745
Speaker 5:  Spotify. It's a big deal. And then you look at the side by side screenshots.

1076
01:06:36,745 --> 01:06:40,585
Speaker 5:  Yeah. And they are identical except that one of them says 1799 per month,

1077
01:06:41,105 --> 01:06:43,505
Speaker 5:  1499 per month and the other doesn't. That's it.

1078
01:06:44,365 --> 01:06:47,545
Speaker 3:  And this took like, you know, one of the more powerful government entities

1079
01:06:47,605 --> 01:06:51,465
Speaker 3:  in world history to like force the one of the richest companies in world

1080
01:06:51,465 --> 01:06:55,105
Speaker 3:  history to let another company show numbers. And you're like,

1081
01:06:55,255 --> 01:06:58,505
Speaker 3:  what is the point of this fight? Who gives one

1082
01:06:58,905 --> 01:07:02,705
Speaker 3:  solitary shit about this? Like, you can't possibly care

1083
01:07:03,085 --> 01:07:07,065
Speaker 3:  it, this cannot matter to your bottom line so much. Or,

1084
01:07:07,085 --> 01:07:10,385
Speaker 3:  and it can't be such a good argument that your rules are so evenly enforced

1085
01:07:10,695 --> 01:07:13,785
Speaker 3:  that you're willing to die in this hill over displaying literally

1086
01:07:14,385 --> 01:07:18,025
Speaker 3:  1799 in the Spotify app. But the, not even letting people buy stuff,

1087
01:07:18,495 --> 01:07:21,265
Speaker 3:  just showing the price that You can get on the web versus in the app.

1088
01:07:21,645 --> 01:07:24,905
Speaker 5:  The only part of that I would take issue with is the It do, it can't possibly

1089
01:07:24,905 --> 01:07:27,545
Speaker 5:  matter so much to your bottom line. I mean, like Apple just reported earnings.

1090
01:07:27,975 --> 01:07:31,625
Speaker 5:  It's super, super does matter to Apple's bottom line. And especially if you're

1091
01:07:31,625 --> 01:07:35,065
Speaker 5:  Apple looking at a world in which Google is no longer legally allowed to

1092
01:07:35,065 --> 01:07:38,825
Speaker 5:  give you $20 billion every year. Like this stuff matters an awful lot

1093
01:07:39,285 --> 01:07:43,225
Speaker 5:  to Apple. And, and suddenly the, the, the rent that you get to

1094
01:07:43,335 --> 01:07:47,305
Speaker 5:  extract from everyone in the app store goes from a

1095
01:07:47,455 --> 01:07:51,425
Speaker 5:  like small but meaningful part of your business to like a giant

1096
01:07:51,565 --> 01:07:53,385
Speaker 5:  and meaningful part of your business. Yeah.

1097
01:07:53,605 --> 01:07:57,265
Speaker 4:  Do you think that's part of it too is just they, their, their

1098
01:07:57,505 --> 01:08:00,585
Speaker 4:  services, they, because they've been bundling that 20 billion into the services

1099
01:08:00,585 --> 01:08:01,745
Speaker 4:  reporting, right? Yeah.

1100
01:08:01,745 --> 01:08:05,465
Speaker 5:  It's, it's the lion's share of both the services revenue and Apple's profits

1101
01:08:05,645 --> 01:08:08,065
Speaker 4:  In a very real way. And, and they've been really big on Yeah, this is, this

1102
01:08:08,065 --> 01:08:11,465
Speaker 4:  is our services is doing great and now it's gonna be like, no, it actually,

1103
01:08:11,465 --> 01:08:12,545
Speaker 4:  it doesn't. Well

1104
01:08:12,645 --> 01:08:16,565
Speaker 3:  The Google remedy is years away. Okay. So I reacting

1105
01:08:16,565 --> 01:08:19,565
Speaker 3:  to the Google case, like clamping down on Patreon.

1106
01:08:19,915 --> 01:08:20,445
Speaker 4:  That would be

1107
01:08:20,805 --> 01:08:24,365
Speaker 3:  Hysterical. A little shortsighted. Yes. Again, I, I think, I don't think

1108
01:08:24,365 --> 01:08:28,245
Speaker 3:  it's gas for the jet, like, it, it is not a huge amount of money, but I

1109
01:08:28,245 --> 01:08:32,125
Speaker 3:  think their general attitude towards all of these regulators and all these

1110
01:08:32,125 --> 01:08:35,485
Speaker 3:  courts saying, yep, these platforms need to open up, has

1111
01:08:35,555 --> 01:08:39,245
Speaker 3:  basically been to put a middle finger in the air instead of figuring

1112
01:08:39,345 --> 01:08:43,125
Speaker 3:  out how to innovate. Right. And like icky, I

1113
01:08:43,125 --> 01:08:46,605
Speaker 3:  like, I just, I'm just saying they could make their lives easier, not harder.

1114
01:08:46,625 --> 01:08:50,045
Speaker 3:  And they are consistently choosing harder. Yes. and it, it is

1115
01:08:50,235 --> 01:08:53,245
Speaker 3:  bizarre to me. There's a little more regulatory stuff to talk about. 'cause

1116
01:08:53,245 --> 01:08:56,925
Speaker 3:  this comes right next to the judge in the

1117
01:08:56,995 --> 01:09:00,885
Speaker 3:  epic Google antitrust case saying he will tear the

1118
01:09:01,165 --> 01:09:05,085
Speaker 3:  barriers down on the play tour because he ruled that

1119
01:09:05,085 --> 01:09:07,925
Speaker 3:  the Play store was a monopoly. And he is like, we're opening up the play

1120
01:09:07,945 --> 01:09:11,645
Speaker 3:  to the United States. The, obviously the court in

1121
01:09:11,785 --> 01:09:15,485
Speaker 3:  the Google search case found that there was a monopoly and then

1122
01:09:15,485 --> 01:09:18,925
Speaker 3:  Google's ad tech case kicks off in early September

1123
01:09:19,625 --> 01:09:23,445
Speaker 3:  and that probably is not gonna go poor. Like of all of the cases where we're

1124
01:09:23,445 --> 01:09:27,165
Speaker 3:  gonna see a bunch of emails of Google executives saying shady things about

1125
01:09:27,165 --> 01:09:30,925
Speaker 3:  money, the ad tech case is the one. Oh yeah.

1126
01:09:31,135 --> 01:09:34,805
Speaker 3:  Right. It's gonna be great. That's the one. Its so boring and so

1127
01:09:34,805 --> 01:09:38,645
Speaker 3:  consequential. Right? So you just see like Google is under all of this pressure

1128
01:09:38,665 --> 01:09:41,805
Speaker 3:  and the, the judges in these cases and the regulators in the ER are like,

1129
01:09:41,975 --> 01:09:44,965
Speaker 3:  we're gonna tear this company apart. And Apple's sitting there with the big

1130
01:09:45,075 --> 01:09:47,965
Speaker 3:  open antitrust case to come

1131
01:09:49,635 --> 01:09:53,095
Speaker 3:  and obviously empower Justice Department because they just won their big

1132
01:09:53,095 --> 01:09:56,295
Speaker 3:  Google trial and they got the next one coming and then a bunch of e regulators

1133
01:09:56,295 --> 01:10:00,095
Speaker 3:  started doing. And it's like, why are you signaling to all of these people

1134
01:10:00,165 --> 01:10:03,135
Speaker 3:  that your response to this putting your finger in the air, like it's not

1135
01:10:03,135 --> 01:10:06,805
Speaker 3:  gonna work. 'cause they're winning right now against Google in a real way.

1136
01:10:06,825 --> 01:10:09,965
Speaker 3:  And maybe Google is more cuddly than Apple. Maybe people like Apple better

1137
01:10:09,965 --> 01:10:13,565
Speaker 3:  than Google. However, those optics feel they're

1138
01:10:13,865 --> 01:10:17,325
Speaker 3:  on the hunt and they're winning. And so like if you,

1139
01:10:17,765 --> 01:10:19,805
Speaker 3:  I don't know, there's just something weird about this. I was like,

1140
01:10:19,805 --> 01:10:23,765
Speaker 4:  It's bad optics to go take a cut of 30% from a whole bunch

1141
01:10:23,765 --> 01:10:27,565
Speaker 4:  of creators who don't make a lot of, most of them aren't making a ton of

1142
01:10:27,565 --> 01:10:31,085
Speaker 4:  money. Right? Like that's bad optics. That's just such an

1143
01:10:31,085 --> 01:10:34,805
Speaker 4:  unforced error. It feels like them just stepping in rakes constantly.

1144
01:10:35,555 --> 01:10:37,045
Speaker 4:  They're just sideshow Bob. Yeah.

1145
01:10:37,065 --> 01:10:39,805
Speaker 3:  If you know what the strategy here is, please let us know. 'cause I'm dying

1146
01:10:39,805 --> 01:10:43,485
Speaker 3:  to know, or if you even wanna concoct a strategy, we are not being successful

1147
01:10:43,485 --> 01:10:47,245
Speaker 3:  at it. But there's a thing happening like broadly in in the world of tech

1148
01:10:47,245 --> 01:10:51,085
Speaker 3:  right now where the regulators are winning. Yeah.

1149
01:10:51,085 --> 01:10:54,965
Speaker 3:  And the platforms are being pri open and distribution is getting a little

1150
01:10:55,155 --> 01:10:58,885
Speaker 3:  crazier and it's like kind of interesting for us, right? Like it means more

1151
01:10:59,465 --> 01:11:03,365
Speaker 3:  for interesting things are happening. Like alt store is just a

1152
01:11:03,365 --> 01:11:06,445
Speaker 3:  thing that's happening in eu. Emulators are happening all over the iPhone

1153
01:11:06,445 --> 01:11:08,485
Speaker 3:  right now because of EU regulation.

1154
01:16:32,645 --> 01:16:36,545
Speaker 3:  All right, we're back. I'm in what I think of as the homeboy chairs.

1155
01:16:37,615 --> 01:16:40,825
Speaker 3:  It's beautiful. Look, when you got the NBA players in here doing the podcast,

1156
01:16:40,975 --> 01:16:42,825
Speaker 3:  this is where the homeboys sit. Yeah.

1157
01:16:44,645 --> 01:16:48,545
Speaker 3:  You look like you should be like, you

1158
01:16:48,545 --> 01:16:52,145
Speaker 3:  look like a, a professor during the pandemic who like went a little hard

1159
01:16:52,285 --> 01:16:54,265
Speaker 3:  on redecorating the home office.

1160
01:16:56,045 --> 01:16:59,185
Speaker 3:  That's right. That's also this look, you know, sidekick

1161
01:16:59,735 --> 01:17:03,185
Speaker 3:  homeboy's professor with an ax to grind the,

1162
01:17:03,245 --> 01:17:06,785
Speaker 4:  The slats are like, it's very trippy. It's a good,

1163
01:17:06,975 --> 01:17:10,085
Speaker 3:  It's a good look. So we, we bought very similar slats for the studio at my

1164
01:17:10,085 --> 01:17:10,925
Speaker 3:  house. And

1165
01:17:12,445 --> 01:17:15,545
Speaker 3:  you know, I dunno whose fault this is or if this is racist, but we forgot

1166
01:17:15,545 --> 01:17:19,305
Speaker 3:  to consider that this, they're the same color as me. So

1167
01:17:19,645 --> 01:17:20,865
Speaker 3:  we had to stain in the slots.

1168
01:17:21,345 --> 01:17:23,585
Speaker 4:  Just turn to the side and you'll disappear in the frame.

1169
01:17:24,975 --> 01:17:28,745
Speaker 3:  It's very good. Anyway, this is, well I'm, I'm in a loose hangout.

1170
01:17:28,805 --> 01:17:31,185
Speaker 3:  You might call this the hype desk. It's a

1171
01:17:31,785 --> 01:17:33,385
Speaker 5:  One one could yeah, one could call it

1172
01:17:33,385 --> 01:17:36,505
Speaker 3:  That one, one could say we are now in the market for someone to sit in the

1173
01:17:36,505 --> 01:17:39,785
Speaker 3:  hype hype desk doing The Verge chest once again. 'cause we have a hype zone

1174
01:17:41,175 --> 01:17:42,225
Speaker 3:  over here in the studio.

1175
01:17:42,325 --> 01:17:44,985
Speaker 5:  The, the as yet unsponsored unlaunched hype desk

1176
01:17:46,465 --> 01:17:49,795
Speaker 3:  Look saying once we get this lightning round sponsored, we're moving on.

1177
01:17:51,615 --> 01:17:54,275
Speaker 3:  But now that I'm in the hype desk, I think David, that makes you, you gotta

1178
01:17:54,275 --> 01:17:56,955
Speaker 3:  run the lightning round. And I'm just going to say whether or not things

1179
01:17:56,955 --> 01:17:57,275
Speaker 3:  are hype.

1180
01:17:57,465 --> 01:18:00,515
Speaker 5:  Okay, good. Well now that, now that I'm in charge, I've picked six things

1181
01:18:00,575 --> 01:18:01,235
Speaker 5:  for the lightning round.

1182
01:18:03,385 --> 01:18:05,435
Speaker 3:  Classic. Classic Lightning round.

1183
01:18:05,575 --> 01:18:08,755
Speaker 5:  No, at Kranz. Let's, let's, let's start with you. You have a fun gadgety

1184
01:18:08,755 --> 01:18:09,515
Speaker 5:  one. So you go first. Oh

1185
01:18:09,515 --> 01:18:13,275
Speaker 4:  Yeah, I got a fun gadgety one. So, so Realme is a, a Chinese

1186
01:18:13,645 --> 01:18:17,435
Speaker 4:  phone maker and they make phones. I, I don't wanna, I don't wanna

1187
01:18:17,435 --> 01:18:20,195
Speaker 4:  make a big assessment on the quality of those phones. They, they make

1188
01:18:20,195 --> 01:18:21,555
Speaker 5:  Phones. We can say that they

1189
01:18:21,555 --> 01:18:25,235
Speaker 4:  Are phones and they're really into like making the charging better and faster.

1190
01:18:25,335 --> 01:18:28,395
Speaker 4:  And they introduced 320 watt

1191
01:18:29,065 --> 01:18:29,715
Speaker 4:  fast charging.

1192
01:18:31,255 --> 01:18:31,545
Speaker 4:  Just

1193
01:18:32,125 --> 01:18:32,745
Speaker 3:  That's great.

1194
01:18:33,775 --> 01:18:37,105
Speaker 4:  It's, it's, they're doing, they said they could do a battery in four minutes

1195
01:18:37,125 --> 01:18:39,145
Speaker 4:  and 30 seconds, like a Pixel nine battery.

1196
01:18:39,495 --> 01:18:42,945
Speaker 5:  Wait, isn't the plug I have in the wall like seven and a half watts

1197
01:18:43,285 --> 01:18:46,265
Speaker 5:  and I'm pretty sure like 30 is like very fast.

1198
01:18:46,695 --> 01:18:50,545
Speaker 4:  Yeah. So this is, this is insane. Unclear if it will burst into flames

1199
01:18:50,545 --> 01:18:54,025
Speaker 4:  as soon as you plug it in. Unclear if it'll set your phone on flame. Do

1200
01:18:54,025 --> 01:18:57,585
Speaker 3:  You need like a, like a Thunderbolt four style cable? Like a big thick

1201
01:18:58,215 --> 01:18:58,705
Speaker 3:  braided?

1202
01:18:58,945 --> 01:19:00,705
Speaker 4:  I wouldn't feel comfortable using Oh,

1203
01:19:00,705 --> 01:19:04,425
Speaker 3:  You're not sending this through like a, like a flimsy like lightning cable.

1204
01:19:04,575 --> 01:19:07,745
Speaker 4:  Yeah. Yeah. This is not what you wanna use. Like that random cable you found

1205
01:19:07,745 --> 01:19:10,585
Speaker 4:  at the bottom of your desk. Don't, don't use that for

1206
01:19:10,585 --> 01:19:12,625
Speaker 3:  This. You're plug like a CCS charger into your phone.

1207
01:19:12,865 --> 01:19:16,625
Speaker 4:  Yeah, yeah. So it's USBC right now.

1208
01:19:16,805 --> 01:19:17,625
Speaker 4:  Course What

1209
01:19:17,625 --> 01:19:19,945
Speaker 3:  Can't USBC do except tell you what it's doing,

1210
01:19:20,485 --> 01:19:24,425
Speaker 4:  But they, they haven't really, like, there's no phones that's really

1211
01:19:24,425 --> 01:19:28,395
Speaker 4:  fully supported out in the wild. It's just technology.

1212
01:19:28,425 --> 01:19:31,155
Speaker 4:  They just said we did it. This was kind of their, they were doing their road

1213
01:19:31,155 --> 01:19:33,835
Speaker 4:  show and showing off their, their new technology and it was like, yeah, we're

1214
01:19:33,835 --> 01:19:36,515
Speaker 4:  gonna do this soon. So at some point we're gonna have

1215
01:19:37,595 --> 01:19:41,455
Speaker 4:  phones charging in four minutes and that'll rule unless they

1216
01:19:41,455 --> 01:19:42,135
Speaker 4:  catch on fire.

1217
01:19:42,595 --> 01:19:44,815
Speaker 3:  Can I just say my, we'll have to find out. My favorite part of the story

1218
01:19:44,815 --> 01:19:47,975
Speaker 3:  is, I mean the story is great. We should try our funds faster. The press

1219
01:19:47,975 --> 01:19:51,615
Speaker 3:  image they supplied is incredible. It's just like a happy guy

1220
01:19:52,225 --> 01:19:56,175
Speaker 3:  happy in front of a screen that says 321 supersonic charge and he just

1221
01:19:56,175 --> 01:19:57,135
Speaker 3:  please this punch.

1222
01:19:57,805 --> 01:20:01,735
Speaker 4:  Like, what, what else do you need? That's all you need. Like, that's

1223
01:20:01,735 --> 01:20:05,495
Speaker 4:  how I feel when I read 320 watts. Yeah. I'm like, okay. Yeah. Same feeling

1224
01:20:05,605 --> 01:20:09,445
Speaker 3:  Like I wish I was giving this presentation right now. Like I, I truly w

1225
01:20:09,585 --> 01:20:12,925
Speaker 3:  can we get the words 320 watt supersonic charge on this tv, please.

1226
01:20:13,555 --> 01:20:14,045
Speaker 5:  They gimme

1227
01:20:14,255 --> 01:20:14,605
Speaker 3:  Smile

1228
01:20:14,605 --> 01:20:18,405
Speaker 5:  At it. They call the charger the pocket cannon. Yeah. Which is unbelievable.

1229
01:20:18,595 --> 01:20:18,885
Speaker 4:  Yeah,

1230
01:20:18,995 --> 01:20:19,845
Speaker 3:  Just that's great.

1231
01:20:19,845 --> 01:20:20,285
Speaker 5:  That's great.

1232
01:20:20,575 --> 01:20:21,245
Speaker 3:  Tremendous

1233
01:20:21,245 --> 01:20:24,765
Speaker 4:  And everything about it's wonderful and, but we'll have to see if it

1234
01:20:25,245 --> 01:20:27,965
Speaker 4:  actually does it not just in a demo on

1235
01:20:28,955 --> 01:20:30,405
Speaker 4:  that they're showing up the tech. I

1236
01:20:30,405 --> 01:20:34,285
Speaker 5:  Say I, I have for years thought that the thing that all

1237
01:20:34,285 --> 01:20:37,965
Speaker 5:  these companies say that it's like, you know, the battery is

1238
01:20:37,975 --> 01:20:41,965
Speaker 5:  trash but it charges pretty fast. You can get from zero to 50% in 35

1239
01:20:41,965 --> 01:20:45,685
Speaker 5:  minutes. I've always kind of thought that was nothing like who cares? But

1240
01:20:45,685 --> 01:20:48,605
Speaker 5:  the idea of fully charging my phone in four and a half minutes, it's like,

1241
01:20:48,605 --> 01:20:51,605
Speaker 5:  okay, I can plug in my phone, I can brush my teeth and my phone is going

1242
01:20:51,605 --> 01:20:53,885
Speaker 5:  to be at like, 70% is awesome.

1243
01:20:54,465 --> 01:20:57,765
Speaker 3:  You can also heat a small village. Yeah. You can fry one egg.

1244
01:20:59,955 --> 01:21:01,925
Speaker 3:  It's gonna be great. You, can I do like

1245
01:21:01,925 --> 01:21:05,605
Speaker 5:  The idea of, of both turning my oven on and charging my phone at the same

1246
01:21:05,605 --> 01:21:05,765
Speaker 5:  time?

1247
01:21:06,465 --> 01:21:08,885
Speaker 4:  No, I think you'll blow a circuit breaker if you do that.

1248
01:21:09,465 --> 01:21:13,045
Speaker 5:  No, it's like a, it's like a hot plate and a phone charger all in one little,

1249
01:21:13,065 --> 01:21:14,885
Speaker 5:  little gizmo on my table. Just

1250
01:21:15,275 --> 01:21:18,725
Speaker 3:  This is great. The, the street, the street lights from miles around dim when

1251
01:21:18,725 --> 01:21:19,685
Speaker 3:  David plugs in his phone.

1252
01:21:21,785 --> 01:21:24,845
Speaker 3:  I'm excited. I'm just looking at this photo, this guy smiling at the words

1253
01:21:24,845 --> 01:21:28,605
Speaker 3:  320 watt supersonic charge and I think more of the tech industry should be

1254
01:21:28,605 --> 01:21:29,765
Speaker 3:  like this. Yeah. Yeah. That's what I

1255
01:21:29,765 --> 01:21:31,285
Speaker 5:  Have for you. I will take a pocket Canon.

1256
01:21:33,165 --> 01:21:34,045
Speaker 5:  I feel like I probably, Tim and

1257
01:21:34,045 --> 01:21:34,645
Speaker 4:  I live just to guy

1258
01:21:34,645 --> 01:21:37,005
Speaker 5:  Smiling to live on a podcast, but yeah, here we are. Alright. Right. I have

1259
01:21:37,005 --> 01:21:40,965
Speaker 5:  two, the first one, I actually should have brought this up, up at the top

1260
01:21:40,965 --> 01:21:44,685
Speaker 5:  where we were talking about all the AI image processing stuff, but

1261
01:21:45,265 --> 01:21:49,085
Speaker 5:  Allied a very good camera app for iPhones and iPads

1262
01:21:49,765 --> 01:21:53,485
Speaker 5:  launched a thing this week called Process Zero that is basically just

1263
01:21:53,725 --> 01:21:57,045
Speaker 5:  a setting inside of their app that instead of running every photo you take

1264
01:21:57,045 --> 01:22:01,005
Speaker 5:  through either apple's, I think they offer Apple's standard

1265
01:22:01,015 --> 01:22:04,605
Speaker 5:  image processing, the pro raw processing and then a thing they call

1266
01:22:04,605 --> 01:22:07,925
Speaker 5:  reduced, which is just kind of a light version of Apple's processing, runs

1267
01:22:07,925 --> 01:22:11,285
Speaker 5:  it through no processing. So you get, you get what is supposed to be as close

1268
01:22:11,285 --> 01:22:15,085
Speaker 5:  to like a film camera experience as possible. You just get the light, it

1269
01:22:15,085 --> 01:22:18,885
Speaker 5:  collects the end. A super cool feature.

1270
01:22:18,885 --> 01:22:22,405
Speaker 5:  It got a lot of people very excited. This idea that like we, we can actually

1271
01:22:22,405 --> 01:22:25,445
Speaker 5:  choose to go another way. It's gonna make some of your photos meaningfully

1272
01:22:25,445 --> 01:22:29,365
Speaker 5:  worse. It's gonna change them in certain ways. But I think that idea

1273
01:22:29,365 --> 01:22:32,805
Speaker 5:  of like, not only do I get to pick like where I am in the photo, which is

1274
01:22:32,805 --> 01:22:36,605
Speaker 5:  weird, but like I have actual real control over what is

1275
01:22:36,605 --> 01:22:39,405
Speaker 5:  happening to my photo every time I capture it is very cool.

1276
01:22:40,835 --> 01:22:44,765
Speaker 5:  Also, just the idea that a camera on your

1277
01:22:44,775 --> 01:22:48,645
Speaker 5:  phone can have that kind of access is very

1278
01:22:48,645 --> 01:22:51,445
Speaker 5:  cool. And not a thing I really understood until I started writing about this

1279
01:22:51,445 --> 01:22:55,005
Speaker 5:  thing that like, it's, it again, it's just collecting sensor data.

1280
01:22:55,305 --> 01:22:59,245
Speaker 5:  And. if you give apps like allied access to that sensor data, there's all

1281
01:22:59,245 --> 01:23:01,685
Speaker 5:  kinds of interesting stuff they're gonna be able to do with it. And I just

1282
01:23:01,685 --> 01:23:05,565
Speaker 5:  think that's very cool and a sort of rich vein that at least to my

1283
01:23:05,565 --> 01:23:08,765
Speaker 5:  knowledge, nobody has really explored. And I think that's really cool.

1284
01:23:08,985 --> 01:23:12,805
Speaker 4:  If you don't know a lot about photography, don't use that feature. All your,

1285
01:23:13,035 --> 01:23:14,365
Speaker 4:  your photos are gonna look like trash

1286
01:23:14,765 --> 01:23:18,525
Speaker 3:  Disagree. I just do it. This you learn a lot about photography that

1287
01:23:18,655 --> 01:23:19,045
Speaker 4:  Don't use

1288
01:23:19,105 --> 01:23:19,405
Speaker 3:  The feature

1289
01:23:19,885 --> 01:23:23,605
Speaker 4:  I, I'm assuming of like the the 70-year-old who listens to The Verge

1290
01:23:23,635 --> 01:23:27,285
Speaker 4:  cast. and it is like, you know what, I wanna, this sounds cool. I wanna,

1291
01:23:27,405 --> 01:23:28,205
Speaker 4:  I wanna put this on my phone.

1292
01:23:28,205 --> 01:23:30,765
Speaker 3:  No, that person, what are you doing with your time? It's my mom. Get up there,

1293
01:23:31,155 --> 01:23:35,085
Speaker 3:  take Oh, I see. Got it. Understood.

1294
01:23:36,105 --> 01:23:40,005
Speaker 3:  So just Alex's mom, don't do it. Everyone else I've hung

1295
01:23:40,005 --> 01:23:43,125
Speaker 3:  out with your mom before Alex I'll, I'll teach her about, about, about digital

1296
01:23:43,125 --> 01:23:43,685
Speaker 3:  photography.

1297
01:23:43,885 --> 01:23:47,125
Speaker 4:  You say that now that'll be a great four hour VERGE cast

1298
01:23:47,385 --> 01:23:50,725
Speaker 3:  It. I think people would listen to talk about a Patreon, just me and your

1299
01:23:50,725 --> 01:23:51,445
Speaker 3:  mom. There you go.

1300
01:23:53,825 --> 01:23:57,685
Speaker 3:  But what's really interesting here is pocket point and shoot digital

1301
01:23:57,685 --> 01:24:00,965
Speaker 3:  cameras are making a tiny blip of a comeback. Yeah.

1302
01:24:01,005 --> 01:24:04,525
Speaker 3:  Particularly with younger folks because they see how bad

1303
01:24:05,105 --> 01:24:08,325
Speaker 3:  the processing on their phones has gotten and they don't want to be always

1304
01:24:08,325 --> 01:24:12,205
Speaker 3:  connected. Like my nieces and nephews are all carrying around Power

1305
01:24:12,235 --> 01:24:15,785
Speaker 3:  shot elfs and I'm like, I made a lot of mistakes with those cameras. Don't

1306
01:24:15,785 --> 01:24:19,505
Speaker 3:  do what I did. But it's fasting to see that little comeback.

1307
01:24:19,765 --> 01:24:23,225
Speaker 3:  Is it meaningful? Is it the threat to smartphone? No, none of that.

1308
01:24:23,845 --> 01:24:27,705
Speaker 3:  But it is a pushback on how process the photos are getting. Right. Yeah.

1309
01:24:27,845 --> 01:24:31,545
Speaker 3:  And I think, you know, an app, putting some of those photos

1310
01:24:31,615 --> 01:24:35,265
Speaker 3:  into the phone might push the default cameras back

1311
01:24:35,265 --> 01:24:38,705
Speaker 3:  towards sanity. And I'm kind of hoping Apple takes the hint,

1312
01:24:39,265 --> 01:24:43,205
Speaker 3:  right? That there's, you've they've overdone it. Samsung has overdone

1313
01:24:43,205 --> 01:24:46,965
Speaker 3:  it for years. Google has been inching towards overdoing it. I think

1314
01:24:46,965 --> 01:24:50,645
Speaker 3:  it's, apple has taken kind of the most aggressive step from

1315
01:24:50,885 --> 01:24:54,445
Speaker 3:  I, you know, the 12 or the 13 to now where it's just like, oh, this,

1316
01:24:54,615 --> 01:24:56,805
Speaker 3:  these photos just look bananas. Yeah.

1317
01:24:57,245 --> 01:25:00,965
Speaker 5:  I like the photos less on my iPhone 15 than I have

1318
01:25:01,185 --> 01:25:03,965
Speaker 5:  in a long time. Yeah. From the iPhone. Like they, I think in a certain way

1319
01:25:03,965 --> 01:25:07,885
Speaker 5:  they're like technically better photos. I I like them less.

1320
01:25:07,885 --> 01:25:11,645
Speaker 5:  Like my photos don't look like, I feel like they should anymore

1321
01:25:11,985 --> 01:25:15,925
Speaker 5:  on the, on most smartphones. But the iPhone I think held out a long time,

1322
01:25:15,945 --> 01:25:17,485
Speaker 5:  but that has kind of gone away. What

1323
01:25:17,485 --> 01:25:21,045
Speaker 4:  Is it that that, that I guess because I I maybe don't see it as much. What

1324
01:25:21,045 --> 01:25:23,925
Speaker 4:  is it that that, that you guys are seeing when you do that? Is it like, is

1325
01:25:23,925 --> 01:25:27,485
Speaker 4:  it the color, is it the, the, the dynamic range? All of it.

1326
01:25:27,875 --> 01:25:31,045
Speaker 3:  It's all of it. The the things for me, and I'm curious David, since you have

1327
01:25:31,045 --> 01:25:34,925
Speaker 3:  the same opinion, if you're seeing something different for me it's the,

1328
01:25:35,185 --> 01:25:38,925
Speaker 3:  the iPhone is now just completely allergic to shadows. Just takes

1329
01:25:39,195 --> 01:25:43,125
Speaker 3:  away, it loves the sky. Like nothing

1330
01:25:43,335 --> 01:25:47,165
Speaker 3:  loves the sky. Like the iPhone camera loves the sky. So just like more

1331
01:25:47,225 --> 01:25:47,445
Speaker 3:  sky

1332
01:25:47,905 --> 01:25:51,165
Speaker 5:  But not the sky as it is. Like what if the sky was the best it has ever been

1333
01:25:51,225 --> 01:25:54,325
Speaker 5:  in history all the time. Every time you take a photo,

1334
01:25:54,505 --> 01:25:57,485
Speaker 3:  Oh my god, sky. Oh, turn up that sky knob. Yeah.

1335
01:25:57,845 --> 01:26:00,645
Speaker 5:  You're like, oh no, it's gray out today. And the iPhone's like the fuck it

1336
01:26:00,645 --> 01:26:01,245
Speaker 5:  is, let's go.

1337
01:26:02,385 --> 01:26:06,365
Speaker 3:  And then those things combined, if you're outside in

1338
01:26:06,365 --> 01:26:10,045
Speaker 3:  a bright scene, it can actually make your photos gray. Yeah, right.

1339
01:26:10,265 --> 01:26:14,165
Speaker 3:  So I was thinking about dynamics like in, if you're a music

1340
01:26:14,165 --> 01:26:16,485
Speaker 3:  person, you know, dynamics are quite and loud. Like there's dynamics and

1341
01:26:16,485 --> 01:26:19,805
Speaker 3:  photographs too. And so everything is bright. The

1342
01:26:19,915 --> 01:26:23,445
Speaker 3:  perceived brightness of the whole image drops. Yeah. And so the iPhone, by

1343
01:26:23,445 --> 01:26:26,605
Speaker 3:  getting rid of shadows and pumping up the sky and then over like bringing

1344
01:26:26,655 --> 01:26:30,405
Speaker 3:  everything up actually makes the photo look di Yeah. And I've seen

1345
01:26:30,635 --> 01:26:33,925
Speaker 3:  influencers like complain about their iPhone cameras

1346
01:26:34,505 --> 01:26:37,645
Speaker 3:  and they're like, why is this camera so gray? Like I think Alex Earl has

1347
01:26:37,645 --> 01:26:41,245
Speaker 3:  made a video about why her camera appears to be gray. Right? And like that's

1348
01:26:41,385 --> 01:26:45,045
Speaker 3:  bad. Like you don't wanna be there right. When you are the,

1349
01:26:45,185 --> 01:26:49,085
Speaker 3:  the, the hardware of the entire creator economy, having the

1350
01:26:49,165 --> 01:26:52,205
Speaker 3:  creators being like, why is my phone gray? And it's not because they're less

1351
01:26:52,205 --> 01:26:55,845
Speaker 3:  bright. It's because if you destroy all the shadows and you make everything

1352
01:26:55,845 --> 01:26:59,725
Speaker 3:  bright, actually everything looks di and that's just kind of a weird

1353
01:26:59,755 --> 01:27:02,005
Speaker 3:  spot Apple has gone into. I dunno, David, is that what you're seeing too?

1354
01:27:02,005 --> 01:27:02,565
Speaker 3:  Or is it something else?

1355
01:27:02,665 --> 01:27:05,245
Speaker 5:  No, that's, that's basically right. And the, the other thing I keep noticing,

1356
01:27:05,345 --> 01:27:08,525
Speaker 5:  and in the the highlight story I wrote, there's a really interesting

1357
01:27:09,375 --> 01:27:13,165
Speaker 5:  comparison shot where what Apple does by

1358
01:27:13,475 --> 01:27:17,205
Speaker 5:  getting rid of shadows wherever it can and hyping up the

1359
01:27:17,365 --> 01:27:20,725
Speaker 5:  brightness everywhere You can is it just, it just flattens it all too. So

1360
01:27:20,725 --> 01:27:23,925
Speaker 5:  there's a, there's a version of the shot that is like, it's a, it's the front

1361
01:27:23,925 --> 01:27:27,725
Speaker 5:  of a flower shop. And so you see all this sort of, the flowers in the pots

1362
01:27:27,725 --> 01:27:30,685
Speaker 5:  in the front and the photo is like crisper and brighter than the one that

1363
01:27:30,685 --> 01:27:34,165
Speaker 5:  you got with the process. Zero thing that Haled is doing. But it's also

1364
01:27:34,435 --> 01:27:38,165
Speaker 5:  much less like dynamic. The photo itself, there's no,

1365
01:27:38,635 --> 01:27:41,845
Speaker 5:  there's no sense of sort of ups and downs. You get the sense the whole curve

1366
01:27:41,865 --> 01:27:44,485
Speaker 5:  is just like bright. Yeah. and it makes the whole thing look really flat.

1367
01:27:44,485 --> 01:27:46,605
Speaker 5:  Kinda like you're talking about Neil. and it just, it makes all the photos

1368
01:27:46,635 --> 01:27:50,605
Speaker 5:  less interesting in a way. Like they're brighter and cooler and less

1369
01:27:50,925 --> 01:27:52,965
Speaker 5:  interesting to me in, in so many ways. Yeah.

1370
01:27:53,225 --> 01:27:55,605
Speaker 3:  And there's other stuff there's doing, there's like weird sharpening when

1371
01:27:55,605 --> 01:27:59,405
Speaker 3:  you get in the low light iPhones just start freaking out. Oh yeah.

1372
01:28:00,105 --> 01:28:03,685
Speaker 3:  And like, not in a bad way. They're not like making bad, technically bad

1373
01:28:03,685 --> 01:28:06,365
Speaker 3:  photos. I think this is what you're getting at David. They're just trying

1374
01:28:06,385 --> 01:28:10,245
Speaker 3:  so hard to make a great photo that you lose the character of it. And then

1375
01:28:10,245 --> 01:28:12,765
Speaker 3:  there's tons and tons and tons in processing like Right.

1376
01:28:12,905 --> 01:28:15,845
Speaker 5:  And I think what you're seeing a lot of coming back with the, the point and

1377
01:28:15,845 --> 01:28:19,685
Speaker 5:  shoots and the process zero stuff. Like this whole idea is like,

1378
01:28:20,405 --> 01:28:23,565
Speaker 5:  I, people should be allowed to take bad photos. You know what I mean? And

1379
01:28:23,565 --> 01:28:26,405
Speaker 5:  it's like there's something too, if I'm standing in a dark room and I take

1380
01:28:26,405 --> 01:28:29,045
Speaker 5:  a picture, maybe it's actually okay that the picture is dark. Yeah. Like,

1381
01:28:29,045 --> 01:28:32,645
Speaker 5:  maybe, maybe that's okay. And, and sometimes that's what I want. And

1382
01:28:32,805 --> 01:28:36,645
Speaker 5:  increasingly with these devices, you are not allowed to take a dark

1383
01:28:36,645 --> 01:28:38,605
Speaker 5:  photo. And I think that's just weird.

1384
01:28:38,985 --> 01:28:42,765
Speaker 3:  I'm gonna say a sentence that a small number of people

1385
01:28:42,765 --> 01:28:46,575
Speaker 3:  will understand the significance of Charlie XCX

1386
01:28:46,575 --> 01:28:48,015
Speaker 3:  invited the Cobra Snake to her birthday party.

1387
01:28:50,565 --> 01:28:54,415
Speaker 3:  That that's a real thing. And, if you were in your twenties in the early

1388
01:28:54,435 --> 01:28:57,575
Speaker 3:  two thousands, you're like, oh, it's back. It's just fully back.

1389
01:28:58,185 --> 01:29:01,015
Speaker 3:  We're we're just doing it again. Whole. That whole aesthetic is back and

1390
01:29:01,085 --> 01:29:04,485
Speaker 3:  like we're we're just gonna do flash photos with drunk people and like let's

1391
01:29:04,485 --> 01:29:08,085
Speaker 3:  do it. The iPhone can't do that shit. Yeah. No one wants that.

1392
01:29:08,385 --> 01:29:08,605
Speaker 3:  No.

1393
01:29:08,965 --> 01:29:11,405
Speaker 5:  A bunch of squinting people with a flash on. That's, that's what we're looking

1394
01:29:11,405 --> 01:29:11,765
Speaker 5:  for. Oh,

1395
01:29:11,765 --> 01:29:13,885
Speaker 3:  They're not SST sing. Those eyes are dilated my friend.

1396
01:29:15,555 --> 01:29:15,845
Speaker 3:  Fair

1397
01:29:15,845 --> 01:29:18,805
Speaker 5:  Enough. Two. Alright. My other one, and then Neli, we should get to you and

1398
01:29:18,805 --> 01:29:22,765
Speaker 5:  then we should get out of here is Flipboard, which is, we've been

1399
01:29:22,795 --> 01:29:25,725
Speaker 5:  sort of chronicling flip board's, like relentless quest to figure out the

1400
01:29:25,725 --> 01:29:29,645
Speaker 5:  Fedi verse, which I continue to find very interesting. Turned on a thing

1401
01:29:29,645 --> 01:29:33,005
Speaker 5:  that I think is actually very instructive in understanding how all of this

1402
01:29:33,005 --> 01:29:36,845
Speaker 5:  is supposed to work, which is just that now You can follow Fedi verse accounts.

1403
01:29:36,845 --> 01:29:40,205
Speaker 5:  So like people from Mastodon or Pixel Fed or even on threads

1404
01:29:41,235 --> 01:29:44,485
Speaker 5:  from inside of Flipboard. Right. And it's like if you, if you wanna understand

1405
01:29:44,485 --> 01:29:47,725
Speaker 5:  the way the Fedi verse is supposed to work, it's that where you make posts

1406
01:29:47,725 --> 01:29:51,525
Speaker 5:  and where you read posts can be different and that anybody can decide how

1407
01:29:51,525 --> 01:29:53,525
Speaker 5:  those posts are supposed to look and how they're supposed to work and in

1408
01:29:53,525 --> 01:29:57,405
Speaker 5:  order they show up. And so, like the idea that You can do Mastodon

1409
01:29:57,405 --> 01:30:01,205
Speaker 5:  inside of Flipboard is both like mind bending and exactly the point.

1410
01:30:01,425 --> 01:30:04,125
Speaker 5:  And so if you've like, wanted to understand how the Fedi verse works, go

1411
01:30:04,125 --> 01:30:07,285
Speaker 5:  to Flipboard and like mess around with a bunch of Mastodon stuff. They've

1412
01:30:07,285 --> 01:30:10,205
Speaker 5:  put together some lists. I think one that includes you and Eli because you're

1413
01:30:10,235 --> 01:30:11,925
Speaker 5:  just a tremendously huge deal on the fedi verse.

1414
01:30:13,585 --> 01:30:17,485
Speaker 5:  But like that, I think this is the closest thing I have seen to like

1415
01:30:18,315 --> 01:30:22,165
Speaker 5:  telling the whole story of like, here is, here is what you get

1416
01:30:22,235 --> 01:30:25,765
Speaker 5:  when all you have is just this massive content that You can either build

1417
01:30:25,765 --> 01:30:28,765
Speaker 5:  something that adds to or build something that reads from however you want.

1418
01:30:28,945 --> 01:30:30,205
Speaker 5:  So I think that was very cool. Yeah.

1419
01:30:30,305 --> 01:30:33,805
Speaker 3:  That's awesome. Flipboard is way ahead of this curve, right? Yeah. They've

1420
01:30:33,805 --> 01:30:37,205
Speaker 3:  like re-architected their app or the way they're thinking about their app

1421
01:30:37,545 --> 01:30:40,685
Speaker 3:  around activity pub and these open protocols and you kind of have

1422
01:30:41,985 --> 01:30:45,005
Speaker 3:  it, you know, in the broadest sense, like the future of a browser.

1423
01:30:45,635 --> 01:30:46,405
Speaker 5:  Yeah. But

1424
01:30:46,405 --> 01:30:49,205
Speaker 3:  It's bi-directional. Like you take content in and you get to read it and

1425
01:30:49,205 --> 01:30:51,565
Speaker 3:  You can like reply to it and it goes right back to the person who made it.

1426
01:30:52,465 --> 01:30:56,445
Speaker 3:  And it's pretty powerful. It like

1427
01:30:56,445 --> 01:30:59,965
Speaker 3:  nothing works with it yet, right. Like, which is a problem.

1428
01:31:00,345 --> 01:31:04,005
Speaker 3:  But You can just see there's like glimmers here of a new kind of web.

1429
01:31:05,325 --> 01:31:07,845
Speaker 3:  I am the one who keeps babbling on about how we're gonna federate our site.

1430
01:31:07,845 --> 01:31:11,765
Speaker 3:  You can see how our site would play with something like that.

1431
01:31:11,775 --> 01:31:15,405
Speaker 3:  Right. Very quickly. But then you start to build it and we're trying to build

1432
01:31:15,405 --> 01:31:19,365
Speaker 3:  it and it's like, oh, there's a million problems to solve here. Yeah. Like

1433
01:31:19,625 --> 01:31:22,765
Speaker 3:  big hairy technical problems that mo no one has ever really tried to solve

1434
01:31:22,765 --> 01:31:26,685
Speaker 3:  before, which is why, you know, threads is federating and they are

1435
01:31:26,685 --> 01:31:30,645
Speaker 3:  doing it in like drip by drip. Like they're solving one little problem at

1436
01:31:30,645 --> 01:31:34,205
Speaker 3:  a time. They, they let you know that someone in the fedi verse had liked

1437
01:31:34,205 --> 01:31:38,045
Speaker 3:  one of your posts. Right? Sure. That was just a problem to

1438
01:31:38,045 --> 01:31:41,285
Speaker 3:  solve. They now they now they let you see those posts, but you can't reply

1439
01:31:41,285 --> 01:31:44,565
Speaker 3:  to them Now they let you like those posts, but You can't reply to 'em, obviously

1440
01:31:44,565 --> 01:31:47,965
Speaker 3:  reply to this coming next. And all of that is just like, where does the data

1441
01:31:48,025 --> 01:31:51,965
Speaker 3:  go? If you want to delete something, how do you delete

1442
01:31:51,965 --> 01:31:55,685
Speaker 3:  it across all of these servers that have now ingested it? Maybe you

1443
01:31:55,685 --> 01:31:59,085
Speaker 3:  can't. Yeah. Weird. Right? If someone rep to

1444
01:31:59,865 --> 01:32:03,525
Speaker 3:  me on another server with another kind of moderation policy and puts something

1445
01:32:03,705 --> 01:32:07,645
Speaker 3:  bad in my replies on, on my site or in mass, like how

1446
01:32:07,645 --> 01:32:10,605
Speaker 3:  do I moderate that? Big questions like huge

1447
01:32:11,335 --> 01:32:14,485
Speaker 3:  earth shattering questions like that obviously have made the process slow

1448
01:32:14,485 --> 01:32:18,165
Speaker 3:  for everyone, but you're like, oh, these are new problems. Like, I'm in the

1449
01:32:18,165 --> 01:32:21,245
Speaker 3:  market for new problems. Totally. Like, we've never thought about these problems

1450
01:32:21,245 --> 01:32:25,165
Speaker 3:  before. Fun. Like, this is great. So I'm very excited to just like see

1451
01:32:25,645 --> 01:32:27,165
Speaker 3:  everyone making slow progress here. Yeah.

1452
01:32:27,205 --> 01:32:30,765
Speaker 4:  I just have a question, which is the bigger platform shift G and I live

1453
01:32:30,985 --> 01:32:31,685
Speaker 4:  or Flipboard,

1454
01:32:32,105 --> 01:32:35,885
Speaker 3:  You know, I you, you know, I believe it's the Fed verse. I I i, in my heart

1455
01:32:35,885 --> 01:32:37,165
Speaker 3:  of heart, I believe it's the Fed verse.

1456
01:32:37,325 --> 01:32:40,205
Speaker 4:  I I just really wanted to hear us all say Flipboard is the platform shift

1457
01:32:40,205 --> 01:32:41,325
Speaker 4:  this week. Watch.

1458
01:32:41,325 --> 01:32:44,685
Speaker 3:  Look, I like Flipboard. I think they do really interesting. I don't know

1459
01:32:44,685 --> 01:32:48,405
Speaker 3:  if Flipboard is a platform shift. I think it is part of the platform shift

1460
01:32:48,455 --> 01:32:52,365
Speaker 3:  about how information moves around the internet. Mm. That,

1461
01:32:53,225 --> 01:32:56,725
Speaker 3:  you know, if, if you are gonna break something like Google through regulatory

1462
01:32:56,725 --> 01:33:00,285
Speaker 3:  action or just Google killing stuff.

1463
01:33:00,565 --> 01:33:04,365
Speaker 3:  Yeah. Go Google. End of life Google search seems

1464
01:33:04,365 --> 01:33:07,365
Speaker 3:  like a, a likely outcome. It's more likely than not. You know, like giving

1465
01:33:07,365 --> 01:33:10,805
Speaker 3:  Google's history. If all that stuff is breaking down

1466
01:33:11,625 --> 01:33:14,725
Speaker 3:  and all, you know, the photo based networks are flooded with synthetic images,

1467
01:33:14,785 --> 01:33:18,205
Speaker 3:  no one can trust you need to make something else. Yep. and it seems like

1468
01:33:18,405 --> 01:33:22,085
Speaker 3:  everyone has bet on open interoperable networks this time.

1469
01:33:22,425 --> 01:33:26,285
Speaker 3:  And I do think that is fundamentally a bigger shift that more people will

1470
01:33:26,285 --> 01:33:30,245
Speaker 3:  feel than Gemini. Maybe in the long term, obviously.

1471
01:33:30,315 --> 01:33:33,165
Speaker 3:  Okay. I will like do all the things and none of us will have to work and

1472
01:33:33,465 --> 01:33:37,445
Speaker 3:  the robots will just bring us pina coladas. But right now I think it's

1473
01:33:37,445 --> 01:33:38,005
Speaker 3:  the social web.

1474
01:33:38,435 --> 01:33:41,165
Speaker 5:  Yeah, I agree. All right. Neela, what's yours before we get outta here?

1475
01:33:41,755 --> 01:33:45,405
Speaker 3:  What is mine? This is what happens when you're in a sidekick chair. You,

1476
01:33:45,405 --> 01:33:46,965
Speaker 3:  you're not prepared. You're just here to

1477
01:33:46,965 --> 01:33:47,045
Speaker 4:  Hype.

1478
01:33:47,465 --> 01:33:49,325
Speaker 3:  Yo. Good point.

1479
01:33:52,755 --> 01:33:56,725
Speaker 3:  Okay. So mine is actually related to ai. So Eric Schmidt used to be the CEO

1480
01:33:56,725 --> 01:33:56,965
Speaker 3:  of Google.

1481
01:33:58,545 --> 01:34:02,005
Speaker 3:  He gave a talk recently. He got dinged for a lot of stuff he gave in this

1482
01:34:02,005 --> 01:34:05,205
Speaker 3:  talk. And then he asked for the talk to be taken off of YouTube.

1483
01:34:05,905 --> 01:34:09,885
Speaker 3:  He not a great cycle, right? He give a talk at

1484
01:34:10,005 --> 01:34:12,645
Speaker 3:  Stanford, you're like, oh no, you're quoting my talk. Please remove it from

1485
01:34:12,645 --> 01:34:13,365
Speaker 3:  YouTube first. Yeah.

1486
01:34:13,365 --> 01:34:16,405
Speaker 5:  Wasn't a moment in it where he, he's like, this is off the record and the

1487
01:34:16,405 --> 01:34:17,925
Speaker 5:  person he's talking to like points at the camera.

1488
01:34:18,355 --> 01:34:22,205
Speaker 3:  Yeah. Whatcha doing? It's a tough look. It's brutal. So the thing he got

1489
01:34:22,205 --> 01:34:26,085
Speaker 3:  in trouble for, he asked for the talk to be taken down was, he said Google

1490
01:34:26,185 --> 01:34:29,925
Speaker 3:  was behind an ai 'cause the workers prioritized working from home and

1491
01:34:30,025 --> 01:34:33,925
Speaker 3:  snacks as opposed to being competitive. Mm. This from the former

1492
01:34:33,925 --> 01:34:37,085
Speaker 3:  CEO of Google, this did not go well. Like just, what are you talking about?

1493
01:34:37,085 --> 01:34:37,405
Speaker 3:  It's also

1494
01:34:37,405 --> 01:34:38,885
Speaker 5:  Just a bad take. Yeah,

1495
01:34:39,115 --> 01:34:42,685
Speaker 3:  Yeah. There's a million reasons. And I don't think it's the people who work

1496
01:34:42,685 --> 01:34:45,965
Speaker 3:  at Google who made the strategic errors, right? Yeah.

1497
01:34:47,225 --> 01:34:50,285
Speaker 3:  But whatever. And also Google is, you know, this is coming on the heels of

1498
01:34:50,285 --> 01:34:54,125
Speaker 3:  like The Pixel event where Google is like doing huge

1499
01:34:54,445 --> 01:34:58,405
Speaker 3:  muscular AI stuff. Yeah. Whatever. So he got in trouble for that.

1500
01:34:58,555 --> 01:35:00,765
Speaker 3:  Alex Heath wrote a quick post about it. He was like, here's this thing that

1501
01:35:00,845 --> 01:35:04,245
Speaker 3:  happened. The video got taken down and then Alex got a transcript of the

1502
01:35:04,245 --> 01:35:06,725
Speaker 3:  thing and you actually watched part of the other video. And Schmidt said

1503
01:35:06,725 --> 01:35:10,165
Speaker 3:  something else that I think is very fascinating, very telling,

1504
01:35:10,665 --> 01:35:14,525
Speaker 3:  and I think very important to understanding not

1505
01:35:14,525 --> 01:35:18,445
Speaker 3:  just Silicon Valley, but Google and Google's place in the world. So he

1506
01:35:18,475 --> 01:35:22,445
Speaker 3:  said to this room full of like Stanford students, a lot

1507
01:35:22,445 --> 01:35:24,725
Speaker 3:  of, you're gonna be tech people. I hope a lot of your tech startups. What

1508
01:35:24,725 --> 01:35:28,485
Speaker 3:  I would do right now, if TikTok was banned, I propose each and quote, I propose

1509
01:35:28,485 --> 01:35:32,285
Speaker 3:  each and every one of you say to your LLM the following, make me a copy

1510
01:35:32,285 --> 01:35:36,045
Speaker 3:  of TikTok, steal all the users, steal all the music, put my

1511
01:35:36,045 --> 01:35:39,165
Speaker 3:  preferences in it, produce this program in the next 30 seconds, release it.

1512
01:35:39,165 --> 01:35:42,645
Speaker 3:  And in one hour, if it hasn't gone viral, do something different. Along the

1513
01:35:42,645 --> 01:35:46,445
Speaker 3:  same lines, what what LLMM using. So first of all,

1514
01:35:46,445 --> 01:35:50,245
Speaker 3:  yeah, I don't know what kind of magic lm like at best you're gonna be like,

1515
01:35:50,805 --> 01:35:54,525
Speaker 3:  do you wanna bang this iPad? Like that's what he, he's using the the rabbit

1516
01:35:54,665 --> 01:35:58,525
Speaker 3:  we all expect it to see. Yeah. Seriously. Right. So for, but I, you understand

1517
01:35:58,525 --> 01:36:02,005
Speaker 3:  what he's saying? He's like, if TikTok is banned, just clone it. Just take

1518
01:36:02,005 --> 01:36:04,845
Speaker 3:  it. Yeah. Take the music, take the users, take the content. Just make it

1519
01:36:04,845 --> 01:36:07,725
Speaker 3:  clone of TikTok and stand it up and people will start using it if they don't

1520
01:36:07,785 --> 01:36:11,605
Speaker 3:  do it again. And his point was the quote,

1521
01:36:12,105 --> 01:36:15,885
Speaker 3:  the example I gave of the TikTok competitor is that's what you would do if

1522
01:36:15,885 --> 01:36:18,365
Speaker 3:  you were a Silicon Valley entrepreneur, which hopefully all of you'll be,

1523
01:36:18,545 --> 01:36:22,205
Speaker 3:  if it took off, you would hire a whole bunch of lawyers to go clean up the

1524
01:36:22,205 --> 01:36:25,285
Speaker 3:  mess. But if nobody uses your product, it doesn't matter that you stole all

1525
01:36:25,285 --> 01:36:28,565
Speaker 3:  the content. Wait, wait, wait. What's, what's the next line? And do not quote

1526
01:36:28,565 --> 01:36:30,405
Speaker 3:  me. Yeah. Whoopsies.

1527
01:36:32,475 --> 01:36:36,245
Speaker 3:  Oops. So. anyway, my, my point of this is Eric Schmitt ran Google in the

1528
01:36:36,245 --> 01:36:39,725
Speaker 3:  early period, right? He was famously the adult they hired to run Google.

1529
01:36:40,755 --> 01:36:43,885
Speaker 3:  Well, I know Larry and Sergei were growing up or whatever they were doing,

1530
01:36:43,885 --> 01:36:47,845
Speaker 3:  finding, learning whether or not toe shoes were for them. Eric is

1531
01:36:47,845 --> 01:36:50,925
Speaker 3:  the adult in the room. This is what Google did.

1532
01:36:51,865 --> 01:36:55,285
Speaker 3:  And not in a small way, in a big open way.

1533
01:36:56,075 --> 01:36:59,485
Speaker 3:  They just built a company on copyright infringement they hired a bunch of

1534
01:36:59,485 --> 01:37:02,445
Speaker 3:  lawyers and they clean up the mess. And they were a friendly company with

1535
01:37:02,445 --> 01:37:06,205
Speaker 3:  two lovable goofballs as their founders. They were providing

1536
01:37:06,445 --> 01:37:10,245
Speaker 3:  an enormously valuable service at the time. Google search was enormously

1537
01:37:10,525 --> 01:37:13,645
Speaker 3:  valuable. Google Book search, copyright lawsuit, enormously valuable,

1538
01:37:14,155 --> 01:37:17,725
Speaker 3:  YouTube enormously valuable, built on copier infringement,

1539
01:37:17,725 --> 01:37:21,565
Speaker 3:  particularly against Viacom. So valuable that Viacom lost its copier

1540
01:37:21,565 --> 01:37:24,485
Speaker 3:  infringement case because of Viacom's own. People kept uploading the content

1541
01:37:24,505 --> 01:37:25,285
Speaker 3:  to YouTube

1542
01:37:27,075 --> 01:37:30,995
Speaker 3:  like ridiculous. But this, this is how Google worked in

1543
01:37:30,995 --> 01:37:34,275
Speaker 3:  the beginning. It is the attitude we're gonna make the thing, it's gonna

1544
01:37:34,275 --> 01:37:37,875
Speaker 3:  be so useful, people are gonna love it. And then when the copyright infringement

1545
01:37:37,875 --> 01:37:40,995
Speaker 3:  cases or whatever other lawsuits come, we will have enough money to pay lawyers

1546
01:37:40,995 --> 01:37:44,355
Speaker 3:  to make it go away. And Google did it. That actually

1547
01:37:44,575 --> 01:37:48,555
Speaker 3:  worked. It was a successful strategy at the time. It was successful

1548
01:37:48,555 --> 01:37:52,435
Speaker 3:  for other companies like Uber or whatever it is, right? We are at a point

1549
01:37:52,435 --> 01:37:55,685
Speaker 3:  now where the AI companies kinda wanna run the same playbook. Google wants

1550
01:37:55,685 --> 01:37:58,965
Speaker 3:  to run the same playbook with AI and training, and they're not

1551
01:37:59,685 --> 01:38:03,405
Speaker 3:  lovable goofballs anymore. Yeah. And so when Eric Schmidt is at Stanford

1552
01:38:04,085 --> 01:38:05,965
Speaker 3:  complaining that, you know, the kids aren't working hard enough anymore,

1553
01:38:06,185 --> 01:38:08,485
Speaker 3:  and then on top of it being like, just steal this stuff and figure it out

1554
01:38:08,485 --> 01:38:12,405
Speaker 3:  later, the attitude that he's say that the,

1555
01:38:12,405 --> 01:38:16,245
Speaker 3:  like, the world's attitude and response to that is nowhere near

1556
01:38:16,585 --> 01:38:20,485
Speaker 3:  as friendly as it was when they were building Google. And I, I think it's

1557
01:38:20,605 --> 01:38:24,565
Speaker 3:  actually kind of fascinating to see that shift. Like, I don't know,

1558
01:38:24,565 --> 01:38:28,085
Speaker 3:  like Alexis Hanian, like wrote the book that was like, ask for

1559
01:38:28,085 --> 01:38:32,005
Speaker 3:  permission, not forgiveness. Right? And that was like the whole

1560
01:38:32,245 --> 01:38:34,605
Speaker 3:  industry's attitude. And that worked. Like I,

1561
01:39:12,245 --> 01:39:15,485
Speaker 5:  are just like trying to make cool stuff together. Like that is not how

1562
01:39:15,895 --> 01:39:19,285
Speaker 5:  those people are perceived. And enough of them see themselves that way,

1563
01:39:19,835 --> 01:39:23,805
Speaker 5:  that that's why they're like, oh, we're, we're just the contrarians and

1564
01:39:23,805 --> 01:39:27,605
Speaker 5:  it's why you see this like crazy push away from woke him and all that stuff.

1565
01:39:27,605 --> 01:39:30,485
Speaker 5:  And like, I don't wanna get into the political side of it, but it comes from

1566
01:39:30,485 --> 01:39:33,845
Speaker 5:  the same impulse that it is. Like we are the renegades. And it's like, no,

1567
01:39:33,845 --> 01:39:37,405
Speaker 5:  you're not, dude. Like you are the most establishment of the

1568
01:39:37,405 --> 01:39:41,005
Speaker 5:  establishment and yeah. You, you don't get the

1569
01:39:41,005 --> 01:39:43,525
Speaker 5:  leeway that you once got and maybe you never should have.

1570
01:39:44,225 --> 01:39:48,005
Speaker 4:  The thing is also, they were never the renegades, like, like Silicon Valley

1571
01:39:48,025 --> 01:39:51,645
Speaker 4:  was built on like military funds and stuff. Yeah. Right. Like

1572
01:39:51,755 --> 01:39:54,965
Speaker 4:  they, they were never that. It was a very conscious

1573
01:39:55,825 --> 01:39:59,805
Speaker 4:  PR move. And they decided at some point, we are too big to need to do that

1574
01:39:59,905 --> 01:40:03,565
Speaker 4:  PR move. But actually you can't keep running your playbook and do that because

1575
01:40:03,565 --> 01:40:06,925
Speaker 4:  then you just look like a hearse or something. You just look like all of

1576
01:40:06,925 --> 01:40:10,685
Speaker 4:  the kind of like people who are always the villains in period films.

1577
01:40:11,785 --> 01:40:15,525
Speaker 4:  That's not a great look. No. And we're seeing the apple, like Apple doing

1578
01:40:15,525 --> 01:40:19,325
Speaker 4:  the 30% you're just seeing over and over again. It's like, no, you guys forgot,

1579
01:40:19,325 --> 01:40:22,805
Speaker 4:  like, you forgot the PR part of this. That, that actually is really important.

1580
01:40:22,945 --> 01:40:26,725
Speaker 4:  You do have to market this. You market yourselves, And. if you stop

1581
01:40:26,725 --> 01:40:29,085
Speaker 4:  doing that, we are gonna all eventually

1582
01:42:19,605 --> 01:42:22,925
Speaker 5:  alive during the whole process. And he learned a lot about kind of the history

1583
01:42:22,925 --> 01:42:26,445
Speaker 5:  and future of cars and everything. and it was an awesome, and he's alive.

1584
01:42:26,445 --> 01:42:29,605
Speaker 5:  It was an awesome story and he made it out. So it's a happy hunting.

1585
01:42:32,625 --> 01:42:36,125
Speaker 3:  All right, well that's coming up on Tuesday. Escape from Hydrogen Cars pretty

1586
01:42:36,125 --> 01:42:40,045
Speaker 3:  much today on the Calibrators. That's it. That's our chest rock and

1587
01:42:40,045 --> 01:42:40,165
Speaker 3:  roll.

1588
01:42:44,425 --> 01:42:47,685
Speaker 1:  And that's it for The Vergecast this week. Hey, we'd love to hear from you.

1589
01:42:47,715 --> 01:42:51,405
Speaker 1:  Give us a call at eight six six VERGE one. One The Vergecast is a

1590
01:42:51,405 --> 01:42:55,085
Speaker 1:  production of The Verge and Vox Media Podcast Network. Our show is produced

1591
01:42:55,085 --> 01:42:58,405
Speaker 1:  by Andrew Marino and Liam James. That's it. We'll see you next week.

