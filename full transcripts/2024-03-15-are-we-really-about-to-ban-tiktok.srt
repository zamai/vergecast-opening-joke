1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: a510c0e4-5fa8-4de2-a36d-8ec4b8dfef5d
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/6850138001847277611/-5719303374909386537/s93290-US-6062s-1710497252.mp3
Description: The Verge 's Nilay Patel, David Pierce, and Alex Cranz discuss the US House of Representatives passing a bill that could ban TikTok, the streaming news of the week, a Dyson robot, and more.

2
00:00:00,805 --> 00:00:01,735
Speaker 1:  Support for the show

3
00:00:32,735 --> 00:00:35,055
Speaker 1:  recommendation of any stock or investment strategy.

4
00:01:05,315 --> 00:01:08,875
Speaker 3:  combined with an AI code assistant and your preferred IDE for rapid

5
00:01:08,875 --> 00:01:12,155
Speaker 3:  development all wrapped up in an auto maintain infrastructure.

6
00:01:12,575 --> 00:01:15,835
Speaker 3:  Search Wix Studio today to explore the full range of features.

7
00:01:20,245 --> 00:01:24,075
Speaker 2:  Hello, And Welcome to our cast flagship podcast of algorithmic warfare.

8
00:01:24,865 --> 00:01:25,155
Speaker 1:  Good.

9
00:01:25,895 --> 00:01:27,275
Speaker 2:  That's good. That's a good phrase.

10
00:01:27,415 --> 00:01:28,955
Speaker 5:  That's a good like band name.

11
00:01:29,665 --> 00:01:29,955
Speaker 2:  Yeah.

12
00:01:30,425 --> 00:01:33,435
Speaker 5:  Like If. you were in high school, you would for sure play bass in a band

13
00:01:33,515 --> 00:01:35,195
Speaker 5:  called Algorithmic Warfare. Right now

14
00:01:35,665 --> 00:01:35,955
Speaker 6:  NELI

15
00:01:36,425 --> 00:01:38,275
Speaker 5:  NELI would for sure a hundred percent

16
00:01:39,555 --> 00:01:43,035
Speaker 2:  Cadillac this week. This is a true story. Cadillac this week teased a new

17
00:01:43,035 --> 00:01:45,515
Speaker 2:  concept called Opulent Velocity.

18
00:01:46,575 --> 00:01:47,035
Speaker 5:  Oh yeah.

19
00:01:47,085 --> 00:01:51,035
Speaker 2:  Which is really good. Like really good. but it sounds like the name of one

20
00:01:51,035 --> 00:01:54,595
Speaker 2:  of those clubs or restaurants in New York that's always empty but always

21
00:01:54,665 --> 00:01:55,435
Speaker 2:  open. Yeah.

22
00:01:55,535 --> 00:01:56,715
Speaker 6:  And is bottle service.

23
00:01:57,095 --> 00:02:00,675
Speaker 2:  But it, but no one's ever in there. No one fully staffed, no visitors.

24
00:02:01,105 --> 00:02:02,435
Speaker 2:  Opulent velocity. Yeah.

25
00:02:02,755 --> 00:02:04,635
Speaker 5:  I love that. I would stand in line for that.

26
00:02:04,865 --> 00:02:06,835
Speaker 2:  Algorithmic warfare is playing at opulent velocity.

27
00:02:08,425 --> 00:02:10,075
Speaker 5:  Tickets are $8,000

28
00:02:12,615 --> 00:02:16,595
Speaker 2:  To no one. Right? Yeah. If, you don't live in New York City. This is

29
00:02:16,595 --> 00:02:18,195
Speaker 2:  like a hard thing to convey

30
00:02:19,865 --> 00:02:23,645
Speaker 2:  or city has corruption in it and

31
00:02:23,645 --> 00:02:27,525
Speaker 2:  sometimes the people have to launder the money. So every now and again,

32
00:02:27,525 --> 00:02:31,235
Speaker 2:  you'll be in a neighborhood where there's just a fully staffed

33
00:02:31,285 --> 00:02:34,715
Speaker 2:  empty restaurant. There used to be one right by our office in Midtown. Yeah.

34
00:02:34,715 --> 00:02:35,995
Speaker 2:  It was deeply confusing,

35
00:02:36,375 --> 00:02:39,875
Speaker 6:  But No, I bet it would be like, great, how are the deals? How are, how are,

36
00:02:39,875 --> 00:02:40,195
Speaker 6:  how are

37
00:02:40,215 --> 00:02:42,715
Speaker 2:  The food? No, you would go in there and you'd be, first of all, you'd be

38
00:02:42,715 --> 00:02:46,595
Speaker 2:  like, I should leave. Yeah. Like the vibes were immediately hostile. Yeah.

39
00:02:47,015 --> 00:02:50,955
Speaker 2:  You're not ordering. And then you would order food and they'd be like,

40
00:02:50,955 --> 00:02:52,435
Speaker 2:  what? We don't know. We

41
00:02:52,435 --> 00:02:55,355
Speaker 6:  Don't, but like we, we have to go to like the grocery store and get you some

42
00:02:55,355 --> 00:02:56,635
Speaker 6:  chicken tenders. We'll be back

43
00:02:56,825 --> 00:02:57,595
Speaker 2:  Opulent velocity.

44
00:02:59,715 --> 00:03:02,215
Speaker 2:  All right. There's a lot happening this week. I'm your friend NELI. Alex.

45
00:03:02,305 --> 00:03:03,855
Speaker 2:  Cranz is here in studio. Yeah,

46
00:03:04,305 --> 00:03:04,655
Speaker 6:  We're

47
00:03:04,655 --> 00:03:07,095
Speaker 2:  Back. I was gonna say it's been a minute. It's a minute. But we were just

48
00:03:07,335 --> 00:03:10,295
Speaker 2:  together in Texas. Yeah. All three of us. But it's been a minute since you

49
00:03:10,295 --> 00:03:11,855
Speaker 2:  and I were together in this studio. That's

50
00:03:11,855 --> 00:03:13,575
Speaker 6:  True. It's nice. It's a good energy. I'm having

51
00:03:13,575 --> 00:03:15,855
Speaker 2:  Fun. And then David Pierce is Vanish was basement once again. Yeah.

52
00:03:15,855 --> 00:03:17,215
Speaker 5:  Cool. Thanks. It's really nice to see

53
00:03:17,215 --> 00:03:17,375
Speaker 2:  You guys

54
00:03:17,695 --> 00:03:18,335
Speaker 6:  Feeling great.

55
00:03:20,315 --> 00:03:20,895
Speaker 6:  How is it?

56
00:03:21,615 --> 00:03:24,695
Speaker 5:  I mean, it's, it's a basement. I did nap over there earlier, so I'm feeling

57
00:03:24,695 --> 00:03:26,535
Speaker 5:  great. Ooh, everything's, everything's going well today.

58
00:03:26,645 --> 00:03:27,135
Speaker 6:  Hell yes.

59
00:03:27,395 --> 00:03:30,295
Speaker 2:  My understanding is that we are soon to give you some sort of green screen

60
00:03:30,345 --> 00:03:32,375
Speaker 2:  experience where you can be anywhere.

61
00:03:32,685 --> 00:03:36,375
Speaker 5:  Liam is threatening to give me a background, but every time he threatens

62
00:03:36,475 --> 00:03:40,295
Speaker 5:  the background, there's one more box involved. And So

63
00:03:41,015 --> 00:03:44,975
Speaker 5:  I think we're, we're now at either two or three boxes plus a six foot

64
00:03:45,005 --> 00:03:47,655
Speaker 5:  long green screen that lives under my couch. So

65
00:03:48,805 --> 00:03:52,735
Speaker 5:  it's either gonna happen and really change my life in a big way

66
00:03:52,795 --> 00:03:56,655
Speaker 5:  or I'm just going to refuse to engage in this process any longer. We'll see.

67
00:03:56,965 --> 00:04:00,895
Speaker 2:  Look, I know Vergecast listeners have a relationship with our producer,

68
00:04:01,045 --> 00:04:04,635
Speaker 2:  Liam, mostly because he's the person who makes us be on time, which we have

69
00:04:04,795 --> 00:04:08,595
Speaker 2:  defeated. Liam, I just wanna be clear that listeners plus hosts have defeated

70
00:04:08,665 --> 00:04:11,875
Speaker 2:  Liam, but the way you know he is the right producer for the show is that

71
00:04:11,875 --> 00:04:15,795
Speaker 2:  when he's allowed to spend money in gadgets and gadget

72
00:04:15,795 --> 00:04:19,565
Speaker 2:  related ideas, it's just outta control like the Oh, he goes all in

73
00:04:19,625 --> 00:04:21,965
Speaker 2:  the studio that is being built at my house fully out of control.

74
00:04:22,395 --> 00:04:22,965
Speaker 6:  It's sick.

75
00:04:23,395 --> 00:04:26,965
Speaker 2:  It's it, it's great. And one day we'll make Liam do the video where he is

76
00:04:26,965 --> 00:04:27,965
Speaker 2:  like, here's all the stuff I bought,

77
00:04:28,865 --> 00:04:31,085
Speaker 5:  But it Studio tour. That's gonna happen. It it's gonna be

78
00:04:31,085 --> 00:04:34,085
Speaker 2:  Great. Yeah. It's a lot of stuff. And then I have ideas.

79
00:04:36,515 --> 00:04:39,885
Speaker 2:  It's not, it's not great. I would not say it's a cost effective studio, but

80
00:04:41,315 --> 00:04:43,245
Speaker 2:  it's, it's just a lot of stuff. It's

81
00:04:43,245 --> 00:04:46,245
Speaker 5:  Great. I like to imagine you just never get out of your chair and you just

82
00:04:46,245 --> 00:04:49,805
Speaker 5:  sort of wheel from set to set all day depending on what you're doing.

83
00:04:50,225 --> 00:04:50,565
Speaker 5:  You just

84
00:04:50,565 --> 00:04:53,325
Speaker 2:  Kind of like, Liam bomb across li has threaten to automate the studio. So

85
00:04:53,325 --> 00:04:55,725
Speaker 2:  you just push one button and like the shades go down and the lights turn

86
00:04:55,725 --> 00:04:57,605
Speaker 2:  on. I don't know that we can get there. You,

87
00:04:57,705 --> 00:05:01,205
Speaker 6:  You totally can. Home assistant, right, Liam? It's gonna be home assistant.

88
00:05:01,875 --> 00:05:02,925
Speaker 6:  It's gonna be sick.

89
00:05:03,125 --> 00:05:05,445
Speaker 2:  I like how you just like try to get Liam to jump in. Come on

90
00:05:05,445 --> 00:05:08,405
Speaker 6:  Liam, hop in. He's not doing it. He's like, no, he's

91
00:05:08,405 --> 00:05:09,005
Speaker 2:  Hiding under the studio.

92
00:05:09,025 --> 00:05:10,165
Speaker 6:  No, he's got, he's got ideas.

93
00:05:12,875 --> 00:05:15,885
Speaker 2:  Yeah. He's not, I, we were waiting. He just didn't show up.

94
00:05:17,575 --> 00:05:18,445
Speaker 6:  He'll not be bathed.

95
00:05:18,445 --> 00:05:21,685
Speaker 2:  He's, he's very upset. That's right. I'm sorry. We love you Liam.

96
00:05:21,915 --> 00:05:22,365
Speaker 6:  Liam is

97
00:05:22,365 --> 00:05:23,845
Speaker 2:  Incredible. Everyone tweeted Liam. Okay.

98
00:05:24,315 --> 00:05:25,445
Speaker 6:  Good things only now

99
00:05:25,445 --> 00:05:28,965
Speaker 2:  That we're on the high vibes. Yeah, there's a lot to talk about this week.

100
00:05:29,365 --> 00:05:33,245
Speaker 2:  There's the TikTok ban, which we gotta talk about a lot. There's a

101
00:05:33,245 --> 00:05:37,165
Speaker 2:  bunch of streaming Wars news, there's Twitter now X

102
00:05:38,145 --> 00:05:41,905
Speaker 2:  pivoting to video, which a real 2012 idea.

103
00:05:41,905 --> 00:05:44,745
Speaker 2:  There's a new YouTube app and then we got a lightning round. There's all

104
00:05:44,745 --> 00:05:47,265
Speaker 2:  kinds of stuff going on. Oh, Starship had its third launch, which appears

105
00:05:47,265 --> 00:05:49,905
Speaker 2:  to be totally successful. That happened to only minutes before we started

106
00:05:49,905 --> 00:05:53,855
Speaker 2:  recording. So I'm saying that, and we'll see

107
00:05:53,855 --> 00:05:56,535
Speaker 2:  if it landed. By the time we get to talking about it,

108
00:05:57,595 --> 00:06:01,365
Speaker 2:  it's gonna be great. But we should start with TikTok, which is undoubtedly

109
00:06:01,385 --> 00:06:05,165
Speaker 2:  the news of the week. It is very confusing,

110
00:06:05,165 --> 00:06:08,525
Speaker 2:  very stressful. And I have promised to have the hottest take of all. But

111
00:06:08,525 --> 00:06:10,285
Speaker 2:  first, David, do you wanna tell us what's going on with TikTok?

112
00:06:10,715 --> 00:06:14,565
Speaker 5:  Sure. So the very short version of what has now become a

113
00:06:14,565 --> 00:06:18,485
Speaker 5:  very long story is that after in 2021 deciding not to ban

114
00:06:18,505 --> 00:06:22,405
Speaker 5:  TikTok, Congress has decided once again that it, it would very much like

115
00:06:22,405 --> 00:06:25,965
Speaker 5:  to ban TikTok. So there is this bill called the Protecting

116
00:06:26,285 --> 00:06:29,765
Speaker 5:  Americans from Foreign Adversary Controlled Applications Act, which just

117
00:06:29,765 --> 00:06:32,885
Speaker 5:  really rolls off the tongue. Hmm. And what it essentially does

118
00:06:33,905 --> 00:06:37,285
Speaker 5:  is block app stores from hosting

119
00:06:37,705 --> 00:06:41,565
Speaker 5:  TikTok and it blocks internet hosting providers from

120
00:06:41,565 --> 00:06:45,325
Speaker 5:  hosting TikTok. And there are a million complications and nuances in that

121
00:06:45,325 --> 00:06:49,125
Speaker 5:  that we should talk about. But the idea is essentially to either ban

122
00:06:49,125 --> 00:06:53,005
Speaker 5:  TikTok outright or force it to be sold to

123
00:06:53,065 --> 00:06:56,605
Speaker 5:  an American company or a company at least not owned by a foreign

124
00:06:56,605 --> 00:07:00,365
Speaker 5:  adversary, which is a technical term that only a few countries qualify

125
00:07:00,415 --> 00:07:04,365
Speaker 5:  under. So it went through committee, I believe it passed in a house

126
00:07:04,365 --> 00:07:05,405
Speaker 5:  committee. 50 to zero.

127
00:07:05,895 --> 00:07:06,925
Speaker 2:  50 to zero. Yeah.

128
00:07:07,025 --> 00:07:10,645
Speaker 5:  And then it went to the broader house where it passed with like 80%. Yes.

129
00:07:10,645 --> 00:07:14,485
Speaker 5:  Which was a huge ridiculous victory in a time where nothing

130
00:07:14,485 --> 00:07:17,805
Speaker 5:  passes with numbers like that. So now this bill is sitting in front of the

131
00:07:17,805 --> 00:07:21,685
Speaker 5:  Senate president Biden has said that if it is passed to him,

132
00:07:21,745 --> 00:07:25,525
Speaker 5:  he will sign it into law. There is essentially now one

133
00:07:25,875 --> 00:07:29,565
Speaker 5:  step remaining between us and a TikTok ban.

134
00:07:29,745 --> 00:07:32,525
Speaker 5:  And it's a big step and there are lots of good reasons to believe it will

135
00:07:32,525 --> 00:07:34,085
Speaker 5:  never surmount that step. Yeah. 'cause

136
00:07:34,085 --> 00:07:36,885
Speaker 6:  It's, it's Rand Paul, right? Like the step is Rand Paul,

137
00:07:37,355 --> 00:07:39,525
Speaker 2:  Senator Rand Paul, the Senate overall. Yeah.

138
00:07:39,635 --> 00:07:42,925
Speaker 5:  It's Rand Paul and it's Chuck Schumer. And there are, there are a lot of

139
00:07:42,925 --> 00:07:46,405
Speaker 5:  people in the Senate who have reasons not to make this happen. Right. but

140
00:07:46,405 --> 00:07:49,885
Speaker 5:  it is, we are much closer to a TikTok ban than we have ever been before

141
00:07:50,785 --> 00:07:54,525
Speaker 5:  to the point where a lot of people inside TikTok and outside

142
00:07:54,545 --> 00:07:56,205
Speaker 5:  TikTok think it's gonna happen.

143
00:07:56,745 --> 00:08:00,365
Speaker 2:  All right. So can I quibble with you on one thing please? And it is just

144
00:08:00,365 --> 00:08:03,725
Speaker 2:  the most pedantic thing, but why are, why else we here? Yeah. The idea that

145
00:08:03,725 --> 00:08:07,005
Speaker 2:  it's a ban on TikTok specifically like

146
00:08:07,275 --> 00:08:08,525
Speaker 2:  conflates, too many ideas.

147
00:08:08,665 --> 00:08:12,645
Speaker 5:  Can I read you the first sentence of the Bill Eli? Yeah. To protect the national

148
00:08:12,885 --> 00:08:15,765
Speaker 5:  security of the United States from the threat posed by foreign adversary

149
00:08:15,765 --> 00:08:18,125
Speaker 5:  controlled applications such as TikTok.

150
00:08:19,475 --> 00:08:22,885
Speaker 5:  It's the only app they name in the bill. This is a TikTok

151
00:08:23,085 --> 00:08:26,365
Speaker 2:  Ban. Sure. And it's the only app specified later in the bill. Right.

152
00:08:26,865 --> 00:08:30,605
Speaker 2:  but it, but the mechanism by which it is accomplishing that goal

153
00:08:31,105 --> 00:08:34,965
Speaker 2:  is not actually by banning TikTok. And I think that's, that's important.

154
00:08:36,025 --> 00:08:39,925
Speaker 2:  If, you wanna understand the dynamics of this bill and the people arrayed

155
00:08:40,305 --> 00:08:42,445
Speaker 2:  for and against it. What might actually happen with TikTok?

156
00:08:44,415 --> 00:08:48,145
Speaker 2:  It's a bill that regulates app stores and internet service providers. Yes.

157
00:08:48,205 --> 00:08:51,985
Speaker 2:  It does not regulate TikTok at all. Like nothing in this bill

158
00:08:53,145 --> 00:08:57,085
Speaker 2:  requires TikTok to do anything. It requires a

159
00:08:57,085 --> 00:09:00,925
Speaker 2:  bunch of other companies to do stuff that will make it impossible for

160
00:09:00,925 --> 00:09:04,685
Speaker 2:  TikTok to do business here. And I think when we have all these

161
00:09:04,685 --> 00:09:08,525
Speaker 2:  conversations about the 170 million Americans who use TikTok and free speech

162
00:09:08,525 --> 00:09:12,125
Speaker 2:  and all these businesses, it's all is though the government is

163
00:09:12,125 --> 00:09:15,315
Speaker 2:  regulating TikTok. but it is, but

164
00:09:15,945 --> 00:09:19,755
Speaker 2:  very specifically and very mechanically in this bill, it is not doing

165
00:09:19,755 --> 00:09:23,075
Speaker 2:  that. It is making it impossible for TikTok to do business in the United States.

166
00:09:23,215 --> 00:09:26,235
Speaker 2:  And you might think that is the same thing. And you are, I'm sure people

167
00:09:26,235 --> 00:09:30,225
Speaker 2:  have a lot of like feelings about what I'm saying, but it If, you just

168
00:09:30,255 --> 00:09:33,825
Speaker 2:  read the language of the bill. The bill does not regulate.

169
00:09:34,125 --> 00:09:37,185
Speaker 2:  It says TikTok and for political expediency,

170
00:09:38,625 --> 00:09:42,565
Speaker 2:  but it doesn't actually regulate TikTok directly. It just says these

171
00:09:42,565 --> 00:09:45,805
Speaker 2:  other companies cannot do business with TikTok. And I think that's actually

172
00:09:45,805 --> 00:09:46,405
Speaker 2:  really important.

173
00:09:46,835 --> 00:09:50,445
Speaker 5:  It's also the only way to do it. Like you, you can't argue that

174
00:09:50,505 --> 00:09:54,365
Speaker 5:  TikTok is a company owned and run by China and then say the US

175
00:09:54,365 --> 00:09:57,645
Speaker 5:  government can regulate it like that. You just can't have it both ways. This

176
00:09:57,645 --> 00:10:00,325
Speaker 5:  is the only way to get to TikTok. If. you want to get to TikTok?

177
00:10:00,705 --> 00:10:04,045
Speaker 2:  No, there are, there are other ways to do it. I some of those ways have succeeded

178
00:10:04,045 --> 00:10:07,525
Speaker 2:  in the courts and some of them have failed. Like over time we are

179
00:10:07,555 --> 00:10:11,245
Speaker 2:  capable of regulating how foreign companies do business in the United States.

180
00:10:11,585 --> 00:10:15,565
Speaker 2:  For example, foreign companies are not really allowed

181
00:10:15,565 --> 00:10:19,485
Speaker 2:  to own like broadcast licenses in the United States. So If, you want to set

182
00:10:19,485 --> 00:10:23,325
Speaker 2:  up a CBS tower in New York City, you can't go get a bunch of Saudi

183
00:10:23,325 --> 00:10:26,965
Speaker 2:  money to do it. We, we seem to be fine with that. I just, and I just wanna

184
00:10:26,965 --> 00:10:30,885
Speaker 2:  put that out there. Like there are some very direct regulations that we have

185
00:10:30,885 --> 00:10:34,485
Speaker 2:  over media ownership in this country. And then there there's this bill, which

186
00:10:34,485 --> 00:10:38,085
Speaker 2:  is like Apple can't do business with TikTok and it's actually different.

187
00:10:38,345 --> 00:10:42,295
Speaker 2:  And the reason I'm poking at that really hard is 'cause I think

188
00:10:42,315 --> 00:10:46,095
Speaker 2:  the rhetoric on both sides of this has gotten one turn

189
00:10:46,355 --> 00:10:50,165
Speaker 2:  too simplistic, right? On the, we should

190
00:10:50,325 --> 00:10:53,885
Speaker 2:  ban it side. It's like this is a danger to the United States. And then you're

191
00:10:53,885 --> 00:10:55,405
Speaker 2:  like, so what's it whatcha are gonna do about it? And they're like, we're

192
00:10:55,405 --> 00:10:58,885
Speaker 2:  gonna tell Apple what to do. Weird. Weird. Just like

193
00:10:59,045 --> 00:11:01,565
Speaker 2:  straightforwardly weird. And on the other side it's like you're infringing

194
00:11:01,565 --> 00:11:05,285
Speaker 2:  our free speech rights by banning TikTok. And then you look at the thing

195
00:11:05,285 --> 00:11:08,525
Speaker 2:  and it's like, oh, that is the third order outcome of this.

196
00:11:09,465 --> 00:11:12,085
Speaker 2:  But if what you're really doing is regulating Apple or you're doing, there's

197
00:11:12,205 --> 00:11:15,525
Speaker 2:  actually all these other outs, including you could sell TikTok,

198
00:11:16,525 --> 00:11:20,415
Speaker 2:  which as you pointed out David in 2021, like, boy

199
00:11:20,415 --> 00:11:23,615
Speaker 2:  haven't we been through this before? Like Microsoft was gonna buy TikTok.

200
00:11:23,965 --> 00:11:27,535
Speaker 2:  Ella was like, this is the weirdest deal I've ever been a part of. Oracle

201
00:11:27,795 --> 00:11:31,205
Speaker 2:  has Project Texas and they, no one cares.

202
00:11:31,955 --> 00:11:35,725
Speaker 2:  Like the least Alex is from Texas. This is the least anything named Texas

203
00:11:35,945 --> 00:11:37,725
Speaker 2:  has ever talked about itself. Yeah,

204
00:11:37,955 --> 00:11:41,205
Speaker 6:  Yeah. It's true. It's true. All the other Texans are really confused

205
00:11:41,905 --> 00:11:44,805
Speaker 6:  what's happening. Like how I got to that. Yeah, I

206
00:11:45,805 --> 00:11:49,745
Speaker 6:  do not, lemme take that back. Yeah, I, I keep

207
00:11:49,745 --> 00:11:52,545
Speaker 6:  looking at this and it's, it's fundamentally just like the next step in the,

208
00:11:52,545 --> 00:11:56,525
Speaker 6:  in the Chinese American trade war, right? Like this is just saying we

209
00:11:56,815 --> 00:12:00,205
Speaker 6:  don't want apps created in China that are popular

210
00:12:01,685 --> 00:12:05,405
Speaker 6:  functioning in the United States full stop and, and a few other

211
00:12:05,605 --> 00:12:09,205
Speaker 6:  countries, but, but specifically China. And, and so this is just an extension

212
00:12:09,205 --> 00:12:12,505
Speaker 6:  of that trade war. And I'm a little like

213
00:12:13,315 --> 00:12:17,065
Speaker 6:  taken aback by it. It does feel like, like the TikTok stuff in particular

214
00:12:17,085 --> 00:12:20,625
Speaker 6:  has always felt vaguely xenophobic. It's always felt a little like, oh, we

215
00:12:20,625 --> 00:12:23,585
Speaker 6:  can't, we can't have the Chinese do things here because America

216
00:12:24,405 --> 00:12:28,225
Speaker 6:  and, and, and, and, but we, we do also at the same time have this this quickly

217
00:12:28,225 --> 00:12:32,105
Speaker 6:  accelerating trade war that, that was, it was like in the background and

218
00:12:32,105 --> 00:12:36,065
Speaker 6:  then Trump was like, let me lob the, the trade equivalent of a

219
00:12:36,065 --> 00:12:39,985
Speaker 6:  bomb into the mix. And and now this is, it's not quite nuclear, but

220
00:12:39,985 --> 00:12:43,785
Speaker 6:  this is like a really significant moment in that trade

221
00:12:43,785 --> 00:12:47,275
Speaker 6:  war. And, and they're just, everybody's so

222
00:12:47,425 --> 00:12:50,555
Speaker 6:  focused on TikTok and ignoring the fact that you are fundamentally changing

223
00:12:50,575 --> 00:12:53,835
Speaker 6:  how the internet works in the United States and saying,

224
00:12:54,455 --> 00:12:57,635
Speaker 6:  no, we are actually gonna build a wall the way that China has a wall. The

225
00:12:57,635 --> 00:13:00,515
Speaker 6:  United States is gonna have a wall and some of this stuff we've already said

226
00:13:00,515 --> 00:13:02,915
Speaker 6:  it about a lot of the technology that's coming out of China. And now they're

227
00:13:02,915 --> 00:13:05,875
Speaker 6:  gonna say, yeah. And, and also these apps and

228
00:13:07,825 --> 00:13:10,605
Speaker 6:  you know, it worked when it was Huawei and it was phones and they didn't

229
00:13:10,605 --> 00:13:13,805
Speaker 6:  have a huge market share in the United States. And so it was like, oh no,

230
00:13:13,805 --> 00:13:17,405
Speaker 6:  we lost Huawei. And like, that sucks 'cause they have really good technology

231
00:13:17,405 --> 00:13:21,205
Speaker 6:  in their devices and now we're like, they're going after

232
00:13:21,425 --> 00:13:24,255
Speaker 6:  TikTok. And that's, and people suddenly care.

233
00:13:25,075 --> 00:13:26,615
Speaker 2:  All right, here it is. You ready, I'm

234
00:13:26,615 --> 00:13:26,775
Speaker 6:  Ready.

235
00:13:27,175 --> 00:13:29,455
Speaker 2:  I think it makes total sense for the United States government to not want

236
00:13:29,455 --> 00:13:32,775
Speaker 2:  Chinese ownership of a major media platform in this country. Like Yeah. It

237
00:13:32,995 --> 00:13:36,575
Speaker 2:  it is sensible on its face. It was sensible on its face for us to not want

238
00:13:36,575 --> 00:13:39,695
Speaker 2:  a bunch of Huawei technology in our communications networks. Yep.

239
00:13:40,815 --> 00:13:44,275
Speaker 2:  And I, I I agree with you. I think most people didn't have like Strand brand

240
00:13:44,435 --> 00:13:48,115
Speaker 2:  affinity for Huawei. So when we would have FCC commissioners

241
00:13:48,215 --> 00:13:50,875
Speaker 2:  on the show, Jeffrey Starks was on the show being like, we gotta rip and

242
00:13:50,875 --> 00:13:51,835
Speaker 2:  replace all the Huawei gear.

243
00:13:53,735 --> 00:13:57,435
Speaker 2:  No creator said anything. Right. As far as I understand, like maybe

244
00:13:57,435 --> 00:14:00,755
Speaker 2:  there was a Huawei powered creator campaign to be like,

245
00:14:01,585 --> 00:14:02,075
Speaker 6:  Save us

246
00:14:02,655 --> 00:14:05,835
Speaker 2:  As far as I can tell, I think some people may be around the phones. Yeah.

247
00:14:06,075 --> 00:14:09,875
Speaker 6:  I mean they had war with the phones, they had like the le it was Yeah. Yeah.

248
00:14:10,015 --> 00:14:10,355
Speaker 6:  It was

249
00:14:10,355 --> 00:14:14,235
Speaker 5:  Cool. Meli. Sure. In order to make that statement, you have to believe

250
00:14:14,375 --> 00:14:17,715
Speaker 5:  one of the two arguments that everybody makes against TikTok, which is either

251
00:14:18,295 --> 00:14:21,795
Speaker 5:  it is this like crucially important vessel through which China is collecting

252
00:14:21,795 --> 00:14:25,315
Speaker 5:  data about Americans, or it is how China is

253
00:14:25,315 --> 00:14:28,955
Speaker 5:  disseminating propaganda and influencing US elections and making our children

254
00:14:29,055 --> 00:14:30,795
Speaker 5:  idiots. Which of those do you believe

255
00:14:31,255 --> 00:14:31,955
Speaker 2:  The second one?

256
00:14:32,375 --> 00:14:35,235
Speaker 5:  Do you, do you really? Yeah. On what evidence?

257
00:14:35,625 --> 00:14:39,115
Speaker 2:  None. I just to be clear, I I just,

258
00:14:39,345 --> 00:14:40,675
Speaker 2:  just to be clear, just

259
00:14:40,675 --> 00:14:41,595
Speaker 5:  To be a great podcast

260
00:14:42,035 --> 00:14:45,555
Speaker 2:  And I, I don't wanna, I don't wanna like say I have a bunch of evidence.

261
00:14:45,715 --> 00:14:49,115
Speaker 2:  I think actually one of the problems in this entire situation

262
00:14:49,775 --> 00:14:53,765
Speaker 2:  is that the House select committee went into a secure

263
00:14:54,125 --> 00:14:57,005
Speaker 2:  briefing. They saw whatever evidence there was,

264
00:14:57,945 --> 00:15:01,605
Speaker 2:  and they walked outta that briefing and went and immediately to a vote and

265
00:15:01,605 --> 00:15:05,565
Speaker 2:  voted 50 to zero to pass this bill that would either get

266
00:15:05,565 --> 00:15:08,645
Speaker 2:  TikTok off the app stores or force them to sell

267
00:15:09,475 --> 00:15:13,365
Speaker 2:  with no dissension, no controversy. I was at South by

268
00:15:13,365 --> 00:15:17,275
Speaker 2:  Southwest. The, the, the, the vibe I

269
00:15:17,275 --> 00:15:21,235
Speaker 2:  heard coming outta the briefing was Congress people saying, If, you

270
00:15:21,235 --> 00:15:24,245
Speaker 2:  saw what we saw, you'd do it too. What did they see?

271
00:15:26,075 --> 00:15:29,355
Speaker 2:  I think they should be made to present that evidence to the American people

272
00:15:30,135 --> 00:15:34,115
Speaker 2:  and yet, and yet they have not. Right. And yet that evidence is also so

273
00:15:34,125 --> 00:15:37,955
Speaker 2:  persuasive that they voted 3 83 to whatever to

274
00:15:37,955 --> 00:15:41,435
Speaker 2:  pass the bill in the full house. And yet there's nothing, the evidence is

275
00:15:41,435 --> 00:15:44,315
Speaker 2:  so persuasive that Joe Biden's like, I'll, I'll I'll sign it when it comes

276
00:15:44,315 --> 00:15:47,155
Speaker 2:  to my desk. And yet no one has made the case.

277
00:15:48,245 --> 00:15:52,065
Speaker 2:  The thing that I'm saying based on no evidence is you should not

278
00:15:52,245 --> 00:15:56,025
Speaker 2:  let an adversary of the United States even have this

279
00:15:56,025 --> 00:15:59,865
Speaker 2:  capability. We didn't know if Huawei was actually spying on our communications

280
00:15:59,865 --> 00:16:02,545
Speaker 2:  networks by embedding hardware directly into the cell system.

281
00:16:03,765 --> 00:16:07,505
Speaker 2:  No one wants to take the chance. Right? Like, that seems

282
00:16:07,555 --> 00:16:07,905
Speaker 2:  silly.

283
00:16:08,405 --> 00:16:11,905
Speaker 6:  The problem, the problem I think with, with the argument of

284
00:16:12,815 --> 00:16:16,745
Speaker 6:  this is about protecting us from, from, from Chinese

285
00:16:17,185 --> 00:16:20,665
Speaker 6:  interests is that meta still exists.

286
00:16:21,185 --> 00:16:24,945
Speaker 6:  A ton of other algorithmically driven social media platforms that are

287
00:16:25,165 --> 00:16:28,945
Speaker 6:  extraordinarily susceptible to propaganda still

288
00:16:28,945 --> 00:16:32,065
Speaker 6:  exist Sure. In this country and function in this country. They're only going

289
00:16:32,065 --> 00:16:35,685
Speaker 6:  after TikTok, which means like Russia

290
00:16:35,835 --> 00:16:39,325
Speaker 6:  went and, and did a whole lot of stuff in 2016, and we have a whole lot of

291
00:16:39,325 --> 00:16:43,245
Speaker 6:  proof of that and not a lot's changed on that front. Instead we were just

292
00:16:43,245 --> 00:16:45,845
Speaker 6:  like, well, we're gonna get rid of, Facebook's gonna get rid of a newsfeed

293
00:16:45,845 --> 00:16:49,765
Speaker 6:  and we're we're all gonna be fine. And, and, and Menal is allowed to exist

294
00:16:49,765 --> 00:16:53,445
Speaker 6:  in the com country. So this is explicitly about

295
00:16:53,455 --> 00:16:57,325
Speaker 6:  China, but feels like so wrongheaded in actually

296
00:16:57,325 --> 00:17:01,245
Speaker 6:  solving the problem because right now, okay, you say we we

297
00:17:01,245 --> 00:17:05,245
Speaker 6:  kill TikTok in the United States, it goes away. China can just

298
00:17:05,245 --> 00:17:08,405
Speaker 6:  go to US data brokers and get all that same

299
00:17:08,405 --> 00:17:10,325
Speaker 2:  Data. But that's the, that's the first thing that David is saying, the data

300
00:17:10,325 --> 00:17:13,485
Speaker 2:  brokers thing. Right. So this is why I ask about the two things because I

301
00:17:13,565 --> 00:17:16,045
Speaker 2:  I agree that, I think I specifically mean the second one, but I think

302
00:17:16,045 --> 00:17:19,705
Speaker 6:  If, but on that second turn, again, they can just

303
00:17:19,845 --> 00:17:23,505
Speaker 6:  go and send their, their propaganda like right now. Okay. They, it's cool.

304
00:17:23,505 --> 00:17:26,265
Speaker 6:  They, they maybe just have a button on the algorithm and they can, they can

305
00:17:26,265 --> 00:17:30,025
Speaker 6:  control the algorithm in a very direct way. Instead they can now just send

306
00:17:30,645 --> 00:17:33,705
Speaker 6:  all of their, their people, their, their propaganda specialists and all of

307
00:17:33,705 --> 00:17:37,505
Speaker 6:  those folks onto, to meta onto, onto threads,

308
00:17:37,575 --> 00:17:41,385
Speaker 6:  onto Instagram, onto X for the four

309
00:17:41,385 --> 00:17:44,585
Speaker 6:  people still there. They, they, they can all, they can send 'em all to all

310
00:17:44,585 --> 00:17:48,465
Speaker 6:  those other places. And that doesn't solve the problem. It just

311
00:17:48,465 --> 00:17:51,725
Speaker 6:  like, it makes their lives just a little bit diff more difficult

312
00:17:52,425 --> 00:17:54,325
Speaker 6:  and Yeah. I I just, but

313
00:17:54,325 --> 00:17:58,005
Speaker 2:  That wait, it makes their lives a lot more difficult. Vastly

314
00:17:58,035 --> 00:18:01,485
Speaker 2:  more difficult. Okay. I do agree with that. For all of their, many,

315
00:18:01,875 --> 00:18:05,165
Speaker 2:  many, many faults. Yeah. Mark

316
00:18:05,255 --> 00:18:09,165
Speaker 2:  Zuckerberg and Sundar Petra and Elon Musk live in the United States.

317
00:18:09,235 --> 00:18:13,045
Speaker 2:  They operate United States companies. Right. Their kids

318
00:18:13,155 --> 00:18:16,845
Speaker 2:  live here. If the United States and China go to war,

319
00:18:17,135 --> 00:18:20,965
Speaker 2:  their kids will be at risk. The United States government has direct

320
00:18:21,365 --> 00:18:25,245
Speaker 2:  regulatory control over their companies. Their companies, again, you

321
00:18:25,245 --> 00:18:28,925
Speaker 2:  can argue about the merits of this as much as you want

322
00:18:29,015 --> 00:18:32,765
Speaker 2:  their companies comply with and often support the military

323
00:18:32,765 --> 00:18:34,645
Speaker 2:  activities of the United States. Right.

324
00:18:34,985 --> 00:18:38,925
Speaker 6:  I'm I'm saying I have a problem with the idea that we

325
00:18:38,925 --> 00:18:41,685
Speaker 6:  are okay with algorithmically driven

326
00:18:42,375 --> 00:18:45,085
Speaker 6:  propaganda machines only when they're American.

327
00:18:45,505 --> 00:18:49,325
Speaker 2:  We are because of the fucking First Amendment. Yeah. Right. Like our

328
00:18:49,325 --> 00:18:53,085
Speaker 2:  government would love to sit down and directly regulate the

329
00:18:53,175 --> 00:18:57,085
Speaker 2:  algorithms of meta and YouTube. They would in a

330
00:18:57,085 --> 00:18:59,685
Speaker 2:  heartbeat. They would do it in one second if they could, and the First Amendment

331
00:18:59,685 --> 00:19:03,655
Speaker 2:  stands in their way. And that's for good

332
00:19:03,655 --> 00:19:07,055
Speaker 2:  reason. Right. You, you tend to believe that Americans have the best interest

333
00:19:07,055 --> 00:19:10,695
Speaker 2:  of America at at heart. And I don't even mean that in a directly

334
00:19:10,695 --> 00:19:14,455
Speaker 2:  patriotic way, I just mean like a do you want the place where you live to

335
00:19:14,455 --> 00:19:18,255
Speaker 2:  get bombed? Yeah. Very directly. Like Yeah.

336
00:19:18,255 --> 00:19:22,135
Speaker 2:  There's just a, a very individualistic impulse that is sort of at the

337
00:19:22,135 --> 00:19:22,535
Speaker 2:  heart of this.

338
00:19:24,295 --> 00:19:28,245
Speaker 2:  China is not that China is, is an adversary to this country. It

339
00:19:28,245 --> 00:19:31,885
Speaker 2:  would like to destabilize this country in some way if it could gain an advantage.

340
00:19:32,065 --> 00:19:35,805
Speaker 2:  It does it militarily. It does it economically. We do it to them.

341
00:19:35,985 --> 00:19:39,655
Speaker 2:  Yep. Straightforward. And I think

342
00:19:39,795 --> 00:19:43,695
Speaker 2:  TikTok users tend to believe that their individual

343
00:19:43,725 --> 00:19:47,495
Speaker 2:  experiences have no relation to that thing. Right. So I've watched

344
00:19:47,655 --> 00:19:51,055
Speaker 2:  a million TikTok videos from TikTokers who are outraged the top They're making

345
00:19:51,055 --> 00:19:53,815
Speaker 2:  the argument you're making. Yeah. Why, why would you regulate us when YouTube

346
00:19:53,815 --> 00:19:54,455
Speaker 2:  still exists? Or

347
00:19:54,815 --> 00:19:57,535
Speaker 6:  Medicines? I mean, I think they should all not exist. I think algorithm

348
00:19:58,075 --> 00:20:01,575
Speaker 6:  algorithmically driven social feeds or it ps on

349
00:20:01,875 --> 00:20:03,135
Speaker 6:  on our country. And and

350
00:20:03,245 --> 00:20:05,695
Speaker 2:  Anybody who's heard me talk knows that I agree with you.

351
00:20:05,695 --> 00:20:07,895
Speaker 6:  Yeah. Yeah. And so that's where I'm at with it.

352
00:20:08,575 --> 00:20:11,935
Speaker 2:  I I don't disagree. Yeah. Come directly to our website. It's The Verge dot

353
00:20:11,935 --> 00:20:14,535
Speaker 2:  com. You have an in a personal relationship with me on that website

354
00:20:15,815 --> 00:20:19,695
Speaker 2:  and then send us money. Sure. Why not? There should

355
00:20:19,695 --> 00:20:22,335
Speaker 2:  be, we make it very hard to send this money. We'll figure it out one day.

356
00:20:23,305 --> 00:20:24,415
Speaker 6:  Venmo NELI. Yeah.

357
00:20:25,525 --> 00:20:29,415
Speaker 2:  This is all just a pain to Cash app. Me. I will make dance videos for you,

358
00:20:29,965 --> 00:20:31,015
Speaker 2:  send me use Cash app.

359
00:20:32,875 --> 00:20:35,895
Speaker 2:  But what I'm getting at is just think about something as dumb as Stanley

360
00:20:36,045 --> 00:20:39,855
Speaker 2:  Cups. Stanley Cups are not a

361
00:20:40,165 --> 00:20:44,095
Speaker 2:  organic trend. Right? The algorithmic fed a bunch of people, a bunch of Stanley

362
00:20:44,195 --> 00:20:47,645
Speaker 2:  Cup content, and then more people were inspired to make Stanley Cup content

363
00:20:48,065 --> 00:20:51,805
Speaker 2:  and then the world around us generated an infinite

364
00:20:51,805 --> 00:20:54,925
Speaker 2:  supply of Stanley Cup explainers. So many of my friends car. And then that

365
00:20:54,925 --> 00:20:55,525
Speaker 2:  trend just died.

366
00:20:55,865 --> 00:20:58,805
Speaker 5:  You sound like somebody who like watched the great hack last night and is

367
00:20:58,805 --> 00:21:00,925
Speaker 5:  like, there's somebody at a button saying, it's Stanley. I

368
00:21:01,085 --> 00:21:02,165
Speaker 2:  I don't, there's somebody like, that's

369
00:21:02,165 --> 00:21:04,005
Speaker 5:  Not how it works. It's just not how it works.

370
00:21:04,145 --> 00:21:08,045
Speaker 2:  But that's not, that's not how Stanley Cup works. But why

371
00:21:08,045 --> 00:21:11,925
Speaker 2:  would you give a foreign power that capability inside the United States

372
00:21:12,225 --> 00:21:14,565
Speaker 2:  to even dream of having that button?

373
00:21:15,245 --> 00:21:18,965
Speaker 5:  A TikTok would tell you that it absolutely has not given China

374
00:21:19,035 --> 00:21:22,725
Speaker 5:  that power inside of the United States. B there's no evidence that it has.

375
00:21:23,315 --> 00:21:26,685
Speaker 2:  Well, look, I'm the, I'm the one who said the government should show us that

376
00:21:26,885 --> 00:21:30,845
Speaker 2:  evidence, but just abstractly. Why, why would you

377
00:21:30,845 --> 00:21:33,805
Speaker 2:  allow that to happen? Look, I'm gonna read to you the Communications Act

378
00:21:33,805 --> 00:21:37,685
Speaker 2:  of 1934. Foreign investors are limited to 20%

379
00:21:37,685 --> 00:21:40,845
Speaker 2:  direct ownership of companies holding a broadcasting license and

380
00:21:40,845 --> 00:21:44,645
Speaker 2:  25% ownership of a holding company. If, you have

381
00:21:44,925 --> 00:21:48,685
Speaker 2:  multiple broadcast licenses. Why did we think it was important to limit the

382
00:21:48,685 --> 00:21:52,525
Speaker 2:  ownership of the airwaves, the United States in 1934?

383
00:21:52,675 --> 00:21:55,685
Speaker 2:  Because we did not want foreign companies controlling what was broadcast

384
00:21:55,685 --> 00:21:59,005
Speaker 2:  to the majority of Americans. The impulse is exactly the same.

385
00:22:00,005 --> 00:22:02,405
Speaker 2:  I get it. The United States should probably

386
00:22:03,595 --> 00:22:07,125
Speaker 2:  explain why it's terrified of TikTok. I I really think this is a huge miss

387
00:22:07,125 --> 00:22:10,685
Speaker 2:  on a part of the government. And if they cannot, they should back the hell

388
00:22:10,685 --> 00:22:14,565
Speaker 2:  off. I agree. But I'm, I'm looking at okay,

389
00:22:14,565 --> 00:22:18,525
Speaker 2:  just on its face, is it a problem that

390
00:22:20,095 --> 00:22:23,955
Speaker 2:  so many Americans are buffeted by algorithms that we do not have

391
00:22:23,955 --> 00:22:27,595
Speaker 2:  any transparency into? And at least one of them, one very important one

392
00:22:27,985 --> 00:22:31,635
Speaker 2:  potentially has an enemy of the United States like

393
00:22:31,635 --> 00:22:34,955
Speaker 2:  controlling it and all that stands in between that is like

394
00:22:35,615 --> 00:22:39,555
Speaker 2:  Tim Cook. Tim Cook is like, iPhones are really important to everyone. Do

395
00:22:39,555 --> 00:22:43,355
Speaker 2:  not do the, do not do a war. Right. And like, that's what got us

396
00:22:43,355 --> 00:22:47,235
Speaker 2:  through the Trump trade war in a a real way. It's basically the

397
00:22:47,235 --> 00:22:51,195
Speaker 2:  idea of the modern global piece is that we'll all be so economically tied

398
00:22:51,195 --> 00:22:55,035
Speaker 2:  up with each other that war will be bad. I don't know, If, you looked around

399
00:22:55,435 --> 00:22:55,995
Speaker 2:  recently, like

400
00:22:57,515 --> 00:23:01,485
Speaker 2:  kind of shaky, like more shaky than it's been in

401
00:23:01,485 --> 00:23:04,285
Speaker 2:  a long time. And I would just point out like

402
00:23:05,345 --> 00:23:08,525
Speaker 2:  on either side, none of these cases are proven. TikTok saying we don't do

403
00:23:08,525 --> 00:23:11,995
Speaker 2:  it great. You gotta prove a negative, very difficult. Hui

404
00:23:11,995 --> 00:23:13,075
Speaker 6:  Also said that a lot and

405
00:23:13,695 --> 00:23:17,315
Speaker 2:  Hui said a lot and you know, most Western companies are like, we just don't

406
00:23:17,315 --> 00:23:21,235
Speaker 2:  want your hardware embedded in our networks. And I I, that to me always felt

407
00:23:21,235 --> 00:23:25,195
Speaker 2:  like very obvious. Like, don't put their hardware in your networks. That's

408
00:23:25,195 --> 00:23:28,675
Speaker 2:  where you get o ran from. By the way, this is like a whole thing. This, and

409
00:23:28,675 --> 00:23:32,395
Speaker 2:  this was what led to pro project Gen five assist. Look, I'm not saying you

410
00:23:32,395 --> 00:23:33,115
Speaker 2:  should ban air, you should

411
00:23:34,625 --> 00:23:37,275
Speaker 2:  keep the app stores from having it. I, I don't know.

412
00:23:37,415 --> 00:23:41,315
Speaker 6:  I'm sorry. I'm still thinking about how like Chinese trade war led to

413
00:23:41,315 --> 00:23:42,035
Speaker 6:  project Gen five

414
00:23:42,835 --> 00:23:44,155
Speaker 2:  Straight line. Oh, it absolutely

415
00:23:44,155 --> 00:23:47,005
Speaker 6:  Did. Yeah. I've seen the meme of the guy with like the

416
00:23:47,095 --> 00:23:50,525
Speaker 2:  Legos, but I'm saying If, you are a TikTok user and you're outraged because

417
00:23:50,525 --> 00:23:54,365
Speaker 2:  they're gonna do this. It's like, think about your experience on TikTok.

418
00:23:54,545 --> 00:23:58,405
Speaker 2:  You are being shown things that you are not in control of their sequence

419
00:23:58,665 --> 00:24:02,365
Speaker 2:  of their content. Like it just happens to you and the number of TikTok trends

420
00:24:02,365 --> 00:24:06,105
Speaker 2:  that come and go because people on the app

421
00:24:06,105 --> 00:24:09,225
Speaker 2:  decide to participate in them. And then our understanding of the culture

422
00:24:09,365 --> 00:24:13,095
Speaker 2:  around us is absolutely, it

423
00:24:13,415 --> 00:24:17,135
Speaker 2:  absolutely has the potential to be controlled by a foreign

424
00:24:17,135 --> 00:24:21,095
Speaker 2:  party. Okay. That I I don't think that

425
00:24:21,095 --> 00:24:24,295
Speaker 2:  that is the, I don't think the United States government has no business in

426
00:24:24,295 --> 00:24:27,015
Speaker 2:  paying attention to that. Should they lay out the evidence, the American

427
00:24:27,015 --> 00:24:30,015
Speaker 2:  people, that this is the only solu they, they should,

428
00:24:31,015 --> 00:24:34,835
Speaker 2:  is the evidence strong enough such that 50 Democrats and Republicans in a

429
00:24:34,835 --> 00:24:37,795
Speaker 2:  room saw it and walked out and voted unanimously?

430
00:24:38,495 --> 00:24:42,235
Speaker 2:  That's weird. That doesn't happen a lot anymore. Like

431
00:24:42,235 --> 00:24:42,875
Speaker 2:  it's just weird.

432
00:24:43,655 --> 00:24:47,635
Speaker 5:  No, it doesn't. but it is also true that the only two things anyone agrees

433
00:24:47,635 --> 00:24:51,115
Speaker 5:  on in politics right now are China is bad and we must protect the children

434
00:24:51,295 --> 00:24:55,275
Speaker 5:  on the internet. And If you want to gin up a 50 to zero vote,

435
00:24:55,295 --> 00:24:58,555
Speaker 5:  you would pick one of those two things. That's just what you would do. And,

436
00:24:58,555 --> 00:25:02,355
Speaker 5:  and on anything you're like, oh, we love kids. Right? Like 50

437
00:25:02,375 --> 00:25:05,915
Speaker 5:  to zero is pretty, it's not that hard to do on that front. Like this is just

438
00:25:05,915 --> 00:25:06,315
Speaker 5:  where we're

439
00:25:06,315 --> 00:25:09,995
Speaker 2:  At. Hey, I challenge you to go do it. It's even csa. Like

440
00:25:10,255 --> 00:25:13,355
Speaker 2:  csa the most we protect the kids is not passing right now.

441
00:25:14,045 --> 00:25:16,035
Speaker 2:  Right. The kids' online safety act is not

442
00:25:16,105 --> 00:25:19,995
Speaker 5:  Yeah. Because that involves actually doing things and, and Congress is

443
00:25:19,995 --> 00:25:23,915
Speaker 5:  not big on actually doing things. But wait, but like I I am, I'm still hung

444
00:25:23,915 --> 00:25:27,635
Speaker 5:  up on this thing where like, okay, Tencent a company that is also

445
00:25:27,635 --> 00:25:31,115
Speaker 5:  headquartered in China and has, I would say much clearer ties

446
00:25:31,655 --> 00:25:35,595
Speaker 5:  to the Chinese Communist Party than maybe not by

447
00:25:35,595 --> 00:25:39,475
Speaker 5:  dance, but certainly TikTok. And I think the like is is TikTok bite dance

448
00:25:39,475 --> 00:25:43,395
Speaker 5:  and is bite dance. TikTok is a very interesting and still sort of unanswered

449
00:25:43,635 --> 00:25:47,515
Speaker 5:  question in a lot of ways that we should probably talk about. But 10 10 owns,

450
00:25:48,035 --> 00:25:51,555
Speaker 5:  I think if not all, almost all of riot games, which makes League of Legends,

451
00:25:51,555 --> 00:25:54,955
Speaker 5:  which is very popular game, including in the United States. It owns a significant

452
00:25:54,955 --> 00:25:58,875
Speaker 5:  part of Epic which makes Fortnite. Can you convincingly

453
00:25:58,885 --> 00:26:02,435
Speaker 5:  prove to me that there is a better chance of me seeing Chinese

454
00:26:02,435 --> 00:26:04,795
Speaker 5:  propaganda on TikTok than in Fortnite?

455
00:26:05,615 --> 00:26:05,835
Speaker 2:  Yes.

456
00:26:06,535 --> 00:26:06,755
Speaker 5:  How?

457
00:26:07,195 --> 00:26:10,315
Speaker 2:  Fortnite doesn't have any news in it. Fortnite is not the main news source

458
00:26:10,375 --> 00:26:13,995
Speaker 2:  for millions of young Americans in the middle of an election year.

459
00:26:14,315 --> 00:26:18,235
Speaker 5:  I think, I mean, a, that assumes that millions of young Americans have a

460
00:26:18,235 --> 00:26:21,915
Speaker 5:  news source or give one solitary shit about the news. And I don't think that

461
00:26:21,915 --> 00:26:25,715
Speaker 5:  they do. And so, but like leaving that aside, there

462
00:26:25,715 --> 00:26:29,555
Speaker 5:  is potential Sure in the absolute worst case scenario

463
00:26:29,555 --> 00:26:33,365
Speaker 5:  that one can possibly imagine bad things can happen

464
00:26:33,365 --> 00:26:36,725
Speaker 5:  on TikTok. Granted, in the absolute worst case scenario,

465
00:26:37,375 --> 00:26:41,045
Speaker 5:  China already owns Yahoo News and we don't even know about it. Like

466
00:26:41,535 --> 00:26:45,045
Speaker 5:  we're, we're arguing about these like insane hypotheticals and we don't know

467
00:26:45,325 --> 00:26:49,085
Speaker 5:  anything and we're just mad at China. Like I I don't know how to make it

468
00:26:49,085 --> 00:26:50,005
Speaker 5:  less simple than that.

469
00:26:50,095 --> 00:26:53,765
Speaker 2:  Right. But I'm saying a majority of the members of the House of

470
00:26:53,765 --> 00:26:57,645
Speaker 2:  Representatives took a bunch of phone calls from their constituents and still

471
00:26:57,695 --> 00:27:01,525
Speaker 2:  voted to pass this bill because of whatever

472
00:27:01,645 --> 00:27:02,005
Speaker 2:  they saw.

473
00:27:02,225 --> 00:27:05,845
Speaker 5:  No disagree. They took a bunch of calls from their constituents and so as

474
00:27:05,925 --> 00:27:09,725
Speaker 5:  a result voted the, the overwhelming takeaway from

475
00:27:09,725 --> 00:27:13,605
Speaker 5:  members of Congress from this huge phone bank thing that TikTok has been

476
00:27:13,885 --> 00:27:17,565
Speaker 5:  encouraging users to do is, see this proves our point. TikTok can make young

477
00:27:17,565 --> 00:27:21,165
Speaker 5:  people do whatever they want, so we have to ban it. This thing has backfired

478
00:27:21,225 --> 00:27:24,845
Speaker 5:  so spectacularly on TikTok in the funniest possible way.

479
00:27:25,185 --> 00:27:25,405
Speaker 6:  It

480
00:27:25,405 --> 00:27:28,165
Speaker 5:  Was bad, it convinced young people to make phone calls and everybody was

481
00:27:28,165 --> 00:27:30,885
Speaker 5:  like, oh my God, they can make young people make phone calls. They can do

482
00:27:31,125 --> 00:27:31,245
Speaker 5:  anything.

483
00:27:32,415 --> 00:27:33,205
Speaker 2:  Right. But

484
00:27:33,465 --> 00:27:36,885
Speaker 5:  That's the only evidence of propaganda that we actually have from TikTok

485
00:27:37,025 --> 00:27:38,885
Speaker 5:  is that they can make people make phone calls.

486
00:27:39,205 --> 00:27:42,485
Speaker 2:  I wanna point out that is indeed very funny. Like it is very funny.

487
00:27:43,605 --> 00:27:46,245
Speaker 2:  I think mostly 'cause TikTok didn't think anything would happen like this

488
00:27:46,705 --> 00:27:50,685
Speaker 2:  and then they overplayed their hand. Yes. Weird. But the idea

489
00:27:50,875 --> 00:27:53,765
Speaker 2:  that you can get a bunch of young people to take political action

490
00:27:54,665 --> 00:27:57,605
Speaker 2:  in service of a company that is owned by the Chinese government

491
00:27:58,265 --> 00:28:01,885
Speaker 2:  should not feel like a backfire when people are like, well that's bad.

492
00:28:02,105 --> 00:28:05,125
Speaker 5:  You can't just say a service run by the Chinese government. Like it's a thing

493
00:28:05,125 --> 00:28:08,565
Speaker 5:  that we know. You just, you just said that so nonchalantly

494
00:28:09,025 --> 00:28:11,565
Speaker 2:  But by chance of the Chinese company has Chinese government not supported.

495
00:28:11,565 --> 00:28:12,765
Speaker 2:  Right. It is just true. Like

496
00:28:14,405 --> 00:28:17,405
Speaker 2:  companies in China are structured differently than the companies here and

497
00:28:17,405 --> 00:28:20,845
Speaker 2:  the state interests are much stronger for those companies. And if they don't

498
00:28:20,845 --> 00:28:24,565
Speaker 2:  like you, they just make you go away. Which is a thing that happens

499
00:28:24,665 --> 00:28:25,525
Speaker 2:  to Chinese companies.

500
00:28:25,555 --> 00:28:26,645
Speaker 6:  Poor fun binging. That's

501
00:28:26,645 --> 00:28:26,725
Speaker 5:  True.

502
00:28:26,875 --> 00:28:30,005
Speaker 2:  Yeah. Right. Like Jack Ma like where'd that guy go? He just disappeared.

503
00:28:30,755 --> 00:28:34,525
Speaker 2:  Like, that's weird. Like that is a different, like a, a

504
00:28:34,525 --> 00:28:37,685
Speaker 2:  crucial difference between United States government and Chinese government.

505
00:28:37,685 --> 00:28:39,445
Speaker 2:  Chinese government is a brutal dictatorship.

506
00:28:40,325 --> 00:28:43,415
Speaker 6:  Yeah. I mean this is, this is the, this is the thing we, we saw with Huawei

507
00:28:43,415 --> 00:28:47,215
Speaker 6:  and, and we're seeing again in, in this case that I think isn't always entirely

508
00:28:47,245 --> 00:28:50,615
Speaker 6:  articulated because racism gets in the way and xenophobia gets in the way,

509
00:28:50,705 --> 00:28:51,495
Speaker 6:  which is that like

510
00:28:53,235 --> 00:28:57,085
Speaker 6:  this, the problem isn't that it's China and China bad because that that's

511
00:28:57,085 --> 00:29:00,765
Speaker 6:  just racism xenophobic. The problem is that the Chinese Communist Party,

512
00:29:00,765 --> 00:29:04,445
Speaker 6:  the CCP has a very capable way

513
00:29:04,705 --> 00:29:08,445
Speaker 6:  of making businesses that are in China, do what they want

514
00:29:08,825 --> 00:29:12,045
Speaker 6:  and they can exert influence and they will exert influence and they have

515
00:29:12,115 --> 00:29:15,885
Speaker 6:  exerted influence. And in tiktoks case, TikTok has gone again

516
00:29:15,985 --> 00:29:19,765
Speaker 6:  and again and again and said they do not do that. We are not based there.

517
00:29:19,785 --> 00:29:23,285
Speaker 6:  We, we, we, we work really, really hard to not have that

518
00:29:23,285 --> 00:29:27,045
Speaker 6:  relationship. And effectively the United States government has said, we

519
00:29:27,255 --> 00:29:28,445
Speaker 6:  don't believe you. Right.

520
00:29:28,445 --> 00:29:32,005
Speaker 2:  Because you made up Project Texas. Yeah. And then when the chips are down,

521
00:29:33,225 --> 00:29:37,005
Speaker 2:  no one is talking about Project Texas. Yep. They, they made up

522
00:29:37,005 --> 00:29:40,815
Speaker 2:  this fake thing, which is like Oracle host the data

523
00:29:40,875 --> 00:29:43,925
Speaker 2:  and there's a, we wrote about it, Alex Heath wrote about it. He visited the

524
00:29:43,925 --> 00:29:47,685
Speaker 2:  Algorithmic Transparency Center, which is basically a children's museum for

525
00:29:47,685 --> 00:29:51,125
Speaker 2:  content moderation where you stand in front of a giant TikTok screen and

526
00:29:51,125 --> 00:29:54,965
Speaker 2:  you're like, ban this, don't ban. And then behind that is like a

527
00:29:54,965 --> 00:29:58,245
Speaker 2:  wall with a data center behind it that you can gaze upon and you're like,

528
00:29:58,245 --> 00:30:01,805
Speaker 2:  look at the data. It's here in the United States. And none of that has anything

529
00:30:01,805 --> 00:30:03,925
Speaker 2:  to do with anything as, as near as we can tell.

530
00:30:04,375 --> 00:30:08,285
Speaker 6:  Right? Yeah. I I think, I think TikTok is always, it, it's always

531
00:30:08,285 --> 00:30:12,045
Speaker 6:  gonna face this battle because unfortunately it is owned by a company

532
00:30:12,835 --> 00:30:16,405
Speaker 6:  that does, is based in China and therefore cannot

533
00:30:16,535 --> 00:30:20,525
Speaker 6:  fully say we are totally independent company like by dance can just not do

534
00:30:20,525 --> 00:30:24,285
Speaker 6:  that. It never can. It never will. As long as the CCP is is staying in its

535
00:30:24,285 --> 00:30:28,165
Speaker 6:  current like regime. And, and so TikTok is always gonna face that

536
00:30:28,265 --> 00:30:30,805
Speaker 6:  and they have, they've really struggled to, to

537
00:30:32,125 --> 00:30:35,845
Speaker 6:  convince the, the government at every turn they've struggled. And part of

538
00:30:35,845 --> 00:30:39,685
Speaker 6:  that is definitely the xenophobia and, and and, and the racism, which

539
00:30:39,685 --> 00:30:43,005
Speaker 6:  is just like completely out of pocket and horrible. Yes.

540
00:30:43,375 --> 00:30:43,725
Speaker 6:  Every

541
00:30:43,725 --> 00:30:44,725
Speaker 2:  Single time. I fully agree there.

542
00:30:45,565 --> 00:30:49,245
Speaker 6:  Horrible. And I just, I don't know that TikTok can ever say

543
00:30:49,525 --> 00:30:53,045
Speaker 6:  anything that is going to make them believe them. Like even if they, if

544
00:30:53,235 --> 00:30:56,405
Speaker 6:  even if Project Texas wasn't so stupidly,

545
00:30:56,515 --> 00:31:00,365
Speaker 6:  transparently like TikTok propaganda to say like us,

546
00:31:01,125 --> 00:31:04,885
Speaker 6:  I don't know what they could do to make the United States government like

547
00:31:04,885 --> 00:31:05,565
Speaker 6:  them. Yeah.

548
00:31:06,065 --> 00:31:09,245
Speaker 2:  Can I say something? Can they do vastly more esoteric and philosophical just

549
00:31:09,245 --> 00:31:10,885
Speaker 2:  to turn this Yeah, yeah, yeah. Somewhere else

550
00:31:12,705 --> 00:31:16,365
Speaker 2:  as I've gotten older, I've realized the thing that the internet does is make

551
00:31:16,565 --> 00:31:19,245
Speaker 2:  everyone believe that collective action problems do not exist,

552
00:31:20,585 --> 00:31:24,015
Speaker 2:  which is If you If you just take that idea and apply it to whatever your

553
00:31:24,015 --> 00:31:26,775
Speaker 2:  political leanings are. You'll quickly realize like this is your primary

554
00:31:27,135 --> 00:31:30,535
Speaker 2:  frustration with other people. It's like some problems are easier to solve

555
00:31:31,035 --> 00:31:34,995
Speaker 2:  if we all do them together, but getting everyone to do everything

556
00:31:34,995 --> 00:31:38,675
Speaker 2:  at the same time is like a political nightmare. Yeah. And that's just life.

557
00:31:38,695 --> 00:31:41,635
Speaker 2:  That's, that's the history of politics. Do collective action problems exist

558
00:31:41,635 --> 00:31:45,435
Speaker 2:  or not? Is it, if I'm like the market will

559
00:31:45,435 --> 00:31:49,035
Speaker 2:  provide fighter jets, it won't unless we all pay our taxes and the government

560
00:31:49,035 --> 00:31:51,395
Speaker 2:  buy fighter jets and we need it. We think we should have fighter jets for

561
00:31:51,435 --> 00:31:55,355
Speaker 2:  X, y and Z reason. And you personally might disagree with those reasons

562
00:31:55,735 --> 00:31:58,955
Speaker 2:  and you personally might sue the government of the United States and say,

563
00:31:59,035 --> 00:32:02,235
Speaker 2:  I do not want my taxes to pay for fighter jets, which is a real thing that

564
00:32:02,235 --> 00:32:05,155
Speaker 2:  happens on the regular and the United States government says, no, you don't

565
00:32:05,155 --> 00:32:08,795
Speaker 2:  get a choice because of collective act like we have to do this thing together.

566
00:32:09,055 --> 00:32:12,835
Speaker 2:  And you might think to yourself, boy, I wish we would pull our taxes and

567
00:32:12,835 --> 00:32:15,435
Speaker 2:  pay for healthcare. I very strongly believe we should pull our taxes and

568
00:32:15,435 --> 00:32:18,515
Speaker 2:  pay for healthcare for people or better education or whatever it is that

569
00:32:18,515 --> 00:32:21,555
Speaker 2:  you think would be better if we all paid a little bit. And we all got a lot.

570
00:32:21,555 --> 00:32:25,275
Speaker 2:  Right. This is like the main thing and what is happening in this TikTok

571
00:32:25,635 --> 00:32:28,675
Speaker 2:  situation is TikTok is a collective action problem.

572
00:32:30,055 --> 00:32:33,795
Speaker 2:  Our government believes the security of the United States is threatened by

573
00:32:33,795 --> 00:32:36,955
Speaker 2:  the existence of TikTok in some way. Our government says that

574
00:32:37,575 --> 00:32:41,205
Speaker 2:  it believes it, it's taking the, the votes that it, it indicate its belief

575
00:32:41,205 --> 00:32:42,205
Speaker 2:  in that problem. Sure.

576
00:32:42,485 --> 00:32:46,125
Speaker 5:  I would remind you that you're the same NELI Patel who believes most of the

577
00:32:46,125 --> 00:32:49,165
Speaker 5:  things that Congress does are like deeply disingenuous and not at all about

578
00:32:49,165 --> 00:32:50,365
Speaker 5:  the thing that they say that they're about.

579
00:32:50,685 --> 00:32:52,925
Speaker 2:  I, I cannot believe I'm the one making this case. I'm, I

580
00:32:52,925 --> 00:32:53,565
Speaker 5:  Can't either. I'm just,

581
00:32:53,565 --> 00:32:54,965
Speaker 2:  I'm like, I'm this now I'm losing

582
00:32:54,965 --> 00:32:55,485
Speaker 5:  My mind. Right now

583
00:32:55,885 --> 00:32:59,405
Speaker 2:  I have never, I just, the the 50 to o vote, I think just really

584
00:32:59,435 --> 00:33:01,925
Speaker 2:  there's something about that. Like they saw the evidence, they walked out,

585
00:33:01,925 --> 00:33:03,005
Speaker 2:  they all did the same thing at Sometimes. I

586
00:33:03,005 --> 00:33:05,645
Speaker 5:  Do agree that that is the single most compelling piece of evidence.

587
00:33:05,645 --> 00:33:08,685
Speaker 2:  I've just got evidence circled in my brain. Whatever happened there is a

588
00:33:08,685 --> 00:33:12,285
Speaker 2:  big deal. I don't know what it is. And that is the problem. Yep. To

589
00:33:12,645 --> 00:33:16,605
Speaker 2:  overcome the collective action problem they have, which is they're going

590
00:33:16,605 --> 00:33:20,485
Speaker 2:  to make a bunch of individuals feel bad. Yep. A

591
00:33:20,485 --> 00:33:23,405
Speaker 2:  bunch of individual businesses will lose their marketing channel. A bunch

592
00:33:23,405 --> 00:33:27,125
Speaker 2:  of individual creators will lose their livelihoods. A bunch of

593
00:33:27,125 --> 00:33:31,005
Speaker 2:  individual people will lose their ability to just see trucks jump over

594
00:33:31,005 --> 00:33:34,805
Speaker 2:  shit on command. This will hurt me personally to overcome

595
00:33:35,025 --> 00:33:38,645
Speaker 2:  the collective action problem. They have to lay out the case. but it is

596
00:33:38,695 --> 00:33:41,965
Speaker 2:  clear that they think if we all endure that pain

597
00:33:42,525 --> 00:33:46,485
Speaker 2:  collectively we will get some benefit. And the benefit will be freedom

598
00:33:46,515 --> 00:33:49,925
Speaker 2:  from Chinese interference in our media. I don't like that's the case.

599
00:33:51,175 --> 00:33:54,195
Speaker 2:  And when you take that and you're like, now I'll make the same case against

600
00:33:54,595 --> 00:33:58,395
Speaker 2:  Facebook or the same case against YouTube, I would point out to you the

601
00:33:58,395 --> 00:34:02,275
Speaker 2:  government has been trying to make that case. They haul these

602
00:34:02,545 --> 00:34:06,035
Speaker 2:  CEOs in front of the government and say, why are your algorithms bad?

603
00:34:06,935 --> 00:34:10,595
Speaker 2:  And the CEOs are like, yeah, I don't know. First Amendment

604
00:34:10,735 --> 00:34:14,595
Speaker 2:  go away. Like they cannot overcome that. They have yet to come up with an

605
00:34:14,795 --> 00:34:18,195
Speaker 2:  argument that is strong enough to overpower the First amendment and solve

606
00:34:18,195 --> 00:34:21,315
Speaker 2:  that collective action problem. They have not yet figured it out. The closest

607
00:34:21,315 --> 00:34:25,195
Speaker 2:  they've come is the kids stuff. That's why you have a kids'

608
00:34:25,195 --> 00:34:28,035
Speaker 2:  online safety act. The closest they've come is sex trafficking. That's why

609
00:34:28,035 --> 00:34:31,115
Speaker 2:  you get fossa and Cesta is carve outs to two 30.

610
00:34:32,175 --> 00:34:35,835
Speaker 2:  That's it. The closest actually the the, the farthest they've gone

611
00:34:36,015 --> 00:34:39,755
Speaker 2:  is copyright law. Right. Like that's why Disney

612
00:34:39,865 --> 00:34:43,395
Speaker 2:  gets to take stuff down off the internet. 'cause we've decided as collectively

613
00:34:43,395 --> 00:34:46,915
Speaker 2:  that's fine. And most people don't argue with that. In this case,

614
00:34:47,305 --> 00:34:51,075
Speaker 2:  they have a different thing that they can't wield against the

615
00:34:51,235 --> 00:34:54,275
Speaker 2:  Facebooks and the, and the YouTubes of the world, which is like national

616
00:34:54,555 --> 00:34:58,325
Speaker 2:  security and they have to make the case. And I, they've had one

617
00:34:58,325 --> 00:35:02,245
Speaker 2:  kind of sham hearing where they just asked like, that's your xenophobia.

618
00:35:02,245 --> 00:35:04,205
Speaker 2:  Yeah, yeah, yeah. Where they just like, we're like, are you Singaporean?

619
00:35:04,205 --> 00:35:08,125
Speaker 2:  He's like, I am Singapore. Yeah. They're like, that doesn't work. They

620
00:35:08,125 --> 00:35:09,645
Speaker 2:  asked the dude if TikTok uses wifi.

621
00:35:11,625 --> 00:35:15,345
Speaker 2:  Truly a horrible theory like that isn't the case. But

622
00:35:15,445 --> 00:35:19,345
Speaker 2:  the some case was made to these people where they are

623
00:35:19,345 --> 00:35:22,945
Speaker 2:  willing to take the representative democracy hit

624
00:35:23,195 --> 00:35:26,985
Speaker 2:  right where their own constituents are calling them and they're interpreting

625
00:35:26,985 --> 00:35:30,755
Speaker 2:  that as this is the problem and I'm gonna vote against what my constituents

626
00:35:30,775 --> 00:35:34,155
Speaker 2:  are saying to me. Can I put on that? That happens in like very rarely.

627
00:35:34,715 --> 00:35:34,835
Speaker 2:  I

628
00:35:34,835 --> 00:35:38,805
Speaker 5:  Think you might be underwriting the extent to which it's

629
00:35:38,805 --> 00:35:40,845
Speaker 5:  a political win to be mad at China right now.

630
00:35:41,105 --> 00:35:44,765
Speaker 2:  No, wait, I disagree. I think banning TikTok is a political loser for everyone.

631
00:35:44,765 --> 00:35:47,965
Speaker 2:  Which is why Donald Trump is out there being like, no, I'll, I'll, I'll keep

632
00:35:47,965 --> 00:35:49,805
Speaker 2:  TikTok kids vote for me. Donald Trump.

633
00:35:49,835 --> 00:35:53,565
Speaker 5:  Yeah. Oh, I totally agree with that. But there, there is a, a subset of people

634
00:35:54,265 --> 00:35:57,885
Speaker 5:  who are older and don't use TikTok

635
00:35:58,385 --> 00:36:02,365
Speaker 5:  and hate China, which is a lot of people in America who

636
00:36:02,365 --> 00:36:06,045
Speaker 5:  are gonna be psyched about this. And so it's like, there there are

637
00:36:06,585 --> 00:36:09,805
Speaker 5:  the, if if you're just taking this as like pure political calculus and like,

638
00:36:09,805 --> 00:36:11,845
Speaker 5:  this is not the thing we should get hung up on, but If you're taking this

639
00:36:11,845 --> 00:36:15,525
Speaker 5:  just pure political calculus. The TikTok users aren't gonna vote

640
00:36:15,945 --> 00:36:19,925
Speaker 5:  anyway. The old people who hate China. Oh God. They love voting.

641
00:36:20,235 --> 00:36:22,845
Speaker 5:  Like that's, and this is the thing that I

642
00:36:23,625 --> 00:36:26,725
Speaker 2:  Can I, can I offer you one thing? This is Unsourced, it's half-assed.

643
00:36:27,575 --> 00:36:31,475
Speaker 2:  I'm sorry. I definitely heard at Southwest Southwest that a significant number

644
00:36:31,475 --> 00:36:34,875
Speaker 2:  of people making the phone calls were boomers who spend all day on TikTok.

645
00:36:34,895 --> 00:36:35,115
Speaker 2:  Oh,

646
00:36:35,115 --> 00:36:37,515
Speaker 6:  The Boomers love TikTok. I I say that because I

647
00:36:37,745 --> 00:36:40,955
Speaker 2:  They got nothing to, they got nothing to do. They're all retired Yeah. Sitting

648
00:36:40,955 --> 00:36:42,955
Speaker 2:  on their bags of money that they have yet to pass on. I

649
00:36:42,995 --> 00:36:45,275
Speaker 6:  I wanna point out, I think you guys are both focused really a lot on the,

650
00:36:45,275 --> 00:36:47,755
Speaker 6:  the political side of this and, and not on the economic side of this. Yeah.

651
00:36:47,755 --> 00:36:51,315
Speaker 6:  Which is TikTok goes away suddenly all those

652
00:36:51,635 --> 00:36:55,355
Speaker 6:  American companies that are, are largely dominant in the social media space

653
00:36:55,815 --> 00:36:59,235
Speaker 6:  across the world. Right. Like, you know, like you Mo I think I was reading

654
00:36:59,245 --> 00:37:02,755
Speaker 6:  today that an enormous portion of the the famous people

655
00:37:03,295 --> 00:37:06,835
Speaker 6:  on social media are, are based in America. 'cause they use American apps

656
00:37:06,835 --> 00:37:09,595
Speaker 6:  like Yeah. YouTube and, and Instagram.

657
00:37:10,495 --> 00:37:14,315
Speaker 6:  TikTok goes away. YouTube and Instagram immediately get more users. Like

658
00:37:14,315 --> 00:37:17,995
Speaker 6:  there is real economic incentive to get rid of TikTok because

659
00:37:18,065 --> 00:37:20,555
Speaker 6:  that puts money back into American companies. But they

660
00:37:20,555 --> 00:37:21,475
Speaker 2:  Could sell it,

661
00:37:21,595 --> 00:37:25,475
Speaker 6:  I think. And I think this is also part of like the lobbying that is

662
00:37:25,475 --> 00:37:29,315
Speaker 6:  happening here. Like, like we're seeing, oh, they went and they, they all

663
00:37:29,315 --> 00:37:33,115
Speaker 6:  got convinced in, in some hearing that we didn't all weren't privy to, but

664
00:37:33,115 --> 00:37:36,875
Speaker 6:  they were also getting convinced by lobbyists from, from Meta and lobbyists,

665
00:37:37,145 --> 00:37:40,555
Speaker 6:  from from Google saying, yeah, you wanna get rid of our com

666
00:37:40,555 --> 00:37:44,275
Speaker 6:  competition, go for it. And, and we, we can

667
00:37:44,295 --> 00:37:48,245
Speaker 6:  ignore that like the the economic part component of

668
00:37:48,245 --> 00:37:50,125
Speaker 6:  this thing because it's huge.

669
00:37:50,465 --> 00:37:54,365
Speaker 5:  Oh, I totally agree. And all these companies have had a big stock bump in

670
00:37:54,365 --> 00:37:58,285
Speaker 5:  the last week since this started to happen. Like Snap is sitting there being

671
00:37:58,285 --> 00:38:01,405
Speaker 5:  like, please, dear God man, TikTok, some people will come use Snap Discover

672
00:38:01,465 --> 00:38:01,685
Speaker 5:  if

673
00:38:01,685 --> 00:38:05,565
Speaker 2:  Snap was smart, they would buy it. That's what I'm saying. Like maybe

674
00:38:05,685 --> 00:38:09,565
Speaker 2:  it go away. Yeah. But maybe Steve Mnuchin will put together

675
00:38:09,585 --> 00:38:13,125
Speaker 2:  his band of investors and buy it. Who is the other name that got floated?

676
00:38:13,125 --> 00:38:14,285
Speaker 6:  Bobby caught it. Bobby

677
00:38:14,685 --> 00:38:14,885
Speaker 2:  Ick.

678
00:38:14,915 --> 00:38:16,445
Speaker 6:  Yeah. Activision's Back baby.

679
00:38:17,035 --> 00:38:19,605
Speaker 2:  When I, when I think about responsible media ownership in the United States,

680
00:38:19,905 --> 00:38:20,125
Speaker 2:  the

681
00:38:20,125 --> 00:38:24,085
Speaker 5:  Way that Choosy two, the CEO of TikTok has talked about it, it that seems

682
00:38:24,085 --> 00:38:27,565
Speaker 5:  like a total non-starter. Like I, I don't think there's any world in which

683
00:38:28,635 --> 00:38:30,095
Speaker 5:  TikTok sells. He

684
00:38:30,095 --> 00:38:30,695
Speaker 2:  Has to say that.

685
00:38:30,995 --> 00:38:34,695
Speaker 5:  But also the, like, who literally who could afford it?

686
00:38:34,725 --> 00:38:38,085
Speaker 5:  Like this is, this is probably a several hundred billion dollars company.

687
00:38:38,845 --> 00:38:40,525
Speaker 6:  Microsoft's back at it.

688
00:38:40,745 --> 00:38:44,485
Speaker 5:  You can't sell to any of the big companies for antitrust reasons.

689
00:38:46,185 --> 00:38:50,125
Speaker 5:  Who else has the money? Snapchat doesn't have Mon, literally TikTok could

690
00:38:50,125 --> 00:38:51,565
Speaker 5:  buy Snapchat. I

691
00:38:51,565 --> 00:38:55,405
Speaker 2:  Don't know man. Elon put together 44 billion for

692
00:38:55,515 --> 00:38:56,005
Speaker 2:  Twitter.

693
00:38:56,705 --> 00:38:59,925
Speaker 5:  You think? Okay, Elon If. you buy TikTok and take it private

694
00:39:00,745 --> 00:39:04,485
Speaker 5:  and rebrand TikTok as X videos. Now we're onto something.

695
00:39:05,365 --> 00:39:08,685
Speaker 2:  I I understand it's a huge number. I just think that the

696
00:39:08,805 --> 00:39:11,375
Speaker 2:  opportunity for a bunch of investors to

697
00:39:12,905 --> 00:39:16,165
Speaker 2:  get that company and that advertising revenue and that influence,

698
00:39:17,515 --> 00:39:20,885
Speaker 2:  it's not such a big number for the thing that it is.

699
00:39:21,785 --> 00:39:22,285
Speaker 2:  Yes. It's a

700
00:39:22,285 --> 00:39:23,205
Speaker 5:  Very big number. It's pretty big number.

701
00:39:23,435 --> 00:39:26,075
Speaker 2:  Well, we don't know what the number is, but

702
00:39:26,185 --> 00:39:27,995
Speaker 5:  Also that's the unknown. You're not okay with,

703
00:39:28,395 --> 00:39:31,715
Speaker 2:  I just, I just think from, you're not gonna be like, we're open to a sale

704
00:39:31,765 --> 00:39:34,155
Speaker 2:  while you're still trying to fend off the bill that would force you to sell

705
00:39:34,155 --> 00:39:34,675
Speaker 2:  it. Sure.

706
00:39:34,775 --> 00:39:35,195
Speaker 5:  Agreed.

707
00:39:35,535 --> 00:39:39,035
Speaker 2:  And at some point there becomes a number. Like everything has a number. It's

708
00:39:39,035 --> 00:39:41,845
Speaker 2:  a business. Yeah. Capitalism baby. Welcome to America.

709
00:39:42,085 --> 00:39:45,845
Speaker 5:  I mean, and it is true that like we got a ways down this road

710
00:39:45,865 --> 00:39:49,845
Speaker 5:  in 2020 based on an executive order that pretty much everybody

711
00:39:49,845 --> 00:39:53,765
Speaker 5:  thought had no chance of holding up in court. And like that's

712
00:39:53,805 --> 00:39:56,965
Speaker 5:  I think the thing that is different now. I think there, there is a real sense

713
00:39:56,965 --> 00:40:00,685
Speaker 5:  that this is a thing that could happen and could stick. And so to the

714
00:40:00,685 --> 00:40:04,365
Speaker 5:  extent that, you know, Oracle talked about it and Microsoft talked about

715
00:40:04,365 --> 00:40:08,045
Speaker 5:  it and there were all of these weird machinations going on. I think everybody

716
00:40:08,235 --> 00:40:12,085
Speaker 5:  kind of knew it was probably nothing. but it seems to be

717
00:40:12,835 --> 00:40:16,645
Speaker 5:  much more likely to be something. And so we might get a real price tag

718
00:40:16,785 --> 00:40:18,085
Speaker 5:  at some point here in The future.

719
00:40:18,555 --> 00:40:21,605
Speaker 2:  Look, all I'm saying, I'm, I don't, I don't think it will end up getting

720
00:40:21,865 --> 00:40:23,325
Speaker 2:  banned. I think it will end up getting sold.

721
00:40:23,545 --> 00:40:25,285
Speaker 5:  Oh, I think the opposite. That's so fun. But

722
00:40:25,375 --> 00:40:28,285
Speaker 2:  We'll see. I don't know. Yeah, that's a good, that's a good prop bet.

723
00:40:28,645 --> 00:40:32,445
Speaker 6:  I think nothing will happen. I think Rand Paul, a few other senators,

724
00:40:32,515 --> 00:40:35,645
Speaker 6:  I'll kill it because they can kill it. Right? Like, like you do need, it

725
00:40:35,645 --> 00:40:39,445
Speaker 6:  was what 60 Senators have to all agree and Oh boy.

726
00:40:39,515 --> 00:40:39,805
Speaker 6:  Yeah.

727
00:40:39,925 --> 00:40:42,885
Speaker 5:  I, I'm I'm with you. I think the massive like

728
00:40:43,435 --> 00:40:46,885
Speaker 5:  betting favorite is nothing. We never hear from this bill again.

729
00:40:47,235 --> 00:40:51,125
Speaker 2:  Yeah, I fair enough. But I will say there are, and I have

730
00:40:51,165 --> 00:40:55,045
Speaker 2:  a long history of producing work about the First

731
00:40:55,045 --> 00:40:55,565
Speaker 2:  Amendment. You can go,

732
00:40:55,865 --> 00:40:57,965
Speaker 5:  You're throwing it all away in one verse cast.

733
00:40:58,305 --> 00:41:01,285
Speaker 2:  You can definitely go to it. I feel very strongly about the First Amendment.

734
00:41:01,575 --> 00:41:05,325
Speaker 2:  There are a tiny handful of things that overcome the First

735
00:41:05,325 --> 00:41:08,845
Speaker 2:  Amendment copyright law. As you may be aware,

736
00:41:09,295 --> 00:41:10,725
Speaker 2:  based on my long body of work,

737
00:41:12,365 --> 00:41:15,125
Speaker 2:  national security is one of those things. Foreign ownership of United States

738
00:41:15,125 --> 00:41:19,045
Speaker 2:  media is historically one of those things. And I think that's gotten lost

739
00:41:19,545 --> 00:41:22,325
Speaker 2:  in all this con this is why I'm so focused on like how mechanics of how the

740
00:41:22,325 --> 00:41:26,045
Speaker 2:  bill actually works. Yeah. Because that thing is actually

741
00:41:26,045 --> 00:41:29,365
Speaker 2:  important. Even If, you, even If you believe they're not using it now. Should

742
00:41:29,365 --> 00:41:33,165
Speaker 2:  they have that capability has traditionally been so big of a deal

743
00:41:33,165 --> 00:41:35,485
Speaker 2:  that we've stopped it before it could even happen. And in this case, we just

744
00:41:35,485 --> 00:41:37,285
Speaker 2:  let it slide 'cause it's an app with dancing kids on it.

745
00:41:37,715 --> 00:41:41,565
Speaker 5:  Yeah. I I mean, and if If you believe that there

746
00:41:41,565 --> 00:41:45,005
Speaker 5:  is a nefarious thing happening here that is the true genius of TikTok, right?

747
00:41:45,005 --> 00:41:48,965
Speaker 5:  That like, like the, the Galaxy brain thing you hear is like all the kids

748
00:41:48,965 --> 00:41:52,485
Speaker 5:  in China are seeing on Deion, which is like the Chinese version of TikTok.

749
00:41:52,515 --> 00:41:56,005
Speaker 5:  They're seeing like stem and how to build robots and code and all this stuff.

750
00:41:56,005 --> 00:41:58,365
Speaker 5:  And we're just seeing dance challenges because it's making us all stupid

751
00:41:58,425 --> 00:42:01,965
Speaker 5:  and slow. And this is like a long con plan to make the Chinese kids smarter

752
00:42:01,965 --> 00:42:05,845
Speaker 5:  than the American kids. Which like if true, incredible. Like

753
00:42:06,035 --> 00:42:07,085
Speaker 5:  well played everybody,

754
00:42:07,785 --> 00:42:08,805
Speaker 6:  My favorite concern,

755
00:42:08,805 --> 00:42:12,285
Speaker 2:  That's why they added the STEM tab to TikTok by the way. I know like this.

756
00:42:12,745 --> 00:42:15,885
Speaker 2:  And I just wanna point out, it's right behind shopping. First it's shopping,

757
00:42:16,715 --> 00:42:19,845
Speaker 2:  then it's stem like, but I think

758
00:42:20,745 --> 00:42:23,285
Speaker 5:  The one thing I'm hung up on, like just, I I agree with you about the 50

759
00:42:23,285 --> 00:42:27,245
Speaker 5:  to zero thing. And I think the idea that there is a smoking

760
00:42:27,545 --> 00:42:30,845
Speaker 5:  gun is very possible. And I'm so willing to be convinced

761
00:42:31,385 --> 00:42:35,005
Speaker 5:  by Yeah. Any shred of evidence that says this is

762
00:42:35,005 --> 00:42:38,485
Speaker 5:  happening. There are plans to make it happen. There is capability to do it

763
00:42:38,485 --> 00:42:42,285
Speaker 5:  quickly. Like whatever. The flip side of it for me is,

764
00:42:42,285 --> 00:42:46,245
Speaker 5:  we've been at this for four years now and we've never heard it. And

765
00:42:46,245 --> 00:42:49,925
Speaker 5:  there are so, so many people with incentive

766
00:42:50,025 --> 00:42:53,325
Speaker 5:  to talk about this publicly. Like so many people.

767
00:42:54,315 --> 00:42:55,885
Speaker 2:  Yeah, but why won't they? Well,

768
00:42:56,165 --> 00:42:57,645
Speaker 6:  I don't know. They get it.

769
00:42:57,985 --> 00:43:00,685
Speaker 2:  We won't talk. Have you met politicians? They they usually talk about it.

770
00:43:00,885 --> 00:43:01,045
Speaker 2:  This

771
00:43:01,045 --> 00:43:03,725
Speaker 5:  Is what I'm saying. So either it is something so

772
00:43:04,695 --> 00:43:08,685
Speaker 5:  grave and incredible that we can't be trust. It's like, it's like some alien

773
00:43:08,835 --> 00:43:12,085
Speaker 5:  shit where like, we can't know or else it would destroy our way of life

774
00:43:12,785 --> 00:43:15,645
Speaker 5:  way. Or there's nothing to talk about. Like I, I don't know how to think.

775
00:43:15,645 --> 00:43:16,605
Speaker 5:  It's not one of those people

776
00:43:16,605 --> 00:43:19,485
Speaker 2:  Usually when there's nothing they make shit up. I just historically with

777
00:43:19,485 --> 00:43:22,125
Speaker 2:  politicians, usually when there's, then there's nothing. you know, it's like

778
00:43:22,855 --> 00:43:25,865
Speaker 2:  they pull off the sheet and the Scooby-Doo kids are like, it was bullshit

779
00:43:25,865 --> 00:43:29,145
Speaker 2:  all along. Like, you know, like that's his,

780
00:43:29,865 --> 00:43:32,545
Speaker 2:  I dunno, maybe that's it. Maybe I'm just over indexing on 50 to zero and

781
00:43:32,545 --> 00:43:35,985
Speaker 2:  the fact that so many of them were convinced by this campaign and

782
00:43:36,175 --> 00:43:38,745
Speaker 2:  there's something there that they won't say, what

783
00:43:38,745 --> 00:43:41,345
Speaker 6:  If this is all viral marketing for three body problems.

784
00:43:41,935 --> 00:43:43,265
Speaker 2:  Very good. Netflix

785
00:43:43,535 --> 00:43:47,345
Speaker 6:  Just really going for it this year. Yeah. We could see Who knows.

786
00:43:48,105 --> 00:43:51,625
Speaker 2:  Look, I I think I've been convinced through the course of the conversation

787
00:43:51,625 --> 00:43:53,585
Speaker 2:  that most likely outcome is nothing. Yeah,

788
00:43:54,695 --> 00:43:56,945
Speaker 6:  Exactly. That's what Netflix wants you to think.

789
00:43:57,165 --> 00:44:01,065
Speaker 2:  And, and I, I really do think, and I can't say

790
00:44:01,305 --> 00:44:04,865
Speaker 2:  this more clearly, the government needs to show us its evidence before it

791
00:44:04,865 --> 00:44:08,785
Speaker 2:  takes this action. Yes. We have not seen it. That is If. you take away one

792
00:44:08,785 --> 00:44:10,985
Speaker 2:  thing from this conversation. It's me saying the government needs to show

793
00:44:10,985 --> 00:44:12,425
Speaker 2:  us this evidence before it takes the action.

794
00:44:14,325 --> 00:44:18,225
Speaker 2:  But it's crazy that the evidence apparently exists. Right. Such that

795
00:44:18,225 --> 00:44:19,225
Speaker 2:  they voted 50 to zero.

796
00:44:19,225 --> 00:44:22,225
Speaker 5:  Yeah. You seem more convinced than ever that there is evidence,

797
00:44:23,105 --> 00:44:26,385
Speaker 5:  which I think is fair. Like what we've seen in the last seven days would

798
00:44:26,705 --> 00:44:30,595
Speaker 5:  indicate that some people have seen some things. I think that's fair,

799
00:44:30,855 --> 00:44:34,645
Speaker 5:  but I just am, I don't think we should take that on faith.

800
00:44:34,965 --> 00:44:37,885
Speaker 2:  I think Americans should own American algorithms. That's it. I I think that,

801
00:44:37,965 --> 00:44:39,525
Speaker 2:  I think that comes down to it like

802
00:44:39,825 --> 00:44:40,645
Speaker 6:  No algorithms.

803
00:44:40,995 --> 00:44:44,405
Speaker 2:  Well, I mean If you really ask me. Yeah. I think we should get rid of the

804
00:44:44,405 --> 00:44:48,365
Speaker 2:  algorithmic media and go start bring back RSS Yeah. A bill to bring

805
00:44:48,365 --> 00:44:50,485
Speaker 2:  back RSS the United States vote Patel.

806
00:44:50,585 --> 00:44:51,645
Speaker 6:  That's what they should do.

807
00:44:51,955 --> 00:44:54,965
Speaker 5:  Just put TikTok on the fedi verse. It solves all of our problems.

808
00:44:55,245 --> 00:44:59,205
Speaker 2:  Everything will be fine. But barring that, I think it's pretty, it it is,

809
00:44:59,225 --> 00:45:02,845
Speaker 2:  it just feels reasonable to me that what people see and

810
00:45:02,845 --> 00:45:05,765
Speaker 2:  consume should be they, the,

811
00:45:06,755 --> 00:45:09,495
Speaker 2:  the people who are accountable for that should be here

812
00:45:10,535 --> 00:45:11,475
Speaker 2:  closer to you.

813
00:45:11,695 --> 00:45:15,235
Speaker 5:  You know, who would agree with that argument is the Communist party of China.

814
00:45:15,815 --> 00:45:19,795
Speaker 2:  And also most people, like, I

815
00:45:19,795 --> 00:45:22,835
Speaker 2:  think most governments are very interested in making sure that their citizens

816
00:45:22,835 --> 00:45:26,795
Speaker 2:  see something that comes from within that's pretty natural. And

817
00:45:26,915 --> 00:45:29,235
Speaker 2:  again, this I think just comes back to everything we've been talking about,

818
00:45:29,235 --> 00:45:32,485
Speaker 2:  which is do you, do you think

819
00:45:33,235 --> 00:45:37,225
Speaker 2:  that you are like an individual and a sea of individuals or

820
00:45:37,225 --> 00:45:40,185
Speaker 2:  that you are part of a collective? And I think the internet makes everybody

821
00:45:40,185 --> 00:45:44,025
Speaker 2:  feel very alone in that particular way. And, and like almost every

822
00:45:44,025 --> 00:45:45,145
Speaker 2:  political problem comes back to that.

823
00:45:46,005 --> 00:45:49,505
Speaker 6:  I'm just thinking about what happens if we get like, everybody's like, oh

824
00:45:49,505 --> 00:45:52,905
Speaker 6:  no, you're right. Like we need to own our own media and then we get like

825
00:45:52,905 --> 00:45:56,665
Speaker 6:  the BBC version of TikTok and like the

826
00:45:56,825 --> 00:46:00,785
Speaker 6:  NHK version of TikTok. Like the national broadcastings.

827
00:46:00,895 --> 00:46:01,185
Speaker 6:  Yeah.

828
00:46:01,645 --> 00:46:01,865
Speaker 2:  For,

829
00:46:01,925 --> 00:46:05,005
Speaker 6:  For company, for countries, but for TikTok.

830
00:46:05,205 --> 00:46:08,125
Speaker 5:  I mean NPRI think has a TikTok account. Just imagine that.

831
00:46:08,845 --> 00:46:12,725
Speaker 6:  I like, yeah. What's theirs? What's the NPR r social media app look like?

832
00:46:13,245 --> 00:46:13,965
Speaker 6:  I wanna see it.

833
00:46:15,065 --> 00:46:15,635
Speaker 2:  Well get

834
00:46:15,635 --> 00:46:17,595
Speaker 6:  On it. Is it just podcast? Is it just the Apple podcast Now?

835
00:46:17,625 --> 00:46:21,595
Speaker 2:  It's just that voice. Alright, we should take a break. Everyone can

836
00:46:21,625 --> 00:46:25,115
Speaker 2:  yell at me in the comments. Also, just tell us what you think. We have a

837
00:46:25,115 --> 00:46:25,515
Speaker 2:  hotline.

838
00:46:25,875 --> 00:46:28,955
Speaker 5:  I just wanna say, I think it's, I actually think I do want people to reach

839
00:46:28,955 --> 00:46:31,435
Speaker 5:  out. You should call the hotline. Eight six six Virg one one. You should

840
00:46:31,435 --> 00:46:35,035
Speaker 5:  email us Vergecast at the virg.com. But if I had to bet, I think most people

841
00:46:35,035 --> 00:46:38,395
Speaker 5:  are gonna agree with you, Eli. I think it is, it is just, my brain is so

842
00:46:38,395 --> 00:46:41,995
Speaker 5:  broken by the fact that you were the one making this argument. I think it's

843
00:46:41,995 --> 00:46:45,955
Speaker 5:  a perfectly fair argument. We're all sort of arguing based

844
00:46:45,955 --> 00:46:48,875
Speaker 5:  on evidence that no one has. And fundamentally you have to trust somebody.

845
00:46:48,875 --> 00:46:52,715
Speaker 5:  And I think ultimately saying the i I choose to not trust China is like not

846
00:46:52,715 --> 00:46:55,835
Speaker 5:  an unreasonable place to be. I just can't believe you're the one saying all

847
00:46:55,835 --> 00:46:58,515
Speaker 5:  of this. But I'll, I'll, I'll get there. I'll settle down. It'll be,

848
00:47:00,465 --> 00:47:04,235
Speaker 2:  Yeah. What, what's the, what's the line of foolish consistencies

849
00:47:04,735 --> 00:47:05,595
Speaker 2:  little minds?

850
00:47:07,105 --> 00:47:10,515
Speaker 2:  Sure. Whatever that quote is. I'm real smart is what I'm trying to say.

851
00:47:13,455 --> 00:47:16,155
Speaker 2:  No, let us know. I look, I've been reading our own comments. I think most

852
00:47:16,155 --> 00:47:19,275
Speaker 2:  of our commenters believe I'm like stridently opposed to this ban.

853
00:47:21,035 --> 00:47:23,835
Speaker 2:  I dunno why. Probably 'cause I haven't said anything about it until now.

854
00:47:24,195 --> 00:47:26,315
Speaker 2:  I think the United States governments owes us this evidence. That's like

855
00:47:26,315 --> 00:47:29,485
Speaker 2:  the main thing I think. But apart from that, I think it's reasonable to say

856
00:47:29,485 --> 00:47:30,805
Speaker 2:  it. Alright. Media ownership

857
00:48:26,275 --> 00:48:28,995
Speaker 7:  outsourcing projects simple, quick, and

858
00:48:58,355 --> 00:49:01,035
Speaker 7:  completed on time ready to scale smarter.

859
00:49:45,405 --> 00:49:46,765
Speaker 11:  clickup.com to get started.

860
00:49:50,205 --> 00:49:53,905
Speaker 2:  Welcome back. All right. I want to tell Alex and David a story about the

861
00:49:53,905 --> 00:49:57,545
Speaker 2:  studio as Lord. It's looking around in the break

862
00:49:58,305 --> 00:50:01,945
Speaker 2:  and things have moved and I, I know why they've moved and it's very funny.

863
00:50:02,365 --> 00:50:05,185
Speaker 2:  So The Verge is part of Vox Media. As you may know,

864
00:50:06,165 --> 00:50:10,035
Speaker 2:  Vox Media has a podcast network called the Vox Media Podcast Network on the

865
00:50:10,055 --> 00:50:13,955
Speaker 2:  Vox Media Podcast Network is a very good podcast called Point Forward with

866
00:50:14,205 --> 00:50:18,195
Speaker 2:  Andre a Goodal and Evan Turner who are basketball players. I'm

867
00:50:18,275 --> 00:50:20,395
Speaker 2:  assuming most people know that, but If you don't. They're basketball players.

868
00:50:20,655 --> 00:50:20,995
Speaker 2:  Now I

869
00:50:20,995 --> 00:50:21,875
Speaker 11:  Know they're very tall

870
00:50:21,895 --> 00:50:25,595
Speaker 2:  And very famous. They do the podcast in the same studio we are in

871
00:50:26,575 --> 00:50:29,165
Speaker 2:  and they, they redress it with their stuff. Are they

872
00:50:29,165 --> 00:50:32,445
Speaker 5:  The reasons it smells like weed all the time. No different podcasts.

873
00:50:32,445 --> 00:50:35,085
Speaker 6:  Does this explain why my seat sometimes changes height?

874
00:50:35,685 --> 00:50:39,525
Speaker 2:  I think it, it explains the chair moving. I don't, they

875
00:50:39,525 --> 00:50:42,605
Speaker 2:  record on Mondays and it would be incredible if on Thursdays,

876
00:50:44,065 --> 00:50:46,245
Speaker 2:  so I'm just gonna say no to that one. Okay. Call

877
00:50:46,245 --> 00:50:49,165
Speaker 6:  Me and If, you ever smoke that much weed? We'll hang out.

878
00:50:49,485 --> 00:50:53,045
Speaker 2:  That's, that's different. But for the, so they

879
00:50:53,045 --> 00:50:56,805
Speaker 2:  redressed the studio for their show, which makes sense. And then we

880
00:50:56,805 --> 00:50:59,365
Speaker 2:  have to put our stuff back. But I think they didn't notice it for the first

881
00:50:59,985 --> 00:51:03,885
Speaker 2:  few they did in here. So the Hena Cube Yay. Was behind them.

882
00:51:05,345 --> 00:51:06,405
Speaker 5:  Why would they get rid of that?

883
00:51:07,235 --> 00:51:07,925
Speaker 6:  It's so cool.

884
00:51:08,075 --> 00:51:11,965
Speaker 2:  Yeah. I think we should play NBA. Well, it was before 2K,

885
00:51:11,965 --> 00:51:14,685
Speaker 2:  like NBA 94 on the Hena Cube. I

886
00:51:14,685 --> 00:51:17,325
Speaker 5:  Think Jam probably existed on the, on the Hyah Cube.

887
00:51:17,645 --> 00:51:20,445
Speaker 2:  I don't think you did. Here's my official pitch for a Vox Media podcast network

888
00:51:20,445 --> 00:51:23,405
Speaker 2:  crossover. I will play NBA Jam

889
00:51:24,305 --> 00:51:26,285
Speaker 2:  on a Game Cube with Andre Kwa.

890
00:51:26,665 --> 00:51:27,445
Speaker 5:  Sounds amazing.

891
00:51:27,985 --> 00:51:29,365
Speaker 2:  We have a game cube. Yeah,

892
00:51:29,835 --> 00:51:30,925
Speaker 5:  Your move, Andre.

893
00:51:31,905 --> 00:51:35,045
Speaker 2:  We have a long promise that we'll get together and do, and Dave and I'll

894
00:51:35,045 --> 00:51:37,445
Speaker 2:  play Madden. And we just are never in the same place at the same time with

895
00:51:37,445 --> 00:51:40,325
Speaker 2:  the Game Cube. Like we've been in the same place at the same time

896
00:51:40,955 --> 00:51:44,805
Speaker 2:  without a game cube. Both of us have been in this room

897
00:51:44,805 --> 00:51:48,645
Speaker 2:  with the Game Cube, but without the other person, we're gonna figure

898
00:51:48,665 --> 00:51:50,325
Speaker 2:  out all three elements at the same time.

899
00:51:50,525 --> 00:51:54,445
Speaker 6:  I think you need some more elements. Like a, A plug Yeah. Controller. A

900
00:51:54,445 --> 00:51:54,765
Speaker 6:  controller.

901
00:51:55,285 --> 00:51:58,445
Speaker 2:  A copy of Madden. Yes. It's critical elements. Some other

902
00:51:58,445 --> 00:51:59,245
Speaker 6:  Stuff has to happen

903
00:52:00,365 --> 00:52:04,045
Speaker 2:  Just once on on point forward. I want these NBA superstars to be like, is

904
00:52:04,045 --> 00:52:06,805
Speaker 2:  that a Heineken game? He I've been searching for?

905
00:52:07,625 --> 00:52:08,125
Speaker 6:  You're like,

906
00:52:08,145 --> 00:52:09,805
Speaker 5:  Yes. It's like I'm on eBay all the time. Looking

907
00:52:09,825 --> 00:52:13,365
Speaker 2:  For one of those. It's very good. That show's great. You should listen to

908
00:52:13,365 --> 00:52:16,685
Speaker 2:  it. They just had Megan Rapinoe on it's south by with them, which was wonderful.

909
00:52:16,755 --> 00:52:20,725
Speaker 2:  Nice. Hell yeah. All right. Speaking of media, huh? That is your segue.

910
00:52:21,705 --> 00:52:25,405
Speaker 2:  Boy, there's a bunch of media streaming news this week.

911
00:52:25,905 --> 00:52:29,805
Speaker 2:  One correction I have to issue for the audience in our streaming draft. This

912
00:52:29,805 --> 00:52:30,525
Speaker 6:  Is true. I won.

913
00:52:31,365 --> 00:52:34,965
Speaker 2:  I Okay. So. I have long since been claiming that I won. I think

914
00:52:35,135 --> 00:52:39,085
Speaker 2:  given this piece of news, I definitively lost even that.

915
00:52:39,125 --> 00:52:42,485
Speaker 2:  I think I had the best lineup. I think this is an instant dq.

916
00:52:42,555 --> 00:52:43,685
Speaker 6:  What happened to MotorTrend?

917
00:52:44,085 --> 00:52:47,765
Speaker 2:  I picked as my niche streaming service. So David set up the draft.

918
00:52:48,185 --> 00:52:51,925
Speaker 2:  We had to pick player in every category 4K awards.

919
00:52:51,955 --> 00:52:55,485
Speaker 2:  Alex has an expansive definition of what counts as award-winning, streaming

920
00:52:55,565 --> 00:52:56,245
Speaker 2:  service. Correct.

921
00:52:57,875 --> 00:53:01,445
Speaker 2:  Live all these things. And the last one was niche. And I

922
00:53:02,565 --> 00:53:05,885
Speaker 2:  candidly blanked on stage and I was like, I dunno, I have enough. Like I

923
00:53:05,885 --> 00:53:09,845
Speaker 2:  picked TikTok, I'm good. you know, like even that it's going get,

924
00:53:10,025 --> 00:53:13,045
Speaker 2:  you know, banned from app stores. Like, I'll take it for now. I want

925
00:53:13,045 --> 00:53:14,805
Speaker 5:  A ban TikTok. I'm gonna pick it first.

926
00:53:15,195 --> 00:53:19,165
Speaker 2:  Yeah, exactly. The point is to be confounding. Never let him

927
00:53:19,165 --> 00:53:22,925
Speaker 2:  know what's coming. So I blanked on stage and I picked

928
00:53:23,075 --> 00:53:27,045
Speaker 2:  what my father-in-Law had been watching at my home before I left

929
00:53:27,045 --> 00:53:31,035
Speaker 2:  for South by Southwest, which is MotorTrend tv. And we published

930
00:53:31,035 --> 00:53:34,715
Speaker 2:  a streaming draft and YouTube commenters, like this shit went

931
00:53:34,715 --> 00:53:38,395
Speaker 2:  92 weeks ago. Oh no. Like it was killed two weeks ago.

932
00:53:40,695 --> 00:53:44,155
Speaker 2:  So first of all, MotorTrend TV was long gone. Yeah. It was called

933
00:53:44,155 --> 00:53:47,855
Speaker 2:  MotorTrend Plus, there's a rebrand and now it's being

934
00:53:47,855 --> 00:53:51,295
Speaker 2:  shuttered and being folded into Discovery Plus. Oh.

935
00:53:51,625 --> 00:53:55,615
Speaker 2:  Which is where all of us learn about house flipping and going to

936
00:53:55,615 --> 00:53:56,655
Speaker 2:  car auctions. Yeah.

937
00:53:56,885 --> 00:53:58,935
Speaker 5:  Have you checked on your father-in-Law? How's he holding up?

938
00:53:59,235 --> 00:54:02,855
Speaker 2:  You know, we haven't brought it up. Just wasn't one of those things. Like

939
00:54:03,035 --> 00:54:03,335
Speaker 2:  is he,

940
00:54:03,335 --> 00:54:06,735
Speaker 5:  He's just watching like, cached videos on, on the

941
00:54:06,735 --> 00:54:08,495
Speaker 2:  Tv. Yeah. you know, we're just gonna let

942
00:54:08,765 --> 00:54:09,055
Speaker 6:  Yeah.

943
00:54:09,595 --> 00:54:12,015
Speaker 2:  You don't wanna, You don't wanna roll to a family member and be like, you

944
00:54:12,015 --> 00:54:13,575
Speaker 2:  have to watch Discovery Plus now. Like

945
00:54:14,775 --> 00:54:16,335
Speaker 6:  I be, the app still works for a while.

946
00:54:16,535 --> 00:54:20,495
Speaker 2:  I think the app is still gonna work for a while. It's No, that's not

947
00:54:20,495 --> 00:54:24,295
Speaker 2:  even right. It's closing in 14 days. Yeah. Super.

948
00:54:24,425 --> 00:54:26,495
Speaker 2:  Super isn't gonna work for a while. Ooh.

949
00:54:27,405 --> 00:54:31,375
Speaker 6:  He's got some time. He's he's got time. He can, he can record

950
00:54:31,375 --> 00:54:32,055
Speaker 6:  it with his phone.

951
00:54:32,285 --> 00:54:36,075
Speaker 2:  Yeah. Episode. I'm just saying episodes. Look, I, I think overall

952
00:54:36,195 --> 00:54:40,015
Speaker 2:  I had the best, the best Suite, but I do

953
00:54:40,175 --> 00:54:44,055
Speaker 2:  think picking an already dead service, like an instant dq.

954
00:54:44,055 --> 00:54:47,295
Speaker 2:  Yeah. Like If, you pick a thing that's got 90, you're at the draft.

955
00:54:47,765 --> 00:54:50,775
Speaker 6:  Netflix is next, but yeah. Get it. Netflix.

956
00:54:50,965 --> 00:54:54,855
Speaker 5:  Yeah. That was the real takeaway is Netflix is super dead really soon. Yes.

957
00:54:54,855 --> 00:54:55,055
Speaker 5:  Yeah.

958
00:54:55,235 --> 00:54:57,055
Speaker 6:  Any minute now. Don't you worry, it's coming.

959
00:54:57,455 --> 00:55:00,855
Speaker 2:  I do think my ability to pick a, an already dead streaming service

960
00:55:01,335 --> 00:55:04,335
Speaker 2:  distracted from your bold prediction that Netflix would die soon.

961
00:55:04,995 --> 00:55:08,415
Speaker 6:  It didn't. I had friends messaging me being like, I heard the podcast

962
00:55:08,605 --> 00:55:11,455
Speaker 6:  Netflix, Alex, what the hell? And I'm like, look,

963
00:55:11,455 --> 00:55:12,135
Speaker 5:  It's outta your mind.

964
00:55:12,855 --> 00:55:14,615
Speaker 6:  I, I think, I think Paramount plus Netflix,

965
00:55:17,135 --> 00:55:19,215
Speaker 2:  I don't actually be very clear.

966
00:55:22,715 --> 00:55:22,935
Speaker 6:  Say,

967
00:55:23,445 --> 00:55:27,175
Speaker 2:  Alright, let's, that's some news. RIP to Motor Trend tv.

968
00:55:27,965 --> 00:55:28,535
Speaker 6:  Real one.

969
00:55:29,125 --> 00:55:32,935
Speaker 2:  Yeah. Bitch and Rides. Where will you live? Now? That's a real show

970
00:55:32,955 --> 00:55:33,375
Speaker 2:  by the way.

971
00:55:33,505 --> 00:55:35,575
Speaker 6:  It'll live, it'll live on Discovery Plus.

972
00:55:36,165 --> 00:55:36,655
Speaker 2:  It's true.

973
00:55:36,725 --> 00:55:38,015
Speaker 6:  Yeah. You, you'll be fine.

974
00:55:38,705 --> 00:55:42,375
Speaker 5:  Which will then be part of Max, which will eventually be merged with Paramount

975
00:55:42,375 --> 00:55:42,655
Speaker 5:  Plus.

976
00:55:43,195 --> 00:55:46,655
Speaker 2:  Yes. One way or another. You're gonna watch Bitching Rides. Yeah.

977
00:55:47,875 --> 00:55:49,775
Speaker 5:  Coming for We'll find you. Don't you worry.

978
00:55:51,115 --> 00:55:54,075
Speaker 2:  I have a lot to say about that show, but I think, I think it's a very limited

979
00:55:54,515 --> 00:55:57,835
Speaker 2:  audience for criticism of Bitching Rides. I've watched a lot of it with my

980
00:55:57,835 --> 00:56:01,755
Speaker 2:  father-in-Law. Okay. Actual news TV news. By the

981
00:56:01,755 --> 00:56:04,795
Speaker 2:  way, here's the dis the disclosure. We'll just get 'em all the way. We mentioned

982
00:56:04,795 --> 00:56:08,075
Speaker 2:  Netflix. I was at EP on a Netflix show called The. future of

983
00:56:08,755 --> 00:56:12,195
Speaker 2:  NBC is an investor in our company. They run the Peacock service, which If

984
00:56:12,195 --> 00:56:14,435
Speaker 2:  you believe Alex Will Far outlive Netflix.

985
00:56:15,055 --> 00:56:17,155
Speaker 6:  I'm right, I'm right. Don't worry about it. I'm right.

986
00:56:19,465 --> 00:56:22,435
Speaker 2:  Yeah. Our company makes Full Swing the golf show on Netflix. That's pretty

987
00:56:22,435 --> 00:56:25,765
Speaker 2:  good. That's it. Those are disclosures today there. I'm sure there are more.

988
00:56:26,165 --> 00:56:29,925
Speaker 2:  I believe Wired connections are better than wireless ones. RIP starlink.

989
00:56:30,285 --> 00:56:33,765
Speaker 2:  That, that's just a fact. I say that because the starlink people think that

990
00:56:33,785 --> 00:56:37,685
Speaker 2:  I'm in the pocket of big Comcast. Yeah, that's a real, I say that all the

991
00:56:37,685 --> 00:56:38,565
Speaker 2:  time. It still comes up. Yeah,

992
00:56:38,985 --> 00:56:39,765
Speaker 6:  That's what I thought.

993
00:56:39,795 --> 00:56:43,045
Speaker 2:  They're like, he's in Big Ethernet's Pocket. All right.

994
00:56:44,585 --> 00:56:48,445
Speaker 2:  Actual news. Yeah. YouTube is revamping its TV app, not YouTube

995
00:56:48,505 --> 00:56:51,805
Speaker 2:  tv, but the YouTube app on TVs.

996
00:56:52,245 --> 00:56:56,115
Speaker 6:  I have a question about this. Yeah, yeah. Who is not watching in

997
00:56:56,115 --> 00:56:59,915
Speaker 6:  full screen? What, what people are like, eh, I wanna

998
00:56:59,915 --> 00:57:02,915
Speaker 6:  watch like with the ads and crap all around it. Who are they?

999
00:57:03,385 --> 00:57:05,875
Speaker 2:  This is everyone's dream is to make QVC. Well,

1000
00:57:06,145 --> 00:57:10,035
Speaker 5:  It's that, that is half of it. I firmly agree with that. That like,

1001
00:57:10,615 --> 00:57:14,275
Speaker 5:  the goal is to let you point at something on your television and it just

1002
00:57:14,275 --> 00:57:17,195
Speaker 5:  appears at your house the next day. Like that is literally what everyone

1003
00:57:17,255 --> 00:57:18,435
Speaker 5:  who makes TV stuff wants

1004
00:57:18,855 --> 00:57:20,595
Speaker 2:  The only dream that anyone has ever had.

1005
00:57:20,785 --> 00:57:24,635
Speaker 5:  Yeah. Truly the other half of it is, YouTube

1006
00:57:24,655 --> 00:57:28,315
Speaker 5:  has been on this very long quest to get YouTube

1007
00:57:28,545 --> 00:57:32,515
Speaker 5:  onto televisions in like a more YouTubey way. Right? Like

1008
00:57:32,515 --> 00:57:36,315
Speaker 5:  YouTube has talked for years now about how the TV is the fastest

1009
00:57:36,315 --> 00:57:40,195
Speaker 5:  growing YouTube platform. Like it's, it's now to the point that I just

1010
00:57:40,195 --> 00:57:42,595
Speaker 5:  laugh whenever they put that in a press release because it's like, yeah,

1011
00:57:42,595 --> 00:57:46,355
Speaker 5:  it's been that way for like a decade now. But the problem with

1012
00:57:46,355 --> 00:57:50,315
Speaker 5:  that is there are lots of things about YouTube that people like that

1013
00:57:50,315 --> 00:57:53,435
Speaker 5:  are not just watching the video, right? Like, there's all this community

1014
00:57:53,435 --> 00:57:56,995
Speaker 5:  stuff. Comments are very important. Recommendations are very important. You

1015
00:57:56,995 --> 00:58:00,755
Speaker 5:  want to subscribe. Like it's harder to subscribe to a channel from your television

1016
00:58:01,145 --> 00:58:05,115
Speaker 5:  than it is from your phone or your computer. And that is actually a

1017
00:58:05,115 --> 00:58:08,995
Speaker 5:  threat to YouTube over time as its stuff gets bigger, right? So yeah, they've

1018
00:58:08,995 --> 00:58:12,515
Speaker 5:  been on this thing forever to figure out like, how do we let you use YouTube

1019
00:58:12,605 --> 00:58:16,355
Speaker 5:  while also watching something on your television. And their s For a long

1020
00:58:16,355 --> 00:58:19,555
Speaker 5:  time was to connect it better to your phone. Like, you know how they have

1021
00:58:19,555 --> 00:58:22,995
Speaker 5:  the thing now where you're watching YouTube on your TV and you open up YouTube

1022
00:58:22,995 --> 00:58:25,435
Speaker 5:  on your phone, that little thing pops up that's like, do you wanna connect

1023
00:58:25,525 --> 00:58:28,795
Speaker 5:  first of all that future rules and thank you to YouTube for doing it. But

1024
00:58:28,795 --> 00:58:31,875
Speaker 5:  that was their big plan, and I think that's how they thought they were gonna

1025
00:58:31,875 --> 00:58:34,475
Speaker 5:  solve it, right? Like, they were like, we're gonna be both the first and

1026
00:58:34,475 --> 00:58:38,075
Speaker 5:  the second screen simultaneously. This to me feels like them saying

1027
00:58:38,655 --> 00:58:41,835
Speaker 5:  that's not really working. And so actually what we need to do is put more

1028
00:58:41,845 --> 00:58:45,675
Speaker 5:  stuff more accessible on the big screen in front of you.

1029
00:58:45,675 --> 00:58:49,195
Speaker 5:  So they have this new thing where in it's full screen by default, I think.

1030
00:58:49,305 --> 00:58:52,635
Speaker 5:  Yeah. But you can press a button and it will, the, the video will shrink,

1031
00:58:52,655 --> 00:58:56,395
Speaker 5:  and then on the right side you'll get some of the metadata, the

1032
00:58:56,395 --> 00:58:59,195
Speaker 5:  description and the comments. And like, you know, I said a list of the products

1033
00:58:59,195 --> 00:59:03,035
Speaker 5:  in the video, it'll look more like seeing YouTube in like a desktop

1034
00:59:03,035 --> 00:59:06,315
Speaker 5:  browser. To me that feels like a

1035
00:59:07,525 --> 00:59:11,115
Speaker 5:  Reasonable thing to do. And also like, yeah, the most

1036
00:59:11,145 --> 00:59:14,675
Speaker 5:  obvious thing, they're like, what if we just did YouTube on your television?

1037
00:59:14,675 --> 00:59:18,315
Speaker 5:  It's like, yeah, that's the one. but it does feel like they're saying

1038
00:59:18,425 --> 00:59:20,995
Speaker 5:  this thing where we're gonna connect it to your other devices and you're

1039
00:59:21,130 --> 00:59:24,045
Speaker 5:  gonna be able to do it all simultaneously maybe is not actually the answer.

1040
00:59:24,045 --> 00:59:24,605
Speaker 5:  The way they thought.

1041
00:59:24,745 --> 00:59:28,605
Speaker 6:  It kind of feels like they pulled a Vizio Oh God. And went,

1042
00:59:28,665 --> 00:59:31,965
Speaker 6:  oh, you know what? Actually people don't wanna control

1043
00:59:32,575 --> 00:59:36,125
Speaker 6:  their TV viewing experience from their phone. Visio was like, yeah,

1044
00:59:36,145 --> 00:59:39,805
Speaker 2:  That's what you meant. I was worried there any number of other bad things

1045
00:59:39,965 --> 00:59:40,165
Speaker 2:  I could

1046
00:59:40,165 --> 00:59:43,525
Speaker 6:  Maybe No, no, no. I'm, I'm thinking very clearly because I just, I have the

1047
00:59:43,525 --> 00:59:47,045
Speaker 6:  26 physio TV and I put it in the guest room and I have a, somebody staying

1048
00:59:47,045 --> 00:59:50,205
Speaker 6:  over and I was like, oh, I have to, like, where's the remote? Yeah.

1049
00:59:50,205 --> 00:59:51,685
Speaker 2:  This person, I had to give you an Android tablet

1050
00:59:52,025 --> 00:59:55,205
Speaker 6:  And I was like, you're just gonna have to use your regular phone. I'm sorry.

1051
00:59:55,665 --> 00:59:56,725
Speaker 6:  And, and it feels like, like, and

1052
00:59:56,765 --> 00:59:59,725
Speaker 2:  I refuse to buy a $29 Roku to solve this problem.

1053
01:00:00,355 --> 01:00:03,925
Speaker 6:  It's true. No, it's 'cause I couldn't find it. It's in another box, but I

1054
01:00:03,925 --> 01:00:07,685
Speaker 6:  don't know where anything is. But, but yeah, this just feels like the same

1055
01:00:07,685 --> 01:00:10,325
Speaker 6:  thing where, where people are starting to realize, wait, actually the phone

1056
01:00:10,325 --> 01:00:13,605
Speaker 6:  is not the best way to do this. And sometimes you just wanna watch this and

1057
01:00:13,885 --> 01:00:17,325
Speaker 6:  interact with it with a remote, because remotes are probably the best way

1058
01:00:17,325 --> 01:00:21,035
Speaker 6:  to control TV is because they've worked Yeah.

1059
01:00:21,185 --> 01:00:25,115
Speaker 2:  Forever. Yeah. And the idea that you'll own both a first and second

1060
01:00:25,115 --> 01:00:28,675
Speaker 2:  screen is like the dream. Like you'll watch up there and shop down here and

1061
01:00:28,675 --> 01:00:30,435
Speaker 2:  it's like, people do that all the time, but they don't. No. We

1062
01:00:30,435 --> 01:00:33,555
Speaker 6:  Watch up there and we TikTok down here for now.

1063
01:00:34,515 --> 01:00:38,315
Speaker 2:  I think this entire story is explained by one quote

1064
01:00:38,315 --> 01:00:42,275
Speaker 2:  from the blog post, just one and the

1065
01:00:42,275 --> 01:00:46,155
Speaker 2:  image that YouTube supplied in that blog post. So the quote from

1066
01:00:46,155 --> 01:00:50,045
Speaker 2:  the blog post, the design changes started with quote, the

1067
01:00:50,115 --> 01:00:53,765
Speaker 2:  idea of reducing the size of the video player and simplifying the

1068
01:00:53,765 --> 01:00:54,325
Speaker 2:  interactions.

1069
01:00:54,805 --> 01:00:55,285
Speaker 6:  I hate it.

1070
01:00:55,625 --> 01:00:58,405
Speaker 2:  That's just like, we're just gonna make the video player smaller because

1071
01:00:58,545 --> 01:01:02,525
Speaker 2:  we have, everyone has long thought that the TV is like the lean

1072
01:01:02,595 --> 01:01:06,325
Speaker 2:  back. You just put up the video and you're done and you're going. And now

1073
01:01:06,325 --> 01:01:09,485
Speaker 2:  they're realizing, oh, this is just an Android tablet in your wall. What

1074
01:01:09,485 --> 01:01:12,165
Speaker 2:  if we just let you control it like an Android tablet instead of saying all

1075
01:01:12,165 --> 01:01:14,165
Speaker 2:  the interactivity happens on your phone. Yeah. Which is what you're saying.

1076
01:01:14,165 --> 01:01:16,805
Speaker 2:  Yeah. But that first one, we're just gonna make the video player smaller

1077
01:01:17,075 --> 01:01:18,925
Speaker 2:  that is now acceptable on our TVs.

1078
01:01:19,385 --> 01:01:19,605
Speaker 5:  Yes.

1079
01:01:19,825 --> 01:01:20,765
Speaker 2:  That's a sea change.

1080
01:01:21,165 --> 01:01:24,845
Speaker 6:  I mean, I I I fundamentally disagree with YouTube on this one.

1081
01:01:25,605 --> 01:01:26,285
Speaker 6:  Possibly. YouTube is small.

1082
01:01:26,285 --> 01:01:28,285
Speaker 2:  This is what I'm saying. The whole story is in that quote. Yeah,

1083
01:01:28,585 --> 01:01:31,365
Speaker 6:  No, I I No, I agree. 'cause you look at that and then you look at the picture

1084
01:01:31,545 --> 01:01:35,325
Speaker 6:  and it's her talking about products and then all the

1085
01:01:35,325 --> 01:01:36,645
Speaker 6:  products are down at the bottom of the video.

1086
01:01:36,825 --> 01:01:40,085
Speaker 2:  No, what there? Yes, that is true. Okay. That's not what you were talking

1087
01:01:40,085 --> 01:01:43,885
Speaker 2:  about. My point is, you pull over in your car and

1088
01:01:44,165 --> 01:01:47,575
Speaker 2:  actually look at this image and you're like, here's what YouTube thought

1089
01:01:47,575 --> 01:01:51,095
Speaker 2:  best represents their big idea. And you look at the

1090
01:01:51,095 --> 01:01:54,855
Speaker 2:  thumbnail and you look at the headline and you're like, oh, YouTube

1091
01:01:54,875 --> 01:01:58,655
Speaker 2:  has a quality problem. Because the headline is, I bought

1092
01:01:58,715 --> 01:02:02,095
Speaker 2:  in All co in all caps, many beauty products that actually work

1093
01:02:03,325 --> 01:02:06,615
Speaker 2:  because that is how you agro. And maybe this video is great. I, I'm, I'm

1094
01:02:06,615 --> 01:02:10,135
Speaker 2:  not saying that quality of the video is wrong. I'm saying YouTube is, the

1095
01:02:10,135 --> 01:02:14,085
Speaker 2:  algorithm is actively cheapening the YouTube brand because it's a

1096
01:02:14,085 --> 01:02:17,925
Speaker 2:  YouTube thumbnail with like a YouTube face on it. It's a headline that has

1097
01:02:17,925 --> 01:02:21,725
Speaker 2:  all caps. It's shouting at you and then underneath it, what

1098
01:02:21,725 --> 01:02:25,445
Speaker 2:  you're supposed to do is buy some stuff. Yeah. And you're like, oh,

1099
01:02:25,445 --> 01:02:29,335
Speaker 2:  this, all this adds up to a less premium

1100
01:02:29,605 --> 01:02:33,215
Speaker 2:  good thing. Cute. you know what I mean? Like, it's, all of it is being in

1101
01:02:33,215 --> 01:02:34,855
Speaker 2:  the mall where everyone's yelling at you. I

1102
01:02:34,855 --> 01:02:38,415
Speaker 5:  Think you're old. Like, that's, that's what I mean,

1103
01:02:38,675 --> 01:02:42,095
Speaker 5:  not to put too fine a point on it, but like the idea that

1104
01:02:42,255 --> 01:02:43,215
Speaker 2:  I think this feels bad.

1105
01:02:44,335 --> 01:02:45,735
Speaker 5:  I I think because you think

1106
01:02:45,775 --> 01:02:48,255
Speaker 2:  I like cool things that are cool. I'm sorry, I didn't realize that was an

1107
01:02:48,255 --> 01:02:48,775
Speaker 2:  old guy thing.

1108
01:02:49,275 --> 01:02:53,215
Speaker 5:  No, I mean, like, if, if you're, if you're mad at this

1109
01:02:53,215 --> 01:02:57,135
Speaker 5:  particular video, fine. It has 2.8 million views, which I would

1110
01:02:57,135 --> 01:03:00,455
Speaker 5:  say is a, a reasonable sign that it's, it's pretty good and people like it.

1111
01:03:00,755 --> 01:03:01,335
Speaker 5:  But also

1112
01:03:01,555 --> 01:03:04,695
Speaker 2:  I'm saying they should revert control of this algorithm to me personally,

1113
01:03:04,795 --> 01:03:06,615
Speaker 2:  the President of America. Just

1114
01:03:07,195 --> 01:03:11,175
Speaker 5:  If this, if this thumbnail just had a jumping truck, would you

1115
01:03:11,175 --> 01:03:12,375
Speaker 5:  be less mad about it

1116
01:03:12,575 --> 01:03:16,495
Speaker 2:  And then underneath it was trucks you could buy? Yeah, probably. Right? No,

1117
01:03:16,495 --> 01:03:19,335
Speaker 2:  look, I, I have, I don't have anything to say about beauty product videos

1118
01:03:19,435 --> 01:03:23,175
Speaker 2:  or any this category video. I'm saying the presentation that

1119
01:03:23,175 --> 01:03:26,815
Speaker 2:  YouTube picked for what do we want you to do on televisions

1120
01:03:27,515 --> 01:03:31,295
Speaker 2:  is a shouty shopping video. Right. Like all

1121
01:03:31,405 --> 01:03:35,015
Speaker 2:  caps in the headline. Like they are trying to take the market

1122
01:03:35,165 --> 01:03:38,455
Speaker 2:  away from television. That's long been the goal

1123
01:03:39,035 --> 01:03:42,815
Speaker 2:  on TVs is where they are growing the most. And I,

1124
01:03:43,455 --> 01:03:46,895
Speaker 2:  I think there's a real clash between what works in the algorithmic YouTube

1125
01:03:46,925 --> 01:03:50,895
Speaker 2:  feed on phones and desktops and then this experience on a television.

1126
01:03:51,005 --> 01:03:54,615
Speaker 5:  This proves the opposite to me. Okay. What this says to me is that

1127
01:03:54,645 --> 01:03:58,615
Speaker 5:  YouTube thought for years that what people would do when they

1128
01:03:58,635 --> 01:04:02,455
Speaker 5:  sat down on their couch is they would YouTube like they television,

1129
01:04:02,665 --> 01:04:05,975
Speaker 5:  which is to say, put something on and sit for 30 minutes and look at it without

1130
01:04:05,975 --> 01:04:09,095
Speaker 5:  doing anything else. And YouTube has slowly discovered over time that not

1131
01:04:09,095 --> 01:04:12,175
Speaker 5:  only is that not what people wanna do, it's not even what they wanna do with

1132
01:04:12,175 --> 01:04:16,135
Speaker 5:  their remotes. That this thing where like fundamentally YouTube is

1133
01:04:16,585 --> 01:04:19,375
Speaker 5:  about the thing that you're watching, but only in part about the thing that

1134
01:04:19,375 --> 01:04:23,095
Speaker 5:  you're watching. It's also about who the creator is and what the

1135
01:04:23,095 --> 01:04:25,255
Speaker 5:  description is and looking at the products in the video, because a lot of

1136
01:04:25,255 --> 01:04:28,775
Speaker 5:  people do like to shop for this stuff and seeing the comments and, and finding

1137
01:04:28,895 --> 01:04:31,975
Speaker 5:  recommendations and going down these rabbit holes. Like to me what this says

1138
01:04:31,975 --> 01:04:35,455
Speaker 5:  is, oh, people actually use YouTube on their TV with their remote

1139
01:04:35,725 --> 01:04:38,615
Speaker 5:  Exactly the same way they use it on their phone. And so what we need to give

1140
01:04:38,615 --> 01:04:40,695
Speaker 5:  them is YouTube that looks like a desktop browser.

1141
01:04:41,205 --> 01:04:44,895
Speaker 2:  Yeah. I, I think I agree. I agree with you. And in that specific

1142
01:04:44,995 --> 01:04:48,775
Speaker 2:  way, I am saying that even If, you look at this headline,

1143
01:04:49,675 --> 01:04:53,095
Speaker 2:  for some reason the word bought is capitalized, but the words that actually

1144
01:04:53,095 --> 01:04:53,855
Speaker 2:  work are not,

1145
01:04:54,715 --> 01:04:56,575
Speaker 5:  And mini beauty products is all Cap All

1146
01:04:56,575 --> 01:05:00,455
Speaker 2:  Is all cap. Like they are very tiny. It's algorithmic. Like when you

1147
01:05:00,455 --> 01:05:04,295
Speaker 2:  take the algorithmic media and you just like make it this much bigger, I

1148
01:05:04,295 --> 01:05:07,735
Speaker 2:  think that stuff is gonna get highlighted in different ways. And maybe the

1149
01:05:07,735 --> 01:05:11,575
Speaker 2:  fight is between people don't care and people do care. But you just end up

1150
01:05:11,575 --> 01:05:15,295
Speaker 2:  in this place where all social media turns into QVC and

1151
01:05:15,295 --> 01:05:18,765
Speaker 2:  really the dream of all interactive TV has always been to be

1152
01:05:18,885 --> 01:05:22,045
Speaker 2:  QVC and YouTube turning itself into QVC,

1153
01:05:22,715 --> 01:05:26,605
Speaker 2:  like literally turning itself into QVC puts them right next to

1154
01:05:26,605 --> 01:05:27,445
Speaker 2:  real QVC.

1155
01:05:27,995 --> 01:05:28,925
Speaker 5:  Yeah. Which is

1156
01:05:28,925 --> 01:05:29,205
Speaker 2:  Weird.

1157
01:05:29,205 --> 01:05:32,245
Speaker 5:  No, I, I, I totally agree with that. And that is very clearly where all of

1158
01:05:32,245 --> 01:05:35,725
Speaker 5:  this is going. They're like, look at some ads, pay us a bunch of money

1159
01:05:36,225 --> 01:05:40,125
Speaker 5:  and buy every single product that exists anywhere in this video. Yeah.

1160
01:05:40,185 --> 01:05:43,165
Speaker 5:  And that is how we went. But you know what's interesting is the, the way,

1161
01:05:43,275 --> 01:05:46,325
Speaker 5:  like our comments are picked up on this too, on the, the piece that we wrote,

1162
01:05:48,115 --> 01:05:51,165
Speaker 5:  what was it a few months ago now that TikTok changed the thing where now

1163
01:05:51,165 --> 01:05:54,685
Speaker 5:  when you swipe up to see the comments, instead of pulling the comments up

1164
01:05:54,685 --> 01:05:57,365
Speaker 5:  over the video, it shrinks the video just down to the top of the screen.

1165
01:05:57,395 --> 01:06:01,205
Speaker 5:  Yeah. So you can still see the whole video just not as big.

1166
01:06:01,845 --> 01:06:04,605
Speaker 5:  That's essentially what this is doing now too. Right? It's saying you wanna

1167
01:06:04,605 --> 01:06:07,285
Speaker 5:  get to the other part of the interface instead of pulling it up over top

1168
01:06:07,285 --> 01:06:10,165
Speaker 5:  of what you're seeing. We're just gonna shrink what you're seeing. And I

1169
01:06:10,165 --> 01:06:14,085
Speaker 5:  think you can argue about whether that's the

1170
01:06:14,085 --> 01:06:17,685
Speaker 5:  correct viewing experience or not. But I think that is very much the trend

1171
01:06:17,685 --> 01:06:21,405
Speaker 5:  of where we're headed is like we want you to see the whole picture. We're

1172
01:06:21,405 --> 01:06:25,005
Speaker 5:  just also gonna recognize that the rest of the interface is at least just

1173
01:06:25,005 --> 01:06:26,925
Speaker 5:  as important as the video

1174
01:06:27,185 --> 01:06:29,285
Speaker 2:  Or at least provides more opportunities to shop. Right?

1175
01:06:29,425 --> 01:06:32,725
Speaker 6:  Mm. That one, I mean it's just all

1176
01:06:32,865 --> 01:06:33,685
Speaker 2:  Oh, you're watching this video?

1177
01:06:33,685 --> 01:06:36,965
Speaker 6:  Yeah, I've been watching the video this whole time. I'm sorry.

1178
01:06:37,725 --> 01:06:40,325
Speaker 6:  I wanted to see what beauty products actually work, but it's not, they

1179
01:06:40,325 --> 01:06:40,805
Speaker 2:  Are many. They

1180
01:06:40,805 --> 01:06:44,485
Speaker 6:  Are, they, they're very, very tiny. But it's, it's cheap stuff that I don't,

1181
01:06:44,525 --> 01:06:45,285
Speaker 6:  I don't wanna use this.

1182
01:06:45,875 --> 01:06:47,245
Speaker 2:  Well, they're many. Yeah,

1183
01:06:47,245 --> 01:06:48,125
Speaker 6:  But it's, but it's

1184
01:06:48,125 --> 01:06:50,045
Speaker 2:  Cheap. Well, you'd think it'd be good stuff, but cheaper not

1185
01:06:50,115 --> 01:06:51,525
Speaker 6:  It's cheap brands Got

1186
01:06:51,525 --> 01:06:52,885
Speaker 2:  You. Ice cold Alex.

1187
01:06:52,995 --> 01:06:56,485
Speaker 6:  Yeah. I'm, I'm, I'm one of those bougie bitches when it comes to my Sephora

1188
01:06:56,755 --> 01:06:57,045
Speaker 6:  runs.

1189
01:06:57,905 --> 01:07:01,605
Speaker 2:  The last time I watched QVCI was in a hotel room in California

1190
01:07:03,035 --> 01:07:06,775
Speaker 2:  and it was, you know, it was the winter, it was just recently and

1191
01:07:06,875 --> 01:07:10,695
Speaker 2:  on QVC in California, someone was earnestly

1192
01:07:11,155 --> 01:07:15,135
Speaker 2:  trying to sell a corded snowblower and being like, this cord

1193
01:07:15,135 --> 01:07:18,415
Speaker 2:  is so convenient, you just plug in the snowblower. And I was like, this is

1194
01:07:18,415 --> 01:07:20,575
Speaker 2:  doomed. And somehow this is also The future of all media.

1195
01:07:20,995 --> 01:07:22,015
Speaker 6:  It is. Everybody wants

1196
01:07:22,015 --> 01:07:25,415
Speaker 2:  To just straightforwardly being like, what it is is a push snowblower, but

1197
01:07:25,415 --> 01:07:28,015
Speaker 2:  you want to just plug it right in. No batteries to worry about.

1198
01:07:28,695 --> 01:07:32,375
Speaker 6:  Yeah. 'cause then you then you get to use your, your extension cord also

1199
01:07:32,375 --> 01:07:33,695
Speaker 6:  purchased on QVC. Exactly.

1200
01:07:33,955 --> 01:07:37,655
Speaker 5:  It really is amazing how much of like the stuff you see on TikTok now even

1201
01:07:39,145 --> 01:07:42,615
Speaker 5:  seals some of the conventions of how people used to talk on QVC. Like the

1202
01:07:42,615 --> 01:07:46,335
Speaker 5:  thing where it's like, describe the problem somebody has in overly dramatic

1203
01:07:46,335 --> 01:07:50,175
Speaker 5:  turn and then big beautiful turn into what a cool world

1204
01:07:50,175 --> 01:07:53,215
Speaker 5:  you live in. Like that's now TikTok shop. And they're like, I can't believe

1205
01:07:53,215 --> 01:07:56,055
Speaker 5:  how expensive it is. It's on the TikTok shop. It's only gonna be Yeah, this

1206
01:07:56,055 --> 01:07:59,895
Speaker 5:  price for this long. Get it now. It's like you're, you're literally doing

1207
01:08:00,135 --> 01:08:03,895
Speaker 5:  a QVC bit. And I suspect most of these people probably

1208
01:08:03,895 --> 01:08:07,655
Speaker 5:  don't know what QVC is and have certainly never seen it, but

1209
01:08:07,655 --> 01:08:11,455
Speaker 5:  like, it just turns out that's the correct way to do a buy this thing

1210
01:08:11,645 --> 01:08:12,415
Speaker 5:  from me video.

1211
01:08:13,195 --> 01:08:15,365
Speaker 2:  It has just been optimized over time. Yeah.

1212
01:08:15,395 --> 01:08:18,885
Speaker 5:  There's just like one evolutionary way Yeah. To tell someone to buy your

1213
01:08:18,885 --> 01:08:20,005
Speaker 5:  stupid cheap product. And

1214
01:08:20,005 --> 01:08:22,245
Speaker 6:  It's the Q Vvc way real, like big

1215
01:08:22,245 --> 01:08:25,245
Speaker 2:  Thinkers. I was just watching this, the, you know, it's like the classic

1216
01:08:25,525 --> 01:08:28,845
Speaker 2:  QVC, like yeah. Male host, female host. Like, wow,

1217
01:08:28,845 --> 01:08:31,965
Speaker 6:  What are you talking about today? How are you gonna cooking your kitchen

1218
01:08:31,965 --> 01:08:35,445
Speaker 2:  With and, and how do you power this snowblower? And I was like, I don't,

1219
01:08:35,445 --> 01:08:37,645
Speaker 2:  this is like obvious on its face. Like

1220
01:08:40,225 --> 01:08:43,045
Speaker 2:  it was very good. It was the most QVC I've watched in, in some time. Yeah.

1221
01:08:43,125 --> 01:08:45,885
Speaker 2:  I, in the mid, it was 70 degrees in California. I was watching people try

1222
01:08:45,885 --> 01:08:48,565
Speaker 2:  to sell me a snowblower. I was like, I don't, maybe I travel too much for

1223
01:08:48,565 --> 01:08:48,685
Speaker 2:  work.

1224
01:08:48,765 --> 01:08:52,725
Speaker 6:  I can't watch QVC because one time in the nineties I watched an episode of

1225
01:08:52,725 --> 01:08:56,485
Speaker 6:  Mama's Family where she got addicted to QVC. That's bad. And,

1226
01:08:56,545 --> 01:09:00,165
Speaker 6:  and the family had to be like, you can't use QVC anymore. And for whatever

1227
01:09:00,165 --> 01:09:03,485
Speaker 6:  reason I was like, me too. Yeah. As like a five-year-old

1228
01:09:04,705 --> 01:09:08,565
Speaker 2:  The end. I will tell one more QVC related story. My dad was

1229
01:09:08,565 --> 01:09:12,365
Speaker 2:  the overnight doctor in the ER in Wisconsin. So he would

1230
01:09:12,365 --> 01:09:15,445
Speaker 2:  come, he wouldn't be able to sleep at night when he wasn't working right.

1231
01:09:15,445 --> 01:09:18,325
Speaker 2:  Because he was used to being up all night. Boy did we have a lot of stuff

1232
01:09:18,325 --> 01:09:18,765
Speaker 2:  in my house.

1233
01:09:20,465 --> 01:09:23,445
Speaker 2:  Boy did I grow up eating a lot of dehydrated apples. The

1234
01:09:23,445 --> 01:09:27,045
Speaker 6:  Only thing on TV at that time of night, like, what are you gonna watch? Oh,

1235
01:09:27,045 --> 01:09:30,605
Speaker 2:  I did it again six to eight weeks later in the eighties, we got a food

1236
01:09:30,605 --> 01:09:33,125
Speaker 2:  dehydrator. It was great.

1237
01:09:33,345 --> 01:09:35,205
Speaker 6:  The fruit leather is in incredible at

1238
01:09:35,215 --> 01:09:38,685
Speaker 2:  House. He was so proud of that food dehydrator. It was just a circle with

1239
01:09:38,725 --> 01:09:41,765
Speaker 2:  a fan. I just, I don't know If you ever actually looked at it? Nevermind.

1240
01:09:41,875 --> 01:09:42,165
Speaker 2:  Yeah,

1241
01:09:42,435 --> 01:09:42,805
Speaker 6:  I've seen

1242
01:09:42,805 --> 01:09:46,445
Speaker 2:  One. They're like, we took the hair dryer and now we've pointed it up. It's

1243
01:09:46,445 --> 01:09:48,045
Speaker 2:  a food dehydrator. You

1244
01:09:48,125 --> 01:09:49,045
Speaker 6:  Get fruit leather.

1245
01:09:49,155 --> 01:09:51,965
Speaker 2:  This is by the way, the Dyson story is they invented a fan and now they only

1246
01:09:51,965 --> 01:09:55,565
Speaker 2:  make fan related products. It's very good. Okay. Other news,

1247
01:09:56,615 --> 01:09:58,385
Speaker 2:  Spotify now has music videos.

1248
01:10:01,005 --> 01:10:01,925
Speaker 6:  I I don't subscribe.

1249
01:10:02,685 --> 01:10:02,905
Speaker 5:  Oh

1250
01:10:02,905 --> 01:10:06,585
Speaker 6:  My God. Sorry. I, I'm excited for you all. I'm excited for everyone who

1251
01:10:06,905 --> 01:10:10,385
Speaker 6:  subscribes and loves a music video. I just open YouTube

1252
01:10:10,725 --> 01:10:14,665
Speaker 6:  on my TV in a tiny box next to below a bunch of sales links

1253
01:10:15,085 --> 01:10:16,985
Speaker 6:  and, and watch my music videos that way. That's

1254
01:10:16,985 --> 01:10:20,545
Speaker 5:  True. You're gonna be able to buy all the cars and beers

1255
01:10:21,045 --> 01:10:24,985
Speaker 5:  and liquors and hats that you see in every music video for the

1256
01:10:24,985 --> 01:10:26,585
Speaker 5:  rest of your life. Alex, are you so excited?

1257
01:10:26,815 --> 01:10:28,425
Speaker 6:  It's gonna be really, really great for me.

1258
01:10:28,765 --> 01:10:32,625
Speaker 5:  No, I think the, the music that he was saying, like, it turns out that every

1259
01:10:32,935 --> 01:10:36,865
Speaker 5:  streaming story right now is kind of a TikTok story. Like, and

1260
01:10:36,865 --> 01:10:40,185
Speaker 5:  we've talked about it a bunch on this show in recent weeks, right? Like this

1261
01:10:40,305 --> 01:10:43,825
Speaker 5:  question of like, okay, Universal's in a big fight with TikTok, TikTok,

1262
01:10:44,045 --> 01:10:47,345
Speaker 5:  TikTok might be having an existential crisis, whether it's gonna continue

1263
01:10:47,345 --> 01:10:51,305
Speaker 5:  to exist, who is going to show up and say, oh, all the music

1264
01:10:51,305 --> 01:10:54,905
Speaker 5:  videos you wanna watch, which are a gigantic portion of what is

1265
01:10:54,905 --> 01:10:58,505
Speaker 5:  successful on the internet as a whole. And Spotify

1266
01:10:58,685 --> 01:11:01,705
Speaker 5:  is like, yeah, we'll do it. But Spotify is doing it in like the slowest,

1267
01:11:01,705 --> 01:11:05,505
Speaker 5:  weirdest way. They have like a tiny number of artists and a few videos and

1268
01:11:05,505 --> 01:11:09,425
Speaker 5:  it's like, guys, it's not actually that hard to put videos into your

1269
01:11:09,445 --> 01:11:13,205
Speaker 5:  app Spotify. Like, kudos for trying I

1270
01:11:13,205 --> 01:11:16,325
Speaker 5:  suppose, but like If, you, If you really wanted to do this, do it

1271
01:11:16,325 --> 01:11:20,165
Speaker 2:  Better. Also, apple has had music videos forever. It's not a great player,

1272
01:11:20,195 --> 01:11:23,245
Speaker 2:  it's not a cool experience. But if you're ever bored on your Apple TV and

1273
01:11:23,245 --> 01:11:25,805
Speaker 2:  your Apple Music subscriber, you can just be like, show me music videos and

1274
01:11:25,805 --> 01:11:27,845
Speaker 2:  we'll just play a playlist of music videos. Or you can open

1275
01:11:27,845 --> 01:11:30,725
Speaker 6:  The YouTube app and and do it there.

1276
01:11:30,925 --> 01:11:34,685
Speaker 5:  I do think though this thing where that, that YouTube music

1277
01:11:34,685 --> 01:11:37,645
Speaker 5:  does very well and no one else does very well. Where you can sort of seamlessly

1278
01:11:37,645 --> 01:11:41,405
Speaker 5:  switch from video to song is very cool. And I think that's what Spotify is

1279
01:11:41,405 --> 01:11:45,325
Speaker 5:  going for here too. But Spotify is just like desperate to be an app that

1280
01:11:45,325 --> 01:11:49,085
Speaker 5:  you look at more because they want you to subscribe, discover

1281
01:11:49,085 --> 01:11:51,565
Speaker 5:  more stuff, pay them money and like look at ads,

1282
01:11:53,345 --> 01:11:57,245
Speaker 5:  but they just aren't gonna get there. Right? Yeah.

1283
01:11:57,245 --> 01:11:59,805
Speaker 5:  Like remember what was it like a year ago when they basically like redesigned

1284
01:11:59,805 --> 01:12:02,405
Speaker 5:  the whole app to be TikTok and everybody was like, no thanks. Like I just

1285
01:12:02,405 --> 01:12:06,245
Speaker 5:  wanna play a song and then put my phone away. And I think they just, they're,

1286
01:12:06,525 --> 01:12:08,405
Speaker 5:  I don't think they're ever gonna escape that. Honestly.

1287
01:12:08,845 --> 01:12:11,925
Speaker 6:  I think Spotify is gonna buy Paramount Plus that's who's gonna do it

1288
01:12:12,745 --> 01:12:13,525
Speaker 6:  Solves everything

1289
01:12:14,355 --> 01:12:16,045
Speaker 2:  Done after Netflix collapses

1290
01:12:18,385 --> 01:12:21,885
Speaker 2:  in other Spotify news. Yeah. Neil Young has returned to Spotify.

1291
01:12:22,225 --> 01:12:24,605
Speaker 2:  I'm pretty sure this is only on the list. So we can reference the time that

1292
01:12:24,605 --> 01:12:27,325
Speaker 2:  Neil Young was on The Vergecast and describes

1293
01:12:27,515 --> 01:12:28,965
Speaker 6:  With his little, with his little player

1294
01:12:29,155 --> 01:12:32,885
Speaker 2:  With the pono. And he described the MacBook to me as Fisher price

1295
01:12:32,885 --> 01:12:35,365
Speaker 2:  quality and said, your new engineer is Captain Kangaroo.

1296
01:12:36,775 --> 01:12:39,335
Speaker 2:  I think we can just run the clips, Andrew, I don't think we have to say anything

1297
01:12:39,335 --> 01:12:42,895
Speaker 2:  else about this. Okay. That man really cares about sound quality.

1298
01:12:43,405 --> 01:12:46,255
Speaker 2:  Very confused about how digital audio sampling works

1299
01:12:47,125 --> 01:12:50,735
Speaker 2:  refuses to acknowledge that. It's very hard to hear the difference at a

1300
01:12:50,735 --> 01:12:54,575
Speaker 2:  appropriate bit rate and thinks that, and I just

1301
01:12:54,575 --> 01:12:58,295
Speaker 2:  wanna say it, the Mac, he thinks the MacBook Pro is a piece of crap,

1302
01:12:58,435 --> 01:13:00,775
Speaker 2:  but an actual quote that we can run now it's

1303
01:13:00,775 --> 01:13:04,215
Speaker 12:  A piece of crap. Are you kidding? That's Fisher price quality.

1304
01:13:04,515 --> 01:13:08,135
Speaker 12:  That's like Captain Kangaroo your new engineer, the

1305
01:13:08,135 --> 01:13:11,575
Speaker 12:  MacBook Pro. What are you talking about? You can't, you can't get anything

1306
01:13:11,575 --> 01:13:12,255
Speaker 12:  out of that thing.

1307
01:13:12,795 --> 01:13:15,175
Speaker 2:  All right, there you go, everybody. Fantastic. That was Neil. Young. Thanks

1308
01:13:15,175 --> 01:13:15,335
Speaker 2:  Neil.

1309
01:13:15,795 --> 01:13:16,775
Speaker 5:  No notes. Neil Young.

1310
01:13:18,335 --> 01:13:21,135
Speaker 2:  Well even, even Neil has caved to Spotify. Yeah,

1311
01:13:21,895 --> 01:13:23,735
Speaker 6:  Everyone does eventually. Well not me,

1312
01:13:24,595 --> 01:13:28,535
Speaker 5:  But it is, I I just appreciate the logic that like, he left, he

1313
01:13:28,535 --> 01:13:32,375
Speaker 5:  was the, the like loud protester to Joe Rogan, right? Right. When he

1314
01:13:32,375 --> 01:13:35,495
Speaker 5:  signed a huge deal at Spotify. Neil Young was like, I can't be on this platform.

1315
01:13:35,715 --> 01:13:39,655
Speaker 5:  And then Joe Rogan got an even bigger but now

1316
01:13:39,885 --> 01:13:43,655
Speaker 5:  non-exclusive deal. So he's now everywhere. And Neil

1317
01:13:43,655 --> 01:13:46,255
Speaker 5:  Young's like, well, shit, I gotta, I gotta sell music somewhere.

1318
01:13:46,565 --> 01:13:50,535
Speaker 6:  It's like, I do enjoy those royalties. Guess I'm stuck. Yeah, those

1319
01:13:50,555 --> 01:13:50,935
Speaker 6:  are nice.

1320
01:13:51,475 --> 01:13:54,575
Speaker 5:  Go beyond. Go beyond like title. I don't think they have podcasts.

1321
01:13:54,755 --> 01:13:58,535
Speaker 2:  Oh my god. Neil's young website. It's so bananas. It's, it's

1322
01:13:58,535 --> 01:13:58,855
Speaker 2:  amazing.

1323
01:13:58,855 --> 01:13:59,455
Speaker 6:  Incredible.

1324
01:14:00,295 --> 01:14:04,135
Speaker 2:  I wanted to read the blog post about his return to Spotify, but it

1325
01:14:04,135 --> 01:14:07,935
Speaker 2:  appears to be down. And also NELI Young's website is fully insane and

1326
01:14:07,935 --> 01:14:11,540
Speaker 2:  looks like an old time newspaper from the Wild West. It's so, so good. It's

1327
01:14:11,540 --> 01:14:14,285
Speaker 2:  incredible. It does have a full res audio player on it with a switch that

1328
01:14:14,285 --> 01:14:18,165
Speaker 2:  says Master. Yeah. Your choices are low res MP three or master

1329
01:14:18,165 --> 01:14:22,125
Speaker 2:  quality. I love it. It's very good. I, again, I love Neil Young. If we just,

1330
01:14:22,125 --> 01:14:25,205
Speaker 2:  you'll listen to episode of To Vergecast after these clips. All of it was

1331
01:14:25,205 --> 01:14:28,765
Speaker 2:  astounding. I'm rarely taken aback the way that Neil Young

1332
01:14:28,955 --> 01:14:32,765
Speaker 2:  took me aback when I was like, so computers exist and he was like, kill yourself.

1333
01:14:37,505 --> 01:14:38,645
Speaker 6:  Get this little music player.

1334
01:14:38,905 --> 01:14:42,285
Speaker 2:  All right. Last bit of video news. I'm just gonna say it. It's about Twitter.

1335
01:14:42,425 --> 01:14:42,645
Speaker 2:  Mm.

1336
01:14:43,105 --> 01:14:44,605
Speaker 6:  Or X You mean X? Yeah. X

1337
01:14:45,335 --> 01:14:49,325
Speaker 2:  Linda. Yaccarino. Everyone's favorite. Yeah.

1338
01:14:49,845 --> 01:14:53,485
Speaker 2:  Composed Stable Media executive. That's wonderful. Continues to say

1339
01:14:53,725 --> 01:14:56,205
Speaker 2:  X is becoming a video first platform because

1340
01:14:56,585 --> 01:14:58,205
Speaker 6:  You get more money from ads.

1341
01:14:58,875 --> 01:15:02,805
Speaker 2:  Yeah. I, when I look around the social media industry and the media

1342
01:15:03,085 --> 01:15:06,805
Speaker 2:  industry, I can confidently say that the pivot to video has worked out

1343
01:15:06,805 --> 01:15:10,125
Speaker 2:  super great for everyone every time and all these companies are doing great

1344
01:15:10,125 --> 01:15:11,285
Speaker 2:  and not doing layoffs. Yep.

1345
01:15:11,715 --> 01:15:15,165
Speaker 6:  Totally. Very, very accurate thing you said. Yeah.

1346
01:15:15,505 --> 01:15:18,645
Speaker 2:  Not, not the biggest companies in the world are super not doing layoffs because

1347
01:15:18,645 --> 01:15:21,285
Speaker 2:  video is totally great for them. And then

1348
01:15:22,405 --> 01:15:26,085
Speaker 2:  everyone's favorite Free Speech Warrior Elon Musk signed

1349
01:15:26,265 --> 01:15:30,255
Speaker 2:  Don Lemon to do a show on XI think he thought

1350
01:15:30,255 --> 01:15:33,375
Speaker 2:  Don Lemon would be sort of the, the counterpart to Tucker Carlson who does

1351
01:15:33,375 --> 01:15:36,935
Speaker 2:  a show on X Don Lemon said, okay, Elon, it'll be my first interview.

1352
01:15:37,645 --> 01:15:41,375
Speaker 2:  They did an interview. We, we saw a tiny little clip of the interview.

1353
01:15:41,655 --> 01:15:41,775
Speaker 2:  I

1354
01:15:41,775 --> 01:15:43,295
Speaker 6:  Couldn't finish watching the clip.

1355
01:15:43,795 --> 01:15:47,295
Speaker 2:  The clip is Don Lemon saying, don't you think you have to answer to reporters

1356
01:15:47,295 --> 01:15:51,015
Speaker 2:  for like hate speech on the platform? Yeah. And Elon saying, I don't have

1357
01:15:51,015 --> 01:15:53,895
Speaker 2:  to talk to reporters, I'm only talking to you because you're on the X platform,

1358
01:15:53,985 --> 01:15:57,935
Speaker 2:  which is very funny. Okay. Deal canceled. Yeah. And

1359
01:15:57,935 --> 01:16:01,895
Speaker 2:  we talked about this I believe last week, but in classic Elon

1360
01:16:01,895 --> 01:16:05,735
Speaker 2:  Musk fashion, there was no actual contract. Mm. So now

1361
01:16:05,795 --> 01:16:09,255
Speaker 2:  Don Lemon is out there threatening to sue x

1362
01:16:09,955 --> 01:16:13,895
Speaker 2:  Yes. For a contract that doesn't exist. And I just want all

1363
01:16:13,895 --> 01:16:17,735
Speaker 2:  of these people, If, you are somewhere around Elon Musk. Just write some

1364
01:16:17,735 --> 01:16:21,375
Speaker 2:  stuff down and sign it on a napkin.

1365
01:16:21,915 --> 01:16:25,815
Speaker 2:  All right. In the notes app, have him take a sharpie to your phone and

1366
01:16:25,815 --> 01:16:28,975
Speaker 2:  sign your phone. After showing him the contract on a notes app,

1367
01:16:29,735 --> 01:16:33,495
Speaker 2:  anything is better than the current situation where people just vibe deal

1368
01:16:33,495 --> 01:16:34,175
Speaker 2:  with Elon.

1369
01:16:34,695 --> 01:16:36,215
Speaker 6:  Yeah. Don't, don't vibe deal. No

1370
01:16:36,215 --> 01:16:37,415
Speaker 2:  Vibe. Please. I beg of you.

1371
01:16:38,525 --> 01:16:39,655
Speaker 6:  What about Handshake

1372
01:16:40,195 --> 01:16:43,775
Speaker 2:  Anyway? No, no, no. No Vibes. Handshakes are the ultimate vibes.

1373
01:16:43,885 --> 01:16:47,055
Speaker 6:  Okay. Sorry. I wanted to make sure, I wanted to like, I wanted to double

1374
01:16:47,055 --> 01:16:49,775
Speaker 6:  check. I felt that way. but I don, like I needed to check

1375
01:16:49,775 --> 01:16:53,095
Speaker 2:  In. Yeah. Handshakes. They should give that to you in law school. Okay. Handshakes

1376
01:16:53,095 --> 01:16:54,135
Speaker 2:  are the ultimate vibes. All

1377
01:16:54,135 --> 01:16:55,855
Speaker 6:  Right. That's a, that's a class actually. Like

1378
01:16:55,995 --> 01:16:58,695
Speaker 2:  No one really knows what's happening on the other side of that handshake.

1379
01:17:00,125 --> 01:17:02,575
Speaker 6:  Well, I mean, not a contract in, in Elon's case,

1380
01:17:03,105 --> 01:17:04,695
Speaker 2:  Never a contract. In Elon's case,

1381
01:17:04,945 --> 01:17:08,415
Speaker 5:  Handshakes are the ultimate vibes, by the way, is algorithmic warfare's first

1382
01:17:08,415 --> 01:17:12,045
Speaker 5:  album title. And it's like surf rock and a variant

1383
01:17:12,115 --> 01:17:12,405
Speaker 2:  Type.

1384
01:17:14,625 --> 01:17:18,325
Speaker 2:  Anyhow, it's very funny that Elon claims that he's a free speech absolutist

1385
01:17:18,765 --> 01:17:22,565
Speaker 2:  canceled the deal over the most minor of questions when you run

1386
01:17:22,645 --> 01:17:24,005
Speaker 2:  a giant platform with speech on it.

1387
01:17:24,435 --> 01:17:28,405
Speaker 5:  Yeah. That interview supposedly running on Monday.

1388
01:17:28,845 --> 01:17:32,805
Speaker 5:  I am going to watch as much of it as I can physically stomach.

1389
01:17:33,445 --> 01:17:35,365
Speaker 6:  I, I started it and, and

1390
01:17:35,745 --> 01:17:36,725
Speaker 2:  You started just that clip.

1391
01:17:36,885 --> 01:17:40,685
Speaker 6:  I started the clip. Don spoke Elon started to talk

1392
01:17:40,785 --> 01:17:44,285
Speaker 6:  and like everything about it, I was like, oh, I'm just cringing

1393
01:17:44,585 --> 01:17:48,245
Speaker 6:  so hard. I can't even finish hearing him. Like finish the sentence.

1394
01:17:48,245 --> 01:17:52,165
Speaker 5:  Yeah. Just the awkwardness alone is, is tough. It was, but we'll

1395
01:17:52,165 --> 01:17:52,245
Speaker 5:  see.

1396
01:17:52,275 --> 01:17:56,205
Speaker 2:  Yeah. Yeah. I, here's one thing I'll say. Many people can have

1397
01:17:56,205 --> 01:18:00,125
Speaker 2:  many opinions of Don Lemon. Elon mostly signed all those deals with

1398
01:18:00,125 --> 01:18:04,005
Speaker 2:  journalists who treat him like he has all the answers. Tucker in his

1399
01:18:04,005 --> 01:18:07,005
Speaker 2:  interviews with Elon treats him like all the answers. Matt Taibbi treats

1400
01:18:07,005 --> 01:18:09,485
Speaker 2:  him like, you're letting me do this thing with all the answers. This is the

1401
01:18:09,485 --> 01:18:13,405
Speaker 2:  first time I think anyone's straight up been like, so there's a

1402
01:18:13,405 --> 01:18:15,925
Speaker 2:  lot of racism here. Are you accountable for it? And he just didn't know what

1403
01:18:15,925 --> 01:18:16,485
Speaker 2:  to do. Yeah.

1404
01:18:17,035 --> 01:18:19,285
Speaker 6:  Elon does not like to be asked questions.

1405
01:18:20,525 --> 01:18:20,815
Speaker 2:  Yeah.

1406
01:18:21,485 --> 01:18:21,775
Speaker 6:  Yeah.

1407
01:18:22,395 --> 01:18:23,575
Speaker 5:  End of sentence, end of

1408
01:18:23,775 --> 01:18:27,415
Speaker 6:  Sentence. He just, he he doesn't like to be pushed ever. Like do, do not

1409
01:18:27,415 --> 01:18:31,255
Speaker 6:  push him. That's a good way to have your, your vibes deal. Un

1410
01:18:31,255 --> 01:18:31,495
Speaker 6:  vibe.

1411
01:18:32,765 --> 01:18:36,535
Speaker 2:  Just sign contracts. If there's one thing I I just beg of you If you it,

1412
01:18:36,635 --> 01:18:39,815
Speaker 2:  it protects both parties. It's not, alright, we gotta take a break

1413
01:18:41,015 --> 01:18:44,575
Speaker 2:  here. There are form contracts available online. Alright.

1414
01:18:45,085 --> 01:18:47,055
Speaker 2:  Just those will be fine. Anything.

1415
01:18:48,785 --> 01:18:49,495
Speaker 2:  We'll be right back.

1416
01:18:51,675 --> 01:18:52,405
Speaker 13:  This episode

1417
01:20:06,125 --> 01:20:09,925
Speaker 15:  visit kia.com/nine to learn more. Ask your Kia

1418
01:20:09,925 --> 01:20:13,725
Speaker 15:  dealer for availability. No system, no matter how advanced can compensate

1419
01:20:13,725 --> 01:20:17,245
Speaker 15:  for all driver error and or driving conditions, always drive safely.

1420
01:20:22,745 --> 01:20:25,085
Speaker 2:  All right, we're back. Lightning round. We gotta make this fact we are way

1421
01:20:25,085 --> 01:20:28,605
Speaker 2:  over. This has been a deep Vergecast. We did food

1422
01:20:28,605 --> 01:20:32,445
Speaker 2:  dehydrating, we did Elon Musk hour on the First Amendment.

1423
01:20:32,515 --> 01:20:36,165
Speaker 2:  Chinese interference. We talked about motor trend tv. I just wanna say

1424
01:20:36,175 --> 01:20:39,885
Speaker 2:  we've been everywhere. This is why you come here. Yeah. And now it's

1425
01:20:39,885 --> 01:20:41,725
Speaker 2:  lightning around. And David says he has a sponsor.

1426
01:20:42,025 --> 01:20:46,005
Speaker 5:  Yes. So at South by Southwest, a friend

1427
01:20:46,005 --> 01:20:49,965
Speaker 5:  of The Vergecast named Simon came and it was his birthday and his big

1428
01:20:49,965 --> 01:20:53,725
Speaker 5:  plan was when we said it was lightning round time to scream. It's my

1429
01:20:53,885 --> 01:20:57,125
Speaker 5:  birthday and I'm sponsoring The Vergecast. We didn't do a lightning round

1430
01:20:57,265 --> 01:21:00,925
Speaker 5:  and he came up to me like full devastated. Oh no, no. So Simon

1431
01:21:00,935 --> 01:21:02,885
Speaker 5:  today is sponsoring the lightning round.

1432
01:21:03,035 --> 01:21:03,685
Speaker 6:  Hell yeah. Simon,

1433
01:21:03,685 --> 01:21:04,605
Speaker 2:  Happy birthday Simon.

1434
01:21:04,775 --> 01:21:06,485
Speaker 5:  Simon. We love you. Happy birthday.

1435
01:21:06,905 --> 01:21:09,765
Speaker 2:  All right. For your lightning round, Cranz is gonna talk about the British

1436
01:21:09,805 --> 01:21:10,365
Speaker 2:  monarchy.

1437
01:21:11,275 --> 01:21:13,005
Speaker 6:  Yeah. Oh my God. You're welcome.

1438
01:21:13,215 --> 01:21:15,805
Speaker 5:  We're so long into the show to just be getting into this now.

1439
01:21:16,555 --> 01:21:20,165
Speaker 6:  Well, it's okay because this is gonna be I think the shortest, what is a

1440
01:21:20,165 --> 01:21:24,085
Speaker 6:  photo one we've ever had? NELI will not be talking. He

1441
01:21:24,085 --> 01:21:26,805
Speaker 6:  will simply be sighing loudly the get tired.

1442
01:21:27,405 --> 01:21:28,285
Speaker 2:  I hate the story so much.

1443
01:21:28,835 --> 01:21:32,725
Speaker 6:  It's so good. Yeah. So, so Kate Middleton

1444
01:21:32,905 --> 01:21:36,325
Speaker 6:  has been out of public view. Who she, she's she's just some, she's a lady

1445
01:21:36,865 --> 01:21:40,565
Speaker 6:  who gets a lot of money to live in England and look pretty very good

1446
01:21:41,225 --> 01:21:45,165
Speaker 6:  and, and she has been out of the public view and there's been a

1447
01:21:45,165 --> 01:21:49,085
Speaker 6:  lot of theories about it. And then a relatively recently

1448
01:21:49,325 --> 01:21:52,485
Speaker 6:  a Spanish journalist who at one point said

1449
01:21:53,815 --> 01:21:57,315
Speaker 6:  out of pocket things about Michael Jackson and how he was probably murdered.

1450
01:21:57,615 --> 01:21:57,835
Speaker 6:  Wow.

1451
01:21:58,045 --> 01:22:00,675
Speaker 5:  Where are we going with this? Yeah. Oh boy.

1452
01:22:00,895 --> 01:22:04,675
Speaker 6:  She said Kate Middleton is in a coma. And, and then, and then

1453
01:22:04,855 --> 01:22:08,755
Speaker 6:  the, the the, the royals came back and said she's not, and that's very

1454
01:22:08,755 --> 01:22:12,155
Speaker 6:  unusual 'cause they usually don't re respond to like absolutely insane stupid

1455
01:22:12,155 --> 01:22:15,955
Speaker 6:  stuff. And so everybody's like, where is she then? So they released

1456
01:22:15,955 --> 01:22:19,835
Speaker 6:  this photo and apparently Kate herself has claimed that she

1457
01:22:19,835 --> 01:22:23,515
Speaker 6:  did the Photoshop job, but someone did it and they did a piss

1458
01:22:23,545 --> 01:22:24,155
Speaker 6:  poor job.

1459
01:22:24,425 --> 01:22:28,275
Speaker 5:  Wait, can I ask when the first time either of you saw this photo and

1460
01:22:28,275 --> 01:22:31,555
Speaker 5:  NELI, I know you follow her on Instagram, so you saw it. She's in your close

1461
01:22:31,555 --> 01:22:33,435
Speaker 5:  friend circle. So I know You saw it very quickly.

1462
01:22:33,675 --> 01:22:37,075
Speaker 2:  I only pretend to not care about the British monarchy because Kate and I

1463
01:22:37,075 --> 01:22:38,115
Speaker 2:  have been involved for several years.

1464
01:22:40,175 --> 01:22:40,595
Speaker 6:  That's

1465
01:22:40,595 --> 01:22:42,995
Speaker 5:  Very true. Everyone has seen this photo. I don't feel like I need to describe

1466
01:22:42,995 --> 01:22:46,555
Speaker 5:  it, but If, you If you haven't go, go to the internet, it will find

1467
01:22:46,555 --> 01:22:49,835
Speaker 2:  You. No. Continue living your life in peace. Under

1468
01:22:49,855 --> 01:22:53,675
Speaker 5:  No circumstances should you pull over your car and look for this image. But

1469
01:22:53,975 --> 01:22:57,875
Speaker 5:  did either of you clock this as like weird in any way?

1470
01:22:57,875 --> 01:22:59,275
Speaker 5:  Yes, a hundred percent. Did you Right away.

1471
01:22:59,275 --> 01:23:02,315
Speaker 6:  Okay. Like I looked at it and I was like, why does every like, they all look

1472
01:23:02,315 --> 01:23:04,715
Speaker 6:  like they have AI faces. Like they're all smiling the

1473
01:23:04,715 --> 01:23:06,125
Speaker 2:  Same weird day. Oh, interesting. You must, you went that far.

1474
01:23:06,195 --> 01:23:09,605
Speaker 6:  Yeah. And then I didn't like to get to like zoom in and everything and I

1475
01:23:09,605 --> 01:23:12,485
Speaker 6:  didn't realize it was a story 'cause I had to get on a flight and So I was

1476
01:23:12,485 --> 01:23:15,565
Speaker 6:  like, this is so stupid. And I sent it to all my friends who we talk sometimes

1477
01:23:15,565 --> 01:23:16,445
Speaker 6:  talk about royal stuff.

1478
01:23:16,665 --> 01:23:19,445
Speaker 2:  One of it's okay, it's just me. Every you are, it's okay. Other people are

1479
01:23:19,445 --> 01:23:20,205
Speaker 2:  allowed to care about royal.

1480
01:23:20,405 --> 01:23:24,045
Speaker 6:  I don't actually care that much. I have a lot of friends who do Sonos.

1481
01:23:24,045 --> 01:23:27,125
Speaker 2:  Like we have a lot of staffers who care about this the most. And

1482
01:23:27,125 --> 01:23:27,285
Speaker 6:  It's,

1483
01:23:27,285 --> 01:23:29,965
Speaker 5:  It's great. Ironically, none of our British staffers just a bunch

1484
01:23:30,665 --> 01:23:32,125
Speaker 6:  Ofs only Americans. It's only the

1485
01:23:32,125 --> 01:23:35,645
Speaker 2:  Ex. The farther away you live from England, the more it appears you care

1486
01:23:35,645 --> 01:23:36,445
Speaker 2:  about this. That's

1487
01:23:36,445 --> 01:23:37,445
Speaker 6:  True. True. Actually,

1488
01:23:37,685 --> 01:23:41,125
Speaker 2:  I wonder if it keeps that keeps going. So If, you circle around the Pacific

1489
01:23:41,135 --> 01:23:42,925
Speaker 2:  Ocean, you start caring about it less again. You

1490
01:23:42,925 --> 01:23:46,405
Speaker 5:  Get to Japan and everybody's like up in arms about Kate Middleton Could be.

1491
01:23:47,345 --> 01:23:51,125
Speaker 6:  But yeah, no, it was, it was clear to me like something was weird in the

1492
01:23:51,125 --> 01:23:54,605
Speaker 6:  photo. 'cause her head was enormous. I was like, why is her head so huge

1493
01:23:54,605 --> 01:23:58,525
Speaker 6:  in this picture? And and it turns out because the whole, most of

1494
01:23:58,525 --> 01:24:02,405
Speaker 6:  it was photoshopped. We don't know entirely how much Kate later

1495
01:24:02,405 --> 01:24:06,005
Speaker 6:  dropped like a, a thing being like, I just love to mess around with Photoshop.

1496
01:24:06,215 --> 01:24:10,085
Speaker 6:  Still no photo of her. The only photo we've seen is a picture of her husband

1497
01:24:10,115 --> 01:24:14,005
Speaker 6:  driving and there was a woman looking away when the photo was

1498
01:24:14,005 --> 01:24:17,125
Speaker 6:  taken and they said, that's Kate, that's good. And it's like, mm. It's it

1499
01:24:17,145 --> 01:24:20,845
Speaker 6:  so unclear where she is unclear she's alive.

1500
01:24:20,845 --> 01:24:23,325
Speaker 2:  Can I, can I answer the one question? Yeah. Not a photo.

1501
01:24:23,945 --> 01:24:26,165
Speaker 6:  Not a photo. You think so? Yeah. Yeah. 'cause a

1502
01:24:26,165 --> 01:24:29,765
Speaker 2:  Photoshop just straightforwardly. Not a moment in time. Yeah,

1503
01:24:29,865 --> 01:24:33,125
Speaker 6:  It was, that was my big question is yeah, what is a photo? Is this a photo?

1504
01:24:33,305 --> 01:24:35,165
Speaker 6:  And it feels like No, and what's cool is

1505
01:24:37,115 --> 01:24:40,995
Speaker 6:  everyone else agrees, including all of like the, the, the, the press everybody

1506
01:24:41,065 --> 01:24:44,995
Speaker 6:  like AP Reuters, everybody said, yeah, we're not gonna carry this photo because

1507
01:24:45,025 --> 01:24:48,755
Speaker 6:  it's not a photo and it's been manipulated and, and so

1508
01:24:49,305 --> 01:24:53,195
Speaker 6:  yeah. Very definitive. Not a photo everybody clocked in. I love how

1509
01:24:53,195 --> 01:24:54,995
Speaker 6:  many people clocked in. I love how quickly like

1510
01:24:55,855 --> 01:24:59,795
Speaker 2:  And I will that the, the misinformation on the social media

1511
01:25:00,035 --> 01:25:01,995
Speaker 2:  platforms about what's been edited here is out of control. That's so the

1512
01:25:01,995 --> 01:25:05,675
Speaker 2:  number of people who think is AI is very high. The number of people who've

1513
01:25:05,675 --> 01:25:06,075
Speaker 2:  decided,

1514
01:25:07,815 --> 01:25:09,955
Speaker 2:  what's it like a magazine cover? Yeah.

1515
01:25:09,955 --> 01:25:12,355
Speaker 5:  It was a Vogue cover I think from years ago. And it's like,

1516
01:25:12,415 --> 01:25:13,795
Speaker 2:  You know, that's use the face, her

1517
01:25:13,795 --> 01:25:14,075
Speaker 6:  Face.

1518
01:25:14,465 --> 01:25:18,355
Speaker 2:  It's like it's nowhere close to being the same face. Yeah, no, it's,

1519
01:25:18,425 --> 01:25:19,315
Speaker 2:  it's just at an angle.

1520
01:25:19,695 --> 01:25:23,195
Speaker 5:  It is very funny. You see them side by side and it's, it's the same person

1521
01:25:23,615 --> 01:25:27,315
Speaker 5:  making what amounts to essentially two totally different faces. And everybody's

1522
01:25:27,315 --> 01:25:29,595
Speaker 5:  like, they swapped them and it's like, no, they super

1523
01:25:29,595 --> 01:25:33,395
Speaker 2:  Didn't. But the heart of the what is a photo debate? The the,

1524
01:25:33,855 --> 01:25:37,635
Speaker 2:  the heart of it is If. you take a long sequence of

1525
01:25:37,635 --> 01:25:41,595
Speaker 2:  photos over a period of time and synthesize one moment in time

1526
01:25:41,595 --> 01:25:45,415
Speaker 2:  that never happened. But con that contains all the other moments in time.

1527
01:25:45,635 --> 01:25:48,615
Speaker 2:  Is that a photo that's the heart of Yeah. The right, like

1528
01:25:49,235 --> 01:25:53,095
Speaker 2:  iPhone smart HDR or whatever they call it now, the photonic engine

1529
01:25:53,945 --> 01:25:57,855
Speaker 2:  takes, you know, eight frames and synthesizes one exposure

1530
01:25:58,155 --> 01:25:58,375
Speaker 2:  and

1531
01:25:58,375 --> 01:25:59,135
Speaker 6:  That's what Kate did.

1532
01:25:59,555 --> 01:26:02,895
Speaker 2:  But she, but the eight frames happened like over five years. you know, it's

1533
01:26:02,895 --> 01:26:04,565
Speaker 2:  like, like that's not the same thing.

1534
01:26:04,865 --> 01:26:06,765
Speaker 6:  Is that even her kids who can say

1535
01:26:07,425 --> 01:26:10,685
Speaker 2:  The reason you asked and I said I clocked it right away, is I have but one

1536
01:26:10,695 --> 01:26:14,485
Speaker 2:  child in getting her to look at the camera and smile is

1537
01:26:14,485 --> 01:26:17,765
Speaker 2:  very difficult. And I was like all three of them. No way. Like, just like

1538
01:26:17,765 --> 01:26:20,925
Speaker 2:  immediately I was like, this is in JC Penney shit. Like, no way. And

1539
01:26:21,035 --> 01:26:24,285
Speaker 6:  It's the same smile on all of them. They all look like they have that that's

1540
01:26:24,285 --> 01:26:27,925
Speaker 6:  the Yeah. The filter in TikTok or whatever that makes you smile. That's what

1541
01:26:27,925 --> 01:26:31,765
Speaker 6:  they, they all look like they do. It's horrible. I'm sorry I

1542
01:26:31,765 --> 01:26:33,725
Speaker 6:  had to write about it. I know a lot. We had a lot of

1543
01:26:33,725 --> 01:26:36,045
Speaker 2:  Commenters. I I don't think we should apologize for writing about it. Okay.

1544
01:26:36,045 --> 01:26:38,565
Speaker 6:  You yeah, because I was gonna say we had a lot of commenters say who gives

1545
01:26:38,645 --> 01:26:38,765
Speaker 6:  a

1546
01:26:38,765 --> 01:26:41,565
Speaker 2:  Shit? All those commenters clicked and commented on the story. This is the

1547
01:26:41,565 --> 01:26:45,205
Speaker 2:  top story on our site by a mile. People really care about this. I do not,

1548
01:26:45,245 --> 01:26:49,085
Speaker 2:  I wanna be very clear about this. I'm an Indian American. My people

1549
01:26:49,085 --> 01:26:52,885
Speaker 2:  have escaped the British Royal family twice. We literally kicked these people

1550
01:26:52,905 --> 01:26:56,005
Speaker 2:  out of, out of the countries that I'm from, twice, two different countries

1551
01:26:56,185 --> 01:26:58,605
Speaker 2:  we brought came together. Here I am.

1552
01:26:59,895 --> 01:27:03,565
Speaker 2:  Don't need you and your queen on my money. Get outta here. Like I not

1553
01:27:03,945 --> 01:27:07,925
Speaker 2:  for you. It's a king now. Sure. I didn't even remember that, but I

1554
01:27:07,925 --> 01:27:10,845
Speaker 2:  understand why it's important. Yeah. I understand why so many members of

1555
01:27:10,845 --> 01:27:13,045
Speaker 2:  our staff thinks it's important. I understand why people are reading the

1556
01:27:13,045 --> 01:27:14,485
Speaker 2:  shit out of it. 'cause

1557
01:27:14,485 --> 01:27:15,365
Speaker 6:  It's hysterical.

1558
01:27:15,545 --> 01:27:19,085
Speaker 2:  It just, I am from Westworld and I'm looking literally getting inside and

1559
01:27:19,085 --> 01:27:22,245
Speaker 2:  be like, doesn't look like anything to me. She's like moving on. I

1560
01:27:22,245 --> 01:27:25,685
Speaker 5:  Mean, I do think If, you want to like, there's a really interesting story

1561
01:27:25,735 --> 01:27:29,445
Speaker 5:  about like the media and information sharing

1562
01:27:29,705 --> 01:27:33,565
Speaker 5:  and how we understand what's true and like all of that is fine and good.

1563
01:27:33,565 --> 01:27:36,965
Speaker 5:  And like Liz Lipato I think is in the middle of writing what I assume will

1564
01:27:36,965 --> 01:27:40,045
Speaker 5:  be 35,000 words about the Daily Mail. That will be very good and I'm very

1565
01:27:40,045 --> 01:27:43,925
Speaker 5:  excited to read it. But like I'm with you. It's, it's absolutely

1566
01:27:43,925 --> 01:27:47,725
Speaker 5:  not an AI story and it is pretty much not at all a

1567
01:27:47,725 --> 01:27:50,845
Speaker 5:  what is a photo story because it's a just a hacky Photoshop job that

1568
01:27:51,005 --> 01:27:54,165
Speaker 2:  Somebody did. CNN did a heroic job of trying to make it a what is a p story

1569
01:27:54,555 --> 01:27:55,005
Speaker 5:  They did.

1570
01:27:55,795 --> 01:27:58,245
Speaker 2:  They're like this. And I admire the, this raises the question of what even

1571
01:27:58,265 --> 01:27:59,285
Speaker 2:  is a photo. And I was like, you guys,

1572
01:27:59,385 --> 01:28:02,485
Speaker 5:  And also thank you to everyone who got that push notification and immediately

1573
01:28:02,485 --> 01:28:04,645
Speaker 5:  sent it to us. This is how we know you're our people.

1574
01:28:08,145 --> 01:28:10,685
Speaker 2:  Anyhow. Well, I hope Kate's okay.

1575
01:28:11,035 --> 01:28:14,285
Speaker 6:  Yeah. Who, who, who can say they may be weakened up burning?

1576
01:28:14,505 --> 01:28:15,685
Speaker 2:  She hasn't texted me back.

1577
01:28:15,835 --> 01:28:19,565
Speaker 6:  Yeah. Yeah. What's up with that? Kate? Get to it. Come on. Eli's

1578
01:28:19,565 --> 01:28:20,605
Speaker 2:  Waiting. It's a love affair.

1579
01:28:22,425 --> 01:28:26,275
Speaker 2:  What can I say? This is why I have to pretend to discard,

1580
01:28:26,295 --> 01:28:27,715
Speaker 2:  to disregard the world. I this

1581
01:28:27,715 --> 01:28:31,595
Speaker 6:  Is one of the rumors is that, that he was cheating on her So I

1582
01:28:31,595 --> 01:28:32,475
Speaker 2:  Think the should be a

1583
01:28:32,545 --> 01:28:35,275
Speaker 6:  Yeah, like Kate and I, she got back at him with you. That's,

1584
01:28:35,375 --> 01:28:39,035
Speaker 2:  Wow. I can't even imagine how dismissive my wife will be of this idea.

1585
01:28:40,495 --> 01:28:43,955
Speaker 2:  My actual divorce lawyer wife would be like, nah, that's not true. No,

1586
01:28:44,665 --> 01:28:45,235
Speaker 6:  Shut it down.

1587
01:28:45,935 --> 01:28:49,635
Speaker 2:  That's, that's not the person I married. Okay. Secondhand line round.

1588
01:28:49,995 --> 01:28:53,955
Speaker 2:  I'll just go as promised while we have been recording Starship

1589
01:28:54,455 --> 01:28:58,435
Speaker 2:  II launched, went up to orbit. Okay. Opened some doors to

1590
01:28:58,435 --> 01:29:01,245
Speaker 2:  prove it could open some doors and then it was supposed to splash down.

1591
01:29:02,915 --> 01:29:03,575
Speaker 2:  Did, did not.

1592
01:29:04,245 --> 01:29:07,735
Speaker 5:  Well presumably it did. Just not in the way that everyone was

1593
01:29:07,835 --> 01:29:08,535
Speaker 5:  hoping for.

1594
01:29:08,725 --> 01:29:12,695
Speaker 2:  Well, no, the quote from SpaceX spokesperson that

1595
01:29:12,695 --> 01:29:16,615
Speaker 2:  we have in our story, we haven't heard from the ship up until

1596
01:29:16,615 --> 01:29:19,895
Speaker 2:  this point. And so the team has made the call that the ship has been lost.

1597
01:29:20,275 --> 01:29:21,895
Speaker 2:  So no splash down today. Oh,

1598
01:29:21,895 --> 01:29:24,935
Speaker 5:  You're right. I took that to mean like it's gonna come down. We just don't

1599
01:29:24,935 --> 01:29:27,495
Speaker 5:  know where. But actually what that means is it's still up there somewhere

1600
01:29:27,875 --> 01:29:29,535
Speaker 2:  Or it burned up in the atmosphere or Yeah.

1601
01:29:29,675 --> 01:29:31,655
Speaker 6:  Or it came down and they lost track of it

1602
01:29:31,755 --> 01:29:34,815
Speaker 2:  Or it exploded in some other way. Yeah. So any number of exciting opportunities

1603
01:29:35,235 --> 01:29:36,295
Speaker 2:  for Starship fans. So

1604
01:29:36,355 --> 01:29:37,695
Speaker 6:  As, as successes go,

1605
01:29:38,885 --> 01:29:41,255
Speaker 2:  Well, so much, much more successful

1606
01:29:42,925 --> 01:29:46,735
Speaker 2:  than before. Yeah. When it fully exploded. That's, that's, and then when

1607
01:29:46,735 --> 01:29:49,895
Speaker 2:  the booster exploded, that's fair. This one went all the way up. It did some

1608
01:29:49,895 --> 01:29:51,575
Speaker 2:  planned maneuvers, love and maneuver.

1609
01:29:53,315 --> 01:29:53,815
Speaker 6:  That's it.

1610
01:29:54,475 --> 01:29:57,455
Speaker 2:  And then quote remained in one piece until contact was lost.

1611
01:29:58,175 --> 01:30:01,655
Speaker 5:  I mean I think it's generally true in these cases that getting it down is

1612
01:30:01,655 --> 01:30:02,895
Speaker 5:  the part the Yeah,

1613
01:30:02,895 --> 01:30:04,615
Speaker 2:  That's the part that they worked on the hardest for

1614
01:30:04,615 --> 01:30:08,295
Speaker 6:  The longest. That is the massive engineering problem with it. Yeah. We, we've

1615
01:30:08,295 --> 01:30:08,495
Speaker 6:  gotten really

1616
01:30:08,495 --> 01:30:11,295
Speaker 5:  Good at putting a test like this, like worry about that once you can get

1617
01:30:11,295 --> 01:30:13,695
Speaker 5:  the thing where it's going right. Like let's get it there and then we'll

1618
01:30:13,695 --> 01:30:16,135
Speaker 5:  worry about getting it back. And it seems like the getting it there, we're

1619
01:30:16,135 --> 01:30:17,215
Speaker 5:  getting there. Like that's cool. Yeah.

1620
01:30:17,215 --> 01:30:19,935
Speaker 2:  That's cool. And probably the guy who runs that company,

1621
01:30:20,925 --> 01:30:23,255
Speaker 2:  different guy should run that company. Maybe a thing

1622
01:30:23,255 --> 01:30:24,535
Speaker 5:  That I could, well it should be Don Lemon say

1623
01:30:24,675 --> 01:30:27,535
Speaker 6:  Why does he care if it comes back? He wants to go up and and stay up. So

1624
01:30:27,595 --> 01:30:30,015
Speaker 2:  Go to Mars Elon. Yeah, I think everyone would be happier. It'll be fine.

1625
01:30:30,235 --> 01:30:30,495
Speaker 6:  All right.

1626
01:30:30,805 --> 01:30:34,745
Speaker 5:  Okay. My around. I'm just gonna run away from that as fast I

1627
01:30:34,745 --> 01:30:38,265
Speaker 5:  can. Yeah, I just, I just wanna take you on like a brief emotional rollercoaster

1628
01:30:38,455 --> 01:30:42,305
Speaker 5:  that I went on earlier this week, which is when I read a headline

1629
01:30:42,415 --> 01:30:46,225
Speaker 5:  from Tom Warren, lovely reporter at The Verge who said Apple

1630
01:30:46,325 --> 01:30:49,665
Speaker 5:  to allow iOS app downloads direct from websites in the EU.

1631
01:30:50,805 --> 01:30:54,395
Speaker 5:  David wakes up to this news. Hell yeah. Sounds awesome.

1632
01:30:54,525 --> 01:30:58,235
Speaker 5:  Super exciting. Apple's gonna like let you properly side load

1633
01:30:58,735 --> 01:31:02,035
Speaker 5:  and then you scroll down away and Apple has done what it always does, which

1634
01:31:02,035 --> 01:31:05,915
Speaker 5:  is say a thing and then set up like a hilarious set of hoops you

1635
01:31:05,915 --> 01:31:08,275
Speaker 5:  have to jump through in order for this to be real, the hoops

1636
01:31:08,275 --> 01:31:08,515
Speaker 6:  You have to,

1637
01:31:08,815 --> 01:31:11,715
Speaker 5:  So in Apple's developer program, you have to be in good standing. You have

1638
01:31:11,915 --> 01:31:15,875
Speaker 5:  to have more than a million annual installs in the EU, which is actually

1639
01:31:15,955 --> 01:31:19,635
Speaker 5:  a huge number. You have to only offer apps from your

1640
01:31:19,635 --> 01:31:23,115
Speaker 5:  developer account. You have to be responsive to communications from Apple.

1641
01:31:23,535 --> 01:31:27,435
Speaker 5:  You have to publish your data. Like you basically have to do all

1642
01:31:27,435 --> 01:31:31,075
Speaker 5:  the things you have to do to be in the app store only harder. And then

1643
01:31:31,335 --> 01:31:32,875
Speaker 5:  you can have it from website.

1644
01:31:32,905 --> 01:31:36,515
Speaker 6:  Your website. Yeah. You have to like go on a dinner date with Tim Cook at

1645
01:31:36,515 --> 01:31:39,555
Speaker 6:  one point. Like, that was a really weird one. I didn't understand that one.

1646
01:31:39,745 --> 01:31:40,035
Speaker 6:  Yeah.

1647
01:31:40,505 --> 01:31:43,235
Speaker 5:  Yeah. You have to go to the house of everyone who wants to download your

1648
01:31:43,235 --> 01:31:47,155
Speaker 5:  app and do it for them. Yeah. So yeah, again, like this

1649
01:31:47,155 --> 01:31:50,955
Speaker 5:  is, this is just what Apple is doing here, right? Like they are,

1650
01:31:50,985 --> 01:31:54,835
Speaker 5:  they are allowing things, but making it so onerous that

1651
01:31:54,875 --> 01:31:57,955
Speaker 5:  I don't think anything real is actually gonna change for people, but just

1652
01:31:57,955 --> 01:32:01,645
Speaker 5:  the fact that this is a thing that technically exists, I still think is very

1653
01:32:01,645 --> 01:32:01,845
Speaker 5:  cool.

1654
01:32:02,435 --> 01:32:06,405
Speaker 6:  Yeah. The concept is cool. The execution is hot garbage.

1655
01:32:07,065 --> 01:32:11,005
Speaker 6:  Yes. I'm just like, how's this gonna work? The EU is absolutely like,

1656
01:32:11,395 --> 01:32:12,165
Speaker 6:  come on man.

1657
01:32:12,435 --> 01:32:13,405
Speaker 2:  They won't stop. They

1658
01:32:13,405 --> 01:32:13,885
Speaker 6:  Won't stop. They

1659
01:32:14,085 --> 01:32:17,165
Speaker 2:  Relentlessly European. Yeah. They will come to your house and then take a

1660
01:32:17,325 --> 01:32:19,805
Speaker 2:  nap or on 4:00 PM and they're gonna wake up and they're gonna regulate the

1661
01:32:19,805 --> 01:32:20,405
Speaker 2:  shit outta you. They

1662
01:32:20,405 --> 01:32:23,605
Speaker 6:  Will work six hours and they will get a lot done in that six hours.

1663
01:32:23,915 --> 01:32:26,285
Speaker 2:  They will. They are, I don't, I don't mean to denigrate our European

1664
01:32:26,285 --> 01:32:29,325
Speaker 6:  Friends. They're wonderful. No, because they are getting stuff done. And

1665
01:32:29,365 --> 01:32:32,445
Speaker 6:  I think, I think Europe is doing a much better job at legislating technology

1666
01:32:32,445 --> 01:32:33,365
Speaker 6:  than the United States. And

1667
01:32:33,365 --> 01:32:35,125
Speaker 2:  It's because they eat well and sleep right? Yeah.

1668
01:32:35,975 --> 01:32:36,325
Speaker 6:  There

1669
01:32:36,325 --> 01:32:37,165
Speaker 2:  We go. The walk a

1670
01:32:37,165 --> 01:32:40,245
Speaker 6:  Lot. Yeah, we figured it out. We solved it.

1671
01:32:40,385 --> 01:32:43,885
Speaker 2:  You do some walkable cities and then suddenly you're able to do tech regulation.

1672
01:32:44,165 --> 01:32:46,965
Speaker 2:  I think all this stuff, we've talked about this at length, is all gonna backfire

1673
01:32:46,965 --> 01:32:50,045
Speaker 2:  on Apple. Like this is political nightmare territory for Apple. These like

1674
01:32:50,275 --> 01:32:53,845
Speaker 2:  technical compliance measures that don't actually add up to anything real.

1675
01:32:54,615 --> 01:32:57,105
Speaker 2:  They're, they're just getting in trouble. All right. Cranz, do you wanna

1676
01:32:57,105 --> 01:32:57,425
Speaker 2:  do one more?

1677
01:32:57,655 --> 01:33:01,545
Speaker 6:  Yeah, I got, I got one more. And that is our,

1678
01:33:01,645 --> 01:33:05,345
Speaker 6:  our European friends will already know about this. The Dyson 360

1679
01:33:06,425 --> 01:33:10,345
Speaker 6:  Vis Nav. What is that you ask With a name? With the

1680
01:33:10,635 --> 01:33:14,505
Speaker 6:  Dyson 360 Vis Nav. That is a, a robot

1681
01:33:14,505 --> 01:33:17,225
Speaker 6:  vacuum cleaner that uses visual navigation.

1682
01:33:17,375 --> 01:33:19,705
Speaker 5:  Wait, do you know what I just realized? Alex? What's that? Do you remember

1683
01:33:19,705 --> 01:33:23,425
Speaker 5:  when Dyson was building an Electric car? They

1684
01:33:23,485 --> 01:33:27,225
Speaker 5:  for sure had a thing called Vis Nav and we're like, oh crap, we gotta use

1685
01:33:27,225 --> 01:33:30,705
Speaker 5:  this name for something. We like bought the domain name. That's where this

1686
01:33:30,705 --> 01:33:31,665
Speaker 5:  came from. How

1687
01:33:31,865 --> 01:33:34,785
Speaker 6:  Was the car gonna go? Was he gonna like have a big fan on the bag?

1688
01:33:34,965 --> 01:33:37,745
Speaker 2:  I'm telling you, anytime Dyson tries to make something that isn't a fan-based

1689
01:33:37,745 --> 01:33:41,705
Speaker 2:  product couldn't work that either sucks or blows to

1690
01:33:41,705 --> 01:33:42,505
Speaker 2:  get to get nowhere.

1691
01:33:42,935 --> 01:33:46,865
Speaker 6:  This thing does apparently suck like that, that that's its

1692
01:33:46,865 --> 01:33:50,705
Speaker 6:  whole thing is it's supposed to be really good at it and it has the

1693
01:33:50,705 --> 01:33:54,545
Speaker 6:  most enormous fluffy brush. Like, like she said, it's got a really fluffy

1694
01:33:54,545 --> 01:33:58,065
Speaker 6:  brush. And I was like, that's a weird thing for you to say and I don't understand.

1695
01:33:58,205 --> 01:34:01,465
Speaker 6:  And then she like sent me a picture and I was like, no, it's awesome. Like

1696
01:34:01,505 --> 01:34:05,305
Speaker 6:  I wanna just reach through the photo and touch it. It just looks very

1697
01:34:05,465 --> 01:34:09,105
Speaker 6:  squeezable. But she's gonna be, she just got it in it's, it's finally

1698
01:34:09,105 --> 01:34:11,985
Speaker 6:  available in the United States or is about to be available in the United States.

1699
01:34:12,125 --> 01:34:15,745
Speaker 6:  She just got it in. She's gonna be spending a lot of time messing around

1700
01:34:15,745 --> 01:34:16,065
Speaker 6:  with it.

1701
01:34:16,525 --> 01:34:18,465
Speaker 5:  How stupidly expensive is it? It's so

1702
01:34:18,465 --> 01:34:18,945
Speaker 6:  Expensive.

1703
01:34:19,255 --> 01:34:20,865
Speaker 2:  It's over a thousand dollars. Ugh.

1704
01:34:21,095 --> 01:34:22,305
Speaker 6:  Yeah, like, come on.

1705
01:34:22,565 --> 01:34:23,625
Speaker 2:  Can I just say the way it, David

1706
01:34:23,915 --> 01:34:25,025
Speaker 6:  Asked me that question. I mean

1707
01:34:25,025 --> 01:34:28,225
Speaker 5:  It's Dyson, So, I, assume whatever number. I think I should just double it.

1708
01:34:28,225 --> 01:34:29,305
Speaker 5:  And that's what Dyson costs.

1709
01:34:29,655 --> 01:34:32,985
Speaker 6:  This is not gonna fit under If. you have one of those cool platform beds

1710
01:34:33,135 --> 01:34:37,035
Speaker 6:  with like real low clearance to the ground. This

1711
01:34:37,035 --> 01:34:39,435
Speaker 6:  will not clean under it. It is, it is quite tall.

1712
01:34:39,435 --> 01:34:40,595
Speaker 2:  $1,200. Sorry.

1713
01:34:41,095 --> 01:34:42,275
Speaker 6:  Purple. Okay, cool.

1714
01:34:42,495 --> 01:34:46,475
Speaker 2:  It does look like one of those things in the Matrix that puts you back in

1715
01:34:46,475 --> 01:34:49,115
Speaker 2:  the power plant. Yeah. But like in a friendly way,

1716
01:34:49,355 --> 01:34:52,475
Speaker 6:  That's what it's doing to the dirt. That's how the dirt feels when it, when

1717
01:34:52,475 --> 01:34:53,195
Speaker 6:  it comes at it,

1718
01:34:53,705 --> 01:34:56,515
Speaker 2:  It's like, you know that scene, it's like I'll get my body back to the power

1719
01:34:56,515 --> 01:34:59,045
Speaker 2:  plant, but I don don't wanna know nothing. It's this thing comes to your

1720
01:34:59,045 --> 01:35:03,005
Speaker 2:  house and it's like, we'll get you back in there. But you have to trade

1721
01:35:03,005 --> 01:35:06,005
Speaker 2:  a neo. I have weird feelings about this vacuuming cleaner,

1722
01:35:06,465 --> 01:35:08,165
Speaker 6:  But it's so fluffy looking like Did you look at the

1723
01:35:08,235 --> 01:35:10,005
Speaker 2:  Look? It does look very fluffy. I

1724
01:35:10,285 --> 01:35:14,165
Speaker 6:  I don't know why I like both. Both Jen and I were both like, oh my

1725
01:35:14,225 --> 01:35:18,045
Speaker 6:  God, this brush, like we lost our minds over the brush, which

1726
01:35:18,065 --> 01:35:21,925
Speaker 6:  was very weird and fun for us. I'm excited to see what she does with it.

1727
01:35:22,195 --> 01:35:22,485
Speaker 6:  Does

1728
01:35:22,555 --> 01:35:23,605
Speaker 2:  Does it vacuum her house?

1729
01:35:24,155 --> 01:35:27,765
Speaker 6:  Yeah. But she's got a lot of robax in there right now and I really want her

1730
01:35:27,765 --> 01:35:31,445
Speaker 6:  to put knives on all of them and have 'em fight and she told me no. So

1731
01:35:31,835 --> 01:35:33,285
Speaker 6:  I'll update you guys on that. We

1732
01:35:33,285 --> 01:35:34,445
Speaker 2:  Can, let's work on that together. Yeah,

1733
01:35:34,445 --> 01:35:36,005
Speaker 6:  We can work on that. I think we can do it.

1734
01:35:36,225 --> 01:35:38,485
Speaker 2:  All right. Dad, what's what? Do you have another one or is it just me again?

1735
01:35:38,745 --> 01:35:42,445
Speaker 5:  Mine's just really quick, which is that Microsoft Teams is now

1736
01:35:42,735 --> 01:35:46,365
Speaker 5:  attempting to become like an app that families use to talk to each other.

1737
01:35:46,385 --> 01:35:48,685
Speaker 5:  And Microsoft has been talking about this for a while as like a thing they

1738
01:35:48,685 --> 01:35:51,885
Speaker 5:  wanna do, but they're now like unifying the apps so you can have personal

1739
01:35:51,885 --> 01:35:55,205
Speaker 5:  and work accounts together. And I just feel very vindicated by the fact that

1740
01:35:55,205 --> 01:35:58,565
Speaker 5:  I've been saying Teams was the stupidest possible name for this product this

1741
01:35:58,565 --> 01:36:01,885
Speaker 5:  whole time. And I was right and I feel good about it.

1742
01:36:02,425 --> 01:36:05,485
Speaker 5:  Can you imagine like going home tonight and being like, okay, I'm gonna set

1743
01:36:05,485 --> 01:36:08,365
Speaker 5:  up the family teams and then we're, that's how we're gonna like, no, I'm

1744
01:36:08,365 --> 01:36:11,925
Speaker 5:  out. Pass abort teams. Get outta here.

1745
01:36:12,605 --> 01:36:15,645
Speaker 2:  I I'm proud of you for having feelings about Microsoft teams. Thank you.

1746
01:36:15,715 --> 01:36:19,285
Speaker 2:  Most people I know who use teams including me, whenever I use it, I try to

1747
01:36:19,285 --> 01:36:22,725
Speaker 2:  use it on my computer. Something bad happens, I join the team meeting, the

1748
01:36:22,725 --> 01:36:25,885
Speaker 2:  audio's all messed up and I always say this thing, I have a very complex

1749
01:36:25,885 --> 01:36:29,405
Speaker 2:  relationship with Microsoft teams and then everyone in the room starts laughing.

1750
01:36:30,395 --> 01:36:31,085
Speaker 6:  It's a good joke

1751
01:36:31,395 --> 01:36:32,405
Speaker 2:  Because it's just,

1752
01:36:32,675 --> 01:36:33,725
Speaker 6:  It's just, it's good.

1753
01:36:33,955 --> 01:36:36,045
Speaker 2:  Yeah. Everyone knows what I'm talking about. Yeah.

1754
01:36:36,525 --> 01:36:39,725
Speaker 5:  Whatever. It's, it's that, and Zoom has to update every single time. Use

1755
01:36:39,725 --> 01:36:41,725
Speaker 5:  it. That's the, those are the two facts of life

1756
01:36:41,825 --> 01:36:45,565
Speaker 2:  Now. It's very good. And then Google meet on my 2015 iMac.

1757
01:36:46,455 --> 01:36:48,825
Speaker 2:  Just talk about a Dyson fan

1758
01:36:50,405 --> 01:36:53,985
Speaker 2:  who that thing could power a car. you know what I'm saying? It's suck, right?

1759
01:36:53,985 --> 01:36:57,945
Speaker 2:  Gotta get a new Mac. Still working on it. Okay. Mine, my last one and

1760
01:36:57,945 --> 01:37:01,305
Speaker 2:  then we gotta wrap this up. Many people wrote in to ask about this.

1761
01:37:01,905 --> 01:37:05,585
Speaker 2:  Nikon is acquiring red. So red, the big famous

1762
01:37:06,405 --> 01:37:08,465
Speaker 2:  camera manufacturer, the,

1763
01:37:08,505 --> 01:37:10,185
Speaker 6:  I think you mean phone maker. Thank the

1764
01:37:10,185 --> 01:37:13,745
Speaker 2:  Phone maker. The the red hydrogen one. Famously one of the worst products

1765
01:37:13,745 --> 01:37:17,065
Speaker 2:  we've ever reviewed. Incredible. A review so bad they canceled the product.

1766
01:37:17,375 --> 01:37:18,905
Speaker 2:  It's only happened a few times in our history.

1767
01:37:19,225 --> 01:37:22,785
Speaker 6:  I was just, ugh. I loved that thing. I mean, I loved like

1768
01:37:22,975 --> 01:37:25,665
Speaker 6:  it's existence. I didn't love it.

1769
01:37:25,895 --> 01:37:29,585
Speaker 2:  What if we took the design language of a rugged hard drive and made you hold

1770
01:37:29,585 --> 01:37:30,185
Speaker 2:  it all the time?

1771
01:37:31,895 --> 01:37:35,065
Speaker 2:  Look at it ridiculous. It was very bad. Bad 3D screen as well.

1772
01:37:36,015 --> 01:37:38,505
Speaker 2:  That is not why they're selling to Nikon. Yeah. They weren't like, we're

1773
01:37:38,505 --> 01:37:41,185
Speaker 2:  so embarrassed. We gotta get out of this. There's been some patent battles

1774
01:37:41,245 --> 01:37:45,225
Speaker 2:  in the past between these two. If you're Nikon you

1775
01:37:45,295 --> 01:37:48,545
Speaker 2:  know that so much of the action to imaging is happening in video.

1776
01:37:49,145 --> 01:37:53,105
Speaker 2:  That it's driving a huge amount of the, just the sensor

1777
01:37:53,105 --> 01:37:56,200
Speaker 2:  technology that is happening. Just all the, the stuff is happening on the

1778
01:37:56,200 --> 01:37:56,685
Speaker 2:  video side

1779
01:37:57,625 --> 01:37:59,365
Speaker 6:  And that's not what Nikon's known for.

1780
01:37:59,515 --> 01:38:03,205
Speaker 2:  It's not what? Not even a little bit. Nope, not at all.

1781
01:38:03,905 --> 01:38:07,365
Speaker 2:  So you, you see the Canons and the Sonys of the world, like really lean into

1782
01:38:07,365 --> 01:38:10,285
Speaker 2:  video. There's just an explosion of digital video making happening everywhere.

1783
01:38:10,665 --> 01:38:13,885
Speaker 2:  Red obviously owns a big chunk of that. I'm not entirely sure how the shape

1784
01:38:13,885 --> 01:38:17,485
Speaker 2:  of this patent battle led to an acquisition. I just know strategically

1785
01:38:19,125 --> 01:38:23,085
Speaker 2:  Nikon was kind of outta moves. Yeah. And I think Red saw

1786
01:38:23,125 --> 01:38:26,725
Speaker 2:  a number and they took the number. I'm very curious to see if

1787
01:38:27,605 --> 01:38:31,525
Speaker 2:  Nikon cameras turned more into red cameras because

1788
01:38:31,645 --> 01:38:35,445
Speaker 2:  I don't think the people who use red cameras will accept them turning more

1789
01:38:35,445 --> 01:38:37,165
Speaker 2:  into Nikon cameras. No,

1790
01:38:37,605 --> 01:38:41,365
Speaker 6:  I feel like both ways, like neither, neither one of those crews

1791
01:38:41,735 --> 01:38:43,485
Speaker 6:  wanna use that product. The other product.

1792
01:38:44,355 --> 01:38:46,485
Speaker 2:  Yeah. And yeah. Which

1793
01:38:46,485 --> 01:38:49,325
Speaker 6:  Is, but that's, that, that makes it a good deal for them is because then

1794
01:38:49,435 --> 01:38:51,285
Speaker 6:  they get both of those those

1795
01:38:51,485 --> 01:38:53,925
Speaker 5:  Audiences. Yeah. Maybe that's okay. Like May Red, that's fine. Is a good

1796
01:38:53,925 --> 01:38:57,205
Speaker 5:  brand with great products. Like maybe, maybe the best place to Land is just

1797
01:38:57,205 --> 01:39:00,285
Speaker 5:  like, oh, you need Nikon to have a video strategy. Like, here it is. It's

1798
01:39:00,285 --> 01:39:00,525
Speaker 5:  called Red

1799
01:39:00,665 --> 01:39:02,605
Speaker 6:  And it's got good glass. So it's like,

1800
01:39:02,605 --> 01:39:06,205
Speaker 2:  Yeah. Nikon. Yeah. I mean, I'm a Nikon person. Famously, our video team is

1801
01:39:06,205 --> 01:39:10,085
Speaker 2:  deeply confused by this at all times. Yeah. But I love my icon

1802
01:39:11,005 --> 01:39:12,365
Speaker 2:  D 7,500 still going strong.

1803
01:39:14,135 --> 01:39:17,125
Speaker 2:  We'll just see. It is also, by the way, it is a good time in still cameras.

1804
01:39:17,185 --> 01:39:19,325
Speaker 2:  We haven't really talked about this, but Becca's been doing a lot of coverage

1805
01:39:19,325 --> 01:39:22,285
Speaker 2:  of like, very exciting still cameras from Fuji and Laika that are coming

1806
01:39:22,285 --> 01:39:22,685
Speaker 2:  out. That

1807
01:39:22,845 --> 01:39:25,845
Speaker 6:  Fuji film I like. I think about it a lot. Yeah. I'm like, I don't need that

1808
01:39:25,845 --> 01:39:29,405
Speaker 6:  camera, but what if, what if I got into photography again?

1809
01:39:29,685 --> 01:39:32,885
Speaker 6:  That's, that's what it like. That's a midlife crisis camera right there.

1810
01:39:32,985 --> 01:39:33,805
Speaker 6:  I'm like, yeah. Oh,

1811
01:39:34,165 --> 01:39:35,805
Speaker 2:  Interesting. Yeah. What if Max doesn't go to college?

1812
01:39:35,995 --> 01:39:38,285
Speaker 6:  Yeah, college is overrated.

1813
01:39:38,515 --> 01:39:41,605
Speaker 2:  Yeah. What? What you want? Get a cool camera? Beautiful street photography.

1814
01:39:41,635 --> 01:39:45,365
Speaker 2:  Yeah. Sorry kid. I took a picture of a dumpster.

1815
01:39:45,435 --> 01:39:49,205
Speaker 2:  Okay, that is, is it? That's The. Vergecast. We're gonna send her to college

1816
01:39:49,305 --> 01:39:53,045
Speaker 2:  one way or the other. We'll just see how many dumpster photos pay for it.

1817
01:39:53,075 --> 01:39:56,965
Speaker 2:  Yeah. If she wants to go, which she's gonna want to because I'm her

1818
01:39:56,965 --> 01:40:00,045
Speaker 2:  father. Okay. That's it. That's s Vergecast. We've gone way over. Thank you

1819
01:40:00,045 --> 01:40:04,005
Speaker 2:  for listening. Many things to give us feedback on this time. David,

1820
01:40:04,005 --> 01:40:05,565
Speaker 2:  tell us how they can get in contact with us.

1821
01:40:05,905 --> 01:40:08,925
Speaker 5:  You can email us Vergecast at The Verge dot com. That goes to all of us.

1822
01:40:09,625 --> 01:40:13,165
Speaker 5:  Or you can call the hotline. Eight six. Six version one one. We got a

1823
01:40:13,295 --> 01:40:16,445
Speaker 5:  tweet from somebody the other day who thought it was very funny that we used

1824
01:40:16,445 --> 01:40:19,965
Speaker 5:  to tell everybody about Twitter. And then we told people about threads for

1825
01:40:19,965 --> 01:40:23,845
Speaker 5:  a minute, and now we want them to call our landline, which is objectively

1826
01:40:23,875 --> 01:40:27,725
Speaker 5:  very funny. We're all also on threads. You can find us there. And

1827
01:40:27,725 --> 01:40:30,485
Speaker 5:  also just like The Verge dot com, we make a website. It's pretty good.

1828
01:40:30,595 --> 01:40:34,205
Speaker 2:  Yeah, come to it directly. Escape the algorithms. That should be our new

1829
01:40:34,205 --> 01:40:37,045
Speaker 2:  tagline. Escape from the algorithms. That's pretty good. The Verge dot com.

1830
01:40:37,045 --> 01:40:38,045
Speaker 2:  All right. That's it. Alright, roll.

1831
01:40:42,385 --> 01:40:45,645
Speaker 3:  And that's it for The Vergecast this week. Hey, we'd love to hear from you.

1832
01:40:45,675 --> 01:40:49,365
Speaker 3:  Give us a call at eight six six Verge one. One The. Vergecast is a

1833
01:40:49,365 --> 01:40:51,645
Speaker 3:  production of The Verge and Vox Media Podcast Network.

