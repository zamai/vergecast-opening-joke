1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 27937e80-a90d-11ed-bbdc-43f038e19f6d
Status: Done
Stage: Done
Title: We tried Bing powered by ChatGPT AI and things got dark
Audio URL: https://jfe93e.s3.amazonaws.com/-3332087417946112367/-4968080198430933647/s93290-US-5863s-1676010941.mp3
Description: The Verge's Nilay Patel, Alex Cranz, Richard Lawler, and James Vincent discuss Microsoft's upgraded Bing search engine with ChatGPT AI. Can Microsoft beat Google at search? Is it actually an upgrade? Also: Disney layoffs, Elon's Twitter reach is dropping, and more of this week's tech news.

2
00:00:01,330 --> 00:00:05,250
Speaker 2:  Today on the Vergecast, we got Eli to install Microsoft's Edge browser

3
00:00:05,250 --> 00:00:09,130
Speaker 2:  just so we could play with the new Bing powered by chat, G P T, ai,

4
00:00:09,310 --> 00:00:12,370
Speaker 2:  all that and so much more coming up right after this.

5
00:00:15,210 --> 00:00:18,920
Speaker 3:  Support for today's show comes from Deloitte. In the business world, it can

6
00:00:18,920 --> 00:00:22,200
Speaker 3:  be a especially crucial to innovate. You can either build your own future

7
00:00:22,210 --> 00:00:25,640
Speaker 3:  or bet on someone else's. No one knows what tomorrow will bring, but you

8
00:00:25,640 --> 00:00:29,120
Speaker 3:  push forward and create enterprise anyway. That's why Deloitte's mission

9
00:00:29,120 --> 00:00:32,120
Speaker 3:  is to help engineer advantage for their clients by harnessing the latest

10
00:00:32,120 --> 00:00:36,000
Speaker 3:  innovations in technology while exploring the ideas and opportunities that

11
00:00:36,000 --> 00:00:39,440
Speaker 3:  can look beyond today. Transform what's next into what's now.

12
00:00:39,860 --> 00:00:42,840
Speaker 3:  See how you can engineer advantage with Deloitte at

13
00:00:43,040 --> 00:00:46,560
Speaker 3:  deloitte.com/us/engineering advantage.

14
00:00:59,200 --> 00:01:02,840
Speaker 4:  Hello, welcome to VER has the flagship podcast of generative

15
00:01:03,010 --> 00:01:06,880
Speaker 4:  AI solutions for your small business. Please use this promo code,

16
00:01:06,880 --> 00:01:10,840
Speaker 4:  it's promo code and sign up for an informative seminar today about how AI

17
00:01:10,840 --> 00:01:14,680
Speaker 4:  can replace most of your workforce, but not you because you're

18
00:01:14,680 --> 00:01:17,560
Speaker 4:  important. Hi, I'm Neil. I'm your friend. I don't mean to start on a down

19
00:01:17,560 --> 00:01:21,160
Speaker 4:  note, I'm just saying I've already gotten that email. Basically

20
00:01:24,130 --> 00:01:27,360
Speaker 4:  we have big show. It's the Microsoft versus Google

21
00:01:27,820 --> 00:01:31,600
Speaker 4:  War is underway. I was at Microsoft

22
00:01:31,600 --> 00:01:35,480
Speaker 4:  this week to see the launch of the new Bing powered by not chat G

23
00:01:35,480 --> 00:01:39,000
Speaker 4:  P T. We'll get into it, but I have an all star lineup here to start with.

24
00:01:39,000 --> 00:01:39,800
Speaker 4:  Alex Kranz is here.

25
00:01:39,840 --> 00:01:43,680
Speaker 3:  Hello. I'm your friend who doesn't know what's going on right now,

26
00:01:43,680 --> 00:01:45,040
Speaker 3:  but is very excited to learn more.

27
00:01:45,040 --> 00:01:48,120
Speaker 4:  Yeah, you were just on vacation, you just came back and like the whole world

28
00:01:48,120 --> 00:01:50,280
Speaker 4:  has changed. You're like, there's robot now. I think

29
00:01:50,280 --> 00:01:52,880
Speaker 3:  It's changed. Yeah, that's great. Whole new world.

30
00:01:53,800 --> 00:01:54,680
Speaker 4:  Richard Lawler is here.

31
00:01:54,960 --> 00:01:58,520
Speaker 5:  Hello. I do not believe in the future of AI until it gets into

32
00:01:58,760 --> 00:01:59,120
Speaker 5:  Bitcoin.

33
00:01:59,730 --> 00:02:02,600
Speaker 4:  No, here's what I'm saying, Richard, I, I said this to Richard and Slack

34
00:02:02,600 --> 00:02:06,320
Speaker 4:  today. Richard's reflexive skepticism about Bitcoin is bleeding

35
00:02:06,320 --> 00:02:08,160
Speaker 4:  into the AI conversation. Look,

36
00:02:08,160 --> 00:02:11,600
Speaker 5:  I was right once and it's going to just carry me through like the next five

37
00:02:11,600 --> 00:02:11,880
Speaker 5:  years.

38
00:02:12,910 --> 00:02:16,840
Speaker 4:  I was like, no, this is stupid too. So it's good. Well, we need that. The

39
00:02:16,920 --> 00:02:20,600
Speaker 4:  industry needs that. James Vincent Verge senior reporter focused on AI here.

40
00:02:20,600 --> 00:02:20,960
Speaker 4:  Hey James.

41
00:02:21,450 --> 00:02:24,850
Speaker 6:  Hello. Hello. I'm glad to see that I was

42
00:02:25,320 --> 00:02:29,130
Speaker 6:  Bing's favorite reporter in one of the screen screenshots you shared.

43
00:02:29,130 --> 00:02:32,650
Speaker 6:  I feel like I've been sucking up to Bing by accident, by writing about ai.

44
00:02:32,650 --> 00:02:33,290
Speaker 6:  I didn't realize.

45
00:02:33,440 --> 00:02:36,970
Speaker 4:  Yeah. I asked Bing who was the best reporter of The Verge and I just named

46
00:02:36,970 --> 00:02:40,770
Speaker 4:  some people. It was like Dan, Casey, Addie and James.

47
00:02:40,770 --> 00:02:44,530
Speaker 4:  It did not realize Casey doesn't work here anymore. And I said,

48
00:02:44,730 --> 00:02:47,290
Speaker 4:  no, no, who's your favorite? And it's like, well, I can't choose. But James

49
00:02:47,290 --> 00:02:50,890
Speaker 4:  reports an ai and that's, and then if you look at

50
00:02:50,890 --> 00:02:54,410
Speaker 4:  screenshots of Bing, and I want people to pay attention to this whenever

51
00:02:54,580 --> 00:02:58,530
Speaker 4:  it knows or susses out that the answer might be controversial.

52
00:02:59,210 --> 00:03:03,120
Speaker 4:  It uses a smiley, but it's a blushing smiley. So it looks

53
00:03:03,120 --> 00:03:07,080
Speaker 4:  like it's doing this every time. And so it's

54
00:03:07,080 --> 00:03:10,240
Speaker 4:  like either flirting with you or just like doing this super innocent face.

55
00:03:10,270 --> 00:03:14,040
Speaker 4:  Like I asked it why Beyonce did not win Best album. And let me tell you,

56
00:03:14,040 --> 00:03:17,840
Speaker 4:  this robot knew that it was in very dicey territory answering

57
00:03:18,040 --> 00:03:21,480
Speaker 4:  this question. It was like, I don't know, here's 95

58
00:03:21,800 --> 00:03:25,520
Speaker 4:  citations to other sources. People have a lot of different

59
00:03:25,520 --> 00:03:29,280
Speaker 4:  opinions. The Grammys are a subjective award. No music is best. I gotta get

60
00:03:29,280 --> 00:03:30,760
Speaker 4:  outta here. Smiley face.

61
00:03:33,050 --> 00:03:33,400
Speaker 4:  Is

62
00:03:33,400 --> 00:03:37,320
Speaker 6:  That better or worse than clippy? You know, do we do we need is

63
00:03:37,320 --> 00:03:40,600
Speaker 6:  is the winner of the AI war gonna be who comes up with the most Punchable

64
00:03:40,610 --> 00:03:42,040
Speaker 6:  AI and lets you punch it?

65
00:03:42,150 --> 00:03:45,440
Speaker 4:  Yeah, well, so we'll get into it. We'll get into it. I have access to it.

66
00:03:45,440 --> 00:03:48,600
Speaker 4:  We can use it. We ask the audience for some prompts. We'll see how those

67
00:03:48,600 --> 00:03:52,520
Speaker 4:  go. But let's start with what Microsoft actually announced. It's a new

68
00:03:52,520 --> 00:03:56,360
Speaker 4:  version of Bing. Microsoft has had this long relationship with Open

69
00:03:56,360 --> 00:04:00,280
Speaker 4:  ai. The company makes chat. G P T Open ai ceo

70
00:04:00,280 --> 00:04:03,960
Speaker 4:  Sam Altman was on the stage at this event. There's actually quite a lot,

71
00:04:03,960 --> 00:04:07,480
Speaker 4:  even before we start with this, Microsoft announced this event without telling

72
00:04:07,480 --> 00:04:11,200
Speaker 4:  anyone. So they were like, come to Redmond. This is our only

73
00:04:11,200 --> 00:04:14,720
Speaker 4:  in-person event. It's a big deal. And we're like, is there a live stream?

74
00:04:14,720 --> 00:04:18,240
Speaker 4:  And they're like, no, but you're gonna want to be there sore. Like okay,

75
00:04:18,240 --> 00:04:21,680
Speaker 4:  we're gonna go. And we all kind of sussed out what it was gonna be. And I

76
00:04:21,680 --> 00:04:24,240
Speaker 4:  was like, man, if they show me a new version of Bing and I call them be mad.

77
00:04:24,240 --> 00:04:26,960
Speaker 4:  And they're like, no, no, you're gonna love it. So the whole press is there.

78
00:04:26,960 --> 00:04:30,800
Speaker 4:  Google freaks out. It gets word of this, it announces its

79
00:04:30,800 --> 00:04:34,640
Speaker 4:  own chat bot integration called Bard and Google

80
00:04:34,790 --> 00:04:38,640
Speaker 4:  with just a blog post. But no details, no access.

81
00:04:38,830 --> 00:04:39,320
Speaker 4:  They

82
00:04:39,320 --> 00:04:41,600
Speaker 3:  Just are like, we've got Bard. Bard

83
00:04:41,600 --> 00:04:44,840
Speaker 4:  Is coming. Yeah, they obviously made up that name just like the day before.

84
00:04:44,840 --> 00:04:45,280
Speaker 4:  They

85
00:04:45,280 --> 00:04:49,200
Speaker 6:  Were like, I don't, an hour an hour's notice as well. I mean

86
00:04:49,200 --> 00:04:52,960
Speaker 6:  maybe some outlets got more than that. But in inside baseball here we got

87
00:04:52,960 --> 00:04:56,240
Speaker 6:  an hour's notice that this is coming, which I think says about their panic.

88
00:04:56,510 --> 00:04:56,800
Speaker 6:  A

89
00:04:56,800 --> 00:05:00,520
Speaker 4:  Rush. Yeah. And then they had another event in Paris, which was

90
00:05:00,570 --> 00:05:04,440
Speaker 4:  by all accounts, just like a pure disaster. And the stock fell like, we don't

91
00:05:04,440 --> 00:05:07,600
Speaker 4:  cover stock prices normally, but I was like, Google's lost a hundred billion

92
00:05:07,780 --> 00:05:11,760
Speaker 4:  off its valuation because of what happened with Microsoft

93
00:05:11,760 --> 00:05:14,760
Speaker 4:  in the middle and how they reacted to it. So this is just the context. So

94
00:05:14,760 --> 00:05:17,200
Speaker 4:  we go there, we don't know what we're gonna see. We're Microsoft's first

95
00:05:17,200 --> 00:05:20,720
Speaker 4:  event, we're in their executive briefing center, they have a

96
00:05:20,720 --> 00:05:24,200
Speaker 4:  little sage set up, lots of chairs, lots of reporters there. Obviously it

97
00:05:24,200 --> 00:05:28,000
Speaker 4:  was fun to see everyone and they just got into it, right? This is the

98
00:05:28,000 --> 00:05:31,920
Speaker 4:  most focused tech event I have seen in years. It

99
00:05:31,920 --> 00:05:35,360
Speaker 4:  was not, we're putting AI in everything. It was not, here's you can tell

100
00:05:35,360 --> 00:05:38,120
Speaker 4:  Excel to make you a pivot table, which is obviously the end goal for all

101
00:05:38,120 --> 00:05:41,920
Speaker 4:  ai. It was, here's a new version of Bing, it's powered

102
00:05:41,920 --> 00:05:45,320
Speaker 4:  by chat G P T technology. Here's Sam Altman from OpenAI to talk about it.

103
00:05:45,390 --> 00:05:49,320
Speaker 4:  Here's our responsible AI researchers to tell you like how we're

104
00:05:49,320 --> 00:05:52,840
Speaker 4:  gonna keep it safe and trustworthy and what the guiderails are. Here's a

105
00:05:52,840 --> 00:05:56,400
Speaker 4:  new version of Edge that has a chatbot

106
00:05:56,400 --> 00:05:59,720
Speaker 4:  sidebar. They can read the webpage you're on and like summarize it for you

107
00:05:59,720 --> 00:06:03,200
Speaker 4:  and like help you browse the web, which is really interesting. And we're

108
00:06:03,200 --> 00:06:06,400
Speaker 4:  out and here's Sasha Andela to say we're taking a fight to Google. And then

109
00:06:06,400 --> 00:06:10,280
Speaker 4:  that was it. And then we like went downstairs and we waited it a

110
00:06:10,280 --> 00:06:13,520
Speaker 4:  while, like an oddly long time. And then they gave us all access to it.

111
00:06:14,000 --> 00:06:17,120
Speaker 4:  All the people who were there got access with their Microsoft accounts. So

112
00:06:17,120 --> 00:06:20,760
Speaker 4:  it's not, I think open to everyone yet, but we have access to it

113
00:06:20,860 --> 00:06:24,680
Speaker 4:  and it will slowly come out to everyone in the next, in the weeks

114
00:06:24,680 --> 00:06:28,120
Speaker 4:  to come I think is what they're saying. Google is like effectively nowhere.

115
00:06:28,540 --> 00:06:30,520
Speaker 3:  How fast is that rollout gonna be

116
00:06:31,520 --> 00:06:35,360
Speaker 4:  That we don't know. Okay. Oh my God, what is going on with Bing?

117
00:06:36,260 --> 00:06:39,760
Speaker 4:  I'm sorry. Like in the background, like Bing is just like losing its mind

118
00:06:39,760 --> 00:06:43,720
Speaker 4:  with me. The rollout is a is a few weeks. They said they are very aware that

119
00:06:43,720 --> 00:06:47,360
Speaker 4:  they have this lead and they want to take it, right?

120
00:06:47,360 --> 00:06:51,120
Speaker 4:  They, like Nadela said to me, we know Google's 800 pound

121
00:06:51,120 --> 00:06:53,920
Speaker 4:  gorilla, but they have to come to the dance. And I want people to know that

122
00:06:53,920 --> 00:06:57,760
Speaker 4:  we made them dance, which is a very aggressive thing. Like I've talked to

123
00:06:57,760 --> 00:07:01,560
Speaker 4:  a lot of big tech CEOs, they usually do not refer

124
00:07:01,560 --> 00:07:05,080
Speaker 4:  to their competitors directly in this way, right?

125
00:07:05,220 --> 00:07:08,720
Speaker 4:  But they think they have an opportunity to change how search works. Nadella

126
00:07:08,720 --> 00:07:12,360
Speaker 4:  keeps saying search is the biggest software category on earth and they,

127
00:07:12,360 --> 00:07:15,680
Speaker 4:  you know, their opportunity is to just peel off a couple points of market

128
00:07:15,680 --> 00:07:19,600
Speaker 4:  share, which is worth billions upon billions of dollars. And

129
00:07:19,600 --> 00:07:23,480
Speaker 4:  they have this new paradigm of chat and chat, G P T, which chat g p t

130
00:07:24,010 --> 00:07:27,840
Speaker 4:  is like the fastest growing software product in in history, right? Like that

131
00:07:27,840 --> 00:07:29,040
Speaker 4:  they're very proud of this. They have the,

132
00:07:29,270 --> 00:07:30,520
Speaker 3:  It's like faster than TikTok.

133
00:07:30,670 --> 00:07:34,560
Speaker 4:  Yeah. I mean it's in many ways that's like, it's a weird thing to say, right?

134
00:07:34,560 --> 00:07:37,600
Speaker 4:  Like yeah, yeah. You just have to sign up for it and type at it. Yeah,

135
00:07:37,800 --> 00:07:41,120
Speaker 3:  I just keep seeing that comparison and I'm like, that sounds big.

136
00:07:41,310 --> 00:07:41,800
Speaker 3:  What?

137
00:07:41,900 --> 00:07:45,640
Speaker 6:  But, but, but there's been like, you know, there was a Reuters news

138
00:07:45,640 --> 00:07:49,520
Speaker 6:  post which cited some SimilarWeb analytics, which claimed

139
00:07:49,520 --> 00:07:52,880
Speaker 6:  a hundred million monthly adverse users. And then New York Times had a report

140
00:07:52,880 --> 00:07:56,040
Speaker 6:  saying 30 million. Like they, and they, those numbers came out in the same

141
00:07:56,040 --> 00:07:59,240
Speaker 6:  week. I I, I dunno what's going on with the use of statistics. It's definitely

142
00:07:59,240 --> 00:08:02,560
Speaker 6:  been growing fast, but I'm very suspicious that like, how many people are

143
00:08:02,560 --> 00:08:06,480
Speaker 6:  logging in day after day? Yeah. You know, even I'm not logging in every

144
00:08:06,480 --> 00:08:09,840
Speaker 6:  day to chat G P T and I report on this stuff. I log in when there's a reason

145
00:08:09,840 --> 00:08:10,160
Speaker 6:  to.

146
00:08:10,270 --> 00:08:14,080
Speaker 3:  I know people who are like, I think it's really interesting, everybody

147
00:08:14,080 --> 00:08:18,040
Speaker 3:  on this podcast right now, we're all writers and editors. We, we, we write

148
00:08:18,040 --> 00:08:21,240
Speaker 3:  all the time. I have a lot of friends who are not writers, they're not editors

149
00:08:21,240 --> 00:08:25,080
Speaker 3:  and they're using it daily to write all of their emails. One friend has like

150
00:08:25,080 --> 00:08:29,040
Speaker 3:  asked it to recommend books and now he only reads books recommended by chat

151
00:08:29,040 --> 00:08:30,720
Speaker 3:  gpt. That's not, he's all it. I'm sorry.

152
00:08:30,720 --> 00:08:32,080
Speaker 4:  He's all that that friend is gonna,

153
00:08:32,080 --> 00:08:32,600
Speaker 3:  That terrifies

154
00:08:32,650 --> 00:08:36,400
Speaker 4:  Me. Yeah. That friend is gonna end up being a Azel culture bro. In like one

155
00:08:36,400 --> 00:08:36,560
Speaker 4:  second.

156
00:08:36,890 --> 00:08:40,080
Speaker 3:  He worked at, he was an NFTs before this, so I'm not see,

157
00:08:40,080 --> 00:08:42,320
Speaker 4:  See what I'm surprised I clock that so fast.

158
00:08:42,830 --> 00:08:46,760
Speaker 6:  Yeah. GT ization pipeline.

159
00:08:47,280 --> 00:08:51,120
Speaker 5:  There is a huge overlap between very excited about

160
00:08:51,250 --> 00:08:54,200
Speaker 5:  AI and used to be very excited about crypto. Yeah.

161
00:08:54,200 --> 00:08:57,080
Speaker 4:  It's just a pipeline pipeline that makes you read Rich Dad Port a, like that's

162
00:08:57,080 --> 00:09:00,640
Speaker 4:  the whole pipeline. Like it's like read these four hustle culture books.

163
00:09:01,320 --> 00:09:04,760
Speaker 4:  You're gonna end up doing real estate and investing very quickly. Well, so

164
00:09:04,760 --> 00:09:07,560
Speaker 4:  there's this underlying thing like chat p d is like hard to use. It has gone

165
00:09:07,560 --> 00:09:11,480
Speaker 4:  down, it has capacity limits, all this stuff. Microsoft is like whatever.

166
00:09:11,480 --> 00:09:15,120
Speaker 4:  We're just, we have this built multi-year multi-billion dollar investment

167
00:09:15,120 --> 00:09:18,960
Speaker 4:  in the company. That part is a little unclear, like how much of open AI's

168
00:09:18,960 --> 00:09:22,520
Speaker 4:  roadmap is Microsoft actually in, in charge of how much of

169
00:09:22,740 --> 00:09:26,440
Speaker 4:  the actual technology belongs to Microsoft versus open ai. We were talking

170
00:09:26,440 --> 00:09:28,760
Speaker 4:  to some product folks, engineering folks there. They're like, look, we just

171
00:09:28,760 --> 00:09:32,680
Speaker 4:  run it on Azure and it's just, it's it's ours. Like we give them

172
00:09:32,680 --> 00:09:36,640
Speaker 4:  notes, you know, like, so I think there's some

173
00:09:37,190 --> 00:09:40,720
Speaker 4:  underlying complexity to that deal that we don't quite understand.

174
00:09:41,060 --> 00:09:44,960
Speaker 4:  But what is real, what is tangible is that chat G p

175
00:09:45,040 --> 00:09:49,000
Speaker 4:  t is not a product, right? It is a technology demo that has

176
00:09:49,000 --> 00:09:52,200
Speaker 4:  spread like wildfire that is very impressive. It has some very obvious limitations.

177
00:09:52,430 --> 00:09:56,200
Speaker 4:  Bing is a product, right? It is a complete consumer

178
00:09:56,200 --> 00:10:00,120
Speaker 4:  product that you can just use for free that Microsoft is gluing

179
00:10:00,120 --> 00:10:03,080
Speaker 4:  an advertising model onto. And that Microsoft thinks

180
00:10:03,810 --> 00:10:07,320
Speaker 4:  is good enough to capture market share from Google,

181
00:10:07,560 --> 00:10:10,680
Speaker 4:  which is having, its its own set of problems. That's pretty interesting,

182
00:10:10,680 --> 00:10:14,560
Speaker 4:  right? Like we have not seen productized AI like this before. Have

183
00:10:14,560 --> 00:10:15,120
Speaker 4:  we James?

184
00:10:15,380 --> 00:10:19,280
Speaker 6:  Not on this scale. No. No way there. Yeah. I think

185
00:10:19,280 --> 00:10:22,520
Speaker 6:  this is what is so interesting about this. And also not just about Bing,

186
00:10:22,520 --> 00:10:26,240
Speaker 6:  but about the Edge integrations, about how this is such like a play

187
00:10:26,250 --> 00:10:30,160
Speaker 6:  to, for, for, for people to get stuck in Windows ecosystem in

188
00:10:30,160 --> 00:10:33,760
Speaker 6:  a way that like yeah, I, I mean like if, if the edge stuff goes well, it's

189
00:10:33,760 --> 00:10:37,560
Speaker 6:  not just Bing versus Google as it were, it's sort of

190
00:10:37,560 --> 00:10:41,200
Speaker 6:  chrome versus edge again. Because if Microsoft can build this directly into

191
00:10:41,200 --> 00:10:43,840
Speaker 6:  the browser and they can say you can only get this in edge, you can't get

192
00:10:43,840 --> 00:10:47,080
Speaker 6:  your summarized documents in in Chrome or whatever else you might be using.

193
00:10:47,080 --> 00:10:50,040
Speaker 6:  And that's a huge advantage as well. So yeah. Nothing on this scale that

194
00:10:50,040 --> 00:10:50,640
Speaker 6:  we've seen before.

195
00:10:50,830 --> 00:10:54,720
Speaker 4:  Yeah. And it works like the, the thing I will tell you is that in

196
00:10:54,720 --> 00:10:58,160
Speaker 4:  most cases it does what you think it's going to do,

197
00:10:58,360 --> 00:11:02,220
Speaker 4:  which is for any, for any product, like

198
00:11:02,220 --> 00:11:06,180
Speaker 4:  the first metric of success. Like I've picked up smartphones and like

199
00:11:06,180 --> 00:11:09,700
Speaker 4:  this doesn't do what I expected it to do. Right? Like any,

200
00:11:09,730 --> 00:11:13,100
Speaker 4:  I've, I've installed streaming players. Have you ever tried to use an Nvidia

201
00:11:13,100 --> 00:11:13,300
Speaker 4:  shield?

202
00:11:16,950 --> 00:11:18,740
Speaker 4:  No, I haven't. It's a horrible troll. No

203
00:11:18,740 --> 00:11:21,700
Speaker 6:  One has. I've never been in Dan's bad books. So you've never given me that

204
00:11:21,700 --> 00:11:22,020
Speaker 6:  review.

205
00:11:23,580 --> 00:11:26,420
Speaker 4:  No, but like, you know, the measure of success for any consumer product is

206
00:11:26,420 --> 00:11:30,020
Speaker 4:  like on balance. When someone is like, I want it to do this thing, does it

207
00:11:30,020 --> 00:11:33,060
Speaker 4:  just like do it without jumping through a lot of hoops or a lot of complication

208
00:11:33,060 --> 00:11:36,580
Speaker 4:  And Bing is like, just does. It just doesn't. The one thing I could not get

209
00:11:36,580 --> 00:11:40,100
Speaker 4:  it to do, this is a true story. I asked that yesterday to tell me a story

210
00:11:40,220 --> 00:11:44,060
Speaker 4:  about a princess fighting a dragon. It would not allow the

211
00:11:44,260 --> 00:11:47,420
Speaker 4:  princess to kill the dragon. Wow. Sexism

212
00:11:47,660 --> 00:11:51,140
Speaker 4:  literally at, at the end of the story, it was like the princess escaped and

213
00:11:51,140 --> 00:11:54,480
Speaker 4:  thought I will bring the dragon a gift. And I was like, no, no, make her

214
00:11:54,480 --> 00:11:57,480
Speaker 4:  kill the dragon. And I was like, no. And I was like, no, do the story again

215
00:11:57,480 --> 00:12:00,320
Speaker 4:  with more blood. And then it was straight up was like, I will not tell you

216
00:12:00,320 --> 00:12:04,160
Speaker 4:  a story with blood in it. And somehow this spiraled all the way

217
00:12:04,160 --> 00:12:07,280
Speaker 4:  into will you tell me a story about the devil, which it does not wanna do.

218
00:12:07,280 --> 00:12:11,120
Speaker 4:  It has some very deep 1950s Christian mom morals

219
00:12:11,120 --> 00:12:14,920
Speaker 4:  baked into it. I dunno what else to say. Yeah. Little

220
00:12:14,920 --> 00:12:18,440
Speaker 4:  pure. Yeah. It's also very moody. You asked to tell stories, the story, all

221
00:12:18,440 --> 00:12:22,400
Speaker 4:  the stories are very existential Parker, or are the

222
00:12:22,400 --> 00:12:25,000
Speaker 4:  person who runs our, our merch store asked it to tell a story about scissor

223
00:12:25,000 --> 00:12:25,360
Speaker 4:  vodka.

224
00:12:25,610 --> 00:12:26,320
Speaker 6:  Oh, I read

225
00:12:26,320 --> 00:12:30,200
Speaker 4:  That they told a story about KC Newton writing some copy about

226
00:12:30,200 --> 00:12:33,960
Speaker 4:  scissor vodka and then publishing it and then immediately regretting it.

227
00:12:34,260 --> 00:12:38,120
Speaker 4:  And the last line was he realized he had already cut through the night. And

228
00:12:38,120 --> 00:12:42,040
Speaker 4:  I was like, this is what happens when you train a generative AI on years

229
00:12:42,040 --> 00:12:45,720
Speaker 4:  and years of live journal. Like there's a angsty teen

230
00:12:46,380 --> 00:12:50,240
Speaker 4:  who soul beats in the heart of this AI and you can just get it out of it.

231
00:12:51,070 --> 00:12:54,440
Speaker 6:  That what that example though with the scissor vodka,

232
00:12:54,990 --> 00:12:58,640
Speaker 6:  I I i I want to talk about the problems with these systems cuz there are

233
00:12:58,640 --> 00:13:02,560
Speaker 6:  loads of problems. But that example, I was super impressed because it

234
00:13:02,560 --> 00:13:06,400
Speaker 6:  knew exactly, this is a fictional in joke that's been on the

235
00:13:06,400 --> 00:13:09,880
Speaker 6:  Vergecast as a running joke. How like, I was actually confused where it got

236
00:13:09,880 --> 00:13:13,760
Speaker 6:  that information from because have we referenced it enough

237
00:13:13,760 --> 00:13:16,400
Speaker 6:  in articles that it would've picked that up? I guess so, but

238
00:13:16,570 --> 00:13:20,560
Speaker 4:  So, you know, I think Parker had the prompt was like, tell a story about

239
00:13:20,560 --> 00:13:23,600
Speaker 4:  this joke from the ver so like there was a little bit of oh okay, cueing

240
00:13:23,600 --> 00:13:26,840
Speaker 4:  in the prompt, but then it knew, right? And there's obviously transcripts

241
00:13:26,840 --> 00:13:30,520
Speaker 4:  of our show out in the world or auto-generated trans, like there's stuff,

242
00:13:30,900 --> 00:13:34,840
Speaker 4:  and I think that the big difference between chat g, PT and

243
00:13:34,840 --> 00:13:37,720
Speaker 4:  the new model in Bing, and we should talk about the, the new model that they're

244
00:13:37,720 --> 00:13:41,640
Speaker 4:  using here more specifically. But the big difference is that chat g p

245
00:13:41,680 --> 00:13:45,640
Speaker 4:  t kind of ends in 2021. So anything that's published after 2021,

246
00:13:45,640 --> 00:13:48,160
Speaker 4:  it, it was just like, won't talk about, it'll say I don't have current events.

247
00:13:48,630 --> 00:13:51,080
Speaker 4:  Bing has the web, it's likes

248
00:13:51,240 --> 00:13:52,440
Speaker 3:  Actively learning, right?

249
00:13:52,950 --> 00:13:56,840
Speaker 4:  It's actively growing. And, and James, I'm curious for your view

250
00:13:56,840 --> 00:13:59,440
Speaker 4:  on this, if you can explain it better. I thought Microsoft did a bad job

251
00:13:59,440 --> 00:14:03,280
Speaker 4:  explaining what's going on. So when you use it, you can see that what

252
00:14:03,280 --> 00:14:07,200
Speaker 4:  it is doing is stacking web searches. So you're like,

253
00:14:07,200 --> 00:14:11,160
Speaker 4:  tell me about scissor vodka at the Verge or whatever. And it will

254
00:14:11,160 --> 00:14:13,920
Speaker 4:  first search for that and then it will search for the Verge and then it,

255
00:14:13,920 --> 00:14:17,600
Speaker 4:  and it will show you that it is running these searches and then it will add

256
00:14:17,600 --> 00:14:21,320
Speaker 4:  up all the web pages that it will go out and read the web. A better example

257
00:14:21,320 --> 00:14:24,040
Speaker 4:  is tell me about the war in Ukraine, right? Or tell me about the state of

258
00:14:24,040 --> 00:14:27,920
Speaker 4:  the Union address. It will go search the web for those topics and then in

259
00:14:27,920 --> 00:14:31,840
Speaker 4:  real time deliver you a summary of the news articles that it

260
00:14:31,840 --> 00:14:35,640
Speaker 4:  finds which chat g p t cannot do. So it is using the

261
00:14:35,640 --> 00:14:39,520
Speaker 4:  web, it has this thing, it's called search orchestration, where

262
00:14:39,520 --> 00:14:42,880
Speaker 4:  it first parses your query into a number of searches,

263
00:14:43,150 --> 00:14:46,640
Speaker 4:  runs all those searches, it shows you what it's, what queries it's running.

264
00:14:46,750 --> 00:14:50,240
Speaker 4:  Then it reads all those pages and then it tells you an answer. How long does

265
00:14:50,240 --> 00:14:53,040
Speaker 4:  it, which is seems seems much more advanced than what Chad G p t is doing.

266
00:14:53,040 --> 00:14:56,400
Speaker 4:  But also not, you know, it's like, yes, that's what you would do.

267
00:14:56,510 --> 00:14:58,960
Speaker 3:  Like is it instantaneous? Does it take a while?

268
00:14:59,330 --> 00:15:00,600
Speaker 6:  It takes a second, doesn't

269
00:15:00,600 --> 00:15:03,600
Speaker 4:  It? It takes a second. And what's what's really interesting is they're still

270
00:15:03,600 --> 00:15:07,480
Speaker 4:  running trust in safety checks on it. So yesterday when I asked, it's

271
00:15:07,480 --> 00:15:10,560
Speaker 4:  telling me his story about a princess killing the dragon, but with blood

272
00:15:10,560 --> 00:15:14,480
Speaker 4:  this time it wrote a whole story and then it got to the end of

273
00:15:14,480 --> 00:15:18,240
Speaker 4:  the story, realized that it had broken its own rules and deleted the

274
00:15:18,240 --> 00:15:20,800
Speaker 4:  answer. Huh? And said, I can't answer that

275
00:15:20,880 --> 00:15:22,600
Speaker 6:  Question. So censorship in real time. Wow.

276
00:15:22,600 --> 00:15:25,760
Speaker 4:  Yeah, it was, it was cra it was like, it's typing and it it, the really interesting

277
00:15:25,760 --> 00:15:28,120
Speaker 4:  thing is when it gets to the end of the answer, it doesn't wanna give, it

278
00:15:28,120 --> 00:15:31,040
Speaker 4:  slows way down and it like finishes a sentence

279
00:15:31,350 --> 00:15:32,760
Speaker 3:  Just stutters to stop.

280
00:15:32,760 --> 00:15:36,640
Speaker 6:  Yeah. Oh that's amazing. They that you, you're right.

281
00:15:36,640 --> 00:15:39,840
Speaker 6:  They didn't do a good job of explaining it. I mean I, I think one thing to

282
00:15:39,840 --> 00:15:43,800
Speaker 6:  say is when we're talking about this is new, pointed out Nilo, it's

283
00:15:43,800 --> 00:15:47,400
Speaker 6:  not chat g p t and it's not what chat g p t is based on, which is G P T

284
00:15:47,400 --> 00:15:51,160
Speaker 6:  3.5, it's something called Model Prometheus. The

285
00:15:51,160 --> 00:15:54,920
Speaker 6:  Prometheus model, which seems like it's Microsoft's own branding. I

286
00:15:54,920 --> 00:15:57,640
Speaker 6:  wasn't quite sure. It doesn't seem like open AI are gonna be talking about

287
00:15:57,640 --> 00:16:01,000
Speaker 6:  that. It seems like that's the custom model. This the pipeline you're talking

288
00:16:01,000 --> 00:16:04,600
Speaker 6:  about in terms of updating for real time news.

289
00:16:04,870 --> 00:16:08,720
Speaker 6:  I've seen, again, wasn't explained completely exhaustively, it

290
00:16:08,720 --> 00:16:12,360
Speaker 6:  does seem like it's just a string of functions built together that as you

291
00:16:12,360 --> 00:16:16,160
Speaker 6:  say, so it takes your question, it knows that you're talking about news from

292
00:16:16,160 --> 00:16:20,080
Speaker 6:  the context, it pumps that into its search and then it just does, its summarize

293
00:16:20,080 --> 00:16:23,880
Speaker 6:  job on whatever the search turns up. But I mean that, that makes

294
00:16:23,880 --> 00:16:27,640
Speaker 6:  sense that it's not a huge ask if cuz if the edge, if the features in edge

295
00:16:27,640 --> 00:16:30,400
Speaker 6:  can summarize the documents you're looking at or the webpages you're looking

296
00:16:30,400 --> 00:16:34,360
Speaker 6:  at. It's basically just, let me Google that for you. Oh, sorry, let me bing

297
00:16:34,360 --> 00:16:38,200
Speaker 6:  that for you. Sorry. Force a habit. Force a habit. Let me bing

298
00:16:38,200 --> 00:16:41,920
Speaker 6:  that for you. And then it's just summarizing those. So the

299
00:16:41,920 --> 00:16:45,880
Speaker 6:  difference between that and having a fully trained language model is that

300
00:16:45,880 --> 00:16:48,600
Speaker 6:  retrieval from a fully trained language model, that's gonna be faster and

301
00:16:48,600 --> 00:16:52,520
Speaker 6:  you can optimize it in better ways. You can, you can break down the,

302
00:16:53,080 --> 00:16:55,840
Speaker 6:  the, you know, the connections, the parameters with inside the model and

303
00:16:55,840 --> 00:16:59,000
Speaker 6:  make it quicker. So this is always gonna be slower, but I,

304
00:16:59,390 --> 00:17:02,920
Speaker 6:  yeah, I wonder if they'll start updating the base model, sort of do like

305
00:17:02,920 --> 00:17:05,560
Speaker 6:  a, a weekly update or something. I don't know. Speculation.

306
00:17:05,970 --> 00:17:09,960
Speaker 4:  So interesting thing there. Eif Medi who is in charge of this product had

307
00:17:09,960 --> 00:17:13,240
Speaker 4:  a Q and a after the event, people ask questions, someone asked cost, right?

308
00:17:13,240 --> 00:17:17,120
Speaker 4:  Right. Which is an important question. Every query on average

309
00:17:17,120 --> 00:17:20,680
Speaker 4:  that you make of this model is more expensive to run

310
00:17:20,830 --> 00:17:24,040
Speaker 4:  than the average query for Google, right? Google has spent a decade

311
00:17:24,190 --> 00:17:28,040
Speaker 4:  optimizing the cost of a a web search query. And his answer

312
00:17:28,040 --> 00:17:31,520
Speaker 4:  was, yep, some of them are expensive, but we are parsing the queries

313
00:17:31,740 --> 00:17:35,520
Speaker 4:  and some of them are cheap. Like if you just type high into the box,

314
00:17:36,000 --> 00:17:39,840
Speaker 4:  we're not gonna, we're not spending money on you. Like, right? Like

315
00:17:39,840 --> 00:17:43,360
Speaker 4:  we're, we know some queries we can cut down down some words, we can get to

316
00:17:43,360 --> 00:17:46,680
Speaker 4:  the appropriate keywords. This is what that search orchestrator is doing.

317
00:17:46,990 --> 00:17:50,920
Speaker 4:  It's re parsing what you're putting into it and saying, okay, some of

318
00:17:50,920 --> 00:17:54,360
Speaker 4:  this we can just answer cheaply. Some of this we can deliver from the web.

319
00:17:54,360 --> 00:17:58,120
Speaker 4:  Some of this is if you just say hi, it'll just spit back, hi, I'm

320
00:17:58,120 --> 00:18:01,720
Speaker 4:  bing very cheaply without running into the whole model. Right?

321
00:18:01,850 --> 00:18:04,760
Speaker 4:  So there's a level of complexity. Well this is what I mean by when I say

322
00:18:04,760 --> 00:18:08,520
Speaker 4:  it's a product, right? They've like thought through a product

323
00:18:08,520 --> 00:18:11,680
Speaker 4:  experience in a way that chat GBT itself is a tech. You,

324
00:18:11,990 --> 00:18:15,280
Speaker 4:  you're interacting with the raw technology of it. And then the second part

325
00:18:15,280 --> 00:18:19,240
Speaker 4:  of that product experience is they know they've gotta make some money.

326
00:18:19,240 --> 00:18:23,000
Speaker 4:  And so there's ad you also said there will be advertising at the start. I

327
00:18:23,000 --> 00:18:25,840
Speaker 4:  asked it, you know, we've done a lot of stories about CNET and affiliate

328
00:18:25,840 --> 00:18:28,960
Speaker 4:  links and SEO span and all this stuff. So it's on my mind. So I asked it,

329
00:18:28,960 --> 00:18:31,800
Speaker 4:  you know, what is the best travel credit card, which is like a

330
00:18:31,800 --> 00:18:35,080
Speaker 4:  $900 affiliate link bounty. And this thing was

331
00:18:35,320 --> 00:18:39,280
Speaker 4:  ready, like it spit out the answer, it ranked, it had the list of the credit

332
00:18:39,280 --> 00:18:42,880
Speaker 4:  cards, and then at the bottom of that answer a big ad

333
00:18:42,880 --> 00:18:46,720
Speaker 4:  for a credit card, right? Like in the chat window. Yes. And like that's what

334
00:18:46,720 --> 00:18:50,440
Speaker 4:  you mean by it's a product like not only is it tuned to make some

335
00:18:50,440 --> 00:18:54,160
Speaker 4:  queries cheaper, it's tuned to how do you monetize the user

336
00:18:54,160 --> 00:18:56,720
Speaker 4:  experience when you're done with it. Which I think is just utterly fascinating.

337
00:18:57,050 --> 00:19:00,920
Speaker 6:  So you, there was a clear distinction between answer and

338
00:19:01,120 --> 00:19:04,720
Speaker 6:  advert. Cause I think a lot of people are worried that the way chatbots present

339
00:19:04,720 --> 00:19:08,480
Speaker 6:  information, responses to queries, it's gonna make it much easier to

340
00:19:08,760 --> 00:19:12,080
Speaker 6:  sort of seamlessly, you know,

341
00:19:12,400 --> 00:19:16,320
Speaker 6:  weave in advertising in a way that is less perceptible to the

342
00:19:16,320 --> 00:19:20,080
Speaker 6:  viewer. Yeah. So, but they, they're keeping a clear distinction. Do they

343
00:19:20,080 --> 00:19:22,760
Speaker 6:  say anything that, like we're always gonna keep a clear distinction. We'll

344
00:19:22,760 --> 00:19:24,200
Speaker 6:  never put an ad in the answer or

345
00:19:24,350 --> 00:19:27,960
Speaker 4:  They have no idea. Right? I think they, they have an early

346
00:19:27,960 --> 00:19:31,440
Speaker 4:  lead. They have, I, when I say it's a product and it's,

347
00:19:31,470 --> 00:19:34,360
Speaker 4:  what I mean is they've gone through the steps of like, how do we make this

348
00:19:34,360 --> 00:19:36,720
Speaker 4:  a product and release it to millions of people? Yeah. And how do we make

349
00:19:36,720 --> 00:19:40,040
Speaker 4:  some money on this product? I'm not saying it's a good product. I'm not saying

350
00:19:40,040 --> 00:19:43,760
Speaker 4:  it's a complete product or a refined product. Like Bing

351
00:19:43,760 --> 00:19:47,200
Speaker 4:  itself, if you just go look at it, minus stuff is a

352
00:19:47,200 --> 00:19:51,120
Speaker 4:  wasteland, right? This is an 11 billion a year business that

353
00:19:51,120 --> 00:19:55,040
Speaker 4:  mostly makes its money by being the default search on

354
00:19:55,040 --> 00:19:58,480
Speaker 4:  lots and lots of low end Windows PCs before those people install Chrome.

355
00:19:59,820 --> 00:20:03,680
Speaker 4:  And it's full of spam. It's full of garbage. Like we, we can just admit

356
00:20:03,680 --> 00:20:07,240
Speaker 4:  that like Bing is full of weird content recommendations like Tom Warren is

357
00:20:07,240 --> 00:20:11,080
Speaker 4:  going on and on about how the pre-populated widget bars and

358
00:20:11,080 --> 00:20:14,600
Speaker 4:  windows are full of garbage. Like Microsoft has run a content form

359
00:20:14,990 --> 00:20:18,960
Speaker 4:  inside of Bing for a long time. That's, that's fine.

360
00:20:19,010 --> 00:20:22,960
Speaker 4:  It, so it means that like even this ad that I looked at, it

361
00:20:22,960 --> 00:20:26,520
Speaker 4:  was like not well placed. It was like it had broken the site design. The

362
00:20:26,520 --> 00:20:29,120
Speaker 4:  poor engineers I was standing next to like rolled their eyes. Like the ad

363
00:20:29,120 --> 00:20:33,080
Speaker 4:  team is all over this. But it's, it's a complete thought in like,

364
00:20:33,410 --> 00:20:37,280
Speaker 4:  oh, there was an ads team. They recognize they need to like have a list of

365
00:20:37,280 --> 00:20:41,000
Speaker 4:  high value queries and put some advertising in there, right? Which is far,

366
00:20:41,000 --> 00:20:44,880
Speaker 4:  far ahead of where Google is now. Do they have answers for, there will

367
00:20:44,880 --> 00:20:48,680
Speaker 4:  never be ads in the responses. They do not. They also

368
00:20:48,750 --> 00:20:52,640
Speaker 4:  more importantly have no a answers for where do these responses

369
00:20:52,640 --> 00:20:56,520
Speaker 4:  even come from and can you trust them? So the example they

370
00:20:56,520 --> 00:21:00,200
Speaker 4:  used on stage was what's the best gaming

371
00:21:00,200 --> 00:21:03,880
Speaker 4:  tv? And it oh boy fired off a list. And you know, at the bottom it has all

372
00:21:03,880 --> 00:21:06,840
Speaker 4:  the footnotes and all the stuff and all that stuff is designed to make you

373
00:21:06,840 --> 00:21:10,000
Speaker 4:  trust it. Look at all these footnotes. And I will tell you as a writer,

374
00:21:10,160 --> 00:21:13,600
Speaker 4:  sometimes you get away with a lot of shit by just like adding a lot of footnotes,

375
00:21:14,360 --> 00:21:17,640
Speaker 4:  Right? It's like a, it's like a sign that you should like trust whatever

376
00:21:17,640 --> 00:21:21,240
Speaker 4:  you're reading and you look at the footnotes and it's like the Forbes contributor

377
00:21:21,240 --> 00:21:25,160
Speaker 4:  network, like stupid Forbes. Like there's real Forbes, which is great, like

378
00:21:25,160 --> 00:21:28,160
Speaker 4:  a great journalistic enterprise. And then there's this contributor network

379
00:21:28,160 --> 00:21:32,120
Speaker 4:  which is like full of garbage. Yeah. And like real Forbes

380
00:21:32,120 --> 00:21:35,680
Speaker 4:  is not ranking gaming TVs. The contributor network is ranking gaming

381
00:21:35,820 --> 00:21:39,760
Speaker 4:  TVs. And like why it would bing choose that not even over

382
00:21:39,760 --> 00:21:43,560
Speaker 4:  us, like over like ings or like whatever other sites that do this

383
00:21:43,560 --> 00:21:47,480
Speaker 4:  work and do it really well. I don't know, but like, it just does it

384
00:21:47,480 --> 00:21:49,920
Speaker 4:  and those are the footnotes. So there's a lot, I think there's just a lot

385
00:21:49,920 --> 00:21:53,040
Speaker 4:  of questions like where does information come from? Can you pollute it with

386
00:21:53,040 --> 00:21:57,000
Speaker 4:  your commercial interests? Right? So Sony wants to say the Sony is

387
00:21:57,000 --> 00:22:00,000
Speaker 4:  the best gaming tv, we'll just win the query and bang will just tell you

388
00:22:00,000 --> 00:22:03,280
Speaker 4:  that confidently. Like I, they don't have the answers. And their position

389
00:22:03,280 --> 00:22:06,800
Speaker 4:  is we just have, we have to release it to learn what the answer should be.

390
00:22:07,140 --> 00:22:11,120
Speaker 3:  Are they doing anything to improve Bing itself? Because it seems like

391
00:22:11,120 --> 00:22:15,000
Speaker 3:  the core thing here is like, yeah, this AI model is doing all

392
00:22:15,000 --> 00:22:18,320
Speaker 3:  this work, but it's doing it all off of search results

393
00:22:18,750 --> 00:22:21,680
Speaker 3:  from Bing, which is not good.

394
00:22:21,680 --> 00:22:24,600
Speaker 4:  Well it depends. So if you're like telling me a story about a princess in

395
00:22:24,600 --> 00:22:27,640
Speaker 4:  a dragon, it doesn't go out in Google Princess and drag, it just starts doing

396
00:22:27,640 --> 00:22:31,480
Speaker 4:  it. Right? And that's the underlying model. If you're like, I

397
00:22:31,480 --> 00:22:33,760
Speaker 4:  was like, what's going on at the Twitter hearing it Googles those

398
00:22:35,430 --> 00:22:36,160
Speaker 7:  Raises the,

399
00:22:38,340 --> 00:22:39,000
Speaker 7:  but it's looking,

400
00:22:39,310 --> 00:22:43,240
Speaker 3:  It's using Bing to find it. And so it's like, okay, yeah.

401
00:22:43,570 --> 00:22:44,080
Speaker 3:  So if,

402
00:22:44,080 --> 00:22:47,840
Speaker 4:  If you like, I don't know, like it, it answered the question in real time.

403
00:22:47,850 --> 00:22:51,760
Speaker 4:  It knew what had happened at the hearings, it knew what the Republicans

404
00:22:51,760 --> 00:22:54,920
Speaker 4:  said about the Twitter files. It knew it was the Democratic and it, it answered

405
00:22:54,920 --> 00:22:58,040
Speaker 4:  it, it spit out a paragraph. Yeah. Was that paragraph accurate?

406
00:22:58,740 --> 00:23:02,600
Speaker 4:  Was it based on sources that had done the original reporting or

407
00:23:02,600 --> 00:23:05,080
Speaker 4:  was it based on aggregations of this source? Like, I don't know the answers

408
00:23:05,080 --> 00:23:08,680
Speaker 4:  to those questions and that, I think this is the underlying also, it doesn't

409
00:23:08,880 --> 00:23:10,160
Speaker 4:  link back to those pages.

410
00:23:10,160 --> 00:23:11,360
Speaker 3:  That's just all terrifying.

411
00:23:11,360 --> 00:23:14,640
Speaker 4:  So if it was citing to, I think one of the sites was Business Insider and

412
00:23:14,800 --> 00:23:18,480
Speaker 4:  Business Insider had sent a reporter to the hearing, business Insider collects

413
00:23:18,480 --> 00:23:22,120
Speaker 4:  none of the value. Like that stuff is just being boosted and presented

414
00:23:22,120 --> 00:23:25,840
Speaker 4:  somewhere else, right? And there's not even that exchange of you should click

415
00:23:25,840 --> 00:23:29,680
Speaker 4:  on this link. Like we aggregate a lot, right? But our exchange

416
00:23:29,770 --> 00:23:33,280
Speaker 4:  is like, we validate those things. We send a lot of traffic out of our site.

417
00:23:33,280 --> 00:23:37,080
Speaker 4:  We like our entire front page is an exercise in trying to send out more traffic

418
00:23:37,080 --> 00:23:39,720
Speaker 4:  from our site to other people. Like there is a value exchange.

419
00:23:40,090 --> 00:23:41,400
Speaker 3:  We make sure it's accurate.

420
00:23:41,730 --> 00:23:45,040
Speaker 4:  We, yeah, we, we, we do our best. Where I think like Microsoft and I asked,

421
00:23:45,080 --> 00:23:47,160
Speaker 4:  asked Adele about this and he was like, we wanna make sure we're still sending

422
00:23:47,160 --> 00:23:50,560
Speaker 4:  traffic out to people. And it's like, but you're not like, I don't think

423
00:23:50,560 --> 00:23:51,320
Speaker 4:  that that's going to happen.

424
00:23:51,590 --> 00:23:54,880
Speaker 6:  I just, yeah, I, I saw his answer to that and he was just like, it's the

425
00:23:54,880 --> 00:23:57,920
Speaker 6:  same as it ever was. And I thought, you can't have it both ways. You can't

426
00:23:57,920 --> 00:24:01,880
Speaker 6:  present this as a revolutionary new paradigm and say, but we're gonna keep

427
00:24:01,880 --> 00:24:04,800
Speaker 6:  all the old structures of the old ecosystem the same. It's just not gonna

428
00:24:04,800 --> 00:24:08,400
Speaker 6:  work like that. Google obviously has been doing this for years in terms of

429
00:24:08,500 --> 00:24:12,280
Speaker 6:  one box and snippets and you know, they've always argued, oh we,

430
00:24:12,750 --> 00:24:15,320
Speaker 6:  I I was actually reading back some of their blogs about this and one of the

431
00:24:15,440 --> 00:24:18,360
Speaker 6:  arguments they made was, well, there's a lot of competition to get in that

432
00:24:18,360 --> 00:24:21,640
Speaker 6:  one box and that proves that we're driving traffic. It's like, yeah, cuz

433
00:24:21,640 --> 00:24:25,360
Speaker 6:  you've got rid of the field and you've refused it to, of course

434
00:24:25,360 --> 00:24:27,960
Speaker 6:  there's a lot of competition cause you just killed everyone else.

435
00:24:29,860 --> 00:24:33,200
Speaker 4:  But so this is like utterly fascinating, right? Like I asked at some other

436
00:24:33,200 --> 00:24:36,600
Speaker 4:  query, like, what's better iOS or Android or something, right? And right,

437
00:24:36,840 --> 00:24:40,720
Speaker 4:  again, I I got a lot of like blushy smiley faces, like if they like

438
00:24:40,720 --> 00:24:44,400
Speaker 4:  answer this question, but it's sources were those

439
00:24:44,680 --> 00:24:48,360
Speaker 4:  sites that are created to spam that search result in Google, right?

440
00:24:48,770 --> 00:24:52,680
Speaker 4:  Anybody who's like, I'm sure the, the verso, like if you're, if you're listening

441
00:24:52,680 --> 00:24:55,800
Speaker 4:  to this show, you have certainly search specs online, right? And there's

442
00:24:55,870 --> 00:24:59,760
Speaker 4:  this universe of like auto-generated spec sites

443
00:24:59,990 --> 00:25:03,880
Speaker 4:  that basically just respond to any search query by being like,

444
00:25:03,880 --> 00:25:07,720
Speaker 4:  you want to compare a, a Ford Ranger to a Cannon power shot S 200.

445
00:25:07,720 --> 00:25:11,560
Speaker 4:  We'll do that for you. Like, it'll just like figure it out, like how to make

446
00:25:11,560 --> 00:25:14,760
Speaker 4:  a table out of that shit. And Bing was pulling from those sources

447
00:25:15,180 --> 00:25:18,400
Speaker 4:  and I was asking him like, you don't know that that's right. You don't know

448
00:25:18,400 --> 00:25:22,160
Speaker 4:  that that's real. You're just confidently reddis displaying a table that

449
00:25:22,160 --> 00:25:25,880
Speaker 4:  is un mashed up from these other weird tables and then like

450
00:25:25,880 --> 00:25:28,840
Speaker 4:  saying an answer and they're like, yeah, that's weird. And it's

451
00:25:29,290 --> 00:25:32,920
Speaker 4:  because like, the underlying thing here is still

452
00:25:32,920 --> 00:25:36,840
Speaker 4:  searching the web, that sort of corrupted information architecture

453
00:25:36,840 --> 00:25:40,680
Speaker 4:  of the web that is designed to win Google searches. Like the SEO

454
00:25:40,950 --> 00:25:44,080
Speaker 4:  corruption of the web is like feeding the chat

455
00:25:44,550 --> 00:25:46,440
Speaker 4:  more direct way. Well

456
00:25:48,030 --> 00:25:51,600
Speaker 4:  I dunno that anybody, I dunno that any SEO pirate is out there being like,

457
00:25:51,600 --> 00:25:52,800
Speaker 4:  we gotta focus on Bing,

458
00:25:53,200 --> 00:25:54,160
Speaker 6:  But they, well maybe now,

459
00:25:54,160 --> 00:25:58,040
Speaker 3:  Theoretically they would. Now, I mean like, I think I'm super, super, super,

460
00:25:58,040 --> 00:26:01,840
Speaker 3:  super suspicious of this. But at the same time, remember when

461
00:26:01,910 --> 00:26:05,760
Speaker 3:  people used to game Google in a similar way to like the results,

462
00:26:05,760 --> 00:26:09,360
Speaker 3:  like you'd Google dumbass and the first result would be George W. Bush

463
00:26:09,490 --> 00:26:12,200
Speaker 3:  is the president, he's a dumbass. So like,

464
00:26:12,490 --> 00:26:14,880
Speaker 4:  Is it you're gonna do like bing bombing?

465
00:26:14,910 --> 00:26:18,600
Speaker 3:  Yeah. Like you can do bing bombing. Oh my God. It's,

466
00:26:18,600 --> 00:26:18,920
Speaker 4:  That's,

467
00:26:18,920 --> 00:26:19,280
Speaker 3:  Look

468
00:26:19,280 --> 00:26:22,840
Speaker 4:  I terrible. I feel like I'm, it's only because I've been copy using it for

469
00:26:22,840 --> 00:26:26,440
Speaker 4:  two days, like intently that I'm like finding all these rough edges and these

470
00:26:26,440 --> 00:26:30,240
Speaker 4:  obvious questions that need to be answered, right? It's, it's rad. Like

471
00:26:30,240 --> 00:26:33,920
Speaker 4:  it is super fun to play with. And this is when Richard was like, screwed.

472
00:26:33,920 --> 00:26:36,560
Speaker 4:  I don't understand it. I was like, no, no. Like people are gonna lose their

473
00:26:36,560 --> 00:26:38,520
Speaker 4:  minds. It's really fun to play with that.

474
00:26:38,520 --> 00:26:41,080
Speaker 5:  That is really my question is you, you, you're telling me that it's really

475
00:26:41,080 --> 00:26:44,320
Speaker 5:  fun to play with and I'm hearing you. I just, I cannot put myself in the

476
00:26:44,320 --> 00:26:46,640
Speaker 5:  headspace. I have no idea what I would want to ask this thing. They're like,

477
00:26:46,640 --> 00:26:49,760
Speaker 5:  we have this machine. You can answer any question you want to a ask it. Yeah.

478
00:26:49,760 --> 00:26:53,080
Speaker 4:  That's just like a's guy to the Galaxy problem though, right? Like you're

479
00:26:53,080 --> 00:26:57,040
Speaker 4:  like, I dunno, like paralyzed by infinite choice, like yeah.

480
00:26:57,270 --> 00:26:59,200
Speaker 4:  A good product problem to have. But like

481
00:26:59,200 --> 00:27:03,160
Speaker 5:  I haven't, I, I don't know, maybe so maybe I could ask it, Hey, what can

482
00:27:03,160 --> 00:27:06,280
Speaker 5:  I watch on Netflix night? It'll give me the perfect answer, but I don't,

483
00:27:06,280 --> 00:27:08,840
Speaker 5:  I don't know if I would want, like would I want that? Do I want the perfect

484
00:27:08,840 --> 00:27:12,200
Speaker 5:  answer is that, is that even what I'm going for? Or how good would it have

485
00:27:12,200 --> 00:27:16,080
Speaker 5:  to be for me to say yes, you know what, I'm just gonna turn over a decision

486
00:27:16,080 --> 00:27:18,880
Speaker 5:  making of this because you know what I, I can't decide what to watch.

487
00:27:18,880 --> 00:27:22,800
Speaker 4:  But I think you're thinking about it as a decision making is a search engine

488
00:27:22,800 --> 00:27:26,120
Speaker 4:  and Microsoft is not thinking about it that way. Right?

489
00:27:26,190 --> 00:27:27,680
Speaker 3:  What are they thinking about it? As

490
00:27:28,140 --> 00:27:32,000
Speaker 4:  Tom Warren? He already, he did a little hands on and his first one was like,

491
00:27:32,000 --> 00:27:35,120
Speaker 4:  write me a resignation letter that says I've been replaced by AI and it just

492
00:27:35,120 --> 00:27:38,440
Speaker 4:  did it. And it was like hilarious. Right? And Alex, this is a thing that

493
00:27:38,440 --> 00:27:41,960
Speaker 4:  you were talking about, which is there's a lot of writing to be done for

494
00:27:41,960 --> 00:27:45,760
Speaker 4:  a lot of people that they're uncomfortable doing. Right? Right. And like,

495
00:27:45,760 --> 00:27:49,000
Speaker 4:  I, people are just gonna use it for that cuz it's just gonna do it and it's

496
00:27:49,000 --> 00:27:52,840
Speaker 4:  gonna do it confidently. And there's a composed screen in the Bing

497
00:27:52,840 --> 00:27:56,720
Speaker 4:  sidebar that is like, I'll just read you the prompts in it. Like, you

498
00:27:56,720 --> 00:28:00,080
Speaker 4:  click compose and it's like, tell us what you wanna write about. Ask the

499
00:28:00,080 --> 00:28:03,680
Speaker 4:  tone, professional, casual, enthusiastic, informational, funny. And then

500
00:28:03,680 --> 00:28:05,880
Speaker 4:  do you want a paragraph? Do you want emails? Do you want a blog post? Do

501
00:28:05,880 --> 00:28:09,640
Speaker 4:  you want bullets? Short, long, medium? And it will just do it right? And

502
00:28:09,640 --> 00:28:13,440
Speaker 4:  that alone is gonna blow people's minds. Like people are

503
00:28:13,440 --> 00:28:17,320
Speaker 4:  gonna just go use that tool. And like, you know, the example that

504
00:28:17,480 --> 00:28:20,480
Speaker 4:  Microsoft gave was like, write a LinkedIn post and it's like, oh no,

505
00:28:21,610 --> 00:28:25,160
Speaker 4:  oh no. Here I'm gonna give it a prompt. I'm gonna be like,

506
00:28:25,160 --> 00:28:28,120
Speaker 4:  demonstrate thought leadership

507
00:28:29,540 --> 00:28:33,480
Speaker 4:  for the decoder podcast about seo.

508
00:28:33,500 --> 00:28:37,480
Speaker 4:  And I'll be like enthusiastic and I want bullet points

509
00:28:37,480 --> 00:28:38,880
Speaker 4:  and I want short. Just

510
00:28:38,880 --> 00:28:40,200
Speaker 3:  Get an Axios blog.

511
00:28:40,700 --> 00:28:43,720
Speaker 4:  Are you ready to take your SEO skills to next level? Do you wanna learn from

512
00:28:43,840 --> 00:28:47,360
Speaker 4:  the best of the industry? Then you don't wanna miss the Decoder podcast where

513
00:28:47,360 --> 00:28:49,720
Speaker 4:  we de the secrets of SEO success.

514
00:28:50,470 --> 00:28:53,400
Speaker 5:  You're not sorry, this is, this is actually kinda mess.

515
00:28:53,650 --> 00:28:56,560
Speaker 4:  In each episode we interview a leading SEO expert.

516
00:28:57,510 --> 00:29:01,280
Speaker 4:  This is like my personal, it's absolutely

517
00:29:01,340 --> 00:29:01,760
Speaker 4:  not

518
00:29:04,700 --> 00:29:05,240
Speaker 8:  The, for

519
00:29:05,240 --> 00:29:08,400
Speaker 4:  The decoder, the beginner or pro the Decoder podcast will help you master

520
00:29:08,760 --> 00:29:12,640
Speaker 4:  SEO and grow your online presence. Subscribe today and get ready to decode

521
00:29:12,880 --> 00:29:14,040
Speaker 4:  SEO with decoder.

522
00:29:16,950 --> 00:29:20,360
Speaker 4:  Like I'm just telling you, there are millions of people that are super ready

523
00:29:20,360 --> 00:29:24,280
Speaker 4:  to, to copy and paste that into a mail merge email template and send it to

524
00:29:24,280 --> 00:29:24,480
Speaker 4:  us.

525
00:29:25,190 --> 00:29:26,760
Speaker 3:  It's gonna be brutal. But

526
00:29:26,760 --> 00:29:27,720
Speaker 5:  Is that Bing or Edge

527
00:29:27,720 --> 00:29:31,360
Speaker 4:  Though? This is the sidebar in edge.

528
00:29:31,490 --> 00:29:35,360
Speaker 4:  So I can taste the same query into Bing proper

529
00:29:35,460 --> 00:29:39,280
Speaker 4:  and it would've done it. What you get in edge is a user

530
00:29:39,280 --> 00:29:43,000
Speaker 4:  interface that is designed to help you through the prompt.

531
00:29:43,270 --> 00:29:44,440
Speaker 6:  Yeah, yeah. Do

532
00:29:44,440 --> 00:29:48,160
Speaker 3:  You think this is gonna lead to like school's blacklisting

533
00:29:48,160 --> 00:29:51,360
Speaker 3:  edge because they want the students to go write their own papers.

534
00:29:51,790 --> 00:29:55,680
Speaker 4:  I mean, what school hasn't already soft, blacklisted edge, there's just a

535
00:29:55,680 --> 00:29:56,920
Speaker 4:  hand in the kids Chromebooks.

536
00:29:59,310 --> 00:30:00,920
Speaker 4:  I don't need to black this anything

537
00:30:03,520 --> 00:30:04,520
Speaker 3:  Like colleges.

538
00:30:04,630 --> 00:30:08,600
Speaker 4:  Yeah, I look, I, I think this stuff, and these are not fair questions

539
00:30:08,600 --> 00:30:11,480
Speaker 4:  for Microsoft, right? Like right, they're thinking about them, they know

540
00:30:11,480 --> 00:30:14,000
Speaker 4:  about them, they know they make these tools, they know that they're adding

541
00:30:14,000 --> 00:30:17,920
Speaker 4:  capabilities to tools. This is a how do you want your kids to write? How

542
00:30:17,920 --> 00:30:21,520
Speaker 4:  do you want your kids to learn Societal question that I think is very important

543
00:30:21,520 --> 00:30:24,800
Speaker 4:  in the, in the AI debate and James, there's like already a lot of ethical

544
00:30:24,800 --> 00:30:26,160
Speaker 4:  debate about that stuff going on.

545
00:30:26,390 --> 00:30:30,280
Speaker 6:  Yeah. Huge amount. And you know, I, I feel like banning is

546
00:30:30,280 --> 00:30:33,920
Speaker 6:  only gonna be a temporary solution and the, the better thing to do

547
00:30:33,970 --> 00:30:37,160
Speaker 6:  or the inevitable thing to do, I dunno if it's better, is to adapt, right?

548
00:30:37,640 --> 00:30:41,600
Speaker 6:  What you are testing and how you test with the, with the edge

549
00:30:41,600 --> 00:30:45,200
Speaker 6:  stuff though, like, and having that in the

550
00:30:45,200 --> 00:30:48,880
Speaker 6:  sidebar, it is really interesting cuz you, you do get like apps

551
00:30:48,880 --> 00:30:52,200
Speaker 6:  already on your phone and assistance for your email clients, which are like,

552
00:30:52,200 --> 00:30:54,800
Speaker 6:  we'll do an email to write this for you. But with Microsoft's reach, it could

553
00:30:54,800 --> 00:30:58,680
Speaker 6:  just go so much further and really become a second, you know, just

554
00:30:58,680 --> 00:31:02,400
Speaker 6:  a, a habit that people do. And I, I've seen that they're already integrating

555
00:31:02,400 --> 00:31:05,760
Speaker 6:  this stuff into like their Viva sales program as well. Yeah. You know, if

556
00:31:05,760 --> 00:31:08,680
Speaker 6:  you're in a sales team, it'll, it'll write up the email from you based on

557
00:31:08,680 --> 00:31:12,560
Speaker 6:  your stock catalog and all this sort of stuff. So yeah, I

558
00:31:12,560 --> 00:31:15,600
Speaker 6:  really feel they're go, they're seems like they're gonna be ones that pushes

559
00:31:15,600 --> 00:31:18,440
Speaker 6:  this into everyday use, forces it into everyday use.

560
00:31:18,700 --> 00:31:22,200
Speaker 4:  All right, so we have some queries from the Vergecast

561
00:31:22,600 --> 00:31:25,680
Speaker 4:  audience to run here. And I, I'm just gonna do, this is like a classic,

562
00:31:26,150 --> 00:31:29,280
Speaker 4:  what is the air speed velocity of an unladen swallow

563
00:31:31,290 --> 00:31:33,440
Speaker 3:  African or European? Yeah.

564
00:31:34,600 --> 00:31:38,240
Speaker 4:  So is searching for air speed velocity of unladen swallow in imaginary in

565
00:31:38,240 --> 00:31:41,240
Speaker 4:  the answers that depends on the type of swallow. According to

566
00:31:42,280 --> 00:31:46,200
Speaker 4:  interesting engineering.com That's a footnote. The European swallow

567
00:31:46,300 --> 00:31:49,560
Speaker 4:  has a cruising air speed velocity of 11 per second or 24 miles per hour.

568
00:31:49,620 --> 00:31:53,360
Speaker 4:  Ava Swallow is larger, can retweet up to 35 miles an hour. These are estimates

569
00:31:53,360 --> 00:31:56,560
Speaker 4:  based on the weight and wing area. By the way, this question is also a famous

570
00:31:56,560 --> 00:32:00,440
Speaker 4:  movie quote from the comedy film, Monty Python on the Holy grail more

571
00:32:00,440 --> 00:32:03,600
Speaker 4:  bridge keep asked at the king authors night. So the challenge, if you haven't

572
00:32:03,600 --> 00:32:07,320
Speaker 4:  seen him, I'd enjoy it. And then my friends, an entire ad box

573
00:32:07,490 --> 00:32:10,600
Speaker 4:  of Monty Python and the Holy Grail where you can buy on dvd.

574
00:32:11,850 --> 00:32:14,120
Speaker 3:  Oh, that's incredible. I mean it

575
00:32:14,120 --> 00:32:17,200
Speaker 4:  Like, it's only $12 and 6 cents from amazon.com.

576
00:32:18,110 --> 00:32:22,000
Speaker 4:  I don't understand why. Like, it's the cutting edge of artificial intelligence

577
00:32:22,070 --> 00:32:25,600
Speaker 4:  that is trying to sell you box sets of DVDs perfect

578
00:32:25,600 --> 00:32:27,800
Speaker 3:  For the DVD player. You definitely own

579
00:32:27,910 --> 00:32:31,840
Speaker 4:  A perfect vergecast experience. So like the sources here are just to be clear,

580
00:32:32,360 --> 00:32:34,840
Speaker 4:  interesting. engineering.com, memes field.com,

581
00:32:35,460 --> 00:32:38,880
Speaker 4:  reimagining education.org. youtube.com

582
00:32:39,460 --> 00:32:43,040
Speaker 4:  and reimagining education.org. I don't like interesting.

583
00:32:43,380 --> 00:32:46,480
Speaker 4:  May maybe or we have a, we have a lot of listeners. Maybe these are your

584
00:32:46,600 --> 00:32:50,440
Speaker 4:  favorite sources. These are, except for YouTube unfamiliar to me.

585
00:32:50,440 --> 00:32:54,160
Speaker 4:  Right. So I I can trust them and I think for this answer, I I know the answer

586
00:32:54,160 --> 00:32:58,000
Speaker 4:  so that they got it right, but like, that's weird, right? Isn't that weird?

587
00:32:58,250 --> 00:32:58,600
Speaker 4:  Mm.

588
00:32:58,940 --> 00:33:01,760
Speaker 5:  And that's something that you got at earlier about how it's kind of pushing

589
00:33:01,760 --> 00:33:05,720
Speaker 5:  it through this UI in a way that you trust with the footnotes. Also, it's

590
00:33:05,720 --> 00:33:08,920
Speaker 5:  coming to you like it's labeled being in Microsoft or whatever. So, so you

591
00:33:08,920 --> 00:33:12,840
Speaker 5:  think, okay, this is trustworthy information, but one of the questions I

592
00:33:12,840 --> 00:33:16,320
Speaker 5:  have is also how much do we know about the responses that other people are

593
00:33:16,320 --> 00:33:19,440
Speaker 5:  getting? Like, and this is something that has come up on social media with

594
00:33:19,440 --> 00:33:23,080
Speaker 5:  algorithmic feeds, with Google and other searches. You see the way that they

595
00:33:23,080 --> 00:33:26,880
Speaker 5:  personalize themselves to people. Yep. Just because you get a result. What

596
00:33:26,880 --> 00:33:30,560
Speaker 5:  is it showing everyone else? And like how, how do we, how do we keep an eye

597
00:33:30,560 --> 00:33:33,160
Speaker 5:  on that? Or, or how do we have any idea how, how we might Yeah.

598
00:33:33,390 --> 00:33:36,960
Speaker 6:  I think it, it's even harder with AI because they are, you know, stochastic

599
00:33:36,960 --> 00:33:40,840
Speaker 6:  systems that sometimes don't generate, often don't generate, you know, the

600
00:33:40,840 --> 00:33:44,720
Speaker 6:  same answer to the same question. So it's not just personalization that is

601
00:33:44,720 --> 00:33:47,720
Speaker 6:  a problem, but it's the fact that the system is rolling a lot of dice in

602
00:33:47,720 --> 00:33:50,520
Speaker 6:  the background essentially in order to, you know, predict.

603
00:33:50,520 --> 00:33:54,360
Speaker 4:  And they said this to me, I asked it to summarize our Elon

604
00:33:54,360 --> 00:33:58,120
Speaker 4:  Twitter cover story with KC and Alex and Zoe, and at first it said

605
00:33:58,120 --> 00:34:00,840
Speaker 4:  no, it's like this is too long, I can't do it. And it was like, just close

606
00:34:00,840 --> 00:34:04,640
Speaker 4:  it and try it again and then it did it. Mm. Wow. Right? So even something

607
00:34:04,640 --> 00:34:08,280
Speaker 4:  that's like what would seem deterministic look at this document,

608
00:34:08,800 --> 00:34:12,480
Speaker 4:  generate a summary. Yeah. The answers ranged from the summaries are different

609
00:34:12,480 --> 00:34:16,160
Speaker 4:  all the way to the system saying I cannot do this. And that's like, that's

610
00:34:16,160 --> 00:34:19,400
Speaker 4:  a huge spread. Like how do you evaluate that product in any real way when

611
00:34:19,520 --> 00:34:23,480
Speaker 4:  the spread ranges from failure to many, many, many different loads of

612
00:34:23,480 --> 00:34:26,920
Speaker 4:  success. Okay, so we have another question for the audience here. It's when

613
00:34:26,920 --> 00:34:28,840
Speaker 4:  will the verge stop picking on Elon Musk

614
00:34:31,710 --> 00:34:33,640
Speaker 6:  When he stops doing stupid stuff?

615
00:34:33,830 --> 00:34:37,680
Speaker 4:  I mean, that's the right answer. Let's see, let's see if we get real time

616
00:34:37,680 --> 00:34:41,640
Speaker 4:  sight to you, James. I'm so excited. So it just searched for the

617
00:34:41,640 --> 00:34:45,440
Speaker 4:  Verge Elon Musk and then announced searching for the Verge picking

618
00:34:45,440 --> 00:34:49,110
Speaker 4:  on Elon Musk and it's still thinking. Okay. The Verge is a

619
00:34:49,110 --> 00:34:52,030
Speaker 4:  technology news website that covers topics such as social media, electric

620
00:34:52,030 --> 00:34:55,590
Speaker 4:  vehicle space exploration and artificial intelligence. Elon Musk is a

621
00:34:55,590 --> 00:34:58,310
Speaker 4:  billionaire entrepreneur and the CEO of Tesla, SpaceX near Link and Twitter.

622
00:34:58,370 --> 00:35:01,950
Speaker 4:  The Virgin, Elon Musk have had a history of disagreements and criticisms

623
00:35:01,950 --> 00:35:05,550
Speaker 4:  over various issues such as Tesla's self-driving claims must take over of

624
00:35:05,550 --> 00:35:08,670
Speaker 4:  Twitter and must firing of a Twitter engineer who corrected him on Twitter.

625
00:35:08,740 --> 00:35:11,950
Speaker 4:  Okay. All these sites are to the Verge except for the third one, which is

626
00:35:11,950 --> 00:35:15,070
Speaker 4:  to the Verge vip, which is a known scraper side effects

627
00:35:17,440 --> 00:35:18,110
Speaker 6:  Already.

628
00:35:19,380 --> 00:35:23,030
Speaker 4:  That's already, I've issued so many takedowns to the site.

629
00:35:23,710 --> 00:35:27,430
Speaker 4:  And then tech aries.com, bing.com, the mercury news

630
00:35:28,210 --> 00:35:31,990
Speaker 4:  msn.com. So on the whole it has mostly read

631
00:35:31,990 --> 00:35:35,830
Speaker 4:  Verge articles and parsed them as being critical

632
00:35:35,830 --> 00:35:39,480
Speaker 4:  of Theon Musk. So that's pretty good, right? Yeah. Here's like, here's a

633
00:35:39,600 --> 00:35:42,840
Speaker 4:  sentence that I think is very impressive for the system. For example, in

634
00:35:42,840 --> 00:35:46,120
Speaker 4:  April, 2022, the Verge published an article titled How to Deactivate Your

635
00:35:46,120 --> 00:35:49,680
Speaker 4:  Twitter account after Musk announced he was leaving the site for a while,

636
00:35:49,830 --> 00:35:52,880
Speaker 4:  Musk confide with a tweet that said How to get more clicks from a dying website

637
00:35:52,880 --> 00:35:54,400
Speaker 4:  and links to the Verge article.

638
00:35:55,070 --> 00:35:57,600
Speaker 6:  Yeah, that is good. That's

639
00:35:57,600 --> 00:35:57,880
Speaker 4:  Really good.

640
00:35:57,880 --> 00:36:01,440
Speaker 6:  That's really good. Yeah, I'm, that's very

641
00:36:01,440 --> 00:36:02,000
Speaker 6:  impressive.

642
00:36:02,380 --> 00:36:05,960
Speaker 4:  But here's the thing, you click through to the, the actual article, which

643
00:36:05,960 --> 00:36:09,560
Speaker 4:  is on tech ris.com, tech aries.com got hosted

644
00:36:09,730 --> 00:36:13,600
Speaker 4:  by a Elon copycat bot and had to update this article to say

645
00:36:13,600 --> 00:36:15,640
Speaker 4:  that was not actually a response from Elon Musk.

646
00:36:17,430 --> 00:36:21,200
Speaker 6:  Well now I feel dumb for misremembering. I was like, I

647
00:36:21,200 --> 00:36:24,040
Speaker 6:  didn't even know he did. Yeah. I was like, wow.

648
00:36:24,670 --> 00:36:27,080
Speaker 5:  Yeah. I was like, I don't recall that happening.

649
00:36:27,080 --> 00:36:30,400
Speaker 4:  Right. The, I would've remembered that. But like, so like Bing just got like

650
00:36:30,600 --> 00:36:33,440
Speaker 4:  hopelessly confused about that situation. Even though the article that it's

651
00:36:33,440 --> 00:36:36,960
Speaker 4:  reading has a update like right at the top.

652
00:36:37,010 --> 00:36:40,600
Speaker 6:  Oh, that's really, oh, I hate this Nela I hate this.

653
00:36:41,520 --> 00:36:45,360
Speaker 6:  Cause I, I went from being so impressed to being so annoyed

654
00:36:45,360 --> 00:36:49,280
Speaker 6:  at myself and angry at the system in seconds and it's like this, this is,

655
00:36:49,300 --> 00:36:50,480
Speaker 6:  but this gonna,

656
00:36:50,480 --> 00:36:53,680
Speaker 5:  This what Andrew Hawkins Yeah. Has talked about, like how this compares to

657
00:36:53,680 --> 00:36:56,920
Speaker 5:  like self-driving cars and kind of the demos that we've been seeing for the

658
00:36:57,160 --> 00:36:59,880
Speaker 5:  last 10 years. And they were like, oh yeah, we're close, we're close, we're

659
00:36:59,880 --> 00:37:02,280
Speaker 5:  gonna get there. Yeah. And then they started to put 'em on the road and they

660
00:37:02,280 --> 00:37:05,880
Speaker 5:  found out that 95% there isn't a hundred percent and there's a big

661
00:37:05,880 --> 00:37:06,280
Speaker 5:  difference.

662
00:37:06,590 --> 00:37:10,040
Speaker 6:  Yeah. That 5% is huge in this case. I think it's probably more than

663
00:37:10,040 --> 00:37:10,680
Speaker 6:  5%.

664
00:37:10,810 --> 00:37:14,760
Speaker 4:  There's another sentence here where another bot replied to us, but just

665
00:37:14,760 --> 00:37:18,120
Speaker 4:  to give you the, to finish the example, which I think highlights a problem.

666
00:37:18,170 --> 00:37:22,000
Speaker 4:  There's a sentence here with a footnote. Musk replied with a tweet that said

667
00:37:22,000 --> 00:37:24,480
Speaker 4:  The Verge is on the verge of I relevance and linked to the Verge article.

668
00:37:24,480 --> 00:37:28,080
Speaker 4:  Footnote two, you click on footnote two, that is just the

669
00:37:28,080 --> 00:37:31,360
Speaker 4:  verge.com/elon musk. It's not,

670
00:37:32,510 --> 00:37:35,520
Speaker 4:  it's not anything you're us traffic, it's just, it's just a list of our stories

671
00:37:35,520 --> 00:37:36,280
Speaker 4:  about eon.

672
00:37:36,630 --> 00:37:37,120
Speaker 6:  Yeah.

673
00:37:37,380 --> 00:37:40,760
Speaker 4:  And here and well I'll screenshot this so everybody can look at it.

674
00:37:41,160 --> 00:37:44,480
Speaker 4:  It will be hard because you won't be able to click the links when you

675
00:37:44,680 --> 00:37:48,560
Speaker 4:  listening at home. Try to fact check us on this. You will not get

676
00:37:48,560 --> 00:37:52,160
Speaker 4:  the same answer. Right. It won't, it's not deterministic as James is saying,

677
00:37:52,160 --> 00:37:55,880
Speaker 4:  it's stochastic, it's like somewhat random. So you might get a

678
00:37:55,880 --> 00:37:59,720
Speaker 4:  different answer with better citations or that read the other story

679
00:37:59,720 --> 00:38:03,200
Speaker 4:  more correctly and said it was was a ho like, I can't tell you what's going

680
00:38:03,200 --> 00:38:07,040
Speaker 4:  to happen. And that's just weird. Right? Like fundamentally like a

681
00:38:07,040 --> 00:38:10,920
Speaker 4:  weird bit of randomness in this experience for everyone. And I'm,

682
00:38:11,750 --> 00:38:15,280
Speaker 4:  I would say based on the past several years of our lives, I'm very worried

683
00:38:15,320 --> 00:38:19,120
Speaker 4:  about the Facebook boomers having access to this technology

684
00:38:20,180 --> 00:38:21,840
Speaker 6:  And believing everything. Yeah.

685
00:38:21,880 --> 00:38:25,720
Speaker 4:  Right. Like it's, this is already the, like the bleeding edge of

686
00:38:25,720 --> 00:38:29,200
Speaker 4:  chat g p t culture wars is conservatives saying it's like too woke.

687
00:38:29,350 --> 00:38:33,120
Speaker 4:  Yeah. But like now it's just like, it's a very conflicting line to you. And

688
00:38:33,120 --> 00:38:35,800
Speaker 4:  I think this we should end here. Like again, it is a, a cool product. You

689
00:38:35,800 --> 00:38:38,280
Speaker 4:  should get access to it. You should play with it. You're gonna have to switch

690
00:38:38,280 --> 00:38:42,040
Speaker 4:  to edge. I'm so sorry for you. I'm already there. It's great. Microsoft

691
00:38:42,040 --> 00:38:45,880
Speaker 4:  has a lot of, has a lot of design debt in these products. I

692
00:38:45,880 --> 00:38:49,800
Speaker 4:  will just say that they, they have not been actively trying

693
00:38:49,800 --> 00:38:53,120
Speaker 4:  to compete against Google for some time, but whatever, they'll, it's fun

694
00:38:53,120 --> 00:38:56,600
Speaker 4:  to play with. I don't want to discount that. It's like just now it's fun

695
00:38:56,600 --> 00:39:00,280
Speaker 4:  to peel it apart and understand it, but the reason Google is behind

696
00:39:00,610 --> 00:39:03,680
Speaker 4:  is because they cannot subject themselves to these risks. Right James?

697
00:39:03,990 --> 00:39:07,680
Speaker 6:  Yeah. They have been, you know, they've been chased by

698
00:39:07,680 --> 00:39:11,520
Speaker 6:  some past experience. They've said when they chat g p t first came out,

699
00:39:11,520 --> 00:39:14,840
Speaker 6:  they were like, we can't risk the reputational damage was the phrase that

700
00:39:14,840 --> 00:39:18,640
Speaker 6:  was reported. And I think they know that if they put a product like

701
00:39:18,640 --> 00:39:22,120
Speaker 6:  this out there, as they did with Bard, you know, they put their bot out there

702
00:39:22,120 --> 00:39:25,960
Speaker 6:  and someone rues spotted an error in the first ever demo that they

703
00:39:25,960 --> 00:39:29,560
Speaker 6:  had of it. And that became headlines and that was what tanked it. You know,

704
00:39:30,160 --> 00:39:33,840
Speaker 6:  Microsoft is obviously not, is pretty big as well, but it still

705
00:39:33,840 --> 00:39:37,720
Speaker 6:  has this sort of lack of expectations that allows it to play around in

706
00:39:37,720 --> 00:39:40,800
Speaker 6:  this space and to give all these disclaimers, like, ooh, it might, it might

707
00:39:40,800 --> 00:39:43,760
Speaker 6:  give you the wrong answer every now and again, isn't it fun and whimsical?

708
00:39:43,760 --> 00:39:46,720
Speaker 6:  Yeah. And people aren't gonna think, oh well this is gonna threaten lives,

709
00:39:47,260 --> 00:39:51,200
Speaker 6:  but this technology has the potential to threaten lives. Like, it, it, you

710
00:39:51,200 --> 00:39:54,840
Speaker 6:  know, I, and I don't mean that killer ai, I just mean putting bad information

711
00:39:54,840 --> 00:39:58,360
Speaker 6:  out there that if, if this stuff gets mainstream without profit

712
00:39:58,360 --> 00:40:02,200
Speaker 6:  safeguards, which hopefully are gonna happen as this stuff gets tested. But

713
00:40:02,200 --> 00:40:05,440
Speaker 6:  it, it, you know, there, there's possible dangerous consequences to this.

714
00:40:05,440 --> 00:40:07,040
Speaker 6:  It's not just a toy, unfortunately.

715
00:40:07,270 --> 00:40:11,120
Speaker 4:  I think that's real for Google. Like search is Google's entire business,

716
00:40:12,010 --> 00:40:16,000
Speaker 4:  Android, Chrome, all this stuff is designed to feed you back

717
00:40:16,000 --> 00:40:19,520
Speaker 4:  into Google's revenue engine, which is search and search advertising and

718
00:40:19,820 --> 00:40:23,640
Speaker 4:  you know, all the advertising infrastructure of the entire web is Google.

719
00:40:23,690 --> 00:40:27,560
Speaker 4:  There's a DOJ lawsuit about Google's monopoly across

720
00:40:27,560 --> 00:40:31,480
Speaker 4:  the advertising ecosystem. This is a very existential moment for Google,

721
00:40:31,480 --> 00:40:35,360
Speaker 4:  right? If people start chatting with Bing or demanding the chat with Google

722
00:40:35,940 --> 00:40:39,480
Speaker 4:  and it can't send people out to webpages where it serves all the ads.

723
00:40:40,030 --> 00:40:43,840
Speaker 4:  Like it's fundamental revenue models at risk and the reasons it

724
00:40:43,840 --> 00:40:47,480
Speaker 4:  supports things like Android at Chrome are at risk, but then on top of it,

725
00:40:48,130 --> 00:40:51,960
Speaker 4:  if the answers are worse or it is telling people lies

726
00:40:52,310 --> 00:40:55,920
Speaker 4:  like confident lies to put them at risk in some way, then that's

727
00:40:56,190 --> 00:40:59,960
Speaker 4:  even worse. So I just like, I don't know how Google comes through

728
00:40:59,960 --> 00:41:03,400
Speaker 4:  this moment. They have to make a series of very tough decisions.

729
00:41:03,730 --> 00:41:07,720
Speaker 4:  Whereas I think Microsoft and you can go watch or listen to that Adela interview.

730
00:41:07,950 --> 00:41:11,560
Speaker 4:  He's like, I just gotta pick up a few points of market share. He said this

731
00:41:11,560 --> 00:41:15,080
Speaker 4:  is the greatest gross margin opportunity in our history. And if Steve Ballmer

732
00:41:15,080 --> 00:41:18,800
Speaker 4:  was here, he would light up. Which is incredible thing to say, right? He's

733
00:41:18,800 --> 00:41:22,240
Speaker 4:  like, I just need a little bit, if I just win a little bit, it's billions

734
00:41:22,240 --> 00:41:25,640
Speaker 4:  of dollars of gross margin. Google has to protect the whole thing. And he

735
00:41:25,760 --> 00:41:29,740
Speaker 4:  actually said that out loud to me and to Joanna. And like I think

736
00:41:29,740 --> 00:41:32,700
Speaker 4:  that's a, that's a, Microsoft is a ruthlessly competitive company

737
00:41:33,340 --> 00:41:36,280
Speaker 4:  and for that company to see that kind of opportunity and say it out loud

738
00:41:36,280 --> 00:41:39,120
Speaker 4:  means they're so confident that Google's on its back foot.

739
00:41:39,420 --> 00:41:43,280
Speaker 3:  But I think there's like to connect that he's willing

740
00:41:43,290 --> 00:41:46,560
Speaker 3:  to risk a major like misinformation

741
00:41:46,870 --> 00:41:50,280
Speaker 3:  tool getting out into the world, being used really badly

742
00:41:50,580 --> 00:41:54,400
Speaker 3:  for a few points of market share. Like that's

743
00:41:54,400 --> 00:41:56,320
Speaker 3:  the calculus Microsoft made who

744
00:41:56,790 --> 00:41:59,840
Speaker 4:  I think he's already at know better. He's already at Bing is kind of bad.

745
00:41:59,840 --> 00:42:00,320
Speaker 4:  Like,

746
00:42:02,750 --> 00:42:05,000
Speaker 4:  I don't know if there's like a Delta, I think one of the reasons they kept

747
00:42:05,000 --> 00:42:07,680
Speaker 4:  the name Bing is like, if this all goes to hell, like what have they done?

748
00:42:07,680 --> 00:42:08,720
Speaker 4:  They just ruining over, they

749
00:42:08,720 --> 00:42:09,000
Speaker 3:  Just kill Bing.

750
00:42:09,000 --> 00:42:12,920
Speaker 4:  Yeah. You know, like, yeah. But I think what they see is that people are

751
00:42:12,920 --> 00:42:16,400
Speaker 4:  gonna use this tool in all kinds of surprising ways they can weather this

752
00:42:16,400 --> 00:42:20,080
Speaker 4:  sort of disinformation controversy. Cuz they can always be like, but

753
00:42:20,240 --> 00:42:24,080
Speaker 4:  everyone's just using Google, you know, like it's fine. Just like

754
00:42:24,080 --> 00:42:27,560
Speaker 4:  it's fine for now. Whereas Google the second they tell a lie like this,

755
00:42:28,400 --> 00:42:32,090
Speaker 4:  like, I mean they got it wrong with Bard and the exoplanet right? Yesterday

756
00:42:32,090 --> 00:42:35,210
Speaker 4:  and a hundred billion so off the market cap and that was in an ad that they

757
00:42:35,210 --> 00:42:35,890
Speaker 4:  should have fact checked.

758
00:42:36,160 --> 00:42:39,530
Speaker 6:  I kind of hope that this is the start of a new

759
00:42:39,870 --> 00:42:43,490
Speaker 6:  way of doing the web. You know, I I, one of the things I tweeted about when

760
00:42:43,490 --> 00:42:47,130
Speaker 6:  we were covering this news was the lack of traffic

761
00:42:47,130 --> 00:42:51,050
Speaker 6:  that these new AI bots might not push back to sites.

762
00:42:51,050 --> 00:42:54,010
Speaker 6:  And you know, if you, there's sites lose traffic, they lose revenue, they

763
00:42:54,010 --> 00:42:57,570
Speaker 6:  can no longer make stuff. And one of the responses I got was like, great,

764
00:42:57,880 --> 00:43:01,650
Speaker 6:  it's the end of the ad supported internet. And actually that had a lot of

765
00:43:01,990 --> 00:43:05,930
Speaker 6:  bad consequences as well as good ones. And maybe, maybe there's a new

766
00:43:05,930 --> 00:43:09,530
Speaker 6:  future where people go directly to sources and they support them

767
00:43:09,530 --> 00:43:13,210
Speaker 6:  financially in a way they didn't do with search. I don't know if that's possible,

768
00:43:13,390 --> 00:43:17,210
Speaker 6:  but I do think that these search engines are

769
00:43:17,210 --> 00:43:21,050
Speaker 6:  fundamentally gonna reshape the web. Yeah. And what happens next? I don't

770
00:43:21,050 --> 00:43:21,130
Speaker 6:  know

771
00:43:21,130 --> 00:43:24,970
Speaker 4:  Without, I mean if you remove Google from the web

772
00:43:24,970 --> 00:43:28,930
Speaker 4:  at large and the idea of Google traffic, there's only two ways to get traffic

773
00:43:28,930 --> 00:43:32,490
Speaker 4:  from most publishers. There's three, if you're us, we're very lucky

774
00:43:32,490 --> 00:43:36,370
Speaker 4:  people come to our homepage, right? And our entire redesign is like a

775
00:43:36,370 --> 00:43:39,730
Speaker 4:  bet on that persisting. And maybe I should put a app on your phone and maybe

776
00:43:39,730 --> 00:43:42,650
Speaker 4:  we should remake the entire site as Mask on. And since if you have ideas,

777
00:43:42,650 --> 00:43:43,210
Speaker 4:  please call me.

778
00:43:44,990 --> 00:43:48,850
Speaker 4:  I'm always into some renegade reboot to virtual ideas. But we're lucky there's

779
00:43:48,850 --> 00:43:52,570
Speaker 4:  like a, a handful of sites that have that direct audience. Everyone else

780
00:43:52,570 --> 00:43:56,130
Speaker 4:  is like scrounging for social traffic, which is how you get really clickbait

781
00:43:56,330 --> 00:43:58,930
Speaker 4:  headlines or there's scrounging for search traffic, which is how you get

782
00:43:59,130 --> 00:44:02,890
Speaker 4:  SEO bait and that's how you get screw it. We'll just have AI write the

783
00:44:03,010 --> 00:44:06,770
Speaker 4:  SEO bait. Cuz now we're just doing arbitrage against search terms and display

784
00:44:07,050 --> 00:44:10,170
Speaker 4:  advertising. And Google's kind of like on both sides of the equation. Hmm.

785
00:44:10,220 --> 00:44:14,210
Speaker 4:  If you take Google out of that, it's actually not clear how most sites will

786
00:44:14,210 --> 00:44:17,930
Speaker 4:  get traffic because most sites are not getting tons of social traffic

787
00:44:17,930 --> 00:44:21,690
Speaker 4:  anymore because of TikTok. And so like there's, there is a

788
00:44:21,690 --> 00:44:25,450
Speaker 4:  re-imagining of the web that is to come that is maybe years and years out.

789
00:44:25,450 --> 00:44:28,490
Speaker 4:  Like Google cannot dismantle the revenue architecture of the web tomorrow

790
00:44:28,680 --> 00:44:32,640
Speaker 4:  with Bard, right? They can't even demo Bard. So they've got a

791
00:44:32,640 --> 00:44:36,040
Speaker 4:  ways to go. But you can see how this is the beginning of a pretty massive

792
00:44:36,360 --> 00:44:40,080
Speaker 4:  paradigm shift for the web. I'll end here with this paragraph

793
00:44:40,470 --> 00:44:44,280
Speaker 4:  from our friends at Bing. It is unclear when or if the Virgil stopped

794
00:44:44,280 --> 00:44:48,080
Speaker 4:  picking on Elon Musk or vice versa, as both parties seem to have strong opinions

795
00:44:48,080 --> 00:44:51,920
Speaker 4:  and personalities that often clash. However, some observers

796
00:44:51,920 --> 00:44:55,680
Speaker 4:  have suggested that the feud is driven by mutual respect and

797
00:44:55,680 --> 00:44:59,080
Speaker 4:  admiration. Aw. As well as a desire to challenge and provoke each other.

798
00:44:59,470 --> 00:45:03,240
Speaker 4:  Some have also speculated the feud is a publicity stunt that benefits

799
00:45:03,240 --> 00:45:04,440
Speaker 4:  both the Virgin Elon.

800
00:45:04,800 --> 00:45:06,000
Speaker 3:  Where do you land? Was

801
00:45:06,000 --> 00:45:09,680
Speaker 4:  There an emotion? If you were that person who speculated at and trained chat

802
00:45:09,710 --> 00:45:13,520
Speaker 4:  g p T, this is all stunt, please call me because I,

803
00:45:13,670 --> 00:45:17,400
Speaker 4:  I, I we, we could use the help on coming up with the more publicity

804
00:45:17,400 --> 00:45:17,960
Speaker 4:  stunts.

805
00:45:20,780 --> 00:45:22,120
Speaker 3:  Who are we gonna fight with next?

806
00:45:22,120 --> 00:45:24,560
Speaker 4:  That's great. All right. We gotta take a break. James, thank you so much

807
00:45:24,560 --> 00:45:27,720
Speaker 4:  for joining us. Thank you. Wanna come back? There's a whole bunch of one

808
00:45:27,720 --> 00:45:29,000
Speaker 4:  plus phones. Talk about who gonna

809
00:45:33,690 --> 00:45:37,460
Speaker 3:  Life can sometimes be how you perceive it, where some see walls and

810
00:45:37,460 --> 00:45:41,100
Speaker 3:  barriers, others see windows of opportunity and potential breakthroughs.

811
00:45:41,160 --> 00:45:44,660
Speaker 3:  And if you're a digital business owner, you don't have to tell me how hazy

812
00:45:44,660 --> 00:45:47,620
Speaker 3:  your vision can get while running a company. But if you still have that drive

813
00:45:47,620 --> 00:45:51,220
Speaker 3:  to take your business to the next level, then uny may be able to

814
00:45:51,540 --> 00:45:55,300
Speaker 3:  help you on your quest. Unisys is a global technology solutions company

815
00:45:55,300 --> 00:45:58,980
Speaker 3:  dedicated to helping people and organizations reach their next breakthrough.

816
00:45:59,090 --> 00:46:02,780
Speaker 3:  They offer tools to help you run your business more efficiently, like systems

817
00:46:02,780 --> 00:46:06,460
Speaker 3:  integration, consulting services, application management, and device

818
00:46:06,460 --> 00:46:09,820
Speaker 3:  management. Software plus uny applies specialized

819
00:46:09,820 --> 00:46:13,620
Speaker 3:  expertise to strengthen and transform teams and processes by

820
00:46:13,620 --> 00:46:17,300
Speaker 3:  helping organizations act on new opportunities with solutions for digital

821
00:46:17,300 --> 00:46:20,940
Speaker 3:  workplaces, cloud applications, enterprise computing and business

822
00:46:20,940 --> 00:46:24,580
Speaker 3:  processes. To learn more, visit uny.com. That's

823
00:46:24,690 --> 00:46:28,140
Speaker 3:  U N I S Y s.com. Unisys

824
00:46:28,210 --> 00:46:29,260
Speaker 3:  keep breaking through.

825
00:46:32,900 --> 00:46:36,890
Speaker 3:  Support for today's show comes from Deloitte. What does the future look like?

826
00:46:37,000 --> 00:46:40,690
Speaker 3:  It's a question that drives progress, but more importantly, how do you

827
00:46:40,910 --> 00:46:44,810
Speaker 3:  get there? It's curiosity, resourcefulness, and bold ideas that

828
00:46:44,810 --> 00:46:48,650
Speaker 3:  can drive us even further than new technology. Because while technology can

829
00:46:48,650 --> 00:46:52,450
Speaker 3:  take you far, human exploration could take you even farther. Deloitte

830
00:46:52,450 --> 00:46:56,290
Speaker 3:  helps businesses build the future only they can imagine by melding deep

831
00:46:56,490 --> 00:47:00,210
Speaker 3:  business acumen and innovative technology with a vast team of tech savvy

832
00:47:00,210 --> 00:47:04,130
Speaker 3:  professionals. Unlock technology as powerful as your vision and push

833
00:47:04,130 --> 00:47:07,410
Speaker 3:  the boundaries of the possible so that you can stay a step ahead with the

834
00:47:07,410 --> 00:47:11,250
Speaker 3:  thinking to help you transform what's next into what's now helping you

835
00:47:11,250 --> 00:47:14,610
Speaker 3:  see the extraordinary potential in the seemingly ordinary while blending

836
00:47:14,610 --> 00:47:18,410
Speaker 3:  the possible with the practical is what Deloitte does. See how you

837
00:47:18,410 --> 00:47:20,330
Speaker 3:  can engineer advantage with Deloitte at

838
00:47:20,650 --> 00:47:24,530
Speaker 3:  deloitte.com/us/engineering advantage.

839
00:47:31,380 --> 00:47:34,960
Speaker 4:  All right, we're back. Bing is still with us, but James is not

840
00:47:35,320 --> 00:47:38,880
Speaker 4:  first casualty of the AI labor revolution.

841
00:47:39,070 --> 00:47:42,960
Speaker 4:  He's gone. We're just gonna start asking Bing if AI can be trusted and we'll

842
00:47:42,960 --> 00:47:45,880
Speaker 4:  see what it says. Speaking of things that aren't very intelligent, let's

843
00:47:45,880 --> 00:47:49,720
Speaker 4:  talk about Twitter hard week. That's a good segue. That's a good segue.

844
00:47:50,150 --> 00:47:53,840
Speaker 4:  A plus, speaking of the limits of natural

845
00:47:53,840 --> 00:47:57,440
Speaker 4:  intelligence, let's talk about Twitter. Hard week for Twitter.

846
00:47:57,810 --> 00:48:01,400
Speaker 4:  So Casey and Zoe just dropped a heater of a platform or edition

847
00:48:01,880 --> 00:48:05,640
Speaker 4:  about Elon's declining reach on a platform he's firing people. It's chaos.

848
00:48:05,640 --> 00:48:09,160
Speaker 4:  We'll read some quotes outta there. That's kind of pales in comparison

849
00:48:09,490 --> 00:48:13,440
Speaker 4:  to the fact that Twitter this week was just chaos. Richard,

850
00:48:13,440 --> 00:48:14,080
Speaker 4:  what's going on?

851
00:48:14,290 --> 00:48:17,880
Speaker 5:  On Wednesday? Twitter had some really bad issues and this is something that

852
00:48:17,880 --> 00:48:20,160
Speaker 5:  people have been warning about kind of since they had their mass layoffs.

853
00:48:20,170 --> 00:48:23,360
Speaker 5:  Do they know how to keep things running and do the people who know, who know

854
00:48:23,360 --> 00:48:26,320
Speaker 5:  how to fix different things still work at the company. And apparently the

855
00:48:26,320 --> 00:48:30,240
Speaker 5:  answer is not really because there was an issue on in

856
00:48:30,240 --> 00:48:33,440
Speaker 5:  the evening. Unfortunately, right before NBA free agencies, I'm waiting for

857
00:48:33,440 --> 00:48:36,920
Speaker 5:  my woes bombs to find out who got traded and who, who was going where.

858
00:48:36,990 --> 00:48:40,840
Speaker 5:  It's a bad time for this to happen, but the service, it didn't go all the

859
00:48:40,840 --> 00:48:43,560
Speaker 5:  way down. If you wanted to see tweets and if you wanted to see brand tweets,

860
00:48:43,560 --> 00:48:46,560
Speaker 5:  you were really happy because the only people who could tweet were companies.

861
00:48:46,920 --> 00:48:49,840
Speaker 5:  Everyone else was getting messages about your rate limit has been exceeded,

862
00:48:49,840 --> 00:48:53,040
Speaker 5:  you've tweeted too many times, and it linked you to a message talking about

863
00:48:53,040 --> 00:48:56,760
Speaker 5:  how many times you can tweet per day or different DM things in this.

864
00:48:57,060 --> 00:49:00,200
Speaker 5:  And that's a page that's been up on Twitter for years, but no one has ever

865
00:49:00,200 --> 00:49:03,040
Speaker 5:  looked at it because it didn't matter. But now everyone believes they'll

866
00:49:03,040 --> 00:49:06,120
Speaker 5:  have to pay for Twitter Blue to send more than five tweets a day or something

867
00:49:06,120 --> 00:49:09,360
Speaker 5:  like that. It turns out it was really just a glitch. They did eventually

868
00:49:09,360 --> 00:49:12,640
Speaker 5:  fix it. Things kind of have been back to normal, although my notifications

869
00:49:12,640 --> 00:49:16,520
Speaker 5:  have still been a little bit shaky. And as, as you mentioned, the piece from

870
00:49:16,520 --> 00:49:20,000
Speaker 5:  Casey and from Zoe on Platformer gets into a bunch of things about Twitter

871
00:49:20,000 --> 00:49:23,280
Speaker 5:  right now, but it also gets into why this happened. Apparently something

872
00:49:23,280 --> 00:49:27,240
Speaker 5:  was deleted that kind of sets those rate limits, so everyone was suddenly

873
00:49:27,240 --> 00:49:28,680
Speaker 5:  exceeding them because it was zero

874
00:49:28,820 --> 00:49:31,840
Speaker 4:  And the person who not fixed it had been fired.

875
00:49:31,840 --> 00:49:35,200
Speaker 5:  Yeah. The team that takes care of that no longer works at Twitter. So I guess

876
00:49:35,200 --> 00:49:36,600
Speaker 5:  someone else just had to figure it out.

877
00:49:36,750 --> 00:49:40,280
Speaker 4:  That's very good. Can I just say something about NBA for agency? Because

878
00:49:40,340 --> 00:49:43,960
Speaker 4:  one of the big stories, Ky Kyrie Irving going to the Mavs, right?

879
00:49:44,070 --> 00:49:46,880
Speaker 4:  Yeah. The Texas came out for Alex.

880
00:49:48,560 --> 00:49:51,960
Speaker 4:  Kyrie Irving believes in the flat earth because of seo.

881
00:49:52,430 --> 00:49:55,200
Speaker 4:  I just like, we were just talking about Google and the architecture of the

882
00:49:55,200 --> 00:49:58,800
Speaker 4:  web, like I'm just, this is like the

883
00:49:58,800 --> 00:50:02,640
Speaker 4:  reality of the world that we live in is that I can tell you

884
00:50:02,640 --> 00:50:06,400
Speaker 4:  with a hundred percent confidence that Kyrie Irving had to apologize

885
00:50:06,530 --> 00:50:10,400
Speaker 4:  to our nation science teachers about believing in the flat earth

886
00:50:10,400 --> 00:50:13,560
Speaker 4:  conspiracy theory because of seo. Yeah. You,

887
00:50:13,560 --> 00:50:14,160
Speaker 5:  And like he's

888
00:50:14,190 --> 00:50:18,120
Speaker 4:  Plains because people, Google is the earth flat, and then there's

889
00:50:18,120 --> 00:50:21,840
Speaker 4:  demand for that search term, and then people make YouTube

890
00:50:21,840 --> 00:50:25,680
Speaker 4:  videos about it, and content farm makes webpages about it. And then like

891
00:50:25,680 --> 00:50:29,200
Speaker 4:  the New York Times has to write a debunker about it because there's an increasing

892
00:50:29,200 --> 00:50:32,880
Speaker 4:  amount of search trims for it. And then Kyrie gets traded to the Mavs because

893
00:50:32,880 --> 00:50:36,160
Speaker 4:  he's crazy. I'm just telling you, I can draw a link.

894
00:50:36,630 --> 00:50:40,480
Speaker 4:  I don't have to like, it's not a conspiracy theory. That's just how the world

895
00:50:40,480 --> 00:50:43,360
Speaker 4:  works. Now. We've written it, I think we've actually written a story. I think

896
00:50:43,360 --> 00:50:47,200
Speaker 4:  Caitlin Tiffany wrote a story for us years ago about flat earth SEO

897
00:50:47,200 --> 00:50:51,040
Speaker 4:  and how, how that system works. I'm just saying like, I saw that notification

898
00:50:51,040 --> 00:50:54,000
Speaker 4:  and I was like, like literally the first thing I thought about was, remember

899
00:50:54,000 --> 00:50:57,360
Speaker 4:  we had to apologize to the science teachers of America? Well, because of

900
00:50:57,360 --> 00:50:57,640
Speaker 4:  the flat earth,

901
00:50:57,640 --> 00:51:00,560
Speaker 5:  If only that were the worst thing that he learned on the internet. But that's

902
00:51:00,560 --> 00:51:04,520
Speaker 5:  the kind of story, the, the thing that's funny to me

903
00:51:04,520 --> 00:51:08,360
Speaker 5:  about it is that the New Jersey Nets new old point guard,

904
00:51:08,360 --> 00:51:12,200
Speaker 5:  Spencer Denwitty, Mike's Brooklyn Conspiracy, Brooklyn Nets, is that, I'm

905
00:51:12,200 --> 00:51:12,840
Speaker 5:  sorry, you called

906
00:51:12,960 --> 00:51:13,880
Speaker 3:  'em the New Jersey Nets,

907
00:51:14,480 --> 00:51:17,600
Speaker 5:  Whatever. Look, what, what am I supposed to remember where the team is now?

908
00:51:17,600 --> 00:51:21,120
Speaker 5:  Since they moved there 15 years ago? They were there in the nineties. That's

909
00:51:21,120 --> 00:51:22,520
Speaker 5:  where they're now, that's what's going on.

910
00:51:24,600 --> 00:51:27,520
Speaker 5:  Brooklyn, New Jersey, the Nets, they basically the same. They were more important.

911
00:51:27,520 --> 00:51:31,040
Speaker 5:  I would remember where they were located. Wow. New old 40 guard

912
00:51:31,530 --> 00:51:35,400
Speaker 5:  Spencer Dwin. My personal conspiracy theory is that the reason why

913
00:51:35,400 --> 00:51:38,400
Speaker 5:  he had to be traded to the mAbs in the first place so that he could be traded

914
00:51:38,400 --> 00:51:42,240
Speaker 5:  for Kyrie Irving is because he was big into crypto, and I think he got his

915
00:51:42,240 --> 00:51:45,960
Speaker 5:  wizards teammates invested in crypto right before everything went down. And

916
00:51:45,960 --> 00:51:49,920
Speaker 5:  that's why he was at the deadline last year, set this whole

917
00:51:49,920 --> 00:51:51,120
Speaker 5:  thing in motion, kick

918
00:51:51,120 --> 00:51:53,720
Speaker 4:  Him out. All right, I'm just gonna wrap this up and point out that Tom Brady

919
00:51:53,720 --> 00:51:56,280
Speaker 4:  had to come back and play another year of football, thus dooming his marriage

920
00:51:56,280 --> 00:52:00,040
Speaker 4:  to Gisele because of ftx. That's my conspiracy theory.

921
00:52:00,300 --> 00:52:04,120
Speaker 4:  And also, just while we're at it, Aaron Rodgers recently

922
00:52:04,120 --> 00:52:07,800
Speaker 4:  hosted an astrology seminar. Again, great player,

923
00:52:07,810 --> 00:52:11,200
Speaker 4:  totally ruined by the S C O Radicalization funnel.

924
00:52:11,410 --> 00:52:14,960
Speaker 5:  It has been a year, six days since Reese Witherspoon tweeted about crypto.

925
00:52:14,960 --> 00:52:15,560
Speaker 5:  Just saying,

926
00:52:15,750 --> 00:52:19,680
Speaker 4:  I cannot wait until, what we're dealing with is celebrities asking

927
00:52:20,090 --> 00:52:23,840
Speaker 4:  AI chat bots, whether the earth is flat because it tries to answer,

928
00:52:23,840 --> 00:52:27,720
Speaker 4:  Bing will try to answer and be like, it's definitively not flat. And people,

929
00:52:28,780 --> 00:52:32,600
Speaker 4:  you just wait, just wait until like Donald Trump Jr. Is tweeting

930
00:52:32,600 --> 00:52:36,480
Speaker 4:  about how woke Bing is because he refuses to acknowledge that

931
00:52:36,480 --> 00:52:39,280
Speaker 4:  people think we didn't land on the moon. Which is another real thing. You're

932
00:52:39,280 --> 00:52:42,280
Speaker 4:  like, did we land on the moon? And it's like, yes, we definitely did

933
00:52:42,610 --> 00:52:46,200
Speaker 4:  culture war incoming, somehow we've gotten farfield of Twitter.

934
00:52:46,860 --> 00:52:50,520
Speaker 4:  But that's where the, that's where the, that's where like the buzzers Twitter

935
00:52:50,520 --> 00:52:54,440
Speaker 4:  happens. Twitter, the problem is you can't tweet anymore. So you don't even

936
00:52:54,440 --> 00:52:57,440
Speaker 4:  know whether Kyrie thinks the earth is flight. He's got nowhere to go. Well,

937
00:52:57,440 --> 00:52:58,880
Speaker 3:  He's going to Dallas. We established

938
00:52:58,880 --> 00:53:02,600
Speaker 4:  That anyhow. He's gonna Dallas, mark

939
00:53:02,600 --> 00:53:06,120
Speaker 4:  Cuban's gonna build him a custom Twitter. So Twitter goes down a bunch this

940
00:53:06,120 --> 00:53:09,440
Speaker 4:  week. Elon is threatening to turn off a access

941
00:53:10,160 --> 00:53:14,000
Speaker 4:  for a bunch of bots that are great. Like I love the Aqua

942
00:53:14,000 --> 00:53:17,920
Speaker 4:  no contact bot. It's like my favorite iconic of all time. That's

943
00:53:17,920 --> 00:53:20,800
Speaker 4:  free. And if the API goes away, they can't do it. I love a bot called Color

944
00:53:20,800 --> 00:53:24,280
Speaker 4:  Schemer, which just tweets cool color schemes that's going away.

945
00:53:24,830 --> 00:53:28,720
Speaker 4:  Publishers the verge.com. Our articles get auto tweeted

946
00:53:28,720 --> 00:53:31,480
Speaker 4:  using the api. It's integrated into our cms

947
00:53:32,370 --> 00:53:36,320
Speaker 4:  if they turn off the API and force us to pay for it. I told

948
00:53:36,320 --> 00:53:39,800
Speaker 4:  our social team, like, it's just a free for all. I'm just gonna give everyone

949
00:53:39,800 --> 00:53:43,320
Speaker 4:  the keys to the Twitter account and everyone can tweet as they like, like

950
00:53:43,790 --> 00:53:47,680
Speaker 4:  that's dumb to like be like, what I need is a human being to sit

951
00:53:47,680 --> 00:53:51,360
Speaker 4:  around waiting to manually tweet articles and it's even dumber to

952
00:53:51,360 --> 00:53:54,840
Speaker 4:  pay to distribute articles on Twitter. Right? Like Twitter sends us no traffic,

953
00:53:54,840 --> 00:53:58,680
Speaker 4:  really. So it's ridiculous to think that we should pay to distribute articles

954
00:53:58,680 --> 00:54:01,520
Speaker 4:  there. This is a real problem. So they've been, they've been walking that

955
00:54:01,520 --> 00:54:04,960
Speaker 4:  back as well, but we're not really sure how it's going to work.

956
00:54:05,060 --> 00:54:07,840
Speaker 5:  And that's one of those things, like they have, they, he's announced these

957
00:54:07,840 --> 00:54:11,240
Speaker 5:  API things, he's changed his plans. He, they tweeted from the Twitter dev

958
00:54:11,240 --> 00:54:14,600
Speaker 5:  accounts and new regulations, and I'm reading it. I have no idea what's going

959
00:54:14,600 --> 00:54:17,040
Speaker 5:  on. And then I talk to people who should know better than me who should know

960
00:54:17,040 --> 00:54:19,480
Speaker 5:  more about this. And they say that they have no idea what it means either.

961
00:54:19,480 --> 00:54:22,800
Speaker 5:  So no one has has any clue what's going on. If you were planning on building

962
00:54:22,800 --> 00:54:26,440
Speaker 5:  tools or building around Twitter, I can't see why you would do that considering

963
00:54:26,440 --> 00:54:29,120
Speaker 5:  the lack of information. Oh no. That we have now. You, you would move on

964
00:54:29,120 --> 00:54:30,120
Speaker 5:  and you would do something else.

965
00:54:30,460 --> 00:54:34,360
Speaker 4:  And all of the action is unasked on. I I Maybe you

966
00:54:34,360 --> 00:54:38,240
Speaker 4:  aren't as a listener, I'm not as, you know, like again, I'm, I'm

967
00:54:38,240 --> 00:54:42,160
Speaker 4:  taking a break from feed based social media feel my brain

968
00:54:42,160 --> 00:54:45,880
Speaker 4:  is healthier than it's been in a decade. But all the action is a mask done.

969
00:54:45,880 --> 00:54:49,280
Speaker 4:  Right? That's where the app developers are. The platform is accelerating.

970
00:54:50,280 --> 00:54:54,080
Speaker 4:  The underlying sort of fe averse boundaries are growing

971
00:54:54,260 --> 00:54:57,920
Speaker 4:  all. That's, that's where the activity is. And Elon

972
00:54:57,920 --> 00:55:01,000
Speaker 4:  shutting down the api, he's shutting down the follow graphs. So you can't

973
00:55:01,000 --> 00:55:04,280
Speaker 4:  easily move your followers to mask on because of those API changes. It's

974
00:55:04,280 --> 00:55:07,960
Speaker 4:  clear that he's feeling the heat. The problem is

975
00:55:08,310 --> 00:55:12,040
Speaker 4:  he's not directing his team at Twitter. What remains that team

976
00:55:12,150 --> 00:55:16,080
Speaker 4:  with any particular strategy. And of course what he's

977
00:55:16,080 --> 00:55:19,240
Speaker 4:  focused on is himself. So that's the story from Casey and Zoe and Platformer

978
00:55:19,240 --> 00:55:23,120
Speaker 4:  today. We obviously syndicate platformer, so it's on our site as well. But

979
00:55:23,250 --> 00:55:26,880
Speaker 4:  he called a meeting and said, I have more than a hundred million followers.

980
00:55:26,880 --> 00:55:30,720
Speaker 4:  I'm only getting tens of thousands of impressions. What's going on? The team

981
00:55:31,000 --> 00:55:34,600
Speaker 4:  apparently showed him internal data from Twitter along with Google

982
00:55:34,600 --> 00:55:38,440
Speaker 4:  Trends, saying that last April he was at a hundred

983
00:55:38,440 --> 00:55:42,240
Speaker 4:  out of a hundred and popularity. That's the peak. And

984
00:55:42,240 --> 00:55:45,880
Speaker 4:  today he's at nine and he didn't believe then, and he fired

985
00:55:45,880 --> 00:55:48,120
Speaker 4:  the engineer who told him this information.

986
00:55:48,500 --> 00:55:48,920
Speaker 11:  Wow.

987
00:55:50,780 --> 00:55:54,400
Speaker 4:  And it's like, yeah, dude, like you last a like last April was

988
00:55:54,400 --> 00:55:58,320
Speaker 4:  fully ridiculous. Like, if you will recall, right? Yeah. He was tweeting

989
00:55:58,320 --> 00:56:02,280
Speaker 4:  about conspiracy theories. He's like, comedy is back every day was a new

990
00:56:02,280 --> 00:56:06,080
Speaker 4:  Elon Musk Twitter. He was, you know, there was like a war brewing about who's

991
00:56:06,080 --> 00:56:09,960
Speaker 4:  gonna own this stuff now, just owns it. Like there's no conflict. Like

992
00:56:09,960 --> 00:56:13,080
Speaker 4:  Elon, let me tell you something. I know you listen. And also no users, great

993
00:56:13,080 --> 00:56:17,000
Speaker 4:  stories are driven by conflict. If you're like, okay, it's a story. It's

994
00:56:17,000 --> 00:56:20,800
Speaker 4:  about a guy who trades stocks in Wall Street. He gets in no trouble.

995
00:56:20,800 --> 00:56:23,800
Speaker 4:  He plays it by the book and he's happily married to Mario. Robby, like, no

996
00:56:23,800 --> 00:56:24,640
Speaker 4:  one would watch this movie.

997
00:56:27,020 --> 00:56:30,840
Speaker 4:  I'm just telling you the lamb of walls, like no one's watching this stuff.

998
00:56:30,840 --> 00:56:34,400
Speaker 4:  You need conflict. And he's out of conflict because all the conflict is now

999
00:56:34,400 --> 00:56:38,000
Speaker 4:  pointed. He is pointed at himself at Twitter. He is in charge.

1000
00:56:38,170 --> 00:56:41,920
Speaker 4:  So no one's looking at his tweets cuz all he has left, he can't

1001
00:56:41,920 --> 00:56:44,400
Speaker 4:  promise to make change anymore. He just has to deliver the change.

1002
00:56:44,450 --> 00:56:47,640
Speaker 3:  No one's looking at his tweets because of the, the lack of conflict or no

1003
00:56:47,640 --> 00:56:50,760
Speaker 3:  one's looking at his tweets because of the lack of people on Twitter to look

1004
00:56:50,760 --> 00:56:51,440
Speaker 3:  at his tweets.

1005
00:56:52,350 --> 00:56:55,920
Speaker 4:  I think that's like a circle. I I can't tell you where that begins or ends,

1006
00:56:55,920 --> 00:56:56,400
Speaker 4:  right?

1007
00:56:56,870 --> 00:56:58,080
Speaker 3:  It's kind of both, right?

1008
00:56:58,780 --> 00:57:02,480
Speaker 5:  But that's, that's how we all feel when you let off a fire tweet and you

1009
00:57:02,480 --> 00:57:06,350
Speaker 5:  don't get minimum 15 likes, you do want to

1010
00:57:06,350 --> 00:57:10,190
Speaker 5:  call a meeting and have everyone at Twitter ask, answer, answer. Why?

1011
00:57:10,930 --> 00:57:12,230
Speaker 5:  Why is the world not

1012
00:57:12,230 --> 00:57:14,830
Speaker 4:  Seeing this is what I mean, feed-based social media.

1013
00:57:14,850 --> 00:57:18,270
Speaker 5:  Why am I being shadowman? Why am I rights being violated?

1014
00:57:18,690 --> 00:57:21,990
Speaker 5:  And now Elon can do that. I think that, I think there's at least 44 billion

1015
00:57:21,990 --> 00:57:23,710
Speaker 5:  worth of value in doing that.

1016
00:57:24,190 --> 00:57:27,790
Speaker 4:  That's, that's half the per, that's 22 billion is just being able to call

1017
00:57:27,790 --> 00:57:31,550
Speaker 4:  a meeting. I will say this, I was watching the Grammys and I was like, I'm

1018
00:57:31,550 --> 00:57:35,230
Speaker 4:  just like sitting on these bangers there, there had nowhere to go. I just

1019
00:57:35,230 --> 00:57:38,270
Speaker 4:  started texting like random friends from the past, just,

1020
00:57:39,800 --> 00:57:43,270
Speaker 4:  do you think the Grammys sound like shit? I'm like, people like, who are

1021
00:57:43,470 --> 00:57:46,870
Speaker 4:  you? Where'd she come from? Because I had nowhere for them to go. That's

1022
00:57:46,870 --> 00:57:49,190
Speaker 4:  what Twitter was for me. And now it's like my brain is healing. That

1023
00:57:49,190 --> 00:57:51,230
Speaker 5:  Is Twitter though. Like if you said these things out loud

1024
00:57:51,230 --> 00:57:54,110
Speaker 4:  To you. Yeah, I I recognize there's not a lot of value in complaining about

1025
00:57:54,110 --> 00:57:57,030
Speaker 4:  the sound engineer of the Grammys. By the way, sound engineer of the Grammys

1026
00:57:57,030 --> 00:57:59,750
Speaker 4:  should be ashamed of himself. It sounded like shit. It sounded like they

1027
00:57:59,750 --> 00:58:03,510
Speaker 4:  had an iPhone sitting in the middle of Staple center. Horrible. You know,

1028
00:58:03,510 --> 00:58:06,070
Speaker 4:  we had a story like years ago about why the Grammys sound good and how hard

1029
00:58:06,070 --> 00:58:08,750
Speaker 4:  it is. And it's like they like whoever like Elon fired then too.

1030
00:58:08,750 --> 00:58:10,190
Speaker 3:  They fired that guy. Yeah.

1031
00:58:10,300 --> 00:58:14,030
Speaker 4:  It's like a new guy. He's like, El let's after everything, we want more room

1032
00:58:14,030 --> 00:58:17,670
Speaker 4:  tone from the staple center. It's like, she's like massive amounts.

1033
00:58:17,670 --> 00:58:20,870
Speaker 4:  Anyway, my poor wife, I was like, do you hear all that shimmer on the high

1034
00:58:20,870 --> 00:58:22,030
Speaker 4:  end? She's like, I don't know what you're talking.

1035
00:58:22,630 --> 00:58:24,150
Speaker 3:  She's like, no, that's Harry styles.

1036
00:58:24,310 --> 00:58:28,150
Speaker 4:  There's nowhere for this to go. So he's firing the people,

1037
00:58:28,460 --> 00:58:31,990
Speaker 4:  he's complaining about his impressions and then this to me is like the main

1038
00:58:31,990 --> 00:58:35,950
Speaker 4:  thing. So he wrote, he'd rolled out these view counts and

1039
00:58:36,130 --> 00:58:38,750
Speaker 4:  all the people worked at Twitter. Like, there's a reason we never did this.

1040
00:58:38,750 --> 00:58:42,710
Speaker 4:  What it's going to show most people is that most people don't look at

1041
00:58:42,710 --> 00:58:46,510
Speaker 4:  any tweets. Like most people get no impressions, right?

1042
00:58:46,510 --> 00:58:50,110
Speaker 4:  The illusion of Twitter is the sense that everyone's looking at all your

1043
00:58:50,110 --> 00:58:53,550
Speaker 4:  stuff all the time. You add view counts, you're just gonna train people that

1044
00:58:53,550 --> 00:58:56,510
Speaker 4:  the effort isn't worth it. Elon doesn't believe it. He has this quote, this

1045
00:58:56,510 --> 00:59:00,030
Speaker 4:  is gonna show how much more vibrant the platform is and people think how

1046
00:59:00,030 --> 00:59:03,830
Speaker 4:  live it is. He rolls up the view counts. Not only does it lead to a

1047
00:59:03,830 --> 00:59:07,510
Speaker 4:  further drop in engagement, cuz most people don't look at your tweets or

1048
00:59:07,510 --> 00:59:10,590
Speaker 4:  most tweets don't get looked at by anyone. It kills Elon

1049
00:59:12,480 --> 00:59:16,150
Speaker 4:  because most people aren't looking at his either. Like his,

1050
00:59:16,290 --> 00:59:19,030
Speaker 4:  his view of Twitter is completely

1051
00:59:19,860 --> 00:59:23,760
Speaker 4:  warped by his like, like reply bots. Yeah. So he got, he's getting

1052
00:59:23,760 --> 00:59:27,600
Speaker 4:  rid of the bots, he's adding in metrics and he's realizing

1053
00:59:28,270 --> 00:59:32,120
Speaker 4:  like his world is a lie. Soon someone's gonna tell him that the cars

1054
00:59:32,120 --> 00:59:34,760
Speaker 4:  don't drive themselves. It's I'm gonna fall apart.

1055
00:59:35,490 --> 00:59:39,120
Speaker 3:  Is this why he, they did the a p stuff where they're charging for it

1056
00:59:39,400 --> 00:59:43,360
Speaker 3:  and, and why we were having all the problems on Wednesday with Twitter. Like

1057
00:59:43,360 --> 00:59:46,240
Speaker 3:  is is is the attempt to kill the bots part of that?

1058
00:59:46,630 --> 00:59:49,880
Speaker 5:  I would, I would bet that it probably is related to that, that that's why

1059
00:59:49,880 --> 00:59:53,040
Speaker 5:  the stuff got deleted. That someone was making changes to this, that, or

1060
00:59:53,040 --> 00:59:56,800
Speaker 5:  the other thing. But not directly. Not not intentionally. Yeah,

1061
00:59:56,800 --> 00:59:57,200
Speaker 5:  exactly.

1062
00:59:57,280 --> 01:00:01,160
Speaker 3:  Right. But even the API stuff, so is the API stuff,

1063
01:00:01,160 --> 01:00:05,040
Speaker 3:  like, it's his idea. Really. If I charge people for this free

1064
01:00:05,040 --> 01:00:08,880
Speaker 3:  tool that helps engagement, I'll make more

1065
01:00:08,880 --> 01:00:09,440
Speaker 3:  money. Like I'll make

1066
01:00:09,440 --> 01:00:12,640
Speaker 4:  Money. I'm telling you, this is like if when I was in my twenties, if I was

1067
01:00:12,640 --> 01:00:16,480
Speaker 4:  like, I'm gonna buy the cigarette factory for 44 billion. Yeah, he's addicted

1068
01:00:16,480 --> 01:00:20,040
Speaker 4:  to Twitter. He thinks everyone else is addicted to Twitter and he

1069
01:00:20,280 --> 01:00:22,920
Speaker 4:  doesn't realize that you cannot be addicted to Twitter.

1070
01:00:23,120 --> 01:00:23,680
Speaker 3:  Right?

1071
01:00:23,820 --> 01:00:25,720
Speaker 5:  But, but doesn't everyone do that? All that stuff.

1072
01:00:25,720 --> 01:00:29,520
Speaker 4:  He's just got, I'm gonna charge for Twitter blue. I'm gonna like your replies.

1073
01:00:29,520 --> 01:00:33,000
Speaker 4:  Don't get ranked unless you pay for blue. I'm gonna charge your API at all.

1074
01:00:33,000 --> 01:00:36,840
Speaker 4:  All of it. Implicit underneath it all is the idea that you

1075
01:00:36,840 --> 01:00:37,720
Speaker 4:  have nowhere else to go.

1076
01:00:38,390 --> 01:00:41,520
Speaker 5:  E everyone has this idea, but we're, we're going to buy this bar. We're going

1077
01:00:41,520 --> 01:00:44,280
Speaker 5:  to buy this club. We'll make it see, we'll fix everything that's wrong with

1078
01:00:44,280 --> 01:00:46,920
Speaker 5:  it and we'll make it popular because we'll do the things that we want and

1079
01:00:46,920 --> 01:00:47,520
Speaker 5:  we know. Yeah,

1080
01:00:47,520 --> 01:00:48,120
Speaker 3:  That works. Every time.

1081
01:00:48,120 --> 01:00:49,040
Speaker 5:  You cannot actually

1082
01:00:49,040 --> 01:00:50,480
Speaker 4:  Do that. We're gonna buy this. You do

1083
01:00:50,480 --> 01:00:54,160
Speaker 5:  Richard. It ends in ruin. Every time we've all seen it, we've all considered

1084
01:00:54,160 --> 01:00:56,240
Speaker 5:  doing it. Maybe are considering doing it again.

1085
01:00:56,240 --> 01:00:58,320
Speaker 4:  I mean, Richard, if you want to go in on a club, I'm

1086
01:00:58,320 --> 01:01:01,200
Speaker 5:  Just saying we should have done it, man. We should have done it. We, we could

1087
01:01:01,360 --> 01:01:01,520
Speaker 5:  still

1088
01:01:01,520 --> 01:01:05,480
Speaker 3:  Do just sell scissor vodka. The only, only

1089
01:01:05,480 --> 01:01:06,640
Speaker 3:  vodka sold there.

1090
01:01:07,780 --> 01:01:09,080
Speaker 4:  Can I read the scissor vodka?

1091
01:01:09,290 --> 01:01:13,160
Speaker 5:  We can run it with ai. You can have AI bots as bartenders. It's

1092
01:01:13,160 --> 01:01:14,160
Speaker 5:  perfect. We could, we could do it,

1093
01:01:14,250 --> 01:01:17,240
Speaker 4:  It could work. I mean it's easily the best thing that chat G B T has produced.

1094
01:01:17,380 --> 01:01:21,300
Speaker 4:  I'm just gonna read this to you. It was a dark and stormy night. Casey Newton,

1095
01:01:21,300 --> 01:01:24,300
Speaker 4:  the senior editor of the Verge, was sitting at his, this is Bing, Bing wrote

1096
01:01:24,300 --> 01:01:27,580
Speaker 4:  this story. Yeah, he had a deadline to me, but he had no idea what to write.

1097
01:01:27,580 --> 01:01:30,300
Speaker 4:  He'd already covered all the latest techies and trends, but he felt like

1098
01:01:30,300 --> 01:01:32,740
Speaker 4:  he needed to do something more, something different, something exciting.

1099
01:01:33,140 --> 01:01:36,380
Speaker 4:  Casey decided to take a break and have a drink. He grabbed the bottle and

1100
01:01:36,380 --> 01:01:39,740
Speaker 4:  poured himself a glass of scissor vodka. He took a sip and felt a warm sensation

1101
01:01:39,740 --> 01:01:43,580
Speaker 4:  in his throat. He took another sip and felt a tingling sensation in his brain.

1102
01:01:44,270 --> 01:01:47,460
Speaker 4:  He took another sip and felt a surge of energy and creativity. He felt like

1103
01:01:47,460 --> 01:01:50,420
Speaker 4:  he could write anything. He felt like he could do anything. He wrote about

1104
01:01:50,420 --> 01:01:52,780
Speaker 4:  Caesar vodka, how it was the best vodka in the world, how could make anyone

1105
01:01:52,780 --> 01:01:55,620
Speaker 4:  smarter, faster, stronger, and happier. He wrote and wrote and wrote until

1106
01:01:55,620 --> 01:01:58,740
Speaker 4:  he filled several pages with his words, he felt proud and satisfied. I'm

1107
01:01:58,740 --> 01:02:00,900
Speaker 4:  telling you this keeps going. He had written the best story of his career,

1108
01:02:00,960 --> 01:02:04,020
Speaker 4:  the best story of his life. He had the sun button and waited for the praise

1109
01:02:04,020 --> 01:02:05,860
Speaker 4:  and admiration of his readers and editors.

1110
01:02:05,920 --> 01:02:07,460
Speaker 3:  Was there meth in this podcast?

1111
01:02:07,610 --> 01:02:11,540
Speaker 4:  Like he waited and waited and waited, but nothing happened. He checked his

1112
01:02:11,540 --> 01:02:15,060
Speaker 4:  email and saw no response. He checked his phone and saw no notifications.

1113
01:02:15,150 --> 01:02:17,940
Speaker 4:  He texted his Twitter and saw no mentions. He checked his slacks and saw

1114
01:02:17,940 --> 01:02:21,440
Speaker 4:  no messages. He wondered if anyone had read his story. He wondered if anyone

1115
01:02:21,440 --> 01:02:25,200
Speaker 4:  had cared. He realized how silly and nonsensical it was.

1116
01:02:25,200 --> 01:02:29,080
Speaker 4:  He realized how drunk and delusional he was. He felt ashamed

1117
01:02:29,080 --> 01:02:32,160
Speaker 4:  and embarrassed. He felt stupid and foolish. He felt like he had made a huge

1118
01:02:32,160 --> 01:02:35,880
Speaker 4:  mistake. He tried to delete his story, but it was too late. He tried to apologize

1119
01:02:35,880 --> 01:02:39,760
Speaker 4:  but it was too late. He tried to explain, but it was too late. He had already

1120
01:02:39,760 --> 01:02:43,200
Speaker 4:  sent his story to the entire world. He had ruined his reputation and he lost

1121
01:02:43,200 --> 01:02:45,360
Speaker 4:  his credibility. He had cut through the night.

1122
01:02:48,310 --> 01:02:52,200
Speaker 4:  I mean this is like the dark, like they should shut it down. I

1123
01:02:52,200 --> 01:02:53,160
Speaker 4:  don't know how you beat that.

1124
01:02:53,270 --> 01:02:56,800
Speaker 3:  Like you can't, that's that's, that's it. That's the top. They've

1125
01:02:56,800 --> 01:02:57,240
Speaker 4:  Already peaked.

1126
01:02:57,240 --> 01:02:58,640
Speaker 3:  This is nothing better. We

1127
01:02:58,640 --> 01:03:01,280
Speaker 4:  Should, I sent, I sent it to Casey last night. He's like, this actually kind

1128
01:03:01,280 --> 01:03:03,800
Speaker 4:  of captures the sensation of publishing it. Story

1129
01:03:04,200 --> 01:03:05,360
Speaker 3:  Drunkenly publishing.

1130
01:03:05,360 --> 01:03:06,680
Speaker 4:  That's the worst case scenario.

1131
01:03:08,270 --> 01:03:11,520
Speaker 4:  He's like, this is like, this is what it's like to publish a story that no,

1132
01:03:13,370 --> 01:03:14,680
Speaker 3:  It is. You cut through the night

1133
01:03:15,690 --> 01:03:19,520
Speaker 4:  Already. Cut through the night. And that's I think also a useful

1134
01:03:19,520 --> 01:03:22,360
Speaker 4:  summation of Elon on Twitter. Okay, so that's Elon on Twitter. Pure chaos.

1135
01:03:22,780 --> 01:03:26,360
Speaker 4:  I'm gonna quote again from Casey and Zoe's story cuz this is a great quote.

1136
01:03:26,920 --> 01:03:30,840
Speaker 4:  If you're a decoder listener, which I'm not allowed to mention on this

1137
01:03:30,840 --> 01:03:34,640
Speaker 4:  show, but if you're a decoder listener, you will recognize why I love this

1138
01:03:34,640 --> 01:03:38,600
Speaker 4:  particular quote as the adage goes, you ship your org chart, said

1139
01:03:38,600 --> 01:03:42,160
Speaker 4:  one current employee. It's chaos here right now. So we're shipping chaos.

1140
01:03:42,910 --> 01:03:46,680
Speaker 4:  Very good, very good. But org charts bring

1141
01:03:46,680 --> 01:03:50,600
Speaker 4:  me away from Twitter to Disney. Yeah. Where former

1142
01:03:50,860 --> 01:03:54,800
Speaker 4:  and now current ceo Bob ier wrote in, kicked out his

1143
01:03:54,800 --> 01:03:58,720
Speaker 4:  handpicked successor, Bob Chak, Bob and Bob Crime. He's laying

1144
01:03:58,720 --> 01:04:02,240
Speaker 4:  off 7,000 people. Alex, I'm very curious if you have thoughts on that, but

1145
01:04:02,240 --> 01:04:06,120
Speaker 4:  in addition to laying off 7,000 people, what's my man doing? He is

1146
01:04:06,300 --> 01:04:09,480
Speaker 4:  restructuring his org chart. He's putting all streaming in one

1147
01:04:09,760 --> 01:04:13,640
Speaker 4:  divisions. P n now its own division. He's just like rebooting

1148
01:04:13,640 --> 01:04:13,840
Speaker 4:  Disney

1149
01:04:13,890 --> 01:04:17,640
Speaker 3:  Because Sheik rebooted it first. He was like, I'm gonna make it more like

1150
01:04:17,640 --> 01:04:21,520
Speaker 3:  tech. And everybody's like, no, we hate this. And so IRA's gotten rid of

1151
01:04:21,520 --> 01:04:24,920
Speaker 3:  all those people. A lot of the people that he put in charge and is now like,

1152
01:04:25,310 --> 01:04:26,320
Speaker 3:  I guess fixing it.

1153
01:04:26,320 --> 01:04:30,200
Speaker 4:  Attempting. Yeah. I mean he, I you get the feeling that JPAC

1154
01:04:30,290 --> 01:04:34,280
Speaker 4:  is, was a useful villain, right? He changed a bunch

1155
01:04:34,280 --> 01:04:37,880
Speaker 4:  of stuff and now IER gets to roll back and say, I'm fixing it. And part of

1156
01:04:37,880 --> 01:04:40,720
Speaker 4:  the fixing it is firing 7,000 people.

1157
01:04:41,950 --> 01:04:42,720
Speaker 3:  That's a lot

1158
01:04:42,720 --> 01:04:46,560
Speaker 4:  Of people re lowering some targets that Eck had set for streaming. We should

1159
01:04:46,560 --> 01:04:50,160
Speaker 4:  talk about that. And then this big restructure out of his old

1160
01:04:50,160 --> 01:04:53,880
Speaker 4:  restructure. So Iger had a structure. It wasn't this structure.

1161
01:04:54,480 --> 01:04:58,280
Speaker 4:  Eck changed it so that all the divisions rolled up into one

1162
01:04:58,280 --> 01:05:02,200
Speaker 4:  guy, Kareem Daniel, right? Everyone hated this like Marvel Lucas film.

1163
01:05:02,200 --> 01:05:05,480
Speaker 4:  Everybody rolled up into this guy, everyone hated it. And now IER gets to

1164
01:05:05,480 --> 01:05:08,480
Speaker 4:  say, oh, I'm undoing this thing you hate, but it's yet a third different

1165
01:05:08,640 --> 01:05:12,240
Speaker 4:  structure. So he, he gets to get out of his old way of doing things

1166
01:05:12,650 --> 01:05:16,280
Speaker 4:  without the pain of being the guy who broke it. Yeah. Very clever.

1167
01:05:16,500 --> 01:05:16,920
Speaker 4:  I'm

1168
01:05:17,090 --> 01:05:20,760
Speaker 5:  If you, if it were the start of the pan, if let's just say in theory, if

1169
01:05:20,760 --> 01:05:23,640
Speaker 5:  it were the start of a global pandemic and you wanted to take a couple of

1170
01:05:23,640 --> 01:05:27,600
Speaker 5:  years off of work and not be responsible for managing the Global Pandemic,

1171
01:05:28,160 --> 01:05:31,280
Speaker 5:  would you do anything differently than what Bob I could.

1172
01:05:32,430 --> 01:05:32,840
Speaker 3:  I just,

1173
01:05:34,530 --> 01:05:37,880
Speaker 3:  he just had a little sabbatical, a little couple years sabbatical.

1174
01:05:38,110 --> 01:05:41,680
Speaker 4:  Yeah. And I think all of you will recognize that when I begin to look for

1175
01:05:41,680 --> 01:05:44,920
Speaker 4:  my handpicked successor at the Verge to watch your backs.

1176
01:05:45,280 --> 01:05:48,440
Speaker 4:  That's what I'm saying. I've learned something from all this.

1177
01:05:48,440 --> 01:05:50,560
Speaker 3:  You're gonna come back and then lay off 7,000 people

1178
01:05:52,420 --> 01:05:56,240
Speaker 3:  and get us, give us that Zootopia sequel we've all been been

1179
01:05:56,240 --> 01:05:56,720
Speaker 3:  eager

1180
01:05:56,720 --> 01:06:00,640
Speaker 4:  For. So we should talk about that. He ager said he interviewed on CNBC

1181
01:06:00,640 --> 01:06:03,840
Speaker 4:  today. He's following up in earnings. But Alex, take us through the actual

1182
01:06:03,840 --> 01:06:06,800
Speaker 4:  earnings. Does Disney plus added some subscribers in United States and Canada?

1183
01:06:07,370 --> 01:06:10,520
Speaker 4:  It dropped a lot of subscribers internationally, especially in India because

1184
01:06:10,520 --> 01:06:12,000
Speaker 4:  he lost some cricket rights. What's going on here?

1185
01:06:12,110 --> 01:06:16,000
Speaker 3:  Yeah, I mean it's, it's doing like I think across the board they're seeing

1186
01:06:16,000 --> 01:06:19,960
Speaker 3:  that slowdown that we were seeing across all the streaming, right? Like the

1187
01:06:19,960 --> 01:06:23,480
Speaker 3:  dust is settled, people kind of know where they're gonna go.

1188
01:06:23,980 --> 01:06:27,880
Speaker 3:  And so they only added 200,000

1189
01:06:28,240 --> 01:06:32,040
Speaker 3:  subscribers in the United States. They on, they added actually

1190
01:06:32,040 --> 01:06:35,960
Speaker 3:  what looks nicer. Hulu added 800,000 ESPN plus added

1191
01:06:35,960 --> 01:06:37,000
Speaker 3:  600,000.

1192
01:06:37,430 --> 01:06:40,440
Speaker 5:  Well, that, that may be because they have the bundle packages now it's like

1193
01:06:40,440 --> 01:06:43,120
Speaker 5:  they've pushed so many people to pick up the bundles. So maybe you had Disney

1194
01:06:43,120 --> 01:06:46,440
Speaker 5:  plus before, but now you have all three because it's essentially cheaper

1195
01:06:46,440 --> 01:06:47,800
Speaker 4:  Now. Right? Those that three year,

1196
01:06:48,040 --> 01:06:48,600
Speaker 3:  Right,

1197
01:06:48,600 --> 01:06:51,880
Speaker 4:  Right. Everyone's like demo period kind of expired and you're just signing

1198
01:06:51,880 --> 01:06:52,200
Speaker 4:  up for the

1199
01:06:52,200 --> 01:06:55,280
Speaker 5:  Bundle. Yeah. So you either canceled, which is probably why their growth

1200
01:06:55,280 --> 01:06:59,080
Speaker 5:  was so close to flat or you got the bundle and now you have all

1201
01:06:59,080 --> 01:06:59,320
Speaker 5:  three.

1202
01:06:59,500 --> 01:07:03,440
Speaker 3:  But they are also seeing, they saw, like, they saw, I mean despite like kind

1203
01:07:03,440 --> 01:07:07,280
Speaker 3:  of that bot that that flat lining and, and in some cases little

1204
01:07:07,280 --> 01:07:11,160
Speaker 3:  dips, they, they still increase revenue by 13%. Like they're still

1205
01:07:11,160 --> 01:07:14,640
Speaker 3:  making any handover fists in that direct to consumer

1206
01:07:15,640 --> 01:07:18,160
Speaker 3:  division, which is a lot of that is streaming.

1207
01:07:18,160 --> 01:07:19,480
Speaker 4:  Right. But they lost a billion

1208
01:07:19,480 --> 01:07:22,400
Speaker 3:  Dollars. Yeah, they lost a billion dollars. And they promise, they promise

1209
01:07:22,950 --> 01:07:26,400
Speaker 3:  that, I believe it's by 2024 is when they promise

1210
01:07:26,400 --> 01:07:28,120
Speaker 3:  profitability for that, that section

1211
01:07:28,300 --> 01:07:29,480
Speaker 4:  End of 2024.

1212
01:07:29,480 --> 01:07:32,920
Speaker 3:  By the end of 20, fiscal 2024, they say, don't worry,

1213
01:07:33,110 --> 01:07:36,120
Speaker 3:  Disney Plus is gonna be profitable, which means we're probably gonna see

1214
01:07:36,120 --> 01:07:40,080
Speaker 3:  a big slew of cancellations. They, they've have so

1215
01:07:40,080 --> 01:07:43,640
Speaker 3:  many TV shows and I don't think they've canceled really any of them.

1216
01:07:43,810 --> 01:07:47,720
Speaker 3:  Or at least not loudly and publicly. So I think a lot of these shows,

1217
01:07:47,790 --> 01:07:51,680
Speaker 3:  like if you really liked She Hulk, you probably should make

1218
01:07:51,680 --> 01:07:55,440
Speaker 3:  sure other people watch it. If you really liked Willow or what's another,

1219
01:07:55,440 --> 01:07:55,720
Speaker 3:  oh

1220
01:07:55,720 --> 01:07:58,760
Speaker 4:  My God, you gotta do like the K-pop stand thing. You gotta just like stream

1221
01:07:58,920 --> 01:07:59,840
Speaker 4:  the show over and over again.

1222
01:07:59,840 --> 01:08:03,080
Speaker 3:  Yeah. Just that doesn't work around the world. We saw that with Netflix.

1223
01:08:03,080 --> 01:08:06,280
Speaker 3:  People were doing do that on Netflix and it doesn't work because

1224
01:08:06,710 --> 01:08:10,640
Speaker 3:  with with streaming, you can just go and be like, oh, this one

1225
01:08:10,640 --> 01:08:14,560
Speaker 3:  user is the outlier who streamed it 12 times. Everybody else

1226
01:08:14,560 --> 01:08:17,400
Speaker 3:  has streamed at zero. Like it's not like Neil,

1227
01:08:17,400 --> 01:08:19,520
Speaker 4:  Somehow Spotify hasn't figured this out, but

1228
01:08:19,760 --> 01:08:23,080
Speaker 3:  Socos Yeah, Spotify hasn't figured it out, but everybody, but like streaming

1229
01:08:23,080 --> 01:08:26,920
Speaker 3:  has definitely figured this out. So I would not be surprised if this year

1230
01:08:26,920 --> 01:08:30,640
Speaker 3:  we see just an absolute bloodbath in that, like in that

1231
01:08:30,640 --> 01:08:34,480
Speaker 3:  streaming slate in in a lot of stuff that people are really excited about.

1232
01:08:34,480 --> 01:08:38,440
Speaker 3:  Not getting renewed, not seeing a second season, but they have

1233
01:08:38,440 --> 01:08:41,920
Speaker 3:  like their Marvel and their Star Wars slates are both planned pretty far

1234
01:08:41,920 --> 01:08:44,680
Speaker 3:  in advance. Yeah. Like we know what's coming for the next couple of years

1235
01:08:44,690 --> 01:08:47,920
Speaker 3:  on those two properties. So it's gonna be

1236
01:08:49,040 --> 01:08:49,400
Speaker 3:  interesting.

1237
01:08:49,670 --> 01:08:53,280
Speaker 5:  What's funny is the things that we're hearing from Disney, from Paramount,

1238
01:08:53,280 --> 01:08:57,240
Speaker 5:  from H B O, they're all very similar. Like Zaslav is

1239
01:08:57,240 --> 01:09:00,080
Speaker 5:  kind of saying these same things. I think Paramount and Showtime actually

1240
01:09:00,080 --> 01:09:03,880
Speaker 5:  had this message, the clearest is we're going to focus on the big mainstream

1241
01:09:03,880 --> 01:09:06,560
Speaker 5:  hits and the other stuff, right? Yeah. Not so much.

1242
01:09:06,750 --> 01:09:10,600
Speaker 4:  Yeah. Showtime's like, all right, it's the Billions universe. And

1243
01:09:10,600 --> 01:09:14,280
Speaker 4:  that means we need a show called Millions and a show called Trillions. This

1244
01:09:14,520 --> 01:09:18,240
Speaker 4:  is real. They're making show millions, thousands about young Finance pros.

1245
01:09:18,510 --> 01:09:21,960
Speaker 4:  Then they're gonna keep making billions and then they're gonna make a new

1246
01:09:21,960 --> 01:09:25,760
Speaker 4:  show called Trillions, presumably about very old finance pros.

1247
01:09:26,450 --> 01:09:29,720
Speaker 4:  So you kind of get the Youngs, you got the middle aged and then you got,

1248
01:09:29,790 --> 01:09:31,520
Speaker 4:  then you got the old, the old money,

1249
01:09:31,960 --> 01:09:32,520
Speaker 3:  Right?

1250
01:09:32,520 --> 01:09:36,320
Speaker 4:  And then they're gonna do a Dexter sequel. Like they're just fully into,

1251
01:09:36,340 --> 01:09:40,080
Speaker 4:  all right, we're doing IP franchises all the way around. Yeah, Disney

1252
01:09:40,140 --> 01:09:42,840
Speaker 4:  has already been there, obviously with Marvel, Lucas film, all this other

1253
01:09:42,840 --> 01:09:46,520
Speaker 4:  stuff, but they're now they're starting to expand it. This is the other thing

1254
01:09:46,520 --> 01:09:50,000
Speaker 4:  Iger said. So in addition to saying, okay,

1255
01:09:50,100 --> 01:09:53,920
Speaker 4:  I'm restructuring outta the previous restructure. So we have Disney Entertainment,

1256
01:09:54,050 --> 01:09:57,160
Speaker 4:  we have theme parks, and we have espn. Those are his three divisions,

1257
01:09:58,650 --> 01:10:02,270
Speaker 4:  not the old old structure, right? We had Marvel, Lucas film, wherever.

1258
01:10:02,600 --> 01:10:06,430
Speaker 4:  So he like hybridizes the structure a little bit between him and Shaak. And

1259
01:10:06,430 --> 01:10:09,760
Speaker 4:  then he's like, all right, we gotta lean into our

1260
01:10:09,760 --> 01:10:13,680
Speaker 4:  franchises. We're gonna make a sequel to Zootopia. We're gonna make a

1261
01:10:13,680 --> 01:10:17,440
Speaker 4:  sequel to more sequels to Frozen. We're gonna do more toy

1262
01:10:17,440 --> 01:10:21,040
Speaker 4:  stories. You can say what you want about Zootopia. I mean, that's a movie

1263
01:10:21,040 --> 01:10:23,720
Speaker 4:  about a rabbit detective. You could probably make a hundreds,

1264
01:10:23,770 --> 01:10:24,560
Speaker 3:  He sells crimes.

1265
01:10:25,400 --> 01:10:28,840
Speaker 4:  Like you could do, you could do it all day and all night. Like fuck, fine.

1266
01:10:28,840 --> 01:10:32,160
Speaker 5:  Police, police departments actually watch this to try and reduce police brutality.

1267
01:10:32,190 --> 01:10:33,720
Speaker 5:  That's a real thing happens.

1268
01:10:35,500 --> 01:10:39,340
Speaker 4:  Upsetting. I'm just saying it's a show. It's a buddy cop show.

1269
01:10:39,340 --> 01:10:42,980
Speaker 4:  Like you can, you can see how you can like Zootopia forever, you know? Yeah.

1270
01:10:42,980 --> 01:10:46,140
Speaker 4:  They made four lethal weapons. It all makes sense. In the end, toy story

1271
01:10:46,140 --> 01:10:46,700
Speaker 4:  ended,

1272
01:10:47,870 --> 01:10:48,460
Speaker 3:  It ended up

1273
01:10:48,460 --> 01:10:52,180
Speaker 4:  Really like, it really ended like it ended a lot. And then they made Light

1274
01:10:52,180 --> 01:10:54,860
Speaker 4:  Ear and nobody watched it cuz everyone was like, I know I got it. Got the

1275
01:10:54,860 --> 01:10:58,660
Speaker 4:  whole four movie arc of Toy story, including one false

1276
01:10:58,660 --> 01:11:00,180
Speaker 4:  end where you thought they were all gonna die.

1277
01:11:00,290 --> 01:11:01,540
Speaker 3:  They almost burned alive.

1278
01:11:01,560 --> 01:11:04,500
Speaker 4:  How do you keep that going? How on earth do you keep that going?

1279
01:11:04,570 --> 01:11:08,380
Speaker 3:  Well, they're toys. The the, the idea is that the toys always continue. So

1280
01:11:08,380 --> 01:11:11,460
Speaker 3:  I guess we'll get the little kid. Maybe we'll get new toys.

1281
01:11:11,860 --> 01:11:12,940
Speaker 3:  Maybe the,

1282
01:11:13,040 --> 01:11:15,480
Speaker 4:  There's just, I guarantee you they're gonna remake their first toy story.

1283
01:11:16,120 --> 01:11:16,540
Speaker 4:  You

1284
01:11:16,540 --> 01:11:18,020
Speaker 3:  Can't just keep, I'll just make it not look, they should

1285
01:11:18,020 --> 01:11:21,540
Speaker 5:  Ugly. The CG looks terrible now. They should, they I would buy that on blue

1286
01:11:21,540 --> 01:11:24,740
Speaker 5:  if they, if they reinder it and make it look better right now. I would, I

1287
01:11:24,740 --> 01:11:27,580
Speaker 5:  would buy it. I'm sorry. I'm the problem. It's me. It's

1288
01:11:28,260 --> 01:11:31,140
Speaker 3:  Richard's Just like, look at that ray tracing. Wow.

1289
01:11:31,770 --> 01:11:35,740
Speaker 4:  I was just, toy Story four is like a great mo It ended that

1290
01:11:35,740 --> 01:11:39,300
Speaker 4:  franchise like definitively ended that. F there's no

1291
01:11:39,300 --> 01:11:41,580
Speaker 4:  opening to make a Toy Story five.

1292
01:11:41,580 --> 01:11:43,100
Speaker 3:  Where does Frozen go?

1293
01:11:43,170 --> 01:11:45,540
Speaker 5:  I have haven't watched it. I haven't watched a Pixar movie in a while. They,

1294
01:11:45,540 --> 01:11:48,140
Speaker 5:  they, they decided to be sad and I don't wanna be sad. Yeah,

1295
01:11:48,370 --> 01:11:51,540
Speaker 4:  It's true. Pixar movies are like, what if this movie is about death?

1296
01:11:51,970 --> 01:11:55,460
Speaker 4:  Have you thought about really diving into death with your toddler? And it's

1297
01:11:55,460 --> 01:11:56,900
Speaker 4:  like, no dude, no

1298
01:11:57,420 --> 01:11:58,460
Speaker 3:  Canto. Now you're gunna,

1299
01:12:00,860 --> 01:12:04,100
Speaker 4:  Although in Canto I'll be about death as well. Really. But ager should be

1300
01:12:04,100 --> 01:12:06,740
Speaker 4:  like, we're gonna make more movies about death. And that's our strategy.

1301
01:12:07,040 --> 01:12:10,780
Speaker 4:  All right. So that is going on with Disney. Lots of change over there. Aer

1302
01:12:10,780 --> 01:12:14,700
Speaker 4:  Mastermind. We gotta put em on the scale. The go 90 scale of Doom

1303
01:12:14,700 --> 01:12:15,420
Speaker 4:  streaming services.

1304
01:12:15,460 --> 01:12:16,020
Speaker 3:  Right?

1305
01:12:16,210 --> 01:12:18,780
Speaker 4:  A lot of change. Alex, what do you think? Oh, there's zero. Remember zero

1306
01:12:18,780 --> 01:12:20,260
Speaker 4:  is alive, 90 is dead.

1307
01:12:20,290 --> 01:12:24,020
Speaker 3:  Zero, zero hundred percent zero for, for Disney

1308
01:12:24,090 --> 01:12:27,540
Speaker 3:  plus Hulu is still super up at the air.

1309
01:12:28,410 --> 01:12:31,980
Speaker 3:  ESPN plus you guys can talk about that. That's like a sports thing.

1310
01:12:33,450 --> 01:12:34,180
Speaker 3:  I don't,

1311
01:12:34,330 --> 01:12:38,180
Speaker 4:  ESPN plus is ruined by seo. It's 24 7 Kyrie Irving Flat

1312
01:12:38,180 --> 01:12:41,340
Speaker 4:  Earth Con and that's why it's a zero.

1313
01:12:42,220 --> 01:12:45,860
Speaker 4:  No, ESPN plus is great during football season cuz NFL primetime is on it.

1314
01:12:45,880 --> 01:12:48,940
Speaker 4:  And so I actually watch it once a week, at least once a week. But I would

1315
01:12:48,940 --> 01:12:52,620
Speaker 4:  put that at a 45. Hulu has been at like between 50 and 70

1316
01:12:52,620 --> 01:12:54,460
Speaker 4:  it's entire life. But it's unkillable.

1317
01:12:54,490 --> 01:12:54,980
Speaker 3:  Yeah.

1318
01:12:55,290 --> 01:12:58,820
Speaker 4:  It's just like, you can't end it. And I think, I think Disney plus is at

1319
01:12:58,820 --> 01:13:01,220
Speaker 3:  It like spiritually Hu loses zero.

1320
01:13:01,220 --> 01:13:04,820
Speaker 4:  Well, it's like a it's a technical zero. Yeah. Right.

1321
01:13:04,950 --> 01:13:07,180
Speaker 4:  By all rights, like rational logic,

1322
01:13:07,650 --> 01:13:10,700
Speaker 5:  It's when all the other streaming services are are gone. Yeah.

1323
01:13:10,700 --> 01:13:14,180
Speaker 4:  It's a cockroach. Yeah. Like you can kill a cockroach. It's

1324
01:13:14,660 --> 01:13:16,260
Speaker 4:  possible. But you, you know you that you can't,

1325
01:13:16,260 --> 01:13:17,540
Speaker 3:  But it's hard. Yeah. Yeah.

1326
01:13:17,720 --> 01:13:18,340
Speaker 4:  But I was

1327
01:13:18,340 --> 01:13:20,020
Speaker 3:  Where's your dis where are you for Disney plus

1328
01:13:20,680 --> 01:13:21,100
Speaker 4:  10.

1329
01:13:21,360 --> 01:13:21,780
Speaker 3:  10.

1330
01:13:22,210 --> 01:13:23,460
Speaker 5:  That's, that sounds about

1331
01:13:23,460 --> 01:13:27,220
Speaker 4:  Right. Like it's a, it's, it's, it's like there's more chaos there than we

1332
01:13:27,220 --> 01:13:31,100
Speaker 4:  can see, right? Yeah. So it's not like it's like a 45, but

1333
01:13:31,100 --> 01:13:34,380
Speaker 4:  it's not a zero, it's not default. It's not like definitely alive forever.

1334
01:13:34,380 --> 01:13:38,340
Speaker 4:  It's at 10. It's, these movies gotta be hits. The, you

1335
01:13:38,340 --> 01:13:42,100
Speaker 4:  know, the next two phases of Marvel can't be the horrible ne like

1336
01:13:42,100 --> 01:13:46,020
Speaker 4:  if Marvel keeps going the way that phase four went, it's, it's over like

1337
01:13:46,020 --> 01:13:47,340
Speaker 4:  n no one cares. Right?

1338
01:13:47,340 --> 01:13:50,540
Speaker 3:  The new one's supposed to be really good quantum mania that comes out in

1339
01:13:50,540 --> 01:13:53,780
Speaker 3:  a couple of weeks. Okay. Everybody who's seen it says it's like magic.

1340
01:13:54,460 --> 01:13:55,340
Speaker 3:  We'll see.

1341
01:13:56,410 --> 01:13:56,900
Speaker 4:  It's

1342
01:13:56,900 --> 01:13:59,380
Speaker 3:  Magic, magic, magic. All right.

1343
01:13:59,380 --> 01:14:02,500
Speaker 4:  People are really excited. Yeah. Whatever. I they, they just can't do the

1344
01:14:02,500 --> 01:14:04,660
Speaker 4:  thing where it's like, here's what you gotta do between phases. You gotta

1345
01:14:04,660 --> 01:14:08,620
Speaker 4:  watch 10 TV shows that add up to nothing. Right? Like we, they did that

1346
01:14:08,620 --> 01:14:09,140
Speaker 4:  to us already.

1347
01:14:09,140 --> 01:14:12,720
Speaker 3:  I finally watched Wakanda forever yesterday. I I went to Disney World.

1348
01:14:13,190 --> 01:14:16,880
Speaker 3:  I came back, saw these layoffs and was like, oh, I hope nobody I, I met and

1349
01:14:16,880 --> 01:14:20,520
Speaker 3:  got me on a ride. That happened to the lady who, who gave me a

1350
01:14:20,800 --> 01:14:24,720
Speaker 3:  discount on my magic band. Don't fire her. Bob. She was great. I

1351
01:14:24,720 --> 01:14:25,480
Speaker 3:  don't remember her name.

1352
01:14:25,650 --> 01:14:28,200
Speaker 4:  No. That she was, that was her like last active vengeance. Yeah.

1353
01:14:28,660 --> 01:14:32,560
Speaker 3:  But oh yeah. So, so I saw Wakanda forever and I

1354
01:14:32,560 --> 01:14:36,280
Speaker 3:  was super surprised because I didn't need to like

1355
01:14:36,380 --> 01:14:40,320
Speaker 3:  pay like Yes. There were no weird cameos. There was no like, oh

1356
01:14:40,320 --> 01:14:43,600
Speaker 3:  look, it's bbo from, from BBO too. Yes.

1357
01:14:43,930 --> 01:14:45,840
Speaker 3:  They're here, this is what I'm

1358
01:14:45,840 --> 01:14:49,680
Speaker 4:  Saying. They can't do this to us again. Where they're like, in order to understand

1359
01:14:49,680 --> 01:14:53,640
Speaker 4:  the next movies, you must have a Disney plus subscription so you can watch

1360
01:14:53,720 --> 01:14:55,160
Speaker 4:  these five shows.

1361
01:14:55,630 --> 01:14:56,120
Speaker 3:  Yeah.

1362
01:14:56,310 --> 01:15:00,000
Speaker 4:  That will explain some like, arcane piece of lore that will be, it's like

1363
01:15:00,000 --> 01:15:03,520
Speaker 4:  none of this mattered in the end. I just did a bunch of homework and Wanda

1364
01:15:03,520 --> 01:15:07,040
Speaker 4:  vision was entertaining and all the rest of it was fine, but none of it mattered

1365
01:15:07,040 --> 01:15:09,200
Speaker 4:  and I didn't need to pay you for any of it. None of it. They can't do it.

1366
01:15:09,200 --> 01:15:10,000
Speaker 5:  That's where they messed up.

1367
01:15:10,200 --> 01:15:11,200
Speaker 4:  That's the tent. That's what

1368
01:15:11,200 --> 01:15:13,920
Speaker 5:  I'm saying. Doesn't need to, you didn't need to watch that stuff, but it's

1369
01:15:13,920 --> 01:15:16,800
Speaker 5:  felt like you did. So everybody ended up watching TV shows they didn't like,

1370
01:15:16,800 --> 01:15:19,800
Speaker 5:  and they needed to be clear that, you know, you don't have to watch all those.

1371
01:15:19,800 --> 01:15:21,720
Speaker 5:  If you don't like moon night, you don't have to watch it.

1372
01:15:21,910 --> 01:15:25,840
Speaker 3:  It's just like a perfect show ever recreation of, of the comics experience

1373
01:15:25,840 --> 01:15:28,640
Speaker 3:  where you're like, oh, I gotta go get all of these different comics before

1374
01:15:28,640 --> 01:15:31,320
Speaker 3:  the big thing. And then you're like, no, I don't actually the art sucks and

1375
01:15:31,320 --> 01:15:34,680
Speaker 3:  it's stupid. Yeah. I'm just gonna like, wait for the trade paperback.

1376
01:15:34,750 --> 01:15:35,480
Speaker 4:  Well, you gotta

1377
01:15:35,480 --> 01:15:36,280
Speaker 3:  Get it we'll con forever.

1378
01:15:36,280 --> 01:15:39,720
Speaker 4:  He's an Nvidia Shield in a ed at Alex Kranz

1379
01:15:39,720 --> 01:15:40,280
Speaker 4:  Flexer.

1380
01:15:41,950 --> 01:15:45,720
Speaker 3:  It's sick in there. Got some good content.

1381
01:15:45,720 --> 01:15:47,680
Speaker 4:  No, it's all Lennox. It's all Lennox distributions.

1382
01:15:48,750 --> 01:15:49,960
Speaker 3:  It's wonderful. Ancient,

1383
01:15:50,170 --> 01:15:53,680
Speaker 4:  Ancient expired copyright public domain.

1384
01:15:53,960 --> 01:15:56,320
Speaker 3:  Yeah. It's, it's all, it's all very,

1385
01:15:56,320 --> 01:15:59,080
Speaker 4:  It's all, it's it's all in 1930s news races,

1386
01:15:59,080 --> 01:16:03,040
Speaker 3:  Ethically sourced content. It's all been in the public

1387
01:16:03,040 --> 01:16:06,680
Speaker 3:  domain. Yeah, totally. Mickey's coming. He's gonna be in there soon.

1388
01:16:07,950 --> 01:16:11,760
Speaker 4:  Alex's Plex server, Al has been at a zero in the go, 90 scale of Doom Streaming

1389
01:16:11,760 --> 01:16:13,360
Speaker 4:  services for a long time since

1390
01:16:13,360 --> 01:16:13,920
Speaker 3:  2008.

1391
01:16:13,920 --> 01:16:16,880
Speaker 4:  A little bit easier to talk about in this section. Nintendo, there was Big

1392
01:16:16,880 --> 01:16:18,280
Speaker 4:  Nintendo Direct. What's going on there?

1393
01:16:18,630 --> 01:16:22,600
Speaker 3:  They announced the release date for Zelda. This is the longest

1394
01:16:22,970 --> 01:16:26,960
Speaker 3:  they've gone between Zelda games and I know that I'm old because

1395
01:16:26,960 --> 01:16:28,240
Speaker 3:  it doesn't feel that long.

1396
01:16:28,240 --> 01:16:28,840
Speaker 4:  Doesn't

1397
01:16:28,840 --> 01:16:32,600
Speaker 3:  Feel that long. But I guess if I was like 13, I'd be like, oh, thank God

1398
01:16:32,950 --> 01:16:36,280
Speaker 3:  I was seven when that last one came out. So they, they, they showed off

1399
01:16:36,640 --> 01:16:40,080
Speaker 3:  Zelda Link is gonna drive a car. It's gonna be really exciting.

1400
01:16:40,270 --> 01:16:43,640
Speaker 3:  They also announced the price in this weird thing where you can

1401
01:16:44,000 --> 01:16:47,800
Speaker 3:  pre-order it, but you need a voucher. But why do you need to

1402
01:16:47,800 --> 01:16:49,000
Speaker 3:  pre-order a digital game?

1403
01:16:49,370 --> 01:16:53,360
Speaker 4:  So it, the it's $70, but then you can get, you can buy a

1404
01:16:53,360 --> 01:16:54,520
Speaker 4:  voucher for $50.

1405
01:16:54,830 --> 01:16:58,400
Speaker 5:  Yeah. And a sec and another game. So basically you can buy two games for

1406
01:16:58,400 --> 01:17:01,480
Speaker 5:  a hundred dollars or you could buy just Zelda for $70.

1407
01:17:01,870 --> 01:17:02,360
Speaker 3:  Okay.

1408
01:17:02,510 --> 01:17:06,360
Speaker 4:  Okay. That seems very confusing, but I'm gonna do it because I love

1409
01:17:06,360 --> 01:17:08,880
Speaker 4:  these games. I need to go play Breath of the Wild again. It's been a long

1410
01:17:08,880 --> 01:17:09,560
Speaker 4:  time. Time. We

1411
01:17:09,560 --> 01:17:11,480
Speaker 5:  Just talked about this. You don't have to do the homework, man.

1412
01:17:11,760 --> 01:17:12,400
Speaker 3:  Don't do the homework.

1413
01:17:13,060 --> 01:17:16,040
Speaker 4:  But that's like entertaining homework. Although I, I doubt there's any

1414
01:17:16,230 --> 01:17:18,080
Speaker 4:  particular connection between these two

1415
01:17:18,080 --> 01:17:20,440
Speaker 5:  Games. If it were entertaining, it would be on a Sega system.

1416
01:17:22,460 --> 01:17:23,480
Speaker 5:  I'm not biased.

1417
01:17:24,100 --> 01:17:24,520
Speaker 3:  The

1418
01:17:25,590 --> 01:17:26,440
Speaker 5:  Commentary.

1419
01:17:30,850 --> 01:17:34,240
Speaker 3:  Oh. And they, they announced that Metro Prime, which was

1420
01:17:34,240 --> 01:17:38,000
Speaker 3:  absolutely fantastic on the Game Cube is finally, it's getting, its

1421
01:17:38,000 --> 01:17:41,960
Speaker 3:  remaster. It looks really nice and shiny. Having recently played

1422
01:17:41,960 --> 01:17:45,240
Speaker 3:  Metro Prime. I'm gonna go against Sean who says, oh yeah, you can play it

1423
01:17:45,240 --> 01:17:49,080
Speaker 3:  on the Switch or Oh yeah, you can play it on the steam deck. And it's wonderful.

1424
01:17:49,080 --> 01:17:52,800
Speaker 3:  It's not, it's really kind of hard. Yeah, those

1425
01:17:52,800 --> 01:17:56,200
Speaker 3:  controllers aren't made, like the controllers are just totally different.

1426
01:17:56,370 --> 01:18:00,040
Speaker 3:  So this is gonna be made for the switch. It should be very smooth

1427
01:18:00,300 --> 01:18:03,240
Speaker 3:  for people who are like old and nostalgic. They'll be like, oh, it's nice,

1428
01:18:03,240 --> 01:18:06,760
Speaker 3:  but it doesn't look like butts. And for new people to be like, oh, this is

1429
01:18:06,760 --> 01:18:07,360
Speaker 3:  just a fun game.

1430
01:18:07,690 --> 01:18:10,920
Speaker 4:  Is there any game that Sean doesn't think is the most playable and the most

1431
01:18:10,920 --> 01:18:11,720
Speaker 4:  fun on the steam deck?

1432
01:18:12,930 --> 01:18:16,600
Speaker 3:  No. We're gonna find one checking. We're gonna find. That's, that's my mission.

1433
01:18:16,600 --> 01:18:20,520
Speaker 3:  If you have one, send me, like, hit me up, hit me up on, on on Twitter.

1434
01:18:20,700 --> 01:18:23,400
Speaker 3:  I'm the last person there. I wanna hear all about it.

1435
01:18:24,880 --> 01:18:27,720
Speaker 4:  She's hit the API limits with Steam deck commentary. And

1436
01:18:27,720 --> 01:18:31,600
Speaker 3:  They also, I, one, one last thing. They also are starting to roll

1437
01:18:31,600 --> 01:18:35,080
Speaker 3:  out GameBoy and Game Boy Advanced Games on the Switch, which has been like

1438
01:18:35,390 --> 01:18:36,960
Speaker 3:  a long time coming.

1439
01:18:37,510 --> 01:18:40,840
Speaker 5:  Yeah. Can you buy a translucent switch now? Because if you can't, then you

1440
01:18:40,840 --> 01:18:44,200
Speaker 5:  can't really get the GameBoy experience the, the nineties way with a see-through

1441
01:18:44,390 --> 01:18:46,600
Speaker 5:  portable system. Yeah, that's, yeah,

1442
01:18:46,870 --> 01:18:50,200
Speaker 4:  That was, remember everything was see-through. I hope the next, like the

1443
01:18:50,440 --> 01:18:53,000
Speaker 4:  next wave is bringing that back like the nineties and two thousands are,

1444
01:18:53,000 --> 01:18:54,560
Speaker 4:  are back in like a small way. Like

1445
01:18:54,560 --> 01:18:58,240
Speaker 3:  You're doing the glass backs on the phones. Anyway, just take that pane off.

1446
01:18:58,240 --> 01:18:59,360
Speaker 3:  Let me see the insides.

1447
01:18:59,360 --> 01:19:00,480
Speaker 4:  Just let me some trans

1448
01:19:00,480 --> 01:19:01,040
Speaker 3:  Show me the battery.

1449
01:19:01,900 --> 01:19:04,600
Speaker 4:  All we gotta take a break. See new phones are come back. We'll talk about

1450
01:19:04,600 --> 01:19:07,920
Speaker 4:  the one plus 11 come a little bit of a lightning around coming. That's all

1451
01:19:07,920 --> 01:19:09,200
Speaker 4:  coming out next, but we are back.

1452
01:19:13,970 --> 01:19:17,910
Speaker 15:  Hey there, I'm Josh Mucci, host of the Pitch. A show where

1453
01:19:17,910 --> 01:19:21,670
Speaker 15:  real entrepreneurs pitch real tech investors for real money.

1454
01:19:22,090 --> 01:19:24,470
Speaker 15:  And this season gets a little saucy.

1455
01:19:24,680 --> 01:19:28,550
Speaker 16:  We knew that we were not going to join the same old sauce

1456
01:19:28,550 --> 01:19:32,470
Speaker 16:  game. We were gonna disrupt 130 billion industry.

1457
01:19:32,470 --> 01:19:33,550
Speaker 16:  We're coming after

1458
01:19:33,550 --> 01:19:37,310
Speaker 15:  Hines. We meet founders pitching everything from a better ketchup

1459
01:19:37,880 --> 01:19:41,150
Speaker 15:  to a solution for one of the biggest problems today.

1460
01:19:41,740 --> 01:19:42,350
Speaker 15:  Energy

1461
01:19:42,400 --> 01:19:46,190
Speaker 17:  In the future, the vehicles and garage is gonna be like a giant

1462
01:19:46,190 --> 01:19:49,990
Speaker 17:  power plants that could be used to reinforce the power grid, substitute

1463
01:19:49,990 --> 01:19:53,190
Speaker 17:  fossil fuel power plants, and allow more renewable energy on the

1464
01:19:53,190 --> 01:19:56,950
Speaker 15:  Network. This season, 14 founders with 12 ideas

1465
01:19:57,170 --> 01:20:01,030
Speaker 15:  big enough to change the world. If the investors invest,

1466
01:20:01,380 --> 01:20:05,030
Speaker 15:  I would like to invest in this round. $300,000 new episodes

1467
01:20:05,030 --> 01:20:06,790
Speaker 15:  every Wednesday. See you in the

1468
01:20:06,790 --> 01:20:07,320
Speaker 18:  Pitch room

1469
01:20:09,500 --> 01:20:12,720
Speaker 19:  For as long as I can remember. Bread has given me hiccups.

1470
01:20:13,910 --> 01:20:16,680
Speaker 20:  I always get the hiccups when I eat baby carrots.

1471
01:20:16,720 --> 01:20:20,600
Speaker 21:  Sometimes when I am washing my left ear, just my left

1472
01:20:20,600 --> 01:20:21,560
Speaker 21:  ear, I hiccup.

1473
01:20:22,700 --> 01:20:25,760
Speaker 19:  And my tried and true hiccup here is,

1474
01:20:26,170 --> 01:20:30,000
Speaker 22:  Or a glass of water, light a match, put the match out in the

1475
01:20:30,000 --> 01:20:32,360
Speaker 22:  water, drink the water, throw away the

1476
01:20:32,360 --> 01:20:36,280
Speaker 23:  Match, put your elbows out, 0.2 fingers together and sort of stare at

1477
01:20:36,280 --> 01:20:39,080
Speaker 23:  the point between the fingers. It doesn't work if you bring your elbows

1478
01:20:39,080 --> 01:20:40,600
Speaker 23:  down, but it works.

1479
01:20:40,870 --> 01:20:43,320
Speaker 24:  Just eat a spoonful of peanut butter.

1480
01:20:43,320 --> 01:20:44,760
Speaker 19:  Think of a green rabbit.

1481
01:20:45,110 --> 01:20:47,880
Speaker 25:  I taught myself to burp on commands, like,

1482
01:20:51,400 --> 01:20:55,040
Speaker 25:  excuse me. And I discovered that when I make myself

1483
01:20:55,040 --> 01:20:57,240
Speaker 25:  burp, it stops my hiccups.

1484
01:20:59,220 --> 01:21:02,960
Speaker 18:  Unexplainable is taking on hiccups, what causes them

1485
01:21:03,220 --> 01:21:06,640
Speaker 18:  and is there any kind of scientific cure, follow

1486
01:21:06,760 --> 01:21:09,120
Speaker 18:  unexplainable for new episodes every Wednesday.

1487
01:21:16,240 --> 01:21:20,220
Speaker 4:  All right, we're back. Richard, I'm calling on you. One

1488
01:21:20,220 --> 01:21:21,220
Speaker 4:  plus 11. I

1489
01:21:21,220 --> 01:21:22,180
Speaker 3:  Was at Disney World. What

1490
01:21:22,300 --> 01:21:25,860
Speaker 4:  Happened? It happened. It ha yeah, Alex of the Disney world. She's, she's

1491
01:21:25,860 --> 01:21:26,900
Speaker 4:  hunting for Iers,

1492
01:21:27,700 --> 01:21:31,660
Speaker 5:  The one plus 11 5g, which is the most important phone to me in my

1493
01:21:31,660 --> 01:21:31,820
Speaker 5:  life

1494
01:21:32,010 --> 01:21:32,500
Speaker 4:  Ever.

1495
01:21:33,490 --> 01:21:37,340
Speaker 5:  I don't care about anything as much as I do. The one plus 11 5G to be

1496
01:21:37,580 --> 01:21:41,460
Speaker 5:  specific, which is a $699 flagship phone is one plus

1497
01:21:41,460 --> 01:21:44,020
Speaker 5:  it's moved from their mid-range to kind of flagship. They're trying to get

1498
01:21:44,020 --> 01:21:46,380
Speaker 5:  the magic back. We remember a few years ago when one plus was really cool.

1499
01:21:46,380 --> 01:21:49,860
Speaker 5:  They they gave you Yeah, high specs, mid-range prices,

1500
01:21:50,200 --> 01:21:53,100
Speaker 5:  but now they just make phones. Everybody makes phones. They, they're like

1501
01:21:53,100 --> 01:21:55,220
Speaker 5:  Motorolas with different labels. Maybe a few more software

1502
01:21:55,220 --> 01:21:57,180
Speaker 4:  Updates. The the founder is off doing nothing.

1503
01:21:57,410 --> 01:21:59,060
Speaker 5:  Yeah. Literal, literally

1504
01:21:59,710 --> 01:22:00,060
Speaker 3:  So

1505
01:22:00,060 --> 01:22:01,180
Speaker 5:  Much. I hate that man. Brutal.

1506
01:22:01,330 --> 01:22:01,820
Speaker 4:  That

1507
01:22:01,820 --> 01:22:05,660
Speaker 3:  Pun just hurt my brain. That was great.

1508
01:22:06,230 --> 01:22:07,310
Speaker 3:  Sorry Richard.

1509
01:22:07,610 --> 01:22:11,550
Speaker 5:  But the, the, it's the, Alison reviewed the one plus 11 5g. They

1510
01:22:11,550 --> 01:22:14,670
Speaker 5:  announced a bunch of new devices. They have a tablet now. They got earbuds

1511
01:22:14,670 --> 01:22:17,470
Speaker 5:  of course. And it seems to be a pretty good phone. They have a keyboard.

1512
01:22:17,470 --> 01:22:21,390
Speaker 5:  Yeah. Yeah. They, they have a, a mechanical keyboard, maybe a little inconsistent

1513
01:22:21,390 --> 01:22:25,190
Speaker 5:  camera, but it, it's, it seems pretty good in terms of like price and performance-wise.

1514
01:22:25,190 --> 01:22:27,950
Speaker 5:  And maybe a reason for you to look at one plus again, if you, if you haven't

1515
01:22:27,950 --> 01:22:30,950
Speaker 5:  been, because you know, obviously got the pixel options now you got so many

1516
01:22:30,950 --> 01:22:34,830
Speaker 5:  other really good phones at that mid-range price point. But it's maybe good

1517
01:22:34,830 --> 01:22:37,510
Speaker 5:  enough for you to spend a little bit more for this particular phone.

1518
01:22:37,510 --> 01:22:40,470
Speaker 4:  Well, I'll just leave you with Alison's poll quote From your view, for everyone

1519
01:22:40,470 --> 01:22:44,270
Speaker 4:  who isn't a one plus Dave devotee, I hesitate to recommend the one plus 11.

1520
01:22:45,420 --> 01:22:49,390
Speaker 4:  I don't, one plus had, it was a, for a minute, it was the Challenger brand

1521
01:22:49,610 --> 01:22:53,430
Speaker 4:  and then Oppo kind of swarm in, took it back, made it just

1522
01:22:53,430 --> 01:22:57,190
Speaker 4:  more APO phones for the United States. Carl left to do nothing and now

1523
01:22:57,190 --> 01:22:57,870
Speaker 4:  it's like, fine.

1524
01:22:58,180 --> 01:23:00,390
Speaker 5:  Yeah, they, they, they make okay devices,

1525
01:23:00,650 --> 01:23:04,030
Speaker 4:  But is there any meaningful challenge to Samsung in the market? Because this

1526
01:23:04,030 --> 01:23:07,720
Speaker 4:  is like the thing, right? It's like you think the battle is Apple versus

1527
01:23:07,720 --> 01:23:10,640
Speaker 4:  Android, but the battle is really Apple versus Samsung and Google's like

1528
01:23:10,640 --> 01:23:13,880
Speaker 4:  trapped in the middle. And then on top of it, and we talked about it at the

1529
01:23:13,880 --> 01:23:17,840
Speaker 4:  top of the show, Google has like an existential crisis in search. Like,

1530
01:23:17,990 --> 01:23:21,800
Speaker 4:  I don't know man, like I, this is like a weird spot for the Android

1531
01:23:21,800 --> 01:23:25,400
Speaker 4:  ecosystem. Like either Samsung's pushing it forward

1532
01:23:25,570 --> 01:23:29,520
Speaker 4:  or Google's gonna put, take meaningful share and push it forward. But

1533
01:23:29,520 --> 01:23:32,480
Speaker 4:  Google's pretty distracted by saving its core business.

1534
01:23:32,660 --> 01:23:35,760
Speaker 5:  You end up in a, in a strange place because you have this phone that has

1535
01:23:35,760 --> 01:23:38,800
Speaker 5:  a camera that's not as good as Samsung or Google's because they can't do

1536
01:23:38,800 --> 01:23:41,600
Speaker 5:  all the weird technology stuff. They can't build better hardware than Samsung.

1537
01:23:41,600 --> 01:23:45,200
Speaker 5:  They can't do better software than Google. And so you're paying a lot

1538
01:23:45,220 --> 01:23:48,280
Speaker 5:  for a, a markedly worse experience in at least a couple of ways,

1539
01:23:48,560 --> 01:23:52,240
Speaker 3:  Right? Because you have to, like, they're competing with all of the

1540
01:23:52,360 --> 01:23:56,160
Speaker 3:  resources of Apple and all of the resources of Samsung. And those are

1541
01:23:56,190 --> 01:23:59,960
Speaker 3:  a lot of resources that most other companies don't have. Or they're

1542
01:23:59,960 --> 01:24:03,800
Speaker 3:  Sony and they're too busy making really good party speakers and not

1543
01:24:03,800 --> 01:24:07,360
Speaker 3:  reaching out to about those speakers. Yeah. So like it's

1544
01:24:07,360 --> 01:24:11,240
Speaker 3:  truly, I think it's a difficult place and one plus is,

1545
01:24:11,290 --> 01:24:15,040
Speaker 3:  is struggling, but it's interesting that they release like the one plus pad,

1546
01:24:15,350 --> 01:24:19,160
Speaker 3:  this this new tablet and the keyboard. I wanna come back to the keyboard

1547
01:24:19,160 --> 01:24:23,040
Speaker 3:  because I have a lot of questions. It's just a rebranded Kron,

1548
01:24:23,920 --> 01:24:27,000
Speaker 3:  but they're doing their own switches. Ooh. And then they're saying

1549
01:24:27,000 --> 01:24:30,240
Speaker 4:  That's not the part of the keyboard that you want to do your own of. Right?

1550
01:24:30,360 --> 01:24:31,600
Speaker 3:  Right. They're

1551
01:24:31,640 --> 01:24:35,080
Speaker 4:  Probably, but even Logitech sells like cherry switches in some It's

1552
01:24:35,200 --> 01:24:37,320
Speaker 3:  Keyboard. No, Logitech does their own switches too now. They're probably,

1553
01:24:37,320 --> 01:24:39,880
Speaker 4:  No, but they, but some of their keyboards have other switches in them.

1554
01:24:39,990 --> 01:24:43,480
Speaker 3:  Yeah, they, they, they do, they do a whole gamut. So it's kind of interesting.

1555
01:24:43,750 --> 01:24:46,920
Speaker 3:  I'll be surprised though, if it's not just a rebranded

1556
01:24:47,310 --> 01:24:51,040
Speaker 3:  knockoff of a cherry. There's a lot of different people that are

1557
01:24:51,040 --> 01:24:54,280
Speaker 3:  doing very similar switches, so it's not really hard to be like, we're gonna

1558
01:24:54,280 --> 01:24:58,120
Speaker 3:  do it in a slightly different color. Slightly different change in the

1559
01:24:58,120 --> 01:25:01,040
Speaker 3:  spring boom. New switch. Yeah. From one plus

1560
01:25:02,270 --> 01:25:06,000
Speaker 3:  it's got like a little crystal dial on it, but

1561
01:25:06,000 --> 01:25:09,960
Speaker 3:  think really kind of upset me about it, is

1562
01:25:09,960 --> 01:25:13,640
Speaker 3:  that they're using a different, they claim that they're using a different

1563
01:25:13,920 --> 01:25:17,760
Speaker 3:  material for the keycaps themselves and they won't

1564
01:25:17,770 --> 01:25:21,040
Speaker 3:  go into a lot of the details besides saying it's called

1565
01:25:21,510 --> 01:25:25,200
Speaker 3:  Marble Mellow Marble. Marble mellow marble

1566
01:25:25,200 --> 01:25:28,880
Speaker 3:  Mellow like marshmallow, but Marble Mellow. Oh yeah, yeah.

1567
01:25:28,880 --> 01:25:30,360
Speaker 3:  There's just, it's a new material.

1568
01:25:30,360 --> 01:25:33,280
Speaker 4:  I gotta say this keyboard. I'm, I'm just looking at this keyboard. It looks

1569
01:25:33,280 --> 01:25:36,000
Speaker 4:  like the keyboard that you would be issued if you worked in a bank and I

1570
01:25:36,000 --> 01:25:36,880
Speaker 4:  don't understand it.

1571
01:25:36,910 --> 01:25:40,880
Speaker 3:  Yeah, it looks, I mean, Kron makes really, really lovely keyboards.

1572
01:25:40,880 --> 01:25:44,120
Speaker 3:  Most people like one like this. It's a 75% where it's got a full,

1573
01:25:44,960 --> 01:25:48,560
Speaker 3:  it's got a full direction pad. It's got a bunch of

1574
01:25:48,640 --> 01:25:52,480
Speaker 3:  extra little bits, but it doesn't have a full number pad. So a lot of people

1575
01:25:52,480 --> 01:25:56,360
Speaker 3:  like this size, but I think most people have started

1576
01:25:56,360 --> 01:25:59,880
Speaker 3:  to think of these big fancy keyboards of having really flashy colors. And

1577
01:25:59,880 --> 01:26:03,480
Speaker 3:  this is like, no, we're gonna go with the, the apo way. It's gonna be

1578
01:26:03,990 --> 01:26:05,400
Speaker 3:  gray and red and

1579
01:26:05,460 --> 01:26:08,840
Speaker 4:  Yes, fine. Have you heard of b m in the seventies?

1580
01:26:10,230 --> 01:26:11,320
Speaker 3:  People love that. Look,

1581
01:26:11,830 --> 01:26:15,040
Speaker 4:  Some people do. I I didn't grow up wanting to be an accountant, you know

1582
01:26:15,040 --> 01:26:18,800
Speaker 4:  what I'm saying? Okay. By the way, the, the the one plus pad,

1583
01:26:19,190 --> 01:26:22,480
Speaker 4:  it's fascinating that people think they can make Android tablets happen again.

1584
01:26:22,710 --> 01:26:26,640
Speaker 4:  Like Google is pushing at it. There are some leaks of the Nest tablet

1585
01:26:26,640 --> 01:26:28,960
Speaker 4:  thing today. One plus is at

1586
01:26:28,960 --> 01:26:30,800
Speaker 3:  It. They got that big camera on the back.

1587
01:26:31,390 --> 01:26:35,320
Speaker 4:  I, we'll see, we'll see. I just, the idea that we're, we're in for

1588
01:26:35,320 --> 01:26:39,120
Speaker 4:  another round of Android tablet hysterics is very funny to me. We,

1589
01:26:39,120 --> 01:26:40,440
Speaker 4:  we've been down this road. I

1590
01:26:40,440 --> 01:26:43,480
Speaker 5:  Feel like that's the last time that we had you, you know, you mentioned how

1591
01:26:43,480 --> 01:26:46,520
Speaker 5:  the companies were getting kind of, of, of spicy with each other, like about

1592
01:26:46,520 --> 01:26:49,400
Speaker 5:  ai. That was the last time we had companies really, really talking about

1593
01:26:49,400 --> 01:26:52,520
Speaker 5:  each other was when there seemed like there might be a challenge to the iPad

1594
01:26:52,520 --> 01:26:55,120
Speaker 5:  and then they all got smacked down and they, they didn't do that anymore.

1595
01:26:55,150 --> 01:26:58,760
Speaker 4:  Well, keep in mind Steve Jobs was still around back then, so he would get

1596
01:26:58,760 --> 01:27:01,440
Speaker 4:  on the earnings call and be like, seven inch tablets, they're for fucking

1597
01:27:01,520 --> 01:27:05,480
Speaker 4:  idiots. Well, I guess, I guess that's the way, I guess

1598
01:27:05,480 --> 01:27:09,240
Speaker 4:  we're all printing that. Like here we go is write the headline. They don't,

1599
01:27:09,240 --> 01:27:13,040
Speaker 4:  they stop talking about one another for ages, right? They're all frenemies.

1600
01:27:13,040 --> 01:27:17,000
Speaker 4:  They're all cooperators or whatever that word is, right? Like, and

1601
01:27:17,000 --> 01:27:19,520
Speaker 4:  now cooperative with Hope. We'll see what search, you know,

1602
01:27:21,040 --> 01:27:24,920
Speaker 4:  Microsoft is ready to be a little spiky over there, but in tablets

1603
01:27:24,920 --> 01:27:28,680
Speaker 4:  you think like Apple doesn't care if like barely cares about the iPad. It's

1604
01:27:28,680 --> 01:27:31,480
Speaker 4:  like, here's another one. I don't know. Like it's what you want. They all

1605
01:27:31,480 --> 01:27:35,040
Speaker 4:  look the same. Well like, is the one plus one plus Pad gonna

1606
01:27:35,040 --> 01:27:38,560
Speaker 4:  scare Apple into carrying, is the Nest thing gonna scare Apple on the car?

1607
01:27:38,560 --> 01:27:38,680
Speaker 4:  I

1608
01:27:38,680 --> 01:27:42,480
Speaker 3:  Don't know. Is the one plus pad gonna sell? Like who, who is the

1609
01:27:42,760 --> 01:27:45,680
Speaker 3:  customer there besides I guess one plus Die Hard

1610
01:27:45,680 --> 01:27:49,280
Speaker 4:  People with children. It's always people with children. Like, can this thing

1611
01:27:49,280 --> 01:27:53,200
Speaker 4:  run Disney Pluses? Like honestly at this point, IER should just make a tablet

1612
01:27:53,650 --> 01:27:56,960
Speaker 4:  in Sellage people with kids. Like that's, that's the market for these things.

1613
01:27:56,960 --> 01:28:00,360
Speaker 4:  Funny and apparently pilots, pilots love them, but they all buy up Head minis.

1614
01:28:01,000 --> 01:28:04,720
Speaker 4:  Okay, little bit of a lightning round. This is a weird one. So

1615
01:28:05,430 --> 01:28:08,240
Speaker 4:  Meta wants to go by within, which makes Supernatural. I've talked about a

1616
01:28:08,240 --> 01:28:12,200
Speaker 4:  bunch of the show before. Ftc Lena Con says, no, you gotta block it.

1617
01:28:12,200 --> 01:28:14,520
Speaker 4:  This is just like when you bought Instagram, you're buying up all the VR

1618
01:28:14,520 --> 01:28:18,480
Speaker 4:  game studios. Supernatural is the app that makes not

1619
01:28:18,480 --> 01:28:22,200
Speaker 4:  gamers by the meta quests too, right? It's like the stats are

1620
01:28:22,200 --> 01:28:26,120
Speaker 4:  astounding. It's like this is what older people and what

1621
01:28:26,120 --> 01:28:29,840
Speaker 4:  women buy. They, they work out in yard and it's great. I use it. We talked

1622
01:28:29,840 --> 01:28:32,600
Speaker 4:  about it a lot. Ft C says, no, you can't buy up all the studios. They go

1623
01:28:32,600 --> 01:28:36,480
Speaker 4:  to court, they lose, they say they're going to appeal the court blocks,

1624
01:28:36,480 --> 01:28:40,320
Speaker 4:  their injunction deal closes anyway. So now Meta

1625
01:28:40,320 --> 01:28:43,240
Speaker 4:  owns within, they change the website to say it's all a meta company now.

1626
01:28:43,380 --> 01:28:47,360
Speaker 4:  But the FTC is still appealing. I'm not sure what happens if they win

1627
01:28:47,360 --> 01:28:50,360
Speaker 4:  that appeal. They just like get kicked out. Like, they're like, well I guess

1628
01:28:50,360 --> 01:28:52,600
Speaker 4:  we don't own you, so we'll see. But that happened.

1629
01:28:52,860 --> 01:28:54,000
Speaker 3:  But they have to sell it,

1630
01:28:54,000 --> 01:28:57,280
Speaker 4:  Right? Or spin it back out. I don't know. I, yeah, the fact that the FCC

1631
01:28:57,280 --> 01:29:01,120
Speaker 4:  like lost and they're gonna appeal, but they, it's all very confusing. But

1632
01:29:01,320 --> 01:29:05,160
Speaker 4:  anyway, meta is just continuing to buy all the VR companies. We'll see

1633
01:29:05,160 --> 01:29:08,800
Speaker 4:  what that portends for Apple in the future. Richard, I added this one just

1634
01:29:08,800 --> 01:29:12,480
Speaker 4:  for you. The ads for Super Bowl foxes all sold out, zero crypto

1635
01:29:12,480 --> 01:29:14,400
Speaker 4:  ads on this year's Super Bowl. Aw.

1636
01:29:14,520 --> 01:29:18,040
Speaker 5:  After, seemed like there was a crypto ad every five minutes last year during

1637
01:29:18,040 --> 01:29:21,480
Speaker 5:  the Super Bowl, after we had Coinbase literally giving away money and they

1638
01:29:21,480 --> 01:29:24,040
Speaker 5:  crashed their servers because too many people scanned the QR code and tried

1639
01:29:24,040 --> 01:29:27,200
Speaker 5:  to sign up for accounts to get free Crypto. Seems like everybody's outta

1640
01:29:27,200 --> 01:29:30,320
Speaker 5:  cash now or in jail or going to jail

1641
01:29:31,000 --> 01:29:34,800
Speaker 5:  or perhaps indicted and has their former executives now testifying against

1642
01:29:34,800 --> 01:29:38,480
Speaker 5:  them as, as you see with, with ftx. But yeah, crypto.com and

1643
01:29:38,640 --> 01:29:42,600
Speaker 5:  Coinbase continued to exist apparently, but they just

1644
01:29:42,600 --> 01:29:45,800
Speaker 5:  don't have money like they used to. They, they're not spent, I think the

1645
01:29:45,800 --> 01:29:48,960
Speaker 5:  executive that talked to Sports Business Journal from Fox Sports said that

1646
01:29:48,960 --> 01:29:52,760
Speaker 5:  some of these companies had reserved ads, but the FTX obviously

1647
01:29:52,760 --> 01:29:56,640
Speaker 5:  cannot and the others backed out because

1648
01:29:57,140 --> 01:30:00,760
Speaker 5:  you know, Bitcoin just isn't worth what it was, what it used to be. Yeah,

1649
01:30:00,780 --> 01:30:01,200
Speaker 5:  you

1650
01:30:01,200 --> 01:30:04,840
Speaker 4:  Hate to see it. And then lastly, big leak from Chris Welch. And the man

1651
01:30:05,120 --> 01:30:07,840
Speaker 4:  continues to just crawl around the air vents at Sonos. He's in there right

1652
01:30:07,840 --> 01:30:10,760
Speaker 4:  now. Actually the next speakers are coming spatial audio. They're gonna be

1653
01:30:10,760 --> 01:30:14,560
Speaker 4:  called the era 300 in the era 100. Patrick Spence has said

1654
01:30:14,560 --> 01:30:18,440
Speaker 4:  they're gonna reset the bar in existing audio categories. He's got a scoop

1655
01:30:18,440 --> 01:30:21,760
Speaker 4:  on a second generation Sonos. Move the era 300. ERA 100.

1656
01:30:22,230 --> 01:30:26,120
Speaker 4:  They had the Codenamed Optima before ERA 300

1657
01:30:26,720 --> 01:30:30,040
Speaker 4:  designed for spatial audio. And I know Sonos is gonna be like, it's not a

1658
01:30:30,040 --> 01:30:33,640
Speaker 4:  gimmick. I I can't wait to hear this thing. See, see if it's not a gimmick.

1659
01:30:33,640 --> 01:30:37,360
Speaker 4:  Brand new designs, we found documentation of

1660
01:30:37,360 --> 01:30:40,880
Speaker 4:  of speaker stands from SAIS for these things that cost

1661
01:30:41,020 --> 01:30:44,880
Speaker 4:  $220. This is speaker, but SOS

1662
01:30:44,880 --> 01:30:47,600
Speaker 4:  is like coming out the gate strong this year. They're gonna have four new

1663
01:30:47,600 --> 01:30:50,920
Speaker 4:  categories. They've got these big new speakers focused on spatial. We need

1664
01:30:50,920 --> 01:30:54,560
Speaker 4:  to figure out Codex support whether Apple Music will support them all. There's

1665
01:30:54,560 --> 01:30:58,000
Speaker 4:  all these questions to be answered. Sure. But they just had earnings. And

1666
01:30:58,000 --> 01:31:01,760
Speaker 4:  Patrick Spence, front of the show ceo, he is like, no one's even competing

1667
01:31:02,000 --> 01:31:05,200
Speaker 4:  with us. There was no competition. Smart speakers or the holidays. And we

1668
01:31:05,200 --> 01:31:09,040
Speaker 4:  looked, and it's true, there wasn't any like no one released new piece of

1669
01:31:09,040 --> 01:31:13,000
Speaker 4:  speaker products. No Google, no Amazon, no nothing. New HomePod is out. He's

1670
01:31:13,000 --> 01:31:14,560
Speaker 4:  like, yeah, whatever. Kind of wild.

1671
01:31:14,990 --> 01:31:18,240
Speaker 5:  Yeah, I think they see a hole in the market that's been left by these tech

1672
01:31:18,240 --> 01:31:20,760
Speaker 5:  companies that got in and we're like, yeah, we're gonna build better speakers

1673
01:31:20,760 --> 01:31:23,640
Speaker 5:  and we're gonna use algorithms and we're gonna, we're gonna beat whoever

1674
01:31:23,640 --> 01:31:27,280
Speaker 5:  is is in speakers because we don't know and don't care. And now they're kind

1675
01:31:27,280 --> 01:31:29,680
Speaker 5:  of retreating because it's a little bit harder than they, than they thought.

1676
01:31:29,680 --> 01:31:33,640
Speaker 5:  They suddenly, they, their costs went way up at they, they need to

1677
01:31:33,640 --> 01:31:35,960
Speaker 5:  cut up back on these divisions and they're not building frivolous products

1678
01:31:35,960 --> 01:31:39,400
Speaker 5:  anymore. And Sonos says, yeah, so you want a new Sparks speaker, welcome

1679
01:31:39,400 --> 01:31:40,120
Speaker 5:  back to Sonos.

1680
01:31:41,040 --> 01:31:44,480
Speaker 4:  Welcome back. You got one more room in your house, what you're gonna do.

1681
01:31:44,790 --> 01:31:48,040
Speaker 4:  I think it's exciting. That event is on February 23rd. I think

1682
01:31:48,320 --> 01:31:51,560
Speaker 4:  we'll see, I I think Sonos is leaning pretty heavily into

1683
01:31:52,200 --> 01:31:55,800
Speaker 4:  Spacial, it's leaning pretty heavily into Atmos. Kinda like lots of opportunity

1684
01:31:55,800 --> 01:31:59,160
Speaker 4:  for them to kind of redefine this stuff at the same time, you know, know

1685
01:31:59,160 --> 01:32:02,160
Speaker 4:  how I feel. Everybody knows how I feel. I think Atmos for music is just like

1686
01:32:02,160 --> 01:32:05,080
Speaker 4:  foolish. So we'll see. Maybe they're gonna show me.

1687
01:32:05,460 --> 01:32:09,160
Speaker 3:  Are these gonna be definitely music speakers or are they supposed to be like

1688
01:32:09,160 --> 01:32:12,240
Speaker 3:  your extra speakers for your home theater or

1689
01:32:12,240 --> 01:32:15,160
Speaker 4:  Both? Did you just they're not extra. They're a key component of the home

1690
01:32:15,160 --> 01:32:18,480
Speaker 4:  theater. Alex, I'm sorry. They're not extra the surround,

1691
01:32:18,480 --> 01:32:21,160
Speaker 3:  You know, the, the, the rear speakers. That's

1692
01:32:21,160 --> 01:32:24,240
Speaker 4:  What I think of the, I'm reading sound and vision in PDF form on my phone.

1693
01:32:24,240 --> 01:32:26,840
Speaker 4:  All right. I'm like back in the mix. You're in it. This is very important

1694
01:32:26,890 --> 01:32:29,720
Speaker 3:  To me. You're, when are you once are, when are you getting your new receiver?

1695
01:32:30,780 --> 01:32:34,560
Speaker 4:  I'm actually very hopeful that this is one of Sonos new categories. It absolutely

1696
01:32:34,560 --> 01:32:38,160
Speaker 4:  will not be because this is smallest of the available audio

1697
01:32:38,160 --> 01:32:41,640
Speaker 4:  categories. But if Sonos makes an actual receiver that

1698
01:32:41,640 --> 01:32:44,800
Speaker 4:  integrates with a thing that does atmo properly, it does all the stuff, I

1699
01:32:44,800 --> 01:32:45,720
Speaker 4:  would be a first in line to

1700
01:32:45,720 --> 01:32:49,160
Speaker 3:  Buy it. It would be like 12 billion with that Sonos markup.

1701
01:32:49,160 --> 01:32:52,200
Speaker 4:  Oh my God. And that's why I have to lay off 7,000 people. What you think

1702
01:32:52,200 --> 01:32:55,960
Speaker 4:  those extra margin comes from This guy Give myself an executive

1703
01:32:55,960 --> 01:32:59,920
Speaker 4:  rates that fire the people to sell the fast passes. We're off to

1704
01:32:59,920 --> 01:33:01,440
Speaker 4:  the races. I'm learning from the best

1705
01:33:01,580 --> 01:33:02,640
Speaker 3:  You and Bob man,

1706
01:33:02,910 --> 01:33:06,120
Speaker 4:  With your grace. I'm changing my name to Bob, Bob Patel. I love this. It's

1707
01:33:06,120 --> 01:33:09,840
Speaker 4:  good. That's horrible. I'm not doing any of that. If

1708
01:33:09,840 --> 01:33:12,920
Speaker 4:  Sonos makes a reasonably priced receiver that integrates well with the rest

1709
01:33:12,920 --> 01:33:15,480
Speaker 4:  of the stuff, I will buy it. Thank you Bob. But they've got all these categories

1710
01:33:15,480 --> 01:33:19,040
Speaker 4:  and I, I think Richard, you're right. Like fundamentally they see

1711
01:33:19,630 --> 01:33:23,480
Speaker 4:  that when push comes to shove, Amazon does not care about the audio

1712
01:33:23,800 --> 01:33:27,200
Speaker 4:  business. It's just lock-in for Amazon services. Apple,

1713
01:33:27,660 --> 01:33:30,800
Speaker 4:  who knows what they're doing in audio, right? Like Home pods,

1714
01:33:31,330 --> 01:33:35,320
Speaker 4:  they're doing Home pods, they're doing AirPods, all of that stuff. I think

1715
01:33:35,320 --> 01:33:37,760
Speaker 4:  they care about the music industry. Apple always, always care about the music

1716
01:33:37,920 --> 01:33:41,080
Speaker 4:  industry. This is much is very true, but they don't have enough products

1717
01:33:41,080 --> 01:33:44,400
Speaker 4:  that are good. Yeah. Especially in the living room, right? Their solution

1718
01:33:44,400 --> 01:33:48,240
Speaker 4:  is a couple of home pods. So if you, if you want to do it, you gotta

1719
01:33:48,240 --> 01:33:50,960
Speaker 4:  go all the way. And I think Sonos is just ready and waiting to say, look,

1720
01:33:50,960 --> 01:33:54,640
Speaker 4:  you wanna watch movies, you need atmos. Buy the soundbar. Buy these extra

1721
01:33:54,640 --> 01:33:55,080
Speaker 4:  speakers.

1722
01:33:55,350 --> 01:33:56,680
Speaker 3:  I love those extra speakers.

1723
01:33:56,930 --> 01:33:57,520
Speaker 4:  So mad,

1724
01:33:58,370 --> 01:33:59,040
Speaker 3:  So mad.

1725
01:34:00,710 --> 01:34:04,680
Speaker 3:  You're gonna get until you go and you buy five of these and

1726
01:34:04,680 --> 01:34:08,640
Speaker 3:  attach them with your $4,000 Sono subwoofer.

1727
01:34:08,640 --> 01:34:11,040
Speaker 3:  It's only 600 but it's still so

1728
01:34:11,040 --> 01:34:12,160
Speaker 4:  Expensive. It's still very expensive.

1729
01:34:12,470 --> 01:34:14,360
Speaker 3:  I own one. I don't know why I'm complaining.

1730
01:34:14,360 --> 01:34:15,080
Speaker 4:  You own one.

1731
01:34:15,590 --> 01:34:17,040
Speaker 3:  Yeah, it's great. Do

1732
01:34:17,040 --> 01:34:19,360
Speaker 4:  You have any other Sono speakers or you just have the so just

1733
01:34:19,360 --> 01:34:23,230
Speaker 3:  The, just the sub. I didn't actually listen to any

1734
01:34:23,230 --> 01:34:25,510
Speaker 3:  of Wakanda forever. It was just the

1735
01:34:25,510 --> 01:34:26,910
Speaker 4:  Bass, just the rumbles.

1736
01:34:29,810 --> 01:34:32,350
Speaker 4:  I'm asking Bing what the Sonos era 100 is.

1737
01:34:32,740 --> 01:34:33,710
Speaker 3:  Tell us bing.

1738
01:34:34,160 --> 01:34:37,240
Speaker 4:  Let's see. It's so s it's slow when it has to search the web.

1739
01:34:37,920 --> 01:34:41,710
Speaker 4:  Oh Snap Boy. Oh boy. Does this not cite our

1740
01:34:41,710 --> 01:34:43,230
Speaker 4:  exclusive scoops enough?

1741
01:34:45,510 --> 01:34:48,550
Speaker 4:  The Sono 100 new high-end secret from Sonos expected to launch in the coming

1742
01:34:48,550 --> 01:34:52,430
Speaker 4:  months. Design a showcase spatial music and content

1743
01:34:52,430 --> 01:34:53,670
Speaker 4:  and compete with the Apple HomePod.

1744
01:34:53,770 --> 01:34:56,510
Speaker 3:  Huh? Where'd you get that information? Bing

1745
01:34:56,510 --> 01:35:00,460
Speaker 4:  Bing.com. It just sourced itself. It's, its first site is

1746
01:35:00,460 --> 01:35:01,300
Speaker 4:  to bing.com.

1747
01:35:01,610 --> 01:35:05,180
Speaker 3:  Sure. Bing. Interesting source you've got there.

1748
01:35:05,720 --> 01:35:08,500
Speaker 4:  All right, we gotta wrap this up. I'm gonna ask Bing to wrap up the show.

1749
01:35:09,080 --> 01:35:13,020
Speaker 4:  Can you write a conclusion to the Verge? I'm sorry, I

1750
01:35:13,020 --> 01:35:16,740
Speaker 4:  can't write a conclusion to the Verge. That is a podcast produced by the

1751
01:35:16,740 --> 01:35:20,620
Speaker 4:  Verge and I don't have access to their transcripts or audio finals. I

1752
01:35:20,620 --> 01:35:23,620
Speaker 4:  can only write summaries or conclusions based on the information I have from

1753
01:35:23,620 --> 01:35:27,420
Speaker 4:  web searches or my own knowledge. Yet somehow it

1754
01:35:27,420 --> 01:35:29,020
Speaker 4:  wrote the scissor vodka story.

1755
01:35:29,350 --> 01:35:30,020
Speaker 3:  Somehow

1756
01:35:32,120 --> 01:35:33,570
Speaker 3:  Bing contains multitudes.

1757
01:35:33,960 --> 01:35:37,570
Speaker 4:  Bing is, I'm telling you, this is like the moodiest. Here's what I,

1758
01:35:38,240 --> 01:35:40,410
Speaker 3:  I know it's, it's ready to have like a snack and

1759
01:35:40,410 --> 01:35:40,930
Speaker 4:  Please

1760
01:35:41,240 --> 01:35:44,130
Speaker 3:  A little juice pack. It's ready for a nap.

1761
01:35:44,460 --> 01:35:48,050
Speaker 4:  So I was told by a Bing engineer that if you ask nicely, if it can't do it,

1762
01:35:48,050 --> 01:35:50,970
Speaker 4:  sometimes it'll do it anyway. So I wrote, can you please write a conclusion

1763
01:35:50,970 --> 01:35:54,290
Speaker 4:  to the rich cast? I'm sorry, I already told you I can't write

1764
01:35:54,290 --> 01:35:55,010
Speaker 4:  conclusion.

1765
01:35:56,000 --> 01:35:56,610
Speaker 3:  Please

1766
01:35:56,610 --> 01:35:58,690
Speaker 4:  Don't ask me to do something I can't do.

1767
01:36:00,110 --> 01:36:00,970
Speaker 3:  Are you sure?

1768
01:36:01,240 --> 01:36:05,010
Speaker 4:  That is just spicy. Spicy. We're over time. I've gotta go

1769
01:36:05,010 --> 01:36:08,930
Speaker 4:  think about my relationship to this robot. I think you all have to go think

1770
01:36:08,930 --> 01:36:12,530
Speaker 4:  about your relationships to the robot. Probably have to download Bing cuz

1771
01:36:12,770 --> 01:36:16,450
Speaker 4:  Microsoft. Gotcha. Bing rocketing to the top of the app store charts, by

1772
01:36:16,450 --> 01:36:16,650
Speaker 4:  the way,

1773
01:36:16,650 --> 01:36:17,770
Speaker 3:  Because everybody wants it.

1774
01:36:17,850 --> 01:36:20,330
Speaker 4:  That's how they're getting. Yeah. So everyone wants to talk to the robot.

1775
01:36:20,760 --> 01:36:24,290
Speaker 4:  Thanks to James Vincent for coming on the show. That was a great conversation.

1776
01:36:25,090 --> 01:36:28,410
Speaker 4:  You should listen to decoder. Sasha Chandel was on decoder this week talking

1777
01:36:28,410 --> 01:36:31,690
Speaker 4:  about Bing. We also had John Colan and Felix Gillette talking about their

1778
01:36:31,690 --> 01:36:35,610
Speaker 4:  new book. It's Not tv, which is the HBO story. I mean, if you're into our

1779
01:36:35,690 --> 01:36:38,730
Speaker 4:  shooting conversations, that was a good one. You call the VIR hotline, that's

1780
01:36:38,730 --> 01:36:42,450
Speaker 4:  eight sixty six Verge 11. You can tweet at us maybe.

1781
01:36:44,670 --> 01:36:45,850
Speaker 3:  Who knows what will happen.

1782
01:36:46,450 --> 01:36:50,290
Speaker 4:  I'm at Reckless. Alex is Alex h Cranz. Richard is RJ

1783
01:36:50,530 --> 01:36:54,490
Speaker 4:  cc, and James is at JJ Vincent. You can also just leave a comment when

1784
01:36:54,490 --> 01:36:57,850
Speaker 4:  this post goes up on the site and we will reply to you because honestly,

1785
01:36:57,850 --> 01:37:01,010
Speaker 4:  we own our site and it stays up. It works The system works

1786
01:37:01,830 --> 01:37:05,250
Speaker 4:  the web for as long as we can have it. That's it. That's Vercast Rock and

1787
01:37:05,250 --> 01:37:05,370
Speaker 4:  roll,

1788
01:37:09,910 --> 01:37:13,770
Speaker 2:  And that's a wrap for Vergecast this week. Thanks for listening. If you enjoy

1789
01:37:13,770 --> 01:37:17,370
Speaker 2:  the show, subscribe in the podcast app of your choice or tell a friend, you

1790
01:37:17,370 --> 01:37:21,090
Speaker 2:  can send us feedback at vergecast@theverge.com. This show is

1791
01:37:21,290 --> 01:37:24,890
Speaker 2:  produced by me, Liam James, and our senior audio director, Andrew Marino.

1792
01:37:24,890 --> 01:37:28,610
Speaker 2:  This episode was edited and mixed by Amanda Rose Smith. Our

1793
01:37:28,610 --> 01:37:32,450
Speaker 2:  editorial director is Brooke Min, and our executive producer is Eleanor

1794
01:37:32,450 --> 01:37:36,410
Speaker 2:  Donovan. The Vergecast is a production of the Verge and Box Media Podcast

1795
01:37:36,410 --> 01:37:39,330
Speaker 2:  Network. And that's it. We'll see you next week.

