1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 37c144d4-4928-4c77-bf35-2b618f211b6d
Status: Done
Stage: Done
Title: Amazon, Google, and crypto are on trial
Audio URL: https://jfe93e.s3.amazonaws.com/9031817360811009889/-1995165788160250833/s93290-US-4277s-1696404857.mp3
Description: Today on the flagship podcast of The Sherman Antitrust Act of 1890: 
01:43 - The Verge’s David Pierce chats with policy editor Adi Robertson and reporter Makena Kelly about US v. Google, and what we’ve learned so far. They also talk about the FTC’s lawsuit against Amazon, which could be the next big tech trial. 

US v. Google antitrust trial: updates 

Amazon reportedly used a secret algorithm to jack up prices 

Satya Nadella tells a court that Bing is worse than Google — and Apple could fix it

Why the US is suing Amazon


28:46 - Later, senior correspondent Liz Lopatto joins the show to preview the trial of Sam Bankman-Fried, the former CEO of FTX.
FTX’s Sam Bankman-Fried is on trial for fraud and conspiracy

52:36 - Keep listening for this week’s Vergecast hotline question with Alex Cranz.
Email us at vergecast@theverge.com or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Enabled (7 ads detected)

2
00:00:02,630 --> 00:00:03,120
Speaker 1:  Welcome

3
00:00:03,120 --> 00:00:06,600
Speaker 2:  To The Vergecast at the flagship podcast of the Sherman Antitrust Act of

4
00:00:06,760 --> 00:00:10,440
Speaker 2:  1890. I'm your friend David Pierce, and I am currently in the hallway outside

5
00:00:10,440 --> 00:00:14,240
Speaker 2:  of Courtroom 10 at the e Barrett Prettyman United States Courthouse

6
00:00:14,460 --> 00:00:18,160
Speaker 2:  in Washington DC Inside Courtroom 10 is where U S V Google,

7
00:00:18,660 --> 00:00:22,200
Speaker 2:  one of the most important tech trials in the last two decades and probably

8
00:00:22,200 --> 00:00:25,560
Speaker 2:  the biggest Antitrust trial since the Microsoft trial in the late nineties

9
00:00:25,860 --> 00:00:29,240
Speaker 2:  is currently going on. I'm here in the building today because Satya Nadella,

10
00:00:29,340 --> 00:00:32,720
Speaker 2:  the C E O of Microsoft is taking the stand to talk about search engines,

11
00:00:33,030 --> 00:00:36,960
Speaker 2:  Bing ai, apple Chat, G P T, and who

12
00:00:36,960 --> 00:00:40,240
Speaker 2:  knows what else. There's a lot to talk to that guy about. This trial has

13
00:00:40,240 --> 00:00:44,200
Speaker 2:  been weird and complex and important and today should be more of the

14
00:00:44,200 --> 00:00:47,800
Speaker 2:  same and that actually is a big part of what we're gonna talk about on the

15
00:00:47,800 --> 00:00:51,480
Speaker 2:  show today. Yes, there are tons of gadgets coming out and lots of news to

16
00:00:51,480 --> 00:00:54,440
Speaker 2:  cover and we're gonna get to all of that, don't you worry. But we also have

17
00:00:54,440 --> 00:00:58,120
Speaker 2:  three very different lawsuits happening that could all change the way the

18
00:00:58,120 --> 00:01:01,640
Speaker 2:  tech industry works. So we're gonna talk about U S V, Google And, what we've

19
00:01:01,640 --> 00:01:04,880
Speaker 2:  learned so far about the future of search. We're also gonna talk about the

20
00:01:05,270 --> 00:01:09,120
Speaker 2:  FTCs lawsuit against Amazon, which could be the next big tech trial. And

21
00:01:09,120 --> 00:01:12,840
Speaker 2:  we're gonna talk about the trial of Sam Bankman free, the former c e O of

22
00:01:12,920 --> 00:01:16,800
Speaker 2:  FTX and for a long time the golden bully of the whole crypto world. And

23
00:01:16,800 --> 00:01:20,360
Speaker 2:  now he's on trial in New York. And in some ways, honestly, it feels like

24
00:01:20,380 --> 00:01:24,040
Speaker 2:  the whole crypto industry is on trial with him. So there's a lot to dig into

25
00:01:24,040 --> 00:01:27,960
Speaker 2:  there as well. All that is coming in just a sec, but the proceedings here

26
00:01:28,020 --> 00:01:30,160
Speaker 2:  are just about to start. And if there's one thing I've learned about the

27
00:01:30,160 --> 00:01:34,080
Speaker 2:  US District Court these last few weeks, it's that they are sticklers for

28
00:01:34,080 --> 00:01:37,520
Speaker 2:  punctuality that, and they never seem to be able to get the screens in the

29
00:01:37,520 --> 00:01:41,280
Speaker 2:  courtroom to work. But I digress, gotta run. This is The Vergecast. See you

30
00:01:41,280 --> 00:01:41,560
Speaker 2:  in a sec.

31
00:03:06,650 --> 00:03:10,500
Speaker 2:  Welcome back. All right, I'm home. Satya na della's testimony is

32
00:03:10,500 --> 00:03:14,420
Speaker 2:  over. He said some really wild stuff about why Bing can't compete

33
00:03:14,420 --> 00:03:18,340
Speaker 2:  with Google and why it's kind of Apple's fault. It was a lot and I have

34
00:03:18,340 --> 00:03:22,100
Speaker 2:  a lot of thoughts. So actually let's just start there. Today, like I mentioned,

35
00:03:22,120 --> 00:03:26,020
Speaker 2:  we have two big Antitrust trials in progress now. One

36
00:03:26,020 --> 00:03:29,220
Speaker 2:  at the very beginning of the process, which is the government's case against

37
00:03:29,360 --> 00:03:33,180
Speaker 2:  Amazon and one very much in the middle. US v Google.

38
00:03:33,470 --> 00:03:37,140
Speaker 2:  These two cases are very different in some ways, but I think they also have

39
00:03:37,340 --> 00:03:41,180
Speaker 2:  a lot in common and the combination of them is going to tell us a

40
00:03:41,180 --> 00:03:44,740
Speaker 2:  lot about the future of the tech industry. So I called up the verges, Addie

41
00:03:44,740 --> 00:03:48,220
Speaker 2:  Robertson and Makena Kelly to help me dig into the differences and

42
00:03:48,220 --> 00:03:52,020
Speaker 2:  similarities and where we go from here. Addie, hello. Hi

43
00:03:52,480 --> 00:03:55,620
Speaker 2:  Makena. Hello. Hi. So, okay, we have

44
00:03:55,890 --> 00:03:59,620
Speaker 2:  basically two big trials to talk about in like

45
00:03:59,620 --> 00:04:02,900
Speaker 2:  very different versions of the process and I want to talk about the ways

46
00:04:02,920 --> 00:04:06,020
Speaker 2:  in which they are the same, but let's just sort of catch up on both of them

47
00:04:06,230 --> 00:04:09,620
Speaker 2:  first. And let's start with U US v Google, because I've been in the courtroom

48
00:04:09,660 --> 00:04:11,860
Speaker 2:  a bunch and Addie and I have been talking about this nonstop for like two

49
00:04:11,860 --> 00:04:15,740
Speaker 2:  weeks. So it is like deep in my mind. Addie, where are we in this trial

50
00:04:15,870 --> 00:04:18,420
Speaker 2:  right now? Like what's, what's your sense? We've talked a bunch about kind

51
00:04:18,420 --> 00:04:22,060
Speaker 2:  of the stakes of the search engine and like what it means to be a

52
00:04:22,060 --> 00:04:25,900
Speaker 2:  default. We're now, what, three weeks in almost four

53
00:04:25,900 --> 00:04:27,260
Speaker 2:  weeks in? Where do you feel like we are

54
00:04:27,680 --> 00:04:30,900
Speaker 5:  So pragmatically in the course of this trial? We're at the part where the

55
00:04:30,900 --> 00:04:34,580
Speaker 5:  justice department is getting close to having made its

56
00:04:34,780 --> 00:04:38,260
Speaker 5:  argument for why Google is an unlawful monopoly, which gives us kind of a

57
00:04:38,260 --> 00:04:42,060
Speaker 5:  skewed view of it that right now we are hearing all of the bad stuff

58
00:04:42,060 --> 00:04:45,860
Speaker 5:  about Google and after this there's going to be some state's attorney generals

59
00:04:45,860 --> 00:04:49,740
Speaker 5:  making their case for why it's ad business is also

60
00:04:49,740 --> 00:04:53,700
Speaker 5:  a monopoly and then we're going to get Google's rebuttal. And I think that's

61
00:04:53,700 --> 00:04:57,620
Speaker 5:  going to probably bring out some details that cast the

62
00:04:57,620 --> 00:04:58,700
Speaker 5:  current case in a new light.

63
00:04:59,890 --> 00:05:03,160
Speaker 2:  Right? Yeah. I kind of don't care about the advertising part of this is that

64
00:05:03,160 --> 00:05:05,840
Speaker 2:  okay, am I allowed to just not be interested in the advertising piece of

65
00:05:05,840 --> 00:05:08,400
Speaker 2:  this case? I get that it's relevant, I just cannot make myself care about

66
00:05:08,400 --> 00:05:08,960
Speaker 2:  it. I

67
00:05:08,960 --> 00:05:12,400
Speaker 5:  Think. Yeah, well in one sense this is all about ads because ads is how search

68
00:05:12,450 --> 00:05:16,280
Speaker 5:  makes money and ads is also if you're going to treat this as

69
00:05:16,280 --> 00:05:20,040
Speaker 5:  their consumers and they are harmed per maybe through raised

70
00:05:20,040 --> 00:05:23,960
Speaker 5:  prices. This is where you get the prices. But it's a lot of

71
00:05:23,960 --> 00:05:25,200
Speaker 5:  it is I think less juicy.

72
00:05:25,430 --> 00:05:29,280
Speaker 2:  Yeah. And so to your point about the, the sort of side of it that we've

73
00:05:29,280 --> 00:05:33,200
Speaker 2:  seen so far, what's your sense of how much of a preview of Google's argument

74
00:05:33,210 --> 00:05:36,520
Speaker 2:  we've actually gotten? Because you, you're right that Google has spent most

75
00:05:36,520 --> 00:05:40,400
Speaker 2:  of its time responding to different allegations from the D O J and

76
00:05:40,430 --> 00:05:43,920
Speaker 2:  John Schmidt line. Google's lead counsel is like spectacularly good at his

77
00:05:43,920 --> 00:05:47,280
Speaker 2:  job and has done a very good job of like being mad at

78
00:05:47,430 --> 00:05:51,200
Speaker 2:  various people for lots of reasons. But Google's defense always

79
00:05:51,200 --> 00:05:54,880
Speaker 2:  seemed to be You know Google is very good and that's not

80
00:05:54,880 --> 00:05:58,840
Speaker 2:  illegal and that's definitely been the case so far. Do you

81
00:05:58,840 --> 00:06:02,200
Speaker 2:  think there's gonna be sort of a, a different turn once Google actually starts

82
00:06:02,200 --> 00:06:02,960
Speaker 2:  to take the stand here?

83
00:06:03,540 --> 00:06:06,840
Speaker 5:  It seems like what we're probably going to get is more people testifying

84
00:06:06,900 --> 00:06:10,760
Speaker 5:  in more detail about how Google is good. And the

85
00:06:10,760 --> 00:06:14,640
Speaker 5:  flip side of this is how being does the same things in Google's

86
00:06:14,640 --> 00:06:18,520
Speaker 5:  estimation as Google, but Bing is bad and therefore does not

87
00:06:18,520 --> 00:06:18,960
Speaker 5:  succeed.

88
00:06:19,150 --> 00:06:23,040
Speaker 2:  Yeah. Being, being bad is like we've been saying the the crux of this entire

89
00:06:23,070 --> 00:06:23,360
Speaker 2:  case.

90
00:06:23,780 --> 00:06:27,120
Speaker 5:  It also seems like this is maybe when Google tries to poke holes in some

91
00:06:27,120 --> 00:06:30,480
Speaker 5:  of the more sort of embarrassing things that the Justice Department has brought

92
00:06:30,480 --> 00:06:31,440
Speaker 5:  up. What's

93
00:06:31,440 --> 00:06:35,200
Speaker 2:  Your sense of how the d o j's side of this is going? I was

94
00:06:35,220 --> 00:06:39,040
Speaker 2:  in court on Monday for Satya Nadella and before they got to

95
00:06:39,050 --> 00:06:42,680
Speaker 2:  Satya they spent a bunch of time on scheduling stuff and it came up a couple

96
00:06:42,680 --> 00:06:46,560
Speaker 2:  of times that Google's stance on how the D O J

97
00:06:46,560 --> 00:06:50,480
Speaker 2:  is doing is that the D O J is taking a long time not

98
00:06:50,480 --> 00:06:54,280
Speaker 2:  moving its case forward and just sort of mucking around

99
00:06:54,430 --> 00:06:57,920
Speaker 2:  without actually proving its point. Of course Google is going to say that

100
00:06:57,980 --> 00:07:01,880
Speaker 2:  loudly and on the record as many times as it can. But what's your sense now

101
00:07:01,960 --> 00:07:05,760
Speaker 2:  a few weeks in, does it feel like the D O J is doing a good job

102
00:07:05,760 --> 00:07:07,640
Speaker 2:  of making the case it's trying to make Yeah,

103
00:07:07,640 --> 00:07:11,360
Speaker 5:  Google's case is sort of just that the D O J is wasting a bunch of time throwing

104
00:07:11,360 --> 00:07:15,120
Speaker 5:  Google's dirty laundry out. Right? But it's also not necessarily

105
00:07:15,130 --> 00:07:18,840
Speaker 5:  clear to me that this case is not partly about Google's dirty laundry

106
00:07:19,100 --> 00:07:22,720
Speaker 5:  and that judge Meta is not interested in potentially

107
00:07:22,720 --> 00:07:26,520
Speaker 5:  embarrassing things that Google executives have said. But it's also, I think

108
00:07:26,870 --> 00:07:30,600
Speaker 5:  it's often pretty hard to tell how judges are going to rule and

109
00:07:31,380 --> 00:07:35,320
Speaker 5:  you should probably not read too much into them. And I also, I don't think

110
00:07:35,320 --> 00:07:39,200
Speaker 5:  that Meta has said a lot of incredibly pointed things.

111
00:07:39,560 --> 00:07:42,800
Speaker 5:  Hmm. He's asked questions but I think it's a little bit hard to tell and

112
00:07:43,400 --> 00:07:46,800
Speaker 5:  there was a hot mic moment where he was talking about how

113
00:07:47,400 --> 00:07:50,800
Speaker 5:  frustrating this all is with another judge because it's so complicated and

114
00:07:50,800 --> 00:07:53,040
Speaker 5:  there's not like a, there's not d n a evidence.

115
00:07:53,260 --> 00:07:54,640
Speaker 2:  Oh, interesting. I didn't know that.

116
00:07:54,830 --> 00:07:57,880
Speaker 5:  That was not his words, that was the, the other judge I believe. But it,

117
00:07:57,880 --> 00:08:01,600
Speaker 5:  it seems like he's a little bit frustrated with a lot of this case,

118
00:08:01,820 --> 00:08:04,640
Speaker 5:  but it's hard for me to tell how that translates into a ruling. Do you think

119
00:08:04,640 --> 00:08:08,600
Speaker 2:  That's because of the way the case is going or because of the actual sort

120
00:08:08,600 --> 00:08:12,240
Speaker 2:  of stakes of the case? Like we've been talking from the beginning that it's

121
00:08:12,240 --> 00:08:15,720
Speaker 2:  not even necessarily super obvious what the

122
00:08:15,770 --> 00:08:19,360
Speaker 2:  boundaries of the fight are here. Everybody's kind of arguing these

123
00:08:19,360 --> 00:08:22,160
Speaker 2:  nebulous things that are good or bad, right?

124
00:08:22,750 --> 00:08:26,240
Speaker 5:  Yeah, you have to argue, okay, so if there's consumer harm,

125
00:08:26,790 --> 00:08:30,640
Speaker 5:  well who are the consumers? What does harm mean? Is it enough to

126
00:08:30,640 --> 00:08:34,520
Speaker 5:  say that Google just isn't as good as it could be even if it's the best thing

127
00:08:34,520 --> 00:08:38,440
Speaker 5:  on the market or is that unfair? And

128
00:08:38,440 --> 00:08:41,760
Speaker 5:  then there's been this ar this whole sort of meta layer to the trial

129
00:08:42,170 --> 00:08:45,920
Speaker 5:  about how much can be fairly disclosed. And so

130
00:08:46,010 --> 00:08:50,000
Speaker 5:  there have been a lot of arguments about how much of any of this

131
00:08:50,100 --> 00:08:54,080
Speaker 5:  is vital to the DOJs argument. And I think that has been its

132
00:08:54,080 --> 00:08:54,560
Speaker 5:  own source of

133
00:08:54,760 --> 00:08:55,720
Speaker 6:  Frustration for a lot of people.

134
00:08:56,230 --> 00:08:58,800
Speaker 2:  Very much so. That got better. Hooray. That has

135
00:08:58,800 --> 00:08:59,280
Speaker 6:  Gotten better.

136
00:09:00,180 --> 00:09:04,040
Speaker 2:  Makena. My first question for you, if I'm remembering this correctly,

137
00:09:04,290 --> 00:09:07,360
Speaker 2:  we've been waiting for this case for what feels like the hundreds of thousands

138
00:09:07,360 --> 00:09:10,520
Speaker 2:  of years. What actually made this case happen? Like how did we finally get

139
00:09:10,520 --> 00:09:14,320
Speaker 2:  to the point where we have like words on paper about what the FTC is mad

140
00:09:14,320 --> 00:09:15,240
Speaker 2:  about at Amazon?

141
00:09:15,670 --> 00:09:19,640
Speaker 6:  Yeah, so the investigation into Amazon on Antitrust grounds has

142
00:09:19,880 --> 00:09:23,720
Speaker 6:  actually been going on since the Trump administration. The former FTC

143
00:09:23,720 --> 00:09:27,680
Speaker 6:  chair Joe Simons kicked it off. Of course a lot happened in tech

144
00:09:27,680 --> 00:09:31,440
Speaker 6:  under the Trump administration as well. Cambridge Analytica, a bunch of

145
00:09:31,600 --> 00:09:35,320
Speaker 6:  other FTC stuff with that company. And so instead of pursuing the

146
00:09:35,320 --> 00:09:39,280
Speaker 6:  Amazon case, Simons kind of designated the FTC

147
00:09:39,280 --> 00:09:43,080
Speaker 6:  is very meager resources. They've gotten more in recent years towards

148
00:09:43,080 --> 00:09:47,040
Speaker 6:  like Facebook and Meta. But of course in 2021

149
00:09:47,270 --> 00:09:51,120
Speaker 6:  President Biden nominated Lena Kahn to be the chair of the

150
00:09:51,260 --> 00:09:54,960
Speaker 6:  FTC. Lena Khan of course is famous for

151
00:09:55,240 --> 00:09:59,040
Speaker 6:  a somewhat viral legal paper on

152
00:09:59,220 --> 00:10:00,000
Speaker 6:  Amazon. The

153
00:10:00,000 --> 00:10:00,720
Speaker 2:  Only one ever.

154
00:10:01,000 --> 00:10:04,880
Speaker 6:  Yeah, the only one ever called the Amazon Antitrust Paradox. And

155
00:10:04,880 --> 00:10:08,680
Speaker 6:  in it she kind of talks about basically how common Antitrust,

156
00:10:08,920 --> 00:10:11,760
Speaker 6:  American Antitrust doctrine, the way that we've approach approached Antitrust

157
00:10:11,760 --> 00:10:15,480
Speaker 6:  law for decades doesn't really apply too well to big tech

158
00:10:15,720 --> 00:10:19,520
Speaker 6:  companies. So Con gets into office, she's confirmed and then she

159
00:10:19,520 --> 00:10:23,480
Speaker 6:  designates You know more of the FTC resources to that case. And so it's been

160
00:10:23,740 --> 00:10:27,600
Speaker 6:  You know probably about five years that the company has been under investigation

161
00:10:28,060 --> 00:10:29,440
Speaker 6:  for anti-competitive behavior.

162
00:10:30,100 --> 00:10:32,840
Speaker 2:  The thing that strikes me about this case, and I want you to kind of lay

163
00:10:32,860 --> 00:10:36,440
Speaker 2:  out the basics of what the FTC actually thinks that Amazon is doing wrong,

164
00:10:36,440 --> 00:10:40,280
Speaker 2:  but one of the things that it strikes me big picture is that, like you said,

165
00:10:40,590 --> 00:10:44,280
Speaker 2:  lean Conn knows better than most that it's very hard to bring an

166
00:10:44,280 --> 00:10:47,800
Speaker 2:  Antitrust case against a company like Amazon, right? We, we talk a lot about

167
00:10:48,140 --> 00:10:51,520
Speaker 2:  how do you prove consumer harm. We typically, these things are like

168
00:10:51,880 --> 00:10:55,680
Speaker 2:  monopoly plus raise prices equals bad is like the legal framework

169
00:10:55,680 --> 00:10:59,480
Speaker 2:  for a lot of this stuff. And that's very hard to do when products get

170
00:10:59,480 --> 00:11:03,240
Speaker 2:  cheaper and when in many cases they're free. Like Google search,

171
00:11:03,590 --> 00:11:07,200
Speaker 2:  what it seems like they tried very, very, very hard to do in this case is

172
00:11:07,200 --> 00:11:11,000
Speaker 2:  make a case about how Amazon has raised prices. And part of me

173
00:11:11,000 --> 00:11:14,720
Speaker 2:  wonders if that case, which is very different from like the big sort of heady

174
00:11:14,920 --> 00:11:17,560
Speaker 2:  argument about Amazon being too powerful that Lena Kahan was making a bunch

175
00:11:17,560 --> 00:11:20,760
Speaker 2:  of years ago. Now we're in this place where she's like, I get the sense she

176
00:11:20,760 --> 00:11:24,040
Speaker 2:  tasked a bunch of people with saying we have to make an argument about

177
00:11:24,420 --> 00:11:27,360
Speaker 2:  Amazon being bad for customers because things are getting more expensive.

178
00:11:27,740 --> 00:11:30,360
Speaker 2:  Is that a fair way to look at what's happening here?

179
00:11:30,870 --> 00:11:34,480
Speaker 6:  Yeah, I, I mean that's how the US Antitrust

180
00:11:34,480 --> 00:11:38,320
Speaker 6:  enforcers have long approached You know Antitrust law is whether or not

181
00:11:38,640 --> 00:11:42,600
Speaker 6:  a company, the BA behavior that it's engaging in is driving up prices,

182
00:11:42,920 --> 00:11:46,840
Speaker 6:  lowering them. And I'm sure people on this podcast have

183
00:11:46,840 --> 00:11:50,320
Speaker 6:  heard You know for so many years the consumer welfare standard. So

184
00:11:50,860 --> 00:11:54,360
Speaker 6:  she has been losing a lot. We've talked about

185
00:11:54,660 --> 00:11:57,840
Speaker 6:  the Microsoft Activision merger,

186
00:11:58,860 --> 00:12:02,720
Speaker 6:  not so hot there. The FTC didn't win of course like Meta

187
00:12:02,900 --> 00:12:06,880
Speaker 6:  and the within acquisition they didn't really win there. And so

188
00:12:06,880 --> 00:12:10,760
Speaker 6:  with a case so monumental like this Amazon case, the

189
00:12:10,880 --> 00:12:14,360
Speaker 6:  FTC really needs to show that it can take these companies on.

190
00:12:14,880 --> 00:12:18,320
Speaker 6:  'cause for the first You know couple years of her tenure, it hasn't quite

191
00:12:18,320 --> 00:12:22,120
Speaker 6:  been working out. And so trying to make those arguments You know about whether

192
00:12:22,500 --> 00:12:26,360
Speaker 6:  Amazon is raising prices is might just be the only winning argument

193
00:12:26,590 --> 00:12:30,280
Speaker 6:  that the FTC can find under current Antitrust doctrine.

194
00:12:30,690 --> 00:12:33,320
Speaker 2:  Right. Yeah. So walk me through that case a little bit. Like what, what are

195
00:12:33,320 --> 00:12:37,120
Speaker 2:  the sort of specific accusations that the government is making against Amazon?

196
00:12:37,470 --> 00:12:41,400
Speaker 6:  Sure. So I don't want to make it seem like the F D

197
00:12:41,440 --> 00:12:45,200
Speaker 6:  C isn't looking at structural parts of Amazon as well. 'cause

198
00:12:45,200 --> 00:12:49,160
Speaker 6:  really the heart of the case is saying that Amazon for as long as it's

199
00:12:49,160 --> 00:12:52,880
Speaker 6:  been around, has been making sizable investments in its company, creating

200
00:12:53,020 --> 00:12:56,800
Speaker 6:  Amazon, Prime Prime video. It's basically a fashion

201
00:12:57,160 --> 00:13:00,960
Speaker 6:  designer has logistics and fulfillment. Amazon is a behemoth

202
00:13:01,220 --> 00:13:04,880
Speaker 6:  and by reinvesting all of this You know would be profit back into the company.

203
00:13:05,720 --> 00:13:09,360
Speaker 6:  It's been able to grow immensely and have a lot of control

204
00:13:09,750 --> 00:13:13,480
Speaker 6:  over individual sellers and then also being very

205
00:13:13,480 --> 00:13:16,960
Speaker 6:  competitive against other You know big box stores like Walmart,

206
00:13:17,580 --> 00:13:21,440
Speaker 6:  target and other companies like that. And so

207
00:13:21,590 --> 00:13:25,360
Speaker 6:  because of that structural You know power that Amazon has

208
00:13:25,440 --> 00:13:28,640
Speaker 6:  created over decades, the FTC is making the argument

209
00:13:29,190 --> 00:13:32,760
Speaker 6:  that it has a lot of control over requesting. You know

210
00:13:33,230 --> 00:13:37,200
Speaker 6:  that some third party sellers put their products on Amazon

211
00:13:37,260 --> 00:13:41,240
Speaker 6:  at a significantly lower price than they would on other platforms. Also

212
00:13:41,350 --> 00:13:45,240
Speaker 6:  requiring, basically requiring third party sellers to buy

213
00:13:45,420 --> 00:13:49,160
Speaker 6:  ads on Amazon's You know search When you go into type of product

214
00:13:49,340 --> 00:13:52,920
Speaker 6:  in order for that product to even be seen while Amazon is selling its own

215
00:13:52,920 --> 00:13:56,640
Speaker 6:  You know Amazon Basics products, which are competitors, it has that control

216
00:13:56,990 --> 00:14:00,640
Speaker 6:  over the infrastructure in order to create a better system for its own

217
00:14:00,640 --> 00:14:04,600
Speaker 6:  products and services compared to those of its competitors.

218
00:14:04,730 --> 00:14:08,400
Speaker 6:  Which yeah, sounds a lot like the case Addie is talking about in a little

219
00:14:08,400 --> 00:14:08,600
Speaker 6:  bit.

220
00:14:08,950 --> 00:14:11,960
Speaker 2:  Yeah, I mean that's the thing, right, that we're, we're in this weird place

221
00:14:11,970 --> 00:14:15,840
Speaker 2:  where just the overarching question is like, are these companies too powerful?

222
00:14:15,860 --> 00:14:19,800
Speaker 2:  And it feels like the Amazon version of that cycle, at least the way

223
00:14:19,800 --> 00:14:23,560
Speaker 2:  the government describes it, is kind of unusually tight and succinct

224
00:14:23,560 --> 00:14:26,720
Speaker 2:  where it's like I I you you can actually explain the whole cycle of how things

225
00:14:26,720 --> 00:14:30,240
Speaker 2:  get more expensive because of Amazon. I don't know whether that's true. Amazon

226
00:14:30,240 --> 00:14:34,080
Speaker 2:  obviously like Vociferously denies that it is responsible for prices

227
00:14:34,080 --> 00:14:36,960
Speaker 2:  going up all over the internet. But it's like the, the government sort of

228
00:14:36,960 --> 00:14:40,240
Speaker 2:  lays out this case where it's like, okay, Amazon forces

229
00:14:40,510 --> 00:14:44,320
Speaker 2:  sellers to use the fulfilled by Amazon things. Those

230
00:14:44,320 --> 00:14:48,280
Speaker 2:  fees are super high and also Amazon prevents them from offering cheaper prices

231
00:14:48,680 --> 00:14:51,690
Speaker 2:  anywhere else because it, it has these mechanisms to figure, figure out what

232
00:14:51,690 --> 00:14:54,200
Speaker 2:  you're pricing around the internet and then they either like bury you in

233
00:14:54,200 --> 00:14:57,400
Speaker 2:  search results or they get rid of the buy box. I've like learned so much

234
00:14:57,400 --> 00:15:01,160
Speaker 2:  about how the Amazon website works through this case, which is really fascinating.

235
00:15:01,500 --> 00:15:05,320
Speaker 2:  But Amazon has all these little knobs it can turn to just wreck your business

236
00:15:05,320 --> 00:15:09,200
Speaker 2:  on Amazon if it feels like it. And so what you do is you

237
00:15:09,200 --> 00:15:12,800
Speaker 2:  raise all your other prices elsewhere in order to not

238
00:15:13,260 --> 00:15:17,000
Speaker 2:  run afoul of Amazon's increasingly expensive process. And

239
00:15:17,350 --> 00:15:21,160
Speaker 2:  that is like an actual case of consumer harm. Like if that's true,

240
00:15:21,590 --> 00:15:25,520
Speaker 2:  that is the most like straightforward, this is bad for

241
00:15:25,800 --> 00:15:28,760
Speaker 2:  consumers anti-trust argument against a tech company. I feel like I've heard

242
00:15:28,760 --> 00:15:29,440
Speaker 2:  in a long time,

243
00:15:29,750 --> 00:15:33,320
Speaker 6:  Yeah, there were a lot of figures in the lawsuit that were

244
00:15:33,880 --> 00:15:37,680
Speaker 6:  redacted that I would so much I would have loved to see. Yes,

245
00:15:37,680 --> 00:15:41,120
Speaker 6:  like the percentage of You know how many people subscribe to Prime,

246
00:15:41,780 --> 00:15:45,720
Speaker 6:  how many people over other websites order stuff

247
00:15:46,190 --> 00:15:50,120
Speaker 6:  through Amazon because of Prime. I think those figures

248
00:15:50,370 --> 00:15:54,360
Speaker 6:  would really, really say a lot and help us to drive that point home

249
00:15:54,700 --> 00:15:57,200
Speaker 6:  if we had them, but of course we don't.

250
00:15:57,880 --> 00:16:01,720
Speaker 2:  Yeah, that complaint was very redacted. Like there was one thing that kept

251
00:16:01,720 --> 00:16:05,440
Speaker 2:  coming up this thing called Project Nessie, which can tell is this like very

252
00:16:05,840 --> 00:16:09,800
Speaker 2:  exciting internal program at Amazon that does something and

253
00:16:09,800 --> 00:16:12,520
Speaker 2:  every time it's about to reveal anything there's just like twofold lines

254
00:16:12,560 --> 00:16:16,200
Speaker 2:  redacted, do we know anything about Project Nessie? What, what is the story

255
00:16:16,200 --> 00:16:16,400
Speaker 2:  here?

256
00:16:16,860 --> 00:16:20,400
Speaker 6:  It is just as elusive as the Lochness monster

257
00:16:20,910 --> 00:16:24,480
Speaker 6:  that it's named after. I have not been able to find too much

258
00:16:24,480 --> 00:16:28,400
Speaker 6:  information on it and I bet You know I hope that when this case, if

259
00:16:28,400 --> 00:16:32,160
Speaker 6:  this case, right, 'cause Amazon could still settle if that will happen, I'm

260
00:16:32,160 --> 00:16:35,720
Speaker 6:  not entirely sure, it's very hard to predict right now, but in a couple of

261
00:16:35,720 --> 00:16:39,080
Speaker 6:  years You know if this case actually goes to court. I'd be really excited

262
00:16:39,080 --> 00:16:42,360
Speaker 6:  to see what else You know comes out of that complaint. Those those pieces

263
00:16:42,360 --> 00:16:46,120
Speaker 6:  of data. More info on Nessie You know and all these things that we haven't

264
00:16:46,120 --> 00:16:49,480
Speaker 6:  really seen but kind of vaguely know about

265
00:16:50,000 --> 00:16:51,200
Speaker 6:  because of You know the text

266
00:16:51,580 --> 00:16:55,240
Speaker 2:  And I'm assuming, if I remember right Addie, the first version of the Google

267
00:16:55,470 --> 00:16:59,440
Speaker 2:  case was super redacted just like the Amazon case was

268
00:16:59,440 --> 00:17:02,120
Speaker 2:  and then we got another version of it that was much less redacted, which

269
00:17:02,120 --> 00:17:05,160
Speaker 2:  is when we learned all the actual information about the case. Am I remembering

270
00:17:05,160 --> 00:17:05,440
Speaker 2:  that right?

271
00:17:05,830 --> 00:17:09,000
Speaker 5:  Yeah, I think that we've gotten, this is kind of typical in a lot of these

272
00:17:09,000 --> 00:17:11,880
Speaker 5:  cases that you'll get very heavily redacted versions and then they slowly

273
00:17:11,940 --> 00:17:13,440
Speaker 5:  get exposed as the trial gets closer.

274
00:17:13,750 --> 00:17:17,480
Speaker 2:  Okay. So we might get Nessie information at some point here in the near future.

275
00:17:18,120 --> 00:17:21,240
Speaker 2:  I just wanna know about Project Nessie, that's all I wanna know in the whole

276
00:17:21,240 --> 00:17:24,200
Speaker 2:  world. I don't care about anything else. Just wanna know what Project Nessie

277
00:17:24,200 --> 00:17:28,000
Speaker 2:  is. If You know, please email meDavid@thevirgin.com. That's all I wanna know.

278
00:17:28,450 --> 00:17:32,400
Speaker 2:  Addie, my, my question for you is like these two cases sort

279
00:17:32,400 --> 00:17:36,120
Speaker 2:  of rhyme to me in the sense that they are like they're happening at

280
00:17:36,120 --> 00:17:39,440
Speaker 2:  roughly at the same time, which is either really interesting or a total coincidence.

281
00:17:39,440 --> 00:17:42,240
Speaker 2:  And I'm curious if you guys see it one way or the other, but it also feels

282
00:17:42,240 --> 00:17:45,560
Speaker 2:  like if you, if you sort of boil it all the way down the question of like

283
00:17:46,020 --> 00:17:49,840
Speaker 2:  is it illegal to be wildly successful? Feels

284
00:17:49,870 --> 00:17:53,560
Speaker 2:  like the question of both of these things And where does being wildly

285
00:17:53,560 --> 00:17:56,280
Speaker 2:  successful in protecting all of that success tip into

286
00:17:56,920 --> 00:18:00,720
Speaker 2:  monopolistic practices? Like do you see similarities between these

287
00:18:00,720 --> 00:18:03,840
Speaker 2:  two cases, Addie, or are they more different than I'm giving them credit

288
00:18:03,840 --> 00:18:04,040
Speaker 2:  for?

289
00:18:04,430 --> 00:18:08,080
Speaker 5:  It's definitely not a coincidence that this kind of aggressive enforcement

290
00:18:08,080 --> 00:18:11,120
Speaker 5:  is happening under the Biden administration, which has nominated people who

291
00:18:11,140 --> 00:18:14,760
Speaker 5:  are very strongly pro being Antitrust

292
00:18:14,760 --> 00:18:18,720
Speaker 5:  watchdogs. So on that side, like the big

293
00:18:18,720 --> 00:18:22,040
Speaker 5:  tech investigations have been going on for years. This is sort of just this

294
00:18:22,040 --> 00:18:25,560
Speaker 5:  finally coming to fruition. On the other hand, I actually think that

295
00:18:25,880 --> 00:18:29,840
Speaker 5:  there are some levels of difference in the case, at least the allegations

296
00:18:30,430 --> 00:18:34,280
Speaker 5:  that Google's case so far, the trial has been all about, look, Google is

297
00:18:34,280 --> 00:18:37,840
Speaker 5:  legitimately good. There are downsides that we haven't gotten into the really

298
00:18:37,840 --> 00:18:40,960
Speaker 5:  the arguments for like privacy, but Google really, it knows what you want.

299
00:18:41,140 --> 00:18:44,880
Speaker 5:  It uses its data to produce a product that's actually

300
00:18:44,910 --> 00:18:48,720
Speaker 5:  genuinely good. The Amazon case, at least from the

301
00:18:48,720 --> 00:18:52,600
Speaker 5:  parts that we've seen, the allegations are basically Amazon's terrible.

302
00:18:53,020 --> 00:18:57,000
Speaker 5:  Amazon forces prices up, it throws ads all

303
00:18:57,000 --> 00:19:00,480
Speaker 5:  over everything and forces sellers to buy them, which is part of the Google

304
00:19:00,480 --> 00:19:03,880
Speaker 5:  case too, but has not really come up as much yet that

305
00:19:04,210 --> 00:19:08,080
Speaker 5:  there are all of these cases where their argument is, look, people

306
00:19:08,080 --> 00:19:11,040
Speaker 5:  don't even necessarily wanna be signed up for Prime as a part of a separate

307
00:19:11,190 --> 00:19:14,960
Speaker 5:  case. They, they're just getting signed up accidentally that

308
00:19:15,020 --> 00:19:18,760
Speaker 5:  it really feels like the argument in the FTC case is that

309
00:19:18,820 --> 00:19:22,800
Speaker 5:  Amazon sucks and there's no alternative. The D

310
00:19:22,840 --> 00:19:26,520
Speaker 5:  O J case against Google, at least so far in court has been Google's really

311
00:19:26,550 --> 00:19:29,840
Speaker 5:  good, but it's bad that no one else can be that good.

312
00:19:30,300 --> 00:19:34,000
Speaker 2:  Makena. Is that your read too? Like do you think the the Amazon is bad case

313
00:19:34,100 --> 00:19:36,680
Speaker 2:  is part of this? I I have gone back and forth on this because on the one

314
00:19:36,680 --> 00:19:39,920
Speaker 2:  hand, yeah, some of the things they're talking about like it's super easy

315
00:19:40,040 --> 00:19:43,840
Speaker 2:  to buy stuff and you get things really fast is like those are good

316
00:19:43,840 --> 00:19:47,000
Speaker 2:  things and, and those are things people like, right? Like lots of people

317
00:19:47,060 --> 00:19:50,480
Speaker 2:  did sign up for Prime on purpose and really fast shipping is one of the things

318
00:19:50,480 --> 00:19:54,120
Speaker 2:  that people really like about Amazon. I do think it's true that the Amazon

319
00:19:54,440 --> 00:19:58,400
Speaker 2:  shopping experience has been on a pretty fast decline for a pretty long time.

320
00:19:58,980 --> 00:20:02,960
Speaker 2:  And I wonder if now is the moment where it's like the,

321
00:20:02,980 --> 00:20:06,960
Speaker 2:  the case is Amazon used to be good and then got really big and has gotten

322
00:20:06,960 --> 00:20:09,480
Speaker 2:  worse for everyone involved and there's nothing you can do about it.

323
00:20:09,880 --> 00:20:12,320
Speaker 5:  I mean, to be clear, people make that case about Google too all the time

324
00:20:12,320 --> 00:20:15,720
Speaker 5:  outside the court fair. Like this isn't necessarily about the reality of

325
00:20:15,720 --> 00:20:19,680
Speaker 5:  the, of the actual platforms right now, but it's sort of the cases that both

326
00:20:19,680 --> 00:20:20,280
Speaker 5:  sides are making.

327
00:20:20,510 --> 00:20:23,880
Speaker 6:  Yeah, I think that's totally fair. I think when it comes to similarities

328
00:20:23,880 --> 00:20:26,840
Speaker 6:  between the two, it really becomes, it really comes down to like the consumer

329
00:20:26,890 --> 00:20:30,760
Speaker 6:  experience and how that feels for the consumer. So when I buy cat

330
00:20:30,760 --> 00:20:34,640
Speaker 6:  food, right, I normally buy my cat food from Amazon, I have to wade

331
00:20:34,640 --> 00:20:38,400
Speaker 6:  through so many listings and often it's not the same seller that I'm

332
00:20:38,400 --> 00:20:41,680
Speaker 6:  buying the same cat food from. And it's really confusing. It's a different

333
00:20:41,680 --> 00:20:45,560
Speaker 6:  price oftentimes it's like it like it sucks but like my

334
00:20:45,560 --> 00:20:48,840
Speaker 6:  cat needs food and I know it's gonna be here in two days 'cause I have Prime,

335
00:20:48,840 --> 00:20:52,560
Speaker 6:  right? So You know you weigh the cons, You know the benefits and the cons

336
00:20:52,560 --> 00:20:56,520
Speaker 6:  over that. And then also You know similarly with Google, it's using

337
00:20:56,520 --> 00:20:59,600
Speaker 6:  that service, using that search bar and how the company

338
00:20:59,960 --> 00:21:03,800
Speaker 6:  controls that search bar. That plays a really key role in

339
00:21:03,800 --> 00:21:04,120
Speaker 6:  the case.

340
00:21:04,750 --> 00:21:08,480
Speaker 2:  Yeah, I, I'm very curious to see, especially in the

341
00:21:08,480 --> 00:21:11,440
Speaker 2:  Amazon case, it doesn't seem like in the Google case we're gonna have the

342
00:21:11,440 --> 00:21:14,920
Speaker 2:  Google has gotten worse argument. It would be interesting if we did,

343
00:21:15,540 --> 00:21:18,040
Speaker 2:  but I it does, it just doesn't seem like we're gonna get there. Google certainly

344
00:21:18,040 --> 00:21:20,560
Speaker 2:  not, is not going to argue that Google is a worse product than it once was.

345
00:21:20,820 --> 00:21:24,760
Speaker 2:  But it does seem like Amazon worked for

346
00:21:24,760 --> 00:21:28,040
Speaker 2:  a long time because it was good and now it's bad and there's nothing you

347
00:21:28,040 --> 00:21:31,960
Speaker 2:  can do about it. It's like that's part of how you win this. Everything is

348
00:21:31,960 --> 00:21:34,960
Speaker 2:  getting worse and more expensive case. Like if you're Lena Khan, you kind

349
00:21:34,960 --> 00:21:35,960
Speaker 2:  of have to make that argument.

350
00:21:36,470 --> 00:21:40,240
Speaker 6:  Yeah, I think that's really the argument that the case

351
00:21:40,850 --> 00:21:44,200
Speaker 6:  looks at the most. And I mean when you look at also like it comes down to

352
00:21:44,200 --> 00:21:48,080
Speaker 6:  like what does the FTC want as well. Now Lenahan has been very

353
00:21:48,150 --> 00:21:51,560
Speaker 6:  like tight-lipped about the exact remedies that they're looking for,

354
00:21:51,940 --> 00:21:55,200
Speaker 6:  but in the press release it says like structural remedy,

355
00:21:55,870 --> 00:21:59,640
Speaker 6:  that is a breakup, right? What gets broken off, what goes

356
00:21:59,640 --> 00:22:03,480
Speaker 6:  where, who buys what? I'm not entirely sure, but it'll be interesting to

357
00:22:03,480 --> 00:22:06,560
Speaker 6:  see You know how that pans out over the next You know months and years.

358
00:22:07,110 --> 00:22:09,600
Speaker 2:  Yeah. Addie do you have a, do you have a theory? If you were gonna break

359
00:22:09,600 --> 00:22:13,000
Speaker 2:  up Amazon, how would you, if you're Lean Con and you're, you have to figure

360
00:22:13,000 --> 00:22:15,560
Speaker 2:  out how to split up that company, what would you do? Well the

361
00:22:15,560 --> 00:22:19,480
Speaker 5:  Really cheap answer is that you split up Amazon the, it's not always called

362
00:22:19,480 --> 00:22:23,360
Speaker 5:  Amazon basics now, but the equivalent of Amazon's white label products,

363
00:22:23,370 --> 00:22:26,880
Speaker 2:  Right? It's many, many, many, many in-house brands that you don't realize

364
00:22:26,900 --> 00:22:28,440
Speaker 2:  are Amazon brands in many cases.

365
00:22:28,690 --> 00:22:31,880
Speaker 5:  Especially because there are specific Antitrust allegations around that.

366
00:22:31,880 --> 00:22:35,280
Speaker 5:  There's the argument that they use all of their consumer data to see what's

367
00:22:35,280 --> 00:22:39,120
Speaker 5:  selling well and then they clone it. I don't know if that's

368
00:22:39,120 --> 00:22:43,040
Speaker 5:  necessarily where the FTC thinks it would be most useful to split

369
00:22:43,040 --> 00:22:45,640
Speaker 5:  up Amazon, but that's just the obvious cleavage point.

370
00:22:45,790 --> 00:22:49,680
Speaker 6:  Yeah. Personally for me, I think the place where it'd be

371
00:22:49,680 --> 00:22:52,680
Speaker 6:  most beneficial for the case to break up Amazon would be the logistics and

372
00:22:52,680 --> 00:22:56,080
Speaker 6:  fulfillment side because that really is what adds that additional

373
00:22:56,080 --> 00:22:59,040
Speaker 6:  competitiveness. Like we're saying that knowing that the product is gonna

374
00:22:59,040 --> 00:23:03,000
Speaker 6:  come in two days, right to you. So instead of like Amazon having You

375
00:23:03,000 --> 00:23:06,840
Speaker 6:  know its own fulfillment services, having to operate with like a U P S or

376
00:23:06,840 --> 00:23:10,720
Speaker 6:  a FedEx more often than not, I think would really, if not, if

377
00:23:10,720 --> 00:23:13,880
Speaker 6:  that's not the only thing that gets broken up, I imagine that would be a

378
00:23:13,880 --> 00:23:17,240
Speaker 6:  really intimate focus of the FTC as well.

379
00:23:17,590 --> 00:23:21,520
Speaker 2:  Yeah. And that would obviously be a huge, huge, huge blow to

380
00:23:21,520 --> 00:23:24,640
Speaker 2:  Amazon. I think realistically you could get rid of the in-house brands and

381
00:23:24,640 --> 00:23:27,120
Speaker 2:  like a bunch of people at Amazon would be like, oh shucks, and they'd all

382
00:23:27,120 --> 00:23:30,240
Speaker 2:  move on. If you split off the logistics side of Amazon, you have like fundamentally

383
00:23:30,240 --> 00:23:34,200
Speaker 2:  changed that company, right? Which I suppose is if you're the FTC

384
00:23:34,340 --> 00:23:38,240
Speaker 2:  the goal. So I I I, it'll be interesting to see how big that swing turns

385
00:23:38,240 --> 00:23:41,640
Speaker 2:  out to be. Last thing before I let you guys go, I, I have been trained over

386
00:23:41,640 --> 00:23:44,680
Speaker 2:  the years that if we're gonna talk about Tech Antitrust, we have to argue

387
00:23:44,680 --> 00:23:48,200
Speaker 2:  about market size because all they argue about is market size. And I've been

388
00:23:48,200 --> 00:23:50,560
Speaker 2:  sitting in the courtroom at Google where everybody is arguing about what

389
00:23:50,600 --> 00:23:54,320
Speaker 2:  a general search engine is and no one seems to know and it's very

390
00:23:54,320 --> 00:23:57,360
Speaker 2:  complicated and there's vertical search engines and there's general search

391
00:23:57,360 --> 00:24:00,200
Speaker 2:  engines and TikTok is neither of those but it's something else and everybody

392
00:24:00,200 --> 00:24:04,160
Speaker 2:  just sort of spins outta control about whether Google just

393
00:24:04,160 --> 00:24:07,240
Speaker 2:  competes with Bing or competes with like every other site that exists on

394
00:24:07,240 --> 00:24:10,040
Speaker 2:  the internet. Amazon I feel like is about to go through exactly the same

395
00:24:10,040 --> 00:24:13,080
Speaker 2:  thing, right? Amazon's case has been, we compete with every store on planet

396
00:24:13,080 --> 00:24:16,160
Speaker 2:  Earth and we're actually like a pretty tiny minority of the retail market.

397
00:24:16,620 --> 00:24:20,160
Speaker 2:  The FTC is gonna have to make a different and much harder case now,

398
00:24:20,330 --> 00:24:21,440
Speaker 2:  right? Yeah.

399
00:24:21,440 --> 00:24:25,200
Speaker 6:  So in the case of Amazon, the FTC basically defines the market

400
00:24:25,300 --> 00:24:27,200
Speaker 6:  as the online marketplace

401
00:24:28,960 --> 00:24:32,880
Speaker 6:  industry, which is a really interesting way to define it, which I think honestly

402
00:24:33,320 --> 00:24:36,680
Speaker 6:  I don't think Amazon would really even like that 'cause it wants you to think

403
00:24:36,680 --> 00:24:40,560
Speaker 6:  that it competes with the big box stores with Target and

404
00:24:40,670 --> 00:24:44,560
Speaker 6:  Walmart and all the Antitrust hearings and all this stuff that we paid attention

405
00:24:44,560 --> 00:24:48,400
Speaker 6:  to over the last couple years. You always have the Amazon reps pointing

406
00:24:48,420 --> 00:24:52,360
Speaker 6:  to You know the way that it arranges products and search to

407
00:24:52,360 --> 00:24:56,080
Speaker 6:  the way that a Walmart or a Target arranges products on a

408
00:24:56,080 --> 00:25:00,040
Speaker 6:  shelf. So in order to define as an online marketplace, I don't

409
00:25:00,040 --> 00:25:02,560
Speaker 6:  think Amazon would be really happy with that. And I imagine they're going

410
00:25:02,560 --> 00:25:06,360
Speaker 6:  to challenge that in court just looking at like the way that it's defined.

411
00:25:06,780 --> 00:25:10,720
Speaker 6:  It really has to do with like online storefronts and I, I imagine that

412
00:25:10,720 --> 00:25:14,040
Speaker 6:  will get kind of shaken out a bit more as time goes on. It seems kind

413
00:25:14,040 --> 00:25:17,400
Speaker 5:  Of co even more complicated because stores like Walmart have gotten more

414
00:25:17,560 --> 00:25:20,400
Speaker 5:  like Amazon, right? That if you go to walmart.com now you can get a bunch

415
00:25:20,400 --> 00:25:22,280
Speaker 5:  of third party storefront store items.

416
00:25:22,780 --> 00:25:25,400
Speaker 2:  But even that well, so this is, this is where it gets really heady for me,

417
00:25:25,400 --> 00:25:29,000
Speaker 2:  right? 'cause I think like if Amazon has its way, the competition is everyone

418
00:25:29,000 --> 00:25:32,200
Speaker 2:  who sells anything in any way anywhere in the world, right? I would argue

419
00:25:32,200 --> 00:25:35,680
Speaker 2:  that is a reach, but also if the FTC has its way, it's like

420
00:25:36,520 --> 00:25:40,400
Speaker 2:  companies that allow other companies to set up storefronts inside of

421
00:25:40,400 --> 00:25:44,240
Speaker 2:  your storefront on the internet. Which is a much, much

422
00:25:44,240 --> 00:25:48,120
Speaker 2:  smaller thing that Amazon and to like a lesser extent Walmart. 'cause

423
00:25:48,120 --> 00:25:51,040
Speaker 2:  Walmart will sell third party stuff, but you can't really have a store on

424
00:25:51,040 --> 00:25:54,240
Speaker 2:  walmart.com in the same way that you can kind of have your own store on

425
00:25:54,240 --> 00:25:58,120
Speaker 2:  amazon.com. So it's like that teeny tiny thing is probably too

426
00:25:58,120 --> 00:26:00,840
Speaker 2:  small because I don't know that like if you're a real person on the internet,

427
00:26:00,840 --> 00:26:04,400
Speaker 2:  you're not thinking like, oh I'm gonna go to the storefront on amazon.com.

428
00:26:04,400 --> 00:26:07,680
Speaker 2:  You're just like shopping for things on Amazon. The answer seems to be, I

429
00:26:07,680 --> 00:26:10,560
Speaker 2:  mean it's somewhere in the middle there, but it does feel like even where

430
00:26:10,950 --> 00:26:14,600
Speaker 2:  like if you go 60 40 on one side or the other, that's gonna end up being

431
00:26:14,600 --> 00:26:15,920
Speaker 2:  really important in this case. Yeah.

432
00:26:15,920 --> 00:26:18,840
Speaker 6:  What are the competitors, 'cause the thing that I'm thinking of is Etsy for

433
00:26:18,840 --> 00:26:22,040
Speaker 6:  example, very small company in comparison like

434
00:26:22,150 --> 00:26:25,160
Speaker 2:  Shopify sort of, but it's, it's a slightly different thing.

435
00:26:25,470 --> 00:26:25,960
Speaker 5:  Alibaba,

436
00:26:26,310 --> 00:26:27,360
Speaker 2:  Alibaba's a good one. Yeah.

437
00:26:27,470 --> 00:26:30,960
Speaker 6:  Instagram is setting up a bunch of like ways to buy products in like

438
00:26:30,960 --> 00:26:34,480
Speaker 6:  storefronts, which I guess are essentially people's accounts now. And then

439
00:26:34,510 --> 00:26:38,320
Speaker 6:  also like TikTok shop maybe. But that's like really, really new.

440
00:26:38,940 --> 00:26:42,600
Speaker 6:  So You know other than like to think about like competitors,

441
00:26:42,670 --> 00:26:46,520
Speaker 6:  it's mostly You know these kind of smaller companies compared

442
00:26:46,520 --> 00:26:50,360
Speaker 6:  to like, I guess like meta stuff and like TikTok stuff, which is really still

443
00:26:50,430 --> 00:26:54,080
Speaker 6:  very nascent and not people I'm not going to Instagram to buy things.

444
00:26:54,860 --> 00:26:57,680
Speaker 5:  And also then you add the whole distribution logistics chain that you mentioned

445
00:26:57,680 --> 00:27:01,120
Speaker 5:  too, that really none of these competitors

446
00:27:01,630 --> 00:27:05,560
Speaker 5:  have that. That it's fairly unique. None of the

447
00:27:05,570 --> 00:27:08,080
Speaker 5:  small like meta and TikTok don't have that at this point.

448
00:27:08,130 --> 00:27:12,080
Speaker 2:  Right? The only company doing Amazon things is Amazon, which

449
00:27:12,080 --> 00:27:15,880
Speaker 2:  is I suppose a, a strength of the argument here but also gonna

450
00:27:15,880 --> 00:27:19,160
Speaker 2:  make it a challenge to figure out like who are we, who else are we arguing

451
00:27:19,170 --> 00:27:23,000
Speaker 2:  about here is gonna be weird in this case.

452
00:27:23,000 --> 00:27:26,840
Speaker 2:  Whereas like at least Google has one real honest to God

453
00:27:26,840 --> 00:27:30,200
Speaker 2:  like apples to apples competitor, which is why the Google trial has become

454
00:27:30,200 --> 00:27:34,120
Speaker 2:  so much about Bing because like why isn't Bing good is like a central question,

455
00:27:34,420 --> 00:27:38,080
Speaker 2:  but in a way you can't quite ask the same question about Walmart

456
00:27:38,900 --> 00:27:42,120
Speaker 2:  and, and get answers about Amazon. It's gonna be very, it's gonna be very

457
00:27:42,120 --> 00:27:44,800
Speaker 2:  strange to see how we talk about this because there just isn't any company

458
00:27:44,860 --> 00:27:47,000
Speaker 2:  out there remotely like Amazon anymore.

459
00:27:47,500 --> 00:27:51,360
Speaker 5:  And we are also not even touching Amazon's media business. The fact that

460
00:27:51,420 --> 00:27:55,320
Speaker 5:  it runs Prime, which is its own very powerful player in its market.

461
00:27:55,630 --> 00:27:57,840
Speaker 5:  Yeah. Like Prime movies, it

462
00:27:57,840 --> 00:27:59,880
Speaker 6:  Has Lord of the Rings now, right? Yeah. There's

463
00:27:59,880 --> 00:28:03,080
Speaker 2:  Like, although that show sucks, so I, I suspect that will not come up on

464
00:28:03,080 --> 00:28:04,560
Speaker 2:  anybody's side in this argument.

465
00:28:04,630 --> 00:28:07,000
Speaker 5:  Well there's the M G M acquisition. Yeah.

466
00:28:07,060 --> 00:28:10,480
Speaker 2:  All these things to bolster Prime like in a lot of ways it does seem like,

467
00:28:10,480 --> 00:28:13,960
Speaker 2:  and this goes back to like is this raising prices things like is the, is

468
00:28:13,960 --> 00:28:17,920
Speaker 2:  the ongoing push and existence of Prime good or bad

469
00:28:17,920 --> 00:28:21,760
Speaker 2:  for consumers is a big part of the question here. And Amazon has spent a

470
00:28:21,760 --> 00:28:25,080
Speaker 2:  long time being like it's cheap. We keep giving you reasons to make it better

471
00:28:25,260 --> 00:28:27,800
Speaker 2:  and the FTC is gonna be like no, actually what it's doing is like building

472
00:28:27,800 --> 00:28:30,960
Speaker 2:  ever higher walled gardens through which it can screw both sellers and customers.

473
00:28:31,360 --> 00:28:31,480
Speaker 2:  A

474
00:28:31,760 --> 00:28:34,240
Speaker 6:  Solution to a problem it created essentially.

475
00:28:34,520 --> 00:28:38,320
Speaker 2:  Yeah. Right, right. And has made more and more expensive to solve over time.

476
00:28:38,990 --> 00:28:41,920
Speaker 2:  What, what do we have any sense of the timeline on the Amazon trial? Like

477
00:28:41,940 --> 00:28:45,880
Speaker 2:  the Google thing took what, almost three years to

478
00:28:46,160 --> 00:28:49,920
Speaker 2:  actually go to trial from that first complaint is, is that a roughly

479
00:28:50,070 --> 00:28:52,640
Speaker 2:  good guide for the Amazon one do we think? Yeah,

480
00:28:52,960 --> 00:28:56,800
Speaker 6:  I think that's probably fair. Justice moves very slowly

481
00:28:56,900 --> 00:29:00,680
Speaker 6:  in this country on all fronts, but I do

482
00:29:00,680 --> 00:29:04,280
Speaker 6:  imagine it's gonna be quite a bit of time and well people

483
00:29:04,280 --> 00:29:07,400
Speaker 6:  interested, I think we just have to continue following it before we have

484
00:29:07,400 --> 00:29:11,280
Speaker 6:  like a gauge of when arguments could take place when things

485
00:29:11,280 --> 00:29:14,400
Speaker 6:  start. Right now it's just, it could be anyone's guess.

486
00:29:14,780 --> 00:29:17,640
Speaker 5:  We also don't really know what's going to end up going to trial. Like even

487
00:29:17,700 --> 00:29:21,560
Speaker 5:  the Google case that went to trial is somewhat subtly different than the

488
00:29:21,560 --> 00:29:22,200
Speaker 5:  one that was filed.

489
00:29:22,470 --> 00:29:26,240
Speaker 2:  Yeah, that's very true. Well listen, as long as Project Nessie doesn't go

490
00:29:26,270 --> 00:29:28,280
Speaker 2:  away in this process, I'll be okay.

491
00:29:28,510 --> 00:29:31,160
Speaker 5:  Okay. Which is a cooler name Project Nessie or Jedi Blue.

492
00:29:31,270 --> 00:29:34,600
Speaker 2:  They're both very good but Project Nessie for something that is heavily

493
00:29:34,760 --> 00:29:38,640
Speaker 2:  redacted is perfect. Yeah. Like it's the Sasquatch

494
00:29:38,640 --> 00:29:41,600
Speaker 2:  like they should just have secret names for everything and then just redact

495
00:29:41,600 --> 00:29:42,800
Speaker 2:  them all. Like that's what I would do.

496
00:29:43,070 --> 00:29:44,400
Speaker 6:  They all have crypted names.

497
00:29:46,230 --> 00:29:50,120
Speaker 2:  Alright, thank you both very much for being here. We gotta take a

498
00:29:50,120 --> 00:29:53,280
Speaker 2:  break and then we're gonna come back and talk about a very different trial,

499
00:29:53,330 --> 00:29:57,120
Speaker 2:  about a very different industry with very different stakes. It's

500
00:29:57,120 --> 00:29:59,240
Speaker 2:  crypto time y'all. We'll be right back.

501
00:31:32,090 --> 00:31:35,900
Speaker 2:  Welcome back as you're hearing this on Wednesday, it's day two

502
00:31:35,960 --> 00:31:39,740
Speaker 2:  of the trial against Sam. Bankman Freed, who's better known as S P F

503
00:31:39,880 --> 00:31:43,580
Speaker 2:  and is also known as the former founder and C t O of FTX,

504
00:31:43,590 --> 00:31:47,580
Speaker 2:  which was for a while, one of the hottest companies in crypto. It was

505
00:31:47,730 --> 00:31:51,580
Speaker 2:  huge. Now of course crypto has taken a dive and

506
00:31:51,720 --> 00:31:55,620
Speaker 2:  so have s SPFs fortunes and the two things have a lot to do with

507
00:31:55,620 --> 00:31:59,020
Speaker 2:  each other. Actually there are a lot of folks out there who think this trial,

508
00:31:59,230 --> 00:32:02,980
Speaker 2:  which is ostensibly just about SS B f, is going to have huge

509
00:32:02,980 --> 00:32:06,900
Speaker 2:  ramifications for the whole crypto universe as new information comes

510
00:32:06,900 --> 00:32:10,700
Speaker 2:  out about how the industry actually works. It's a complicated

511
00:32:10,860 --> 00:32:14,660
Speaker 2:  trial and an important one. The Verges Liz Lipato is covering it for us.

512
00:32:14,840 --> 00:32:18,660
Speaker 2:  And I suspect right this second she's probably in a courtroom. So

513
00:32:18,760 --> 00:32:22,340
Speaker 2:  we caught up a couple of days ago before things really got going. Hi Liz.

514
00:32:22,760 --> 00:32:22,980
Speaker 2:  Hey

515
00:32:22,980 --> 00:32:23,900
Speaker 7:  David, how's it going?

516
00:32:24,370 --> 00:32:27,300
Speaker 2:  Okay, so I realized I was prepping for this and like you and I have both

517
00:32:27,300 --> 00:32:30,660
Speaker 2:  been following this pretty closely for a long time. You

518
00:32:30,830 --> 00:32:34,740
Speaker 2:  mercifully more closely than I you've hired tolerance for this nonsense

519
00:32:34,740 --> 00:32:38,620
Speaker 2:  than I do I think. But I realized after all of like the chaos of

520
00:32:38,680 --> 00:32:42,480
Speaker 2:  the last however many months it's been, I've sort of lost

521
00:32:42,490 --> 00:32:46,040
Speaker 2:  track of what Sam Bankman Freed is actually on trial

522
00:32:46,300 --> 00:32:50,160
Speaker 2:  for. So in a weird way, let's just start at like absolute ground

523
00:32:50,160 --> 00:32:52,680
Speaker 2:  level here. I think there are a lot of layers and a lot of things to talk

524
00:32:52,680 --> 00:32:56,240
Speaker 2:  about. But like what does this man actually being accused of

525
00:32:56,620 --> 00:32:57,640
Speaker 2:  and on trial for?

526
00:32:58,230 --> 00:33:01,920
Speaker 8:  Well conveniently David, I brought something to the

527
00:33:01,920 --> 00:33:05,720
Speaker 8:  recording. Did you? And it is, it is a copy of the superseding

528
00:33:05,720 --> 00:33:09,520
Speaker 8:  indictment. So this is what he's on trial for. I love it. And there are seven

529
00:33:09,520 --> 00:33:13,400
Speaker 8:  counts in it. Okay. And they are wire fraud

530
00:33:13,460 --> 00:33:17,400
Speaker 8:  and conspiracy to confi wire fraud mostly. Okay, so

531
00:33:17,400 --> 00:33:21,160
Speaker 8:  count one is wire fraud on the customers of FTX. Count

532
00:33:21,180 --> 00:33:24,760
Speaker 8:  two is conspiracy to commit wire fraud on the customers of FTX. Sure.

533
00:33:24,860 --> 00:33:27,680
Speaker 8:  That's, this is pretty straightforward. And I just wanna pause here and talk

534
00:33:27,680 --> 00:33:30,960
Speaker 8:  about how you prove this because this is part of what's exciting part of

535
00:33:30,960 --> 00:33:34,680
Speaker 8:  it. For wire fraud, you have to show the bank transfer happened. That's boring.

536
00:33:35,340 --> 00:33:39,120
Speaker 8:  But then you have to prove that people were defrauded. That

537
00:33:39,180 --> 00:33:43,160
Speaker 8:  Sam Bankman freed, knew he was lying to the customers of

538
00:33:43,300 --> 00:33:46,920
Speaker 8:  FTX. And so this is something where we might hear testimony from actual customers

539
00:33:47,100 --> 00:33:51,080
Speaker 8:  You know who are talking about what he told them. It's where we

540
00:33:51,080 --> 00:33:54,640
Speaker 8:  might talk about what he was saying in front of Congress is where we might

541
00:33:54,640 --> 00:33:58,280
Speaker 8:  talk about what he You know what the Super Bowl ad said. Those kinds of things

542
00:33:58,300 --> 00:34:00,000
Speaker 8:  are where this all comes into play,

543
00:34:00,010 --> 00:34:03,240
Speaker 2:  Right? And this sort of base underlying thing is that he used

544
00:34:04,000 --> 00:34:07,640
Speaker 2:  customer's money basically funneled it to this in his investment arm called

545
00:34:07,960 --> 00:34:08,960
Speaker 2:  Alameda. Was it Alameda Capital?

546
00:34:09,680 --> 00:34:10,160
Speaker 8:  Alameda Research.

547
00:34:10,560 --> 00:34:11,120
Speaker 2:  Alameda Research.

548
00:34:11,260 --> 00:34:14,680
Speaker 8:  But also used it to buy himself real estate and to make some investments.

549
00:34:14,710 --> 00:34:18,520
Speaker 8:  It's, it's a straightforward, the accusations are straightforward, it's embezzlement,

550
00:34:19,470 --> 00:34:21,160
Speaker 8:  it's very old fashioned. See this

551
00:34:21,160 --> 00:34:24,360
Speaker 2:  Is why this is useful 'cause I feel like this is all, it all spins in so

552
00:34:24,360 --> 00:34:28,040
Speaker 2:  many directions about like the crypto industry and tax fraud and all this

553
00:34:28,040 --> 00:34:32,000
Speaker 2:  stuff. But ultimately it is just like he used money that wasn't his to do

554
00:34:32,000 --> 00:34:35,200
Speaker 2:  things you're not allowed to do with money that isn't yours. It's like that's

555
00:34:35,200 --> 00:34:37,520
Speaker 2:  exactly right. It's pretty simple. Okay. Alright. So that's the first two.

556
00:34:37,520 --> 00:34:38,080
Speaker 2:  What else we got?

557
00:34:38,380 --> 00:34:42,000
Speaker 8:  So we have count three wire fraud on lenders to Alameda research.

558
00:34:42,220 --> 00:34:45,920
Speaker 8:  So this is his crypto trading arm and they had borrowed money and now the

559
00:34:45,920 --> 00:34:49,720
Speaker 8:  allegation is that he defrauded the people he borrowed money from. And then

560
00:34:49,720 --> 00:34:53,560
Speaker 8:  count four is conspiracy to commit wire fraud. Again, this you, you

561
00:34:53,560 --> 00:34:54,400
Speaker 8:  see where this is going,

562
00:34:54,620 --> 00:34:56,800
Speaker 2:  You want to do it and then you do it. Yeah. Yeah.

563
00:34:57,060 --> 00:35:00,960
Speaker 8:  And then count five is conspiracy to commit securities fraud

564
00:35:01,180 --> 00:35:04,920
Speaker 8:  on investors of FTX. So that's different. And that's the one where we might

565
00:35:04,920 --> 00:35:08,480
Speaker 8:  see VC testimony. So the people who were

566
00:35:08,550 --> 00:35:12,480
Speaker 8:  investing were given bad information. Sam, bickman, Fried had re reason

567
00:35:12,480 --> 00:35:16,240
Speaker 8:  to know it was bad information. That's the allegation, right? So you might

568
00:35:16,240 --> 00:35:19,640
Speaker 8:  see somebody step up on the stand and say, hey, this is what the documents

569
00:35:19,640 --> 00:35:23,440
Speaker 8:  that I got said, here's what Sam said and here's the due diligence

570
00:35:23,440 --> 00:35:26,960
Speaker 8:  we did. Here are our due diligence documents. And again, you have to prove

571
00:35:26,960 --> 00:35:30,880
Speaker 8:  that he knew what he was saying is wrong 'cause like being an idiot isn't

572
00:35:30,880 --> 00:35:34,560
Speaker 8:  illegal. Right? So that's count five. And then we have

573
00:35:34,610 --> 00:35:38,040
Speaker 8:  count six, which is conspiracy to commit

574
00:35:38,360 --> 00:35:41,320
Speaker 8:  commodity fraud on customers of F D X. I'm

575
00:35:41,320 --> 00:35:42,280
Speaker 2:  Seeing a trend here. Liz.

576
00:35:42,390 --> 00:35:45,880
Speaker 8:  Yeah, let's, well we're gonna get to the conspirators in a minute, right?

577
00:35:46,220 --> 00:35:50,080
Speaker 8:  And then count seven is conspiracy to commit money laundering. Okay. So those,

578
00:35:50,080 --> 00:35:52,720
Speaker 8:  that's what, that's what we're gonna be hearing from. And part of the reason

579
00:35:52,800 --> 00:35:56,120
Speaker 8:  I wanted to go through those things specifically is that there's a bunch

580
00:35:56,120 --> 00:36:00,040
Speaker 8:  of other stuff that's going on around this. There

581
00:36:00,040 --> 00:36:03,720
Speaker 8:  are so many things going on. There's like an SS e c lawsuit, there's a C

582
00:36:03,760 --> 00:36:07,120
Speaker 8:  F D C lawsuit, there's another trial actually that's gonna be happening.

583
00:36:07,270 --> 00:36:10,920
Speaker 8:  It's scheduled for next March for a number of counts we aren't gonna be hearing

584
00:36:10,920 --> 00:36:14,040
Speaker 8:  here. So I wanted to make sure we knew which counts we're dealing with, right?

585
00:36:14,200 --> 00:36:18,000
Speaker 8:  'cause some of the allegations around like campaign finance stuff for

586
00:36:18,200 --> 00:36:21,840
Speaker 8:  instance, while they might show up in this trial, they are not the charges

587
00:36:22,030 --> 00:36:23,400
Speaker 8:  that are being brought against him here.

588
00:36:23,710 --> 00:36:27,160
Speaker 2:  Yeah. And you've kind of alluded to this, but one of the things I think is

589
00:36:27,310 --> 00:36:31,040
Speaker 2:  important and sort of complicated to understand is what's different about

590
00:36:31,040 --> 00:36:34,680
Speaker 2:  what happened at FTX versus what has happened in some of these other

591
00:36:34,980 --> 00:36:38,960
Speaker 2:  crypto messes we've talked about on this show over the years. And I

592
00:36:38,960 --> 00:36:42,560
Speaker 2:  think about like everything from You know the, the Luna

593
00:36:42,560 --> 00:36:45,200
Speaker 2:  debacle where a bunch of people lost a lot of money to like what happened

594
00:36:45,200 --> 00:36:47,840
Speaker 2:  with Axe Infinity where a bunch of people lost a lot of money. It, it seems

595
00:36:47,840 --> 00:36:51,600
Speaker 2:  like there's one thing that is like crypto gone

596
00:36:51,820 --> 00:36:55,240
Speaker 2:  bad and that seems to have all gone, kind of gone one direction and this

597
00:36:55,240 --> 00:36:59,160
Speaker 2:  has gone a slightly different direction. Like how do you explain

598
00:36:59,180 --> 00:37:02,800
Speaker 2:  the difference between what all those things are, where a lot of people lose

599
00:37:02,840 --> 00:37:05,080
Speaker 2:  a lot of money And what this has become?

600
00:37:05,820 --> 00:37:09,720
Speaker 8:  Oh boy. So Tara Luna was a project that

601
00:37:09,920 --> 00:37:13,880
Speaker 8:  I think was badly conceived from the jump and there were a number

602
00:37:13,880 --> 00:37:17,240
Speaker 8:  of people who predicted that that death spiral would happen in exactly the

603
00:37:17,240 --> 00:37:20,760
Speaker 8:  way that it did. Right. And now there are You know also some allegations

604
00:37:20,760 --> 00:37:24,680
Speaker 8:  that are being brought against Quan about You know, the last I

605
00:37:24,680 --> 00:37:27,880
Speaker 8:  saw was that he might have been falsifying some trading. Okay. But as far

606
00:37:28,120 --> 00:37:31,640
Speaker 8:  as I know, and I'm I'm saying this now, we may, we may see something else

607
00:37:31,640 --> 00:37:35,560
Speaker 8:  in the future. As far as I know, DeQuan did not tip his hand into the till

608
00:37:35,620 --> 00:37:39,560
Speaker 8:  and actually take money. Okay. Right. And when you talk about like

609
00:37:39,580 --> 00:37:42,760
Speaker 8:  the various crypto failures of things like Three Arrows Capital

610
00:37:43,370 --> 00:37:47,280
Speaker 8:  again, like they had loans that went bad and they couldn't make good on them.

611
00:37:47,470 --> 00:37:51,280
Speaker 8:  Sure. There's a difference between making bad betts and actually

612
00:37:51,280 --> 00:37:55,080
Speaker 8:  taking people's money. So like that's kind of what we're looking at. And

613
00:37:55,080 --> 00:37:58,080
Speaker 8:  there are people within the crypto industry by the way, who are very happy

614
00:37:58,220 --> 00:38:01,720
Speaker 8:  to see Sam Bankman free go down because they want,

615
00:38:01,950 --> 00:38:05,080
Speaker 8:  they want the fraudsters out of the industry. They really do think that this

616
00:38:05,280 --> 00:38:08,360
Speaker 8:  is something that's big and real and important. So clearing out all of the

617
00:38:08,360 --> 00:38:11,320
Speaker 8:  villains, if you will, is a positive for crypto.

618
00:38:12,240 --> 00:38:15,520
Speaker 8:  I think that they are a little confused about what the general public

619
00:38:15,630 --> 00:38:19,560
Speaker 8:  understands about crypto because I think once you're in

620
00:38:19,560 --> 00:38:22,920
Speaker 8:  it, like there's a lot of stuff that, there are a lot of subtleties and nuances.

621
00:38:22,920 --> 00:38:25,640
Speaker 8:  It's kind of like an onion, right? Like there's just always more down there.

622
00:38:25,670 --> 00:38:29,280
Speaker 8:  Yeah. But Sam, Bankman Freed was really, really successful at

623
00:38:29,280 --> 00:38:32,680
Speaker 8:  marketing and really, really successful at promoting himself and really,

624
00:38:32,680 --> 00:38:36,160
Speaker 8:  really successful at making himself synonymous with crypto in the United States.

625
00:38:36,620 --> 00:38:39,640
Speaker 2:  He was the good guy. Yeah. Like not only was he not the villain, he was like

626
00:38:39,740 --> 00:38:43,680
Speaker 2:  the disheveled good guy of crypto who like wasn't trying to sell you

627
00:38:43,720 --> 00:38:46,360
Speaker 2:  a bunch of nonsense. He was the other one. Right.

628
00:38:46,940 --> 00:38:49,960
Speaker 8:  And so that makes it a lot harder for anybody who says, Hey, we wanna be

629
00:38:49,960 --> 00:38:53,080
Speaker 8:  regulated 'cause You know who else said that was Sam Bankman free. Right.

630
00:38:53,410 --> 00:38:57,400
Speaker 8:  Right. So there's a like sort of a lot of a taint here I

631
00:38:57,400 --> 00:39:01,240
Speaker 8:  think for people who are not directly involved in crypto. And one of the

632
00:39:01,240 --> 00:39:04,400
Speaker 8:  sort of long-term goals of crypto is I think to get a lot of people involved

633
00:39:04,620 --> 00:39:08,280
Speaker 8:  and I think potentially You know this kind of trial and the

634
00:39:08,280 --> 00:39:11,960
Speaker 8:  associations with Sam Bankman free as a very public face of crypto

635
00:39:12,210 --> 00:39:15,880
Speaker 8:  could be bad for the entire industry as far as like recruiting new

636
00:39:16,080 --> 00:39:16,560
Speaker 8:  customers goes.

637
00:39:17,110 --> 00:39:20,840
Speaker 2:  Yeah, I was thinking about this. I re-watched the, the big short movie relatively

638
00:39:21,080 --> 00:39:24,000
Speaker 2:  recently. I love it very much. But there's this character in it, Michael

639
00:39:24,010 --> 00:39:28,000
Speaker 2:  Burry, who is like one of the first people to see that the housing

640
00:39:28,060 --> 00:39:31,840
Speaker 2:  crisis is coming and that the way we've propped up mortgage bonds

641
00:39:31,900 --> 00:39:35,760
Speaker 2:  is a disaster. And he is like the voice of reason. He's also like a

642
00:39:35,940 --> 00:39:39,600
Speaker 2:  maniac. And I had this moment of reading about Sam

643
00:39:39,600 --> 00:39:43,360
Speaker 2:  Bankman freed in the run up to this trial thinking he's both trying

644
00:39:43,380 --> 00:39:47,160
Speaker 2:  to be like the c e o of Goldman Sachs setting up these

645
00:39:47,160 --> 00:39:50,920
Speaker 2:  systems that are a disaster. And the Michael Burry saying

646
00:39:51,230 --> 00:39:54,720
Speaker 2:  this is all a mess and is all going to come crashing down. He like tried

647
00:39:54,720 --> 00:39:58,560
Speaker 2:  to do both of those things simultaneously and sort of play all sides

648
00:39:58,560 --> 00:40:02,280
Speaker 2:  depending on who he's in a room talking to. And did it really well for a

649
00:40:02,280 --> 00:40:05,760
Speaker 2:  surprisingly long period of time. He was like, this is the future also. We

650
00:40:05,760 --> 00:40:09,320
Speaker 2:  need to be regulated also. It might be nothing, but it's possibly everything.

651
00:40:09,660 --> 00:40:12,040
Speaker 2:  And like it worked until it didn't.

652
00:40:12,470 --> 00:40:15,520
Speaker 8:  Well I have a, I have a couple thoughts about this and then there's, there's

653
00:40:15,520 --> 00:40:19,360
Speaker 8:  something that I've noticed when I explain crypto to people, which is

654
00:40:19,990 --> 00:40:23,440
Speaker 8:  I'll explain it to them and they'll say, oh, is that it? Is that all? And

655
00:40:23,440 --> 00:40:27,200
Speaker 8:  it's like, yeah, that that's all I that is it. You know And they think it

656
00:40:27,200 --> 00:40:30,400
Speaker 8:  must be much more complicated than it actually is. And there You know there

657
00:40:30,420 --> 00:40:34,200
Speaker 8:  are like a bunch of, there's a bunch of complicated math in there

658
00:40:34,500 --> 00:40:37,960
Speaker 8:  You know, but conceptually it's actually not that difficult to understand.

659
00:40:38,140 --> 00:40:41,360
Speaker 8:  And so as soon as you explain like an N F T to people, they're like, but

660
00:40:41,840 --> 00:40:44,320
Speaker 8:  I thought that, I thought this was supposed to be sophisticated. It's like,

661
00:40:44,320 --> 00:40:47,240
Speaker 8:  well the math is sophisticated, the programming is sophisticated. But like

662
00:40:47,240 --> 00:40:51,000
Speaker 8:  the concept pretty simple. And I think one of the things

663
00:40:51,000 --> 00:40:54,600
Speaker 8:  that people like Sam Beckman Fried really benefit from is this assumption

664
00:40:54,860 --> 00:40:58,560
Speaker 8:  of technical complexity. And that if you think it

665
00:40:58,560 --> 00:41:01,880
Speaker 8:  sounds You know half baked, maybe it's just that you don't understand it,

666
00:41:02,330 --> 00:41:06,160
Speaker 8:  maybe you're just not smart enough to understand it. And Bankman

667
00:41:06,260 --> 00:41:10,040
Speaker 8:  Free's background as somebody who went to m i t

668
00:41:10,640 --> 00:41:14,600
Speaker 8:  worked on Jane Street, You know math whizz makes it easy to

669
00:41:14,600 --> 00:41:17,400
Speaker 8:  sell something like that. Part of what's really striking to me about all

670
00:41:17,400 --> 00:41:21,080
Speaker 8:  of this is actually running the casino is a pretty

671
00:41:21,080 --> 00:41:24,880
Speaker 8:  profitable business. And if he had just run FTX and like let

672
00:41:25,240 --> 00:41:29,200
Speaker 8:  Alameda fail, I think he would be fine. The problem here

673
00:41:29,580 --> 00:41:33,440
Speaker 8:  is that he wanted to propped up Alameda research, which was

674
00:41:33,500 --> 00:41:36,560
Speaker 8:  the reason he founded FTX in the first place. Like if you go back to that,

675
00:41:37,230 --> 00:41:40,520
Speaker 8:  that profile from Sequoia Capital that they like deleted 'cause it was so

676
00:41:40,520 --> 00:41:43,240
Speaker 8:  embarrassing, but don't worry, it's, it's on the internet archive, you can

677
00:41:43,240 --> 00:41:46,880
Speaker 8:  go read it. He talks about You know other exchanges being rickety and

678
00:41:47,360 --> 00:41:50,360
Speaker 8:  Alameda having losses because the exchanges weren't good enough. And so he

679
00:41:50,360 --> 00:41:53,000
Speaker 8:  wanted to build an exchange that was good enough for what he wanted to do.

680
00:41:54,140 --> 00:41:57,920
Speaker 8:  And again, You know there are moments in that

681
00:41:57,920 --> 00:42:01,160
Speaker 8:  profile where the, the VCs are like, well we assumed he wouldn't need money,

682
00:42:01,180 --> 00:42:05,040
Speaker 8:  but here he is and it's like, that's an alarm bell for me right there. Yeah.

683
00:42:05,060 --> 00:42:07,920
Speaker 8:  You know there might be a good reason to go get VC money even if you don't

684
00:42:07,920 --> 00:42:11,480
Speaker 8:  need it just because it lets you expand faster for instance, lets you do

685
00:42:11,480 --> 00:42:15,280
Speaker 8:  more things. But in retrospect that does seem like a striking

686
00:42:15,280 --> 00:42:18,560
Speaker 8:  thing in the profile where they're like, oh, we assumed he was just minting

687
00:42:18,560 --> 00:42:21,040
Speaker 8:  money hand over fist. But here he is asking us for some.

688
00:42:22,600 --> 00:42:26,440
Speaker 8:  Yeah. And You know, if you read the s e c complaint, they say FTX was

689
00:42:26,480 --> 00:42:30,240
Speaker 8:  a fraud from the jump that the like from the very beginning You know

690
00:42:30,480 --> 00:42:34,080
Speaker 8:  customer funds were being misallocate. And so I'm partially curious to know

691
00:42:34,800 --> 00:42:38,640
Speaker 8:  sort of like the timeline of all of this because the way that

692
00:42:38,760 --> 00:42:42,720
Speaker 8:  FTX ex was exposed was particularly chaotic. Yes. And we

693
00:42:42,720 --> 00:42:46,240
Speaker 8:  found out about the misappropriated customer funds after

694
00:42:46,920 --> 00:42:49,200
Speaker 8:  a different kind of chaos that is not on trial.

695
00:42:49,590 --> 00:42:53,400
Speaker 2:  Explain that really quickly and then let's, again, there are many more tentacles

696
00:42:53,400 --> 00:42:55,680
Speaker 2:  of this story that are gonna come out over time, but I do think that part

697
00:42:55,680 --> 00:42:58,440
Speaker 2:  is important. 'cause you're right, it's not on trial, but it is like central

698
00:42:58,540 --> 00:43:01,840
Speaker 2:  to what happened to FTX. So just explain that chaos real fast. Sure.

699
00:43:02,100 --> 00:43:05,880
Speaker 8:  So CoinDesk gets a hold of Alameda research's balance

700
00:43:05,890 --> 00:43:09,880
Speaker 8:  sheet and the balance sheet is weird. That's the easiest

701
00:43:09,980 --> 00:43:13,640
Speaker 8:  way to put it. Yep. There's an awful lot of this token

702
00:43:14,040 --> 00:43:17,840
Speaker 8:  F t t that's minted by FTX that's propping up the balance

703
00:43:17,840 --> 00:43:21,120
Speaker 8:  sheet and backing up their loans. That's like if

704
00:43:21,830 --> 00:43:25,280
Speaker 8:  Sephora were to go out and get loans based on the beauty

705
00:43:25,470 --> 00:43:28,920
Speaker 8:  insider points, which they determine the value of. Okay. That's a good

706
00:43:28,920 --> 00:43:29,800
Speaker 2:  Example. I like that. Yeah.

707
00:43:30,140 --> 00:43:34,000
Speaker 8:  And so there's, there's something like weird happening here and Sam

708
00:43:34,000 --> 00:43:37,640
Speaker 8:  Bank Reed has a long running rivalry with the head of Binance

709
00:43:38,340 --> 00:43:42,280
Speaker 8:  cz and CZ happens to have a lot of F T T tokens because

710
00:43:43,220 --> 00:43:47,200
Speaker 8:  CZ was an early investor in FTX and Sam bought him out and gave him f

711
00:43:47,280 --> 00:43:50,920
Speaker 8:  t t tokens to do it. And so CZ essentially announced he's going to dump his

712
00:43:50,940 --> 00:43:54,720
Speaker 8:  tokens and at that point the market panics. And so

713
00:43:54,720 --> 00:43:57,680
Speaker 8:  people, there's, there's a run. People are trying to get their money out,

714
00:43:57,870 --> 00:44:01,640
Speaker 8:  they're You know dumping tokens left, right. And center

715
00:44:01,740 --> 00:44:05,160
Speaker 8:  FTX is like, we're up for sale. Binance is like, oh we'll buy you. And then

716
00:44:05,360 --> 00:44:08,960
Speaker 8:  Binance like after a day is like, just kidding, we're not buying this.

717
00:44:09,500 --> 00:44:13,240
Speaker 8:  And then after that there's bankruptcy and it's in this period

718
00:44:13,340 --> 00:44:17,200
Speaker 8:  of time post bankruptcy that these

719
00:44:17,200 --> 00:44:21,120
Speaker 8:  details start to emerge that get weirder. You know

720
00:44:21,120 --> 00:44:24,360
Speaker 8:  like the, the sort of like funky accounting of

721
00:44:24,950 --> 00:44:28,920
Speaker 8:  valuing yourself by a token that you get to assign the value of yourself.

722
00:44:28,920 --> 00:44:32,360
Speaker 8:  Like that's not great in and of itself. Yeah. But the customer funds stuff

723
00:44:32,360 --> 00:44:36,000
Speaker 8:  that comes up afterwards where it's like there's this hideous balance sheet

724
00:44:36,000 --> 00:44:39,840
Speaker 8:  of terrors that the, the Financial Times gets a hold of that. Like

725
00:44:40,150 --> 00:44:42,640
Speaker 8:  it's still up there. Like if you wanna go look at that terrible spreadsheet,

726
00:44:42,640 --> 00:44:46,320
Speaker 8:  like it gives me panic attacks, but like go look, there's You know, just

727
00:44:46,320 --> 00:44:49,640
Speaker 8:  like a hole, there's an $8 billion hole

728
00:44:49,910 --> 00:44:53,840
Speaker 8:  billion with a B. That's when everybody was sort of like, okay, well

729
00:44:54,670 --> 00:44:57,040
Speaker 8:  where's the money? Where's the money Lebowski?

730
00:44:57,230 --> 00:45:01,080
Speaker 2:  Well, and so this is where the FTX trial and this

731
00:45:01,110 --> 00:45:04,600
Speaker 2:  sort of relatively specific set of allegations against Sam, Bankman Freed

732
00:45:04,870 --> 00:45:08,720
Speaker 2:  becomes the trial about crypto. Right. And you, you wrote a,

733
00:45:08,800 --> 00:45:12,480
Speaker 2:  a sort of run up to the trial getting at a lot of this that there is a, there

734
00:45:12,480 --> 00:45:15,880
Speaker 2:  is a sense in the industry that actually what's about to happen is

735
00:45:16,560 --> 00:45:20,360
Speaker 2:  a lot of evidence is going to be introduced and a lot of testimony is going

736
00:45:20,360 --> 00:45:24,280
Speaker 2:  to be given not just about Sam but about the

737
00:45:24,280 --> 00:45:28,240
Speaker 2:  crypto world. And this is both a a, it seems like both a prosecution

738
00:45:28,440 --> 00:45:32,040
Speaker 2:  tactic and a defense tactic is to basically make the whole crypto

739
00:45:32,130 --> 00:45:34,440
Speaker 2:  world look really, really, really, really bad.

740
00:45:34,990 --> 00:45:38,720
Speaker 8:  Yeah, that's right. I think there is a lot of danger here Without knowing

741
00:45:38,860 --> 00:45:41,920
Speaker 8:  the specifics of what's going to be said, we're gonna find out during opening

742
00:45:42,240 --> 00:45:46,000
Speaker 8:  arguments what we've got is an offshore exchange that is

743
00:45:46,000 --> 00:45:49,800
Speaker 8:  doing something that would be illegal in the United States. You can't run

744
00:45:50,110 --> 00:45:53,280
Speaker 8:  both your own trading firm and your own exchange. Like that's an obvious

745
00:45:53,720 --> 00:45:54,800
Speaker 8:  conflict of interest. Right. We

746
00:45:54,800 --> 00:45:55,760
Speaker 2:  Have laws about that. Yeah.

747
00:45:56,420 --> 00:45:59,680
Speaker 8:  It turns out, yeah. So it's in and it's in The Bahamas, so. Hmm.

748
00:46:00,300 --> 00:46:04,040
Speaker 8:  And You know as we, we ran through the charges, I think it's worth thinking

749
00:46:04,040 --> 00:46:06,880
Speaker 8:  about what kind of evidence it takes to prove each one of these charges.

750
00:46:06,950 --> 00:46:10,000
Speaker 8:  Like there's the boring part where you show the wire transfer happened, like

751
00:46:10,000 --> 00:46:13,400
Speaker 8:  that's gonna happen. Sure. There's like some chain of custody stuff about

752
00:46:13,400 --> 00:46:17,080
Speaker 8:  like text messages also boring, but that has to go on the record. But then

753
00:46:17,230 --> 00:46:20,960
Speaker 8:  it's like you have to demonstrate what was actually said by

754
00:46:21,020 --> 00:46:24,960
Speaker 8:  Sam Bankman, Fried And what Sam Bankman Freed knew. And

755
00:46:24,960 --> 00:46:28,040
Speaker 8:  those might be two entirely different things. And so you think about like,

756
00:46:28,040 --> 00:46:32,000
Speaker 8:  okay, what kinds of text messages were there, what was going on in Slack?

757
00:46:32,510 --> 00:46:36,160
Speaker 8:  What conversations were happen happening? We know that there are a couple

758
00:46:36,160 --> 00:46:39,400
Speaker 8:  of his co-conspirators who pled guilty and are cooperating will most likely

759
00:46:39,550 --> 00:46:43,480
Speaker 8:  testify including his ex-girlfriend Carolyn Ellison, who was one of

760
00:46:43,480 --> 00:46:45,720
Speaker 8:  the CEOs of Alameda research. You know

761
00:46:45,980 --> 00:46:48,800
Speaker 2:  Who was in a position to know everything about what happened here.

762
00:46:49,030 --> 00:46:52,920
Speaker 8:  Exactly. And there is a recording of her contemporaneously explaining

763
00:46:52,920 --> 00:46:56,800
Speaker 8:  what happened. Like you can say, you can make an argument

764
00:46:56,850 --> 00:47:00,800
Speaker 8:  maybe to try to take her down. Oh, well You know she's trying to pin it

765
00:47:00,800 --> 00:47:04,520
Speaker 8:  all on Sam because she wants a a, an easier sentence. But like if you have

766
00:47:04,520 --> 00:47:08,280
Speaker 8:  that contemporaneous evidence of her explaining what happened,

767
00:47:08,620 --> 00:47:12,160
Speaker 8:  that's a much harder thing to make. You can't make it stick if she's, she

768
00:47:12,160 --> 00:47:15,160
Speaker 8:  said it before she thought she was gonna get caught. You know. So there's

769
00:47:15,160 --> 00:47:19,040
Speaker 8:  a lot of stuff that is going on that I think we could potentially

770
00:47:19,040 --> 00:47:21,680
Speaker 8:  hear about. But one of the things that I want everybody to sort of remember,

771
00:47:21,680 --> 00:47:24,800
Speaker 8:  because there are so many moving parts in this case that it's easy to get

772
00:47:24,800 --> 00:47:28,160
Speaker 8:  lost is that right before Sam Bankman Freed was

773
00:47:28,720 --> 00:47:32,560
Speaker 8:  arrested in The Bahamas, he was going to testify before Congress and

774
00:47:32,580 --> 00:47:36,200
Speaker 8:  we had his prepared testimony, which included a group

775
00:47:36,310 --> 00:47:40,240
Speaker 8:  chat of crypto exchanges where he was being You

776
00:47:40,240 --> 00:47:43,800
Speaker 8:  know, sort of scolded by cz. And

777
00:47:44,240 --> 00:47:47,840
Speaker 8:  I wonder one if we're going to see more

778
00:47:48,140 --> 00:47:51,880
Speaker 8:  of those exchanges, especially brought in by the defense and two,

779
00:47:52,070 --> 00:47:55,320
Speaker 8:  what they will say, because You know this is the sort of thing where like

780
00:47:55,840 --> 00:47:59,560
Speaker 8:  I don't think it's unusual for crypto exchanges

781
00:47:59,900 --> 00:48:03,000
Speaker 8:  to have conversations with each other. I'm, I'm sure that happens all the

782
00:48:03,000 --> 00:48:06,480
Speaker 8:  time. Sure. If only because You know everybody's trying to be like, okay,

783
00:48:06,480 --> 00:48:08,840
Speaker 8:  so what's the s e c gonna do next? But like

784
00:48:10,520 --> 00:48:14,360
Speaker 8:  I am interested in You know what kinds of evidence might be

785
00:48:14,360 --> 00:48:18,120
Speaker 8:  brought forward potentially either to try to get the not guilty

786
00:48:18,120 --> 00:48:22,080
Speaker 8:  verdict or to try to get Sam a lighter sentence. Because you

787
00:48:22,080 --> 00:48:25,200
Speaker 8:  have to keep in mind the defense is doing about three things at once. First

788
00:48:25,220 --> 00:48:29,040
Speaker 8:  and foremost, they want him not guilty. Sure. But should that fail,

789
00:48:29,510 --> 00:48:33,400
Speaker 8:  they second wanna make sure that sentencing is relatively light and

790
00:48:33,400 --> 00:48:36,760
Speaker 8:  third want grounds for appeals. So that means there's a bunch of evidence

791
00:48:36,760 --> 00:48:39,080
Speaker 8:  that they're going to be stuffing the record with that may not necessarily

792
00:48:39,220 --> 00:48:43,120
Speaker 8:  be directly relevant to the verdict itself, but might

793
00:48:43,240 --> 00:48:45,520
Speaker 8:  for instance, be helpful for those other two goals.

794
00:48:46,110 --> 00:48:50,080
Speaker 2:  Okay. And it seems like if you're his defense, the only two moves I can

795
00:48:50,080 --> 00:48:54,040
Speaker 2:  think of are you either have to make the case that he didn't

796
00:48:54,110 --> 00:48:57,520
Speaker 2:  know what was going on. Like you said, that being an idiot is not illegal.

797
00:48:57,860 --> 00:49:01,600
Speaker 2:  And so they, they either have to make the, he's just sort of a

798
00:49:01,790 --> 00:49:05,680
Speaker 2:  dumb figurehead case or make the

799
00:49:06,030 --> 00:49:09,960
Speaker 2:  everybody in crypto as a conman. Sam's not worse than everybody else case.

800
00:49:10,140 --> 00:49:13,600
Speaker 2:  Is there a, is there a third version of the defense that you've heard about?

801
00:49:14,190 --> 00:49:18,080
Speaker 8:  Yeah, so one of the things that that that sort of a joke

802
00:49:18,140 --> 00:49:21,520
Speaker 8:  and white collar crime is either you're too small to be responsible or you're

803
00:49:21,520 --> 00:49:23,080
Speaker 8:  too big to be responsible and like, yeah,

804
00:49:23,080 --> 00:49:23,920
Speaker 2:  There you go. You know, like

805
00:49:23,920 --> 00:49:27,400
Speaker 8:  That you're too far down the food chain to be responsible for the crime or

806
00:49:27,400 --> 00:49:30,320
Speaker 8:  you're so high up the food chain, you had no idea it happened. Right.

807
00:49:30,320 --> 00:49:33,720
Speaker 2:  He's like, I'm hobnobbing with democratic hopefuls who, how could I possibly

808
00:49:33,720 --> 00:49:35,200
Speaker 2:  have known what was going on. That's right.

809
00:49:35,350 --> 00:49:38,960
Speaker 8:  Yeah. So I expect that we're gonna get the, he was, he was too far up the

810
00:49:38,960 --> 00:49:42,600
Speaker 8:  food chain to know the specifics of what happened. But I also think that

811
00:49:43,170 --> 00:49:46,720
Speaker 8:  based on the reporting I've seen, there's going to be an advice of counsel

812
00:49:46,720 --> 00:49:49,880
Speaker 8:  defense. He's basically going to say that his, he's gonna throw his lawyers

813
00:49:49,880 --> 00:49:52,480
Speaker 8:  under the bus. He's gonna say, the lawyers told me that this was the best

814
00:49:52,480 --> 00:49:55,840
Speaker 8:  way to do things, so I did it their way. I don't know how much water that's

815
00:49:55,840 --> 00:49:59,440
Speaker 8:  going to hold. I am very curious about what kind of

816
00:49:59,640 --> 00:50:02,720
Speaker 8:  evidence you might present in order to make that defense.

817
00:50:03,200 --> 00:50:07,160
Speaker 8:  Particularly, because there seems to be a lot, just like

818
00:50:07,200 --> 00:50:11,080
Speaker 8:  a mountain of evidence here in terms of like chats

819
00:50:11,080 --> 00:50:14,760
Speaker 8:  and recordings and press, You know moments in the press, all of these things.

820
00:50:15,390 --> 00:50:19,240
Speaker 8:  Just a, just a mountain of stuff that he said. So I am

821
00:50:19,240 --> 00:50:23,120
Speaker 8:  very curious about what could possibly be brought forward in order to,

822
00:50:23,260 --> 00:50:26,920
Speaker 8:  to show that he was acting at the advice of counsel, that he was doing what

823
00:50:26,920 --> 00:50:28,880
Speaker 8:  his lawyers told him to do, and it wasn't his fault.

824
00:50:29,470 --> 00:50:33,400
Speaker 2:  Just from a trial perspective itself. How do you think this is

825
00:50:33,400 --> 00:50:37,040
Speaker 2:  gonna compare to, say, the Elizabeth Holmes trial, which you also covered

826
00:50:37,040 --> 00:50:40,680
Speaker 2:  very closely. That one was just like a nonstop spectacle, right? There were

827
00:50:40,860 --> 00:50:44,200
Speaker 2:  people cosplaying as Elizabeth Holmes outside of the courthouse.

828
00:50:44,660 --> 00:50:48,120
Speaker 2:  Do you think this one's gonna be sort of a show in the same way?

829
00:50:48,760 --> 00:50:52,320
Speaker 8:  I, I honestly have no idea. I think there are going to be a lot of people

830
00:50:52,550 --> 00:50:55,760
Speaker 8:  from the crypto industry who are going to pop by to watch. I've certainly

831
00:50:55,760 --> 00:50:59,200
Speaker 8:  spoken with people who've expressed an interest in doing so. Just out of

832
00:50:59,200 --> 00:51:02,840
Speaker 8:  curiosity, in the same way that like You know, I, I think a lot of us are

833
00:51:02,840 --> 00:51:06,160
Speaker 8:  very curious about this. Certainly. I'm curious. That's why I'm going. One

834
00:51:06,160 --> 00:51:09,880
Speaker 8:  of the things that I'm interested in is You know with a lot of the sort of

835
00:51:09,880 --> 00:51:13,800
Speaker 8:  like crypto bankruptcy proceedings, there are investors who show

836
00:51:13,800 --> 00:51:17,520
Speaker 8:  up. And so I'm curious if we're gonna see people who are FTX customers who

837
00:51:17,520 --> 00:51:20,840
Speaker 8:  are going to show up to see what happens and You know. The other thing that's

838
00:51:20,840 --> 00:51:23,680
Speaker 8:  like worth keeping in mind here is we've been talking about the sort of boring

839
00:51:23,680 --> 00:51:27,400
Speaker 8:  financial side of all of this, but there is this salacious human

840
00:51:27,400 --> 00:51:30,400
Speaker 8:  element that I am now going to talk about because Totally. I think that's

841
00:51:30,400 --> 00:51:33,120
Speaker 8:  one of the things that people are really interested in. You know questions

842
00:51:33,120 --> 00:51:36,760
Speaker 8:  about recreational drug use. A lot of the people within FTX were dating each

843
00:51:36,760 --> 00:51:40,480
Speaker 8:  other. I mean, Carolyn Ellison is Sam, Beckman Fried's, ex-girlfriend

844
00:51:40,700 --> 00:51:44,360
Speaker 8:  You know. And like someone who is likely to testify and who has already pled

845
00:51:44,360 --> 00:51:48,280
Speaker 8:  guilty is his childhood friend from Map camp. Like, oh, right. There's some

846
00:51:48,720 --> 00:51:52,680
Speaker 8:  operatic stuff going on. So I think that there's like, I don't

847
00:51:52,680 --> 00:51:56,440
Speaker 8:  know if we're gonna see necessarily people showing up dressed as Sam Bankman

848
00:51:56,450 --> 00:52:00,160
Speaker 8:  freed or in FTX gear, although we might, who knows?

849
00:52:00,500 --> 00:52:03,800
Speaker 8:  But I do think that there is a very, very high

850
00:52:03,890 --> 00:52:07,760
Speaker 8:  likelihood of like real fireworks. Because if you think about like

851
00:52:07,930 --> 00:52:10,600
Speaker 8:  David, you've worked at a startup too. If you think about what people are

852
00:52:10,600 --> 00:52:13,080
Speaker 8:  like when they're, you're working at startups like, especially because you're

853
00:52:13,080 --> 00:52:15,800
Speaker 8:  working these long hours and everybody's in their twenties and like you don't

854
00:52:15,800 --> 00:52:19,760
Speaker 8:  know what you're doing. Yep. It's just, just the case. There are shenanigans

855
00:52:20,020 --> 00:52:23,520
Speaker 8:  and these are shenanigans that are now going to be in the courtroom. And

856
00:52:23,520 --> 00:52:27,200
Speaker 8:  so like you can imagine in an attempt to discredit a witness, you might bring

857
00:52:27,200 --> 00:52:28,640
Speaker 8:  up some dumb stuff they did in the office.

858
00:52:29,270 --> 00:52:33,080
Speaker 2:  Yeah. Or in an effort to discredit the defendant, you might

859
00:52:33,080 --> 00:52:36,880
Speaker 2:  bring up a lot of their own personal shenanigans. And I, I do, I think you're

860
00:52:36,880 --> 00:52:40,240
Speaker 2:  right that there were a lot, there are a lot of shenanigans we know about

861
00:52:40,350 --> 00:52:44,080
Speaker 2:  because especially like since the man went on house arrest,

862
00:52:44,140 --> 00:52:47,360
Speaker 2:  he has, he had the most public house arrest of all time and just happily

863
00:52:47,470 --> 00:52:50,880
Speaker 2:  told anyone who asked about all the shenanigans going on, on going on at

864
00:52:50,960 --> 00:52:54,840
Speaker 2:  FTX. And yeah, I have a feeling there is a lot more to come.

865
00:52:54,940 --> 00:52:56,440
Speaker 2:  How long is this trial supposed to be?

866
00:52:56,870 --> 00:53:00,120
Speaker 8:  It's scheduled for about five weeks. It may run a little longer or a little

867
00:53:00,120 --> 00:53:03,560
Speaker 8:  shorter, but I, I will be in New York City for all of October in the first

868
00:53:03,560 --> 00:53:06,320
Speaker 8:  couple weeks in November. I'm actually turning 40 while in there. Ah,

869
00:53:06,570 --> 00:53:10,560
Speaker 2:  Happy almost birthday. Very. Thank you. Tell Sam that he, you owes you, this

870
00:53:10,560 --> 00:53:10,920
Speaker 2:  is how I'm

871
00:53:10,920 --> 00:53:12,200
Speaker 8:  Celebrating. Yeah, it's,

872
00:53:12,230 --> 00:53:15,680
Speaker 2:  It's, it's, it feels very fitting for you as actually is how to celebrate

873
00:53:15,680 --> 00:53:17,200
Speaker 2:  your birthday. This feels right,

874
00:53:17,580 --> 00:53:21,360
Speaker 8:  But yeah, I You know, I think that there's, there's a lot to come

875
00:53:21,540 --> 00:53:25,240
Speaker 8:  and I, I really can't wait to find out what kind of evidence

876
00:53:25,340 --> 00:53:28,760
Speaker 8:  I'm gonna see because You know there's a lot of stuff that as a reporter,

877
00:53:29,520 --> 00:53:33,000
Speaker 8:  I just love being in other people's business. I'm a huge gossip. Like that's

878
00:53:33,000 --> 00:53:36,200
Speaker 8:  just the truth of the matter. Like I was that before I was a reporter, I

879
00:53:36,200 --> 00:53:39,480
Speaker 8:  grew up in a small town. Gossip was a contact sport. Like this is like a

880
00:53:39,480 --> 00:53:43,320
Speaker 8:  game I love. And the government can get ahold of so much more juicy info

881
00:53:43,480 --> 00:53:47,400
Speaker 8:  than I can. Like I would love to see the due diligence

882
00:53:47,400 --> 00:53:51,280
Speaker 8:  that Sequoia did. Like I would love it. I never get to see that stuff.

883
00:53:51,500 --> 00:53:53,680
Speaker 8:  So this is the kind of thing that I'm really hyped for.

884
00:53:54,020 --> 00:53:57,280
Speaker 2:  It is a really underrated thing. I had this experience being in the, the

885
00:53:57,280 --> 00:54:00,880
Speaker 2:  courtroom for U S V Google for a couple of the sort of bigger named

886
00:54:01,060 --> 00:54:04,840
Speaker 2:  people, the people who a never meet with

887
00:54:05,110 --> 00:54:08,600
Speaker 2:  reporters most of the time. s Bankman free is sort of unusual in that he

888
00:54:08,600 --> 00:54:11,400
Speaker 2:  loved talking to reporters, but most of the time these people either never

889
00:54:11,400 --> 00:54:15,160
Speaker 2:  tell the truth or never meet with reporters in general, but just

890
00:54:15,560 --> 00:54:17,680
Speaker 2:  watching them sit there and they're, it's like, oh, they have to tell the

891
00:54:17,680 --> 00:54:20,920
Speaker 2:  truth now and they have to say it out loud and I get to just sit here and

892
00:54:20,920 --> 00:54:24,600
Speaker 2:  listen to it. It's the best It rules. Sometimes it's very boring and

893
00:54:24,760 --> 00:54:27,320
Speaker 2:  procedural and it takes a long time, but eventually they have to answer the

894
00:54:27,440 --> 00:54:28,680
Speaker 2:  question and it's kind of great.

895
00:54:30,840 --> 00:54:33,280
Speaker 2:  Alright, well we're gonna check in a bunch over the course of this trial,

896
00:54:33,280 --> 00:54:36,440
Speaker 2:  like you said, it's, it's long. I suspect if I had to guess, I would say

897
00:54:36,440 --> 00:54:39,880
Speaker 2:  it's gonna kind of ebb and flow. There's gonna be a lot of really

898
00:54:40,170 --> 00:54:44,160
Speaker 2:  wonky talk about how money moves around. But then we're gonna get

899
00:54:44,160 --> 00:54:46,720
Speaker 2:  a lot of shenanigans and we're gonna check in on both of those things.

900
00:54:47,150 --> 00:54:50,400
Speaker 8:  I'll tell you what David, because I, I don't know how many of our listeners

901
00:54:50,420 --> 00:54:53,520
Speaker 8:  are aware of like the sort of the reporting that goes on, but because there's

902
00:54:53,520 --> 00:54:57,240
Speaker 8:  a limited amount of people that just a limited physical number of bodies

903
00:54:57,240 --> 00:55:00,360
Speaker 8:  that can fit in that courtroom, I'm usually like, for something like this,

904
00:55:00,460 --> 00:55:04,040
Speaker 8:  I'm gonna be standing outside at like an unholy hour in the morning. And

905
00:55:04,040 --> 00:55:07,920
Speaker 8:  so if there are shenanigans, I have some time where I'm doing

906
00:55:07,920 --> 00:55:11,440
Speaker 8:  nothing standing on the streets of New York City. And so yes, I will be calling

907
00:55:11,500 --> 00:55:13,920
Speaker 8:  in. You'll get to hear the cell phone report. This is

908
00:55:13,920 --> 00:55:16,120
Speaker 2:  What I like to hear. All right, thanks Liz. We'll talk

909
00:55:16,200 --> 00:55:17,800
Speaker 8:  Again soon. Alright. Bye David.

910
00:55:18,390 --> 00:55:21,400
Speaker 2:  Alright, we gotta take one more break and then we're gonna get to The Vergecast

911
00:55:21,400 --> 00:55:22,520
Speaker 2:  hotline. We'll be right back.

912
00:56:32,850 --> 00:56:36,820
Speaker 2:  Welcome back. Let's answer a question from The Vergecast hotline as we

913
00:56:36,820 --> 00:56:40,100
Speaker 2:  do on this show every week. As a reminder, the hotline number is

914
00:56:40,100 --> 00:56:43,900
Speaker 2:  eight six six Verge one, one call and ask us all of your

915
00:56:43,900 --> 00:56:47,780
Speaker 2:  best tech questions. No question, too big, no question. Too weird. The weirder

916
00:56:47,780 --> 00:56:51,340
Speaker 2:  the better. If I'm being honest with you. We've gotten some amazing questions

917
00:56:51,660 --> 00:56:54,780
Speaker 2:  recently. Thank you for all of your most bonkers thoughts about all things

918
00:56:54,780 --> 00:56:57,980
Speaker 2:  technology. Oh, and if you don't wanna call or can't, you can always email

919
00:56:57,980 --> 00:57:01,260
Speaker 2:  us Vergecast at The Verge dot com. That works just as well.

920
00:57:01,690 --> 00:57:03,540
Speaker 2:  Today's question comes from Zach.

921
00:57:04,800 --> 00:57:08,700
Speaker 13:  Hi, this is Zach. I'm in Milwaukee, Wisconsin. My daughter is a

922
00:57:09,060 --> 00:57:12,580
Speaker 13:  voracious reader, very proud dad. It also means she just goes through

923
00:57:12,890 --> 00:57:16,220
Speaker 13:  tons of library books. Basically anytime we go to a bookstore, she's picking

924
00:57:16,280 --> 00:57:20,220
Speaker 13:  up something. I kind of don't know where to go as far as

925
00:57:20,980 --> 00:57:24,700
Speaker 13:  a electronic reader. This feels like a really natural holiday gift.

926
00:57:25,080 --> 00:57:28,620
Speaker 13:  But do I just go for the iPad because it's got the most access to apps,

927
00:57:28,870 --> 00:57:32,460
Speaker 13:  especially things like hoopla, things that work with the local library system.

928
00:57:33,060 --> 00:57:36,820
Speaker 13:  I don't want to really get super locked into a an into an ecosystem. But

929
00:57:36,820 --> 00:57:40,620
Speaker 13:  on the other hand, like if you go with the E Ink, it's not gonna

930
00:57:40,620 --> 00:57:44,420
Speaker 13:  use for anything else. It's just gonna be for for reading. But then it doesn't

931
00:57:44,420 --> 00:57:47,740
Speaker 13:  have access to those, those library apps. And, and we're kind of back to

932
00:57:47,740 --> 00:57:51,380
Speaker 13:  square one spending You know 10 to $15 for every single book,

933
00:57:51,380 --> 00:57:55,020
Speaker 13:  especially books you will read once I, I don't know what the correct answer

934
00:57:55,020 --> 00:57:58,420
Speaker 13:  is. So light up the crayon signal and

935
00:57:59,000 --> 00:58:02,060
Speaker 13:  get me the best information you've got. Thanks. Bye.

936
00:58:03,010 --> 00:58:06,590
Speaker 2:  Ask and you shall receive. We lit up the crayon signal. Alex. Cranz is here.

937
00:58:06,610 --> 00:58:07,070
Speaker 2:  Hi Alex.

938
00:58:07,690 --> 00:58:10,350
Speaker 14:  Hi. Oh my God, this is a great question, right?

939
00:58:10,480 --> 00:58:14,390
Speaker 2:  There are so many layers to this question in ways that I find so

940
00:58:14,390 --> 00:58:18,310
Speaker 2:  very interesting. So let me just try and like lay the land for you here

941
00:58:18,450 --> 00:58:22,390
Speaker 2:  and see if you think about this the way that I do. Okay. There's like a hardware

942
00:58:22,390 --> 00:58:25,990
Speaker 2:  and a software question here. I think we can immediately rule out buying

943
00:58:26,070 --> 00:58:29,710
Speaker 2:  a Kindle. Yes. Because we don't wanna be tethered to one

944
00:58:29,710 --> 00:58:33,270
Speaker 2:  ecosystem, right? Fair, yeah. Good on that. Okay. So I think we're, we're

945
00:58:33,270 --> 00:58:36,430
Speaker 2:  basically in one of three places now. We, we can either tell our buddies

946
00:58:36,430 --> 00:58:40,350
Speaker 2:  Zach to buy an iPad. We can tell our friends Zach to buy a different

947
00:58:40,850 --> 00:58:44,430
Speaker 2:  EIN ebook reader, which is, i I know you're gonna have several thoughts about

948
00:58:44,430 --> 00:58:48,390
Speaker 2:  certain brands that may or may not exist in America but are possible

949
00:58:48,390 --> 00:58:52,270
Speaker 2:  to find or you can buy a different Android

950
00:58:52,270 --> 00:58:55,070
Speaker 2:  tablet. Those seem like the three categories. Am I missing anything?

951
00:58:55,430 --> 00:58:59,190
Speaker 14:  I, I think that's exactly right. Okay. Because the Kindle, Kindle

952
00:58:59,210 --> 00:59:02,630
Speaker 14:  can work with some libraries, but it only works with Libby and and

953
00:59:02,740 --> 00:59:06,150
Speaker 14:  Overdrive and that's not like the only library ecosystem

954
00:59:06,610 --> 00:59:07,390
Speaker 14:  out there. And it's

955
00:59:07,390 --> 00:59:10,990
Speaker 2:  Also kind of wacky and complicated and yeah, they just haven't done a good

956
00:59:10,990 --> 00:59:11,750
Speaker 2:  job of that for

957
00:59:11,780 --> 00:59:15,750
Speaker 14:  Kids. Like it's very involved and Cobo has kind of

958
00:59:15,750 --> 00:59:18,910
Speaker 14:  built itself as like, oh you can use it for your library books and all these

959
00:59:18,910 --> 00:59:22,200
Speaker 14:  other kinds of reading. Like I think it's got pocket built in or it used

960
00:59:22,200 --> 00:59:26,040
Speaker 14:  to, it's also not really great 'cause again, it's really limited

961
00:59:26,220 --> 00:59:29,720
Speaker 14:  to overdrive and otherwise you're gonna be like teaching your daughter how

962
00:59:29,720 --> 00:59:33,400
Speaker 14:  to side load stuff and that is a great skill she should have.

963
00:59:33,680 --> 00:59:37,160
Speaker 14:  Like I highly encourage you doing that. I don't know if this is the time

964
00:59:37,160 --> 00:59:38,400
Speaker 14:  you want to do that.

965
00:59:38,880 --> 00:59:39,080
Speaker 2:  Yeah.

966
00:59:39,180 --> 00:59:41,240
Speaker 14:  So I don't wanna get into your parenting. Like

967
00:59:41,540 --> 00:59:44,520
Speaker 2:  You teach your kids to side load whenever feels right to you. Yeah.

968
00:59:44,520 --> 00:59:48,040
Speaker 14:  That's a very personal moment for you and your daughter. So yeah, it really

969
00:59:48,040 --> 00:59:51,960
Speaker 14:  is like, okay, do you wanna go iPad and You know it's more likely to,

970
00:59:52,100 --> 00:59:54,840
Speaker 14:  she can crack it and break it and, and make it more difficult to use, a

971
00:59:54,840 --> 00:59:58,800
Speaker 14:  lot easier than a lot of other devices. But it is very, very flexible.

972
00:59:58,900 --> 01:00:02,280
Speaker 14:  But also like you could catch your plane Roblox on it or

973
01:00:02,920 --> 01:00:05,560
Speaker 14:  watching YouTube. Like there's a lot of things that can happen there. Or

974
01:00:05,560 --> 01:00:09,400
Speaker 14:  you can go with something like probably the best brand and I've, I've

975
01:00:09,400 --> 01:00:12,360
Speaker 14:  mentioned it a bunch of times on the show and David already knows what I'm

976
01:00:12,360 --> 01:00:13,360
Speaker 14:  gonna say, which is books

977
01:00:14,000 --> 01:00:15,640
Speaker 2:  B O O X we should say Yeah.

978
01:00:16,000 --> 01:00:19,920
Speaker 14:  B O O X. And they're probably the best at like Android e

979
01:00:19,940 --> 01:00:23,640
Speaker 14:  Ink tablets. I'm a little hesitant to say go that route just because

980
01:00:24,260 --> 01:00:28,160
Speaker 14:  she is a child. And like it can be a little complicated. And so

981
01:00:28,180 --> 01:00:32,000
Speaker 14:  you will probably still have to teach her the side loading situation but

982
01:00:32,000 --> 01:00:35,960
Speaker 14:  also a whole bunch of other things. And like if you want your

983
01:00:36,040 --> 01:00:39,960
Speaker 14:  daughter to be really, really understanding of how technology works, the

984
01:00:39,960 --> 01:00:43,840
Speaker 14:  books is the best way to go. If you don't wanna also be participating

985
01:00:43,840 --> 01:00:47,600
Speaker 14:  in that educational activity, the iPad or like an

986
01:00:47,600 --> 01:00:50,920
Speaker 14:  Android tablets, like a traditional Android tablet feels right.

987
01:00:51,110 --> 01:00:54,760
Speaker 2:  Yeah. My my heart wants books to be the answer

988
01:00:54,910 --> 01:00:58,640
Speaker 2:  because in theory that combination of, it's almost

989
01:00:58,640 --> 01:01:01,760
Speaker 2:  exclusively a reading device, but I also need all the other apps because

990
01:01:01,760 --> 01:01:05,640
Speaker 2:  there are lots of places you read, not just in the one ebook system, right?

991
01:01:05,830 --> 01:01:09,720
Speaker 2:  Like yes, what an incredibly common use case that no one

992
01:01:09,740 --> 01:01:13,720
Speaker 2:  has fixed. I want books to be the answer, but I I do agree. I think for

993
01:01:13,790 --> 01:01:17,680
Speaker 2:  most people the book's version of Android

994
01:01:17,900 --> 01:01:21,760
Speaker 2:  is just like somewhere between one and five ticks too complicated

995
01:01:21,860 --> 01:01:22,560
Speaker 2:  to really work.

996
01:01:22,940 --> 01:01:25,880
Speaker 14:  I'm using like the, the most recent color one and it's got the most recent

997
01:01:26,160 --> 01:01:29,960
Speaker 14:  software on it, night and day difference really in onboarding

998
01:01:29,960 --> 01:01:33,800
Speaker 14:  versus, yeah, like the Google Play store is built in now. So you can

999
01:01:33,800 --> 01:01:37,040
Speaker 14:  just start using the Google Play store whereas before you had, you would've

1000
01:01:37,040 --> 01:01:40,760
Speaker 14:  had to teach your daughter about patients and, and waiting for 24 hours

1001
01:01:40,900 --> 01:01:44,720
Speaker 14:  for Google to register the device. After you register it, now you can just

1002
01:01:45,130 --> 01:01:48,800
Speaker 14:  start using it. So the, it has improved a

1003
01:01:49,160 --> 01:01:53,080
Speaker 14:  lot and, and there's some pretty affordable ones there. You know, there's,

1004
01:01:53,080 --> 01:01:55,760
Speaker 14:  there's some, I think like the pokey three is like

1005
01:01:56,680 --> 01:02:00,480
Speaker 14:  $150. Maybe it's, it's a little more affordable. I definitely

1006
01:02:00,480 --> 01:02:04,280
Speaker 14:  would look into it and have a serious conversation with yourself on how

1007
01:02:04,280 --> 01:02:07,960
Speaker 14:  much you are willing to troubleshoot things. 'cause I think it's still gonna

1008
01:02:07,960 --> 01:02:11,400
Speaker 14:  require it, even with a software update, there's still gonna be more handholding

1009
01:02:11,400 --> 01:02:15,320
Speaker 14:  than with an iPad, but it's probably gonna get you closer to that experience

1010
01:02:15,320 --> 01:02:18,880
Speaker 14:  you're looking for. So yeah, it just depends on like how often do you wanna

1011
01:02:18,880 --> 01:02:21,640
Speaker 14:  have to answer tech questions for your daughter

1012
01:02:22,000 --> 01:02:25,840
Speaker 2:  Fair. Can I throw one wrench in here that I Oh yes. Am not

1013
01:02:25,880 --> 01:02:28,360
Speaker 2:  a hundred percent sure I think is a good idea, but I think might be a good

1014
01:02:28,360 --> 01:02:32,280
Speaker 2:  idea, which is one of Amazon's tablets. My

1015
01:02:32,330 --> 01:02:36,080
Speaker 2:  hesitation with all tablets, whether they run Android or iOS,

1016
01:02:36,420 --> 01:02:40,040
Speaker 2:  is that they have all the apps. That's true. But

1017
01:02:40,180 --> 01:02:43,960
Speaker 2:  buying stuff on those devices is a gigantic pain in the ass

1018
01:02:44,030 --> 01:02:47,880
Speaker 2:  because of the way that Google and Apple run those platforms. You can't buy

1019
01:02:47,880 --> 01:02:50,800
Speaker 2:  Kindle books in the Kindle app. You know where you can buy Kindle books in

1020
01:02:50,800 --> 01:02:54,720
Speaker 2:  the Kindle app and buy other things in other apps is on the fire tablets.

1021
01:02:55,340 --> 01:02:59,240
Speaker 2:  And those tablets aren't like amazing hardware. But like the, the fire

1022
01:02:59,500 --> 01:03:03,200
Speaker 2:  HD plus eight inch has a decent screen. It's pretty

1023
01:03:03,250 --> 01:03:05,960
Speaker 2:  rough and tumble. You're not really gonna break it if you beat it up. They

1024
01:03:05,960 --> 01:03:09,720
Speaker 2:  make a kid's version that's even more rugged and it's $70. Like,

1025
01:03:10,160 --> 01:03:13,880
Speaker 2:  I, I cannot explain enough how much more expensive

1026
01:03:13,880 --> 01:03:17,560
Speaker 2:  every other tablet is. This one is not a great tablet. But if, if

1027
01:03:17,560 --> 01:03:21,240
Speaker 2:  truly all you want is a reading device, this feels like it might be enough.

1028
01:03:21,900 --> 01:03:25,720
Speaker 14:  It might be, I think you'd have to double check on what apps will work with

1029
01:03:25,720 --> 01:03:29,360
Speaker 14:  it because it's still like Amazon's thing and they want you to buy their

1030
01:03:29,360 --> 01:03:31,880
Speaker 14:  books. Right. They don't, won't necess like they might make it difficult.

1031
01:03:32,480 --> 01:03:36,240
Speaker 14:  I, I don't know the state of like the Libby app on on a fire

1032
01:03:36,260 --> 01:03:40,080
Speaker 14:  tablet or, or the hoopla or whatever. So you

1033
01:03:40,320 --> 01:03:42,880
Speaker 14:  probably would need to do just a touch of research there. 'cause I haven't

1034
01:03:42,880 --> 01:03:43,640
Speaker 14:  used one in a little bit.

1035
01:03:43,750 --> 01:03:47,080
Speaker 2:  It's definitely significantly more open than the Kindle, but significantly

1036
01:03:47,230 --> 01:03:51,080
Speaker 2:  less open than like full Android. You're still getting Amazon's spin

1037
01:03:51,100 --> 01:03:52,880
Speaker 2:  on Android. That's definitely true. Yeah.

1038
01:03:53,020 --> 01:03:56,960
Speaker 14:  But if it's got the apps, it's probably like the most affordable

1039
01:03:57,100 --> 01:04:00,320
Speaker 14:  and like easiest to use of it. It just requires like

1040
01:04:00,630 --> 01:04:04,080
Speaker 14:  quadruple checking that the app is available for it also. It's like a hundred

1041
01:04:04,080 --> 01:04:07,600
Speaker 14:  bucks and easy to return. So if you get it and it doesn't work, return it.

1042
01:04:07,900 --> 01:04:11,120
Speaker 14:  Buy books, buy an iPad and you'll be happy.

1043
01:04:11,550 --> 01:04:15,200
Speaker 2:  Yeah. I I will say I think we're probably aligned on this one that like if

1044
01:04:15,200 --> 01:04:18,600
Speaker 2:  money is no object and you're not worried about like breaking the thing,

1045
01:04:18,600 --> 01:04:22,440
Speaker 2:  the iPad mini is the correct answer. Right? It is like objectively the best

1046
01:04:22,440 --> 01:04:24,080
Speaker 2:  device of all these devices. Yeah,

1047
01:04:24,240 --> 01:04:28,200
Speaker 14:  I I I try to switch between my, my e-reader and my iPad mini a lot

1048
01:04:28,660 --> 01:04:31,960
Speaker 14:  and I'll oftentimes will find my, like my iPad mini just does more stuff

1049
01:04:32,300 --> 01:04:36,240
Speaker 14:  so I use it more. But I love having my, my e-reader.

1050
01:04:36,280 --> 01:04:40,000
Speaker 14:  I love being able to read it outside. I love it for just focus and I think

1051
01:04:40,000 --> 01:04:43,440
Speaker 14:  for a kid it's prob that might actually be a good thing in some cases, right?

1052
01:04:43,470 --> 01:04:47,320
Speaker 14:  Like they gotta focus on the reading and not just go off on a tear

1053
01:04:47,320 --> 01:04:50,440
Speaker 14:  being like, I wonder like when you read a chapter in a book and you're like,

1054
01:04:50,440 --> 01:04:53,680
Speaker 14:  oh that's interesting and you immediately go Google it on your iPad. That's

1055
01:04:53,680 --> 01:04:57,240
Speaker 14:  easy on your, on your e-reader. You have to wait and do it later and

1056
01:04:57,300 --> 01:04:59,880
Speaker 14:  that's kind of nice. 'cause then you just keep reading,

1057
01:04:59,970 --> 01:05:02,520
Speaker 2:  Right? Yeah. It's either a feature or a bug depending on how you look at

1058
01:05:02,520 --> 01:05:06,440
Speaker 2:  it. And I think that has a lot to do with it. So I think we're aligned on

1059
01:05:06,440 --> 01:05:09,760
Speaker 2:  that. I would say if you're feeling ambitious, Zach,

1060
01:05:10,340 --> 01:05:14,120
Speaker 2:  buy a books device. See how it feels. My sense would be it will

1061
01:05:14,190 --> 01:05:18,000
Speaker 2:  immediately be obvious to you if it's more and more

1062
01:05:18,000 --> 01:05:21,360
Speaker 2:  work than you want, right? Yeah. Like you're gonna take the thing outta the

1063
01:05:21,360 --> 01:05:24,560
Speaker 2:  box, turn it on and immediately just be like, Nope. Or you're gonna be like,

1064
01:05:24,560 --> 01:05:27,800
Speaker 2:  oh this solves all my problems. Right. That's that seems it. It will not

1065
01:05:27,800 --> 01:05:29,480
Speaker 2:  be unclear. I wouldn't think it, it,

1066
01:05:29,480 --> 01:05:31,880
Speaker 14:  Yeah, it will not be unclear. You're gonna know really, really quickly.

1067
01:05:32,020 --> 01:05:35,840
Speaker 14:  And generally speaking, the new, the new operating system, the new

1068
01:05:35,840 --> 01:05:38,400
Speaker 14:  version they've rolled out has been really, really good. They're very good

1069
01:05:38,400 --> 01:05:41,920
Speaker 14:  about like getting the latest version of Android on things. You just can't

1070
01:05:41,940 --> 01:05:45,920
Speaker 14:  use 70% of Android 'cause it's not meant for a black and white

1071
01:05:46,500 --> 01:05:49,320
Speaker 14:  tablet. Yeah, that's so like you can watch YouTube on it. Don't

1072
01:05:50,260 --> 01:05:53,560
Speaker 2:  If you Yeah, it's a specific kind of torture trying to watch

1073
01:05:53,950 --> 01:05:57,920
Speaker 2:  YouTube on a device like that. So my other question for you is where do

1074
01:05:57,920 --> 01:06:00,680
Speaker 2:  you buy your eBooks? I realized in prepping for this that I

1075
01:06:01,520 --> 01:06:04,960
Speaker 2:  accidentally just became sort of Amazon exclusive like a million years ago.

1076
01:06:05,480 --> 01:06:08,640
Speaker 2:  I loved the Kindle and had a bunch of Kindle books and now that's where all

1077
01:06:08,640 --> 01:06:12,560
Speaker 2:  my books are. So I have kept buying Kindle books and like, am I here to tell

1078
01:06:12,560 --> 01:06:15,600
Speaker 2:  you that the Caliber app exists and does a really good job of stripping d

1079
01:06:15,600 --> 01:06:18,280
Speaker 2:  r m from your Kindle books so that you can use them on other devices? No,

1080
01:06:18,280 --> 01:06:21,440
Speaker 2:  that's not what I'm here to tell you. It's true. And the app is free and

1081
01:06:21,440 --> 01:06:24,440
Speaker 2:  open source and it strips d r m from all your eBooks. So you can use them

1082
01:06:24,440 --> 01:06:28,240
Speaker 2:  on other devices, but that's not the point. My question for you is where

1083
01:06:28,240 --> 01:06:30,680
Speaker 2:  do you get your eBooks, if not from Amazon? I

1084
01:06:30,680 --> 01:06:34,440
Speaker 14:  Originally started with Nook and then I found Caliber and, and

1085
01:06:34,590 --> 01:06:38,120
Speaker 14:  made the switch to Amazon and took my whole Nook library with me, which

1086
01:06:38,120 --> 01:06:41,560
Speaker 14:  was really, really nice. And then I was at Amazon for a while and then,

1087
01:06:41,560 --> 01:06:45,280
Speaker 14:  then I was like, I feel weird being in this one ecosystem. So I switched

1088
01:06:45,310 --> 01:06:49,040
Speaker 14:  back to Nook and brought all my books back via Caliber. And so now

1089
01:06:49,100 --> 01:06:53,040
Speaker 14:  I'm usually like, I, I tend to go Nook, but I've got a couple

1090
01:06:53,040 --> 01:06:56,080
Speaker 14:  of like, there's ebooks.com, there's a couple of other ones and I'll kind

1091
01:06:56,080 --> 01:06:59,160
Speaker 14:  of look around. 'cause sometimes the stories, the selection is different.

1092
01:06:59,340 --> 01:07:03,240
Speaker 14:  And honestly, Amazon has a ton of books. It's gotten so big

1093
01:07:03,240 --> 01:07:06,560
Speaker 14:  with self-publishing that a lot of like self-published books, somebody will

1094
01:07:06,560 --> 01:07:09,680
Speaker 14:  say, oh, you gotta read this. It's really good. It's only available at Amazon,

1095
01:07:09,680 --> 01:07:13,000
Speaker 14:  which is super frustrating. And also sometimes I'll just buy it directly

1096
01:07:13,070 --> 01:07:17,000
Speaker 14:  from the, the publisher and the author gets more

1097
01:07:17,000 --> 01:07:20,680
Speaker 14:  money that way. So that's if you really are supporting an author, buying

1098
01:07:20,680 --> 01:07:24,120
Speaker 14:  it directly from their poper if available best way to buy the books.

1099
01:07:24,470 --> 01:07:24,960
Speaker 14:  Yeah, and

1100
01:07:24,960 --> 01:07:28,720
Speaker 2:  You can usually, if You know what you wanna buy, if you just Google the title

1101
01:07:28,900 --> 01:07:32,600
Speaker 2:  and ebook, you can pretty quickly find that publisher website usually and,

1102
01:07:32,620 --> 01:07:36,200
Speaker 2:  and get the book that way. That's a good trick. What I wish existed like

1103
01:07:36,280 --> 01:07:39,960
Speaker 2:  bookshop.org, which is this amazing website for buying physical books from

1104
01:07:39,960 --> 01:07:43,840
Speaker 2:  like actual bookstores that are better citizens of the publishing

1105
01:07:43,840 --> 01:07:47,760
Speaker 2:  world than your Amazon's. I love that website and I wish something like it

1106
01:07:47,760 --> 01:07:51,680
Speaker 2:  existed for eBooks. It feels like ebooks.com is like kind of that

1107
01:07:51,780 --> 01:07:52,400
Speaker 2:  but not quite.

1108
01:07:52,820 --> 01:07:56,720
Speaker 14:  Ebooks.com is kind of doing that. Libro FM

1109
01:07:56,910 --> 01:08:00,440
Speaker 14:  does that, but it's almost exclusively audio books. I spend like

1110
01:08:00,440 --> 01:08:04,000
Speaker 14:  $15 a month there and it gives me one book credit and that's nice. And I

1111
01:08:04,000 --> 01:08:07,880
Speaker 14:  know I'm supporting a, an author and I'm supporting my local bookstore,

1112
01:08:07,910 --> 01:08:11,360
Speaker 14:  like feels great. You can also find your local bookstores. A lot of 'em

1113
01:08:11,560 --> 01:08:14,680
Speaker 14:  actually will have partnerships with Booksellers online and be like, oh

1114
01:08:14,680 --> 01:08:18,480
Speaker 14:  yeah, you, you can go here and buy any ebook from us at

1115
01:08:18,480 --> 01:08:22,240
Speaker 14:  this. They often will have garbage websites, but if you wanna

1116
01:08:22,240 --> 01:08:25,480
Speaker 14:  support your local bookstore, that's the way to do it. It just unfortunately

1117
01:08:25,480 --> 01:08:28,200
Speaker 14:  requires more work than logging into Amazon.

1118
01:08:28,540 --> 01:08:31,200
Speaker 2:  The only thing I would add to your list of websites, which is, which is very

1119
01:08:31,200 --> 01:08:35,000
Speaker 2:  good and I just am going to go sign up for Libro FM right now, is there's

1120
01:08:35,000 --> 01:08:38,800
Speaker 2:  this website called BookBub, B O O K B U b.com. And

1121
01:08:38,860 --> 01:08:42,840
Speaker 2:  its whole thing is just spectacular deals on eBooks from

1122
01:08:42,840 --> 01:08:46,800
Speaker 2:  around the internet. And so it's like not a place to go if you're like,

1123
01:08:46,920 --> 01:08:50,480
Speaker 2:  I wanna read this specific brand new book. But if you're just like, I like

1124
01:08:50,720 --> 01:08:54,320
Speaker 2:  spy novels, let me know when I can get a spy novel for a dollar

1125
01:08:54,320 --> 01:08:58,000
Speaker 2:  99 as an ebook. They send emails and it has

1126
01:08:58,000 --> 01:09:01,680
Speaker 2:  become my like most quickly clicked email every week because

1127
01:09:01,710 --> 01:09:05,680
Speaker 2:  it's just nonstop ebook deals and it's great and I use it all the time. So

1128
01:09:05,680 --> 01:09:06,360
Speaker 2:  highly recommend

1129
01:09:06,460 --> 01:09:08,880
Speaker 14:  I'm doing that as soon as we're done with this podcast.

1130
01:09:09,440 --> 01:09:12,400
Speaker 2:  I think we've helped. Right this, this feels, Zach, let us know what you

1131
01:09:12,400 --> 01:09:16,360
Speaker 2:  end up doing. I think your instincts are good and if you, if you buy a books

1132
01:09:16,360 --> 01:09:19,360
Speaker 2:  and you love it, it will warm Alex's heart, so let us know. It will,

1133
01:09:19,420 --> 01:09:19,760
Speaker 14:  It will

1134
01:09:19,990 --> 01:09:21,520
Speaker 2:  Alex. Thank you. Appreciate it as always.

1135
01:09:21,860 --> 01:09:22,280
Speaker 14:  Always.

1136
01:09:26,350 --> 01:09:26,840
Speaker 1:  Alright,

1137
01:09:26,840 --> 01:09:29,720
Speaker 2:  That's it for the Vergecast today. Thanks to everybody who came on the show

1138
01:09:29,720 --> 01:09:33,400
Speaker 2:  today, and thank you as always for listening as ever. There is lots more

1139
01:09:33,400 --> 01:09:36,400
Speaker 2:  from everything we talked about at The Verge dot com. We're covering all

1140
01:09:36,400 --> 01:09:39,560
Speaker 2:  of these trials pretty closely, so we'll put some links in the show notes,

1141
01:09:39,580 --> 01:09:42,880
Speaker 2:  but also we're posting all over The Verge dot com as everything happens.

1142
01:09:43,060 --> 01:09:46,640
Speaker 2:  So keep an eye on the website also, if you have thoughts, questions, feelings,

1143
01:09:46,740 --> 01:09:50,040
Speaker 2:  or tips on how to improve my handwriting because I'm not allowed to have

1144
01:09:50,040 --> 01:09:53,160
Speaker 2:  electronics in the courtroom. You can always email us at Vergecast at The

1145
01:09:53,240 --> 01:09:57,160
Speaker 2:  Verge dot com or keep calling the hotline. 8 6 6 Verge one, one. we love

1146
01:09:57,160 --> 01:10:00,280
Speaker 2:  hearing from you. Send us all your thoughts and questions and ideas for what

1147
01:10:00,280 --> 01:10:03,080
Speaker 2:  we should do on the show. We do at least one hotline question every week,

1148
01:10:03,300 --> 01:10:06,600
Speaker 2:  so please keep 'em coming. This show is produced by Andrew Marino and Liam

1149
01:10:06,600 --> 01:10:10,480
Speaker 2:  James. Brooke Miners is our editorial director of Audio Vergecast is Verge

1150
01:10:10,480 --> 01:10:14,080
Speaker 2:  production and part of the Vox Media podcast network. Neli, Alex and I will

1151
01:10:14,080 --> 01:10:17,800
Speaker 2:  be back on Friday to talk about the pixel event, the sphere in Vegas,

1152
01:10:18,380 --> 01:10:22,320
Speaker 2:  the sad fate of the $17,000 Apple Watch and all of the rest of this

1153
01:10:22,320 --> 01:10:24,760
Speaker 2:  week's tech news. We'll see you then. Rock and roll.

