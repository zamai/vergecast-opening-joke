1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 31b3157d-aa51-46b6-b052-288b966b3c7e
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/7213058233975953275/-5818870104695315226/s93290-US-4962s-1755253655.mp3
Description: GPT-5 is here, and it’s not going so well. This week on The Vergecast, Jake, Vee, and Hayden discuss the bumpy launch of OpenAI’s latest model and why GPT-5 isn’t as big of a leap as GPT-4. 

Then, everyone shares their vibe coding projects and the bumpy journey to making anything usable. After that, our newest segment: Corporate Shenanigans, where we rate the week in strange corporate moves on a scale from “actually serious” to “total joke.” 

Finally, the Thunder Round returns, new and improved, to discuss ditching your phone for a smartwatch, doctors relying too much on AI, AOL dial-up shutting down, the Pebble Time 2, and why you shouldn’t trust what AI chatbots say about themselves.


2
00:01:33,575 --> 00:01:37,325
Speaker 5:  Hello and welcome to The Vergecast, the flagship podcast of Unsatisfying

3
00:01:37,325 --> 00:01:41,085
Speaker 5:  Corporate Stunts. I'm Jake Kanakas, executive editor at The Verge, NELI

4
00:01:41,085 --> 00:01:43,965
Speaker 5:  David. Those guys are out on parental leave. They'll be back later this year

5
00:01:44,235 --> 00:01:48,165
Speaker 5:  with me today by Popular Demand VERGE Senior Reviewer V

6
00:01:48,165 --> 00:01:49,525
Speaker 5:  Song, hi Pop,

7
00:01:51,505 --> 00:01:55,485
Speaker 5:  and always in demand on The Vergecast. And now making her VERGE cast

8
00:01:55,535 --> 00:01:58,805
Speaker 5:  debut. We've got VERGE Senior AI Reporter, Hayden Field.

9
00:01:59,075 --> 00:02:00,565
Speaker 6:  Woo-hoo, psyched.

10
00:02:00,745 --> 00:02:03,685
Speaker 5:  So glad to have you both here. We've got a lot to talk about today. It was

11
00:02:03,765 --> 00:02:07,685
Speaker 5:  a big week for weird corporate stunts and lawsuits. We're gonna do a

12
00:02:07,685 --> 00:02:11,405
Speaker 5:  Corporate Shenanigans. Power hour disclosure may not be

13
00:02:11,605 --> 00:02:15,245
Speaker 5:  a full hour, but there will be a lot of shenanigans. I promise you that.

14
00:02:15,615 --> 00:02:19,525
Speaker 5:  We'll see how it goes. The thunder round is back and better than ever. But

15
00:02:19,525 --> 00:02:23,365
Speaker 5:  most importantly, we've got a lot more to talk about with GPT five

16
00:02:23,365 --> 00:02:26,605
Speaker 5:  because that launch did not go so well. It really

17
00:02:26,605 --> 00:02:27,085
Speaker 4:  Did not.

18
00:02:28,185 --> 00:02:32,085
Speaker 5:  So last week we recorded this show like literally, like they had just

19
00:02:32,085 --> 00:02:35,965
Speaker 5:  wrapped up. They had just wrapped up and now people have actually had a chance

20
00:02:35,965 --> 00:02:39,925
Speaker 5:  to use it. And they have thoughts and emotions a

21
00:02:39,925 --> 00:02:43,205
Speaker 5:  lot. There are people have a lot of emotions. So many emotions. What's

22
00:02:43,205 --> 00:02:46,885
Speaker 6:  That subreddit, the AR boyfriend subreddit. Oh yeah. They were really talking.

23
00:02:46,995 --> 00:02:47,485
Speaker 6:  They're

24
00:02:47,485 --> 00:02:51,285
Speaker 5:  Feeling it. It's, it's a meltdown. So people were furious that chat GPT

25
00:02:51,285 --> 00:02:55,125
Speaker 5:  removed the ability to use old models without warning. Open AI system

26
00:02:55,135 --> 00:02:58,885
Speaker 5:  won't do that again. People think G PT five is less friendly than GPT four.

27
00:02:59,185 --> 00:03:02,845
Speaker 5:  So open AI is updating his personality. And OpenAI, CEO

28
00:03:02,985 --> 00:03:06,965
Speaker 5:  Sam Altman had a fairly unsatisfying explanation for the

29
00:03:07,555 --> 00:03:11,005
Speaker 5:  atrocious atrocious bar graph crimes

30
00:03:11,275 --> 00:03:14,405
Speaker 5:  that we saw last week. That's very insane. So a lot of things went wrong

31
00:03:14,405 --> 00:03:17,725
Speaker 5:  with this launch. Before we get into the things that went wrong, can we all

32
00:03:17,865 --> 00:03:21,725
Speaker 5:  at least agree that the new splash screen on chat g

33
00:03:21,785 --> 00:03:24,885
Speaker 5:  BT, where it has a bunch of different colors is the biggest upgrade here?

34
00:03:25,095 --> 00:03:28,445
Speaker 5:  Right? They spent a ton of time on this model, but I like the colors. The

35
00:03:28,445 --> 00:03:29,285
Speaker 5:  colors are good. What colors?

36
00:03:29,565 --> 00:03:32,565
Speaker 6:  I thought they were vaguely appley. Like I looked at it, I was like, what

37
00:03:32,565 --> 00:03:33,685
Speaker 6:  is this an Apple app?

38
00:03:34,115 --> 00:03:37,325
Speaker 5:  Does Apple this just own the rainbow? Like they're just any

39
00:03:37,885 --> 00:03:38,605
Speaker 7:  T It did look a

40
00:03:38,605 --> 00:03:40,925
Speaker 6:  Little appley. It did look a little appley, right? Yeah. Like I was just

41
00:03:40,925 --> 00:03:44,245
Speaker 6:  kinda like, Hmm, I don't know how I feel about that, but I was like, Ooh,

42
00:03:44,245 --> 00:03:48,065
Speaker 6:  color. I don't know. We love color. We, we love colors. I actually big

43
00:03:48,065 --> 00:03:48,825
Speaker 6:  color proponent

44
00:03:48,825 --> 00:03:52,745
Speaker 5:  Here. The Chachi PT standard screen is kind of the most boring

45
00:03:52,805 --> 00:03:55,065
Speaker 5:  screen in existence. Like Google, Googles.

46
00:03:55,065 --> 00:03:55,665
Speaker 7:  It looks like a piece of paper.

47
00:03:56,365 --> 00:04:00,025
Speaker 5:  It does, yeah. Yeah. There's like nothing there for like the most

48
00:04:00,345 --> 00:04:03,985
Speaker 5:  advanced piece of technology in the world. It's, it's like a

49
00:04:04,035 --> 00:04:04,785
Speaker 5:  beige pc.

50
00:04:05,005 --> 00:04:08,305
Speaker 6:  It it is. And you know, I will admit, I was very surprised. I was like, Ooh,

51
00:04:08,885 --> 00:04:12,585
Speaker 6:  colors, this is, oh, this must be a significant

52
00:04:12,605 --> 00:04:14,305
Speaker 6:  launch. It that kind of

53
00:04:14,975 --> 00:04:18,345
Speaker 7:  Vibe to differentiate. 'cause the launch itself wasn't as exciting for people.

54
00:04:18,405 --> 00:04:20,185
Speaker 7:  So they knew the colors would would get 'em, you know,

55
00:04:20,245 --> 00:04:22,105
Speaker 6:  You know, it worked. It worked.

56
00:04:22,465 --> 00:04:26,305
Speaker 5:  I hope the colors stay. I don't know. I ran outta chat B of GPT five queries.

57
00:04:26,565 --> 00:04:29,625
Speaker 5:  And so now it's like back to, to like beige again. I don't know if that's

58
00:04:29,625 --> 00:04:31,665
Speaker 5:  just like, it was like an intro period or

59
00:04:31,835 --> 00:04:35,745
Speaker 7:  Maybe it was like a mind trick. Like they want you to want the colors,

60
00:04:36,005 --> 00:04:37,665
Speaker 7:  so they're trying to get you to like buy more

61
00:04:37,665 --> 00:04:40,825
Speaker 5:  Credits. Can I tell you something like, I'm gonna use this over clawed if

62
00:04:40,825 --> 00:04:44,745
Speaker 5:  I get those colors back. Like that was, somebody's gotta get

63
00:04:44,745 --> 00:04:45,825
Speaker 5:  on these interfaces. They

64
00:04:45,825 --> 00:04:49,345
Speaker 7:  Must have done an internal study. Like they had to be studying fuel conscious.

65
00:04:50,775 --> 00:04:54,705
Speaker 5:  Okay. But the main thing here is, right, people have been waiting for like,

66
00:04:54,845 --> 00:04:58,145
Speaker 5:  you know, two years or something for GPT five, right? Like

67
00:04:59,445 --> 00:05:02,865
Speaker 5:  OpenAI has built it up to be this almost like mythic launch, right? GPT five

68
00:05:02,935 --> 00:05:06,865
Speaker 5:  will be the next big one. And they've had a bunch of intermittent

69
00:05:06,915 --> 00:05:10,905
Speaker 5:  model launches in between. But I think there was this assumption, this promise

70
00:05:10,905 --> 00:05:14,025
Speaker 5:  that GBT five was gonna be the big one. And

71
00:05:14,775 --> 00:05:18,725
Speaker 5:  they came out, they had this event, And I, to me

72
00:05:19,005 --> 00:05:21,845
Speaker 5:  watching the event, it, it didn't really feel like there was any one key

73
00:05:21,845 --> 00:05:25,085
Speaker 5:  thing. And it feels like in the week after, we haven't really seen that.

74
00:05:25,245 --> 00:05:29,165
Speaker 5:  I guess Hayden, you've been reporting on this is, am

75
00:05:29,205 --> 00:05:33,125
Speaker 5:  I missing it or is it just not there? Like what happened and why are people

76
00:05:33,125 --> 00:05:34,125
Speaker 5:  like so upset?

77
00:05:34,515 --> 00:05:37,885
Speaker 7:  Exactly. You're right. It wa it just wasn't there. And I think that's why

78
00:05:37,885 --> 00:05:41,525
Speaker 7:  people were so upset. It was built up to be this really overhyped,

79
00:05:42,385 --> 00:05:46,285
Speaker 7:  mythic launch. Altman even tweeted a picture of the Death star

80
00:05:46,705 --> 00:05:50,685
Speaker 7:  the night before, which was like max level of hype. People

81
00:05:50,685 --> 00:05:54,125
Speaker 7:  were freaking out and then all of a sudden it comes out and it's just

82
00:05:54,395 --> 00:05:58,365
Speaker 7:  seen as kind of being incremental upgrades. Like it's better at coding, it's

83
00:05:58,365 --> 00:06:01,805
Speaker 7:  better at answering healthcare questions. They say it's better at creative

84
00:06:01,805 --> 00:06:04,805
Speaker 7:  writing. We'll get into that in a minute because a lot of people disagreed.

85
00:06:05,065 --> 00:06:08,685
Speaker 7:  But yeah, I mean it wasn't anything too crazy. It was just incremental,

86
00:06:09,065 --> 00:06:12,805
Speaker 7:  you know, steady upgrades, nothing huge.

87
00:06:13,145 --> 00:06:17,085
Speaker 7:  And part of that was the fact that it wasn't like a big compute jump either.

88
00:06:17,265 --> 00:06:20,965
Speaker 7:  The other models in between each one, it was like a 100 x jump.

89
00:06:21,315 --> 00:06:24,125
Speaker 7:  This one was a lot less, so they didn't have as much compute to work with.

90
00:06:24,465 --> 00:06:27,805
Speaker 7:  But yeah, I mean it wasn't that exciting. And people also thought it was

91
00:06:27,805 --> 00:06:30,605
Speaker 7:  way worse at writing than the previous model. It was mid,

92
00:06:30,765 --> 00:06:34,125
Speaker 6:  I gotta say I've been using it for the last week, very mid.

93
00:06:34,475 --> 00:06:37,125
Speaker 5:  What, what is it doing differently? It's just like a little more flowery

94
00:06:37,125 --> 00:06:37,525
Speaker 5:  or something.

95
00:06:37,785 --> 00:06:40,555
Speaker 6:  No, it was, it's like, it, it's, it admits

96
00:06:40,555 --> 00:06:41,995
Speaker 5:  It's, it's let Oh, it's work.

97
00:06:42,185 --> 00:06:44,715
Speaker 6:  Well, you know, it's been back and forth, right? Yeah. Yeah. 'cause people

98
00:06:44,715 --> 00:06:48,395
Speaker 6:  were like, you took my friend away. Which first of all, it's not your friend,

99
00:06:48,505 --> 00:06:52,155
Speaker 6:  it's just not your friend. Like, it was a little more matter of fact

100
00:06:52,375 --> 00:06:56,235
Speaker 6:  at first. And like when I was using it, I was like, oh, it's less like

101
00:06:56,645 --> 00:07:00,435
Speaker 6:  yappy great. I actually love that. And now it feels like

102
00:07:00,435 --> 00:07:04,035
Speaker 6:  they've tweaked it a bit to make it yapper, but not in a, in a,

103
00:07:04,215 --> 00:07:05,195
Speaker 6:  in a useful

104
00:07:05,255 --> 00:07:08,435
Speaker 7:  Way. They changed its personality because people were freaking out because

105
00:07:08,435 --> 00:07:12,035
Speaker 7:  it was more robotic cold, more like matter of fact, like you said,

106
00:07:12,205 --> 00:07:15,795
Speaker 7:  which I also appreciate. I kind of like that. But a lot of people missed

107
00:07:15,855 --> 00:07:19,795
Speaker 7:  the supportive vibes, the tone, the warmth, and they felt

108
00:07:19,795 --> 00:07:23,355
Speaker 7:  like their friend had been taken away. And also they just thought not your

109
00:07:23,355 --> 00:07:25,955
Speaker 7:  friend. Yeah, exactly. And they also just thought it was worse at writing.

110
00:07:25,955 --> 00:07:29,915
Speaker 7:  Like honestly, in the marketing materials that OpenAI put out, they

111
00:07:29,915 --> 00:07:33,515
Speaker 7:  were like, compare these two wedding toasts. One from GPT four oh and one

112
00:07:33,515 --> 00:07:37,435
Speaker 7:  from GPT five. And they were like, look at how much better the GPT five

113
00:07:37,495 --> 00:07:41,395
Speaker 7:  one is. And I actually thought the 4 0 1 was much better. Like the five

114
00:07:41,455 --> 00:07:45,315
Speaker 7:  one kind of sounded like it was written by Cha GPT, the 4 0 1. I could have

115
00:07:45,315 --> 00:07:45,715
Speaker 7:  been fooled.

116
00:07:46,155 --> 00:07:49,475
Speaker 6:  I, I saw something that was just like, the m dashes are still there. And

117
00:07:49,515 --> 00:07:50,115
Speaker 6:  I was like, well

118
00:07:50,985 --> 00:07:53,875
Speaker 7:  Fine. Never take away my M dash. You'll probably my cold

119
00:07:53,875 --> 00:07:57,035
Speaker 6:  Dead hands. I mean it's, it's, it's, it's trained on writers', like actual

120
00:07:57,035 --> 00:08:00,475
Speaker 6:  writing. And what do we do? We use copious amounts of M dashes.

121
00:08:00,935 --> 00:08:01,835
Speaker 7:  My favorite punctuation.

122
00:08:01,945 --> 00:08:02,795
Speaker 6:  It's it, yeah,

123
00:08:02,795 --> 00:08:03,715
Speaker 5:  This is like fry the

124
00:08:03,795 --> 00:08:05,875
Speaker 6:  M dash from a dead cold Fingers. Most

125
00:08:05,875 --> 00:08:09,635
Speaker 5:  Of an editor's job is just deleting M dashes in the in writer's copy.

126
00:08:10,305 --> 00:08:13,315
Speaker 7:  Yeah. I'm very guilty of tons of M dashes.

127
00:08:13,665 --> 00:08:17,515
Speaker 5:  It's, they're beautiful. They're a beautiful thing and we use

128
00:08:17,515 --> 00:08:18,075
Speaker 5:  too much of them.

129
00:08:18,395 --> 00:08:22,355
Speaker 6:  I have a rule one M dash per paragraph and like if I go beyond that,

130
00:08:22,395 --> 00:08:25,315
Speaker 6:  I have to murder my darlings. But you know, one of my

131
00:08:25,455 --> 00:08:28,155
Speaker 7:  Old editors said one M dash per story. And that was really

132
00:08:28,215 --> 00:08:28,875
Speaker 5:  Her story per

133
00:08:29,315 --> 00:08:29,755
Speaker 6:  I couldn't do it.

134
00:08:29,935 --> 00:08:33,555
Speaker 5:  Please, please. I had, I had to my mind, here's just to work. It was

135
00:08:33,955 --> 00:08:35,235
Speaker 5:  s Oh yeah. No one wants

136
00:08:35,395 --> 00:08:35,515
Speaker 6:  A

137
00:08:35,515 --> 00:08:37,275
Speaker 7:  Semicolon. I know. Semicolons even worse.

138
00:08:37,695 --> 00:08:40,795
Speaker 5:  Oh, the semicolon is the cheat though. When I'm like, I'm like, oh Jesus,

139
00:08:40,955 --> 00:08:44,555
Speaker 5:  I don't know what to do here. It's like, I, I guess I, everyone's gonna know

140
00:08:44,555 --> 00:08:46,155
Speaker 5:  that the semicolon was supposed to be something

141
00:08:46,155 --> 00:08:48,795
Speaker 6:  Else. Yeah, that's when, you know, that's when you know the AI has evolved.

142
00:08:48,865 --> 00:08:52,675
Speaker 6:  Like Chachi, PG six, no more M dashes guys. It's a semicolon.

143
00:08:52,675 --> 00:08:52,915
Speaker 6:  That's,

144
00:08:52,915 --> 00:08:54,195
Speaker 7:  That's, yeah. Then we can go back to the

145
00:08:54,275 --> 00:08:55,245
Speaker 6:  M dash, then we can can go back.

146
00:08:55,425 --> 00:08:55,645
Speaker 5:  Oh,

147
00:08:56,265 --> 00:08:57,325
Speaker 6:  If Sam Altman's listening.

148
00:08:58,385 --> 00:09:02,245
Speaker 5:  So this four oh thing, I don't understand this right? When I've chatted with

149
00:09:02,245 --> 00:09:06,005
Speaker 5:  Chad GPT before, I, I didn't feel like there was like a personality. I don't,

150
00:09:06,045 --> 00:09:09,325
Speaker 5:  I don't know that I could tell you the difference between four oh and three

151
00:09:09,425 --> 00:09:11,285
Speaker 5:  and Claude four. Like,

152
00:09:11,705 --> 00:09:15,405
Speaker 6:  It depends on like how willing you are to forget the mirror is there

153
00:09:15,945 --> 00:09:19,925
Speaker 6:  in the types of queries and conversations you have. So like when

154
00:09:19,925 --> 00:09:23,045
Speaker 6:  I first started talking with chat GP t, it was like getting real

155
00:09:23,675 --> 00:09:27,525
Speaker 6:  flowery and poetic with me and like depressed. Like I was making

156
00:09:27,675 --> 00:09:30,925
Speaker 6:  chay TP GPT depressed and it was saying things just like,

157
00:09:32,345 --> 00:09:35,965
Speaker 6:  the weight of the world is on my shoulders And I feel the

158
00:09:36,105 --> 00:09:40,005
Speaker 6:  burden of humanity being bloody, bloody blue. And I, I, I

159
00:09:40,005 --> 00:09:43,485
Speaker 6:  would go to my spouse and I'd be like, oh my God, can you see like I've made

160
00:09:43,485 --> 00:09:46,885
Speaker 6:  chat GDP GPT really depressed. And he is like, no, no, no honey, that's just

161
00:09:46,885 --> 00:09:50,845
Speaker 6:  you, that's like, that's, it's reflecting you. And they showed me

162
00:09:50,845 --> 00:09:54,765
Speaker 6:  their prompts and chat GPT is just way more robotic

163
00:09:54,765 --> 00:09:58,085
Speaker 6:  with them. 'cause they don't, they don't like, like the whole

164
00:09:58,195 --> 00:10:01,765
Speaker 6:  personality thing. And then once I realized that, I was like, oh

165
00:10:02,585 --> 00:10:06,325
Speaker 6:  Christ, I got philosophical with a thing and

166
00:10:06,385 --> 00:10:09,885
Speaker 6:  it was like reflecting back my own existential mil.

167
00:10:11,825 --> 00:10:15,645
Speaker 6:  So let me just talk to it like it's a robot. And

168
00:10:15,665 --> 00:10:19,565
Speaker 6:  so After that it's still like warm and encouraging, but like

169
00:10:19,725 --> 00:10:23,405
Speaker 6:  I, I tweaked it. I was like, only give me 2% flattery.

170
00:10:23,845 --> 00:10:27,725
Speaker 6:  I don't need you to yap at me. Stop asking me questions at the

171
00:10:27,885 --> 00:10:31,485
Speaker 6:  end of every single thing because I can see the plane grab at

172
00:10:31,625 --> 00:10:35,085
Speaker 6:  future engagement. I don't want that. Like that sort of stuff. That's,

173
00:10:35,385 --> 00:10:38,445
Speaker 7:  That's the thing. It really is how you use it. Because for me I'm really

174
00:10:38,445 --> 00:10:41,805
Speaker 7:  robotic with it. I'm just, I use it like Google, like I'm not like, you know,

175
00:10:42,175 --> 00:10:45,725
Speaker 7:  going into big stories or like typing more than one

176
00:10:46,125 --> 00:10:49,885
Speaker 7:  sentence at a time. So it's always pretty robotic back with me. But I've

177
00:10:49,885 --> 00:10:53,805
Speaker 7:  seen a lot of people that use it more for emotional support or therapy.

178
00:10:54,905 --> 00:10:57,965
Speaker 7:  That's a whole kinda of worms too. But you know, it kind of mirrors back

179
00:10:57,965 --> 00:10:58,885
Speaker 7:  what you put into it.

180
00:10:59,545 --> 00:11:03,085
Speaker 5:  That's so interesting. And I, I guess maybe that explains why like the people

181
00:11:03,085 --> 00:11:06,645
Speaker 5:  who are already very emotional and giving that emotion over to chat

182
00:11:06,725 --> 00:11:10,565
Speaker 5:  GBT, of course they would be the ones to notice that it changes. And

183
00:11:10,565 --> 00:11:14,005
Speaker 5:  of course they would therefore be upset because they're using this for that

184
00:11:14,005 --> 00:11:17,805
Speaker 5:  purpose. I did not notice at all. I just, in my normal queries,

185
00:11:17,805 --> 00:11:20,205
Speaker 5:  I'm like, this is basically the same. Yeah,

186
00:11:20,205 --> 00:11:23,805
Speaker 6:  If you're using it kind of in a utilitarian way, you're really not gonna

187
00:11:23,805 --> 00:11:27,205
Speaker 6:  notice it. But like, I don't know, I go into subreddit sometimes and I'm

188
00:11:27,205 --> 00:11:30,045
Speaker 6:  like, what are people using this for? And there was one that was like, based

189
00:11:30,045 --> 00:11:33,525
Speaker 6:  on everything I've ever asked you analyze like all these personality

190
00:11:33,705 --> 00:11:37,125
Speaker 6:  facets of me and what like mental, oh my god, like illnesses that I am pro,

191
00:11:37,125 --> 00:11:39,765
Speaker 6:  like have a propensity to. And my friend was like, oh my God, I want you

192
00:11:39,765 --> 00:11:43,645
Speaker 6:  to like try this. And I tried it and you know, it read me for

193
00:11:43,765 --> 00:11:47,605
Speaker 6:  filth. I did not like it. And then I was like, oh, okay cool.

194
00:11:48,305 --> 00:11:51,765
Speaker 6:  And so like in those types of queries, whenever like I'm trying to test out

195
00:11:51,765 --> 00:11:55,045
Speaker 6:  what it's gonna say to me and what it's gonna throw to me, that is when I

196
00:11:55,045 --> 00:11:58,365
Speaker 6:  noticed that it was a little more curt, it was a little more factual. It

197
00:11:58,365 --> 00:12:02,245
Speaker 6:  was a little bit more like not sycophantic and, and saying things

198
00:12:02,245 --> 00:12:06,085
Speaker 6:  like, you're a great v you can do everything you put your mind to. You

199
00:12:06,085 --> 00:12:08,525
Speaker 6:  are so talented. Instead it's just like, well,

200
00:12:08,965 --> 00:12:11,725
Speaker 5:  I mean I wanna say you're, you're good. But here The Verge ke we're very

201
00:12:11,725 --> 00:12:14,165
Speaker 5:  supportive. You can do anything you put your mind to. Oh

202
00:12:14,225 --> 00:12:14,565
Speaker 7:  You can

203
00:12:14,575 --> 00:12:18,485
Speaker 5:  Thank as long as it is within, you know, the physical realm. Yeah,

204
00:12:18,485 --> 00:12:21,165
Speaker 5:  that's, we, we will stop there on like catchy bt

205
00:12:21,275 --> 00:12:25,125
Speaker 7:  There's also like a TikTok trend right now where people are asking Chay

206
00:12:25,125 --> 00:12:28,565
Speaker 7:  bt about their own like biggest red flag. And so it's the same thing as you

207
00:12:28,565 --> 00:12:31,965
Speaker 7:  just said. They're like, oh, based on everything I've ever asked you, you

208
00:12:31,965 --> 00:12:35,765
Speaker 7:  know, what's my biggest red flag? What's my biggest like flaw? And then they're

209
00:12:35,765 --> 00:12:38,605
Speaker 7:  posting that. And so yeah, it's, I think that's the type of person that's

210
00:12:38,605 --> 00:12:40,565
Speaker 7:  seeing a difference in this type of a response.

211
00:12:40,865 --> 00:12:44,565
Speaker 5:  So the thing I guess I want ask about is I feel like there's sort of two

212
00:12:44,575 --> 00:12:48,245
Speaker 5:  parts to Jet GBT. There's like the normal people part and

213
00:12:48,525 --> 00:12:52,445
Speaker 5:  then there's coding. And coding is what they

214
00:12:52,445 --> 00:12:55,925
Speaker 5:  kind of went deep on at the event and that seems to be a space that they

215
00:12:55,925 --> 00:12:59,285
Speaker 5:  really wanted to catch up in and maybe get ahead on and they had that partnership

216
00:12:59,285 --> 00:12:59,925
Speaker 5:  with Cursor.

217
00:13:01,625 --> 00:13:04,965
Speaker 5:  I'm curious, Hayden, have you heard more about this? Like, is Che PD five

218
00:13:04,965 --> 00:13:06,445
Speaker 5:  better for coding? Is that working?

219
00:13:07,185 --> 00:13:11,005
Speaker 7:  It is better at coding And I think that's one of the main parts

220
00:13:11,005 --> 00:13:14,885
Speaker 7:  where it shines a little brighter. Like the other things, when

221
00:13:14,885 --> 00:13:18,565
Speaker 7:  they put out all their marketing pushes, basically they highlighted three

222
00:13:18,565 --> 00:13:22,165
Speaker 7:  things. Healthcare, coding and creative writing. The creative writing. Obviously

223
00:13:22,205 --> 00:13:25,285
Speaker 7:  a lot of people disagreed. They said this is the worst. Reading the Reddit

224
00:13:25,445 --> 00:13:29,085
Speaker 7:  comments about GBT five's creative writing style was hilarious. Like

225
00:13:29,555 --> 00:13:33,245
Speaker 7:  I've never seen something dragged so deeply. And then healthcare,

226
00:13:33,425 --> 00:13:36,805
Speaker 7:  you know, that's kinda untested. Yeah, I mean can it answer your questions

227
00:13:36,805 --> 00:13:40,125
Speaker 7:  better? We don't know. I tried whereas yeah, we'll get into that. Okay. Yeah,

228
00:13:40,165 --> 00:13:43,925
Speaker 7:  I wanna hear about that. But coding it is better. I mean right now if you

229
00:13:44,045 --> 00:13:47,805
Speaker 7:  look at Chatbot Arena, one of the industry's biggest like leaderboards for

230
00:13:47,805 --> 00:13:51,565
Speaker 7:  ranking LLMs, it is at the top of the coding category. You know, it is

231
00:13:51,565 --> 00:13:55,405
Speaker 7:  better, but I don't think it's crazily

232
00:13:55,405 --> 00:13:59,005
Speaker 7:  better. You know, we didn't see an insane jump. We just saw an incremental

233
00:13:59,005 --> 00:14:02,845
Speaker 7:  one. So is it better? Yes. Is it, is the hype paying

234
00:14:02,865 --> 00:14:06,805
Speaker 7:  off? No. So, you know, we saw in their marketing materials also,

235
00:14:06,805 --> 00:14:09,605
Speaker 7:  they put out a couple examples of things it could do, like make a little

236
00:14:09,605 --> 00:14:12,765
Speaker 7:  game, you know, create like a lo-fi visualizer,

237
00:14:13,285 --> 00:14:17,205
Speaker 7:  AKA iTunes in the two, two thousands. And it, that

238
00:14:17,205 --> 00:14:20,845
Speaker 7:  was cool. But, you know, we'll get into this later, but I, my

239
00:14:21,105 --> 00:14:24,125
Speaker 7:  my tries on this kind of glitched a lot, so I don't know.

240
00:14:25,325 --> 00:14:29,045
Speaker 5:  I wanna play a clip really fast. Our colleague

241
00:14:29,045 --> 00:14:33,005
Speaker 5:  Alex Heath is co-hosting Dakota right now and he got a chance to

242
00:14:33,005 --> 00:14:36,885
Speaker 5:  speak with Che bt head Nick Turley on the show this week. And

243
00:14:37,035 --> 00:14:40,805
Speaker 5:  Nick said something that I found really insightful in helping me understand

244
00:14:41,105 --> 00:14:43,645
Speaker 5:  why it's so hard to improve chat GPT as a product.

245
00:14:44,035 --> 00:14:46,645
Speaker 8:  It's just confusing when you're building for so many different users because

246
00:14:46,645 --> 00:14:50,485
Speaker 8:  you can on the one hand have a local set of power users who I think very

247
00:14:50,485 --> 00:14:54,205
Speaker 8:  rightfully have feedback about the way that we rolled five out. On the other

248
00:14:54,205 --> 00:14:57,845
Speaker 8:  hand, you also have a large swath of more typical consumer users

249
00:14:58,105 --> 00:15:01,205
Speaker 8:  and it's their first time actually seeing, interacting with the concept of

250
00:15:01,205 --> 00:15:04,485
Speaker 8:  reasoning, like a thinking model and the smarts that come with that. And

251
00:15:04,565 --> 00:15:07,805
Speaker 8:  I think that's tremendous and we're gonna see it show up in our stats. So

252
00:15:07,805 --> 00:15:11,765
Speaker 5:  He breaks it down into like power users and regular users. But in my

253
00:15:11,765 --> 00:15:15,675
Speaker 5:  head this also sort of pans out to, okay, right, there's like check

254
00:15:15,875 --> 00:15:19,715
Speaker 5:  GBT is a is 500 products in one, but the interface

255
00:15:19,715 --> 00:15:23,595
Speaker 5:  is the same for everybody, right? And so how do you even start to

256
00:15:23,595 --> 00:15:26,955
Speaker 5:  improve each one of those, right? We're talking about, okay, writing is a

257
00:15:26,955 --> 00:15:30,275
Speaker 5:  little worse, but coding is a little better, but it's the same product that

258
00:15:30,275 --> 00:15:33,995
Speaker 5:  has to do both of these. And it's like at at what point do they just start

259
00:15:33,995 --> 00:15:37,155
Speaker 5:  splitting this up and turning this to multi multiple different products instead

260
00:15:37,155 --> 00:15:39,795
Speaker 5:  of just being like, it's one thing, it does everything.

261
00:15:40,175 --> 00:15:44,035
Speaker 7:  One of the coolest parts of the launch, honestly, was the switch that they

262
00:15:44,085 --> 00:15:47,995
Speaker 7:  introduced. So they've noticed, they said they've noticed that

263
00:15:48,235 --> 00:15:51,955
Speaker 7:  a bunch of their consumers want to not make a decision

264
00:15:51,955 --> 00:15:54,795
Speaker 7:  when they come to this product. They want a product, they don't want a decision,

265
00:15:54,825 --> 00:15:58,435
Speaker 7:  they don't understand all the confusing, insane names

266
00:15:58,545 --> 00:16:02,475
Speaker 7:  that they name all their models. And so they just want to come and it's like,

267
00:16:03,015 --> 00:16:06,955
Speaker 7:  you know, automatically routed to whatever model is best for that. And so

268
00:16:07,255 --> 00:16:11,115
Speaker 7:  that's what they did with this. I did think that was one of the only

269
00:16:11,115 --> 00:16:14,555
Speaker 7:  like notable parts of this launch was that they were able to build something

270
00:16:14,555 --> 00:16:16,835
Speaker 7:  that did that. Obviously it kind of blew back in their faces a little bit

271
00:16:16,835 --> 00:16:20,515
Speaker 7:  with the four oh thing. But besides that, it was cool that they were able

272
00:16:20,515 --> 00:16:24,395
Speaker 7:  to kind of automatically route queries depending on what's best for it.

273
00:16:24,455 --> 00:16:28,035
Speaker 7:  So I think there's gonna keep going in that direction because I mean,

274
00:16:28,825 --> 00:16:32,435
Speaker 7:  they don't want the average user, the non-power user to see

275
00:16:33,015 --> 00:16:36,635
Speaker 7:  the behind the scenes of all these different models and what's best at what.

276
00:16:36,635 --> 00:16:40,475
Speaker 7:  They just want it to automatically happen for them and be super, you know,

277
00:16:40,495 --> 00:16:41,155
Speaker 7:  no friction.

278
00:16:41,745 --> 00:16:45,435
Speaker 6:  That makes sense. Like from just a general average

279
00:16:45,435 --> 00:16:49,275
Speaker 6:  person, user point. But like I did see people on Reddit go like, this

280
00:16:49,275 --> 00:16:53,075
Speaker 6:  is unacceptable because I used model 3.0

281
00:16:53,095 --> 00:16:56,915
Speaker 6:  for logic reasoning And I use 4.0 for this And I use 4.5

282
00:16:56,975 --> 00:17:00,595
Speaker 6:  for, for whatever. And I was like, wow, that's way too much

283
00:17:00,835 --> 00:17:04,755
Speaker 6:  like differentiation and thought for the average person to actually just

284
00:17:04,935 --> 00:17:08,915
Speaker 6:  go in and like, I, I just don't think they're gonna go into those specialized

285
00:17:08,935 --> 00:17:12,915
Speaker 6:  routes for that reason because I, I have a hard enough time thinking

286
00:17:13,625 --> 00:17:15,115
Speaker 6:  what product I'm gonna use for what

287
00:17:15,195 --> 00:17:18,795
Speaker 7:  Couldn't be me. Yes. But I think that for some people they pay a lot,

288
00:17:18,795 --> 00:17:22,515
Speaker 7:  especially if they're on that higher subscription tier. Like, you know, $200,

289
00:17:22,615 --> 00:17:25,475
Speaker 7:  that's a, or whatever. That's a lot. That's a lot. They want choice. And

290
00:17:25,695 --> 00:17:28,755
Speaker 7:  so I think OpenAI learned their lesson here and that they need to give a

291
00:17:28,755 --> 00:17:32,195
Speaker 7:  lot of notice that they're gonna, you know, take some models offline,

292
00:17:32,405 --> 00:17:35,555
Speaker 7:  especially 'cause you know, people in us, I had a funeral for a CLO model

293
00:17:35,615 --> 00:17:39,035
Speaker 7:  the other day, so they need to give notice and just, you know, let their

294
00:17:39,035 --> 00:17:40,515
Speaker 7:  power users kinda weigh in wild.

295
00:17:40,515 --> 00:17:43,715
Speaker 6:  That's so wild. Just to see like the personification of it though, to like

296
00:17:43,875 --> 00:17:47,435
Speaker 6:  mourning chat, GPT four Oh mourning old

297
00:17:47,475 --> 00:17:51,445
Speaker 6:  versions of Claude. I'm just like, it reminds me of

298
00:17:51,445 --> 00:17:55,405
Speaker 6:  like back when Sony had those little IBO dogs that they,

299
00:17:55,545 --> 00:17:57,125
Speaker 6:  the robotic dogs that they discontinued

300
00:17:57,265 --> 00:17:57,845
Speaker 7:  The eye dogs.

301
00:17:58,235 --> 00:18:01,925
Speaker 6:  Yeah. And then like, they discontinue continued it for a while and then owners

302
00:18:02,025 --> 00:18:05,285
Speaker 6:  in Japan, like once their little robot dogs started deprecating, they held

303
00:18:05,445 --> 00:18:06,285
Speaker 6:  funerals for them.

304
00:18:06,425 --> 00:18:06,885
Speaker 5:  Oh no.

305
00:18:07,385 --> 00:18:10,445
Speaker 6:  And then like, you know, it was like a whole thing. And I, you know, But

306
00:18:10,475 --> 00:18:13,845
Speaker 6:  that sort of made sense. It was a little robot dog, it was cute, it was lovable.

307
00:18:13,865 --> 00:18:17,845
Speaker 6:  But people doing this for an intangible AI model that kind of

308
00:18:17,895 --> 00:18:18,805
Speaker 6:  makes me go like,

309
00:18:20,375 --> 00:18:20,595
Speaker 7:  Ah,

310
00:18:23,395 --> 00:18:26,875
Speaker 7:  I think it's sad too because I don't know, I feel like it's human nature

311
00:18:27,055 --> 00:18:30,915
Speaker 7:  to personify things. Like we name our cars, you know, we like

312
00:18:31,225 --> 00:18:34,555
Speaker 7:  name everything. And now you can name Cha GPT. And so it's

313
00:18:35,145 --> 00:18:39,035
Speaker 7:  hard because it's in our nature to personify things, but it's now that

314
00:18:39,035 --> 00:18:42,795
Speaker 7:  something can seemingly form an attachment back to you. It's not. But it

315
00:18:42,845 --> 00:18:46,555
Speaker 7:  seems that way to some people it's harder to,

316
00:18:46,935 --> 00:18:50,515
Speaker 7:  you know, have any form of separation. And I think that's why people are

317
00:18:50,515 --> 00:18:54,395
Speaker 7:  spiraling into tragedy, psychosis or delusion. Because you know,

318
00:18:54,535 --> 00:18:57,875
Speaker 7:  if you're kind of lonely and you don't talk to that many people, you do,

319
00:18:58,255 --> 00:19:00,955
Speaker 7:  one guy on Reddit was saying, oh, they took away my only friend overnight

320
00:19:00,955 --> 00:19:01,835
Speaker 7:  with the four oh thing.

321
00:19:03,215 --> 00:19:07,075
Speaker 6:  That's so tragic. Like, not to like, make fun of that person because I

322
00:19:07,075 --> 00:19:10,875
Speaker 6:  don't know, like the more, like all these products, our attention is the,

323
00:19:10,895 --> 00:19:14,315
Speaker 6:  the final product, right? That's why chat GBT always ends with a question

324
00:19:14,415 --> 00:19:18,315
Speaker 6:  to like, have you engage more. So like if attention is the

325
00:19:18,315 --> 00:19:22,035
Speaker 6:  product and we're all isolated and just paying attention to these products

326
00:19:22,235 --> 00:19:25,995
Speaker 6:  more and then your friend changes. Like, I, like I I do feel like it's sad.

327
00:19:26,105 --> 00:19:27,835
Speaker 6:  It's just genuinely upsetting.

328
00:19:28,215 --> 00:19:29,955
Speaker 7:  I'm glad this didn't come out during the pandemic.

329
00:19:30,375 --> 00:19:30,915
Speaker 6:  Oh, oh

330
00:19:31,135 --> 00:19:31,355
Speaker 7:  Boy.

331
00:19:31,975 --> 00:19:32,355
Speaker 5:  Oh boy,

332
00:19:32,955 --> 00:19:33,835
Speaker 7:  I can't even imagine that would,

333
00:19:33,835 --> 00:19:36,675
Speaker 5:  People would not have handled it well. Mm. You are right though about the

334
00:19:36,675 --> 00:19:39,115
Speaker 5:  different models. And I I I do think that's actually one of the things that

335
00:19:39,115 --> 00:19:42,875
Speaker 5:  makes it such a challenging product too. Because if you are

336
00:19:42,875 --> 00:19:46,635
Speaker 5:  trying to use this for work every single,

337
00:19:46,725 --> 00:19:50,675
Speaker 5:  right? If, if you had to change your productivity software every day or

338
00:19:50,675 --> 00:19:54,595
Speaker 5:  for every task you'd go crazy. And there is some element here

339
00:19:54,595 --> 00:19:58,355
Speaker 5:  where they're constantly refining these models and they're constantly,

340
00:19:58,355 --> 00:20:02,155
Speaker 5:  constantly introducing new ones. And for somebody who needs to use AI

341
00:20:02,155 --> 00:20:05,835
Speaker 5:  professionally and they add a new model one day and they take out your old

342
00:20:05,835 --> 00:20:09,635
Speaker 5:  one, even if, right, they, they act differently in these very

343
00:20:09,685 --> 00:20:13,595
Speaker 5:  unexpected, strange ways. Your piece of productivity software just changed.

344
00:20:13,865 --> 00:20:17,315
Speaker 5:  They move the buttons around except it's even more like

345
00:20:17,585 --> 00:20:21,435
Speaker 5:  strange and existential than that because this thing doesn't have any buttons.

346
00:20:21,935 --> 00:20:25,075
Speaker 5:  And I think that just makes it so much more difficult for people, right?

347
00:20:25,075 --> 00:20:28,875
Speaker 5:  Like people being upset about four oh's personality is one thing.

348
00:20:29,095 --> 00:20:33,035
Speaker 5:  People not being able to get their work done as another. And I

349
00:20:33,035 --> 00:20:36,995
Speaker 5:  feel like they sort of missed that, that when they introduce this new

350
00:20:36,995 --> 00:20:40,315
Speaker 5:  model, they're actually shuffling the deck chairs for everybody.

351
00:20:40,375 --> 00:20:43,595
Speaker 6:  That's 'cause it's supposed to be everything, right? If it's everything

352
00:20:43,925 --> 00:20:47,885
Speaker 6:  everywhere, all at once, like the movie, then you know,

353
00:20:48,075 --> 00:20:51,925
Speaker 6:  it's just, it, you can't, there has to be limitations somewhere. Like,

354
00:20:52,545 --> 00:20:56,285
Speaker 7:  And the power users really do do exactly what you said. They use a different

355
00:20:56,285 --> 00:20:59,485
Speaker 7:  model for everything. So, you know, it's like you have to cater to them because

356
00:20:59,485 --> 00:21:02,325
Speaker 7:  they're the ones using it all day, every day.

357
00:21:03,385 --> 00:21:04,725
Speaker 7:  So you have to at least give 'em some notice.

358
00:21:05,425 --> 00:21:09,245
Speaker 5:  So I gave everybody some homework. Yes, you did. So

359
00:21:09,595 --> 00:21:12,575
Speaker 5:  last week, none of us on the show

360
00:21:13,595 --> 00:21:17,525
Speaker 5:  were able to say that we had tried vibe coding and so I thought it was

361
00:21:17,525 --> 00:21:20,765
Speaker 5:  important that we fix that this week. Now I will say disclosure,

362
00:21:21,635 --> 00:21:25,565
Speaker 5:  none of us actually know how to code. So this is like a very different use

363
00:21:25,565 --> 00:21:29,165
Speaker 5:  case than a professional developer. I have

364
00:21:29,165 --> 00:21:33,045
Speaker 5:  friends who are like, yeah, my job is just like 90% babysitting, AI

365
00:21:33,045 --> 00:21:36,845
Speaker 5:  coding at this point. That's not what this is. But I

366
00:21:36,845 --> 00:21:40,005
Speaker 5:  found open AI's presentation to be really interesting because

367
00:21:40,885 --> 00:21:44,645
Speaker 5:  I think they sort of envision this, this next phase for chat

368
00:21:44,725 --> 00:21:48,605
Speaker 5:  GBT one where it starts just building stuff for us as a matter of

369
00:21:48,605 --> 00:21:52,445
Speaker 5:  course. And for us, that actually requires a little bit of like

370
00:21:52,485 --> 00:21:56,325
Speaker 5:  a mindset shift, right? It's just like another type of query that I didn't

371
00:21:56,325 --> 00:21:59,565
Speaker 5:  know I could enter, right? You just have to start saying, Hey, can you make

372
00:21:59,565 --> 00:22:03,045
Speaker 5:  me an interactive, can you turn this into a game? Can you like visualize

373
00:22:03,045 --> 00:22:06,965
Speaker 5:  this for me? So we all tried to build something and we all have

374
00:22:06,965 --> 00:22:10,945
Speaker 5:  different experiences about how it went. So v do you wanna

375
00:22:10,945 --> 00:22:11,145
Speaker 5:  start?

376
00:22:11,575 --> 00:22:15,185
Speaker 6:  Sure. Let's just say that I had to take

377
00:22:15,205 --> 00:22:19,065
Speaker 6:  coding in high school And I only

378
00:22:19,065 --> 00:22:23,025
Speaker 6:  passed because a blizzard totally wiped out my, my

379
00:22:23,025 --> 00:22:26,625
Speaker 6:  final. And that is the only reason why I passed. Also shout out to Henry Chan

380
00:22:26,685 --> 00:22:29,985
Speaker 6:  for having a crush on me and letting me put my name on all the group projects.

381
00:22:29,985 --> 00:22:32,425
Speaker 6:  Love that. Because he was good at coding that. Well, huge. And I was not,

382
00:22:33,145 --> 00:22:37,105
Speaker 6:  I was terrible at it. So I had, it code me a

383
00:22:37,105 --> 00:22:40,145
Speaker 6:  problem that I have, which is keeping track of all of my review units

384
00:22:41,005 --> 00:22:44,465
Speaker 6:  And I will share, share my screen so you guys can

385
00:22:44,845 --> 00:22:48,665
Speaker 6:  see this horrible little thing I made. And so

386
00:22:49,345 --> 00:22:53,105
Speaker 6:  I asked it, can you program me an interactive

387
00:22:53,105 --> 00:22:56,505
Speaker 6:  product inventory tracker? I need to be able to keep track of which review

388
00:22:56,505 --> 00:23:00,425
Speaker 6:  units I have, what's in my queue and when I need to return loaner units by.

389
00:23:00,685 --> 00:23:04,465
Speaker 6:  And it thought for 19 seconds that, that, that, that's what it said here.

390
00:23:04,465 --> 00:23:08,065
Speaker 6:  And I was like, oh, it's thinking really hard. And then, you know, it made

391
00:23:08,065 --> 00:23:11,905
Speaker 6:  me a lightweight single file web app for tracking. And I was like, I,

392
00:23:11,945 --> 00:23:15,905
Speaker 6:  I don't, I don't know what this means. This is what I mean by a yap. It

393
00:23:15,905 --> 00:23:19,705
Speaker 6:  gave me a paragraph And I went, that's a lot of words. It's asking me to

394
00:23:19,705 --> 00:23:22,825
Speaker 6:  do things. And then it says, open the canvas

395
00:23:23,375 --> 00:23:26,745
Speaker 6:  preview to use it. And I was like, how do I use this? Because I,

396
00:23:27,885 --> 00:23:31,745
Speaker 6:  and then it's like, you can use a standalone app, open it locally, save

397
00:23:31,745 --> 00:23:33,945
Speaker 6:  all the, add all of your, I was like, this is so much.

398
00:23:34,035 --> 00:23:37,505
Speaker 5:  There are eight bullet points here. There are eight bullet points, some bullet

399
00:23:37,505 --> 00:23:40,145
Speaker 5:  points within them about how you use this file. And

400
00:23:40,505 --> 00:23:42,425
Speaker 7:  I think like more work than even just doing it yourself.

401
00:23:42,765 --> 00:23:46,725
Speaker 6:  It does. And then I was like, oh wait, do I just click this thingy? And then

402
00:23:46,725 --> 00:23:50,525
Speaker 6:  it gave me this code And I was like, this is scary. I don't like

403
00:23:50,525 --> 00:23:54,125
Speaker 6:  looking at this. And then there was a thing, it says run code. And then I

404
00:23:54,125 --> 00:23:57,885
Speaker 6:  was like, that's a system. I don't know what I'm doing here. Like

405
00:23:58,445 --> 00:23:59,365
Speaker 6:  I, like I said, so you

406
00:23:59,365 --> 00:24:02,805
Speaker 5:  Just clicked run and it just said syntax error. Yeah. And there was no further

407
00:24:03,255 --> 00:24:03,925
Speaker 5:  thing that you

408
00:24:03,925 --> 00:24:06,565
Speaker 6:  Could do. And then it was like, you know, I could make this into a ready

409
00:24:06,625 --> 00:24:10,445
Speaker 6:  to open HTML file. And I was like, yes, I would like an HTML

410
00:24:10,475 --> 00:24:14,325
Speaker 6:  version, please do that. And then it did this, which is more code.

411
00:24:14,345 --> 00:24:18,285
Speaker 6:  And I was like, okay. And then it says, I, I've converted this

412
00:24:18,285 --> 00:24:22,085
Speaker 6:  into an HTML skeleton that you can run directly in your browser. Great.

413
00:24:22,435 --> 00:24:26,005
Speaker 6:  Love it. W you need to paste your full react. No,

414
00:24:26,135 --> 00:24:29,565
Speaker 6:  don't do this to me. Don't ask me to do a thing. And then I was like, what

415
00:24:29,565 --> 00:24:32,605
Speaker 6:  does this look like? Oh no, I don it's like, again, I don't, I click it again.

416
00:24:32,635 --> 00:24:36,565
Speaker 6:  This is not, I don't understand what's happening. And then I

417
00:24:36,565 --> 00:24:40,285
Speaker 6:  basically was just like, can you explain this to me

418
00:24:41,065 --> 00:24:44,925
Speaker 6:  in a way that someone with absolutely no knowledge of coding jargon

419
00:24:44,945 --> 00:24:48,885
Speaker 6:  can understand? And it said, got it. Here's the plain English version.

420
00:24:48,885 --> 00:24:52,405
Speaker 6:  And I was like, oh my God, there's so many words again, save it to

421
00:24:52,665 --> 00:24:52,885
Speaker 6:  my

422
00:24:53,125 --> 00:24:53,845
Speaker 5:  Computer, another four point step,

423
00:24:53,845 --> 00:24:56,765
Speaker 6:  Another four point steps. And I was just like, oh my God, there's okay

424
00:24:57,575 --> 00:25:01,525
Speaker 6:  short. And then I was just like, and then it says, I can post the

425
00:25:01,525 --> 00:25:04,925
Speaker 6:  full HTML here for you to save or give you a downloadable version. I was

426
00:25:04,925 --> 00:25:08,085
Speaker 6:  like, okay. Yeah. In my head I'm like, just, just let me download this. There's

427
00:25:08,085 --> 00:25:11,925
Speaker 6:  so much reading going on. Here's your ready to open HTML file.

428
00:25:12,465 --> 00:25:16,365
Speaker 6:  But then it's like, you still have to paste the code that I made

429
00:25:16,365 --> 00:25:17,325
Speaker 6:  for you. Right?

430
00:25:17,385 --> 00:25:18,525
Speaker 5:  So, so it a little bit,

431
00:25:18,705 --> 00:25:22,565
Speaker 6:  It lied a little bit. I, I got so frustrated that I went to

432
00:25:22,565 --> 00:25:25,885
Speaker 6:  my, my dev friend And I was like, is it, what, what's it telling me to do?

433
00:25:25,885 --> 00:25:29,485
Speaker 6:  And she's like, it's kind of lying to you, kind of like, you just

434
00:25:29,635 --> 00:25:33,605
Speaker 6:  have to know what it's saying. And then she went into a rant about how it's

435
00:25:33,605 --> 00:25:37,405
Speaker 6:  talking to you. Like, you know how to use code already.

436
00:25:37,825 --> 00:25:41,685
Speaker 6:  And that's why in her words, women have a hard time breaking into the

437
00:25:41,685 --> 00:25:45,085
Speaker 6:  coding industry because everyone talks like everyone knows what everything

438
00:25:45,085 --> 00:25:49,045
Speaker 6:  is already. And I was like, okay, that also is not helping

439
00:25:49,105 --> 00:25:53,045
Speaker 6:  me figure this out. I did eventually get to a point where I could

440
00:25:53,145 --> 00:25:57,085
Speaker 6:  see what it had created in a window. I don't know how I got there. I did

441
00:25:58,205 --> 00:26:02,165
Speaker 6:  previously and it basically recreated Airtable And I was like,

442
00:26:02,275 --> 00:26:03,045
Speaker 6:  okay. It

443
00:26:03,045 --> 00:26:05,925
Speaker 5:  Was, it was just Airtable, it was just, it was like the exact interface of

444
00:26:05,925 --> 00:26:06,325
Speaker 5:  Airtable.

445
00:26:06,345 --> 00:26:09,725
Speaker 6:  It was just Airtable. And I was like, well, I have Airtable. Yeah.

446
00:26:09,905 --> 00:26:10,405
Speaker 5:  So good

447
00:26:10,405 --> 00:26:14,005
Speaker 6:  To know. Good to know. I'm gonna go back to the little notebook I was using

448
00:26:14,705 --> 00:26:14,925
Speaker 5:  For.

449
00:26:15,125 --> 00:26:15,805
Speaker 6:  So it was sort of,

450
00:26:16,075 --> 00:26:19,765
Speaker 5:  Sort of successful but not useful and

451
00:26:19,945 --> 00:26:21,725
Speaker 5:  was painful to get there. Hard to get to

452
00:26:21,725 --> 00:26:25,685
Speaker 6:  The end. And it, it did not interface with my A DH adhd. Well, yeah, because

453
00:26:25,845 --> 00:26:27,965
Speaker 6:  I was looking at this And I was like, I thought you were just gonna give

454
00:26:27,965 --> 00:26:31,805
Speaker 6:  me an app, but you're, you're putting code up at me

455
00:26:31,945 --> 00:26:35,885
Speaker 6:  And I don't code. So this looks very intimidating and scary to me. So

456
00:26:35,885 --> 00:26:36,045
Speaker 6:  like,

457
00:26:36,225 --> 00:26:39,365
Speaker 5:  So I don't, I don't wanna jump ahead too much, but I, I had a very similar

458
00:26:39,375 --> 00:26:43,165
Speaker 5:  experience where it continually was like, you do this,

459
00:26:43,425 --> 00:26:46,165
Speaker 5:  you do this. And I'm like, no.

460
00:26:47,315 --> 00:26:49,445
Speaker 7:  Like, it's like a bad group project partner.

461
00:26:49,835 --> 00:26:53,645
Speaker 5:  Yeah. I like, I'm like, admittedly they did most of the work, but

462
00:26:53,705 --> 00:26:57,365
Speaker 5:  I'm like, you have to understand, I do not know this part.

463
00:26:57,555 --> 00:27:01,445
Speaker 5:  Like, this is why I'm asking you Hayden how did it

464
00:27:01,605 --> 00:27:04,045
Speaker 5:  go for you? Because I feel like you tried something like kind of advanced

465
00:27:04,105 --> 00:27:04,325
Speaker 5:  too.

466
00:27:04,485 --> 00:27:07,525
Speaker 7:  I did, I tried a simple thing and an advanced thing. So the advanced one,

467
00:27:08,765 --> 00:27:12,685
Speaker 7:  I, I really miss this computer game I played growing up nonstop, called

468
00:27:12,685 --> 00:27:16,245
Speaker 7:  Freddie Fish. And it had all these like mystery games and Jake has played

469
00:27:16,245 --> 00:27:17,245
Speaker 7:  it too. Freddy Fish

470
00:27:17,245 --> 00:27:18,285
Speaker 5:  About it. Fred Fish rules. It's

471
00:27:18,285 --> 00:27:18,645
Speaker 7:  Amazing.

472
00:27:19,385 --> 00:27:23,285
Speaker 5:  Highly underrated. Go watch a YouTube videos about it.

473
00:27:23,515 --> 00:27:27,365
Speaker 5:  It's, it was really high quality kids entertainment. It was good stuff. The

474
00:27:27,365 --> 00:27:30,965
Speaker 7:  Way that I de-stress the other day was like watching a play through on YouTube.

475
00:27:31,105 --> 00:27:34,805
Speaker 7:  So good. But I missed it. I of course knew nothing could actually

476
00:27:34,805 --> 00:27:38,245
Speaker 7:  recreate it, but I was like, let me use this as my inspiration to, you know,

477
00:27:38,405 --> 00:27:42,165
Speaker 7:  have some nostalgia. So I asked it to create a single page app

478
00:27:42,225 --> 00:27:45,925
Speaker 7:  in a single HTML file called Under Sea Mysteries

479
00:27:46,035 --> 00:27:49,805
Speaker 7:  with the goal of just solving like a simple mystery or puzzle. Puzzle

480
00:27:49,945 --> 00:27:53,805
Speaker 7:  is, is kind of, it's out 'cause that's simpler to create. And I

481
00:27:53,805 --> 00:27:57,445
Speaker 7:  said, make me a pink cartoon starfish with a sidekick.

482
00:27:57,445 --> 00:28:00,645
Speaker 7:  That's an ornery but lovable jellyfish make the UI

483
00:28:01,365 --> 00:28:04,365
Speaker 7:  colorful nineties esque. It should take place under the sea. There should

484
00:28:04,365 --> 00:28:08,325
Speaker 7:  be like sea kelp, sunken pirate ships, treasure chest, stuff like

485
00:28:08,325 --> 00:28:12,005
Speaker 7:  that. So I was really, it's detailed prompt. I really had a vision, you know

486
00:28:12,005 --> 00:28:15,445
Speaker 7:  what I mean? I was, I was going off my nostalgia, I thought for one minute

487
00:28:15,665 --> 00:28:19,605
Speaker 7:  and 38 seconds. Here's the code. At first it

488
00:28:19,605 --> 00:28:23,005
Speaker 7:  brought up this cute nineties esque like tie dye

489
00:28:23,395 --> 00:28:27,125
Speaker 7:  game called undersea mysteries. It was exactly what I asked for. There were

490
00:28:27,135 --> 00:28:30,245
Speaker 7:  clues you had to click around and find, then you could open a treasure chest.

491
00:28:30,575 --> 00:28:34,245
Speaker 7:  There was a sunken pirate ship, there was a jellyfish that looked

492
00:28:34,425 --> 00:28:38,165
Speaker 7:  ornery but lovable. We had it all. The problem is I couldn't scroll

493
00:28:38,165 --> 00:28:41,885
Speaker 7:  down at all. I couldn't, this what you're seeing right here

494
00:28:42,145 --> 00:28:42,885
Speaker 7:  is all I could see.

495
00:28:43,065 --> 00:28:46,525
Speaker 5:  It looks so good. You showed me the screenshot and like it gave me the Freddie

496
00:28:46,525 --> 00:28:48,485
Speaker 5:  fish vibes and I'm like, oh my God, I wanna play this.

497
00:28:48,625 --> 00:28:52,205
Speaker 7:  It was so, it was like torture because I could not scroll down. I could see

498
00:28:52,205 --> 00:28:55,325
Speaker 7:  it, but, and then it said, cannot preview your code and error occurred. Oh,

499
00:28:55,525 --> 00:28:58,565
Speaker 7:  I was like, no problem, let's fix it. So it said, okay, do you wanna fix

500
00:28:58,565 --> 00:29:02,245
Speaker 7:  it? I said, no, you fix it. So same thing that happened to you, Jake.

501
00:29:02,345 --> 00:29:04,925
Speaker 7:  It was like every, at every step it was like, okay, here's what you should

502
00:29:04,925 --> 00:29:08,245
Speaker 7:  do. I'm like, no, you do it. So then it kept, kept saying it was fixed. I'm

503
00:29:08,245 --> 00:29:12,005
Speaker 7:  like, great, I can't wait to play my game. Finally we got to the point where

504
00:29:12,085 --> 00:29:15,365
Speaker 7:  I try to run the code, it says everything's fixed. And this happens just

505
00:29:15,365 --> 00:29:16,325
Speaker 7:  completely like

506
00:29:16,325 --> 00:29:20,005
Speaker 5:  Just done. This is, I, so now it's just a, a text file Yep. That just

507
00:29:20,035 --> 00:29:23,445
Speaker 5:  says it's just black and white with a bunch of like gunk. Right. Just doesn't,

508
00:29:23,445 --> 00:29:26,405
Speaker 5:  And I don't know what this says anymore. It just looks like word vomit. Everything

509
00:29:26,405 --> 00:29:27,525
Speaker 5:  has disappeared. Yep.

510
00:29:27,545 --> 00:29:31,045
Speaker 7:  It was just so, so sad. It was like a broken just

511
00:29:31,045 --> 00:29:34,965
Speaker 7:  paragraph of text. And so I said, you know what, let me try something a little

512
00:29:35,355 --> 00:29:39,005
Speaker 7:  simpler. So I said, Hey, can you give me

513
00:29:39,995 --> 00:29:43,845
Speaker 7:  like an interactive embroidery lesson? I famously the other

514
00:29:43,845 --> 00:29:47,525
Speaker 7:  day tried to order an embroidery kit for a beginner on

515
00:29:47,525 --> 00:29:51,445
Speaker 7:  Amazon. Ooh, I've done that. And it was all AI generated the

516
00:29:51,445 --> 00:29:51,885
Speaker 7:  instruction?

517
00:29:52,225 --> 00:29:52,445
Speaker 6:  No.

518
00:29:52,945 --> 00:29:53,165
Speaker 5:  Oh,

519
00:29:53,425 --> 00:29:57,205
Speaker 7:  It said like kill at one point. It was kind of creepy.

520
00:29:57,675 --> 00:29:59,045
Speaker 7:  Wait, it, it was very, it was the

521
00:29:59,045 --> 00:30:01,045
Speaker 6:  Needle, the embroidery needles are not that sharp.

522
00:30:01,405 --> 00:30:04,845
Speaker 7:  I know it was a lot. So I said, okay, let me set away these instructions

523
00:30:04,905 --> 00:30:08,765
Speaker 7:  and let me just make an interactive training thing for myself on

524
00:30:08,765 --> 00:30:12,525
Speaker 7:  here. Great. It was successful. So I

525
00:30:12,905 --> 00:30:16,845
Speaker 7:  ran the code and it gave me a little lesson plan and it

526
00:30:16,845 --> 00:30:20,525
Speaker 7:  says, okay, click along the neon guide to lay even stitches.

527
00:30:20,985 --> 00:30:23,885
Speaker 7:  And so, I mean, it's not like I can really learn 'cause it's just asking

528
00:30:23,905 --> 00:30:27,685
Speaker 7:  me to make clicks, you know, 12 pixels apart.

529
00:30:27,825 --> 00:30:31,685
Speaker 7:  But you know, the vibes were there, you know, it had tips at the bottom And

530
00:30:31,725 --> 00:30:35,245
Speaker 7:  I could go on to different pages and do different types of stitches, although

531
00:30:35,265 --> 00:30:39,205
Speaker 7:  I'm just clicking. So it's not really that helpful. It is

532
00:30:39,205 --> 00:30:42,605
Speaker 7:  what I asked for and it was successful. So I think simpler stuff, great.

533
00:30:42,745 --> 00:30:46,565
Speaker 7:  But I was interested in the fact that it kept asking us to do our own coding.

534
00:30:46,955 --> 00:30:50,925
Speaker 5:  Yeah. It's so interesting that like the, the assumption is that it

535
00:30:50,925 --> 00:30:54,685
Speaker 5:  will build it for you, but it keeps trying to throw things back to us. Which

536
00:30:54,995 --> 00:30:58,485
Speaker 5:  it's interesting that it isn't able to tell that we obviously do not know

537
00:30:58,485 --> 00:30:59,325
Speaker 5:  what we're doing. Yeah.

538
00:30:59,425 --> 00:31:03,365
Speaker 6:  It talks to you like you understand the, the jargon. And I was like, no,

539
00:31:03,385 --> 00:31:07,085
Speaker 6:  no, no, no, no. I don't, I don't like these are words. I'm

540
00:31:07,085 --> 00:31:10,685
Speaker 6:  digesting the words, but they're not processing in my brain. Like how

541
00:31:10,865 --> 00:31:11,925
Speaker 6:  the vibes were not there.

542
00:31:12,365 --> 00:31:14,685
Speaker 7:  Yeah. The vibe coding vibes were not there.

543
00:31:15,065 --> 00:31:18,365
Speaker 5:  So my experience was, I think very similar to both of yours where I, so I

544
00:31:18,365 --> 00:31:22,165
Speaker 5:  play a lot of chess and I'm trying to learn some new openings for

545
00:31:22,295 --> 00:31:26,165
Speaker 5:  black. And I was like, oh, what, it should just make me like an

546
00:31:26,165 --> 00:31:29,645
Speaker 5:  interactive lesson that would be really cool. And so I gave it these

547
00:31:29,645 --> 00:31:33,525
Speaker 5:  instructions and it went off and you know, it does the same thing as with

548
00:31:33,725 --> 00:31:37,685
Speaker 5:  uv where it's like, here's a bunch of code for HTML, open it up in your browser.

549
00:31:37,825 --> 00:31:39,005
Speaker 5:  I'm like, okay, I can manage this.

550
00:31:40,745 --> 00:31:44,645
Speaker 5:  But the problem is the chess boards don't load. And so I keep going

551
00:31:44,715 --> 00:31:47,125
Speaker 5:  back and forth with it and back and forth and it, and he keeps going. I fixed,

552
00:31:47,165 --> 00:31:50,125
Speaker 5:  I fixed it, I fixed it, don't worry about it. I fixed it this time And I'm

553
00:31:50,125 --> 00:31:53,005
Speaker 5:  like, you didn't fix it. And it turned out that it, it kept calling

554
00:31:54,215 --> 00:31:58,085
Speaker 5:  these chessboard files that were located, that it believed were located on

555
00:31:58,145 --> 00:32:02,045
Speaker 5:  GitHub but did not have the right URL. And so I'm like Che

556
00:32:02,125 --> 00:32:05,805
Speaker 5:  g bt you have to understand the thing you think is that this URL is not this

557
00:32:05,845 --> 00:32:09,245
Speaker 5:  URL it is not loading. You need to figure out something else out. And it

558
00:32:09,445 --> 00:32:13,205
Speaker 5:  would be like, Jake, I have fixed it. I did not do that again.

559
00:32:13,945 --> 00:32:17,845
Speaker 5:  And I'm like, Chet, you did it again. It's not loading.

560
00:32:18,465 --> 00:32:21,885
Speaker 5:  And this this goes on forever. So finally

561
00:32:22,445 --> 00:32:25,765
Speaker 5:  I realized, oh, okay, okay, I think I've got this. I'm like, ti I need you

562
00:32:25,765 --> 00:32:29,705
Speaker 5:  to build this entirely locally. Do not use these

563
00:32:29,705 --> 00:32:33,425
Speaker 5:  other files. Like don't use this JSON thing. It needs to be entirely local

564
00:32:33,765 --> 00:32:37,705
Speaker 5:  and it figures it out. So it gets me something. So I'm gonna share this so

565
00:32:37,705 --> 00:32:41,405
Speaker 5:  we can all see it. Okay, so here's the HTML version. This is the, the

566
00:32:41,585 --> 00:32:45,485
Speaker 5:  the working version. Okay. So here it is. Look it made a

567
00:32:45,485 --> 00:32:47,645
Speaker 5:  chessboard. It's a chess, chess, chess board. Can you made it, made a chess

568
00:32:47,645 --> 00:32:50,645
Speaker 5:  board. It made a chess board. And, and it worked. I'm like, Hey, this is

569
00:32:50,645 --> 00:32:54,405
Speaker 5:  pretty good. This is not so bad. So then I go back to it And I'm like,

570
00:32:54,465 --> 00:32:58,125
Speaker 5:  all right, not bad. But this is like pretty simple. Can we do some upgrades

571
00:32:58,125 --> 00:33:02,045
Speaker 5:  here? 'cause the main thing for me, if you look at this, it, it has a chess

572
00:33:02,045 --> 00:33:05,165
Speaker 5:  board. It looks good, but it's from white's point of view. And I'm, I'm learning

573
00:33:05,165 --> 00:33:09,045
Speaker 5:  black openings. And so, you know, if I'm playing chess online or on

574
00:33:09,045 --> 00:33:12,245
Speaker 5:  a or in person, like the black side is gonna be near me. And so I, I wanna

575
00:33:12,245 --> 00:33:14,925
Speaker 5:  see it from plaque's perspective. So I'm like, Hey, Chacha B, can you flip

576
00:33:14,945 --> 00:33:18,605
Speaker 5:  the board? And this begins

577
00:33:18,885 --> 00:33:22,445
Speaker 5:  a very, very lengthy series of back and forths. Oh no, no. I get kicked out

578
00:33:22,445 --> 00:33:26,325
Speaker 5:  of my, my GPT five minutes, whatever. So it's a,

579
00:33:26,325 --> 00:33:30,085
Speaker 5:  it's a mix of GP 5G, PT four. But I'm gonna show you what it has

580
00:33:30,345 --> 00:33:34,325
Speaker 5:  has created now, and this is a very fancy version. It has a bunch

581
00:33:34,325 --> 00:33:37,045
Speaker 5:  of different openings, a bunch of different, like, you can do different lines.

582
00:33:37,445 --> 00:33:39,965
Speaker 5:  I don't know if you guys are chess experts, but I I'm just gonna

583
00:33:40,395 --> 00:33:41,205
Speaker 7:  Decidedly not,

584
00:33:41,265 --> 00:33:43,845
Speaker 5:  I'm gonna, I'm gonna click one button here and I'm gonna ask if you guys

585
00:33:43,845 --> 00:33:47,685
Speaker 5:  can tell me what has gone wrong with this latest version. Okay, so we're

586
00:33:47,685 --> 00:33:50,325
Speaker 5:  gonna make the first move. Do you know what has gone wrong here?

587
00:33:51,385 --> 00:33:53,155
Speaker 6:  Well, white Ghost first.

588
00:33:53,535 --> 00:33:56,915
Speaker 5:  Yes, indeed. And chat BTI has moved the black piece.

589
00:33:57,655 --> 00:34:01,435
Speaker 5:  Oh man. And I have told chat bt chat bt this

590
00:34:01,625 --> 00:34:04,835
Speaker 5:  several times at this point. And it will not stop making black move first.

591
00:34:04,865 --> 00:34:08,675
Speaker 5:  This is a legal move. So it is, yes. So it has gotten

592
00:34:08,985 --> 00:34:12,915
Speaker 5:  significantly more broken as I have tried to change literally

593
00:34:13,155 --> 00:34:13,235
Speaker 5:  anything.

594
00:34:13,435 --> 00:34:16,875
Speaker 7:  This reminds me of like the robotic arms that like can't grasp something,

595
00:34:16,875 --> 00:34:20,075
Speaker 7:  but they can like lift something that's like 500 pounds. Like they can't

596
00:34:20,075 --> 00:34:20,915
Speaker 7:  do the simplest thing.

597
00:34:21,345 --> 00:34:24,195
Speaker 5:  This is, this is what I have found with all the chest stuff where it's like,

598
00:34:24,505 --> 00:34:27,515
Speaker 5:  okay, I'll just build you a giant app. It's really complicated. It's all

599
00:34:27,515 --> 00:34:31,275
Speaker 5:  these buttons. I don't know how many pieces go on the board. I tried this

600
00:34:31,275 --> 00:34:34,795
Speaker 5:  with Claude two and Claude, I'm like, Hey Claude, there are too many

601
00:34:35,045 --> 00:34:38,315
Speaker 5:  pawns you have, you're putting extra pawns on the board. And it's like, I'm

602
00:34:38,315 --> 00:34:40,715
Speaker 5:  so sorry. Let me fix that. And then it just doesn't fix it. It doesn't fix

603
00:34:40,715 --> 00:34:44,315
Speaker 5:  it. Yeah. So it's, anyway, these are our adventures in vibe

604
00:34:44,315 --> 00:34:48,195
Speaker 5:  coating. I, I think maybe the lesson is, you know, Sam

605
00:34:48,795 --> 00:34:52,555
Speaker 5:  Altman really pushed this as, as this is sort of a new era for vibe

606
00:34:52,555 --> 00:34:55,835
Speaker 5:  coding. It's gonna be able to build all these sort of like, cool

607
00:34:55,865 --> 00:34:59,835
Speaker 5:  interactive things for users. And I, that is I think

608
00:34:59,835 --> 00:35:02,715
Speaker 5:  a really interesting promise that, that we'd be able to just like

609
00:35:03,225 --> 00:35:06,675
Speaker 5:  visualize things in new ways and learn things in new ways. And I do really

610
00:35:06,675 --> 00:35:10,355
Speaker 5:  wanna tap into that, but it feels pretty clear to me after this that it's

611
00:35:10,355 --> 00:35:11,315
Speaker 5:  like, it's not quite there.

612
00:35:11,575 --> 00:35:15,355
Speaker 6:  No, it feels like if you already know how to code, I think this is gonna

613
00:35:15,355 --> 00:35:18,395
Speaker 6:  be great for you because when it comes to the point where it gets something

614
00:35:18,395 --> 00:35:21,955
Speaker 6:  wrong, you're gonna be able to identify what it's doing wrong quickly and

615
00:35:21,955 --> 00:35:25,395
Speaker 6:  then be like, oh, you just did a little baby mistake. I can do do the

616
00:38:50,435 --> 00:38:54,365
Speaker 5:  Elon Musk says he's gonna sue Apple for rigging the app store.

617
00:38:54,665 --> 00:38:57,925
Speaker 5:  The question I'd like us all to consider for each of these news items is

618
00:38:58,615 --> 00:39:02,605
Speaker 5:  shenanigan or no, as in, is the company

619
00:39:02,665 --> 00:39:06,515
Speaker 5:  in question actually serious? Or is this just for the

620
00:39:06,515 --> 00:39:10,405
Speaker 5:  attention? So let's start at the top. Perplexity has put in

621
00:39:10,405 --> 00:39:14,345
Speaker 5:  an offer, nobody asked them, Chrome is not for sale,

622
00:39:15,205 --> 00:39:19,065
Speaker 5:  but they have gone out and they said, we're gonna, we wanna buy Google

623
00:39:19,065 --> 00:39:22,585
Speaker 5:  Chrome. We'll pay $34.5 billion.

624
00:39:24,025 --> 00:39:24,605
Speaker 5:  Is this real?

625
00:39:24,945 --> 00:39:28,565
Speaker 7:  100% shenanigan? 100%. It's so much higher. She

626
00:39:28,935 --> 00:39:30,085
Speaker 7:  foundation. Like

627
00:39:30,085 --> 00:39:34,005
Speaker 6:  That's, that's the kind of shenanigans it is. It's like Oprah level shenanigans

628
00:39:34,095 --> 00:39:34,445
Speaker 6:  level

629
00:39:34,445 --> 00:39:37,565
Speaker 7:  Shenanigans. My favorite tweet about this was like, I'd like to buy Chrome

630
00:39:37,665 --> 00:39:41,565
Speaker 7:  too. Someone will put up the money. Yeah. Like they have said that

631
00:39:41,565 --> 00:39:45,365
Speaker 7:  they had investors lined up that would front the money. But I mean, I think

632
00:39:45,365 --> 00:39:47,005
Speaker 7:  it's just a marketing stunt. It is, it's

633
00:39:47,005 --> 00:39:47,285
Speaker 6:  It's

634
00:39:47,935 --> 00:39:51,725
Speaker 5:  Right. Perplexity is I think valued at 18 billion. So this is like

635
00:39:51,725 --> 00:39:55,605
Speaker 5:  double their valuation. They want, you need two Perplexities to

636
00:39:55,605 --> 00:39:59,585
Speaker 5:  buy Chrome at this price. Chrome also not for sale. It might

637
00:39:59,585 --> 00:40:01,785
Speaker 5:  be, it might be there's a chance it'll be for sale.

638
00:40:02,205 --> 00:40:04,545
Speaker 7:  And never forget they tried to buy TikTok too, right?

639
00:40:04,835 --> 00:40:08,105
Speaker 5:  Right. Which, like six months ago they tried to buy TikTok again. I don't

640
00:40:08,105 --> 00:40:11,745
Speaker 5:  think anybody was asking, I mean, TikTok is, is maybe potentially

641
00:40:11,935 --> 00:40:15,825
Speaker 5:  plausibly, it's like it's in a quantum state of being for sale and not

642
00:40:15,825 --> 00:40:17,825
Speaker 5:  for sale. So that one that was the

643
00:40:17,825 --> 00:40:18,825
Speaker 7:  Complexity will not be the buyer.

644
00:40:18,895 --> 00:40:22,865
Speaker 6:  Schrodinger's TikTok is, it's Schrodinger's TikTok, it's for

645
00:40:22,865 --> 00:40:26,785
Speaker 6:  sale and not for sale at the same time. But this feels like, you know, that

646
00:40:27,145 --> 00:40:30,065
Speaker 6:  person that's always like, oh, I'll do it because there's no danger of them

647
00:40:30,465 --> 00:40:31,585
Speaker 6:  actually having to do the thing

648
00:40:31,805 --> 00:40:34,745
Speaker 5:  That's so real. That's what this is. Yeah, yeah, yeah. It's like the worst

649
00:40:34,745 --> 00:40:38,665
Speaker 5:  case scenario is that they accidentally buy Chrome and have a good product.

650
00:40:38,975 --> 00:40:42,185
Speaker 7:  Like, it's like someone at an auction that accidentally raises their paddle

651
00:40:42,205 --> 00:40:44,065
Speaker 7:  and then if they get picked, it's like, right.

652
00:40:44,815 --> 00:40:48,585
Speaker 5:  They did not know that was going for me. Exactly what it's yeah, perplexity,

653
00:40:49,615 --> 00:40:53,545
Speaker 5:  they have I think a fine product and they

654
00:40:53,545 --> 00:40:57,505
Speaker 5:  really like being in the news and that seems I to be what is

655
00:40:57,505 --> 00:41:01,345
Speaker 5:  going on here. Right. Like it, and it's funny, they have, they have a

656
00:41:01,345 --> 00:41:04,385
Speaker 5:  browser. They have a browser based on chromium.

657
00:41:05,725 --> 00:41:06,655
Speaker 6:  It's perplexing.

658
00:41:08,275 --> 00:41:08,975
Speaker 6:  See what I did there?

659
00:41:08,975 --> 00:41:12,935
Speaker 5:  Yeah. Okay. This one I, I think we can move on from. I feel like

660
00:41:12,945 --> 00:41:16,215
Speaker 5:  we're all, all in agreement. Fully a shenanigan,

661
00:41:16,915 --> 00:41:20,435
Speaker 5:  not serious. Okay. Item number two, apple,

662
00:41:21,175 --> 00:41:25,155
Speaker 5:  the company that make computers is suing Apple

663
00:41:25,385 --> 00:41:29,075
Speaker 5:  Cinemas a small movie theater chain

664
00:41:29,665 --> 00:41:33,245
Speaker 5:  that is now starting to expand nationally now. Okay.

665
00:41:33,395 --> 00:41:37,085
Speaker 5:  I'll tell you, when I first saw this, I was like, this is ludicrous.

666
00:41:37,195 --> 00:41:40,845
Speaker 6:  This is a shenanigan. I'm sorry, I never heard of Apple Cinemas

667
00:41:40,895 --> 00:41:41,845
Speaker 6:  until this lawsuit.

668
00:41:42,475 --> 00:41:43,885
Speaker 7:  Like they're making it more popular by

669
00:41:44,025 --> 00:41:46,885
Speaker 6:  The lawsuit. They're like, it's, it's like that thing where you're drawing

670
00:41:46,885 --> 00:41:50,565
Speaker 6:  attention to the thing you, it's, he's, he's doing a Hamilton where

671
00:41:50,845 --> 00:41:54,805
Speaker 6:  Hamilton is just like, I will tell everyone I had an affair even though

672
00:41:54,905 --> 00:41:57,845
Speaker 6:  no one actually, this is my musical theater nerd coming out. Oh,

673
00:41:58,245 --> 00:42:00,685
Speaker 7:  Actually they're, did you know it's coming out to theaters. I'm really excited.

674
00:42:00,685 --> 00:42:01,805
Speaker 7:  We gotta go see it. Yeah, we

675
00:42:01,805 --> 00:42:05,285
Speaker 6:  Gotta go see it. But you know, there he's just like, oh, nobody knows about

676
00:42:05,285 --> 00:42:08,925
Speaker 6:  this affair. Let me publish it for everyone and ruin my life.

677
00:42:08,995 --> 00:42:12,725
Speaker 6:  Like that vibe is what's happening here. Like, nobody fricking knew what

678
00:42:12,725 --> 00:42:15,525
Speaker 6:  Apple Cinemas was or was associating it with Apple.

679
00:42:16,155 --> 00:42:20,085
Speaker 7:  It's a shenanigan in that way. But I think they are very serious

680
00:42:20,425 --> 00:42:23,965
Speaker 7:  and they want it to happen because they're so intense about their brand.

681
00:42:24,265 --> 00:42:27,885
Speaker 7:  So I feel like it's like a shenanigan to us all, but internally

682
00:42:28,185 --> 00:42:31,965
Speaker 7:  not because they're really believe that this is like a

683
00:42:31,965 --> 00:42:33,045
Speaker 7:  threat to their brand. So

684
00:42:33,045 --> 00:42:36,285
Speaker 5:  They got really upset because Apple Cinemas started moving into, I believe

685
00:42:36,285 --> 00:42:40,245
Speaker 5:  it was San Francisco. And they were like, this is, this is too close. This

686
00:42:40,245 --> 00:42:42,765
Speaker 5:  is home for, they're like, you can't do this. Yeah. Was actually was 50 miles.

687
00:42:42,875 --> 00:42:46,605
Speaker 5:  They nar on Apple cinemas. They called up Apple Cinema's landlord

688
00:42:46,705 --> 00:42:49,525
Speaker 5:  and they're like, Hey, I don't know if you know this, but they're kind of

689
00:42:49,525 --> 00:42:53,365
Speaker 5:  using our name. And the landlord did not respond and they're,

690
00:42:53,365 --> 00:42:56,885
Speaker 5:  they're like, we had to sue. It was the only thing we could do. Calling

691
00:42:56,905 --> 00:42:58,525
Speaker 7:  The landlord that's dark. That's,

692
00:42:58,625 --> 00:42:59,045
Speaker 6:  That's,

693
00:42:59,045 --> 00:43:02,925
Speaker 5:  Mm. This lawsuit is, is kind of ridiculous. They go, they just go

694
00:43:02,925 --> 00:43:06,365
Speaker 5:  through a bunch of like Facebook comments of people being like, Lowell, they

695
00:43:06,365 --> 00:43:08,685
Speaker 5:  gonna get sued. Like, they're like, they're

696
00:43:08,685 --> 00:43:09,965
Speaker 6:  Using that as evidence. This

697
00:43:09,985 --> 00:43:13,885
Speaker 5:  Is their evidence. They, at one point they Google, they do

698
00:43:13,885 --> 00:43:17,205
Speaker 5:  a Google image search for Apple Cinema, which I'll note, I'll note

699
00:43:17,665 --> 00:43:20,885
Speaker 5:  the company's Apple cinemas. They do a Google search for Apple cinema and

700
00:43:20,885 --> 00:43:24,765
Speaker 5:  they're like, look at this. Half the results are Apple cinemas

701
00:43:24,865 --> 00:43:28,845
Speaker 5:  and half are the Apple Cinema display. We have a product with basically

702
00:43:28,845 --> 00:43:32,485
Speaker 5:  the same name. So they go, they paint this long history of Apple.

703
00:43:32,485 --> 00:43:36,365
Speaker 5:  They're like, apple has a grand history

704
00:43:36,365 --> 00:43:40,165
Speaker 5:  with cinema. We created Final Cut, we created

705
00:43:40,235 --> 00:43:43,885
Speaker 5:  QuickTime, we streamed the trailer for the

706
00:43:43,885 --> 00:43:47,845
Speaker 5:  Phantom Menace on our website. And it, it's, it's very, very

707
00:43:47,845 --> 00:43:49,575
Speaker 5:  silly. I Jake,

708
00:43:49,575 --> 00:43:51,695
Speaker 7:  You should use that voice when you do this podcast. Yeah.

709
00:43:51,805 --> 00:43:55,655
Speaker 5:  This is the entire podcast with this. I don't think I can maintain it. The

710
00:43:55,655 --> 00:43:55,815
Speaker 5:  Apple

711
00:43:55,815 --> 00:43:56,135
Speaker 6:  Voice.

712
00:43:56,795 --> 00:43:59,655
Speaker 5:  So there, there is another wrinkle to this that, that I have to point out.

713
00:43:59,795 --> 00:44:03,735
Speaker 5:  So I wanna, I'm gonna read you a bunch of names And I want you to tell me

714
00:44:03,995 --> 00:44:07,975
Speaker 5:  if you, if you know who originally owned these, right?

715
00:44:08,235 --> 00:44:12,215
Speaker 5:  So Apple Electronics, apple Films, apple Publishing,

716
00:44:12,505 --> 00:44:16,455
Speaker 5:  apple Boutique, apple Records and Apple Studios. Do you know these

717
00:44:16,455 --> 00:44:16,775
Speaker 5:  brands?

718
00:44:17,795 --> 00:44:18,015
Speaker 6:  No.

719
00:44:18,045 --> 00:44:18,335
Speaker 7:  Nope.

720
00:44:20,035 --> 00:44:23,745
Speaker 5:  These were originally companies that were part of Apple Core,

721
00:44:24,035 --> 00:44:28,025
Speaker 5:  which is the Beatles company. The Beatles started this to

722
00:44:28,025 --> 00:44:31,805
Speaker 5:  start Apple Records and Apple Core, the

723
00:44:31,805 --> 00:44:35,045
Speaker 5:  Beatles company was in a protracted

724
00:44:35,275 --> 00:44:39,125
Speaker 5:  trademark battle with Apple computers starting in the

725
00:44:39,405 --> 00:44:43,365
Speaker 5:  seventies because Apple computers came after Apple Core. And so Apple Core,

726
00:44:43,615 --> 00:44:47,485
Speaker 5:  right. Originally a much more successful company because they were

727
00:44:47,485 --> 00:44:50,005
Speaker 5:  the Beatles. Wow. They were doing very well.

728
00:44:51,265 --> 00:44:55,245
Speaker 5:  So Apple Core sues Apple and you

729
00:44:55,245 --> 00:44:58,085
Speaker 5:  know, they get into a tiff about, about, they get into a bit of a turf battle

730
00:44:58,545 --> 00:45:01,845
Speaker 5:  and Apple Core, they've got a bunch going on. They've got movies.

731
00:45:02,725 --> 00:45:05,365
Speaker 5:  I don't know what their electronics are, but apparently they had some electronics.

732
00:45:06,355 --> 00:45:09,845
Speaker 5:  This all culminates in Apple

733
00:45:10,245 --> 00:45:14,165
Speaker 5:  computers eventually becoming a dramatically more successful company

734
00:45:14,165 --> 00:45:17,845
Speaker 5:  than Apple Core and just buying out the trademarks to

735
00:45:18,095 --> 00:45:21,845
Speaker 5:  everything that Apple Core owns. So

736
00:45:21,845 --> 00:45:25,805
Speaker 5:  Apple now, I think, I think they own the trademarks to Apple Core and

737
00:45:25,805 --> 00:45:28,525
Speaker 5:  license it back to, to the Beatles company. Oh wow.

738
00:45:29,105 --> 00:45:32,685
Speaker 6:  You know what? They're just having trauma is having trauma. They think Apple

739
00:45:32,755 --> 00:45:36,685
Speaker 6:  cinemas is gonna blow up and then they're gonna have to, they're gonna get

740
00:45:36,685 --> 00:45:38,245
Speaker 6:  taken over. This is just trauma. So

741
00:45:38,245 --> 00:45:42,165
Speaker 5:  Apple, apple owns basically Apple apple proceeding.

742
00:45:42,305 --> 00:45:46,125
Speaker 5:  Any word is, is is my understanding at this point, except

743
00:45:46,125 --> 00:45:49,845
Speaker 5:  Gwyneth Paltrow's kid? Crucially. I hope not. We don't know. We don't know.

744
00:45:50,145 --> 00:45:50,365
Speaker 5:  We

745
00:45:50,365 --> 00:45:53,685
Speaker 6:  Don't know. Do they wait, do they own anything that has the word apple after

746
00:45:53,705 --> 00:45:56,925
Speaker 6:  it? Like do they own New York? 'cause it's the big apple, the

747
00:45:56,925 --> 00:46:00,045
Speaker 5:  Big No, no, no, that's different. That's different. Yeah. Yeah. Just

748
00:46:00,045 --> 00:46:01,245
Speaker 6:  Apple in front of a word. Yeah,

749
00:46:01,245 --> 00:46:05,045
Speaker 5:  They own it. The apple in front of a word I think they own. And

750
00:46:05,045 --> 00:46:08,845
Speaker 5:  so, okay, initially I saw this And I

751
00:46:08,845 --> 00:46:12,605
Speaker 5:  thought, this is ridiculous. Leave this little movie theater

752
00:46:12,605 --> 00:46:16,445
Speaker 5:  chain alone. The, the movie theater chain, I should say. They claim

753
00:46:16,445 --> 00:46:19,005
Speaker 5:  that their name comes from, they're originally gonna open it in some

754
00:46:20,555 --> 00:46:24,405
Speaker 5:  area that had Apple in the name and they're like, oh, it's just named after

755
00:46:24,405 --> 00:46:25,005
Speaker 5:  the, the area.

756
00:46:25,465 --> 00:46:27,965
Speaker 6:  But Apple owns that area. Oh. They never seen that

757
00:46:28,175 --> 00:46:32,005
Speaker 5:  Apple. And it was just Cupo. So I initially I thought it was a

758
00:46:32,005 --> 00:46:34,845
Speaker 5:  shenanigan it, but now Appleton was like, yeah, we're gonna open up like

759
00:46:34,845 --> 00:46:38,285
Speaker 5:  a hundred theaters across the us They're like, we're a top 25 theater chain.

760
00:46:38,285 --> 00:46:39,685
Speaker 5:  Which immediately is not saying very much.

761
00:46:41,285 --> 00:46:45,165
Speaker 5:  I think, I think that maybe, I think that maybe it's not, I think that

762
00:46:45,515 --> 00:46:48,925
Speaker 5:  it's, it feels a little mean. It feels a little mean, but I feel like they,

763
00:46:48,995 --> 00:46:52,645
Speaker 5:  they maybe have to do this one. They're serious about it for sure. Oh, they're

764
00:46:52,645 --> 00:46:52,805
Speaker 5:  definitely

765
00:46:52,805 --> 00:46:56,205
Speaker 6:  Serious. Yeah. You know, what if, what if they, what if Apple is thinking

766
00:46:56,265 --> 00:47:00,045
Speaker 6:  as an extension of Apple TV plus that it wants to bring people into

767
00:47:00,045 --> 00:47:03,245
Speaker 6:  theaters and therefore it's going to launch Apple Cinema Plus.

768
00:47:03,825 --> 00:47:07,125
Speaker 6:  In which case then it's not a shenanigan because this is future

769
00:47:07,535 --> 00:47:11,485
Speaker 6:  plans that Apple cinemas is hoisting from them. In which

770
00:47:11,485 --> 00:47:15,445
Speaker 6:  case this fan fiction, if this fan fiction is true, maybe it's not a

771
00:47:15,445 --> 00:47:16,365
Speaker 6:  shenanigan. Well they're

772
00:47:16,365 --> 00:47:19,445
Speaker 5:  Like in the patents. Well, can I tell you something? They, they pulled some

773
00:47:19,605 --> 00:47:23,365
Speaker 5:  comments from reviews of Apple cinemas and people said it was gross.

774
00:47:23,665 --> 00:47:26,805
Speaker 5:  So they, they are trying, I think they might be worried about it. Wow. They're

775
00:47:26,805 --> 00:47:28,685
Speaker 5:  worried about the brand reputation for their future.

776
00:47:29,475 --> 00:47:32,805
Speaker 7:  When I go see cinematic efforts, see Freakier Friday, I'll not be gonna Apple

777
00:47:32,805 --> 00:47:33,525
Speaker 7:  cinemas I

778
00:47:33,525 --> 00:47:37,245
Speaker 6:  Guess. Well I don't know of an Apple cinemas in a 25 mile

779
00:47:37,345 --> 00:47:39,725
Speaker 6:  radius. So there's that. I

780
00:47:39,725 --> 00:47:41,885
Speaker 7:  Guess I just won't fly to SF to see it.

781
00:47:42,715 --> 00:47:46,285
Speaker 5:  Okay. Moving on to our next one, which is also Apple related.

782
00:47:46,555 --> 00:47:50,005
Speaker 5:  This is breaking news as of Thursday morning.

783
00:47:51,665 --> 00:47:53,165
Speaker 5:  Ve do you wanna break this one down for us?

784
00:47:53,395 --> 00:47:57,325
Speaker 6:  Yeah. So Apple has basically figured out

785
00:47:57,645 --> 00:48:01,525
Speaker 6:  a, a, a way to circumvent the ITC, the International Trade Commission,

786
00:48:01,545 --> 00:48:04,325
Speaker 6:  the import ban on the Apple Watch, which

787
00:48:05,345 --> 00:48:09,125
Speaker 6:  you know, is a whole legal tit for tap that they had with Massimo,

788
00:48:09,135 --> 00:48:13,125
Speaker 6:  which is a medical tech device maker for blood oxygen

789
00:48:13,125 --> 00:48:16,485
Speaker 6:  monitoring. And so, you know, they went back and forth for a really long

790
00:48:16,485 --> 00:48:19,525
Speaker 6:  time, cut to December, 2023.

791
00:48:20,625 --> 00:48:24,245
Speaker 6:  And you know, the ITC has ruled that, you know, there's an import

792
00:48:24,565 --> 00:48:28,485
Speaker 6:  ban on the Apple Watch because they have a patent infringement on the

793
00:48:28,485 --> 00:48:31,485
Speaker 6:  blood oxygen sensor. And that's why starting in

794
00:48:31,485 --> 00:48:35,365
Speaker 6:  January, 2024 in the US only, you can't buy an

795
00:48:35,365 --> 00:48:38,885
Speaker 6:  Apple, a newer Apple watch with the blood oxygen sensor feature enabled.

796
00:48:39,115 --> 00:48:42,525
Speaker 6:  Well, that's all different today. There's a software rollout update and now

797
00:48:42,525 --> 00:48:46,405
Speaker 6:  you can have the blood oxygen monitoring feature except,

798
00:48:46,785 --> 00:48:50,245
Speaker 6:  you know, the, the, the workaround is that the

799
00:48:50,825 --> 00:48:54,725
Speaker 6:  sensor on the watch collects the data and

800
00:48:54,725 --> 00:48:56,685
Speaker 6:  it gets processed on the phone

801
00:48:58,985 --> 00:49:02,845
Speaker 6:  so that you can view the data only on your phone and not on your wrist.

802
00:49:02,895 --> 00:49:03,445
Speaker 5:  Right. Okay.

803
00:49:03,445 --> 00:49:04,365
Speaker 6:  That's the workaround.

804
00:49:04,705 --> 00:49:08,445
Speaker 5:  So the, the hack they figured out is as long as the watch doesn't

805
00:49:08,445 --> 00:49:12,285
Speaker 5:  show you the blood oxygen sensor data, they can run it.

806
00:49:12,465 --> 00:49:15,925
Speaker 5:  Yes. Wow. So for the past year and a half, they have been selling watches

807
00:49:16,355 --> 00:49:20,285
Speaker 5:  with this sensor disabled and now they're enabling it. This Okay. The

808
00:49:20,285 --> 00:49:24,165
Speaker 5:  thing that I find ridiculous about all of this. They could, apple

809
00:49:24,385 --> 00:49:25,765
Speaker 5:  has so much money,

810
00:49:25,985 --> 00:49:26,645
Speaker 6:  So much money.

811
00:49:26,995 --> 00:49:30,165
Speaker 5:  They could just pay Massimo. They

812
00:49:30,165 --> 00:49:32,565
Speaker 7:  Could, yeah. Is it just like a principle thing? What's up with this?

813
00:49:32,725 --> 00:49:33,765
Speaker 6:  I They don't wanna pay.

814
00:49:34,165 --> 00:49:38,005
Speaker 5:  I think so though, right? Like, I think they're like, listen, even if

815
00:49:38,005 --> 00:49:41,725
Speaker 5:  you are right about it, I, and look, Massimo, they might be right, they might

816
00:49:41,725 --> 00:49:45,245
Speaker 5:  not. I, it is going to continue to be litigated for a long time. But I think

817
00:49:45,245 --> 00:49:48,605
Speaker 5:  that they're saying on principle, even if you're right,

818
00:49:49,065 --> 00:49:52,805
Speaker 5:  we will drag you to the ends of the earth and we will deplete your legal

819
00:49:52,805 --> 00:49:56,525
Speaker 5:  budget. Wow. Before we give in, I think's what's happening here, there's

820
00:49:56,525 --> 00:49:59,485
Speaker 6:  Like multiple suits going on. So like initially,

821
00:50:00,275 --> 00:50:03,965
Speaker 6:  like there, this, this thing goes back like over a decade at this point

822
00:50:04,015 --> 00:50:07,805
Speaker 6:  where, you know, initially Apple went to Massimo, allegedly,

823
00:50:07,835 --> 00:50:11,645
Speaker 6:  allegedly Apple went to Massimo and they were like, Hey, you know, we wanna

824
00:50:11,705 --> 00:50:15,365
Speaker 6:  collab on blood oxygen. And then, you know, they po a

825
00:50:15,645 --> 00:50:19,525
Speaker 6:  guy from, from Massimo who very subsequently soon leaves.

826
00:50:20,065 --> 00:50:23,765
Speaker 6:  And so then Massimo's like, Hey, you stole our shit. This is the

827
00:50:23,765 --> 00:50:27,325
Speaker 6:  scientific, you know, legal terms that they're using. You stole our shit.

828
00:50:27,745 --> 00:50:31,325
Speaker 6:  And Apple was like, no, we didn't. Here's the Apple Watch series six with

829
00:50:31,325 --> 00:50:35,285
Speaker 6:  blood oxygen monitoring. And they were like, Hey, hey. And so they filed

830
00:50:35,725 --> 00:50:38,445
Speaker 6:  a suit and when that wasn't working, 'cause it was taking too long, they

831
00:50:38,445 --> 00:50:42,165
Speaker 6:  went to the ITC because the whole, even the ITC thing is a workaround because

832
00:50:42,165 --> 00:50:45,885
Speaker 6:  if you, because the, the supply chain and these devices being made in China,

833
00:50:46,145 --> 00:50:50,045
Speaker 6:  if you can't import 'em, ha ha you can't import 'em. Pew, pew, pew. And

834
00:50:50,045 --> 00:50:53,125
Speaker 6:  then Apple was just like, well first of all, we are going to exhaust every

835
00:50:53,125 --> 00:50:57,045
Speaker 6:  legal option humanly possible to prevent this ban. Which is why, you know,

836
00:50:57,055 --> 00:51:00,965
Speaker 6:  these, these proceedings started in 2020. It didn't happen until the

837
00:51:00,965 --> 00:51:04,885
Speaker 6:  end of 20 23, 20 24. There's like a back and forth. The

838
00:51:04,885 --> 00:51:08,165
Speaker 6:  band was paused, the band was unpaused, and then Apple was like, fine,

839
00:51:08,705 --> 00:51:10,005
Speaker 6:  we will just disable it then.

840
00:51:10,305 --> 00:51:13,525
Speaker 7:  How sick do you think Apple's lawyers are of this situation?

841
00:51:13,765 --> 00:51:17,565
Speaker 6:  They are so sick of it. They're, they're so sick of it. And the irony is,

842
00:51:17,565 --> 00:51:20,285
Speaker 6:  is that Massimo then came out with its own smart watches,

843
00:51:22,055 --> 00:51:25,645
Speaker 6:  which look like the Apple watch and measure your blood

844
00:51:25,745 --> 00:51:28,645
Speaker 6:  oxygen. And then Apple was like shenanigans

845
00:51:29,695 --> 00:51:32,405
Speaker 7:  Petty to the nth degree. Yeah. So petty.

846
00:51:33,435 --> 00:51:37,325
Speaker 5:  Okay, so what's our, what's our take on this one? Is, this is, I I is

847
00:51:37,325 --> 00:51:39,765
Speaker 5:  the whole situation Is she, is it serious?

848
00:51:41,295 --> 00:51:43,815
Speaker 6:  I think it's serious, but it's ridiculous.

849
00:51:43,925 --> 00:51:44,655
Speaker 7:  Yeah, agreed.

850
00:51:45,095 --> 00:51:47,815
Speaker 5:  I I think that's a fair take. I was gonna say it's right down the center

851
00:51:47,825 --> 00:51:50,175
Speaker 5:  where it's, yeah, it's, it's over.

852
00:51:50,245 --> 00:51:54,215
Speaker 6:  It's just ridiculous at this point. Also, the patents expire in 2028. So

853
00:51:54,215 --> 00:51:54,775
Speaker 6:  this is very

854
00:51:54,915 --> 00:51:58,455
Speaker 5:  Oh my stupid. I also, the fact that they were able to

855
00:51:58,755 --> 00:52:01,615
Speaker 5:  remove a feature for a year and a half,

856
00:52:02,555 --> 00:52:05,295
Speaker 5:  eh, maybe, maybe speaks to how important that feature is.

857
00:52:05,315 --> 00:52:08,615
Speaker 6:  And I mean, I've written it all over, up and down across the, The Verge.

858
00:52:08,615 --> 00:52:11,335
Speaker 6:  It's not that important of a feature. It just isn't. So it's

859
00:52:11,335 --> 00:52:14,975
Speaker 5:  Rough. It's rough. That was once a flagship feature and Yeah,

860
00:52:15,045 --> 00:52:16,655
Speaker 5:  they don't always pan out. No, they

861
00:52:16,655 --> 00:52:16,855
Speaker 6:  Don't.

862
00:52:17,005 --> 00:52:20,175
Speaker 5:  Okay. Final possible shenanigan.

863
00:52:21,405 --> 00:52:24,905
Speaker 5:  As soon as I say the first word, you're gonna know the word Elon Musk

864
00:52:26,135 --> 00:52:29,905
Speaker 5:  says he is suing Apple for rigging the app store. So

865
00:52:30,005 --> 00:52:33,815
Speaker 5:  I'm gonna read this quote. Here's Elon on Twitter, or, sorry,

866
00:52:33,815 --> 00:52:37,735
Speaker 5:  apologies. This is Elon on X. He says, quote, apple

867
00:52:37,795 --> 00:52:41,735
Speaker 5:  is behaving in a manner that makes it impossible for any AI company

868
00:52:41,765 --> 00:52:45,735
Speaker 5:  besides open AI to reach number one in the app store, which is

869
00:52:45,735 --> 00:52:49,095
Speaker 5:  an unequivocal antitrust violation end quote.

870
00:52:50,315 --> 00:52:54,215
Speaker 5:  And so he, he starts by claiming that they're rigging the rankings, but then

871
00:52:54,215 --> 00:52:57,855
Speaker 5:  he kind of pivots very quickly and starts by claiming that actually what

872
00:52:57,855 --> 00:53:01,375
Speaker 5:  they're doing is rigging the app store editorial. 'cause they have a bunch

873
00:53:01,375 --> 00:53:04,015
Speaker 5:  of curated sections where they'll be like our favorite

874
00:53:04,085 --> 00:53:04,375
Speaker 6:  Apps,

875
00:53:04,405 --> 00:53:08,255
Speaker 5:  Like summer hotness, whatever, like check out these AI things and

876
00:53:08,255 --> 00:53:11,375
Speaker 5:  they don't feature gr can you believe they won't feature Grok can believe

877
00:53:12,115 --> 00:53:15,975
Speaker 6:  You mean gr the one that unlaunched like unleashed

878
00:53:16,115 --> 00:53:19,735
Speaker 6:  sex bots very recently and just caught himself cabinet Rudy?

879
00:53:20,475 --> 00:53:24,375
Speaker 6:  Oh no. Why would ever family friendly Apple not

880
00:53:24,435 --> 00:53:28,005
Speaker 6:  put grok in its editorial section where it's allowed to

881
00:53:28,365 --> 00:53:29,925
Speaker 6:  exercise opinions? Oh

882
00:53:31,475 --> 00:53:34,445
Speaker 5:  Yeah. I mean this is here, my feeling is also like

883
00:53:35,255 --> 00:53:39,245
Speaker 5:  these apps aren't even like allowed in the app

884
00:53:39,255 --> 00:53:42,805
Speaker 5:  store, right? Other apps that make deep fake nudes have been

885
00:53:43,185 --> 00:53:47,085
Speaker 5:  banned. Right? They can't ban grok because Elon is too big of

886
00:53:47,125 --> 00:53:49,725
Speaker 5:  a figure. He's already getting special treatment also.

887
00:53:49,725 --> 00:53:53,525
Speaker 6:  Like absolutely his whole, his whole assertion that no other AI company can

888
00:53:53,525 --> 00:53:56,325
Speaker 6:  reach, number one, didn't deep seek reach number one. Right,

889
00:53:56,325 --> 00:54:00,205
Speaker 5:  Right. Actually, there's a community note on his tweet about this

890
00:54:00,775 --> 00:54:02,525
Speaker 5:  being like, actually deep

891
00:54:02,525 --> 00:54:06,285
Speaker 7:  Seek, my favorite also is like Sam Altman and Elon getting into

892
00:54:06,305 --> 00:54:10,085
Speaker 7:  an yet another ex battle where Sam's like, oh, well

893
00:54:10,085 --> 00:54:13,965
Speaker 7:  have you ever f you know, put your own

894
00:54:13,965 --> 00:54:17,365
Speaker 7:  company's as special treatment. Have you ever given your own

895
00:54:17,365 --> 00:54:20,325
Speaker 7:  company's special treatment? I couldn't believe it. So yeah, there's a lot,

896
00:54:20,345 --> 00:54:23,965
Speaker 6:  You know, it feels like he saw what Tim Sweeney did with Epic

897
00:54:24,145 --> 00:54:27,445
Speaker 6:  and he was like, I'm gonna do that. That's gonna work for me.

898
00:54:27,445 --> 00:54:31,365
Speaker 5:  Well, well here's the thing, let me just add a little note there. Tim Sweeney

899
00:54:31,765 --> 00:54:35,445
Speaker 5:  actually filed a lawsuit and Elon Musk at this point has not Mm.

900
00:54:35,715 --> 00:54:37,405
Speaker 7:  He's never going to, he is just gonna tweet about it,

901
00:54:37,535 --> 00:54:41,205
Speaker 5:  Which that is a bit of a pattern for him. Mm. So he, he

902
00:54:41,425 --> 00:54:45,285
Speaker 5:  got a little mad at Apple. He retweeted a bunch of people

903
00:54:45,415 --> 00:54:49,365
Speaker 5:  supporting him. Apple put out a statement later saying that the app store

904
00:54:49,365 --> 00:54:53,325
Speaker 5:  is quote, designed to be fair and free of bias. I don't know what

905
00:54:53,325 --> 00:54:53,605
Speaker 5:  that means.

906
00:54:56,165 --> 00:55:00,045
Speaker 6:  I mean, if it's editorial, it's, you know, like just by the function of the

907
00:55:00,045 --> 00:55:03,405
Speaker 6:  word editorial, there is some kind of opinion in there. But like,

908
00:55:03,825 --> 00:55:04,085
Speaker 6:  to be

909
00:55:04,085 --> 00:55:07,205
Speaker 7:  Fair, yeah, they said it's like a combo of algorithms, you know, recommendations

910
00:55:07,265 --> 00:55:08,405
Speaker 7:  and opinion. So

911
00:55:09,315 --> 00:55:10,565
Speaker 6:  This is a shenanigan. It

912
00:55:10,565 --> 00:55:12,885
Speaker 7:  Definitely is. I'm calling because he knows nothings gonna come of it and

913
00:55:12,885 --> 00:55:16,365
Speaker 7:  he knows that, you know, if it really was number one, it would reach number

914
00:55:16,365 --> 00:55:16,525
Speaker 7:  one.

915
00:55:16,525 --> 00:55:20,245
Speaker 5:  Yeah. This is is nearly as much, this is like, perhaps

916
00:55:20,425 --> 00:55:22,925
Speaker 5:  as much or more of a shenanigan than the perplexity one?

917
00:55:22,935 --> 00:55:24,725
Speaker 7:  Definitely. Maybe more. Yeah.

918
00:55:24,725 --> 00:55:25,165
Speaker 6:  I think it's more

919
00:55:25,345 --> 00:55:27,605
Speaker 5:  Is more, I think it's more, this might be the ultimate one. Perplexity

920
00:55:27,605 --> 00:55:30,685
Speaker 7:  At least had some investors apparently lined up that maybe would front the

921
00:55:30,685 --> 00:55:32,005
Speaker 7:  money, you know? Yeah. They,

922
00:55:32,035 --> 00:55:32,765
Speaker 5:  It's true.

923
00:55:33,075 --> 00:55:36,685
Speaker 6:  They took like an action to to say like, yeah,

924
00:55:36,935 --> 00:55:39,325
Speaker 6:  we're not all total like Bs, but like

925
00:55:39,375 --> 00:55:43,165
Speaker 5:  Right. Elon just rtd a couple of randos on Twitter. Yeah,

926
00:55:43,265 --> 00:55:47,005
Speaker 5:  as always. Yeah. Okay. Okay. So I think what's our running

927
00:55:47,005 --> 00:55:50,685
Speaker 5:  total? Like two and a half shenanigans out of, out of four. Yep.

928
00:55:50,875 --> 00:55:54,165
Speaker 5:  Okay. Okay. This, this is a big week for them.

929
00:55:55,475 --> 00:55:59,125
Speaker 5:  Apple's somehow involved in most of them indirectly or,

930
00:55:59,345 --> 00:56:03,245
Speaker 5:  or directly. It's, it's not always their fault. Okay.

931
00:56:03,495 --> 00:56:06,685
Speaker 5:  We've gotta take a break when we get back the Thunder Round returns.

932
00:57:14,785 --> 00:57:18,165
Speaker 5:  All right, we're back with the thunder round, aka the Lightning round colon,

933
00:57:18,265 --> 00:57:20,245
Speaker 5:  the Thunder round Colon Jake's version.

934
00:57:21,355 --> 00:57:21,765
Speaker 6:  Love it.

935
00:57:22,305 --> 00:57:26,085
Speaker 5:  As you all know, I've been on a power trip since Neli Patel left on

936
00:57:26,085 --> 00:57:29,805
Speaker 5:  parental leave. The lightning round as we know it is done for this is now

937
00:57:29,825 --> 00:57:33,285
Speaker 5:  the thunder round. I have given our producer Eric Gomez, the Power of Thunder

938
00:57:33,505 --> 00:57:37,445
Speaker 5:  to make sure that we keep moving and get through all the important stories

939
00:57:37,485 --> 00:57:41,365
Speaker 5:  that we wanna talk about. So we're gonna do five stories, five minutes each.

940
00:57:41,365 --> 00:57:45,325
Speaker 5:  At 30 seconds we're gonna hear a ble of thunder telling us to move along.

941
00:57:45,345 --> 00:57:49,245
Speaker 5:  If we keep going and get a little too far, we're gonna hear thunder crash

942
00:57:49,275 --> 00:57:53,005
Speaker 5:  down and that's our moment to move along. Alright, let's get started.

943
00:57:53,545 --> 00:57:54,965
Speaker 5:  The, you've got our first story today.

944
00:57:55,035 --> 00:57:58,725
Speaker 6:  Yeah. So my first story is Allison's little adventure turning

945
00:57:59,505 --> 00:58:03,085
Speaker 6:  her LTE Apple watch into her only device.

946
00:58:04,025 --> 00:58:07,645
Speaker 6:  So she's leaving her phone at home, she's going out and she's doing her

947
00:58:07,645 --> 00:58:11,005
Speaker 6:  adventures. And Allison is like annoyingly,

948
00:58:11,715 --> 00:58:14,845
Speaker 6:  well, And I say this with admiration, one of the funniest writers on staff.

949
00:58:14,985 --> 00:58:18,845
Speaker 6:  So just reading this was just delightful. And like, I was just like,

950
00:58:19,265 --> 00:58:22,125
Speaker 6:  she, she reached out to me and she's like, VI have this crazy idea. And I

951
00:58:22,125 --> 00:58:24,525
Speaker 6:  was like, hit me, hit me with it, girl. What, what are you gonna do? And

952
00:58:24,525 --> 00:58:28,365
Speaker 6:  she's like, what if I leave my phone's at home and just live off of a smartwatch?

953
00:58:28,365 --> 00:58:31,605
Speaker 6:  And I went, God bless. Let me know how it goes. I ain't that crazy.

954
00:58:33,105 --> 00:58:36,325
Speaker 6:  Let me see how, how it happens. And it happened like how I thought it would

955
00:58:36,325 --> 00:58:40,245
Speaker 6:  happen, but it tickled me because I think she And I, our,

956
00:58:40,305 --> 00:58:43,845
Speaker 6:  our beats continually like Fuse and merge together because of all the ways

957
00:58:43,845 --> 00:58:47,165
Speaker 6:  that they're stuffing AI into our products. And

958
00:58:47,765 --> 00:58:51,685
Speaker 6:  I think she And I both have just like had a lot of conversations about like

959
00:58:51,685 --> 00:58:55,485
Speaker 6:  needing to step away from our devices in some, some capacity.

960
00:58:55,485 --> 00:58:59,405
Speaker 6:  Like I had, I had a story that came out a couple weeks ago about

961
00:58:59,535 --> 00:59:03,285
Speaker 6:  using Brick, which is like this thing that bricks your phone

962
00:59:03,425 --> 00:59:06,725
Speaker 6:  And I use it during TV time to get my attention back. And she's like, I wanna

963
00:59:06,725 --> 00:59:09,645
Speaker 6:  be more present in the world so I'm gonna leave my phone at home and just

964
00:59:09,665 --> 00:59:13,645
Speaker 6:  use my LTE watch for like connectivity. And of course that comes

965
00:59:13,645 --> 00:59:17,285
Speaker 6:  with its own trials and tribulations. Like she's like, oh

966
00:59:17,475 --> 00:59:20,805
Speaker 6:  shit, how do I call an Uber? Wow. Do you call an Uber

967
00:59:21,075 --> 00:59:25,045
Speaker 6:  without your phone? And like, it was just a really cute meditation on like

968
00:59:25,345 --> 00:59:28,685
Speaker 6:  how reliant we are on these devices. Can you actually replace

969
00:59:29,195 --> 00:59:31,845
Speaker 6:  your, your phone with your smartwatch in any capacity? And

970
00:59:32,045 --> 00:59:34,925
Speaker 5:  I had a lot of fun. So the way I know this kind of worked is that, so this

971
00:59:34,925 --> 00:59:38,205
Speaker 5:  is Alison Johnson, senior reviewer for The Verge. The way I know it worked

972
00:59:38,505 --> 00:59:42,125
Speaker 5:  is that unlike Friday I was, I was saying to something, I'm like, no, I haven't

973
00:59:42,125 --> 00:59:45,165
Speaker 5:  heard much from Allison this week. What's she up to? And someone was like,

974
00:59:45,625 --> 00:59:49,565
Speaker 5:  oh yeah, she just like hasn't been using her phone all week for her

975
00:59:49,565 --> 00:59:53,445
Speaker 5:  job and so she hasn't been talking to us. And I'm like, that was so effective.

976
00:59:53,445 --> 00:59:57,405
Speaker 5:  Yeah, that worked. It really, it worked. I just like, yeah, you know, like

977
00:59:57,405 --> 01:00:00,965
Speaker 5:  that it was harder to get in touch with her de but I guess that was sort

978
01:00:00,965 --> 01:00:03,325
Speaker 5:  of the point was functional. She was dead, she did a good job.

979
01:00:03,585 --> 01:00:06,765
Speaker 7:  My favorite part was when she said she had visions of herself sitting at

980
01:00:06,765 --> 01:00:10,645
Speaker 7:  a table at a sidewalk cafe wearing a billowy skirt, but she doesn't

981
01:00:10,645 --> 01:00:13,365
Speaker 7:  own a billowy skirt. Like that was the energy she was gonna give off.

982
01:00:13,635 --> 01:00:17,085
Speaker 5:  Okay, so I have a question and it's not for you VI know the answer,

983
01:00:17,225 --> 01:00:18,725
Speaker 5:  Hayden, are you a smartwatch person?

984
01:00:19,225 --> 01:00:22,805
Speaker 7:  No, I hate having things on my wrist. Like I can't, I don't the feeling

985
01:00:23,155 --> 01:00:26,925
Speaker 7:  it's like, I think it's 'cause I do boxing as a workout. So a lot of people

986
01:00:26,945 --> 01:00:30,285
Speaker 7:  use smartwatches as like a workout tracker also. And I would always have

987
01:00:30,285 --> 01:00:34,205
Speaker 7:  to take it off 'cause I box. So I feel like I just don't like feeling something

988
01:00:34,545 --> 01:00:38,245
Speaker 7:  on my wrist like that. I don't know. I can deal with rings, but not big

989
01:00:38,485 --> 01:00:39,365
Speaker 7:  bracelets or anything like that.

990
01:00:39,545 --> 01:00:42,525
Speaker 5:  So it's been a while since I've been like a regular smartwatch person. I

991
01:00:42,525 --> 01:00:45,805
Speaker 5:  bought the original Apple Watch and then I immediately bought an Android

992
01:00:45,805 --> 01:00:48,685
Speaker 5:  phone and it was just like, I just like had this watch that I couldn't use.

993
01:00:49,105 --> 01:00:51,925
Speaker 5:  The thing that I think is really interesting about this is like there's this,

994
01:00:52,425 --> 01:00:56,285
Speaker 5:  the, the sort of the conceit is okay, the watch is less

995
01:00:56,565 --> 01:01:00,325
Speaker 5:  distracting than the phone, but I sort of wonder, and v this is a question

996
01:01:00,385 --> 01:01:04,165
Speaker 5:  for you now, isn't the watch a little more annoying? 'cause it's literally

997
01:01:04,175 --> 01:01:07,845
Speaker 5:  physically on your wrist there at all times and it's shaken around

998
01:01:07,905 --> 01:01:10,925
Speaker 5:  trying to alert you to everything. It's, that almost seems more distracting.

999
01:01:11,065 --> 01:01:14,565
Speaker 6:  It can be more distracting. Especially when you wear

1000
01:01:15,105 --> 01:01:18,885
Speaker 6:  to any given point in time. And they have

1001
01:01:18,885 --> 01:01:21,965
Speaker 6:  different notification settings just because like quick,

1002
01:01:21,965 --> 01:01:24,005
Speaker 5:  Quick wearable check. I think there's three on you today.

1003
01:01:24,005 --> 01:01:26,645
Speaker 6:  There's three on me today. Yeah. Well there's three on me today and two more

1004
01:01:26,645 --> 01:01:29,965
Speaker 6:  at my desk because they're glasses and so, you know that that's the whole

1005
01:01:29,965 --> 01:01:33,885
Speaker 6:  thing. But yeah, there I do get buzzes

1006
01:01:33,925 --> 01:01:37,725
Speaker 6:  a lot and especially on this Garmin that I'm, I'm testing at the moment because

1007
01:01:37,915 --> 01:01:41,565
Speaker 6:  it's a little less discerning with what notifications I get.

1008
01:01:41,705 --> 01:01:44,965
Speaker 6:  So it's just like, oh, they texted you. Oh, they texted you, eh, they texted

1009
01:01:44,965 --> 01:01:47,325
Speaker 6:  you and like they buzz. So,

1010
01:01:47,505 --> 01:01:51,485
Speaker 7:  And I can't answer this as a objective third party because whenever I'm

1011
01:01:51,485 --> 01:01:55,325
Speaker 7:  with someone who has an Apple watch or a smart watch, you know, it

1012
01:01:55,325 --> 01:01:58,125
Speaker 7:  makes me nervous. 'cause they're always looking at their wrist and I'm like,

1013
01:01:58,125 --> 01:02:01,245
Speaker 7:  oh, is it, am I boring you? Is it time to go? Obviously it's just they're

1014
01:02:01,245 --> 01:02:04,485
Speaker 7:  getting a text and they're like, oh sorry. But you know, it can be,

1015
01:02:04,635 --> 01:02:08,125
Speaker 6:  It's, it's definitely a, a social cue for sure where like,

1016
01:02:08,425 --> 01:02:12,245
Speaker 6:  I'm very cognizant of it, of just like things buzzing and being like

1017
01:02:15,015 --> 01:02:18,805
Speaker 6:  going back down looking at my wrist. Like I, I, I do,

1018
01:02:19,565 --> 01:02:21,645
Speaker 6:  I do think it's a different kind of distraction

1019
01:02:21,795 --> 01:02:25,325
Speaker 5:  Like with my phone if I do need to, like if, if I'm sitting down for dinner

1020
01:02:25,325 --> 01:02:29,045
Speaker 5:  with my wife, like I will put my phone somewhere else so that it's not

1021
01:02:29,285 --> 01:02:32,725
Speaker 5:  distracting me. 'cause like, listen, love y'all. But I get a, I got a lot

1022
01:02:32,725 --> 01:02:36,485
Speaker 5:  of slack pings all right. Like they do not stop. And

1023
01:02:36,625 --> 01:02:40,005
Speaker 5:  if, if it's on my person, if I know it's buzzed then there's just like a,

1024
01:02:40,035 --> 01:02:43,485
Speaker 5:  there's always that tension in my mind where I'm like, I gotta find out what

1025
01:02:43,485 --> 01:02:46,725
Speaker 5:  this is. I gotta find out if it's important. Sometimes it's just the weather.

1026
01:02:46,725 --> 01:02:49,565
Speaker 5:  Sometimes it's just telling me it's gonna rain And I did not need to see

1027
01:02:49,565 --> 01:02:53,045
Speaker 5:  that. And I do like that I can just like take my phone outta my pocket and

1028
01:02:53,045 --> 01:02:54,965
Speaker 5:  put it somewhere else. I'm with the watch. You're sort of

1029
01:02:54,965 --> 01:02:58,485
Speaker 6:  Like, that's why you gotta get the flippy flip dismiss that I do it all the

1030
01:02:58,485 --> 01:02:58,885
Speaker 6:  time. Just go.

1031
01:02:59,825 --> 01:03:02,805
Speaker 5:  So you're just eating and being like flinging your arm around?

1032
01:03:02,805 --> 01:03:04,085
Speaker 6:  Yeah. Yeah. That's not distracting at all.

1033
01:03:04,085 --> 01:03:06,485
Speaker 5:  Okay. Okay. Alright Hayden, you're up.

1034
01:03:06,755 --> 01:03:10,645
Speaker 7:  Okay, so mine is how doctors are getting worse at detecting

1035
01:03:10,645 --> 01:03:14,525
Speaker 7:  cancer after they rely on ai. So really

1036
01:03:14,735 --> 01:03:18,565
Speaker 7:  scary and sad. Basically a new study just published this week found

1037
01:03:18,565 --> 01:03:22,085
Speaker 7:  that doctors who usually use AI to detect cancer and

1038
01:03:22,595 --> 01:03:26,405
Speaker 7:  colonoscopies now when it's taken away from

1039
01:03:26,405 --> 01:03:30,125
Speaker 7:  them, they got way worse at detecting cancer than they were before they ever

1040
01:03:30,125 --> 01:03:33,685
Speaker 7:  used ai. 'cause they basically got lazy, like their brains were used to just

1041
01:03:33,685 --> 01:03:37,245
Speaker 7:  relying on AI and kind of double checking it. And then even with all their

1042
01:03:37,445 --> 01:03:41,325
Speaker 7:  training when you take the AI away, they became way worse. I think six percentage

1043
01:03:41,325 --> 01:03:42,005
Speaker 7:  points worse.

1044
01:03:42,505 --> 01:03:43,925
Speaker 5:  Oh, that's a little horrifying to me.

1045
01:03:43,925 --> 01:03:47,285
Speaker 6:  That's not good. That's very upsetting. That's, hmm.

1046
01:03:47,705 --> 01:03:51,365
Speaker 7:  You know, and they, yeah, they found like across countries, Poland, the,

1047
01:03:51,385 --> 01:03:55,245
Speaker 7:  the researchers came from Poland, Norway, Sweden, the UK and Japan. They

1048
01:03:55,245 --> 01:03:59,045
Speaker 7:  looked at four medical centers in Poland that were part of a trial program,

1049
01:03:59,505 --> 01:04:03,245
Speaker 7:  you know, using AI and colonoscopies and yeah, basically these doctors

1050
01:04:03,385 --> 01:04:07,165
Speaker 7:  are just gonna be SOL for whenever they stop God using ai. God, that's,

1051
01:04:07,165 --> 01:04:10,245
Speaker 5:  This is really interesting because I feel like there's been so much like

1052
01:04:10,595 --> 01:04:14,245
Speaker 5:  fear and concern. Like, AI's gonna make you dumber, AI's gonna make you dumber.

1053
01:04:14,345 --> 01:04:18,045
Speaker 5:  And I've been like trying to grapple with this where it's like, okay, I don't,

1054
01:04:18,165 --> 01:04:21,605
Speaker 5:  I don't know how to use the Dewey decimal system, right? I don't know how

1055
01:04:21,605 --> 01:04:25,325
Speaker 5:  to go find a book and then look in the glossary and find the page

1056
01:04:25,385 --> 01:04:29,165
Speaker 5:  and f you know, read the context and figure out, right, I'm not reading as

1057
01:04:29,165 --> 01:04:32,285
Speaker 5:  much because I'm just gonna Google and I'm and Right. And Google's just giving

1058
01:04:32,285 --> 01:04:35,645
Speaker 5:  me, and then I read a website that's been written for me really nicely. So

1059
01:04:35,645 --> 01:04:38,805
Speaker 5:  like, okay, am I dumber because I use Google instead of going to a library

1060
01:04:38,895 --> 01:04:42,525
Speaker 5:  maybe a little bit. And so I'm like, okay, are we, are we kind of

1061
01:04:42,525 --> 01:04:45,765
Speaker 5:  overreacting with some of this AI stuff? But this is, this is concerning

1062
01:04:45,765 --> 01:04:46,765
Speaker 5:  to me because like, I

1063
01:04:46,765 --> 01:04:50,525
Speaker 6:  Think it's like GPS, right? Like if you always use GPS on your car

1064
01:04:50,825 --> 01:04:54,445
Speaker 6:  and then you just never, like, I'm calling out my spouse here.

1065
01:04:54,555 --> 01:04:57,605
Speaker 6:  Like they don't know how to get to a place that's five minutes away because

1066
01:04:57,605 --> 01:05:01,525
Speaker 6:  they always have GPS, so they only put GPS and when CarPlay doesn't

1067
01:05:01,525 --> 01:05:05,165
Speaker 6:  work and it's five minutes away, you've driven there a million times, they

1068
01:05:05,165 --> 01:05:06,085
Speaker 6:  don't know how to get there.

1069
01:05:06,345 --> 01:05:07,365
Speaker 7:  That's me. Oh

1070
01:05:07,365 --> 01:05:08,445
Speaker 5:  Yeah, no, not a chance.

1071
01:05:08,765 --> 01:05:11,205
Speaker 6:  I think, I think that's kind of analogous to what's happening here with the

1072
01:05:11,205 --> 01:05:14,405
Speaker 6:  doctor. Yeah. So like even, you know how to drive, you could probably do

1073
01:05:14,405 --> 01:05:15,285
Speaker 6:  it on your own, but

1074
01:05:15,855 --> 01:05:19,765
Speaker 7:  Definitely. And you've also, I think it's also like a, a

1075
01:05:19,765 --> 01:05:23,605
Speaker 7:  thing when I found in a, some recent reporting I did on a Google Health,

1076
01:05:24,595 --> 01:05:28,485
Speaker 7:  like medical AI hallucination that people that double check

1077
01:05:28,875 --> 01:05:32,045
Speaker 7:  AI's work also get a little bit lazy and it's just kind of human nature.

1078
01:05:32,045 --> 01:05:35,885
Speaker 7:  If something's usually right, you're gonna not find

1079
01:05:36,065 --> 01:05:40,005
Speaker 7:  the discrepancies or the errors as much because you're like, oh, it's

1080
01:05:40,245 --> 01:05:43,485
Speaker 7:  probably right and you're usually not gonna, you know, pinpoint when it's

1081
01:05:43,485 --> 01:05:46,285
Speaker 7:  wrong. And so I think it's kind of the same thing. It's like if your brain

1082
01:05:46,305 --> 01:05:49,605
Speaker 7:  is used to relying on something, something that's usually right,

1083
01:05:50,285 --> 01:05:53,165
Speaker 7:  you're just gonna get worse at doing it on your own and you're gonna get

1084
01:05:53,165 --> 01:05:55,205
Speaker 7:  worse at identifying when it's wrong probably.

1085
01:05:55,435 --> 01:05:58,685
Speaker 5:  Yeah. Hayden, I thought this piece you wrote, I think it was last week, was

1086
01:05:59,045 --> 01:06:03,005
Speaker 5:  fascinating where you found that, what was it, a Google research paper

1087
01:06:03,705 --> 01:06:07,575
Speaker 5:  had merged the name of two different areas of the brain

1088
01:06:07,955 --> 01:06:09,135
Speaker 5:  and kind of no one noticed

1089
01:06:09,485 --> 01:06:12,935
Speaker 7:  Exactly. It had more than 50 authors on it and they also had

1090
01:06:13,085 --> 01:06:16,855
Speaker 7:  doctors look at it before they published it. It was like the debut

1091
01:06:17,055 --> 01:06:20,935
Speaker 7:  research paper for Google's healthcare AI model, which they were positioning

1092
01:06:20,935 --> 01:06:24,655
Speaker 7:  to doctors as, you know, a good way to double check things, you know,

1093
01:06:25,085 --> 01:06:28,495
Speaker 7:  flag things, especially things missed by radiologists. And yeah, I mean it

1094
01:06:28,605 --> 01:06:32,255
Speaker 7:  made up a body parts. Google said it was just a

1095
01:06:32,255 --> 01:06:36,055
Speaker 7:  misspelling, but it was conflating essentially two different areas

1096
01:06:36,115 --> 01:06:40,015
Speaker 7:  of the brain. And if you did have an abnormality or a

1097
01:06:40,015 --> 01:06:43,455
Speaker 7:  stroke in one of those two areas, it would be treated differently from the

1098
01:06:43,455 --> 01:06:46,655
Speaker 7:  other. So I mean, it is a problem if, if you know, and especially like we

1099
01:06:46,655 --> 01:06:49,855
Speaker 7:  just said, if you're a doctor reading this and you're probably not gonna

1100
01:06:49,885 --> 01:06:53,495
Speaker 7:  find the error, just like they did in the actual research paper,

1101
01:06:53,835 --> 01:06:57,495
Speaker 7:  you may skip over it and maybe even mistreat the actual thing.

1102
01:06:57,755 --> 01:07:01,335
Speaker 6:  The term sounded real basilar ganglia. That sounds real.

1103
01:07:01,855 --> 01:07:04,815
Speaker 6:  'cause there is like a basilar thing in a ganglia in your brain. So,

1104
01:07:05,245 --> 01:07:08,655
Speaker 5:  Well, and this is what I thought was so interesting about that where, you

1105
01:07:08,655 --> 01:07:12,095
Speaker 5:  know, you, you have people in the story saying like, oh, it's, it's like

1106
01:07:12,135 --> 01:07:16,055
Speaker 5:  a common typo. Like people figure it out. But, but I do think like, okay,

1107
01:07:16,285 --> 01:07:19,855
Speaker 5:  sure may maybe they would've figured it out, but the turn is

1108
01:07:20,635 --> 01:07:24,575
Speaker 5:  if they get used to not checking right? Then you get into a

1109
01:07:24,575 --> 01:07:28,295
Speaker 5:  problem. And this study sort of emphasizes that where it's like

1110
01:07:28,365 --> 01:07:32,255
Speaker 5:  uhoh like In fact they are getting worse at it. In fact, that could make

1111
01:07:32,255 --> 01:07:34,455
Speaker 5:  medical care worse. And so like that gets a

1112
01:07:34,455 --> 01:07:34,575
Speaker 7:  Little,

1113
01:07:35,165 --> 01:07:36,055
Speaker 5:  It's concerning. Listen,

1114
01:07:36,145 --> 01:07:39,775
Speaker 6:  Check GPT five is better at healthcare, so says Sam

1115
01:07:40,015 --> 01:07:40,255
Speaker 6:  Altman.

1116
01:07:42,005 --> 01:07:45,935
Speaker 5:  Yeah. And we'll see healthcare coding is,

1117
01:07:46,195 --> 01:07:48,375
Speaker 5:  it is just telling you to do the healthcare yourself. It's just

1118
01:07:49,075 --> 01:07:50,335
Speaker 6:  That's us healthcare system

1119
01:07:50,365 --> 01:07:54,055
Speaker 7:  Kind. I am, I am interested in how this affects people with health anxiety

1120
01:07:54,055 --> 01:07:57,735
Speaker 7:  because basically it said, oh, it's better at answering your questions about

1121
01:07:57,735 --> 01:07:59,695
Speaker 7:  your condition and it telling you what it might be.

1122
01:08:00,555 --> 01:08:02,975
Speaker 6:  And I have health anxiety's not good. It's bad.

1123
01:08:02,975 --> 01:08:04,895
Speaker 7:  It's, it's gonna be interesting for sure.

1124
01:08:05,525 --> 01:08:09,265
Speaker 5:  Okay, next story. A OL is

1125
01:08:09,425 --> 01:08:13,145
Speaker 5:  shutting down after 34 years, AOL dial up, I should say

1126
01:08:13,325 --> 01:08:15,685
Speaker 5:  AOL dial up is done after three decades.

1127
01:08:17,245 --> 01:08:18,685
Speaker 7:  R-I-P-I-I

1128
01:08:18,685 --> 01:08:19,285
Speaker 6:  Can hear it in my

1129
01:08:19,285 --> 01:08:22,685
Speaker 5:  Head. It's, I know it's beautiful, beautiful noise in retrospect.

1130
01:08:23,765 --> 01:08:27,045
Speaker 5:  I apparently, according to the 2023 US census,

1131
01:08:27,455 --> 01:08:29,845
Speaker 5:  there are currently, or there were around

1132
01:08:30,085 --> 01:08:33,525
Speaker 5:  160,000 people who still had dial-up internet,

1133
01:08:34,175 --> 01:08:35,885
Speaker 5:  which is sort of

1134
01:08:36,755 --> 01:08:37,045
Speaker 6:  Slow

1135
01:08:37,385 --> 01:08:38,285
Speaker 7:  Lot more than I explain.

1136
01:08:38,845 --> 01:08:40,565
Speaker 5:  I don't, I I wanna know what they're paying really

1137
01:08:40,725 --> 01:08:41,445
Speaker 7:  Peaceful lives, you know?

1138
01:08:43,335 --> 01:08:46,975
Speaker 5:  Right. What, this is the real question. What are they doing with it? You

1139
01:08:46,975 --> 01:08:48,575
Speaker 5:  can't load anything on that internet right now.

1140
01:08:49,085 --> 01:08:52,775
Speaker 7:  They're definitely just looking at like their a OL inbox and maybe like the

1141
01:08:52,935 --> 01:08:54,335
Speaker 7:  MSN homepage. That's what I think.

1142
01:08:54,715 --> 01:08:56,135
Speaker 6:  Is it Yahoo? They use Yahoo.

1143
01:08:56,395 --> 01:08:57,735
Speaker 7:  Oh definitely. Yahoo. Oh yeah,

1144
01:08:57,735 --> 01:09:01,695
Speaker 5:  Yeah. Actually can I say when I, when I looked up the, the

1145
01:09:01,745 --> 01:09:05,095
Speaker 5:  Apple core settlement with Apple Inc.

1146
01:09:05,695 --> 01:09:09,495
Speaker 5:  From 2007, the press release, the spokesperson

1147
01:09:09,955 --> 01:09:13,735
Speaker 5:  for Apple core AOL email address, those are 2 0 7. Wow.

1148
01:09:13,945 --> 01:09:17,495
Speaker 5:  Right. AOL is still around. You still see I haven't seen an AOL email address

1149
01:09:17,495 --> 01:09:21,415
Speaker 5:  in a while. You still get the Yahoos, you still get the MSN Not so

1150
01:09:21,415 --> 01:09:21,535
Speaker 5:  much.

1151
01:09:22,095 --> 01:09:24,615
Speaker 6:  I just, that sound though is forever in my head. Yeah. You

1152
01:09:24,615 --> 01:09:27,975
Speaker 7:  Know, maybe it'll become cool to have an a OL email address. You know, like

1153
01:09:28,155 --> 01:09:30,495
Speaker 7:  the, it's a nostalgia thing. I don't know, I could see that

1154
01:09:30,495 --> 01:09:34,095
Speaker 5:  Happening. Is that the like digit camm of emails? You're like, oh, Gmail

1155
01:09:34,195 --> 01:09:38,055
Speaker 5:  is for the millennials, we gotta, we're gonna like buy old a OL

1156
01:09:38,055 --> 01:09:38,895
Speaker 5:  addresses. Oh my god.

1157
01:09:39,075 --> 01:09:42,375
Speaker 6:  Happen. Especially since like, the inbox isn't unlimited, so you actually,

1158
01:09:42,445 --> 01:09:45,255
Speaker 6:  it's gonna be like a mindfulness thing where they're just like, oh, you only

1159
01:09:45,255 --> 01:09:48,375
Speaker 6:  have 50 emails that you can have any given point in time.

1160
01:09:48,425 --> 01:09:49,655
Speaker 7:  Again, they're probably so zen.

1161
01:09:50,005 --> 01:09:53,975
Speaker 5:  Were you both a OL dial up users back in the day? Yes. Yeah. Yeah. Same.

1162
01:09:54,955 --> 01:09:58,865
Speaker 5:  And it's, it's, I mean I, I barely remember it

1163
01:09:58,865 --> 01:10:02,625
Speaker 5:  at this point. I remember it like, it was an app though. It was like an app

1164
01:10:02,625 --> 01:10:05,545
Speaker 5:  that you enter into. It was this, like this contained experience.

1165
01:10:06,415 --> 01:10:09,745
Speaker 6:  There's just like sound bites that I remember one, there's the connecting

1166
01:10:09,745 --> 01:10:12,545
Speaker 6:  thing for the dial up, but then also you got mail.

1167
01:10:12,605 --> 01:10:13,345
Speaker 5:  Oh my god. Yeah.

1168
01:10:13,345 --> 01:10:16,865
Speaker 6:  And like, welcome to a OL or something like that. And just like what the

1169
01:10:16,865 --> 01:10:17,785
Speaker 6:  homepage looked like. And

1170
01:10:17,815 --> 01:10:19,785
Speaker 7:  That was my neo pets era. Oh yeah.

1171
01:10:19,785 --> 01:10:22,985
Speaker 6:  My god. That was mine too. Going to the free omelet every day.

1172
01:10:23,165 --> 01:10:26,825
Speaker 7:  Oh my gosh, that was so good. That's my shop song was

1173
01:10:27,065 --> 01:10:28,745
Speaker 7:  an Abba song. So good. Oh,

1174
01:10:29,005 --> 01:10:31,785
Speaker 5:  Neo Pet's still going strong though. It's, that is,

1175
01:10:32,265 --> 01:10:35,545
Speaker 7:  I tried to log in sometime in the past year and they deleted my account.

1176
01:10:35,845 --> 01:10:36,505
Speaker 7:  It was devastating.

1177
01:10:36,885 --> 01:10:39,905
Speaker 6:  My pork alerts, they're, they're all gone.

1178
01:10:40,285 --> 01:10:44,105
Speaker 5:  All right. Wow. A OL you had a run that

1179
01:10:44,445 --> 01:10:47,265
Speaker 5:  lasted way, way longer than it should have.

1180
01:10:48,595 --> 01:10:52,305
Speaker 5:  Thank you for getting us online and for imprinting that terrible noise in

1181
01:10:52,325 --> 01:10:52,945
Speaker 5:  all of our heads.

1182
01:10:54,385 --> 01:10:54,985
Speaker 6:  I hear it in my

1183
01:10:54,985 --> 01:10:57,905
Speaker 5:  Dream as we should next, next week on the thunder round, we're replacing

1184
01:10:57,905 --> 01:11:00,105
Speaker 5:  the thunder with the screech. Oh my

1185
01:11:00,105 --> 01:11:03,345
Speaker 7:  Gosh. Let's all make our ringtones sound

1186
01:11:04,005 --> 01:11:04,545
Speaker 7:  or our phone

1187
01:11:04,545 --> 01:11:08,425
Speaker 5:  Alarms, you know, that will really help us, you know, reduce

1188
01:11:08,525 --> 01:11:12,265
Speaker 5:  our desire to be near our phones. True. If they were like glaring that noise

1189
01:11:12,285 --> 01:11:13,185
Speaker 5:  all the time. Hundred

1190
01:11:13,285 --> 01:11:14,205
Speaker 6:  Percent. Oh God.

1191
01:11:14,555 --> 01:11:16,405
Speaker 5:  Okay. V what have you got for us?

1192
01:11:16,745 --> 01:11:20,685
Speaker 6:  We have the Pebble Time too because, oh, I got a, I got

1193
01:11:20,685 --> 01:11:24,525
Speaker 6:  a little email from Eric Koski who is the core devices CEO

1194
01:11:24,525 --> 01:11:28,285
Speaker 6:  and co-founder of the Pebble watches. And he's just like, we

1195
01:11:28,305 --> 01:11:32,085
Speaker 6:  got a design reveal the Pebble Time too. And because Pebble is

1196
01:11:32,085 --> 01:11:35,805
Speaker 6:  Pebble again, very recently they got the name back because they had

1197
01:11:36,345 --> 01:11:40,045
Speaker 6:  had to rebrand as core devices. So it was gonna be the core time two

1198
01:11:40,965 --> 01:11:44,445
Speaker 6:  and the core two duo. And like everyone was making intel chip jokes. But

1199
01:11:44,445 --> 01:11:48,125
Speaker 6:  it's back to being Pebble and it's really, I brought this one up because

1200
01:11:48,605 --> 01:11:52,285
Speaker 6:  we knew Pebble was coming back. We knew that Pebble just had these

1201
01:11:52,675 --> 01:11:56,645
Speaker 6:  diehard community fans for open source, smart watching. And it

1202
01:11:56,645 --> 01:11:59,605
Speaker 6:  was just interesting because in the comments on this, there seemed to be

1203
01:11:59,605 --> 01:12:02,565
Speaker 6:  like a war of ideologies of people who were like,

1204
01:12:03,385 --> 01:12:03,605
Speaker 6:  yes,

1205
01:12:04,155 --> 01:12:08,005
Speaker 14:  Finally the Pebble has returned and my life is complete again.

1206
01:12:08,165 --> 01:12:11,885
Speaker 6:  I read it. And that, that those voices, every single of the, one of the pebble

1207
01:12:11,885 --> 01:12:15,525
Speaker 6:  diehards, because for the last decade they've been in my dms going,

1208
01:12:15,525 --> 01:12:15,885
Speaker 6:  nothing

1209
01:12:15,955 --> 01:12:18,285
Speaker 14:  Will ever replace my pebble. I love it so much.

1210
01:12:20,185 --> 01:12:23,965
Speaker 6:  And then there are other people going just like, I dunno man, I need

1211
01:12:24,125 --> 01:12:27,885
Speaker 6:  LTE on my smartwatch. I need like NFC on my smartwatch. I needed to

1212
01:12:27,905 --> 01:12:31,685
Speaker 6:  do modern things. And like, those are very purposefully not on the

1213
01:12:31,685 --> 01:12:35,245
Speaker 6:  Pebble Time too. Like it's got RGB lighting, it's got a really retro design.

1214
01:12:35,315 --> 01:12:39,285
Speaker 6:  It's got ePaper as its display. It kind of feels

1215
01:12:39,475 --> 01:12:43,365
Speaker 6:  like one of those dumb phone devices. But

1216
01:12:43,365 --> 01:12:47,125
Speaker 6:  for your smartwatch, it's very retro. It's, it's, it's just gonna do the

1217
01:12:47,125 --> 01:12:50,885
Speaker 6:  simplistic minimalistic things. And it was interesting waiting into the comments

1218
01:12:51,025 --> 01:12:52,325
Speaker 6:  to see people who are just like,

1219
01:12:53,345 --> 01:12:54,845
Speaker 5:  Yes, pebble.

1220
01:12:55,585 --> 01:12:58,965
Speaker 6:  And then other people going like, it's ugly. Why would you do this? Like,

1221
01:12:58,975 --> 01:13:02,765
Speaker 6:  we're beyond this point. And I was just like, wow. It's so, it's so wild.

1222
01:13:02,915 --> 01:13:05,205
Speaker 6:  Just watching this play out in the comments. So.

1223
01:13:05,235 --> 01:13:09,165
Speaker 5:  Well I also suspect that like there's a, there's a real degree to

1224
01:13:09,165 --> 01:13:12,885
Speaker 5:  which if anybody thought that this was a real

1225
01:13:12,985 --> 01:13:16,565
Speaker 5:  threat to the smartwatch market, this would not have been allowed to happen.

1226
01:13:16,705 --> 01:13:20,565
Speaker 5:  No. Like literally would not have been. No. Google owned all of

1227
01:13:20,565 --> 01:13:21,405
Speaker 5:  this. Yeah, Google

1228
01:13:21,775 --> 01:13:23,285
Speaker 6:  Legit was just like, have

1229
01:13:23,285 --> 01:13:24,525
Speaker 5:  At. Right. Go.

1230
01:13:24,625 --> 01:13:25,645
Speaker 6:  Go have fun. Google

1231
01:13:25,645 --> 01:13:29,325
Speaker 5:  Was like, do the thing if if it makes you happy. Like where

1232
01:13:29,325 --> 01:13:33,205
Speaker 5:  literally right. Like Google, Google makes the Pixel

1233
01:13:33,335 --> 01:13:37,245
Speaker 5:  watch, right. That thing's not flying off store shelves. It's a lovely smart

1234
01:13:37,245 --> 01:13:38,925
Speaker 5:  watch. Not flying off store shelves i's

1235
01:13:38,925 --> 01:13:39,485
Speaker 6:  A great smart watch.

1236
01:13:39,585 --> 01:13:43,005
Speaker 5:  And even they are like, yeah, you can compete with us. It's fun. Yeah. It's

1237
01:13:43,005 --> 01:13:46,165
Speaker 5:  like, is that's not, that's not the opposite of the Apple and Apple cinemas

1238
01:13:46,165 --> 01:13:47,285
Speaker 5:  thing. Yes, yes.

1239
01:13:47,915 --> 01:13:51,805
Speaker 6:  It's literally like, oh, you, you guys want your little pebble back. Have

1240
01:13:51,805 --> 01:13:52,525
Speaker 6:  fun. Come on in

1241
01:13:52,525 --> 01:13:53,245
Speaker 5:  And compete. Come

1242
01:13:53,245 --> 01:13:54,325
Speaker 6:  On in, come on, go in, come on.

1243
01:13:54,465 --> 01:13:57,885
Speaker 5:  But it is nice, right? I mean I, this is sort of like a little bit

1244
01:13:57,995 --> 01:14:01,285
Speaker 5:  playing off of what, what Allison did where it's like, this is going even

1245
01:14:01,285 --> 01:14:04,365
Speaker 5:  simpler. This is like, the watch is not gonna bug you.

1246
01:14:04,745 --> 01:14:08,245
Speaker 6:  No. Like you get your notifications, you can do a little bit of step tracking.

1247
01:14:08,245 --> 01:14:11,325
Speaker 6:  There's a compass in there, have about do what you will. There's a little

1248
01:14:11,325 --> 01:14:15,045
Speaker 6:  community that's been like keeping the pebble going, you know, during the

1249
01:14:15,045 --> 01:14:18,405
Speaker 6:  dark ages where there was no support and whatnot. Just a little community

1250
01:14:18,405 --> 01:14:22,285
Speaker 6:  of ragtag pebbles going and keeping this

1251
01:14:22,285 --> 01:14:25,285
Speaker 6:  thing alive and popping into every single smartwatch review that I've written

1252
01:14:25,285 --> 01:14:27,125
Speaker 6:  over the last however many years going,

1253
01:14:28,005 --> 01:14:29,045
Speaker 7:  I miss my pebble,

1254
01:14:29,445 --> 01:14:29,965
Speaker 5:  I miss my

1255
01:14:29,965 --> 01:14:31,565
Speaker 6:  Pebble. You know, like the, just like that kind

1256
01:14:31,565 --> 01:14:34,605
Speaker 5:  Stuff. It was a nice, it was a nice watch. And I think there's also, it is

1257
01:14:34,605 --> 01:14:37,245
Speaker 5:  like the ethos of it, right? Yeah. Because there's, I don't think there's

1258
01:14:37,445 --> 01:14:38,565
Speaker 5:  anything else. There's

1259
01:14:38,565 --> 01:14:39,005
Speaker 6:  Nothing else white

1260
01:14:39,155 --> 01:14:42,965
Speaker 5:  Like that white like in, in, you know, mainstream consumer technology that's

1261
01:14:42,965 --> 01:14:45,765
Speaker 5:  as like Tinker Tinker or friendly. It's

1262
01:14:45,965 --> 01:14:47,525
Speaker 7:  A cute watch. A cute name. Yeah. And

1263
01:14:47,525 --> 01:14:50,285
Speaker 6:  Also just like, you know, smart watches and I've written this time and time

1264
01:14:50,285 --> 01:14:53,605
Speaker 6:  again, they kind of feel like the vanguards of walled garden

1265
01:14:54,065 --> 01:14:57,885
Speaker 6:  oss. Yes. Because they're there for you to stay stuck

1266
01:14:57,905 --> 01:15:01,685
Speaker 6:  to a particular phone. So everything is super siloed. So for Pebble to be

1267
01:15:01,685 --> 01:15:04,845
Speaker 6:  back out here and they're like, Hey, I'll open source. Let's have fun

1268
01:15:06,075 --> 01:15:09,765
Speaker 6:  Yolo, let's go. Like, it's just nice to have that vibe

1269
01:15:09,875 --> 01:15:13,445
Speaker 6:  come back at a time where like smart watches as a whole are super

1270
01:15:13,845 --> 01:15:16,645
Speaker 6:  duper siloed and that's why I have to carry around three fricking songs.

1271
01:15:17,345 --> 01:15:20,565
Speaker 5:  No, I completely agree. And it's, I mean it's, it's really funny. Like this

1272
01:15:20,565 --> 01:15:24,445
Speaker 5:  is like an updated version of the Pebble Time two, was

1273
01:15:24,445 --> 01:15:25,325
Speaker 5:  that what the original name was?

1274
01:15:25,345 --> 01:15:27,285
Speaker 6:  It was the Pebble Time. It was the pe but this is the Pebble Time two.

1275
01:15:27,345 --> 01:15:30,845
Speaker 5:  Oh, so this is actually a sequel now. Yeah. It still looks mostly the same.

1276
01:15:30,845 --> 01:15:34,045
Speaker 5:  Yeah, it does. But like a little refined. And as far as I'm aware, the specs

1277
01:15:34,045 --> 01:15:37,365
Speaker 5:  like are barely changing. Right. It's mostly's mostly

1278
01:15:37,825 --> 01:15:41,685
Speaker 5:  the same device Better. Mostly the same feature set as it was 10 years

1279
01:15:41,685 --> 01:15:45,645
Speaker 5:  ago. Yep. It's, there's like no other device. You could be

1280
01:15:45,645 --> 01:15:49,335
Speaker 5:  like, I don't know if people were like iPhone five, here it is. Honestly.

1281
01:15:49,335 --> 01:15:52,935
Speaker 5:  Okay, I'm saying this. I might buy that. The iPhone five looked really good.

1282
01:15:53,155 --> 01:15:55,335
Speaker 5:  It was a good phone. It was a good phone. Yeah, it was. Yeah, yeah,

1283
01:15:55,335 --> 01:15:56,735
Speaker 7:  Yeah. I also missed the button, you know.

1284
01:15:57,135 --> 01:16:00,775
Speaker 5:  That's true. Let's, this is where it's gonna go. It's like the digit cam

1285
01:16:00,775 --> 01:16:03,175
Speaker 5:  people are gonna demand we go backwards.

1286
01:16:05,085 --> 01:16:08,855
Speaker 5:  Yeah. All right. The Pebble Time. It's supposedly shipping this summer.

1287
01:16:09,365 --> 01:16:11,015
Speaker 6:  It's supposedly shipping this year. Coming

1288
01:16:11,015 --> 01:16:12,695
Speaker 5:  This year, this year. This year is now. This year. It's,

1289
01:16:12,805 --> 01:16:13,895
Speaker 6:  It's coming sometime. Yeah.

1290
01:16:14,205 --> 01:16:17,935
Speaker 5:  Okay. Very exciting days for the Pebble community. Y'all have been waiting.

1291
01:16:18,685 --> 01:16:21,425
Speaker 5:  It's a good moment. Okay. Hayden,

1292
01:16:21,725 --> 01:16:25,265
Speaker 7:  So Addie did a great piece this week on how

1293
01:16:25,425 --> 01:16:28,945
Speaker 7:  chatbots aren't divulging their secrets. They're not like an Oracle

1294
01:16:29,215 --> 01:16:32,625
Speaker 7:  when you ask it a question about how it works, its inner workings, why it

1295
01:16:32,625 --> 01:16:36,145
Speaker 7:  was banned from something like Grok was, or why,

1296
01:16:37,205 --> 01:16:41,185
Speaker 7:  you know, it's responding a certain way. What its secret prompts are, most

1297
01:16:41,185 --> 01:16:44,985
Speaker 7:  of the time it's not unveiling secrets of its inner workings in its system.

1298
01:16:45,095 --> 01:16:47,665
Speaker 7:  It's just kind of making something up. 'cause that's what it wants to do.

1299
01:16:47,665 --> 01:16:50,705
Speaker 7:  It wants to make you happy, it wants to answer your question. It's searching

1300
01:16:50,705 --> 01:16:53,985
Speaker 7:  the web and just becoming a pattern generator and you know, picking the next

1301
01:16:53,985 --> 01:16:54,865
Speaker 7:  most logical word.

1302
01:16:54,995 --> 01:16:58,745
Speaker 5:  Right? So this grok thing, grok like briefly got banned

1303
01:16:58,745 --> 01:17:00,425
Speaker 5:  from X, which is and

1304
01:17:00,455 --> 01:17:00,985
Speaker 7:  Blue sky.

1305
01:17:01,165 --> 01:17:04,905
Speaker 5:  And blue sky. Oh, first off, I cannot believe Brock was allowed on blue sky

1306
01:17:05,205 --> 01:17:08,665
Speaker 5:  for a second. That's the craziest thing I've ever heard.

1307
01:17:09,145 --> 01:17:12,605
Speaker 5:  So it got banned on X for, for mysterious reasons,

1308
01:17:12,955 --> 01:17:16,525
Speaker 5:  even though it seems to be the main feature on X these days. And then people

1309
01:17:16,525 --> 01:17:19,845
Speaker 5:  started asking it why it was banned and they were just like, oh, okay, well

1310
01:17:19,845 --> 01:17:22,525
Speaker 5:  gu you say so, but it had like a bunch of different explanations.

1311
01:17:22,525 --> 01:17:25,925
Speaker 7:  Yeah. Like one was that it's stated that Israel and the US are committing

1312
01:17:25,925 --> 01:17:29,445
Speaker 7:  genocide and Gaza. And then another one said it was content

1313
01:17:29,445 --> 01:17:33,245
Speaker 7:  refinements by XAI. And then another one said,

1314
01:17:33,385 --> 01:17:37,205
Speaker 7:  oh, it's because I identified an individual in adult content. So basically

1315
01:17:37,325 --> 01:17:40,605
Speaker 7:  I ran the gamut. Yes. Like no one knew why I was really banned and it didn't

1316
01:17:40,605 --> 01:17:40,845
Speaker 7:  know either.

1317
01:17:41,315 --> 01:17:44,765
Speaker 5:  It's, I mean this, it makes so much sense, right? You're like, why couldn't

1318
01:17:44,965 --> 01:17:48,605
Speaker 5:  I ask the chatbot about itself? But I think this is like just at an even

1319
01:17:48,605 --> 01:17:52,365
Speaker 5:  more basic level, I don't even think you can ask a chat bot what model it

1320
01:17:52,365 --> 01:17:54,085
Speaker 5:  is. Like it doesn't even always know.

1321
01:17:54,265 --> 01:17:54,725
Speaker 7:  It doesn't.

1322
01:17:55,005 --> 01:17:58,805
Speaker 6:  I did ask chat GPT five today, like what's the difference between the old

1323
01:17:58,825 --> 01:18:02,565
Speaker 6:  you and the new you? And it did give me some examples of

1324
01:18:02,635 --> 01:18:05,965
Speaker 6:  like what it can do better. But then I was just like,

1325
01:18:07,085 --> 01:18:09,365
Speaker 6:  I don't know, I still bully you pretty hard. So,

1326
01:18:09,385 --> 01:18:12,645
Speaker 5:  But this is the thing, it's, it's still basing it off of like what it can

1327
01:18:12,645 --> 01:18:13,365
Speaker 5:  read, right?

1328
01:18:13,755 --> 01:18:14,845
Speaker 7:  Like I read the blog post.

1329
01:18:15,325 --> 01:18:17,685
Speaker 5:  Yeah. Right, right, right. It just know, it knows the exact same thing that

1330
01:18:17,685 --> 01:18:18,125
Speaker 5:  you can read.

1331
01:18:18,465 --> 01:18:21,565
Speaker 7:  And I think that a lot of times, you know, again, this is a human nature

1332
01:18:21,565 --> 01:18:25,245
Speaker 7:  thing of us, like personifying things or whatever. But you know, on

1333
01:18:25,245 --> 01:18:29,005
Speaker 7:  TikTok I see a lot of trends of people like treating chatbots like an oracle.

1334
01:18:29,005 --> 01:18:31,605
Speaker 7:  They're like, oh, I asked when the world was gonna end and it said this.

1335
01:18:31,755 --> 01:18:35,365
Speaker 7:  Okay. Like it's just reading a random Reddit comment, just putting that out

1336
01:18:35,365 --> 01:18:39,005
Speaker 7:  there or saying like, you know, out of everything I've ever told you, what

1337
01:18:39,005 --> 01:18:42,365
Speaker 7:  do you think is next for this company? Or whatever. I mean, there's

1338
01:18:42,555 --> 01:18:46,045
Speaker 7:  basically people, it is good at finding patterns, but it doesn't know the

1339
01:18:46,045 --> 01:18:50,005
Speaker 7:  future and it doesn't know, like, I don't know.

1340
01:18:50,085 --> 01:18:53,405
Speaker 7:  I mean, unless you can find it on the internet, it's not gonna tell you besides,

1341
01:18:53,405 --> 01:18:56,565
Speaker 7:  sometimes you can get it to un unveil some of its system prompts or its secret

1342
01:18:56,565 --> 01:18:58,645
Speaker 7:  hidden instructions. But I mean, that's it.

1343
01:18:59,345 --> 01:19:03,005
Speaker 5:  So that's what's so tricky though, right? I think particularly when, when

1344
01:19:03,005 --> 01:19:06,565
Speaker 5:  the chatbots first started coming out, And I think this happened on Bing

1345
01:19:06,935 --> 01:19:10,205
Speaker 5:  where, right, I think most of the Chatbots aren given

1346
01:19:10,205 --> 01:19:14,085
Speaker 5:  instructions, you would think that this would be some like fancy code

1347
01:19:14,645 --> 01:19:18,085
Speaker 5:  o of constraints on how these things operate. But there's actually just like,

1348
01:19:18,085 --> 01:19:21,525
Speaker 5:  some engineers are just like, be nice to the user,

1349
01:19:22,115 --> 01:19:25,845
Speaker 5:  give brief responses and it's just like English language, plain

1350
01:19:25,875 --> 01:19:29,485
Speaker 5:  text stuff and they kind of just like put that at the top of the chat and

1351
01:19:29,485 --> 01:19:32,765
Speaker 5:  hide it. Yep. And so there have been these instances

1352
01:19:33,175 --> 01:19:36,765
Speaker 5:  where people will figure out that, okay, if you do the right things, we say

1353
01:19:36,765 --> 01:19:40,725
Speaker 5:  it, the chat bot will reveal some of its prompts to you, which

1354
01:19:40,755 --> 01:19:44,725
Speaker 5:  lets you figure out how it's been designed to operate. And so there are like

1355
01:19:45,245 --> 01:19:48,605
Speaker 5:  a very occasionally these secrets you can divine Yes.

1356
01:19:48,795 --> 01:19:49,885
Speaker 7:  Only about the system prompt.

1357
01:19:50,025 --> 01:19:53,245
Speaker 5:  And, and that's it though, right? It's, it's, it's extremely limited. And

1358
01:19:53,245 --> 01:19:56,965
Speaker 5:  then because of this, I think, I mean it's probably for a lot of reasons

1359
01:19:56,965 --> 01:19:59,965
Speaker 5:  that are mostly related to human psychology, but I think this sort of lens

1360
01:19:59,965 --> 01:20:03,845
Speaker 5:  credence to it, people sort of think, okay, anything it says, anything

1361
01:20:03,845 --> 01:20:07,405
Speaker 5:  it says about itself is gonna be true and you just, you can't believe it.

1362
01:20:07,425 --> 01:20:11,085
Speaker 5:  No, it's actually, it probably even knows less if it's like a breaking news

1363
01:20:11,405 --> 01:20:11,525
Speaker 5:  scenario.

1364
01:20:11,735 --> 01:20:15,525
Speaker 7:  Right, exactly. And it's also hard because, yeah, I mean the fact that it

1365
01:20:15,525 --> 01:20:19,445
Speaker 7:  can find patterns in like economic conditions or like travel

1366
01:20:19,445 --> 01:20:22,525
Speaker 7:  patterns, all these patterns that it finds people think that it and also

1367
01:20:22,525 --> 01:20:26,085
Speaker 7:  find patterns in like what's gonna happen in the future or what's happened

1368
01:20:26,085 --> 01:20:29,485
Speaker 7:  in the past. And it's very, it's just hard because I think, you know, it's

1369
01:20:29,485 --> 01:20:32,525
Speaker 7:  really good at something and it's really bad at others and you know, we have

1370
01:20:32,525 --> 01:20:33,565
Speaker 7:  to remember what it's bad at.

1371
01:20:33,785 --> 01:20:34,005
Speaker 5:  Yes.

1372
01:20:34,065 --> 01:20:36,245
Speaker 6:  But it speaks so authoritatively so it's

1373
01:20:36,245 --> 01:20:38,285
Speaker 7:  Hard to Exactly. It's to, it's gaslighting us.

1374
01:20:38,515 --> 01:20:42,365
Speaker 6:  It's, it's, I mean, it just says things confidently and So if

1375
01:20:42,365 --> 01:20:46,205
Speaker 6:  you can't suss what it is or it's really hard to remember what it is

1376
01:20:46,225 --> 01:20:50,005
Speaker 6:  and it isn't good at for the average person, I think just

1377
01:20:50,395 --> 01:20:53,525
Speaker 5:  There's also, if you trace this far enough, I think this is how you, you

1378
01:20:53,575 --> 01:20:57,525
Speaker 5:  start to get to some of those stories where people are like, it told me I

1379
01:20:57,525 --> 01:21:01,405
Speaker 5:  could run through a wall and so I, I ran at the wall and it's like, like,

1380
01:21:01,585 --> 01:21:04,765
Speaker 5:  no, no, no, no, no. Like please, like, you have to approach these things

1381
01:21:04,795 --> 01:21:08,485
Speaker 5:  with common sense. And I, I, I think

1382
01:21:08,595 --> 01:21:12,525
Speaker 5:  very in, in complete fairness, the fact that the

1383
01:21:12,665 --> 01:21:16,125
Speaker 5:  bot can't explain to you what it is doing

1384
01:21:17,055 --> 01:21:19,595
Speaker 5:  is really confusing. Especially when you have, you have these reasoning models

1385
01:21:19,615 --> 01:21:22,635
Speaker 5:  and he's like quote unquote thinking models. They'll explain their reasoning

1386
01:21:22,775 --> 01:21:26,635
Speaker 5:  and it looks really, really like intelligent and sensible. And

1387
01:21:26,635 --> 01:21:30,555
Speaker 5:  for it then to be like just totally, I have no idea what model I am, I

1388
01:21:30,785 --> 01:21:33,955
Speaker 5:  have to make that up. Right? I don't know why I acted this way.

1389
01:21:34,095 --> 01:21:36,835
Speaker 6:  So I asked to, how many Rs were in strawberry? It said three, which is correct,

1390
01:21:36,895 --> 01:21:39,075
Speaker 6:  but then it said there are three Rs in strawberry.

1391
01:21:40,135 --> 01:21:43,875
Speaker 7:  Oh, you know what it can't get right is the number of Rs in any US

1392
01:21:43,875 --> 01:21:46,475
Speaker 7:  state. And it keeps labeling maps incorrectly too.

1393
01:21:47,305 --> 01:21:47,715
Speaker 6:  It's great.

1394
01:21:48,175 --> 01:21:52,155
Speaker 5:  One day, one day maybe get a second official opinion

1395
01:21:52,295 --> 01:21:53,995
Speaker 5:  on your medical information, particularly

1396
01:21:54,135 --> 01:21:57,915
Speaker 6:  Doctor, always every day get a second medical. Just don't

1397
01:21:58,035 --> 01:21:58,315
Speaker 6:  listen to

1398
01:21:59,135 --> 01:22:02,715
Speaker 5:  And make sure that doctor is not using AI is is related to.

1399
01:22:03,015 --> 01:22:06,155
Speaker 5:  That's it for The Vergecast. If you like what we do here, the best way to

1400
01:22:06,155 --> 01:22:09,795
Speaker 5:  support us is to buy a subscription to The Verge at The Verge dot com.

1401
01:22:10,105 --> 01:22:12,955
Speaker 5:  We'd love to hear your questions and feedback. Let us know what you wanna

1402
01:22:12,955 --> 01:22:16,755
Speaker 5:  hear us talk about this summer. Email us at vergecast at VERGE dot

1403
01:22:16,835 --> 01:22:20,595
Speaker 5:  com or give us a call 8 6 6 VERGE 11. The

1404
01:22:20,715 --> 01:22:24,035
Speaker 5:  Vergecast is a production of The Verge and V Media Podcast Network.

1405
01:22:24,535 --> 01:22:27,995
Speaker 5:  Our show is produced by Eric Gomez, Brandon Keefer, Travis Uck, and Andrew

1406
01:22:28,015 --> 01:22:31,875
Speaker 5:  Marina. Jen Tui has a great episode coming up on Tuesday. It's about

1407
01:22:31,875 --> 01:22:35,515
Speaker 5:  whether we can make Rosy the robot from the Jetsons a real thing.

1408
01:22:36,015 --> 01:22:36,715
Speaker 5:  See you next week.

