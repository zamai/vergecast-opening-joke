1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: bf299f50-bf23-11ed-bd03-bb2695b8f1fa
Status: Done
Stage: Done
Title: Spotify's redesign, streaming boxes suck, and Gigi Sohn withdraws from FCC nomination
Audio URL: https://jfe93e.s3.amazonaws.com/-8836567189564204052/5742041410682136371/s93290-US-5956s-1678439570.mp3
Description: The Verge's Nilay Patel, David Pierce, Alex Cranz, and Richard Lawler discuss Spotify's changes within its app, what happening this week at Twitter, Gigi Sohn withdrawing her nomination for FCC commissioner, and a whole lot more.

2
00:00:00,000 --> 00:00:03,760
Speaker 1:  Support for today's show comes from Deloitte. In the business world, it can

3
00:00:03,760 --> 00:00:07,160
Speaker 1:  be especially crucial to innovate. You can either build your own future or

4
00:00:07,160 --> 00:00:10,440
Speaker 1:  bet on someone else's. No one knows what tomorrow will bring, but you push

5
00:00:10,440 --> 00:00:14,160
Speaker 1:  forward and create enterprise anyway. That's why Deloitte's mission is to

6
00:00:14,160 --> 00:00:17,320
Speaker 1:  help engineer advantage for their clients by harnessing the latest innovations

7
00:00:17,320 --> 00:00:21,040
Speaker 1:  and technology while exploring the ideas and opportunities that can look

8
00:00:21,040 --> 00:00:24,320
Speaker 1:  beyond today. Transform what's next into what's now.

9
00:00:24,660 --> 00:00:27,440
Speaker 1:  See how you can engineer advantage with Deloitte at

10
00:00:27,680 --> 00:00:31,200
Speaker 1:  deloitte.com/us/engineering advantage.

11
00:00:43,260 --> 00:00:46,980
Speaker 3:  Hello and welcome to Ro Cast, the flagship podcast of Wiper

12
00:00:46,980 --> 00:00:50,860
Speaker 3:  Innovation where all your wiper innovation needs. The code is first

13
00:00:50,860 --> 00:00:54,780
Speaker 3:  cast. Do you think that there's a podcast for the wiper industry?

14
00:00:55,010 --> 00:00:55,420
Speaker 3:  I was

15
00:00:55,420 --> 00:00:58,340
Speaker 4:  Just wondering, what's the competition there do you think? Is it heated?

16
00:00:58,950 --> 00:00:59,300
Speaker 1:  It

17
00:00:59,300 --> 00:01:03,140
Speaker 3:  Exists. Well, I, I mean I love nothing more than a good

18
00:01:03,140 --> 00:01:07,060
Speaker 3:  trade publication. Like I, I will just sit around reading Tire Business Weekly,

19
00:01:07,970 --> 00:01:11,180
Speaker 3:  a magazine for people who run tire stores. It's very good. What

20
00:01:11,180 --> 00:01:14,180
Speaker 5:  If, what if there's been monopolization in the windshield wiper industry?

21
00:01:14,180 --> 00:01:16,980
Speaker 5:  It's like glasses where like one company actually makes all the brands,

22
00:01:17,550 --> 00:01:21,430
Speaker 3:  Right? But even that company has like probably a newsletter like

23
00:01:21,430 --> 00:01:22,470
Speaker 3:  looks SOA weekly

24
00:01:24,410 --> 00:01:27,910
Speaker 3:  and like every page is like, we bought another sunglasses company

25
00:01:28,210 --> 00:01:31,950
Speaker 3:  competition. We have, Lexia has always been at war with East Asia.

26
00:01:34,080 --> 00:01:37,630
Speaker 3:  Hi, I'm nea. I'm your friend Alex Kino. Cranz is here.

27
00:01:38,130 --> 00:01:39,470
Speaker 1:  I'm not at war with Asia.

28
00:01:40,310 --> 00:01:41,310
Speaker 3:  Good. That's

29
00:01:41,410 --> 00:01:43,230
Speaker 1:  Big announcement for the show today.

30
00:01:43,380 --> 00:01:47,270
Speaker 3:  I think we should start every episode by stipulating that Alex is

31
00:01:47,270 --> 00:01:48,990
Speaker 3:  not at war with Asia.

32
00:01:49,090 --> 00:01:51,310
Speaker 1:  The whole continent, the whole thing.

33
00:01:52,410 --> 00:01:56,310
Speaker 3:  You just one of these days though, if we do it

34
00:01:56,310 --> 00:01:59,950
Speaker 3:  enough, eventually we have to pay it off. It's like check off's gun. Yeah,

35
00:01:59,950 --> 00:02:03,590
Speaker 3:  like eventually we're like, it's Alex's last episode. She's declared

36
00:02:03,590 --> 00:02:06,310
Speaker 3:  war. Richard Lawler is here. Hey Richard.

37
00:02:06,340 --> 00:02:08,310
Speaker 5:  I have not committed securities fraud today.

38
00:02:09,160 --> 00:02:13,140
Speaker 3:  Hey. Yes, that's a win. I mean honestly in the context of a

39
00:02:13,140 --> 00:02:17,100
Speaker 3:  tech show, not committing securities fraud in 2023 is a

40
00:02:17,100 --> 00:02:17,820
Speaker 3:  win. I'll

41
00:02:17,820 --> 00:02:18,380
Speaker 5:  Take it. It's,

42
00:02:18,650 --> 00:02:22,580
Speaker 3:  That's good. Has your, have you collapsed a bank today because it's the second

43
00:02:22,580 --> 00:02:23,780
Speaker 3:  of two has collapsed.

44
00:02:23,780 --> 00:02:24,940
Speaker 5:  I, I didn't say that. I

45
00:02:24,940 --> 00:02:28,580
Speaker 3:  Haven't. And then as you may have heard ominously in the background, David Pierce

46
00:02:28,580 --> 00:02:29,740
Speaker 3:  has returned, hello,

47
00:02:29,960 --> 00:02:33,740
Speaker 4:  I'm back. Back. I cannot honestly say I have not committed securities fraud

48
00:02:33,740 --> 00:02:37,020
Speaker 4:  today. It's like, it's a bold thing to just confidently say, right? Like

49
00:02:37,210 --> 00:02:40,300
Speaker 4:  I don't know what's happening to me today. What do I know about securities

50
00:02:40,300 --> 00:02:40,460
Speaker 4:  fraud?

51
00:02:40,640 --> 00:02:44,300
Speaker 3:  You sound like every crypto executive in America. You're like what is the

52
00:02:44,460 --> 00:02:47,100
Speaker 3:  security and what is fraud and can you really add them together? Yeah. Is

53
00:02:47,100 --> 00:02:47,940
Speaker 3:  that a sentence? What is a

54
00:02:48,020 --> 00:02:50,780
Speaker 4:  Sentence? I live in The Bahamas. I can, I can do nothing wrong. Like what?

55
00:02:50,780 --> 00:02:51,620
Speaker 4:  There are no rules here.

56
00:02:52,160 --> 00:02:55,580
Speaker 3:  Buy a Bitcoin, please God. Buy a Bitcoin someone.

57
00:02:55,770 --> 00:02:59,680
Speaker 3:  What's what we're referencing by the way, is it over the weekend Richard

58
00:02:59,790 --> 00:03:03,680
Speaker 3:  Silver Gate, which is a financial institution that was backing a lot of

59
00:03:03,680 --> 00:03:07,560
Speaker 3:  crypto teetered. Its way towards a collapse. And then actually

60
00:03:07,680 --> 00:03:11,240
Speaker 3:  today this bank has not collapsed. It's Silicon Valley Bank, which is a

61
00:03:11,270 --> 00:03:15,200
Speaker 3:  sort of legendary Silicon Valley financial institution. One of the top

62
00:03:15,200 --> 00:03:18,960
Speaker 3:  15 largest banks in the country. I think its stock is

63
00:03:18,960 --> 00:03:21,560
Speaker 3:  collapsing cuz it has been exposed to crypto as

64
00:03:21,560 --> 00:03:25,520
Speaker 5:  Well. Yeah, the financial contagion continues. It's not good. And

65
00:03:25,520 --> 00:03:28,640
Speaker 5:  as Liz Lato wrote about the silver gate collapse, one of the major impacts

66
00:03:28,640 --> 00:03:32,160
Speaker 5:  is that it's gonna be a lot harder to kind of get your cash out of crypto.

67
00:03:32,370 --> 00:03:36,360
Speaker 5:  So if you were planning on doing that, you might want to figure out

68
00:03:36,360 --> 00:03:36,840
Speaker 5:  something

69
00:03:36,950 --> 00:03:39,040
Speaker 3:  That won't accelerate the cycle at all.

70
00:03:39,040 --> 00:03:41,670
Speaker 5:  No, no. Never does. It's not

71
00:03:41,670 --> 00:03:44,350
Speaker 3:  A big if Richard's like, here's what you should do. Run on the bank.

72
00:03:45,020 --> 00:03:46,510
Speaker 5:  I I didn't say you shouldn't.

73
00:03:48,060 --> 00:03:51,750
Speaker 4:  It's like it's wild how quickly the run on the bank has turned

74
00:03:51,750 --> 00:03:55,190
Speaker 4:  into like the run on crypto has turned into like the run on the financial

75
00:03:55,190 --> 00:03:59,150
Speaker 4:  system. Yeah, it just every day like the concentric circles just get

76
00:03:59,150 --> 00:04:00,990
Speaker 4:  a little bit wider. It's really wild.

77
00:04:01,100 --> 00:04:03,590
Speaker 1:  Well that's what happens when a pyramid collapses.

78
00:04:03,920 --> 00:04:06,430
Speaker 3:  No, that's a triangle. David was talking about circles

79
00:04:06,440 --> 00:04:09,990
Speaker 1:  Pyramid circle. It's fine, don't worry about it. I did okay in

80
00:04:09,990 --> 00:04:10,470
Speaker 1:  geometry.

81
00:04:10,620 --> 00:04:13,870
Speaker 3:  That might be the worst joke I've ever told in the show. Look at the end

82
00:04:13,870 --> 00:04:17,590
Speaker 3:  of it, the, it collapses enough in Crans declares war on the continent of

83
00:04:17,590 --> 00:04:21,550
Speaker 3:  Asia. So stay tuned for that. It's coming. I don't wanna talk

84
00:04:21,550 --> 00:04:25,390
Speaker 3:  about crypto though. I, although I will say after two and a half years

85
00:04:25,390 --> 00:04:29,190
Speaker 3:  of pandemic, being able to use words like contagion in a different

86
00:04:29,190 --> 00:04:32,950
Speaker 3:  way, frankly refreshing. Just putting that out there. Okay,

87
00:04:32,950 --> 00:04:36,630
Speaker 3:  let's talk about the cyber truck wiper. The only story in technology, there's

88
00:04:36,630 --> 00:04:37,350
Speaker 1:  A bold claim.

89
00:04:37,960 --> 00:04:41,550
Speaker 3:  There's only one story and it's a windshield wiper. So here,

90
00:04:41,550 --> 00:04:44,990
Speaker 3:  here's some inside baseball and how journalism is made.

91
00:04:45,770 --> 00:04:49,170
Speaker 3:  We're, we're doing the thing that we do. We, you know, we open our, we wake

92
00:04:49,170 --> 00:04:52,170
Speaker 3:  up, we open our laptops like what's going on in the world. We see a bunch

93
00:04:52,170 --> 00:04:55,850
Speaker 3:  of pictures of like Tesla fans at the Tesla

94
00:04:55,850 --> 00:04:59,330
Speaker 3:  headquarters in California. Cuz you know, Tesla's two headquarters now they

95
00:04:59,330 --> 00:05:02,850
Speaker 3:  move the company officially to Texas with the

96
00:05:03,370 --> 00:05:07,330
Speaker 3:  engineering headquarters in California. Elon was just in California. Governor

97
00:05:07,330 --> 00:05:09,970
Speaker 3:  Newsom, they announced this whole expansion, whatever. So they have this

98
00:05:09,970 --> 00:05:13,930
Speaker 3:  event investors, the whole thing. They park a bunch of Tesla vehicles outside

99
00:05:13,930 --> 00:05:17,650
Speaker 3:  of a building, including a cyber truck. Like any good editor-in-chief, I

100
00:05:17,650 --> 00:05:21,370
Speaker 3:  basically screamed, get me photos of Spider-Man. There's two

101
00:05:21,650 --> 00:05:25,450
Speaker 3:  things you wanna do as an editor chief. You wanna circle print layouts hung

102
00:05:25,450 --> 00:05:29,410
Speaker 3:  on the glass walls of a conference room and say, fix this up before you go

103
00:05:29,410 --> 00:05:32,210
Speaker 3:  to print. I've never been able to do that. Maybe one day I will. Although

104
00:05:32,210 --> 00:05:35,650
Speaker 3:  we did just win the as award for best print design, which is deeply funny.

105
00:05:35,860 --> 00:05:39,050
Speaker 3:  However, that's one. And then two, you want, you wanna scream, get me photos

106
00:05:39,050 --> 00:05:42,170
Speaker 3:  of Spider-Man. So we see the cyber truck, we see the wiper ice cream. Get

107
00:05:42,170 --> 00:05:45,890
Speaker 3:  any photos of Spider-Man, I literally said this in Slack. Veen

108
00:05:45,960 --> 00:05:49,250
Speaker 3:  goes out with a long lens, try to get splice shots of the cyber truck

109
00:05:49,820 --> 00:05:53,290
Speaker 3:  to the place where the, the cyber truck was by the time he arrives by the

110
00:05:53,290 --> 00:05:57,130
Speaker 3:  way. And he like recruits his Uber driver into like a scheme to sneak

111
00:05:57,320 --> 00:06:00,880
Speaker 3:  ever closer to the cyber truck like the Uber driver's gonna pose as a fan

112
00:06:00,880 --> 00:06:01,480
Speaker 3:  of Tesla.

113
00:06:03,090 --> 00:06:05,680
Speaker 3:  It was great. We were like very excited. And they get there and the cyber

114
00:06:05,680 --> 00:06:09,360
Speaker 3:  truck is gone. However, then Tesla has its

115
00:06:09,760 --> 00:06:13,690
Speaker 3:  investor day, which is mostly a dod and after that Tesla had a design

116
00:06:13,940 --> 00:06:17,930
Speaker 3:  franson whole housing tweets, a picture in front of the cyber

117
00:06:17,930 --> 00:06:21,810
Speaker 3:  truck being like, I just took the beta out for a drive. And in the picture

118
00:06:22,350 --> 00:06:26,130
Speaker 3:  the truck has clearly been out in the rain. And you can see

119
00:06:26,130 --> 00:06:28,690
Speaker 3:  the sweep of the gigantic wiper.

120
00:06:29,760 --> 00:06:33,650
Speaker 3:  This is the, like I frozen my tracks when I saw this tweet.

121
00:06:34,440 --> 00:06:38,010
Speaker 3:  I can literally just imagine you like at home just screaming

122
00:06:38,330 --> 00:06:41,850
Speaker 3:  enhanced at your computer. Just like furiously making the browser bigger.

123
00:06:41,850 --> 00:06:45,610
Speaker 3:  Trying to get the picture. Yeah, I mean I, it's there. I was like, God

124
00:06:45,640 --> 00:06:47,770
Speaker 3:  damnit Tim bake this a touch screen

125
00:06:49,620 --> 00:06:53,490
Speaker 3:  so you, you can see it, you can see how the wiper is gonna work

126
00:06:53,540 --> 00:06:57,210
Speaker 3:  if you, in following along on the show, you know that the cyber trucks

127
00:06:57,210 --> 00:07:01,170
Speaker 3:  wiper has been a point of major contention cuz they announced this

128
00:07:01,170 --> 00:07:04,850
Speaker 3:  thing by throwing rocks through the windows, but it didn't have a

129
00:07:04,850 --> 00:07:08,610
Speaker 3:  windshield wiper. So they, they got all distracted by the not

130
00:07:08,610 --> 00:07:12,290
Speaker 3:  bulletproof, bulletproof glass and forgot the windshield wiper. Then

131
00:07:12,290 --> 00:07:16,170
Speaker 3:  Elon's tweeting. I am deeply concerned about the wiper, which is an amazing

132
00:07:16,170 --> 00:07:20,050
Speaker 3:  thing for an automotive CEO to tweet like period. Just

133
00:07:20,050 --> 00:07:23,130
Speaker 3:  in li I've interviewed a lot of auto CEOs. None of them are ever, like, what

134
00:07:23,130 --> 00:07:26,650
Speaker 3:  keeps me up at night is windshield wipers. God knows they care about them.

135
00:07:27,360 --> 00:07:30,930
Speaker 3:  They just keep that under wraps. Like what's top 10 anxieties of the CEO

136
00:07:30,930 --> 00:07:33,410
Speaker 3:  Volvo. It's like, he's like windshield wipers. Well they

137
00:07:33,530 --> 00:07:36,330
Speaker 1:  Actually, they talk about it in the publication. Yeah. Like they're industry

138
00:07:36,330 --> 00:07:36,690
Speaker 1:  pup

139
00:07:36,980 --> 00:07:38,170
Speaker 3:  In the wiper pop.

140
00:07:38,320 --> 00:07:38,810
Speaker 1:  Yeah,

141
00:07:38,810 --> 00:07:41,770
Speaker 3:  It's fine. Anyway, Elon's tweeting about it. He's like, the best thing would

142
00:07:41,770 --> 00:07:45,050
Speaker 3:  be for it to extend. And that's complicated. So everyone starts to think

143
00:07:45,050 --> 00:07:48,890
Speaker 3:  that the cyber truck wiper is going to extend the people. Tesla

144
00:07:48,890 --> 00:07:52,410
Speaker 3:  fans are leaping out of bushes to tell you about the Mercedes mono

145
00:07:52,410 --> 00:07:56,370
Speaker 3:  wiper concept from like the 1982 C class. It's fully

146
00:07:56,370 --> 00:08:00,010
Speaker 3:  ridiculous. There's, there's a YouTube video showing

147
00:08:00,010 --> 00:08:03,930
Speaker 3:  how the Mercedes mono wiper worked that I swear to God has

148
00:08:03,930 --> 00:08:07,770
Speaker 3:  a million views and it's just hopeful cyber truck fans. Aw.

149
00:08:07,770 --> 00:08:11,650
Speaker 3:  Because the concept, all 12 of them watching it several

150
00:08:11,970 --> 00:08:15,890
Speaker 3:  thousand times a piece and like, it's very cool and like it

151
00:08:15,890 --> 00:08:19,530
Speaker 3:  was actually, it was mounted in the, the middle of the windshield and

152
00:08:19,530 --> 00:08:22,570
Speaker 3:  it's, it makes like a bow tie shape and there's like a gearing, there's a

153
00:08:22,570 --> 00:08:26,450
Speaker 3:  gear set in the wiper. The point of this is that Mercedes did not make

154
00:08:26,450 --> 00:08:30,130
Speaker 3:  this anymore. They were like, this was a bad idea and they went

155
00:08:30,130 --> 00:08:33,850
Speaker 3:  back to wipers. Cyber truck wiper does not extend,

156
00:08:34,460 --> 00:08:38,050
Speaker 3:  it just leaves a whole chunk of the windshield dirty. It's amazing

157
00:08:38,080 --> 00:08:41,850
Speaker 3:  that after all of this time they're like, I don't know, does the passenger

158
00:08:41,850 --> 00:08:45,770
Speaker 3:  need to see out the windshield? No they don't. I love it. I can't

159
00:08:45,770 --> 00:08:47,010
Speaker 3:  get enough of this thing. How

160
00:08:47,010 --> 00:08:50,370
Speaker 1:  Much water do you think it sloughs off? Like does it soak the people

161
00:08:51,550 --> 00:08:54,850
Speaker 1:  and the other cars just ah, every time like

162
00:08:54,850 --> 00:08:58,160
Speaker 3:  It has to Yeah, but it's like raining really hard and you and you're moving

163
00:08:58,160 --> 00:09:00,520
Speaker 3:  like a four foot wiper. Just

164
00:09:01,870 --> 00:09:05,720
Speaker 4:  I, by the way, four foot wiper is as far as I can tell. Not

165
00:09:05,720 --> 00:09:09,400
Speaker 4:  an exaggeration. Like I, I'm just, I'm just doing math here cuz for I'm,

166
00:09:09,400 --> 00:09:13,160
Speaker 4:  I'm now at 500% zoom on this photo on my Twitter professor.

167
00:09:13,160 --> 00:09:16,720
Speaker 4:  This is, this is where I am. It's very good to be back in the verge cast.

168
00:09:16,750 --> 00:09:20,400
Speaker 4:  It's like you assume, you know, Franz is a normal height dude.

169
00:09:20,400 --> 00:09:24,240
Speaker 4:  This thing is at least 75% as tall as he

170
00:09:24,240 --> 00:09:28,120
Speaker 4:  is. So this is, this is a human sized windshield

171
00:09:28,120 --> 00:09:31,640
Speaker 3:  Wiper. I'm gonna need like the Reddit people to do the thing where they like

172
00:09:32,210 --> 00:09:36,120
Speaker 3:  de warp the photo because there's a perspective trick that's happening

173
00:09:36,120 --> 00:09:36,280
Speaker 3:  there.

174
00:09:36,470 --> 00:09:40,000
Speaker 4:  Sure. But he's also standing right in front of it. It's not like, it's not

175
00:09:40,000 --> 00:09:43,480
Speaker 4:  like the distance between the two things. Unless the cyber truck is sneakily,

176
00:09:43,480 --> 00:09:46,720
Speaker 4:  you know, 17 feet wide, which would not totally shock me. It's like the first

177
00:09:46,720 --> 00:09:50,480
Speaker 4:  two lane wide vehicle ever. Like, I don't know. But yeah, it just, it

178
00:09:50,480 --> 00:09:53,800
Speaker 4:  covers, it gets the whole driver's side super clean on the driver's side

179
00:09:53,800 --> 00:09:56,600
Speaker 4:  it seems, except for about a, a little stripe on top. And

180
00:09:56,600 --> 00:09:57,360
Speaker 3:  That's fine, that's

181
00:09:57,360 --> 00:10:01,000
Speaker 4:  Fine. It's normal. But then you come around and as you get all the way to

182
00:10:01,000 --> 00:10:04,910
Speaker 4:  the other side, it, it's about the top right?

183
00:10:04,980 --> 00:10:08,950
Speaker 4:  I don't know, sixth. It just ignores entirely. It's like, ah, there's no

184
00:10:08,950 --> 00:10:11,310
Speaker 4:  one here. You're not gonna need to see out of this. It's fine. Yeah,

185
00:10:11,310 --> 00:10:14,630
Speaker 3:  You'll definitely never turn your head to the right while driving the cyber

186
00:10:14,750 --> 00:10:15,070
Speaker 3:  truck.

187
00:10:15,960 --> 00:10:19,710
Speaker 4:  No. Yeah. If if ever a drone is flying up

188
00:10:19,710 --> 00:10:22,870
Speaker 4:  kind of just above you and to the right, you'll never notice your toast.

189
00:10:22,870 --> 00:10:25,950
Speaker 3:  Yeah. It's all, all of it's very funny. I still think they should go with

190
00:10:25,950 --> 00:10:29,430
Speaker 3:  three wipers in a circle, which I, I promise you can be done. You get the

191
00:10:29,430 --> 00:10:31,630
Speaker 3:  two at the bottom going like this and one at the top going like

192
00:10:31,630 --> 00:10:34,670
Speaker 4:  That. I was imagining like a spinning Roomba on your windshield.

193
00:10:34,980 --> 00:10:38,430
Speaker 3:  I mean, at this point nobody looks in the middle.

194
00:10:38,940 --> 00:10:42,470
Speaker 3:  I don't know when the cyber truck is gonna ship. I swear to you,

195
00:10:42,930 --> 00:10:46,750
Speaker 3:  the wiper on the cyber truck is a monumental

196
00:10:46,750 --> 00:10:50,630
Speaker 3:  piece of tech history because if the cyber truck is not

197
00:10:50,630 --> 00:10:54,510
Speaker 3:  a success or if they can't solve the wiper and ship the cyber

198
00:10:54,510 --> 00:10:58,470
Speaker 3:  truck, Tesla's in trouble. There are facts, right? Like

199
00:10:58,470 --> 00:11:01,110
Speaker 3:  they've collected millions of hundred dollars reservations

200
00:11:01,110 --> 00:11:03,630
Speaker 5:  For this thing. I'm looking at it now and you know what, I'm gonna go the

201
00:11:03,630 --> 00:11:04,590
Speaker 5:  other way. I think the wiper works.

202
00:11:04,590 --> 00:11:05,950
Speaker 3:  Huh? You think the wiper works? The

203
00:11:05,950 --> 00:11:06,990
Speaker 5:  Wiper works. If you take a look at

204
00:11:06,990 --> 00:11:09,910
Speaker 4:  The top of it, Richard, it objectively doesn't, it just doesn't,

205
00:11:10,920 --> 00:11:12,470
Speaker 4:  it does not wipe the windshield.

206
00:11:12,890 --> 00:11:13,310
Speaker 3:  The

207
00:11:13,310 --> 00:11:17,150
Speaker 5:  Roof of the car comes in under the glass, like you

208
00:11:17,150 --> 00:11:20,150
Speaker 5:  can't see through most of that anyway, where the, where the wiper isn't wiping,

209
00:11:20,160 --> 00:11:22,870
Speaker 5:  it just has such a monumentally stupid design

210
00:11:23,700 --> 00:11:27,070
Speaker 5:  that it looks like it's not clearing the visible area. But you can't even

211
00:11:27,070 --> 00:11:29,710
Speaker 5:  see outta that spot. Anyway. I, I don't know, is that like a

212
00:11:29,710 --> 00:11:32,470
Speaker 3:  Pocket up here? No, that's not right. I, I see what you're saying. But there's

213
00:11:32,470 --> 00:11:36,390
Speaker 3:  like a, I don't know, we, I get, we gotta see this is, it's get me

214
00:11:36,550 --> 00:11:40,350
Speaker 3:  photos of Spider-Man. If you're out in the world and

215
00:11:40,350 --> 00:11:44,110
Speaker 3:  you see a cyber truck just as much as you can get photos

216
00:11:44,110 --> 00:11:46,950
Speaker 3:  of this wiper, it's the only story in technology that matters.

217
00:11:47,820 --> 00:11:50,990
Speaker 3:  I promise you it's all I want. It's all I wanna talk about. The best part

218
00:11:50,990 --> 00:11:53,920
Speaker 3:  of this story is I put that up on our new site in our, our with our new tool

219
00:11:54,130 --> 00:11:57,920
Speaker 3:  is a quick post because yes, it was worth 20 minutes of our

220
00:11:57,950 --> 00:12:01,760
Speaker 3:  time, but I was like, I can't be overwriting this.

221
00:12:01,820 --> 00:12:04,720
Speaker 3:  And another publication wrote an entire story.

222
00:12:05,160 --> 00:12:08,840
Speaker 4:  Listen, it's weird. Wiper weekly needs something to put on the cover. You're

223
00:12:08,840 --> 00:12:09,520
Speaker 4:  like, don't

224
00:12:09,520 --> 00:12:13,240
Speaker 3:  Shame wiper weekly. God, if there's a trade publication for wiper

225
00:12:13,400 --> 00:12:16,040
Speaker 3:  engineers, can you please reach out to us? I would love to interview you

226
00:12:17,520 --> 00:12:21,160
Speaker 3:  Ezer if you're a reader or if you're a writer or an editor, it doesn't matter

227
00:12:21,160 --> 00:12:24,840
Speaker 3:  if you are just aware of the wiper industry trade publication,

228
00:12:24,840 --> 00:12:28,360
Speaker 3:  reach out. I just wanna know what you're like. Alright, that's enough on

229
00:12:28,360 --> 00:12:31,320
Speaker 3:  windshield wipers. Let's talk about the other biggest design story in technology,

230
00:12:31,320 --> 00:12:35,080
Speaker 3:  which is Spotify and the general TikTok application

231
00:12:35,410 --> 00:12:39,360
Speaker 3:  of everything. David, y you wrote up the design, there was an event

232
00:12:39,360 --> 00:12:42,960
Speaker 3:  this week, Alex Heath was there. We're gonna have some more coverage. We

233
00:12:42,960 --> 00:12:45,320
Speaker 3:  got an interview with our head of design and decoder coming out next week.

234
00:12:45,320 --> 00:12:46,480
Speaker 3:  But tell us what's going on with Spotify.

235
00:12:46,550 --> 00:12:49,840
Speaker 4:  Yeah, so this was Spotify's Stream on event, which it does

236
00:12:50,720 --> 00:12:53,640
Speaker 4:  occasionally. The last one I think was two years ago. It's their big kind

237
00:12:53,640 --> 00:12:56,800
Speaker 4:  of state of the union. Here's what's going on at Spotify thing. And

238
00:12:57,230 --> 00:13:01,200
Speaker 4:  mostly they talk to creators. It was like 90 minutes of them being like,

239
00:13:01,220 --> 00:13:05,080
Speaker 4:  are you a creator? We love you all creators, we love you.

240
00:13:05,080 --> 00:13:08,560
Speaker 4:  We are Spotify. Come to Spotify. We love you creators. Hello. They brought

241
00:13:08,560 --> 00:13:11,920
Speaker 4:  out the Jonas Brothers just to introduce a video, which was the coolest flex

242
00:13:11,920 --> 00:13:15,360
Speaker 4:  I've ever seen in my entire life. They just came out and they were like,

243
00:13:15,360 --> 00:13:18,680
Speaker 4:  look, Jennifer Lopez also like Spotify. And then they've left. It was amazing.

244
00:13:18,740 --> 00:13:22,400
Speaker 4:  But anyway, the big announcement was that they're redesigning

245
00:13:22,620 --> 00:13:26,520
Speaker 4:  the Spotify homepage and anyone who has used Spotify knows that

246
00:13:26,520 --> 00:13:30,440
Speaker 4:  basically Spotify is just like a lot of album covers. That's the only sort

247
00:13:30,440 --> 00:13:34,080
Speaker 4:  of design in there. It's just rows and rows of tiles of album covers. And

248
00:13:34,080 --> 00:13:37,960
Speaker 4:  now it looks a lot more like some mix of like

249
00:13:37,960 --> 00:13:41,840
Speaker 4:  Instagram stories and TikTok and like a little

250
00:13:41,840 --> 00:13:45,480
Speaker 4:  bit of YouTube. But the idea is basically if you go to like the podcast

251
00:13:45,480 --> 00:13:48,880
Speaker 4:  thing, instead of getting a bunch of album covers of podcasts, you're gonna

252
00:13:48,880 --> 00:13:52,600
Speaker 4:  get actual like feeds of auto playing

253
00:13:52,990 --> 00:13:56,840
Speaker 4:  podcasts. They're, they're big into video for as a thing.

254
00:13:56,840 --> 00:14:00,760
Speaker 4:  They're big into big imagery. Now. The idea is to be much more sort of immersive

255
00:14:00,760 --> 00:14:04,320
Speaker 4:  and also like discoverable. Instead of just

256
00:14:04,840 --> 00:14:07,640
Speaker 4:  fighting to have better album covers, it's gonna actually start to try to

257
00:14:07,640 --> 00:14:10,920
Speaker 4:  play you the most interesting bit of a podcast or a song or an audiobook

258
00:14:10,920 --> 00:14:14,040
Speaker 4:  and actually connect to you that way. So that's the sort of

259
00:14:14,380 --> 00:14:17,960
Speaker 4:  detoxification of it all. Everything is much more full screen. It's auto-playing.

260
00:14:17,960 --> 00:14:21,800
Speaker 4:  It's much louder, it's much more visual. And as far as I can tell

261
00:14:22,010 --> 00:14:26,000
Speaker 4:  Spotify users hate this in the same way that

262
00:14:26,000 --> 00:14:29,920
Speaker 4:  they've hated every other non-music listening thing that Spotify

263
00:14:29,940 --> 00:14:33,280
Speaker 4:  has done, which is now the impossible track that Spotify is on. Or Spotify

264
00:14:33,280 --> 00:14:36,280
Speaker 4:  is like, okay, as we've talked about many times in this show, it turns out

265
00:14:36,280 --> 00:14:39,320
Speaker 4:  being a streaming music company is an awful, awful, awful, awful business.

266
00:14:39,320 --> 00:14:42,560
Speaker 4:  It's not great. Don't do it if you ever wanna make any money. So Spotify

267
00:14:42,570 --> 00:14:46,520
Speaker 4:  is now this big company that like can't stop losing money on music and is

268
00:14:46,520 --> 00:14:48,920
Speaker 4:  trying desperately to find other ways to make money. They've, they've made

269
00:14:48,920 --> 00:14:51,000
Speaker 4:  this big bet on podcasts. They've bought an audiobook company, they're trying,

270
00:14:51,160 --> 00:14:55,000
Speaker 4:  trying to make live audio happen. And then you have Spotify users who just

271
00:14:55,000 --> 00:14:58,120
Speaker 4:  keep raising their hand being like, I I just would like to listen to my music,

272
00:14:58,120 --> 00:15:01,960
Speaker 4:  please, can you leave me alone? And this is Spotify trying

273
00:15:02,250 --> 00:15:06,200
Speaker 4:  to sort of satisfy everybody and at least based on the reaction to

274
00:15:06,200 --> 00:15:09,120
Speaker 4:  what we've seen, the app is not out yet for most people, but people do not

275
00:15:09,120 --> 00:15:11,880
Speaker 4:  like the idea of what Spotify is going for here. As far as I can

276
00:15:11,880 --> 00:15:15,200
Speaker 3:  Tell, I'm very sympathetic to the notion that people hate redesigns. I've,

277
00:15:15,200 --> 00:15:18,800
Speaker 3:  I've lived through it myself. Yes, absolutely, that's fine. But I will say

278
00:15:18,800 --> 00:15:22,280
Speaker 3:  that we, Reddit did a mild redesign this week too.

279
00:15:22,530 --> 00:15:26,520
Speaker 3:  We had the chief product person from Reddit on decoder. They're splitting

280
00:15:26,520 --> 00:15:30,480
Speaker 3:  that into a text feed and a video feed and all the feedback is get this video

281
00:15:30,480 --> 00:15:34,000
Speaker 3:  feed outta my face. Yep. Like we don't want it, even though all of the numbers

282
00:15:34,230 --> 00:15:37,360
Speaker 3:  inside of Reddit are, oh boy, people are spending a lot of time on video.

283
00:15:37,360 --> 00:15:40,920
Speaker 3:  People hate the video player. If we're gonna do video, we should, we should

284
00:15:40,920 --> 00:15:44,720
Speaker 3:  just put it over there and make a video feed and a text feed. And even then

285
00:15:44,720 --> 00:15:47,440
Speaker 3:  people are like, get this video outta my face. So I think there's like a

286
00:15:47,440 --> 00:15:51,360
Speaker 3:  revealed preference. That's when you're alone and you're

287
00:15:51,480 --> 00:15:54,840
Speaker 3:  your private time, you're watching the videos and when someone asks you about

288
00:15:54,840 --> 00:15:58,600
Speaker 3:  it, you're like, I never watch videos. I only read novels. Yes. And I think

289
00:15:58,600 --> 00:16:00,560
Speaker 3:  every one of these companies is like dealing with that.

290
00:16:00,620 --> 00:16:04,040
Speaker 4:  But the challenge there is the metrics don't

291
00:16:04,080 --> 00:16:07,960
Speaker 4:  track reality, right? Because it's like, if I'm on Spotify is a

292
00:16:07,960 --> 00:16:11,680
Speaker 4:  perfectly good example, right? If I open up Spotify, press play on a playlist,

293
00:16:11,870 --> 00:16:15,400
Speaker 4:  turn my phone off, put it in my pocket and never touch it again, in a certain

294
00:16:15,400 --> 00:16:18,160
Speaker 4:  sense, that's a huge victory, right? Like that is the intended use of Spotify.

295
00:16:18,160 --> 00:16:20,920
Speaker 4:  I can listen to music all day without needing to interact with the app. Like

296
00:16:20,920 --> 00:16:24,720
Speaker 4:  from user experience, that's a gigantic win for Spotify trying to like, make

297
00:16:24,720 --> 00:16:28,640
Speaker 4:  money and sell lots of really great powerful visual ads, that's a disaster.

298
00:16:28,740 --> 00:16:32,240
Speaker 4:  And so what this is now is Spotify saying, and they even said this during

299
00:16:32,240 --> 00:16:34,600
Speaker 4:  the stream on event, they're like, we're not worried about engagement metrics.

300
00:16:34,600 --> 00:16:37,560
Speaker 4:  We're not here to just try to keep you inside of our app as much as you can.

301
00:16:37,720 --> 00:16:41,560
Speaker 4:  While very clearly building things that autoplay, that autoplay

302
00:16:41,560 --> 00:16:45,200
Speaker 4:  with sound and that are designed to be endlessly scrolling so that you look

303
00:16:45,200 --> 00:16:48,200
Speaker 4:  at them for much longer. It's like you at some point you can't have it both

304
00:16:48,200 --> 00:16:51,200
Speaker 4:  ways and they're gonna be like, oh, well engagement went way up. And it's

305
00:16:51,200 --> 00:16:54,480
Speaker 4:  like, well of course it did. But that's, are we sure that's good? Like is

306
00:16:54,480 --> 00:16:55,680
Speaker 4:  that what we want out of Spotify?

307
00:16:56,110 --> 00:17:00,040
Speaker 3:  Yeah, I So one thing that, that the music industry in particular

308
00:17:00,170 --> 00:17:04,040
Speaker 3:  is fighting against straight up is TikTok. TikTok is

309
00:17:04,040 --> 00:17:07,960
Speaker 3:  where every song breaks. It's where, I don't know, like Fleetwood

310
00:17:07,960 --> 00:17:11,400
Speaker 3:  Mac rises like a zombie to continue haunting me for the rest of my days.

311
00:17:12,630 --> 00:17:15,640
Speaker 3:  Just shut up. It's so tiresome,

312
00:17:16,350 --> 00:17:20,280
Speaker 3:  rude. Sorry. I, under the music is beautifully made and I understand they

313
00:17:20,280 --> 00:17:24,000
Speaker 3:  were all dating each other and it, it is on a technical level

314
00:17:24,190 --> 00:17:27,720
Speaker 3:  some of the finest music ever made. It is

315
00:17:27,970 --> 00:17:31,440
Speaker 3:  so boring. I'm sorry, Eli reviews

316
00:17:31,670 --> 00:17:35,080
Speaker 3:  rumors and ranting out Fleetwood Max since I was 16 years old.

317
00:17:35,430 --> 00:17:38,760
Speaker 3:  This is like the sanded off edges of me talking about the,

318
00:17:40,100 --> 00:17:43,880
Speaker 3:  but like that's a thing that happened, right? The guy riding the

319
00:17:43,880 --> 00:17:47,720
Speaker 3:  longboard in California, getting the free cranberries for life or whatever

320
00:17:47,730 --> 00:17:51,680
Speaker 3:  is an entirely a TikTok phenomenon. I realize that if you don't know

321
00:17:51,680 --> 00:17:54,840
Speaker 3:  what I'm talking about, that sounded completely bonkers. But if you just

322
00:17:54,900 --> 00:17:58,280
Speaker 3:  put those words into Google, you will, you will understand.

323
00:17:58,430 --> 00:18:02,160
Speaker 3:  It's a whole thing that happened. Yep. That's TikTok. Like TikTok just like

324
00:18:02,160 --> 00:18:05,280
Speaker 3:  made that song relevant again. It made fleet relevant again. It's doing it

325
00:18:05,280 --> 00:18:08,920
Speaker 3:  over and over and over again. It's where new artists break, it's

326
00:18:09,160 --> 00:18:12,160
Speaker 3:  changing the complexion of the music industry. It's making songs shorter,

327
00:18:12,160 --> 00:18:16,120
Speaker 3:  which is very funny. It's like sampling it. Like if everything is in the

328
00:18:16,120 --> 00:18:19,480
Speaker 3:  music industry is happening on TikTok and then underneath it all,

329
00:18:19,750 --> 00:18:23,720
Speaker 3:  TikTok is not a music service really. And so

330
00:18:23,720 --> 00:18:27,600
Speaker 3:  they're kind of like, yeah, music industry, you want to break a song, just

331
00:18:27,600 --> 00:18:31,520
Speaker 3:  pay us a bunch of money and we'll make sure those tracks get promoted

332
00:18:31,610 --> 00:18:35,480
Speaker 3:  in a way that if Spotify does it and people claim Spotify does

333
00:18:35,480 --> 00:18:39,280
Speaker 3:  it, but if they actually do that, everyone will get really mad at Spotify.

334
00:18:39,550 --> 00:18:43,520
Speaker 3:  Yeah. So like Spotify's just got like a, a major problem on its hands that

335
00:18:43,520 --> 00:18:47,240
Speaker 3:  all discovery happens on TikTok and then people go to Spotify to listen to

336
00:18:47,240 --> 00:18:51,160
Speaker 3:  the song, but they're spending all of their time on a platform that has video

337
00:18:51,520 --> 00:18:55,200
Speaker 3:  advertising built into it, which is much more lucrative than Spotify

338
00:18:55,230 --> 00:18:55,720
Speaker 3:  free.

339
00:18:55,720 --> 00:18:59,000
Speaker 4:  Right. But the the important second piece of that though is like,

340
00:18:59,310 --> 00:19:03,120
Speaker 4:  it's not audio led discovery, right? Like people are watching

341
00:19:03,120 --> 00:19:06,680
Speaker 4:  videos through which they discover audio and that's

342
00:19:06,830 --> 00:19:10,560
Speaker 4:  like Spotify has everybody, lots of different publications or not

343
00:19:10,560 --> 00:19:13,360
Speaker 4:  publications. Lots of different companies have tried to figure out how to

344
00:19:13,360 --> 00:19:16,840
Speaker 4:  do Audio First discovery. And it turns out it's essentially impossible because

345
00:19:16,840 --> 00:19:20,280
Speaker 4:  the idea of like, I'm gonna sit here and just listen to something I've never

346
00:19:20,280 --> 00:19:23,320
Speaker 4:  heard of for a while is super boring and people get tired of it and that's

347
00:19:23,320 --> 00:19:25,840
Speaker 4:  why everybody puts the hook to their song at the beginning of the song now.

348
00:19:25,900 --> 00:19:29,760
Speaker 4:  And so, but what you have with the video is it's, it's just

349
00:19:29,760 --> 00:19:32,400
Speaker 4:  more interesting. It's just gonna hold your attention a little longer, which

350
00:19:32,400 --> 00:19:35,520
Speaker 4:  gives the song a chance to catch you a little longer and then you can sort

351
00:19:35,520 --> 00:19:39,240
Speaker 4:  of trip through TikTok that way. And so Spotify has been trying to play this

352
00:19:39,240 --> 00:19:43,160
Speaker 4:  like how do we do more visual things game forever to keep you looking

353
00:19:43,160 --> 00:19:46,800
Speaker 4:  at the app and has just never solved it anything like the way

354
00:19:46,800 --> 00:19:48,240
Speaker 4:  TikTok has solved it. Yeah.

355
00:19:48,260 --> 00:19:52,240
Speaker 3:  And now they've just made TikTok again. And I, I think that the big question

356
00:19:52,240 --> 00:19:56,010
Speaker 3:  is whether people are going to open Spotify first

357
00:19:56,580 --> 00:20:00,330
Speaker 3:  to be like, I wanna find some new things. This is Spotify's claim, right?

358
00:20:00,330 --> 00:20:03,810
Speaker 3:  That the business they're in is actually discovery and not

359
00:20:03,810 --> 00:20:07,570
Speaker 3:  playback. And if you, you listen to the interview with

360
00:20:07,570 --> 00:20:11,530
Speaker 3:  Gustav that Alex is gonna do on decoder next week, or if you listen to their

361
00:20:11,530 --> 00:20:15,330
Speaker 3:  event, they're very clear that the the whole

362
00:20:15,330 --> 00:20:18,890
Speaker 3:  thing they're doing is trying to get people to try new things. Yeah. And

363
00:20:18,890 --> 00:20:22,610
Speaker 3:  that is fundamentally Spotify's value to the world is discovery across the

364
00:20:22,610 --> 00:20:24,970
Speaker 3:  list. I'll just read this quote, not to give away the whole interview, but

365
00:20:24,970 --> 00:20:28,330
Speaker 3:  he says in regards to cover art, he said to Alex, you have to click through

366
00:20:28,330 --> 00:20:31,010
Speaker 3:  one of the titles and you have to wait for one and a half on minutes on average

367
00:20:31,300 --> 00:20:34,970
Speaker 3:  to get to the hook. That can't be the best way to discover music. The best

368
00:20:34,970 --> 00:20:38,850
Speaker 3:  way to discover audio must be through audio, which makes

369
00:20:38,850 --> 00:20:42,810
Speaker 3:  intuitive sense. But I know that when people open Spotify and

370
00:20:42,810 --> 00:20:46,290
Speaker 3:  it just starts blasting them with hooks, they're gonna lose their minds.

371
00:20:46,290 --> 00:20:49,520
Speaker 4:  Yeah, I think that's right. And I think by the way, the, the discovery thing

372
00:20:49,520 --> 00:20:53,440
Speaker 4:  is something you'll hear from every single music platform. They all think

373
00:20:53,590 --> 00:20:57,360
Speaker 4:  that the main thing that they can do for the music industry and for

374
00:20:57,360 --> 00:21:00,120
Speaker 4:  listeners is expose you to new stuff. Right? Because it's like, if I wanna

375
00:21:00,120 --> 00:21:04,080
Speaker 4:  listen to Rumors by Fleetwood Mac, I have Infinity Options, many of them

376
00:21:04,080 --> 00:21:06,280
Speaker 4:  free one of them type it into YouTube.

377
00:21:06,280 --> 00:21:08,080
Speaker 3:  And the last one being Don't

378
00:21:09,150 --> 00:21:13,040
Speaker 1:  Rude Rumors is wonderful, a perfect album.

379
00:21:14,670 --> 00:21:18,600
Speaker 3:  Look, I'm not even disputing that the argument, I know that many

380
00:21:18,600 --> 00:21:19,440
Speaker 3:  people feel this way.

381
00:21:19,870 --> 00:21:21,200
Speaker 1:  Mila Hayes for you it back

382
00:21:21,350 --> 00:21:24,480
Speaker 4:  When I spent a bunch of time with Lior Cohen who runs YouTube music a while

383
00:21:24,480 --> 00:21:27,480
Speaker 4:  back and he said very much the same things. And like Apple will say the same

384
00:21:27,480 --> 00:21:30,560
Speaker 4:  thing. That's why they gave Zane Lowe all that money, right? It's like discovery

385
00:21:30,650 --> 00:21:33,480
Speaker 4:  is the thing. They want to help break artists so they can be friends with

386
00:21:33,480 --> 00:21:36,360
Speaker 4:  the music industry. They want to help break artists so that listeners will

387
00:21:36,360 --> 00:21:40,200
Speaker 4:  keep coming back to discover new things. Like that is the product in a really

388
00:21:40,200 --> 00:21:44,000
Speaker 4:  real way, it's just that TikTok showed up and is so much better at it than

389
00:21:44,000 --> 00:21:44,560
Speaker 4:  anybody else.

390
00:21:44,690 --> 00:21:48,560
Speaker 1:  Is it also because like the playlist suck because for a long time they kind

391
00:21:48,560 --> 00:21:52,360
Speaker 1:  of tried to replicate the DJ by doing all day playlists,

392
00:21:52,360 --> 00:21:55,960
Speaker 1:  right? And and are people just not listening to those playlists and finding

393
00:21:55,960 --> 00:21:57,080
Speaker 1:  new musicians that way?

394
00:21:57,230 --> 00:22:00,520
Speaker 3:  Well, Spotify rolled out the AI playlist. Yeah, but those suck. So they're

395
00:22:00,520 --> 00:22:02,400
Speaker 3:  doing much, much more of this stuff.

396
00:22:02,570 --> 00:22:05,960
Speaker 5:  It sounds like the problem for TikTok, the problem for Spotify, the problem

397
00:22:05,960 --> 00:22:09,360
Speaker 5:  for YouTube music is that I am not 16 always

398
00:22:09,540 --> 00:22:13,200
Speaker 5:  and I'm not always hearing the best music I will ever hear ever

399
00:22:13,330 --> 00:22:14,440
Speaker 5:  at that point in my life.

400
00:22:16,620 --> 00:22:19,480
Speaker 5:  And if I were, maybe I would wanna listen to these playlists and listen to

401
00:22:19,480 --> 00:22:22,680
Speaker 5:  a bunch of new songs because I'd be young and I I would be experiencing new

402
00:22:22,680 --> 00:22:25,760
Speaker 5:  things and I would say, yes, I am them. I'm making this music my entire personality

403
00:22:25,760 --> 00:22:29,670
Speaker 5:  now as, as I did then. But it's now X number

404
00:22:29,670 --> 00:22:33,270
Speaker 5:  of years later that music is still my personality. I want to hear the music

405
00:22:33,270 --> 00:22:37,150
Speaker 5:  that I listened to a decade plus ago. That is the only thing that I want.

406
00:22:37,180 --> 00:22:40,830
Speaker 5:  I do not want a playlist. I do not want suggestions. I want to hear the same

407
00:22:40,830 --> 00:22:43,670
Speaker 5:  songs that I've already heard. Possibly you could remix them and blend them

408
00:22:43,830 --> 00:22:47,710
Speaker 5:  together. That's cool. No new music. But I, I guess that's a

409
00:22:47,990 --> 00:22:50,550
Speaker 5:  problem for Spotify that that I don't wanna listen to the new things.

410
00:22:50,620 --> 00:22:54,510
Speaker 3:  Well, so under underneath that is, the real problem for Spotify

411
00:22:54,920 --> 00:22:58,710
Speaker 3:  is that you listening to hits from the nineties over and over

412
00:22:58,710 --> 00:23:02,630
Speaker 3:  again does not actually make those artists any money. And maybe it

413
00:23:02,630 --> 00:23:05,830
Speaker 3:  shouldn't, right? Like in the CD era, you would buy that cd, you would listen

414
00:23:05,830 --> 00:23:09,390
Speaker 3:  to it for the rest of your life. That artist would not get money every time

415
00:23:09,390 --> 00:23:13,270
Speaker 3:  you listen to a cd. But they got a lot of money up front for the

416
00:23:13,270 --> 00:23:17,230
Speaker 3:  cd, right? And that u usually sustained most artists now

417
00:23:17,230 --> 00:23:20,590
Speaker 3:  it's like the game that they're all playing is like pennies forever,

418
00:23:20,830 --> 00:23:24,430
Speaker 3:  right? So Spotify has a lot of incentive to make their catalog artists,

419
00:23:24,800 --> 00:23:28,750
Speaker 3:  or like the catalog artists from major labels happy because no one is getting

420
00:23:28,750 --> 00:23:31,830
Speaker 3:  the big dollars up front. They're all just getting pennies over time. But

421
00:23:31,830 --> 00:23:34,870
Speaker 3:  they still have to break new artists. And to break new artists, you gotta

422
00:23:34,870 --> 00:23:38,270
Speaker 3:  shove 'em in people's faces all the time. You gotta break new songs. And

423
00:23:38,270 --> 00:23:42,150
Speaker 3:  I, I think all of this stuff is in a real tension with the other piece

424
00:23:42,150 --> 00:23:46,050
Speaker 3:  of what they announced, which is an emphasis on video podcasts

425
00:23:46,150 --> 00:23:50,050
Speaker 3:  and showing you little clips of video podcasts in the feed as you

426
00:23:50,050 --> 00:23:53,930
Speaker 3:  scroll. Because that is just a jarring transition from like,

427
00:23:54,000 --> 00:23:57,090
Speaker 3:  here's the hook of a song, here's the hook of a song. Do you like this playlist?

428
00:23:57,090 --> 00:24:00,650
Speaker 3:  Go over here, here's three people talking about whatever. Which is

429
00:24:01,330 --> 00:24:02,370
Speaker 3:  admittedly what we do here.

430
00:24:03,460 --> 00:24:04,010
Speaker 1:  Hi guys.

431
00:24:04,250 --> 00:24:07,690
Speaker 3:  And we'll probably figure out how to get involved in that on Spotify. But

432
00:24:07,690 --> 00:24:11,610
Speaker 3:  it's just, there's a lot of stuff, there's a lot of business models

433
00:24:11,610 --> 00:24:13,850
Speaker 3:  they're trying to cram into one experience.

434
00:24:14,030 --> 00:24:17,730
Speaker 4:  But this is the magic of TikTok. Like that that thing

435
00:24:17,730 --> 00:24:21,090
Speaker 4:  you just described is the thing that has made TikTok so powerful, which is

436
00:24:21,090 --> 00:24:24,970
Speaker 4:  that it can be wrong about what you're gonna be interested in nine

437
00:24:24,970 --> 00:24:28,730
Speaker 4:  outta 10 times. And TikTok that that like endless vertical scrolling

438
00:24:28,730 --> 00:24:32,370
Speaker 4:  thing with video and sound is like immersive enough

439
00:24:32,370 --> 00:24:36,010
Speaker 4:  even when you don't care about what it is that it keeps you scrolling. And

440
00:24:36,010 --> 00:24:39,170
Speaker 4:  that's like, that's the magical thing that TikTok solved is most of the time

441
00:24:39,170 --> 00:24:41,450
Speaker 4:  you don't care about the thing that's being shown to you, but the price of

442
00:24:41,450 --> 00:24:45,250
Speaker 4:  TikTok being wrong is so low because the scrolling experience

443
00:24:45,250 --> 00:24:48,490
Speaker 4:  is so fun that you will just keep scrolling even when you don't care about

444
00:24:48,490 --> 00:24:52,330
Speaker 4:  the content. Like the activity is enough. And what that gave TikTok

445
00:24:52,330 --> 00:24:56,090
Speaker 4:  permission to do was just shove stuff you don't care about in your face

446
00:24:56,090 --> 00:25:00,010
Speaker 4:  all the time to see what hits. And everyone is copying that for exactly

447
00:25:00,010 --> 00:25:02,410
Speaker 4:  that same reason, right? Like that's what Facebook is trying to do. They're

448
00:25:02,410 --> 00:25:05,290
Speaker 4:  like, we are you interested in this? And you say no. And they're like, what

449
00:25:05,290 --> 00:25:07,850
Speaker 4:  about this? And you say no. And they're like, what about this? And they'll

450
00:25:07,850 --> 00:25:08,130
Speaker 4:  just do that

451
00:25:08,130 --> 00:25:12,010
Speaker 3:  Forever and, and Facebook can't figure it out. It's like, is it girls? And

452
00:25:12,010 --> 00:25:15,890
Speaker 3:  they'll, there's just like one bikini girl no matter what at all times.

453
00:25:16,410 --> 00:25:19,610
Speaker 3:  And I'm like, no, no, no, it's trucks jumping over stuff. I want to be very

454
00:25:19,610 --> 00:25:23,210
Speaker 3:  clear about this. I literally typed the words into the search box

455
00:25:23,910 --> 00:25:27,530
Speaker 3:  and like every couple weeks I was like, I don't know, just one thing that'll

456
00:25:27,530 --> 00:25:27,890
Speaker 3:  make your wife

457
00:25:27,890 --> 00:25:31,530
Speaker 4:  Mad minus bloopers from the office. It's just like when in doubt, TikTok

458
00:25:31,530 --> 00:25:34,410
Speaker 4:  just show me bloopers from the office and like, we're cool again, everything's

459
00:25:34,410 --> 00:25:37,890
Speaker 4:  fine. But no, but that's the thing and that's why you do that extra visual

460
00:25:37,890 --> 00:25:41,730
Speaker 4:  thing because it's just constant. There's just so much going

461
00:25:41,730 --> 00:25:45,370
Speaker 4:  on in a way that like if you show me eight seconds of silence at the beginning

462
00:25:45,370 --> 00:25:48,650
Speaker 4:  of a song and a playlist or like a slow building guitar, people are out.

463
00:25:48,650 --> 00:25:52,570
Speaker 4:  But if you just like play loud noise over and over again as I scroll. Yeah.

464
00:25:52,570 --> 00:25:53,490
Speaker 4:  Like that's gonna keep me

465
00:25:53,490 --> 00:25:57,090
Speaker 1:  Engaged. Okay, so in the seventies, like music in the seventies, that's when

466
00:25:57,090 --> 00:26:00,810
Speaker 1:  we started getting the long guitar solos and stuff before that in the forties

467
00:26:00,810 --> 00:26:04,770
Speaker 1:  and fifties. Bill Specter, horrible man, dead now, but he made the wall

468
00:26:04,770 --> 00:26:05,370
Speaker 1:  of sound, right?

469
00:26:06,290 --> 00:26:07,770
Speaker 3:  Horrible man. Dead was coming to him. Phil

470
00:26:08,030 --> 00:26:11,050
Speaker 1:  Was coming to him. I mean played like Russian roulette, Jesus and the lady

471
00:26:11,050 --> 00:26:14,850
Speaker 1:  died, it was not great. True. Wore a cape, dude,

472
00:26:14,850 --> 00:26:18,450
Speaker 1:  like wore a cape to record music. But in the fifties and

473
00:26:18,450 --> 00:26:22,290
Speaker 1:  sixties wearing his little cape, he created That's true. Like a

474
00:26:22,290 --> 00:26:26,130
Speaker 1:  whole new way of listening to music, which was just blasted

475
00:26:26,240 --> 00:26:30,130
Speaker 1:  into your ears on every single, like, he was like, I'm gonna make

476
00:26:30,130 --> 00:26:33,970
Speaker 1:  it really, really loud because everybody's just listening on radio. And so

477
00:26:34,390 --> 00:26:37,890
Speaker 1:  the louder it is, the more they'll like be likely to sit around and listen.

478
00:26:37,890 --> 00:26:41,730
Speaker 1:  Which is why we have the Beach Boys, but also like all of those great

479
00:26:41,800 --> 00:26:45,560
Speaker 1:  pops from the, the early sixties. So that's just kind of what they're doing

480
00:26:45,720 --> 00:26:46,920
Speaker 1:  again on TikTok,

481
00:26:46,920 --> 00:26:50,640
Speaker 3:  Pretty much the, the music distribution thing is like really interesting.

482
00:26:50,640 --> 00:26:54,480
Speaker 3:  So Phil Specker is like a, in the like the 45 era, right? He's like

483
00:26:54,480 --> 00:26:58,360
Speaker 3:  doing singles, he's distributing on radio. There's a really great Vox video

484
00:26:58,520 --> 00:27:02,400
Speaker 3:  about the dawn of the 12 inch single and like bands like

485
00:27:02,400 --> 00:27:05,680
Speaker 3:  New Order, were like Blue Monday will be 45 minutes long. Cause we've got,

486
00:27:05,680 --> 00:27:09,280
Speaker 3:  we can just have like oceans of vinyl to print on. Yeah. And then we

487
00:27:09,280 --> 00:27:13,040
Speaker 3:  collab and then you kind of get into those seventies, eighties songs

488
00:27:13,040 --> 00:27:16,560
Speaker 3:  where it's like, what if we did synth pads for like a minute

489
00:27:17,150 --> 00:27:21,000
Speaker 3:  before a single drum? Right? And it's like these like

490
00:27:21,000 --> 00:27:24,680
Speaker 3:  huge builds and like Pink Floyd is just like, you know,

491
00:27:25,190 --> 00:27:29,040
Speaker 3:  swishing around your house, just haunting you. That's great. Like

492
00:27:29,040 --> 00:27:33,000
Speaker 3:  that music is great. Could not work with any modern distribution. No. Yeah,

493
00:27:33,000 --> 00:27:36,520
Speaker 3:  because you can't, you there's, you just can't get to the hook right away.

494
00:27:36,620 --> 00:27:40,360
Speaker 3:  And all of that was when people bought vinyl records, they,

495
00:27:40,360 --> 00:27:43,880
Speaker 3:  they literally thought they wanted a lot of music for the money.

496
00:27:44,110 --> 00:27:48,040
Speaker 3:  Like the Clash is like Sand Anisa is 3, 3 12

497
00:27:48,320 --> 00:27:52,280
Speaker 3:  inches. It's like six sides of vinyl. There are skits in here for some

498
00:27:52,280 --> 00:27:56,240
Speaker 3:  reason we don't know why. And that's just value for dollar. And

499
00:27:56,240 --> 00:27:59,840
Speaker 3:  now everything is free. So it's like just on to the next one. Fine.

500
00:28:00,140 --> 00:28:03,680
Speaker 3:  The thing that's really interesting on Spotify one, it's not a swipe, it's

501
00:28:03,680 --> 00:28:07,640
Speaker 3:  a scroll, which is the smallest distinction, but I

502
00:28:07,640 --> 00:28:10,880
Speaker 3:  think a weird one, right? They're trying to like cop this user interface

503
00:28:11,080 --> 00:28:13,840
Speaker 3:  behavior from TikTok, but they're making you like slowly scroll through this

504
00:28:13,840 --> 00:28:17,480
Speaker 3:  stuff. I think I would bet they switch to swipes pretty soon. And then two,

505
00:28:17,480 --> 00:28:21,280
Speaker 3:  what TikTok has is a, a infinite universe of user generated

506
00:28:21,280 --> 00:28:25,240
Speaker 3:  content. So there, there is a lot of garbage, but then

507
00:28:25,240 --> 00:28:28,440
Speaker 3:  like things will hit that no one ever thought of, right? And that's like

508
00:28:28,440 --> 00:28:32,320
Speaker 3:  the magic Spotify is still pretty curated. Like what

509
00:28:32,320 --> 00:28:36,120
Speaker 3:  ends up in that feed is gonna be pretty curated by the music industry,

510
00:28:36,410 --> 00:28:39,840
Speaker 3:  by the podcast industry. Spotify does have anchor, they're like user

511
00:28:39,840 --> 00:28:43,760
Speaker 3:  generated podcast tool, but they've really diminished its stature.

512
00:28:43,760 --> 00:28:47,160
Speaker 3:  I think they've even renamed it. Yeah. It's part of like Spotify for podcasters

513
00:28:47,160 --> 00:28:50,840
Speaker 3:  now. Yeah. So you've just got this feed, it's like it acts a little differently.

514
00:28:51,250 --> 00:28:54,920
Speaker 3:  It is way more curated and professional. And usually those

515
00:28:54,920 --> 00:28:58,880
Speaker 3:  things together mean that they get stale fast as opposed to

516
00:28:58,880 --> 00:29:02,640
Speaker 3:  like the endless, like what are the kids doing today of TikTok?

517
00:29:03,020 --> 00:29:06,160
Speaker 5:  The question for Spotify is that now that they're, they've leading into video,

518
00:29:06,300 --> 00:29:07,800
Speaker 5:  can they be on the go 90 scale?

519
00:29:09,940 --> 00:29:12,880
Speaker 3:  Can I read you this quote that I've just been thinking about? So Spotify's

520
00:29:12,880 --> 00:29:16,160
Speaker 3:  leading into video podcasts, everyone's in the video podcasts. The reason

521
00:29:16,160 --> 00:29:20,000
Speaker 3:  is not complicated, right? It's that for the platforms,

522
00:29:20,000 --> 00:29:23,720
Speaker 3:  not for necessarily for the podcasters, but for the platforms being able

523
00:29:23,720 --> 00:29:27,520
Speaker 3:  to insert video advertising is more lucrative

524
00:29:27,520 --> 00:29:31,320
Speaker 3:  than audio advertising. We are obviously this shows on YouTube

525
00:29:31,320 --> 00:29:34,880
Speaker 3:  now, like the details of our money are actually opaque to us. That's the

526
00:29:34,880 --> 00:29:37,680
Speaker 3:  whole point of the fact that we are journalism. There's a sales team, they

527
00:29:37,680 --> 00:29:40,920
Speaker 3:  do it all over there, but there's a real dynamic between the money you make

528
00:29:40,920 --> 00:29:44,160
Speaker 3:  and, and the audio and the money you make in video. And the dollars in video

529
00:29:44,160 --> 00:29:47,960
Speaker 3:  are generally higher. They're not higher on YouTube, which is weird.

530
00:29:47,960 --> 00:29:51,920
Speaker 3:  But YouTube is like the gold standard video platform. A

531
00:29:51,920 --> 00:29:55,760
Speaker 3:  lot of the platforms want to go capture those video dollars. So that's why

532
00:29:55,760 --> 00:29:59,240
Speaker 3:  Reddit does it. That's why Spotify's doing it. But here's this quote and

533
00:29:59,520 --> 00:30:02,960
Speaker 3:  it just video podcasting is one of the fastest

534
00:30:02,960 --> 00:30:06,560
Speaker 3:  growing areas of podcasting and we expect that growth to continue.

535
00:30:06,560 --> 00:30:10,200
Speaker 3:  That's from Julie McNamara, head of Global Podcast Studios at Spotify at

536
00:30:10,200 --> 00:30:14,080
Speaker 3:  this event. What's the video podcast? Is it just videos of

537
00:30:14,080 --> 00:30:18,000
Speaker 3:  people talking? I mean I, this is a video podcast, right? That's, yes. I

538
00:30:18,000 --> 00:30:21,840
Speaker 3:  think we get that is the view of video podcast. Yes.

539
00:30:22,190 --> 00:30:26,080
Speaker 3:  Okay. Hundred percent. What is it? A video

540
00:30:26,080 --> 00:30:26,480
Speaker 3:  podcast?

541
00:30:26,590 --> 00:30:30,440
Speaker 4:  I actually, I think Alex is right. Like I, I think the the, there was a

542
00:30:30,440 --> 00:30:34,400
Speaker 4:  great Twitter thread and I don't remember who it was, but I'm sorry. I'll

543
00:30:34,400 --> 00:30:37,240
Speaker 4:  see if I can find it and I'll tweet it back out. Actually I won't. I'm gonna

544
00:30:37,240 --> 00:30:39,480
Speaker 4:  use Twitter. But that's a whole other point that they were talking about

545
00:30:40,040 --> 00:30:43,960
Speaker 4:  Jason and Travis Kelsey, these football playing brothers who have had a super

546
00:30:43,960 --> 00:30:47,160
Speaker 4:  successful thing. And one of the points that the thread made was that they

547
00:30:47,160 --> 00:30:50,600
Speaker 4:  don't call it a podcast like it is distributed as a podcast on podcast

548
00:30:51,280 --> 00:30:54,680
Speaker 4:  platforms, but they just think of it as like a show. And I think that's right.

549
00:30:54,680 --> 00:30:58,560
Speaker 4:  Like what is, what is an interview show other than a video

550
00:30:58,560 --> 00:31:02,520
Speaker 4:  podcast, right? Like people talking to people on screen has been around

551
00:31:02,520 --> 00:31:05,960
Speaker 4:  forever. The only difference is like, we show the microphones now. And so

552
00:31:05,960 --> 00:31:09,920
Speaker 4:  I think what's happened is this stuff has all just sort of collapsed

553
00:31:09,920 --> 00:31:13,120
Speaker 4:  where it's like, okay, people talking is interesting. Watching people talk

554
00:31:13,120 --> 00:31:16,600
Speaker 4:  is interesting. These things don't all have to be different.

555
00:31:16,850 --> 00:31:20,760
Speaker 4:  We can just shove them together and just let them be shows like the

556
00:31:20,760 --> 00:31:24,480
Speaker 4:  word podcast is like a relic of iPods, right? Like it hasn't

557
00:31:24,480 --> 00:31:27,360
Speaker 4:  described what this industry is in a really long time. And

558
00:31:27,360 --> 00:31:30,800
Speaker 3:  So, no, I'm telling you this is an exist. You were describing very confidently

559
00:31:30,970 --> 00:31:33,320
Speaker 3:  an existential crisis for the podcast industry.

560
00:31:33,450 --> 00:31:35,560
Speaker 4:  Oh, absolutely. It's happening. It's like

561
00:31:35,740 --> 00:31:39,520
Speaker 3:  The idea that you make radio and you distribute is MP3 files via

562
00:31:39,660 --> 00:31:43,560
Speaker 3:  RSS to it. It an ecosystem of players are all inter

563
00:31:43,560 --> 00:31:46,840
Speaker 3:  independent and can compete with each. That's po. Like

564
00:31:47,330 --> 00:31:50,280
Speaker 3:  if you ask people what is a podcast, they will start with

565
00:31:51,020 --> 00:31:51,880
Speaker 3:  RSS feeds.

566
00:31:51,880 --> 00:31:55,360
Speaker 4:  Sure. And that broke the minute Spotify started spending money on podcasters,

567
00:31:55,360 --> 00:31:59,200
Speaker 4:  right? Like this is, this has been dying for a while. And I think what you're

568
00:31:59,200 --> 00:32:02,960
Speaker 4:  seeing now is everybody just acknowledging that like, okay, this,

569
00:32:02,960 --> 00:32:06,160
Speaker 4:  this doesn't, this distinction doesn't exist anymore. And actually what we're

570
00:32:06,160 --> 00:32:08,840
Speaker 4:  talking about is just a bunch of different kinds of distribution for the

571
00:32:08,840 --> 00:32:12,240
Speaker 4:  same kind of thing, which is people you talk that you care about doing stuff

572
00:32:12,480 --> 00:32:15,960
Speaker 4:  together, talking to each other. It's right. Like it's, I don't know, these

573
00:32:15,960 --> 00:32:17,000
Speaker 4:  things are not that far apart. I

574
00:32:17,000 --> 00:32:19,800
Speaker 3:  Don't think we, again, we obviously are participants in this. I

575
00:32:19,800 --> 00:32:20,160
Speaker 4:  Love video

576
00:32:20,160 --> 00:32:23,600
Speaker 3:  Podcasts. We make videos of this podcast and other podcasts. We put them

577
00:32:23,600 --> 00:32:26,720
Speaker 3:  on YouTube. We should figure out how to put them on Spotify. I didn't even

578
00:32:26,720 --> 00:32:30,560
Speaker 3:  know that Apple Podcast supports video. It does, does it? I don't know

579
00:32:30,560 --> 00:32:33,400
Speaker 3:  anybody who watches video and Apple Podcast, but it definitely supports video

580
00:32:33,430 --> 00:32:33,920
Speaker 3:  only

581
00:32:33,920 --> 00:32:34,800
Speaker 1:  Way I watch video.

582
00:32:35,990 --> 00:32:37,040
Speaker 3:  Just the only

583
00:32:37,040 --> 00:32:38,160
Speaker 6:  Way, no other

584
00:32:38,160 --> 00:32:41,480
Speaker 3:  Way to watch it. Watch who it, I watch RSS fed video and app,

585
00:32:41,480 --> 00:32:44,960
Speaker 5:  But I catch myself on TikTok sometimes watching video clips of podcasts that

586
00:32:44,960 --> 00:32:48,000
Speaker 5:  I've already listened to. Absolutely. And I, I can't even really

587
00:32:48,000 --> 00:32:51,920
Speaker 3:  Explain it. By the way, go subscribe to youtube.com/ver,

588
00:32:52,800 --> 00:32:53,720
Speaker 3:  we'd really appreciate it.

589
00:32:54,120 --> 00:32:57,920
Speaker 4:  It's great. Okay. But wait, wait, Mila, let me, let me just expand this

590
00:32:57,920 --> 00:33:00,920
Speaker 4:  existential crisis slightly. Yeah. So one of my favorite podcasts is the

591
00:33:00,920 --> 00:33:04,680
Speaker 4:  Always Sunny podcast, which is just the three creators and

592
00:33:04,680 --> 00:33:08,280
Speaker 4:  stars of the show. It's always Sunny in Philadelphia doing a podcast.

593
00:33:08,740 --> 00:33:12,720
Speaker 4:  The the show is a podcast. It's also a video podcast on YouTube,

594
00:33:12,840 --> 00:33:16,600
Speaker 4:  often on YouTube on, during their podcast they will play clips of their

595
00:33:16,600 --> 00:33:20,480
Speaker 4:  show and talk about the clips from their show or

596
00:33:20,480 --> 00:33:23,320
Speaker 4:  about the process of writing this show. So you could argue that their podcast

597
00:33:23,320 --> 00:33:26,360
Speaker 4:  has bled into a video podcast which has bled into their television show.

598
00:33:26,360 --> 00:33:29,080
Speaker 4:  And I'm sure they're gonna do an episode where they make a podcast. They

599
00:33:29,080 --> 00:33:31,360
Speaker 4:  did do an episode where they make a podcast. It's like, what

600
00:33:31,360 --> 00:33:31,480
Speaker 3:  Is,

601
00:33:32,030 --> 00:33:33,000
Speaker 4:  What is any of

602
00:33:33,000 --> 00:33:33,880
Speaker 3:  This anymore? What is

603
00:33:33,880 --> 00:33:34,520
Speaker 4:  Content? I don't know.

604
00:33:34,990 --> 00:33:38,680
Speaker 3:  I just, the idea that everything is a video podcast and

605
00:33:38,880 --> 00:33:42,600
Speaker 3:  soon Spotify will try to shove it into a feed that is almost TikTok but not

606
00:33:42,600 --> 00:33:44,120
Speaker 3:  quite. That's where we're going.

607
00:33:44,120 --> 00:33:45,400
Speaker 4:  Yes, absolutely. Yes.

608
00:33:45,400 --> 00:33:49,320
Speaker 3:  Right. Like one of my favorite examples of this is cnbc. All of their

609
00:33:49,320 --> 00:33:53,000
Speaker 3:  hours are published as audio podcasts in Apple Pod.

610
00:33:53,000 --> 00:33:56,760
Speaker 3:  You can go get Squawk on the street as a podcast every day.

611
00:33:56,820 --> 00:34:00,640
Speaker 3:  And it's just CNBC Anchors doing their show with

612
00:34:00,640 --> 00:34:03,400
Speaker 3:  no regard to the fact that it's a podcast. It play, it works perfectly

613
00:34:03,400 --> 00:34:06,240
Speaker 4:  Fine. Yeah. You just have to imagine there's a lower crawl saying stocks

614
00:34:06,240 --> 00:34:08,600
Speaker 4:  down, everybody panics. And that's all

615
00:34:08,700 --> 00:34:12,560
Speaker 3:  Run on your bank. Get out there. Just run at your bank as fast

616
00:34:12,560 --> 00:34:16,400
Speaker 3:  as you can. I mean, I think they're usually, when people

617
00:34:16,400 --> 00:34:20,240
Speaker 3:  think of podcasts, they, they think of not a distribution

618
00:34:20,950 --> 00:34:24,930
Speaker 3:  but like a form. Yes. Right. This thing that we make is

619
00:34:24,930 --> 00:34:28,770
Speaker 3:  a podcast that despite all odds has been going on for over 10 years

620
00:34:28,770 --> 00:34:31,850
Speaker 3:  now. And it, it's just this, right? It's people talking to each other, maybe

621
00:34:31,850 --> 00:34:35,530
Speaker 3:  some format, maybe somewhere along the way seminal commit a murder and we'll

622
00:34:35,530 --> 00:34:37,690
Speaker 3:  figure out who did it. Richard, that's on next season of VER

623
00:34:38,350 --> 00:34:40,450
Speaker 4:  Two, crime is an ideal waiting

624
00:34:40,450 --> 00:34:43,490
Speaker 3:  To happen. Can we get, William, can you start playing like the Tinkly serial

625
00:34:43,530 --> 00:34:44,610
Speaker 3:  piano here? Please.

626
00:34:46,240 --> 00:34:49,730
Speaker 3:  That would be amazing. Right? There's formats in podcasting, but you kind

627
00:34:49,730 --> 00:34:52,330
Speaker 3:  of understand what they are and people riff on them and they expand them

628
00:34:52,330 --> 00:34:56,250
Speaker 3:  in. You do not think of RSS based distribution. And I think once you

629
00:34:56,250 --> 00:35:00,210
Speaker 3:  open the door to, it's a video too. I, I have seen podcasts

630
00:35:00,210 --> 00:35:03,090
Speaker 3:  where everyone's wearing laugh mics and just sitting around on couches and

631
00:35:03,090 --> 00:35:06,890
Speaker 3:  you're like, this is getting, like, this is just a talk show now. This is

632
00:35:07,040 --> 00:35:10,850
Speaker 3:  late night television, but we're calling it a video podcast to get it

633
00:35:10,850 --> 00:35:14,690
Speaker 3:  into all this distribution. I don't know, like there's Spotify is,

634
00:35:14,940 --> 00:35:18,650
Speaker 3:  they're gonna end up competing more with YouTube than I think they understand

635
00:35:18,860 --> 00:35:22,490
Speaker 3:  because YouTube has all of that and it has YouTube videos and it has

636
00:35:23,530 --> 00:35:24,570
Speaker 3:  whatever else, right? I

637
00:35:24,660 --> 00:35:28,130
Speaker 1:  Oh, like I think yeah, they'll kind, they'll compete with YouTube in that

638
00:35:28,130 --> 00:35:31,930
Speaker 1:  the fact that YouTube is creating its own like podcasting setup

639
00:35:31,930 --> 00:35:34,810
Speaker 1:  and everything. But at the same time, I keep going back to this show critical

640
00:35:34,810 --> 00:35:38,080
Speaker 1:  role, which I've only watched like half of, of an episode cuz they're four

641
00:35:38,080 --> 00:35:41,160
Speaker 1:  hours long and that's a terrible thing to do with your day. But it was a

642
00:35:41,160 --> 00:35:43,880
Speaker 1:  show that was four hours long and people were sitting there watching it and

643
00:35:43,880 --> 00:35:47,720
Speaker 1:  they kept begging for a podcast and they got a podcast and

644
00:35:47,750 --> 00:35:51,240
Speaker 1:  some u some listeners go and they listen to the podcast. Some people watch

645
00:35:51,240 --> 00:35:54,800
Speaker 1:  the show and the show's like still gotten like better. The production

646
00:35:54,800 --> 00:35:58,000
Speaker 1:  qualities have improved. It's all like they're investing further

647
00:35:58,710 --> 00:36:02,280
Speaker 1:  into that side of it. So it's like, I think those two audiences are just

648
00:36:02,280 --> 00:36:06,160
Speaker 1:  very different. And this is just a big mad grab to get

649
00:36:06,160 --> 00:36:08,680
Speaker 1:  as much audience as possible as quickly as possible. Right.

650
00:36:08,870 --> 00:36:11,920
Speaker 3:  Yeah, I, that's what every platform is always doing. I just think Spotify

651
00:36:11,920 --> 00:36:15,080
Speaker 3:  in particular thinks it's competing with TikTok in As, and it's

652
00:36:15,080 --> 00:36:15,480
Speaker 1:  With

653
00:36:15,480 --> 00:36:16,680
Speaker 3:  YouTube. With YouTube,

654
00:36:16,750 --> 00:36:17,240
Speaker 1:  Yeah.

655
00:36:17,420 --> 00:36:21,320
Speaker 3:  And YouTube is out there. Like YouTube was at Hotpod Summit, our

656
00:36:21,470 --> 00:36:25,280
Speaker 3:  hotpod, our podcasting conference a couple weeks ago, they announced

657
00:36:25,370 --> 00:36:29,120
Speaker 3:  YouTube podcast features. They announced video podcast features,

658
00:36:29,120 --> 00:36:33,080
Speaker 3:  background play like YouTube knows they, they see it coming. They

659
00:36:33,080 --> 00:36:37,020
Speaker 3:  see that opportunity. Yeah. But Spotify I think is, they're headed in

660
00:36:37,020 --> 00:36:40,660
Speaker 3:  a different way and somewhere lost in all of this is, boy, I'd like to just

661
00:36:40,660 --> 00:36:44,380
Speaker 3:  see a bunch of songs in my catalog and pick from them.

662
00:36:44,460 --> 00:36:47,020
Speaker 3:  Right. Which appears to be fully outta favor at this point.

663
00:36:47,170 --> 00:36:47,820
Speaker 1:  It's done.

664
00:36:48,370 --> 00:36:51,500
Speaker 3:  Yeah. No one will ever own any music ever again. All right. We gotta take

665
00:36:51,500 --> 00:36:55,340
Speaker 3:  a break. We'll come back. We gotta talk about David's anger at streaming

666
00:36:55,340 --> 00:36:58,980
Speaker 3:  boxes. This is just a real streaming media episode. And then of course there's

667
00:36:58,980 --> 00:37:02,020
Speaker 3:  a Twitter update. We got some policy updates. There's a lot going on. We'll

668
00:37:02,020 --> 00:37:02,380
Speaker 3:  be right back

669
00:37:08,600 --> 00:37:12,500
Speaker 7:  For years now. It's been very unlikely for a big mega

670
00:37:12,500 --> 00:37:16,060
Speaker 7:  box office hit to win best picture at the Oscars

671
00:37:16,390 --> 00:37:20,180
Speaker 8:  As like c CGI heavy movies sort of started to dominate the top

672
00:37:20,180 --> 00:37:24,100
Speaker 8:  10. That's when you sort of started to see that like the public's taste and

673
00:37:24,100 --> 00:37:27,740
Speaker 8:  the Oscar's taste just like really, really started to part ways.

674
00:37:27,740 --> 00:37:31,140
Speaker 8:  Like, I wish they were more aligned too, but I kind of want the public to

675
00:37:31,140 --> 00:37:34,220
Speaker 8:  maybe like, you know, go see the Fable Mans guys. Yeah. Like it's not gonna

676
00:37:34,220 --> 00:37:35,020
Speaker 8:  hurt you. I don't know

677
00:37:35,300 --> 00:37:39,220
Speaker 7:  What's up with the Oscars and Blockbusters this

678
00:37:39,220 --> 00:37:42,620
Speaker 7:  week on Intuit Vultures Pop Culture podcast,

679
00:37:43,160 --> 00:37:45,460
Speaker 7:  new episodes Tuesdays and Fridays.

680
00:37:48,310 --> 00:37:51,850
Speaker 9:  Hey, it's Newell King, co-host of today, explained here by now you've heard

681
00:37:51,850 --> 00:37:55,650
Speaker 9:  about Scott Adams, the Dilbert creator and interpreter of polling data.

682
00:37:56,170 --> 00:37:59,970
Speaker 10:  Well, Rasmussen Poll had a provocative little poll today.

683
00:38:00,480 --> 00:38:04,170
Speaker 10:  They said, do you agree or disagree with a statement?

684
00:38:04,280 --> 00:38:05,770
Speaker 10:  It's okay to be white.

685
00:38:05,910 --> 00:38:08,290
Speaker 9:  Who spent a career building a comic empire.

686
00:38:08,500 --> 00:38:12,170
Speaker 11:  It spoke to so many people. It was the comic strip that you would

687
00:38:12,550 --> 00:38:16,490
Speaker 11:  see push pinned onto cubicle walls as sort of

688
00:38:16,490 --> 00:38:19,770
Speaker 11:  the corporate culture was changing. We needed humor to

689
00:38:20,380 --> 00:38:23,970
Speaker 11:  survive that time. And Scott hit it perfectly,

690
00:38:23,970 --> 00:38:27,810
Speaker 9:  Then got pulled from newspapers after a racist tirade. So many questions,

691
00:38:27,810 --> 00:38:31,530
Speaker 9:  including why is Rasmussen asking people if it's okay to be white?

692
00:38:31,720 --> 00:38:32,770
Speaker 3:  It's a really

693
00:38:32,770 --> 00:38:34,850
Speaker 8:  Weird thing to ask people. And

694
00:38:35,050 --> 00:38:38,360
Speaker 12:  To be honest, I haven't heard a good explanation for why,

695
00:38:38,740 --> 00:38:42,720
Speaker 9:  But we found answers today. Explained. It's in your feed every weekday at

696
00:38:42,720 --> 00:38:43,120
Speaker 9:  2:00 PM

697
00:38:50,600 --> 00:38:54,450
Speaker 3:  Okay. All right, we're back. So David, you went

698
00:38:54,820 --> 00:38:58,810
Speaker 3:  on leave child cared for the child and then you

699
00:38:58,810 --> 00:39:01,930
Speaker 3:  did the thing that everybody on leave does. Parental leave does is you held

700
00:39:01,930 --> 00:39:05,210
Speaker 3:  a baby who was sleeping, you couldn't move and you just

701
00:39:05,260 --> 00:39:09,210
Speaker 3:  thought deeply about technology and you concluded, I think rationally

702
00:39:09,210 --> 00:39:13,090
Speaker 3:  what most people do, the same television is a disaster and you

703
00:39:13,090 --> 00:39:15,050
Speaker 3:  should tell people about it. Tell us about it.

704
00:39:15,120 --> 00:39:18,810
Speaker 4:  That's basically right. So what I promised I wouldn't do

705
00:39:19,190 --> 00:39:23,170
Speaker 4:  was I was not going to become a dad gadget guy. I

706
00:39:23,170 --> 00:39:26,810
Speaker 4:  was like, I will not come back from parental leave and be the guy

707
00:39:26,810 --> 00:39:29,730
Speaker 4:  who's like, have you heard of the Ki Karu? Like I'm not, I will not be that

708
00:39:29,730 --> 00:39:29,930
Speaker 4:  guy.

709
00:39:29,930 --> 00:39:30,850
Speaker 3:  The ki Karu.

710
00:39:30,850 --> 00:39:34,730
Speaker 4:  Yeah, I'm not doing it. You cannot beat me into this. Now I'm not doing

711
00:39:35,010 --> 00:39:38,930
Speaker 4:  it. What did happen was I spent a tremendous amount of

712
00:39:38,930 --> 00:39:42,570
Speaker 4:  time with a child sleeping on top of me watching television. And

713
00:39:42,800 --> 00:39:46,610
Speaker 4:  I watched television on my smart tv. I watched television on my Roku.

714
00:39:46,610 --> 00:39:50,210
Speaker 4:  I watch television on my fire tv. I watched television on my Apple tv.

715
00:39:50,440 --> 00:39:54,170
Speaker 4:  I watched television on my, on my Nvidia Shield because I am a

716
00:39:54,240 --> 00:39:57,850
Speaker 4:  maniac who owns all these things. They're all bad. This is the thing that

717
00:39:57,850 --> 00:40:01,450
Speaker 4:  I have landed on is there was a time, not that many years ago when

718
00:40:01,670 --> 00:40:05,530
Speaker 4:  the TV was going to be like the hub of technology, right? This was when

719
00:40:05,630 --> 00:40:09,450
Speaker 4:  the smart home was really starting to become a thing. This was when smartphone

720
00:40:09,450 --> 00:40:12,250
Speaker 4:  technology was starting to sort of percolate out and everything was getting

721
00:40:12,250 --> 00:40:16,170
Speaker 4:  new processing power and much more sort of sensory awareness. This was the

722
00:40:16,170 --> 00:40:19,410
Speaker 4:  moment when like the game console was gonna shrink all the way down and just

723
00:40:19,410 --> 00:40:22,130
Speaker 4:  become your set top box. Microsoft tried to do it with the Xbox. Everybody

724
00:40:22,130 --> 00:40:26,050
Speaker 4:  was like, the set top box is the future. And what turned out to happen

725
00:40:26,060 --> 00:40:29,930
Speaker 4:  is that set top boxes are bad and getting worse and becoming

726
00:40:29,930 --> 00:40:33,850
Speaker 4:  sort of increasingly commodified because for a bunch of reasons that have

727
00:40:33,850 --> 00:40:37,650
Speaker 4:  to do with how these companies make money, what the streaming services themselves

728
00:40:37,650 --> 00:40:41,490
Speaker 4:  want. And just the fact that this is the world we live

729
00:40:41,490 --> 00:40:45,250
Speaker 4:  in. And smart TVs continue to get cheaper and cheaper, they

730
00:40:45,250 --> 00:40:48,770
Speaker 4:  suck and there's no way for them to get any better. There's no incentive

731
00:40:48,820 --> 00:40:52,810
Speaker 4:  or reason for anyone to try to build a good set top box anymore. And that

732
00:40:52,810 --> 00:40:55,330
Speaker 4:  just made me sad. And I got to the end of this post and I was like, I'm gonna,

733
00:40:55,330 --> 00:40:59,210
Speaker 4:  I'm gonna write an angry thing demanding everybody do better. And I got to

734
00:40:59,210 --> 00:41:02,290
Speaker 4:  the end of it and was like, oh no, it, it's just bad and it's never getting

735
00:41:02,290 --> 00:41:02,770
Speaker 4:  any better.

736
00:41:02,770 --> 00:41:06,530
Speaker 3:  Yeah. The, so the ones that you really called out were, it's still very

737
00:41:06,530 --> 00:41:10,450
Speaker 3:  app-based. Yeah. Which is what some of them want. I think Apple's still like,

738
00:41:10,690 --> 00:41:13,850
Speaker 3:  whatever it's app-based, that's fine, but two, so it's app based instead

739
00:41:13,850 --> 00:41:15,290
Speaker 3:  of content based. So

740
00:41:15,290 --> 00:41:19,170
Speaker 4:  Yeah, I mean that's the, the simplest thing set top box should do

741
00:41:19,170 --> 00:41:22,970
Speaker 4:  for you is take you to the things you wanna watch. Like that doesn't strike

742
00:41:22,970 --> 00:41:23,290
Speaker 4:  you as,

743
00:41:23,290 --> 00:41:26,570
Speaker 1:  But it's never going to, cuz Netflix Complicated doesn't wanna

744
00:41:26,570 --> 00:41:30,530
Speaker 1:  participate in any ecosystem that allows you to, that allows

745
00:41:30,530 --> 00:41:33,310
Speaker 1:  you to find their content anywhere. But the Netflix app,

746
00:41:33,550 --> 00:41:37,470
Speaker 4:  Right? It's like if, if if 30 years ago, you know,

747
00:41:37,470 --> 00:41:40,350
Speaker 4:  one of the cable companies had just been like, no, we don't wanna be in the

748
00:41:40,350 --> 00:41:43,390
Speaker 4:  guide. You have to use a different guide if you wanna get to cnn. This is

749
00:41:43,390 --> 00:41:46,990
Speaker 4:  somehow the world we've ended up in. Yes. It's like, like the, the old

750
00:41:46,990 --> 00:41:50,950
Speaker 4:  spreadsheet TV guide was a much better interface than anything we have for

751
00:41:50,950 --> 00:41:54,350
Speaker 4:  finding stuff to watch now. And like that is a deeply sad state of affairs.

752
00:41:54,920 --> 00:41:58,630
Speaker 3:  So I love Verge readers because a lot of them are like, whatever the Apple

753
00:41:58,630 --> 00:42:01,990
Speaker 3:  TV is fine. Which I think is a reasonable, it's

754
00:42:02,350 --> 00:42:03,430
Speaker 3:  extremely fine.

755
00:42:03,620 --> 00:42:07,430
Speaker 4:  It's fine. I say that in the piece, like it's, it's probably the best one

756
00:42:07,430 --> 00:42:11,350
Speaker 4:  you can buy because it's the only one that has an actually fast

757
00:42:11,350 --> 00:42:13,710
Speaker 4:  processor. And it's like, you know what? If the system is my

758
00:42:13,820 --> 00:42:15,990
Speaker 3:  Nvidia shield, people just lost their minds. I

759
00:42:15,990 --> 00:42:16,190
Speaker 4:  Was like,

760
00:42:16,590 --> 00:42:18,030
Speaker 1:  Whatever. Say that about the shield.

761
00:42:18,610 --> 00:42:22,390
Speaker 4:  The shield is really fast and just utterly decimated by the fact that Android

762
00:42:22,400 --> 00:42:26,310
Speaker 4:  TV doesn't work very well. Yes. But there's a good processor in

763
00:42:26,310 --> 00:42:29,670
Speaker 4:  there. It just isn't very fast and it's not NVIDIA's fault, but the Apple

764
00:42:29,670 --> 00:42:33,630
Speaker 4:  TV is a perfectly fine thing, right? But like, there's

765
00:42:33,630 --> 00:42:37,470
Speaker 4:  so many simple ways it could be a lot better. One of them is

766
00:42:37,470 --> 00:42:41,190
Speaker 4:  just like if Siri weren't trash and Apple had ever made

767
00:42:41,190 --> 00:42:45,150
Speaker 4:  Siri good at anything ever for any reason, the Apple TV might be

768
00:42:45,150 --> 00:42:49,110
Speaker 4:  more useful, but it, it just, it's fine. And if, if

769
00:42:49,110 --> 00:42:52,870
Speaker 4:  you want, fine, I can sell you fine for $15. Like you go

770
00:42:53,110 --> 00:42:56,990
Speaker 4:  buy a Roku stick that's inevitably on sale at Amazon or buy a fire TV that

771
00:42:56,990 --> 00:43:00,910
Speaker 4:  they will just give you for free if you look at them and it's all

772
00:43:00,910 --> 00:43:01,310
Speaker 4:  just fine,

773
00:43:01,870 --> 00:43:04,550
Speaker 5:  Whatever. I feel like, fine. It was better a few years ago. Like when, when

774
00:43:04,550 --> 00:43:08,510
Speaker 5:  the Chromecast originally came out, it felt good to use it. It was, it

775
00:43:08,510 --> 00:43:12,360
Speaker 5:  worked. It was cheap. And I think those are the, the two, the two

776
00:43:12,360 --> 00:43:13,240
Speaker 5:  bars that need to cross.

777
00:43:14,230 --> 00:43:17,670
Speaker 3:  There are a lot of Chromecast fans in the comments of this piece by the way.

778
00:43:17,670 --> 00:43:18,310
Speaker 3:  They were like,

779
00:43:18,510 --> 00:43:19,310
Speaker 4:  Whatever. Oh, there,

780
00:43:19,310 --> 00:43:22,910
Speaker 5:  Yeah, it's not, it's not nearly as cheap. It doesn't work nearly as well.

781
00:43:23,180 --> 00:43:26,870
Speaker 5:  Yeah. You know, like now you get HDR and 4K and all these other things if

782
00:43:26,870 --> 00:43:30,670
Speaker 5:  you want them, but it's not as easy to use. I'm trying to watch an

783
00:43:30,760 --> 00:43:34,630
Speaker 5:  F1 clip like casted to my TV and suddenly the volume just

784
00:43:34,900 --> 00:43:38,790
Speaker 5:  starts going to maximum because my phone is at maximum. And, and

785
00:43:38,790 --> 00:43:42,630
Speaker 5:  I'm like, why would anyone want this? This experience? This should not be

786
00:43:42,630 --> 00:43:44,550
Speaker 5:  like this. Why, why, why am I having these problems?

787
00:43:44,550 --> 00:43:48,470
Speaker 3:  You want to feel the, the beat of the engine thrumming

788
00:43:48,470 --> 00:43:48,750
Speaker 3:  through

789
00:43:48,750 --> 00:43:52,390
Speaker 5:  Your body, not want to wake my wife up at 2:00 AM with the sounds of of

790
00:43:52,600 --> 00:43:53,470
Speaker 5:  F1 engine, but

791
00:43:53,470 --> 00:43:55,390
Speaker 3:  You're like, honey, listen to this engine.

792
00:43:55,390 --> 00:43:56,510
Speaker 5:  It'll be the last time

793
00:43:57,030 --> 00:44:00,790
Speaker 4:  While I was sitting there complaining about set boxes being bad, Anna,

794
00:44:00,800 --> 00:44:04,270
Speaker 4:  my wife just kept saying, I don't care about any of the rest of this. Just

795
00:44:04,270 --> 00:44:07,710
Speaker 4:  why aren't all the apps the same volume? Like I turn on my smart TV

796
00:44:08,050 --> 00:44:11,910
Speaker 4:  and I have to put it, I put it to 25 for Netflix, 35

797
00:44:11,910 --> 00:44:15,710
Speaker 4:  for Peacock, 45 for HBO O. And then I go back to

798
00:44:15,710 --> 00:44:18,990
Speaker 4:  Netflix and it blows my ears out and wakes up my child. And it's like, this

799
00:44:18,990 --> 00:44:22,110
Speaker 4:  is the simplest thing that this hardware could do is just make everything

800
00:44:22,110 --> 00:44:25,950
Speaker 4:  the same volume. But it can't because it's not allowed to. Because the streaming

801
00:44:25,950 --> 00:44:29,070
Speaker 4:  services won't allow the set type the box makers to do anything.

802
00:44:29,370 --> 00:44:33,280
Speaker 1:  Did you notice that Peacock also doesn't, hasn't fixed the,

803
00:44:33,280 --> 00:44:36,440
Speaker 1:  the difference between audio and commercials versus Oh it's horrible. Yeah.

804
00:44:36,440 --> 00:44:39,680
Speaker 1:  Regular things like this is the number one thing people always hated. It

805
00:44:39,680 --> 00:44:43,560
Speaker 1:  was a great thing that Soundbar tried to solve and somehow the soundbar could

806
00:44:43,560 --> 00:44:46,960
Speaker 1:  not solve it on Peacock because peacock's like, no, we want you to have this.

807
00:44:46,960 --> 00:44:50,840
Speaker 1:  Like it's, and it's always like condom commercials is all I

808
00:44:50,840 --> 00:44:53,920
Speaker 1:  get on Peacock and it's just like, wow. And I'm like, well

809
00:44:53,920 --> 00:44:57,120
Speaker 3:  This is the connected TV ecosystem has found you Alex,

810
00:44:57,650 --> 00:44:59,920
Speaker 1:  It has failed profoundly.

811
00:44:59,920 --> 00:45:01,840
Speaker 3:  Mark Zuckerberg's listening to you my friend,

812
00:45:03,030 --> 00:45:06,800
Speaker 1:  I was just like, what is happening? Because it's so loud and it's like, do

813
00:45:06,800 --> 00:45:10,480
Speaker 1:  you need condoms? I'm like, no, I, I'm good. Thanks

814
00:45:11,570 --> 00:45:12,280
Speaker 1:  my God.

815
00:45:13,860 --> 00:45:16,990
Speaker 1:  Very, very loudly. And then back to poker face soft whisper.

816
00:45:17,660 --> 00:45:21,390
Speaker 3:  Yeah, great. I like TV that it's a conversation you're having with your tv.

817
00:45:21,390 --> 00:45:22,510
Speaker 3:  You're like, no thank you

818
00:45:22,510 --> 00:45:24,070
Speaker 1:  Because I'm sitting in my house like, nope.

819
00:45:24,840 --> 00:45:28,390
Speaker 3:  So what's fascinating about this is Apple in particular,

820
00:45:29,620 --> 00:45:33,470
Speaker 3:  Everywhere else in its ecosystems has absolute

821
00:45:33,470 --> 00:45:37,270
Speaker 3:  control over its developers. Like the idea that iPhone

822
00:45:37,270 --> 00:45:41,110
Speaker 3:  apps would be this wildly inconsistent or not participate in universal search

823
00:45:41,110 --> 00:45:44,470
Speaker 3:  or whatever. Apple would write the rule, people would complain.

824
00:45:45,230 --> 00:45:48,790
Speaker 3:  European bureaucrats would issue a directive. The whole there, you, you everyone

825
00:45:48,790 --> 00:45:52,030
Speaker 3:  knows the exact cycle I'm talking about if you're a chest listener, right?

826
00:45:52,100 --> 00:45:55,990
Speaker 3:  Yeah. We would do a whole episode about it. It would be a thing on

827
00:45:55,990 --> 00:45:59,830
Speaker 3:  the TV side, apple does not have the market share to exercise the

828
00:45:59,830 --> 00:46:03,790
Speaker 3:  control. And they have a lot of fans and people really like it. But apps

829
00:46:03,790 --> 00:46:07,670
Speaker 3:  launch, they launch without support for apples. They sometimes,

830
00:46:07,670 --> 00:46:11,190
Speaker 3:  they don't even launch on the Apple TV right away. They launch without support

831
00:46:11,190 --> 00:46:14,470
Speaker 3:  for features. They launched Features light. I'm specifically thinking about

832
00:46:14,470 --> 00:46:18,350
Speaker 3:  YouTube TV launching 5.1 surround just way after it came

833
00:46:18,350 --> 00:46:21,910
Speaker 3:  to other platforms. And then the apps themselves are still kind of just like

834
00:46:21,980 --> 00:46:25,710
Speaker 3:  HTML five wrappers because there's so many TV platforms

835
00:46:25,900 --> 00:46:29,870
Speaker 3:  that the streaming vendors have just been like, screw it, they're all

836
00:46:29,870 --> 00:46:33,790
Speaker 3:  web apps. Here's the web app package for ties in. Here's the

837
00:46:33,790 --> 00:46:37,710
Speaker 3:  web app package for whatever LG is running Web Os on and on go.

838
00:46:37,710 --> 00:46:41,110
Speaker 4:  Not only are they doing that, it's, they're also on this incredible

839
00:46:41,300 --> 00:46:44,790
Speaker 4:  race to the technological bottom because now that there are all these incredibly

840
00:46:44,790 --> 00:46:48,110
Speaker 4:  cheap smart TVs, you have to build that app in such a way that not only does

841
00:46:48,110 --> 00:46:52,030
Speaker 4:  it work across all these platforms, it works on this unbelievably cheap

842
00:46:52,410 --> 00:46:56,350
Speaker 4:  low end plat processor inside of like a shitty TCL

843
00:46:56,360 --> 00:47:00,070
Speaker 4:  tv. And so you're in this position where you, you are actually

844
00:47:00,070 --> 00:47:04,030
Speaker 4:  incentivized against building something that works because it would break

845
00:47:04,030 --> 00:47:06,910
Speaker 4:  most of the time. Yeah. Like even if you built a really good app for the

846
00:47:06,910 --> 00:47:10,270
Speaker 4:  Apple tv, it would then not work most other places. So of course you're gonna

847
00:47:10,270 --> 00:47:12,950
Speaker 4:  build the lowest common denominator, which is what everybody has started

848
00:47:12,950 --> 00:47:13,190
Speaker 4:  doing.

849
00:47:13,880 --> 00:47:17,830
Speaker 3:  So one of the interesting responses I saw to your piece, David, were

850
00:47:17,830 --> 00:47:21,350
Speaker 3:  the people who said, this is why I've started buying channels inside of Apple

851
00:47:21,350 --> 00:47:25,110
Speaker 3:  TV and inside of YouTube TV and inside of Amazon. Yep.

852
00:47:25,110 --> 00:47:27,710
Speaker 3:  Right? They're like, I don't wanna use a Showtime app. I just bought Showtime

853
00:47:27,710 --> 00:47:31,360
Speaker 3:  inside of YouTube TV or wherever. And that gets me closer

854
00:47:31,370 --> 00:47:35,200
Speaker 3:  to a single interface. We've seen A lot of these companies are starting

855
00:47:35,200 --> 00:47:39,080
Speaker 3:  to think about their products as bundles. Apple does it, Amazon does it,

856
00:47:39,080 --> 00:47:43,040
Speaker 3:  YouTube does it. H b o Max is gonna turn into some something.

857
00:47:43,050 --> 00:47:45,720
Speaker 3:  They're just gonna call it Max. And that's gonna be a horrible day for me.

858
00:47:46,000 --> 00:47:46,480
Speaker 3:  ESPN

859
00:47:46,480 --> 00:47:49,920
Speaker 5:  Has said that it's going to perhaps, or there's been a rumor that s ESPN

860
00:47:49,920 --> 00:47:53,680
Speaker 5:  might allow other sports sports channels to plug into it

861
00:47:53,680 --> 00:47:55,680
Speaker 5:  so that it could become a hub for your sports streaming.

862
00:47:55,680 --> 00:47:59,520
Speaker 1:  That's Plexus big play right now. Every, every couple of

863
00:47:59,520 --> 00:48:03,200
Speaker 1:  years. Plex doesn't new, is that Plexus big play? No, that has become

864
00:48:03,640 --> 00:48:06,960
Speaker 1:  Plexus big play is they said, we wanna be your central hub. So we've found

865
00:48:06,960 --> 00:48:10,840
Speaker 1:  these weird, horrible hacks that are not actually very user

866
00:48:11,080 --> 00:48:14,960
Speaker 1:  friendly to, to let all of the apps work inside

867
00:48:14,960 --> 00:48:18,840
Speaker 1:  our platform because we recognize that everything sucks. And like Apple

868
00:48:18,840 --> 00:48:22,800
Speaker 1:  did that with the TV app, the terribly, terribly named TV

869
00:48:22,820 --> 00:48:26,800
Speaker 1:  app. They try to do that. But again, everybody gets bodied because Netflix

870
00:48:26,800 --> 00:48:30,760
Speaker 1:  or some other big player doesn't wanna listen to him and nobody has

871
00:48:30,760 --> 00:48:32,400
Speaker 1:  the market share to force.

872
00:48:32,530 --> 00:48:36,480
Speaker 3:  Several years ago the Verges office was in Midtown New York and we want to

873
00:48:36,480 --> 00:48:39,840
Speaker 3:  go out after work or a drink or a snack

874
00:48:40,140 --> 00:48:43,120
Speaker 3:  mid. You haven't been to Midtown New York. It's kind of like a weird ghost

875
00:48:43,120 --> 00:48:45,840
Speaker 3:  town. We used to walk into this restaurant, it was a couple blocks away.

876
00:48:46,390 --> 00:48:50,380
Speaker 3:  It was really nice. It looked expensive. There was never anyone in

877
00:48:50,380 --> 00:48:54,180
Speaker 3:  there, ever. Zero people were ever in this

878
00:48:54,180 --> 00:48:58,020
Speaker 3:  restaurant. And like 400 people worked there. That restaurant was a front

879
00:48:58,020 --> 00:49:01,980
Speaker 3:  for the mob. And in this metaphor, that restaurant is

880
00:49:02,140 --> 00:49:02,340
Speaker 3:  Plex.

881
00:49:06,460 --> 00:49:07,020
Speaker 3:  Speak

882
00:49:07,020 --> 00:49:07,660
Speaker 4:  To that Eli.

883
00:49:07,900 --> 00:49:11,740
Speaker 3:  Just put that out there. That's fine man. You can, you can

884
00:49:11,740 --> 00:49:14,700
Speaker 3:  tell me you're doing all kinds of shit, but

885
00:49:15,100 --> 00:49:17,660
Speaker 3:  everybody knows what's happening in the back of that restaurant.

886
00:49:19,370 --> 00:49:23,060
Speaker 1:  It's fast TV back there. That's what they got going on. It's free

887
00:49:23,060 --> 00:49:24,140
Speaker 1:  supported tv.

888
00:49:25,490 --> 00:49:25,980
Speaker 3:  Yeah.

889
00:49:26,240 --> 00:49:27,140
Speaker 1:  The only way to watch

890
00:49:29,150 --> 00:49:30,340
Speaker 3:  No customers.

891
00:49:31,970 --> 00:49:35,700
Speaker 3:  Very odd, very odd situation. Actually. The TV

892
00:49:35,880 --> 00:49:39,700
Speaker 3:  and Apple is like a perfect example of this, right? They wanted it.

893
00:49:39,920 --> 00:49:43,540
Speaker 3:  You can see what it would be if it worked, but no one will play ball.

894
00:49:43,630 --> 00:49:46,100
Speaker 3:  So it barely works. And it's not the home screen of the product.

895
00:49:46,920 --> 00:49:50,660
Speaker 4:  Yeah, it's, this is the thing is it's not, it's not like, it's not

896
00:49:50,660 --> 00:49:54,020
Speaker 4:  obvious how to do this better, right? Like there's a, there's a big long

897
00:49:54,020 --> 00:49:57,900
Speaker 4:  vision of like the TV as the center of your home

898
00:49:57,910 --> 00:50:00,660
Speaker 4:  in a lot of really interesting ways that are actually really complicated.

899
00:50:00,660 --> 00:50:04,460
Speaker 4:  And multi-user technology is like a thing we actually really have not solved

900
00:50:04,460 --> 00:50:08,260
Speaker 4:  yet. So whatever, we can talk about that later. But the simple thing is like,

901
00:50:08,260 --> 00:50:12,140
Speaker 4:  just make it easier for me to watch things on my TV and

902
00:50:12,140 --> 00:50:15,420
Speaker 4:  everybody knows how that would work. And there's been just enough players

903
00:50:15,420 --> 00:50:18,860
Speaker 4:  who have refused that it's been easier for everybody else to refuse and it

904
00:50:18,860 --> 00:50:21,980
Speaker 4:  has just collapsed. Like it's not unclear what Apple would like to do. It

905
00:50:21,980 --> 00:50:22,820
Speaker 4:  just can't do it.

906
00:50:23,650 --> 00:50:25,870
Speaker 1:  You know, it's gonna fix this, you know

907
00:50:25,870 --> 00:50:28,960
Speaker 4:  It's gonna fix You say Plex, I'm gonna, I'm gonna leave. No, I'm going back

908
00:50:28,960 --> 00:50:30,280
Speaker 4:  on parental leave. If you say Plex

909
00:50:31,190 --> 00:50:32,680
Speaker 1:  ATSC 3.00

910
00:50:32,680 --> 00:50:32,920
Speaker 4:  God,

911
00:50:32,950 --> 00:50:35,280
Speaker 3:  Yeah, that's

912
00:50:35,280 --> 00:50:35,440
Speaker 4:  Even

913
00:50:35,440 --> 00:50:39,200
Speaker 3:  Worse. Nothing like 600 ultra complex channels of

914
00:50:39,200 --> 00:50:42,800
Speaker 3:  infomercials beamed directly to you from your local CBS affiliate

915
00:50:43,330 --> 00:50:44,760
Speaker 1:  In 4k. In

916
00:50:45,200 --> 00:50:48,920
Speaker 4:  We're like one scissor vodka joke away from me filling my V Bingo

917
00:50:48,920 --> 00:50:50,680
Speaker 4:  card on my first day back. This is very

918
00:50:50,840 --> 00:50:53,680
Speaker 3:  Exciting. It's gonna be great. All right. That's streaming. Streaming music,

919
00:50:53,680 --> 00:50:57,640
Speaker 3:  streaming tv, the business models, the money is preventing

920
00:50:57,640 --> 00:51:00,280
Speaker 3:  good user experiences, I think is what we're, yep. What we're getting at

921
00:51:00,280 --> 00:51:03,640
Speaker 3:  here, this brings me to Twitter we're the money is preventing a good user

922
00:51:03,640 --> 00:51:07,480
Speaker 3:  experience in a different way in that all of the people have been

923
00:51:07,480 --> 00:51:11,120
Speaker 3:  fired and so the site keeps crashing. I don't know if there's much more to

924
00:51:11,120 --> 00:51:14,400
Speaker 3:  say, but there's just a lot going on with Twitter, but it's all kind of the

925
00:51:14,400 --> 00:51:18,280
Speaker 3:  same story, which is Elon fired everybody and now all the people

926
00:51:18,280 --> 00:51:21,440
Speaker 3:  who know what they're doing Yep. Are gone. And so

927
00:51:22,400 --> 00:51:25,800
Speaker 3:  Zoe and Casey at Australian platform are, it's on the site

928
00:51:26,480 --> 00:51:29,840
Speaker 3:  basically. They tried to make an API change, brought down the whole site

929
00:51:29,840 --> 00:51:31,320
Speaker 3:  for a several hours

930
00:51:31,320 --> 00:51:35,160
Speaker 1:  Because it was just one guy or one person, there was just one engineer on

931
00:51:35,160 --> 00:51:37,120
Speaker 1:  the project and they broke it and we're like, whoop.

932
00:51:38,740 --> 00:51:42,160
Speaker 3:  And Elon did some tweets about how everything is brittle. That resulted in

933
00:51:42,160 --> 00:51:44,920
Speaker 3:  a lot of software. People being like, the reality of all software is that

934
00:51:44,920 --> 00:51:48,680
Speaker 3:  it's brittle and it, the solution to that is knowing people, knowing what

935
00:51:48,680 --> 00:51:49,040
Speaker 3:  they're doing.

936
00:51:49,150 --> 00:51:52,680
Speaker 4:  I was interviewing somebody a couple of years ago for a, a totally unrelated

937
00:51:52,680 --> 00:51:55,640
Speaker 4:  story and they like paused me at the end of our interview. I did the, like,

938
00:51:55,640 --> 00:51:57,560
Speaker 4:  is there anything I should have asked you? Like what else are you thinking

939
00:51:57,560 --> 00:52:00,840
Speaker 4:  about? Question, which is a good one for reporters to do. And he like looks

940
00:52:00,840 --> 00:52:04,120
Speaker 4:  at me dead in the face and he goes, you need to report on tech debt more

941
00:52:04,120 --> 00:52:07,720
Speaker 4:  because tech debt is the underlying most important story

942
00:52:07,930 --> 00:52:11,480
Speaker 4:  of why everything is broken all the time. Yeah. And like my response was,

943
00:52:11,710 --> 00:52:15,560
Speaker 4:  I, I'm sure you're right. That is a just staggeringly boring story,

944
00:52:15,560 --> 00:52:19,520
Speaker 4:  but this is that, right? Like it's, it's just this, this service has been

945
00:52:19,520 --> 00:52:23,080
Speaker 4:  around for almost 20 years. There is tech debt everywhere

946
00:52:23,300 --> 00:52:26,680
Speaker 4:  and that just is what it is. You can't rewrite the thing from scratch, which

947
00:52:26,680 --> 00:52:29,480
Speaker 4:  is now what Elon is promising to do, which I find deeply hilarious.

948
00:52:30,530 --> 00:52:34,200
Speaker 3:  He also promised to open source the algorithm. He also promised creator,

949
00:52:34,350 --> 00:52:38,320
Speaker 4:  I said promising. This is my point, this that's just as likely as rereading

950
00:52:38,320 --> 00:52:41,640
Speaker 4:  the Twitter code from scratch. Right? Like you just, you can't do it. And

951
00:52:41,640 --> 00:52:44,440
Speaker 4:  this is why at some point you have to employ people who know what they're

952
00:52:44,440 --> 00:52:48,000
Speaker 4:  doing in order to keep making the service that you make work.

953
00:52:48,630 --> 00:52:52,360
Speaker 5:  That's one approach. But Netflix got a lot of mileage a few years ago because

954
00:52:52,360 --> 00:52:56,000
Speaker 5:  they had this technology they called Chaos Monkey where it would test the

955
00:52:56,000 --> 00:52:58,880
Speaker 5:  resilience of their platform. Cause it would go around and like shut stuff,

956
00:52:58,880 --> 00:53:02,280
Speaker 5:  shut stuff off at random and see if it still worked. And that was supposedly

957
00:53:02,280 --> 00:53:06,080
Speaker 5:  how Netflix would keep working mostly everywhere all the time. And now Twitter

958
00:53:06,080 --> 00:53:09,840
Speaker 5:  has a chaos monkey. Yeah. Named Elon Musk. And

959
00:53:10,490 --> 00:53:14,360
Speaker 5:  he is stress testing the app. And when we get through this, it'll be

960
00:53:14,360 --> 00:53:18,120
Speaker 5:  fine. Eventually they'll find every single hole.

961
00:53:18,120 --> 00:53:19,960
Speaker 5:  It's just gonna take probably the rest of our lives.

962
00:53:19,960 --> 00:53:22,800
Speaker 1:  If all the people he fired don't sue it into oblivion.

963
00:53:22,800 --> 00:53:24,280
Speaker 4:  Richard, you've changed since I left

964
00:53:24,600 --> 00:53:28,520
Speaker 3:  Big crypto, crypto, big Elon guy. So there's one piece of the

965
00:53:28,520 --> 00:53:31,160
Speaker 3:  Twitter story we should talk about on the show. We did not write about it

966
00:53:31,160 --> 00:53:35,000
Speaker 3:  on the site cuz the story is so weird and so many of

967
00:53:35,000 --> 00:53:38,560
Speaker 3:  the details are actually quite hard to confirm and have not been confirmed.

968
00:53:38,690 --> 00:53:42,280
Speaker 3:  So say what the story is first and then just talk about why we didn't do,

969
00:53:42,280 --> 00:53:43,280
Speaker 3:  because it's unpleasant.

970
00:53:43,440 --> 00:53:44,080
Speaker 1:  It's just too,

971
00:53:44,290 --> 00:53:48,080
Speaker 3:  So there's a Twitter designer named Harold

972
00:53:48,080 --> 00:53:52,040
Speaker 3:  Dur. Thorleif goes by Holly on Twitter, Holly tweets,

973
00:53:52,070 --> 00:53:55,880
Speaker 3:  Elon, Hey, my laptop got shut off several days ago. I don't know if I'm fired.

974
00:53:55,880 --> 00:53:59,240
Speaker 3:  Am I fired? No one will respond to be Maybe if we tweeted Elon enough. Elon

975
00:53:59,570 --> 00:54:03,400
Speaker 3:  is just incredibly rude. Yeah's, no way to put it.

976
00:54:03,400 --> 00:54:04,520
Speaker 3:  He's just rude. He's like, what?

977
00:54:04,610 --> 00:54:08,040
Speaker 1:  He responds with like, what do you do here? Just tell me right away. Like

978
00:54:08,040 --> 00:54:11,840
Speaker 1:  without any, any kind of politeness, any, let's take this to dms. Let's,

979
00:54:11,840 --> 00:54:15,680
Speaker 1:  let's email this out. He's just like, what do you do here? And then the guy

980
00:54:15,680 --> 00:54:19,280
Speaker 1:  is like, well I can't tell you because that'll break my confidentiality agreement.

981
00:54:19,620 --> 00:54:20,040
Speaker 1:  And

982
00:54:20,280 --> 00:54:23,960
Speaker 3:  Which by the way, watching this as a distance Yeah. You're like, that's oh

983
00:54:23,960 --> 00:54:24,520
Speaker 3:  that's trap.

984
00:54:25,480 --> 00:54:29,040
Speaker 1:  And and and Elon is like, fine, break it. Tell me everything.

985
00:54:29,140 --> 00:54:32,920
Speaker 1:  And so the guy tells him some stuff. Elon laughs at him because he is like,

986
00:54:32,920 --> 00:54:34,680
Speaker 1:  I worked on like a Figma project,

987
00:54:34,800 --> 00:54:38,040
Speaker 3:  Right? He's, he's like, one of the things he did was he negotiated a price

988
00:54:38,040 --> 00:54:41,800
Speaker 3:  of a software as a service product down by 500 K. And he is like, which thing?

989
00:54:41,800 --> 00:54:44,680
Speaker 3:  And he is like, Figma. And I don't think Elon knew what Figma was.

990
00:54:44,760 --> 00:54:48,520
Speaker 1:  Elon just laughed because presumably he didn't know what it was and

991
00:54:48,520 --> 00:54:51,760
Speaker 1:  didn't realize that it's like hugely important for software designers to

992
00:54:51,760 --> 00:54:55,560
Speaker 1:  figure out what this software's gonna actually look like. So he just kind

993
00:54:55,560 --> 00:54:59,400
Speaker 1:  of roasts the guy and then he continues to roast the guy the next

994
00:54:59,400 --> 00:55:03,320
Speaker 1:  day to other people who are like, Elon, you're being kind of a dick. And

995
00:55:03,320 --> 00:55:06,480
Speaker 1:  Elon's like, yeah, but the guy didn't even do anything here. He said he had

996
00:55:06,480 --> 00:55:09,680
Speaker 1:  some sort of like issues so he couldn't even type. So what's even the point

997
00:55:09,680 --> 00:55:13,440
Speaker 1:  of this guy? And it's like, well, oh, because Halle was, is

998
00:55:13,640 --> 00:55:17,600
Speaker 1:  actually like a pretty noted disability activist in Iceland who's building

999
00:55:17,600 --> 00:55:21,560
Speaker 1:  a bunch of wheelchair ramps and had also like

1000
00:55:21,560 --> 00:55:25,280
Speaker 1:  then explained in a Twitter thread how he had muscular dystrophy, how he

1001
00:55:25,280 --> 00:55:29,240
Speaker 1:  had a wife and he slept in a big bed with, with his wife. Unlike Elon,

1002
00:55:29,260 --> 00:55:33,200
Speaker 1:  how he saw his children every day unlike Elon. And just

1003
00:55:33,200 --> 00:55:33,720
Speaker 1:  like brutal,

1004
00:55:33,750 --> 00:55:34,240
Speaker 3:  Just

1005
00:55:34,240 --> 00:55:38,160
Speaker 1:  Brutally goes after Elon while explaining like how every single

1006
00:55:38,160 --> 00:55:41,920
Speaker 1:  way that Elon is wrong. And then Elon apparently realized

1007
00:55:41,920 --> 00:55:45,840
Speaker 1:  that he had fired someone for disability reasons and then tweeted that

1008
00:55:45,840 --> 00:55:49,680
Speaker 1:  he had fired someone for disabilities and that's a good way to lose

1009
00:55:49,680 --> 00:55:53,600
Speaker 1:  your company or at least a lot of money. And then said,

1010
00:55:53,600 --> 00:55:56,120
Speaker 1:  okay, we're gonna work it all out on the back end. And then there was also

1011
00:55:56,120 --> 00:55:59,280
Speaker 1:  this whole thing where a lot of people were saying, well, Halle was actually

1012
00:55:59,280 --> 00:56:03,240
Speaker 1:  would be owed a hundred million if he was fired.

1013
00:56:03,580 --> 00:56:07,520
Speaker 1:  But that's really difficult to confirm. So there's just a lot

1014
00:56:07,520 --> 00:56:10,600
Speaker 1:  like it was just a messy, messy HR dispute

1015
00:56:10,800 --> 00:56:14,690
Speaker 1:  happening in real time on Twitter and we all had

1016
00:56:14,690 --> 00:56:16,770
Speaker 1:  to watch it and that was just kind of gross.

1017
00:56:17,280 --> 00:56:21,210
Speaker 3:  Yeah, it was gross. So Elon tweets, he did know actual

1018
00:56:21,210 --> 00:56:24,080
Speaker 3:  work. He claimed as an excuse. He had a disability that prevented him from

1019
00:56:24,080 --> 00:56:27,960
Speaker 3:  typing. There's a response where he is like muscular dystrophy. I will say

1020
00:56:27,960 --> 00:56:31,480
Speaker 3:  that the sort of like Elon take ecosystem went

1021
00:56:31,690 --> 00:56:35,680
Speaker 3:  bananas around all of this. And the world of people who were

1022
00:56:35,680 --> 00:56:39,120
Speaker 3:  like, he got him, he set a trap now he owes him the money, he got fired.

1023
00:56:39,120 --> 00:56:42,880
Speaker 3:  First of all, the guy's in Iceland, we don't know what

1024
00:56:42,880 --> 00:56:46,840
Speaker 3:  law his contract is under. We just dunno how he is employed. So we don't

1025
00:56:46,840 --> 00:56:49,680
Speaker 3:  even know what law controls here. Two, there is this thing with a hundred

1026
00:56:49,680 --> 00:56:53,240
Speaker 3:  million dollars is a founder. There's a lot of

1027
00:56:53,240 --> 00:56:57,200
Speaker 3:  reporting that we have that Alex Heath has that Casey and Zoe have at Platformer.

1028
00:56:57,310 --> 00:57:01,040
Speaker 3:  That when Twitter acquired founders, they're shares vested

1029
00:57:01,040 --> 00:57:04,920
Speaker 3:  faster. They were owed more money. So they had had founders on

1030
00:57:04,920 --> 00:57:08,560
Speaker 3:  do not fire lists because it would cost them so much money to fi to fire

1031
00:57:08,560 --> 00:57:11,080
Speaker 3:  them on these accelerated investing schedules. But we don't know how that

1032
00:57:11,080 --> 00:57:14,920
Speaker 3:  applies to this guy. Then this guy's also Iceland's man of

1033
00:57:14,920 --> 00:57:18,720
Speaker 3:  the year. It's a real thing because of his work as a

1034
00:57:18,720 --> 00:57:22,480
Speaker 3:  disability activist building the ramps. But most importantly, he did not

1035
00:57:22,760 --> 00:57:26,640
Speaker 3:  sell his company for stock. He very famously sold it

1036
00:57:26,640 --> 00:57:30,200
Speaker 3:  for cash. So he would pay more taxes because he credits

1037
00:57:30,200 --> 00:57:34,040
Speaker 3:  Iceland's social services for allowing him to live, work and thrive with

1038
00:57:34,040 --> 00:57:37,400
Speaker 3:  his disability. That's like the wrong person to fight. Yes. And

1039
00:57:37,400 --> 00:57:38,640
Speaker 1:  To fight publicly on Twitter.

1040
00:57:38,870 --> 00:57:42,600
Speaker 3:  What I'm just getting at is the, the story

1041
00:57:42,600 --> 00:57:46,160
Speaker 3:  right, that he got baited Elon would owe him a hundred million dollars.

1042
00:57:46,410 --> 00:57:50,040
Speaker 3:  We actually can't confirm like 50 of the

1043
00:57:50,040 --> 00:57:53,680
Speaker 3:  dots in between. Boy, that was a real

1044
00:57:53,680 --> 00:57:57,600
Speaker 3:  jerk interaction and Elon publicly apologized and

1045
00:57:57,600 --> 00:58:01,400
Speaker 3:  said he'd FaceTimed the guy or the head of video call and everything is

1046
00:58:01,400 --> 00:58:05,040
Speaker 3:  resolved. The guy's considering saying right and no one's talking. So I just

1047
00:58:05,040 --> 00:58:08,320
Speaker 3:  like, I just wanna say this is like kind of why we A, it was gross. It seemed

1048
00:58:08,320 --> 00:58:11,640
Speaker 3:  petty and gross and small and sort of, it's just more of the same, right?

1049
00:58:11,640 --> 00:58:15,520
Speaker 3:  It's just like Elon's playing the hits of like doing his business like a

1050
00:58:15,520 --> 00:58:18,880
Speaker 3:  jerk on Twitter and then b in the middle is just like a

1051
00:58:19,270 --> 00:58:23,080
Speaker 3:  what feels like an unconfirmed, unconfirmed

1052
00:58:23,720 --> 00:58:27,400
Speaker 3:  story that to do it responsibly have to report out. And I think

1053
00:58:27,400 --> 00:58:30,280
Speaker 3:  that's just really telling. Like I think the Twitter story is still really

1054
00:58:30,280 --> 00:58:34,160
Speaker 3:  important. I think what happens to this social network that is the architecture

1055
00:58:34,170 --> 00:58:37,960
Speaker 3:  of lots of things, like this whole podcast is about Aaron Rods in the New York

1056
00:58:37,960 --> 00:58:40,280
Speaker 3:  chats right now, I'm just telling you like, it's on the back of my mind every

1057
00:58:40,280 --> 00:58:43,600
Speaker 3:  second of every day. And it's all just playing out on Twitter, right? It's

1058
00:58:43,600 --> 00:58:46,560
Speaker 3:  just like the architecture of sports media is still on Twitter. The architecture

1059
00:58:46,570 --> 00:58:50,360
Speaker 3:  of politics is still on Twitter. So what happens Twitter is important. It

1060
00:58:50,360 --> 00:58:54,240
Speaker 3:  just, right now every day is like these little explosions

1061
00:58:54,240 --> 00:58:57,840
Speaker 3:  of chaos that kind of don't mean as much as they should mean

1062
00:58:58,210 --> 00:59:00,560
Speaker 3:  or don't mean as much as people want them to me. Yeah.

1063
00:59:00,730 --> 00:59:03,760
Speaker 4:  My relationship with Twitter has changed so much the last few months. Like

1064
00:59:03,760 --> 00:59:07,680
Speaker 4:  I, I just bailed on Twitter and I have to say I have been shocked by

1065
00:59:07,680 --> 00:59:11,560
Speaker 4:  how little I have missed, like the, the thing that felt truist to

1066
00:59:11,560 --> 00:59:15,080
Speaker 4:  me of everything that happened the last few months was that thing where Elon

1067
00:59:15,080 --> 00:59:18,840
Speaker 4:  forced the engineers to juice his own metrics because it

1068
00:59:18,840 --> 00:59:21,960
Speaker 4:  just, everywhere, every time I would open it up, my mentions were filled

1069
00:59:21,960 --> 00:59:25,840
Speaker 4:  with people tagging me in crypto scams and my timeline was just

1070
00:59:25,840 --> 00:59:29,320
Speaker 4:  Elon replying to people. And it's just like, what is this place now? And

1071
00:59:29,320 --> 00:59:32,800
Speaker 4:  I think there's a great piece on our site this week called How a Social Network

1072
00:59:32,800 --> 00:59:35,320
Speaker 4:  Falls Apart. That really rang true to me that way. Or was just like, the

1073
00:59:35,320 --> 00:59:39,120
Speaker 4:  place just feels worse now. Like forget the fact that it keeps

1074
00:59:39,510 --> 00:59:43,320
Speaker 4:  collapsing because nobody works there anymore and like it

1075
00:59:43,320 --> 00:59:47,280
Speaker 4:  is just not being run in a competent way as far as anybody can tell. It

1076
00:59:47,280 --> 00:59:50,680
Speaker 4:  just, it just feels bad to me. But it, there is still that thing where I

1077
00:59:50,680 --> 00:59:53,560
Speaker 4:  think people don't know where else to go and it's like Mastodon is not that

1078
00:59:53,560 --> 00:59:57,120
Speaker 4:  thing, at least not yet. And there's nowhere else. So it's like if you, if

1079
00:59:57,120 --> 01:00:00,840
Speaker 4:  you are one of those people who wants to know what's going on with

1080
01:00:00,840 --> 01:00:04,440
Speaker 4:  Aaron Rodgers and the Jets, a person of, of which I am not one,

1081
01:00:04,780 --> 01:00:08,120
Speaker 4:  but if, if you are one of those people, there's, there's just still nowhere

1082
01:00:08,120 --> 01:00:10,480
Speaker 4:  else to go. And that's one of the things that is the most surprising to me

1083
01:00:10,480 --> 01:00:14,280
Speaker 4:  is that it, it people feel stuck, I think in a realer way

1084
01:00:14,280 --> 01:00:14,960
Speaker 4:  every single day.

1085
01:00:15,070 --> 01:00:18,920
Speaker 3:  Yeah. But it's also like, no, there's a guy who

1086
01:00:18,920 --> 01:00:22,880
Speaker 3:  followed the Jets plane to California and then he like went

1087
01:00:22,880 --> 01:00:26,840
Speaker 3:  to the airport and like watched the Yeah. Twitter stuff. You know what

1088
01:00:26,840 --> 01:00:29,840
Speaker 3:  I'm talking about? It's like someone found the plane, they went and saw the

1089
01:00:29,840 --> 01:00:32,880
Speaker 3:  plane, they saw Aaron Rogers walking the plane. Yep. The only place that

1090
01:00:32,880 --> 01:00:36,200
Speaker 3:  happens is Twitter. Like there's no replacement for that specifically. Maybe

1091
01:00:36,200 --> 01:00:38,320
Speaker 3:  it'll happen a little bit on Reddit, four chan, but the

1092
01:00:39,910 --> 01:00:43,720
Speaker 3:  four chan, if sports media moves to four chan,

1093
01:00:43,720 --> 01:00:47,640
Speaker 3:  that will be wild. Get ready. But I, I just think like the

1094
01:00:47,640 --> 01:00:51,040
Speaker 3:  stuff in the background of Twitter is like, the experiment is how much can

1095
01:00:51,040 --> 01:00:54,240
Speaker 3:  you break it? How much can you make people feel bad and they still have to

1096
01:00:54,240 --> 01:00:57,000
Speaker 3:  use it. And that's always what Twitter, what Elon that's always the Elon

1097
01:00:57,000 --> 01:00:59,800
Speaker 3:  has a banking on right? Is people are addicted to Twitter and he can do anything

1098
01:01:00,060 --> 01:01:03,960
Speaker 3:  cuz the guy who's the most addicted to cigarettes bought the cigarette factory.

1099
01:01:04,300 --> 01:01:05,840
Speaker 3:  And we're just gonna see how it goes.

1100
01:01:05,840 --> 01:01:09,040
Speaker 5:  Well something that I've noticed is that people complain about Twitter and

1101
01:01:09,040 --> 01:01:12,840
Speaker 5:  we, we talk about Elon and his strategies and how, how he's working, but

1102
01:01:12,930 --> 01:01:16,120
Speaker 5:  he has been effective in one kind of particular way that I've noticed They

1103
01:01:16,120 --> 01:01:19,320
Speaker 5:  defaulted everyone to the the four u page to the algorithmic timeline. They

1104
01:01:19,320 --> 01:01:23,280
Speaker 5:  have both timelines. People use the algorithmic timeline a lot and

1105
01:01:23,280 --> 01:01:26,480
Speaker 5:  that is part of the reason why so many people saw, for example, this story

1106
01:01:26,480 --> 01:01:29,960
Speaker 5:  playing out. Because if you are on that one and you follow anyone involved

1107
01:01:29,960 --> 01:01:33,080
Speaker 5:  or anyone who is talking about it, it's going to be at the top of your feed.

1108
01:01:33,420 --> 01:01:37,280
Speaker 5:  And at least so far that bet has not been a, an incorrect

1109
01:01:37,280 --> 01:01:41,120
Speaker 5:  one for Elon in, for Twitter to put to kind of algorithmically juice

1110
01:01:41,310 --> 01:01:45,200
Speaker 5:  discontent and unhappiness, whatever, whatever that

1111
01:01:45,200 --> 01:01:48,400
Speaker 5:  does for people. I don't know. Yeah. But it has kept their attention and

1112
01:01:48,400 --> 01:01:51,600
Speaker 5:  something that, you know, if you're gonna remain on Twitter, I just, I I

1113
01:01:51,600 --> 01:01:55,520
Speaker 5:  beg people please don't use the algorithmic timeline. Turn off replies

1114
01:01:55,520 --> 01:01:59,040
Speaker 5:  from people who don't follow you. You don't need to see what they say and

1115
01:01:59,040 --> 01:02:02,000
Speaker 5:  turn off notifications for likes. You don't need to know whether or not people

1116
01:02:02,000 --> 01:02:02,800
Speaker 5:  agree with you.

1117
01:02:03,170 --> 01:02:06,380
Speaker 3:  That's true. Turn off most of the features of Twitter is good advice from

1118
01:02:06,380 --> 01:02:09,900
Speaker 3:  Richard. Also, if you see a bank run it at it as fast

1119
01:02:09,900 --> 01:02:10,900
Speaker 5:  As you can. What could go wrong?

1120
01:02:10,930 --> 01:02:14,820
Speaker 3:  Just dead Sprint. Do you know how 17 I drove a Mustang into the bank? That's

1121
01:02:14,820 --> 01:02:16,500
Speaker 3:  a real story. We're gonna take a break. We'll be right back.

1122
01:02:16,500 --> 01:02:17,500
Speaker 5:  Was it during a podcast?

1123
01:02:17,780 --> 01:02:21,760
Speaker 3:  We'll be right back. We got some policy stuff to talk about. It was

1124
01:02:21,760 --> 01:02:25,040
Speaker 3:  not during, that was a, technically if you drive a Mustang into a bank in

1125
01:02:25,040 --> 01:02:28,680
Speaker 3:  the nineties, that's a video podcast. We'll be right back.

1126
01:02:35,580 --> 01:02:39,360
Speaker 3:  All right, we're back a little bit of policy news and we gotta talk about

1127
01:02:39,360 --> 01:02:42,760
Speaker 3:  this dish story, which is criminally undercover. And we got some gadgets

1128
01:02:42,810 --> 01:02:43,640
Speaker 3:  to close this

1129
01:02:43,640 --> 01:02:45,720
Speaker 4:  Out. And weird, weird.

1130
01:02:45,870 --> 01:02:49,480
Speaker 3:  It's weird, it's real weird. Policy news. Congress

1131
01:02:49,480 --> 01:02:53,080
Speaker 3:  rolled out a bill that would allow the White House to ban TikTok

1132
01:02:53,080 --> 01:02:56,720
Speaker 3:  across the nation. Gotta say, it feels like the TikTok

1133
01:02:56,720 --> 01:03:00,640
Speaker 3:  ban is coming, right? Like yeah, everybody on both sides is like, what

1134
01:03:00,640 --> 01:03:04,280
Speaker 3:  if we get rid of TikTok and states across the country have

1135
01:03:04,280 --> 01:03:07,520
Speaker 3:  banned it in for their government devices. The federal government has banned

1136
01:03:07,520 --> 01:03:11,400
Speaker 3:  it for government devices. It's gotten weird out there and TikTok has done

1137
01:03:11,900 --> 01:03:15,280
Speaker 3:  approximately nothing to solve this problem from what I can tell.

1138
01:03:15,280 --> 01:03:19,160
Speaker 1:  Because they know they have teens. They know they have like a, an army

1139
01:03:19,250 --> 01:03:22,840
Speaker 1:  of teens for when this band goes down that they can just

1140
01:03:22,840 --> 01:03:23,800
Speaker 1:  point at the problem.

1141
01:03:24,070 --> 01:03:27,920
Speaker 4:  I mean, Eli, can I interest you in Project Texas, which I think if I

1142
01:03:27,920 --> 01:03:31,800
Speaker 4:  understand correctly, is a room where a person says TikTok is

1143
01:03:31,800 --> 01:03:32,720
Speaker 4:  great, trust us.

1144
01:03:32,890 --> 01:03:36,680
Speaker 3:  So they do have that project Texas, which the CEO of TikTok has talked about,

1145
01:03:36,680 --> 01:03:40,400
Speaker 3:  which TikTok has talked about. They have transparency centers.

1146
01:03:40,430 --> 01:03:44,120
Speaker 3:  Alex Heath went to one. The transparency centers are like

1147
01:03:44,360 --> 01:03:47,840
Speaker 3:  giant touchscreens where you can pretend to be a TikTok moderator.

1148
01:03:47,950 --> 01:03:51,120
Speaker 3:  It's very much like a children's museum for content moderation. I dunno how

1149
01:03:51,120 --> 01:03:51,920
Speaker 3:  else to describe it. Yes.

1150
01:03:51,920 --> 01:03:54,680
Speaker 4:  That's all I can think of. Anytime I hear somebody talk about, it's like

1151
01:03:54,680 --> 01:03:57,960
Speaker 4:  going to the museum and you touch it and it's like that's what gravity is.

1152
01:03:58,350 --> 01:04:00,120
Speaker 4:  This time it's content moderation.

1153
01:04:00,630 --> 01:04:04,080
Speaker 3:  It's like, like there's a part of me that's like, that's good. Like more

1154
01:04:04,080 --> 01:04:07,720
Speaker 3:  people should understand like how this works and how hard it is. On the other

1155
01:04:07,720 --> 01:04:10,640
Speaker 3:  hand, you're like, this is your answer to the government being like, yeah,

1156
01:04:10,720 --> 01:04:14,640
Speaker 3:  China is a threat, is a science museum for content moderation.

1157
01:04:14,640 --> 01:04:18,520
Speaker 3:  However, in that, in the transparency centers, there is a room full of

1158
01:04:18,520 --> 01:04:22,040
Speaker 3:  servers that Alex and Casey and Taylor, Laurens and everybody else who wanted

1159
01:04:22,040 --> 01:04:25,560
Speaker 3:  to, where these things were not allowed to go in were Oracle employees. You

1160
01:04:25,720 --> 01:04:29,640
Speaker 3:  remember Oracle is tied up in this, in some Byzantine way, are allowed to

1161
01:04:29,640 --> 01:04:33,280
Speaker 3:  review talk's, code, see all the data they're they're using

1162
01:04:33,300 --> 01:04:36,560
Speaker 3:  cuz they're in control of it. And then this is the one that I thought was

1163
01:04:36,560 --> 01:04:40,520
Speaker 3:  the funniest piece of this. All Oracle will submit the app

1164
01:04:40,650 --> 01:04:44,520
Speaker 3:  to Apple in the app store, which will solve all the problems.

1165
01:04:44,590 --> 01:04:47,360
Speaker 1:  Yeah. You just need some American capitalists

1166
01:04:47,990 --> 01:04:50,240
Speaker 1:  inserted into things and it's fine.

1167
01:04:50,430 --> 01:04:54,200
Speaker 3:  Well it's like you guys, you know the app on the phone like sends the data

1168
01:04:54,200 --> 01:04:58,120
Speaker 3:  to China. Yeah. It doesn't, it doesn't matter who delivers the

1169
01:04:58,120 --> 01:05:00,600
Speaker 3:  floppy to to the spaceship.

1170
01:05:01,890 --> 01:05:05,760
Speaker 3:  Problem is the, the network, you know, the internet.

1171
01:05:05,760 --> 01:05:09,560
Speaker 3:  It, it's a network that is interconnected. It's just like a very

1172
01:05:09,560 --> 01:05:12,200
Speaker 3:  funny piece of that whole puzzle. It's like, what if Oracle was in charge

1173
01:05:12,200 --> 01:05:15,320
Speaker 3:  of this app? It's like, yeah, what if the app was totally disconnected from

1174
01:05:15,320 --> 01:05:19,280
Speaker 3:  the Chinese government? I'm like, huh, that's challenging. So that's all

1175
01:05:19,280 --> 01:05:23,160
Speaker 3:  happening and like Texa is making a big show of it. We're covering it

1176
01:05:23,160 --> 01:05:26,600
Speaker 3:  obviously, but this act, the strict act is bipartisan

1177
01:05:26,900 --> 01:05:30,080
Speaker 3:  and it would allow the Secretary of Commerce to ban foreign technologies

1178
01:05:30,080 --> 01:05:33,160
Speaker 3:  and companies from operating the us They present a threat to national security.

1179
01:05:34,200 --> 01:05:38,120
Speaker 3:  So this whole thing, all these companies reacting to TikTok,

1180
01:05:38,200 --> 01:05:41,280
Speaker 3:  there might just be like a hole at the center of their strategy. Like you

1181
01:05:41,280 --> 01:05:43,040
Speaker 3:  wake up and you're like, what do we do now?

1182
01:05:44,630 --> 01:05:48,560
Speaker 4:  I mean, I do wonder if part of the bet from a

1183
01:05:48,560 --> 01:05:52,000
Speaker 4:  lot of these companies is that eventually TikTok is going to either be,

1184
01:05:52,180 --> 01:05:56,040
Speaker 4:  you know, hamstrung and sold or outright band and all of a

1185
01:05:56,240 --> 01:05:59,960
Speaker 4:  sudden there's gonna be this massive gold rush of trying

1186
01:05:59,970 --> 01:06:03,840
Speaker 4:  to be the next talkies thing for users in the

1187
01:06:03,840 --> 01:06:07,360
Speaker 4:  United States. And they're all just sitting there waiting for this moment

1188
01:06:07,360 --> 01:06:11,120
Speaker 4:  to happen. Which I i the part of this that's so strange to me is that

1189
01:06:11,120 --> 01:06:14,920
Speaker 4:  every individual move against this seems not

1190
01:06:14,920 --> 01:06:18,600
Speaker 4:  like specious, but it's it's also sort of theoretical, right? It's like,

1191
01:06:18,600 --> 01:06:21,720
Speaker 4:  it's very hard to prove that TikTok is being

1192
01:06:21,920 --> 01:06:25,680
Speaker 4:  nefarious in some way. You, you can talk about what the

1193
01:06:25,680 --> 01:06:29,600
Speaker 4:  Chinese government has access to. You can talk about the way the algorithms

1194
01:06:29,600 --> 01:06:33,000
Speaker 4:  are being tuned. There, there are all these things that sort of seem

1195
01:06:33,010 --> 01:06:36,680
Speaker 4:  sketchy but have proven very hard to prove. And then so you get all

1196
01:06:36,960 --> 01:06:40,880
Speaker 4:  these bills that say things like, we can do it if we want to,

1197
01:06:40,880 --> 01:06:44,120
Speaker 4:  if we're able to, but only if it's allowed. And they're like, wait, what?

1198
01:06:44,660 --> 01:06:48,360
Speaker 4:  And it just, we, we seem to just be sort of like circling this over and over,

1199
01:06:48,360 --> 01:06:52,200
Speaker 4:  but it, it does seem like we've gotten to a point where there's enough smoke

1200
01:06:52,200 --> 01:06:54,600
Speaker 4:  on this that it feels like there's gonna be fire.

1201
01:06:54,750 --> 01:06:58,640
Speaker 3:  Yeah. Or at least the attempt, right? Because they gotta prove that it's

1202
01:06:58,640 --> 01:07:01,040
Speaker 3:  a threat to national security. And TikTok has done all this project Texas

1203
01:07:01,040 --> 01:07:04,680
Speaker 3:  stuff, but it's out there. It's, it's in the background in a very serious

1204
01:07:04,680 --> 01:07:08,480
Speaker 3:  way that governments around the country are, you get to posture

1205
01:07:08,480 --> 01:07:12,320
Speaker 3:  against China for free. Yep. And you get to say that you're doing it for

1206
01:07:12,320 --> 01:07:15,280
Speaker 3:  the kids. Everyone's very worried about the teens at all times. Think of

1207
01:07:15,280 --> 01:07:18,400
Speaker 3:  the children. So that's one, two Wait, wait.

1208
01:07:18,710 --> 01:07:22,360
Speaker 4:  Move on. Can I just, can I just say one thing like, I just wanna give Congress

1209
01:07:22,360 --> 01:07:26,280
Speaker 4:  a lot of credit for the, the, the acronyms in these

1210
01:07:26,280 --> 01:07:29,520
Speaker 4:  names where like clearly somebody's like, we wanna call this the restrict

1211
01:07:29,520 --> 01:07:33,280
Speaker 4:  act but it has to stand for something. So the RESTRICT ACT stands for the

1212
01:07:33,280 --> 01:07:36,760
Speaker 4:  restricting the emergence of security threats that Risk Information and Communications

1213
01:07:36,760 --> 01:07:40,480
Speaker 4:  Technology Act or the Restrict Act. Yes. And I just think that's wonderful.

1214
01:07:40,540 --> 01:07:41,960
Speaker 4:  Congratulations to

1215
01:07:42,310 --> 01:07:45,680
Speaker 3:  Mark Warner and the rest that's a C, that's a b plus.

1216
01:07:46,210 --> 01:07:50,080
Speaker 3:  It best starting the restrict act with the word restrict completely ridiculous.

1217
01:07:50,790 --> 01:07:52,560
Speaker 3:  Like you just immediately lose points.

1218
01:07:52,790 --> 01:07:56,520
Speaker 4:  That's fair. That's fair. Can I interest you in the Data act? The

1219
01:07:56,520 --> 01:07:59,040
Speaker 4:  Deterring America's Technological Adversaries Act.

1220
01:08:02,570 --> 01:08:06,440
Speaker 3:  Alright, speaking of Congress, we'll we'll have more on

1221
01:08:06,440 --> 01:08:10,400
Speaker 3:  this very soon, but obviously we pay a lot of attention to the FCC

1222
01:08:10,400 --> 01:08:14,200
Speaker 3:  here because theoretically the FCC regulates the nation's

1223
01:08:14,200 --> 01:08:18,120
Speaker 3:  telecom providers. No one's doing a good job. Particularly the

1224
01:08:18,120 --> 01:08:21,800
Speaker 3:  Biden FCC has been deadlocked at two, two for a long time. Two

1225
01:08:21,800 --> 01:08:25,000
Speaker 3:  Republicans, two Democrats, they've accomplished nothing.

1226
01:08:25,310 --> 01:08:29,200
Speaker 3:  Just flat out nothing. The Trump FCC accomplished a lot. Most

1227
01:08:29,200 --> 01:08:31,560
Speaker 3:  of it was destructive, but they accomplished a lot. They're like, let's get

1228
01:08:31,560 --> 01:08:35,400
Speaker 3:  rid of net neutrality. Did it? What if the government

1229
01:08:35,400 --> 01:08:38,880
Speaker 3:  was run by Verizon? Like, did it? That's fine. Biden,

1230
01:08:39,020 --> 01:08:42,840
Speaker 3:  fcc, Biden campaigns and all this stuff. They've accomplished nothing because

1231
01:08:42,840 --> 01:08:46,040
Speaker 3:  they've been deadlocked at two, two for 16 months.

1232
01:08:46,420 --> 01:08:50,320
Speaker 3:  The fifth commissioner has been waiting on, her name is Gigi soon Gigi

1233
01:08:50,320 --> 01:08:53,040
Speaker 3:  has been on the Verge House. She's a character on the Verge. She's like this

1234
01:08:53,240 --> 01:08:56,480
Speaker 3:  ferocious consumer advocate. She was on the Board of Public Knowledge, the

1235
01:08:56,480 --> 01:09:00,080
Speaker 3:  First Amendment organization. She's been sitting there for

1236
01:09:00,080 --> 01:09:03,840
Speaker 3:  16 months. No, she's been nominated twice over it

1237
01:09:03,840 --> 01:09:06,560
Speaker 3:  expired both times. She's gone to committee twice. There's been hearings.

1238
01:09:06,560 --> 01:09:10,360
Speaker 3:  We did an entire decoder episode about this bizarre mystery

1239
01:09:10,360 --> 01:09:14,280
Speaker 3:  where they cannot get her confirmation over the finish line. And the

1240
01:09:14,560 --> 01:09:17,840
Speaker 3:  answer is, Comcast at and t Verizon

1241
01:09:18,480 --> 01:09:22,440
Speaker 3:  furiously spending money to keep the Biden FCC deadlocked.

1242
01:09:22,440 --> 01:09:25,920
Speaker 3:  And in particular from keeping a true consumer advocate on there. This is

1243
01:09:25,920 --> 01:09:29,840
Speaker 3:  the point of the show where we missed actually disclosures earlier. I

1244
01:09:29,840 --> 01:09:33,560
Speaker 3:  should note Comcast is a minority investor in Vox Media or parent

1245
01:09:33,560 --> 01:09:37,280
Speaker 3:  company. You might tell from the tone of my voice. That's cool. How do you

1246
01:09:37,280 --> 01:09:41,200
Speaker 3:  feel about that? That's fine. It's, it's, there's no

1247
01:09:41,200 --> 01:09:43,440
Speaker 3:  love loss there. They're fine. They're all very cool. We also made a Netflix

1248
01:09:43,440 --> 01:09:46,280
Speaker 3:  show. We made a Netflix, Netflix show. Netflix show. I, it's called The Future

1249
01:09:46,280 --> 01:09:49,320
Speaker 3:  of That's great. You should go watch it on your Comcast internet connection,

1250
01:09:50,200 --> 01:09:52,480
Speaker 3:  your overpriced Comcast Internet Connection

1251
01:09:54,020 --> 01:09:58,000
Speaker 3:  disclosures. We have some. Gigi quit this

1252
01:09:58,000 --> 01:10:01,040
Speaker 3:  week. She withdrew. She's like, couldn't take it. Couldn't take the attacks.

1253
01:10:01,170 --> 01:10:04,480
Speaker 3:  McKenna Kelly is reporting on all this. We'll have a lot more on it. But

1254
01:10:04,480 --> 01:10:08,080
Speaker 3:  I just wanna point out this is like a policy disaster.

1255
01:10:08,270 --> 01:10:11,880
Speaker 3:  Yeah. That is squarely Biden's fault. Like he did not push

1256
01:10:12,090 --> 01:10:15,920
Speaker 3:  to have a functional telecom regulator in this country as you, I mean

1257
01:10:15,920 --> 01:10:19,200
Speaker 3:  this is just me doing greatest hits now. Americans pay the highest prices

1258
01:10:19,200 --> 01:10:22,880
Speaker 3:  for the slowest speeds in the entire world. If you go to Europe,

1259
01:10:23,140 --> 01:10:26,680
Speaker 3:  you can get unlimited data send card that works anywhere in Europe

1260
01:10:26,740 --> 01:10:30,160
Speaker 3:  for like, I dunno nothing. $2

1261
01:10:30,470 --> 01:10:34,160
Speaker 3:  here. It's massive amounts of money and getting more expensive.

1262
01:10:35,040 --> 01:10:38,920
Speaker 3:  We're gonna come to Dish Network. Our government approved the merger of

1263
01:10:39,000 --> 01:10:42,360
Speaker 3:  T-Mobile and Sprint reducing the amount of competitors in the market

1264
01:10:42,580 --> 01:10:46,320
Speaker 3:  and said Dish, they would stand up Dish Network as a fourth competitor.

1265
01:10:46,430 --> 01:10:50,200
Speaker 3:  Dish Network has been down for two weeks. Like

1266
01:10:50,200 --> 01:10:54,120
Speaker 3:  the whole fucking company had a cyber attack. People couldn't pay

1267
01:10:54,120 --> 01:10:58,000
Speaker 3:  their bills. Customer service agents couldn't even respond to people. Installers

1268
01:10:58,000 --> 01:11:01,840
Speaker 3:  weren't getting scheduled. Zero coverage except for us.

1269
01:11:02,070 --> 01:11:05,720
Speaker 3:  Like just crazy. Like the amount of competition we've reduced and the

1270
01:11:05,720 --> 01:11:09,200
Speaker 3:  amount that we've allowed prices to rise. Cuz we do not have a functional

1271
01:11:09,200 --> 01:11:12,840
Speaker 3:  telecom regulator in this country. And this, this failure to nominate Gigi

1272
01:11:12,840 --> 01:11:16,680
Speaker 3:  is like just a stark reminder that actually,

1273
01:11:16,680 --> 01:11:20,120
Speaker 3:  like we talk a lot about tech company corruption and like big tech, it's

1274
01:11:20,120 --> 01:11:24,080
Speaker 3:  the telecoms. Like they still own massive chunks of

1275
01:11:24,080 --> 01:11:27,720
Speaker 3:  political power and they wield it with absolute like

1276
01:11:27,720 --> 01:11:31,240
Speaker 3:  nightmare like efficiency to make sure they get what they want and keep the

1277
01:11:31,520 --> 01:11:34,480
Speaker 3:  monopolies in place. It's, I'm furious about it, as you can

1278
01:11:34,720 --> 01:11:37,720
Speaker 4:  Probably tell. And Gigi's own really, really, really did not mince words

1279
01:11:37,730 --> 01:11:41,240
Speaker 4:  to that effect. Like, I, I just keep reading this quote that she said over

1280
01:11:41,240 --> 01:11:44,240
Speaker 4:  and over, which is in our story. She says, it is a sad day for our country

1281
01:11:44,240 --> 01:11:47,480
Speaker 4:  and our democracy when dominant industries with assistance from unlimited

1282
01:11:47,480 --> 01:11:51,000
Speaker 4:  dark money get to choose their regulators. And with the help of friends in

1283
01:11:51,000 --> 01:11:54,400
Speaker 4:  the Senate, the powerful cable and media companies have done just that. It's

1284
01:11:54,400 --> 01:11:57,800
Speaker 4:  like, yeah, there it is. Folks like, it's, it's pretty much that simple.

1285
01:11:57,800 --> 01:12:01,480
Speaker 1:  It was the most open and shut should have been approved

1286
01:12:01,480 --> 01:12:05,440
Speaker 1:  immediately. And instead there was a lot of conversation about how

1287
01:12:05,440 --> 01:12:09,360
Speaker 1:  she hated Republicans and that she was gonna take Newsmax and

1288
01:12:09,360 --> 01:12:13,120
Speaker 1:  what was it, one America off the air. Even though she wouldn't have

1289
01:12:13,120 --> 01:12:17,080
Speaker 1:  had that power, there was a lot of just huge misinformation about her Ted

1290
01:12:17,080 --> 01:12:20,960
Speaker 1:  Cruz popping champagne at at her loss. Even though

1291
01:12:20,960 --> 01:12:24,760
Speaker 1:  all of his constituents are absolutely destroyed by the

1292
01:12:25,000 --> 01:12:28,000
Speaker 1:  terrible broadband in this country and all they want is better broadband.

1293
01:12:28,000 --> 01:12:30,920
Speaker 1:  And he's like, yeah, fuck you. Broadband and joy. Yeah.

1294
01:12:31,060 --> 01:12:34,440
Speaker 3:  And he and his claim is like, he's like a, because she has like previously

1295
01:12:34,440 --> 01:12:35,480
Speaker 3:  criticized Fox News

1296
01:12:35,910 --> 01:12:36,400
Speaker 1:  Yeah.

1297
01:12:37,050 --> 01:12:39,820
Speaker 3:  That she would like do something to free speech. Meanwhile,

1298
01:12:39,820 --> 01:12:41,660
Speaker 1:  When, when she had zero control, when,

1299
01:12:41,960 --> 01:12:45,220
Speaker 3:  And also like I didn't pay attention to Fox News News lately.

1300
01:12:46,650 --> 01:12:47,140
Speaker 4:  Yeah.

1301
01:12:47,650 --> 01:12:48,860
Speaker 1:  Good entertainment channel.

1302
01:12:48,860 --> 01:12:52,540
Speaker 3:  But meanwhile, right, there's no net neutrality in this country. And so

1303
01:12:52,540 --> 01:12:56,260
Speaker 3:  things are starting to happen that are really weird. Like state

1304
01:12:56,260 --> 01:13:00,180
Speaker 3:  senators in Texas proposing bills to force ISPs

1305
01:13:00,230 --> 01:13:03,950
Speaker 3:  to block websites with abortion information on them. Yep. And to

1306
01:13:04,460 --> 01:13:08,390
Speaker 3:  make it so that hosting providers in Texas cannot host any

1307
01:13:08,390 --> 01:13:12,270
Speaker 3:  website that has abortion information on it. Like I, that's straight

1308
01:13:12,270 --> 01:13:15,830
Speaker 3:  up, like fully in the realm of our

1309
01:13:15,920 --> 01:13:18,990
Speaker 3:  telecom policy is now allowing

1310
01:13:19,290 --> 01:13:23,110
Speaker 3:  infringements on free speech. Like the basics

1311
01:13:23,110 --> 01:13:26,270
Speaker 3:  of net neutrality. Even if you go to the big, even if you go to Comcast,

1312
01:13:26,340 --> 01:13:29,990
Speaker 3:  I've talked to Comcast about this, right? They're like, yeah, we think no

1313
01:13:29,990 --> 01:13:33,270
Speaker 3:  blocking, no locking, that's what I always call it. Right? No blocking of

1314
01:13:33,270 --> 01:13:37,130
Speaker 3:  websites, no blocking of devices from the network. Everyone agrees

1315
01:13:37,130 --> 01:13:39,970
Speaker 3:  on this. If you write a net neutrality bill and you're like, all right, we're

1316
01:13:39,970 --> 01:13:43,810
Speaker 3:  gonna start with no blocking, no locking, no one come jumps

1317
01:13:43,810 --> 01:13:47,690
Speaker 3:  out and says, do do this. Like, maybe the exceptions are we'll block devices

1318
01:13:47,690 --> 01:13:50,530
Speaker 3:  that are malicious. And everyone's like, yeah, sure, that makes sense. But

1319
01:13:50,530 --> 01:13:54,090
Speaker 3:  the basics are like, don't, you can't block websites, you can't block content

1320
01:13:54,090 --> 01:13:57,130
Speaker 3:  and you can't block devices. And they, they've been saying this for over

1321
01:13:57,130 --> 01:14:01,050
Speaker 3:  a decade that we've been covering this and you get rid of it in just a

1322
01:14:01,050 --> 01:14:04,610
Speaker 3:  few years after you get rid of it. You have state senators in Texas saying,

1323
01:14:04,930 --> 01:14:07,930
Speaker 3:  actually we got rid of Dobbs too. Now you should block websites to abortion

1324
01:14:07,930 --> 01:14:10,450
Speaker 3:  information. But if you're a house, listen, I don't care where you're on

1325
01:14:10,450 --> 01:14:13,480
Speaker 3:  the political spectrum, that is just straight up an attack on the first amendment

1326
01:14:13,480 --> 01:14:16,680
Speaker 3:  and an attack on how we think the internet should work. Like maybe you think

1327
01:14:16,680 --> 01:14:19,480
Speaker 3:  people should get abortions. The idea that you can block the information

1328
01:14:19,480 --> 01:14:23,080
Speaker 3:  or block hosting providers from even having the websites like fully outta

1329
01:14:23,080 --> 01:14:26,120
Speaker 3:  bounds. And that's what you get without like functional telecom policy anyway.

1330
01:14:26,120 --> 01:14:29,720
Speaker 3:  It's outrageous. McKenna's gonna have more on it. There's

1331
01:14:30,080 --> 01:14:33,840
Speaker 3:  a lot to this story. It's a, it's a long weaving tale. Like as,

1332
01:14:33,840 --> 01:14:37,680
Speaker 3:  as David said, of dark money and corruption. Go listen to the

1333
01:14:37,680 --> 01:14:41,280
Speaker 3:  decoder episode about it. One thing I'll note, so little competition,

1334
01:14:41,460 --> 01:14:44,800
Speaker 3:  the star of that decoder episode was the CEO of newsmax,

1335
01:14:44,920 --> 01:14:48,320
Speaker 3:  which is Chris Roddy is not a liberal by anyone's conception.

1336
01:14:48,700 --> 01:14:52,640
Speaker 3:  And he was like, I want Gigi sound on the FCC because she

1337
01:14:52,640 --> 01:14:55,920
Speaker 3:  is a fighter for competition. And what I need to do is compete. That's a

1338
01:14:55,920 --> 01:14:58,360
Speaker 3:  big deal. So go listen to that episode coder in the next week we'll have

1339
01:14:58,360 --> 01:14:58,640
Speaker 3:  more for

1340
01:14:58,640 --> 01:15:00,800
Speaker 4:  McKenna. But wait, can I ask a really dumb question before we move on from

1341
01:15:00,800 --> 01:15:04,480
Speaker 4:  this subject? What happens now? Like, does the Biden administration have

1342
01:15:04,480 --> 01:15:07,760
Speaker 4:  to nominate somebody else? Is it they nominate two two forever? Like what

1343
01:15:07,760 --> 01:15:08,800
Speaker 4:  happens now? They'll,

1344
01:15:08,800 --> 01:15:12,760
Speaker 1:  They'll nominate somebody else and they probably will not be

1345
01:15:12,810 --> 01:15:16,640
Speaker 1:  as like a, as good an advocate for consumers.

1346
01:15:16,640 --> 01:15:20,600
Speaker 1:  It'll probably be someone much more palatable to the telecoms because yeah,

1347
01:15:20,670 --> 01:15:21,840
Speaker 1:  that's the only way they're

1348
01:15:21,840 --> 01:15:23,800
Speaker 3:  Pass through lawyer from Verizon is

1349
01:15:23,800 --> 01:15:26,000
Speaker 4:  A cheap PI coming back. Be honest, that

1350
01:15:26,000 --> 01:15:29,040
Speaker 3:  Gonna happen. Be someone like that. It'll be someone who's a little more

1351
01:15:29,040 --> 01:15:32,920
Speaker 3:  liberal but it's like a democrat who works for at and t

1352
01:15:32,920 --> 01:15:36,840
Speaker 3:  like the former general counsel of charter communication. Like

1353
01:15:37,030 --> 01:15:40,440
Speaker 3:  that's what we've had for years and that's what which we're gonna get again.

1354
01:15:40,440 --> 01:15:43,960
Speaker 3:  And so it, I would just not like when,

1355
01:15:44,360 --> 01:15:44,880
Speaker 3:  what's

1356
01:15:44,880 --> 01:15:46,400
Speaker 4:  John Ledger doing these days? He could do it.

1357
01:15:46,900 --> 01:15:50,320
Speaker 3:  Put him an example of the Biden administration's confidence in fcc,

1358
01:15:50,560 --> 01:15:54,420
Speaker 3:  right? They, they did all that rural broadband stuff and

1359
01:15:54,420 --> 01:15:57,940
Speaker 3:  they did not do it through the fcc, they did it through other agencies cuz

1360
01:15:57,940 --> 01:16:01,340
Speaker 3:  they just don't trust the FCC to be effective. It's maybe, maybe you should

1361
01:16:01,340 --> 01:16:04,940
Speaker 3:  shut it down. Like maybe you wanna go full libertarian and be like, my three

1362
01:16:04,940 --> 01:16:08,380
Speaker 3:  part plan for America is like to shut this down cuz it's a disaster. Fine.

1363
01:16:08,380 --> 01:16:11,140
Speaker 3:  I'm not gonna disagree with you at this moment in time. You gotta replace

1364
01:16:11,140 --> 01:16:15,020
Speaker 3:  it with something with some effective oversight of

1365
01:16:15,020 --> 01:16:18,780
Speaker 3:  the telecoms, not of the content. Right. I don't think that we should have

1366
01:16:18,780 --> 01:16:22,180
Speaker 3:  government speech regulations. I think everybody knows that. I'm saying

1367
01:16:22,180 --> 01:16:26,100
Speaker 3:  literally at and t, Verizon, T-Mobile, Comcast, all of 'em

1368
01:16:26,280 --> 01:16:30,220
Speaker 3:  are little monopolies. Their markets are not competitive and they do

1369
01:16:30,220 --> 01:16:33,980
Speaker 3:  weird shit and raise prices all the time. And that's like, you can't even

1370
01:16:33,980 --> 01:16:37,820
Speaker 3:  argue with that. Do we think that ISPs in this country

1371
01:16:38,120 --> 01:16:41,980
Speaker 3:  are like great and that people love them? No. Does no one does.

1372
01:16:41,980 --> 01:16:43,780
Speaker 3:  0% of the people believe that

1373
01:16:44,090 --> 01:16:44,940
Speaker 4:  Long pause.

1374
01:16:45,400 --> 01:16:48,740
Speaker 1:  Two members of the s c do. Yeah. They think it's going great.

1375
01:16:48,930 --> 01:16:52,900
Speaker 3:  It's going great. The one ISP people love is starlink. Although in

1376
01:16:52,900 --> 01:16:56,260
Speaker 3:  the starline credit yesterday I saw someone who said, Hey,

1377
01:16:56,610 --> 01:17:00,580
Speaker 3:  I was at the mall the other day and T-Mobile home internet is available

1378
01:17:00,580 --> 01:17:04,300
Speaker 3:  in my area and I switched to 5g home internet over

1379
01:17:04,300 --> 01:17:04,660
Speaker 3:  Starling.

1380
01:17:04,800 --> 01:17:05,220
Speaker 4:  Wow.

1381
01:17:05,360 --> 01:17:08,500
Speaker 3:  And ever in the go read the thread. People are like, I do it too.

1382
01:17:09,700 --> 01:17:10,120
Speaker 3:  Who

1383
01:17:10,180 --> 01:17:11,520
Speaker 4:  Big win for 5g.

1384
01:17:12,070 --> 01:17:15,920
Speaker 3:  It's the, the only win for 5g. 5G sister. Okay. Speaking of

1385
01:17:15,920 --> 01:17:19,760
Speaker 3:  5g, I mentioned this thing about Dish Network. This is super weird. It's

1386
01:17:19,760 --> 01:17:23,720
Speaker 3:  super weird. So Dish is a big company, right? They run Dish, they run the,

1387
01:17:23,720 --> 01:17:27,440
Speaker 3:  the satellite television service. They run Boost Mobile that

1388
01:17:27,720 --> 01:17:30,360
Speaker 3:  they picked up. They run Project Genisis, their

1389
01:17:30,940 --> 01:17:34,560
Speaker 3:  ultra-competitive 5G network for this. Just everybody's striking fears in

1390
01:17:34,560 --> 01:17:38,040
Speaker 3:  the heart. Hans Berg CEO Verizon wakes up

1391
01:17:38,150 --> 01:17:40,800
Speaker 3:  cold sweat in the middle of night. He's like, project Genisis, where are

1392
01:17:40,800 --> 01:17:40,920
Speaker 3:  we

1393
01:17:40,920 --> 01:17:43,640
Speaker 4:  On this? Do they still have just the one phone? I know I was out for a while.

1394
01:17:44,080 --> 01:17:45,640
Speaker 4:  Is it still just the one phone? They've

1395
01:17:45,640 --> 01:17:49,000
Speaker 3:  Been known updates. Okay, cool. They've got the one phone, they got the one

1396
01:17:49,000 --> 01:17:50,520
Speaker 3:  tower in Portland. They're doing great.

1397
01:17:51,040 --> 01:17:53,080
Speaker 1:  Mitchell is the only subscriber.

1398
01:17:53,430 --> 01:17:57,240
Speaker 3:  Yeah. This is the day of their earnings call. This happened several weeks

1399
01:17:57,240 --> 01:18:01,120
Speaker 3:  ago and we covered it. We got a tip from an installer just

1400
01:18:01,120 --> 01:18:04,320
Speaker 3:  to our general tips line. Hey, like our systems have been down for hours

1401
01:18:04,980 --> 01:18:08,920
Speaker 3:  and we think it's a cyber attack. That same day they had an earnings call

1402
01:18:08,920 --> 01:18:12,880
Speaker 3:  where they said, this is not a cyber attack. We'll we'll have it

1403
01:18:12,880 --> 01:18:16,640
Speaker 3:  back up shortly. Like days went by Richard. I think it was like two

1404
01:18:16,640 --> 01:18:20,440
Speaker 3:  full days before any other updates. People couldn't log in and pay their

1405
01:18:20,440 --> 01:18:24,280
Speaker 3:  bills on the Boost Mobile website. The dish network.com website

1406
01:18:24,540 --> 01:18:28,440
Speaker 3:  was just a weird sorry, message that was it just like

1407
01:18:28,440 --> 01:18:31,760
Speaker 3:  a box that said we're sorry we're down. Like you couldn't pay your Boost

1408
01:18:31,760 --> 01:18:34,840
Speaker 3:  mobile bill, you couldn't sign up. People's deliveries or service appointments

1409
01:18:34,840 --> 01:18:38,600
Speaker 3:  were canceled. There was no coverage of this except for us,

1410
01:18:38,600 --> 01:18:40,360
Speaker 3:  basically in a handful of trade publications.

1411
01:18:40,500 --> 01:18:44,360
Speaker 5:  And they finally put out a statement eventually saying that there was a cybersecurity

1412
01:18:44,720 --> 01:18:47,960
Speaker 5:  incident. They, they still haven't really said what, what is going on?

1413
01:18:48,590 --> 01:18:51,760
Speaker 5:  I think the last time this was updated was on March 7th. Where are, where

1414
01:18:51,760 --> 01:18:54,720
Speaker 5:  are they now? What have they fixed? What is resolved? This is

1415
01:18:55,270 --> 01:18:56,320
Speaker 5:  just kind of nowhere.

1416
01:18:56,750 --> 01:19:00,080
Speaker 3:  Yeah. On the third they said they're making progress. Oh,

1417
01:19:00,800 --> 01:19:03,400
Speaker 3:  first of all, this is a mystery. We should get to the bottom of it. Second

1418
01:19:03,400 --> 01:19:07,240
Speaker 3:  of all, it's wild that this is happening to a major tele,

1419
01:19:07,240 --> 01:19:10,520
Speaker 3:  like a telecom company is going through this. There's almost no coverage

1420
01:19:10,520 --> 01:19:14,080
Speaker 3:  of it anywhere. And then three, this is the company

1421
01:19:14,080 --> 01:19:16,840
Speaker 3:  that's supposed to provide competition in the broadband market.

1422
01:19:18,110 --> 01:19:18,600
Speaker 3:  Like

1423
01:19:20,270 --> 01:19:24,120
Speaker 3:  Dreams Jeep Pie. Like you're like, there will be four competitors.

1424
01:19:24,120 --> 01:19:27,800
Speaker 3:  Dish Network is gonna do it. They can't, they can't even

1425
01:19:27,800 --> 01:19:28,520
Speaker 3:  reboot the pc.

1426
01:19:29,320 --> 01:19:33,000
Speaker 4:  There is something deeply hilarious to me about the Dish

1427
01:19:33,000 --> 01:19:36,240
Speaker 4:  website right now, like dish.com, which at least in my experience so far

1428
01:19:36,240 --> 01:19:40,000
Speaker 4:  doesn't always load but does sometimes load. There are, there are

1429
01:19:40,000 --> 01:19:43,760
Speaker 4:  three sort of buckets that you can see at the top three parts of the

1430
01:19:43,760 --> 01:19:46,360
Speaker 4:  website. The first one says, thank you for your patience. It says, you know,

1431
01:19:46,360 --> 01:19:50,280
Speaker 4:  we're we're experiencing a system issue that's been there for what, two

1432
01:19:50,280 --> 01:19:54,160
Speaker 4:  weeks now. The second one is customer support. That's good. And

1433
01:19:54,160 --> 01:19:58,040
Speaker 4:  the third one is a is a big banner that says Get inflation free

1434
01:19:58,040 --> 01:20:01,840
Speaker 4:  TV with Dish. The same price every month for three years.

1435
01:20:02,460 --> 01:20:06,360
Speaker 4:  And I just, it's like, it's a super bold move to be like, come pay

1436
01:20:06,360 --> 01:20:10,080
Speaker 4:  us for tv. You can't have, but we will not raise the price on the TV

1437
01:20:10,080 --> 01:20:13,080
Speaker 4:  that you're not allowed to have and we will never install for you. And

1438
01:20:13,080 --> 01:20:14,800
Speaker 14:  We will charge you immediately.

1439
01:20:14,800 --> 01:20:18,720
Speaker 4:  It's gonna be, it's only $80 a month for

1440
01:20:18,720 --> 01:20:22,080
Speaker 4:  TV that we will never install at your house because of a cybersecurity incident.

1441
01:20:22,080 --> 01:20:23,600
Speaker 4:  Welcome to Dish. I

1442
01:20:23,600 --> 01:20:27,000
Speaker 3:  Will say Dish is not paying a very big Figma bill looking at this website.

1443
01:20:29,350 --> 01:20:33,200
Speaker 3:  That's that's not a cost that they're carrying. Yeah. No one needs

1444
01:20:33,200 --> 01:20:36,200
Speaker 3:  to reduce that bill because that bill is currently $0. Everybody,

1445
01:20:36,750 --> 01:20:38,240
Speaker 3:  this is a Squarespace template.

1446
01:20:39,760 --> 01:20:42,360
Speaker 3:  It's weird. We'll see if it comes back up, but it's just, I want to clock

1447
01:20:42,360 --> 01:20:45,840
Speaker 3:  cause it's so weird that no one's talking about it. All right, let's close

1448
01:20:46,080 --> 01:20:49,600
Speaker 3:  with the lightning round. I think this is very funny. I think the Bing number

1449
01:20:49,600 --> 01:20:51,400
Speaker 3:  is very funny. David, do you wanna talk about the Bing number?

1450
01:20:51,630 --> 01:20:55,560
Speaker 4:  Sure. So Bing, which is now probably more in

1451
01:20:55,560 --> 01:20:58,800
Speaker 4:  the news over the last two months than ever accumulated in the history of

1452
01:20:58,800 --> 01:21:00,640
Speaker 4:  Bing. Would you say that's fair to say? Yeah.

1453
01:21:00,830 --> 01:21:03,120
Speaker 3:  This is the most bing that has ever been bung. Yeah.

1454
01:21:03,970 --> 01:21:07,520
Speaker 4:  We, we, we have binged bonged, we have binged debunked

1455
01:21:07,730 --> 01:21:08,280
Speaker 4:  so hard

1456
01:21:09,220 --> 01:21:09,640
Speaker 3:  For

1457
01:21:09,640 --> 01:21:13,560
Speaker 4:  Weeks and Microsoft very proudly announced that it

1458
01:21:13,560 --> 01:21:16,880
Speaker 4:  now has a hundred million active daily users. Which

1459
01:21:17,290 --> 01:21:21,280
Speaker 4:  on the one hand, so Microsoft's credit is not a small number. Like a hundred

1460
01:21:21,280 --> 01:21:24,640
Speaker 4:  million people using your search engine every day. Big number, very exciting.

1461
01:21:24,830 --> 01:21:28,640
Speaker 4:  I think Google is is substantially over 10 times

1462
01:21:28,750 --> 01:21:32,680
Speaker 4:  that size. Yeah. And, and again, let's not forget, this is not

1463
01:21:32,680 --> 01:21:35,720
Speaker 4:  like the number of people who are gonna use this forever. This is like being

1464
01:21:35,720 --> 01:21:39,640
Speaker 4:  at its absolute buzzies in the history of the product

1465
01:21:40,050 --> 01:21:43,880
Speaker 4:  is somewhere in the range of one-tenth the size of

1466
01:21:43,880 --> 01:21:47,480
Speaker 4:  Google, which again, it's a big market as, as

1467
01:21:47,680 --> 01:21:51,640
Speaker 4:  Sacha Nella said to you, like, they don't have to beat Google to make an

1468
01:21:51,640 --> 01:21:54,480
Speaker 4:  awful lot of money from a search engine. Yeah. But it's just like th this

1469
01:21:54,480 --> 01:21:58,360
Speaker 4:  was a stark reminder of just exactly how big

1470
01:21:58,360 --> 01:22:00,320
Speaker 4:  Google still is in this space.

1471
01:22:00,490 --> 01:22:03,960
Speaker 3:  So their math at the event was for every

1472
01:22:03,980 --> 01:22:07,920
Speaker 3:  1% of market share they saw 2 billion for

1473
01:22:07,920 --> 01:22:11,800
Speaker 3:  revenue. So they've ticked up to something Now I

1474
01:22:11,800 --> 01:22:15,640
Speaker 3:  think that math was based on people using being like a search

1475
01:22:15,640 --> 01:22:17,040
Speaker 3:  engine and not

1476
01:22:17,590 --> 01:22:19,960
Speaker 4:  Like trying to get it to fall in love with them.

1477
01:22:22,240 --> 01:22:25,200
Speaker 3:  Right. Not asking it if it needs condoms, if you get what I'm saying.

1478
01:22:27,380 --> 01:22:31,320
Speaker 3:  And like, I don't know if that has played out. Like

1479
01:22:31,320 --> 01:22:34,240
Speaker 3:  they had to restrict write the number of queries. They're now back up to

1480
01:22:34,240 --> 01:22:37,360
Speaker 3:  10 queries. I think they thought most easier to shut up and be like, how

1481
01:22:37,360 --> 01:22:40,560
Speaker 3:  many two by fours fit into a Kia? Which is like their big example.

1482
01:22:41,120 --> 01:22:43,600
Speaker 3:  And instead it's like, people be like, do you love me?

1483
01:22:43,800 --> 01:22:45,000
Speaker 4:  What does your butt look like? Being

1484
01:22:47,070 --> 01:22:47,560
Speaker 14:  Like,

1485
01:22:47,860 --> 01:22:51,440
Speaker 3:  Are you afraid of death? And it's like, I don't think that you can monetize

1486
01:22:51,440 --> 01:22:51,720
Speaker 3:  that.

1487
01:22:52,400 --> 01:22:52,760
Speaker 4:  CPMs

1488
01:22:52,760 --> 01:22:55,920
Speaker 3:  A real one. So I'm, I'm wondering if there's like actually a cost curve here

1489
01:22:55,920 --> 01:22:59,720
Speaker 3:  where the advertising is being delivered at the rate that

1490
01:23:00,120 --> 01:23:03,680
Speaker 3:  Microsoft assumed it would be delivered at. But it is, you're right. Like

1491
01:23:03,680 --> 01:23:06,720
Speaker 3:  you only get an edge, Deb, you gotta sign up. There's a wait list. But this

1492
01:23:06,720 --> 01:23:10,280
Speaker 3:  is the most Bing that is like our friend John Gruber

1493
01:23:10,540 --> 01:23:14,200
Speaker 3:  has a headline on Daring Fireball. It says Microsoft Bing is the most exciting

1494
01:23:14,200 --> 01:23:17,720
Speaker 3:  product in tech and it's definitely because people are trying to make out

1495
01:23:17,720 --> 01:23:17,920
Speaker 3:  with their

1496
01:23:17,920 --> 01:23:18,400
Speaker 4:  Laptops.

1497
01:23:18,400 --> 01:23:20,600
Speaker 3:  Yes, yes. Not because it's a better search experience than

1498
01:23:20,600 --> 01:23:23,520
Speaker 4:  Google, but that that's worth your whatever, 10 billion investment in open

1499
01:23:23,680 --> 01:23:27,400
Speaker 4:  AI right there. Like we Bing has gotten more press

1500
01:23:27,400 --> 01:23:31,320
Speaker 4:  and juice than ever before. And like you, it's, it's, I

1501
01:23:31,320 --> 01:23:35,200
Speaker 4:  suspect they will happily take that investment over and over and

1502
01:23:35,200 --> 01:23:37,920
Speaker 4:  over again. Even if they can never figure out how to make this anything more

1503
01:23:37,920 --> 01:23:40,160
Speaker 4:  than a novelty. Which it very much still is.

1504
01:23:40,470 --> 01:23:42,720
Speaker 3:  It's, it's a fun novelty. I Oh it's

1505
01:23:42,720 --> 01:23:43,960
Speaker 4:  Delightful. It's so fun.

1506
01:23:44,200 --> 01:23:45,680
Speaker 3:  Is it? But it man,

1507
01:23:45,700 --> 01:23:46,800
Speaker 4:  But it's kind of nothing.

1508
01:23:47,910 --> 01:23:51,880
Speaker 3:  I was using one called character ai again talking about, this is always talking

1509
01:23:51,880 --> 01:23:54,920
Speaker 3:  about like someone's dream. But the short version of the story is

1510
01:23:55,440 --> 01:23:58,840
Speaker 3:  someone's showing me character ai so I click on it character dot a I can

1511
01:23:58,840 --> 01:24:02,240
Speaker 3:  go on. It's like you chat with like famous characters and I was like, I'm

1512
01:24:02,240 --> 01:24:05,800
Speaker 3:  gonna talk to Mario for Mario 64 within two moves

1513
01:24:06,230 --> 01:24:09,960
Speaker 3:  I got Mario from Mario 64 to ask me if I felt lucky

1514
01:24:09,960 --> 01:24:11,400
Speaker 3:  Punk. And

1515
01:24:11,400 --> 01:24:11,720
Speaker 1:  I was like,

1516
01:24:12,830 --> 01:24:15,280
Speaker 3:  Like this is spectacular. Perfect.

1517
01:24:16,910 --> 01:24:20,560
Speaker 3:  I dunno what's going on. This is as much fun as you can have with the

1518
01:24:20,760 --> 01:24:20,920
Speaker 3:  computer.

1519
01:24:22,030 --> 01:24:22,600
Speaker 4:  I love it.

1520
01:24:24,710 --> 01:24:28,040
Speaker 3:  None of this makes any sense. None of this is good. This isn't like

1521
01:24:28,590 --> 01:24:32,560
Speaker 3:  a quality, I guess I'm talking about it now, but like it's not useful.

1522
01:24:32,560 --> 01:24:35,400
Speaker 3:  It's not even like that entertaining cuz it just like, it breaks the same

1523
01:24:35,400 --> 01:24:39,200
Speaker 3:  way every time. But I'm sure Sacha somewhere is like,

1524
01:24:39,230 --> 01:24:40,680
Speaker 3:  just keep that number going up.

1525
01:24:40,830 --> 01:24:43,920
Speaker 4:  Yeah. All this stuff is really terrific.

1526
01:24:44,310 --> 01:24:48,240
Speaker 4:  Really expensive marketing and no one quite knows

1527
01:24:48,780 --> 01:24:50,000
Speaker 4:  for what yet.

1528
01:24:50,000 --> 01:24:53,720
Speaker 3:  Yeah. Speaking of Google and search, Google's like freaking

1529
01:24:53,720 --> 01:24:57,680
Speaker 3:  out. It's like very obvious. They declared a code red, they're

1530
01:24:57,680 --> 01:25:01,640
Speaker 3:  like rolling it out. They had the sort of disastrous bard launch. Who the

1531
01:25:01,640 --> 01:25:05,360
Speaker 3:  bard got something wrong. Which we now all realize is basically the, the

1532
01:25:05,360 --> 01:25:08,640
Speaker 3:  main thing that these generative AI systems do is they confidently lie

1533
01:25:08,640 --> 01:25:11,120
Speaker 4:  To you. Yeah. The thing it got wrong was like very low stakes in

1534
01:25:11,830 --> 01:25:12,320
Speaker 3:  What?

1535
01:25:12,800 --> 01:25:13,120
Speaker 4:  Yeah.

1536
01:25:13,390 --> 01:25:17,360
Speaker 3:  Like yeah, but report from Bloomberg. Google wants to

1537
01:25:17,360 --> 01:25:21,080
Speaker 3:  put AI in all of its products as soon as possible within

1538
01:25:21,080 --> 01:25:21,400
Speaker 3:  months.

1539
01:25:21,630 --> 01:25:25,600
Speaker 1:  Wasn't, forgive me, what wasn't AI already in all of Google's

1540
01:25:25,600 --> 01:25:29,400
Speaker 1:  products. Isn't that what every Google IO is about is how AI

1541
01:25:29,400 --> 01:25:33,000
Speaker 1:  is in all of their stuff and it's doing everything and AI will save

1542
01:25:33,000 --> 01:25:36,160
Speaker 5:  The day. Yes. And it so it can erase stuff in the background of your photos,

1543
01:25:36,260 --> 01:25:39,200
Speaker 5:  but it's not telling you that it loves you. So it has to

1544
01:25:39,200 --> 01:25:43,160
Speaker 3:  Get that. No, they demo that. I, well I think Google's mistake again,

1545
01:25:43,160 --> 01:25:46,600
Speaker 3:  they invented the technology. Like we, if you are listening to this in your

1546
01:25:46,600 --> 01:25:50,280
Speaker 3:  car right now and you slow down just a little bit, a Google PR

1547
01:25:50,280 --> 01:25:54,120
Speaker 3:  person will come running out on the highway to tell you that the T in chat

1548
01:25:54,120 --> 01:25:58,000
Speaker 3:  g p t was invented by Google and stands transformer, like just pump the

1549
01:25:58,000 --> 01:26:01,520
Speaker 3:  brakes a little bit, just feather 'em a little bit. And like someone is gonna

1550
01:26:01,520 --> 01:26:05,280
Speaker 3:  leap out of a bush to be like the T in j b t was invented by Google.

1551
01:26:05,280 --> 01:26:09,080
Speaker 3:  Like it's their technology. They they should be saying it a lot. Yeah. But

1552
01:26:09,080 --> 01:26:12,600
Speaker 3:  it's like, yeah, you didn't realize the value of this technology. Was

1553
01:26:12,740 --> 01:26:16,560
Speaker 3:  the robot sounding nuts anything

1554
01:26:16,630 --> 01:26:17,240
Speaker 3:  useful?

1555
01:26:19,490 --> 01:26:20,880
Speaker 1:  If only they'd realized,

1556
01:26:22,070 --> 01:26:25,480
Speaker 3:  Yeah, like, like the value of this technology is like

1557
01:26:25,660 --> 01:26:29,520
Speaker 3:  1000 TikTok hustle culture bros being like, here's how to make

1558
01:26:29,520 --> 01:26:33,080
Speaker 3:  money with Chad G P T. And they were like, here's what's gonna happen. Sun's

1559
01:26:33,080 --> 01:26:36,440
Speaker 3:  gonna demo having a conversation with a Venus fly trap.

1560
01:26:37,040 --> 01:26:38,360
Speaker 3:  And you're like, what are you talking about?

1561
01:26:39,510 --> 01:26:40,560
Speaker 1:  Should have been Mario,

1562
01:26:41,640 --> 01:26:45,600
Speaker 3:  Should have been Mario just openly threatening me, which

1563
01:26:45,600 --> 01:26:49,520
Speaker 3:  is all anybody wants. I kept typing and it asked me to sign

1564
01:26:49,520 --> 01:26:52,720
Speaker 3:  up and I told James Vincent like, I wanna sign up just so I see if I can

1565
01:26:52,720 --> 01:26:56,400
Speaker 3:  get Mario to explicitly call me a coward. You know, like that's how they

1566
01:26:56,400 --> 01:27:00,120
Speaker 3:  get you like 1299 and Mario's be like, you're a coward.

1567
01:27:00,520 --> 01:27:03,720
Speaker 3:  I didn't sign up. So you like being nagged by the ai. This is what we're

1568
01:27:03,800 --> 01:27:06,680
Speaker 3:  learning a lot about each other. Thanks to chat, chat gpc. Mario was like,

1569
01:27:06,680 --> 01:27:08,920
Speaker 3:  jump through this painting and come on an adventure with me. And I was like,

1570
01:27:08,920 --> 01:27:11,640
Speaker 3:  I don't wanna jump through the painting. Right? Because like saying no to

1571
01:27:11,640 --> 01:27:14,600
Speaker 3:  the AI always makes him very mad. And he is like, come on, it'll be fun.

1572
01:27:14,600 --> 01:27:18,280
Speaker 3:  I was like, what's behind the painting? And he is like evil. This is so dumb.

1573
01:27:18,280 --> 01:27:22,040
Speaker 3:  Every time talking about this, you just, you sound like you're talking

1574
01:27:22,040 --> 01:27:25,720
Speaker 3:  about a dream. This is like Addie's point and like you had this like

1575
01:27:25,720 --> 01:27:29,560
Speaker 3:  emotional experience with no stakes that no one cares about ai. Everybody

1576
01:27:29,560 --> 01:27:32,760
Speaker 3:  that's the big song. But Mario was there. Mario was there.

1577
01:27:34,300 --> 01:27:37,840
Speaker 3:  Can you explain this humane thing to me? It sounds

1578
01:27:38,030 --> 01:27:38,880
Speaker 3:  very bad.

1579
01:27:38,970 --> 01:27:40,320
Speaker 1:  It sounds like Google clips.

1580
01:27:40,830 --> 01:27:43,120
Speaker 3:  Speaking of AI technologies that I nowhere

1581
01:27:43,120 --> 01:27:44,840
Speaker 1:  From speaking of AI technology,

1582
01:27:44,940 --> 01:27:47,400
Speaker 3:  Did you know the t and chat G B T was invented by?

1583
01:27:47,620 --> 01:27:51,000
Speaker 1:  Was it, I had no idea. Now I'm about get a bunch

1584
01:27:51,000 --> 01:27:53,680
Speaker 3:  Of, have a brake a little bit. If you're on cruise control right now, just,

1585
01:27:53,680 --> 01:27:56,120
Speaker 3:  you know, push, you know, you can push the button in a wheel, take it down

1586
01:27:56,120 --> 01:27:59,320
Speaker 3:  from 62 to 59 Google employee, you'll come just

1587
01:27:59,320 --> 01:28:02,200
Speaker 1:  Running right next to the car as fast as they can.

1588
01:28:06,360 --> 01:28:10,080
Speaker 3:  Those like Google shuttle buses will pull up like hold up paper

1589
01:28:10,080 --> 01:28:13,880
Speaker 3:  in the windows. We are the T We are the T. Okay.

1590
01:28:14,110 --> 01:28:18,040
Speaker 1:  Humane is the company. It was started by some former Apple people.

1591
01:28:18,250 --> 01:28:22,160
Speaker 1:  There's a lot of hype around it. It's gotten a lot of investment,

1592
01:28:22,160 --> 01:28:25,760
Speaker 1:  including Sam Altman from Open AI has invested a lot of money in it.

1593
01:28:25,770 --> 01:28:29,720
Speaker 1:  They've even talked about their I P O not actually talked about

1594
01:28:29,910 --> 01:28:33,880
Speaker 1:  what they make at Hu Humane, which is kind of

1595
01:28:33,880 --> 01:28:37,800
Speaker 1:  a problem if you're gonna do things like an I P O and a leak of

1596
01:28:37,800 --> 01:28:41,520
Speaker 1:  a from 2021 pitch deck suggests that

1597
01:28:41,520 --> 01:28:45,240
Speaker 1:  it's some sort of wearable camera. Yeah. Which

1598
01:28:45,520 --> 01:28:48,440
Speaker 1:  I think we've all kind of moved past

1599
01:28:49,250 --> 01:28:51,240
Speaker 1:  as a thing anybody really wants.

1600
01:28:51,730 --> 01:28:55,440
Speaker 3:  So the the league is a very blurry slide deck that was obviously made for

1601
01:28:55,440 --> 01:28:59,320
Speaker 3:  investors. Again, John Gruber had it posted on the website.

1602
01:28:59,320 --> 01:29:03,080
Speaker 3:  So this is what we're working off of. There's a, a bunch of patents floating

1603
01:29:03,080 --> 01:29:06,280
Speaker 3:  around in the world. Like, let's saw it up. There's an awful lot of hype

1604
01:29:06,280 --> 01:29:09,720
Speaker 3:  with this company. Yes. And so some of the patents are like, it'll project

1605
01:29:09,720 --> 01:29:13,200
Speaker 3:  a virtual keyboard on any surface. You can like type with your hands, but

1606
01:29:13,200 --> 01:29:16,120
Speaker 3:  a lot of them are about, okay, it's gonna record everything and like show

1607
01:29:16,120 --> 01:29:20,040
Speaker 3:  you stuff. But like, it's basically the core of it from what we can

1608
01:29:20,040 --> 01:29:23,960
Speaker 3:  talk on the stack is a camera that you wear all the time that is constantly

1609
01:29:23,960 --> 01:29:26,920
Speaker 3:  recording everything, sending it to a cloud, categorizing it with of course

1610
01:29:27,010 --> 01:29:30,400
Speaker 3:  ai, what else? 10,000 monkeys typing furiously.

1611
01:29:30,620 --> 01:29:34,360
Speaker 3:  And then you can say things like, show me my daughter's home run from

1612
01:29:34,360 --> 01:29:37,120
Speaker 3:  earlier today and it will deliver you that video.

1613
01:29:37,270 --> 01:29:41,080
Speaker 4:  Yeah. I mean this is, this is Google clips, it's Snap spectacles,

1614
01:29:41,350 --> 01:29:45,280
Speaker 4:  it's Facebook's smart glasses thing like this. This is a, a, a

1615
01:29:45,510 --> 01:29:49,320
Speaker 4:  rich area that no one has cracked in any kind of way that anyone

1616
01:29:49,680 --> 01:29:50,440
Speaker 4:  actually cares about

1617
01:29:50,870 --> 01:29:54,640
Speaker 1:  Here. Here's my question. So they, they talk a lot about

1618
01:29:54,690 --> 01:29:58,520
Speaker 1:  AI in this. It's a bunch of former Apple people. How much of this is

1619
01:29:58,550 --> 01:30:01,680
Speaker 1:  a play to get acquired by Apple

1620
01:30:02,540 --> 01:30:06,320
Speaker 1:  for, for ar stuff, VR stuff in the future?

1621
01:30:06,370 --> 01:30:09,720
Speaker 1:  Because if you're ingesting all of that data, if this thing goes out and

1622
01:30:09,720 --> 01:30:13,480
Speaker 1:  exists and suddenly and people decide to wear a camera all the time

1623
01:30:13,480 --> 01:30:17,440
Speaker 1:  that ingests all of this data, now you're getting a lot of data that can

1624
01:30:17,440 --> 01:30:20,800
Speaker 1:  be really, really useful if you want to train your facial

1625
01:30:20,800 --> 01:30:23,920
Speaker 1:  recognition and all your other fancy like AI

1626
01:30:24,030 --> 01:30:25,680
Speaker 1:  components for your Spark glasses.

1627
01:30:26,720 --> 01:30:30,000
Speaker 3:  So Gruber had a note about this in the blog post where he leaked the deck

1628
01:30:30,060 --> 01:30:33,800
Speaker 3:  and there Yeah, this is like the interpersonal workings of Humane, the people

1629
01:30:33,800 --> 01:30:37,000
Speaker 3:  who love to start it. Yeah. Apparently not Beloved at Apple. People thought

1630
01:30:37,000 --> 01:30:39,400
Speaker 3:  they took too much credit for stuff that team spilled. Oh.

1631
01:30:39,690 --> 01:30:40,040
Speaker 1:  So

1632
01:30:40,040 --> 01:30:43,920
Speaker 3:  Maybe that's like gruber sourcing. Who knows? Maybe not. That is

1633
01:30:43,920 --> 01:30:47,240
Speaker 3:  the vibe that he reported when he leaked this tech. Okay. Now that doesn't

1634
01:30:47,240 --> 01:30:51,000
Speaker 3:  mean they won't get sold to Google or Microsoft like somewhere the Google

1635
01:30:51,000 --> 01:30:54,280
Speaker 3:  clips product managers. Like what if we just like bought my idea again? Did

1636
01:30:54,280 --> 01:30:58,200
Speaker 3:  it, did it good? Who knows? But they have raised an awful lot of money

1637
01:30:58,200 --> 01:31:02,000
Speaker 3:  and they, man the hype here has been like just off

1638
01:31:02,240 --> 01:31:06,040
Speaker 3:  the charts, like this is a company that makes videos about like the

1639
01:31:06,040 --> 01:31:08,000
Speaker 3:  feelings they hope you have about their products. So

1640
01:31:08,000 --> 01:31:11,400
Speaker 5:  Would would you say the hype is taking a a sort of a magical leap? Is that

1641
01:31:12,420 --> 01:31:13,600
Speaker 4:  Yes, dude.

1642
01:31:13,630 --> 01:31:15,040
Speaker 3:  That's what I keep thinking of

1643
01:31:15,040 --> 01:31:18,720
Speaker 4:  Too. But at least Magical Leap made a thing that is like hopelessly impractical

1644
01:31:18,720 --> 01:31:22,120
Speaker 4:  and the field of view is only this big. But like, but there was cool technology

1645
01:31:22,400 --> 01:31:25,800
Speaker 4:  actually. Very cool. Yeah. This to me is like, I'm not sure they're doing

1646
01:31:26,000 --> 01:31:28,360
Speaker 3:  Anything. I'm sorry, can we just back up

1647
01:31:28,360 --> 01:31:32,200
Speaker 1:  On that? No, the technology was cool. I'll defend that. Like, beating

1648
01:31:32,330 --> 01:31:33,520
Speaker 1:  it directly into your

1649
01:31:33,520 --> 01:31:37,080
Speaker 3:  Eyeball. Eyeball. They, they promised that they were gonna hack the GPU of

1650
01:31:37,080 --> 01:31:39,560
Speaker 3:  your brain. Those were the words they used.

1651
01:31:39,670 --> 01:31:40,320
Speaker 4:  Hell yeah.

1652
01:31:40,580 --> 01:31:44,360
Speaker 3:  And then they remember they had that crazy wired story with like the, I mean

1653
01:31:44,360 --> 01:31:47,000
Speaker 3:  now I think they just hung up a bunch of like l e d rob lights,

1654
01:31:48,230 --> 01:31:49,920
Speaker 3:  like glued them to someone's, they had

1655
01:31:49,920 --> 01:31:50,440
Speaker 5:  We making

1656
01:31:50,440 --> 01:31:52,280
Speaker 1:  Demos. All the commercials were the whale

1657
01:31:52,820 --> 01:31:55,960
Speaker 3:  And the whale and they had the video that no one could tell if it was real.

1658
01:31:55,960 --> 01:31:59,800
Speaker 3:  Cause it was like com. It was like they generated it it and handed it out

1659
01:31:59,800 --> 01:32:02,560
Speaker 3:  and then in the end they'd use the same sort of LCD wave guide stuff.

1660
01:32:02,590 --> 01:32:06,480
Speaker 1:  Like when Beyonce saw it and then decided to invest Beyonce went neat.

1661
01:32:06,510 --> 01:32:10,000
Speaker 3:  Yeah, no, the number of celebrities who went to Florida to invest in magically

1662
01:32:10,000 --> 01:32:13,040
Speaker 3:  because they're the GPUs of their brains have been hacked is off the charts.

1663
01:32:13,860 --> 01:32:17,640
Speaker 3:  I'm just saying this, that feels like this thing, right? Like, it's like,

1664
01:32:17,880 --> 01:32:18,160
Speaker 3:  but

1665
01:32:18,160 --> 01:32:18,520
Speaker 1:  With ai

1666
01:32:18,520 --> 01:32:22,200
Speaker 3:  The first step is what's, isn't there another, there's like another

1667
01:32:22,200 --> 01:32:26,040
Speaker 3:  app and their, their pitch is, will record everything you do on your computer

1668
01:32:26,040 --> 01:32:27,040
Speaker 3:  so you can find it again.

1669
01:32:27,860 --> 01:32:28,280
Speaker 1:  Why

1670
01:32:28,280 --> 01:32:29,360
Speaker 3:  Would you? It's called Rewind.

1671
01:32:29,360 --> 01:32:30,800
Speaker 4:  You do that, it's like rewind

1672
01:32:30,970 --> 01:32:34,680
Speaker 3:  Ai. Like I 1000% too much GenX to be like, yeah,

1673
01:32:34,680 --> 01:32:38,280
Speaker 3:  that's a good idea. Like I saw that Will Smith movie with Gene Hackman.

1674
01:32:38,430 --> 01:32:39,200
Speaker 3:  I No,

1675
01:32:40,790 --> 01:32:44,760
Speaker 4:  Yeah, no, the the thing the humane story really reminds me of is when

1676
01:32:44,760 --> 01:32:48,440
Speaker 4:  Carl pay left OnePlus and started nothing and spent months and months

1677
01:32:48,440 --> 01:32:52,320
Speaker 4:  talking about how we need a hardware revolution and everything needs to be

1678
01:32:52,320 --> 01:32:53,640
Speaker 4:  different. And then just launch headphones

1679
01:32:55,060 --> 01:32:57,280
Speaker 1:  And a phone with LEDs. That's true.

1680
01:32:57,750 --> 01:33:00,400
Speaker 4:  Sure. On the back. Yeah. Con congratulations.

1681
01:33:00,400 --> 01:33:01,160
Speaker 3:  That's innovation.

1682
01:33:01,390 --> 01:33:02,200
Speaker 1:  Yeah. Yeah.

1683
01:33:02,320 --> 01:33:06,280
Speaker 4:  Great headphones. But you can see the headphones. It's like fine. But

1684
01:33:06,840 --> 01:33:10,680
Speaker 4:  this feels like it, it just, the fact that no one has

1685
01:33:10,680 --> 01:33:14,240
Speaker 4:  learned that hype eventually comes around and crushes you

1686
01:33:14,240 --> 01:33:17,680
Speaker 4:  underneath it is mind blowing to me. And Humane just keeps

1687
01:33:18,040 --> 01:33:21,880
Speaker 4:  doing this to itself. Like all these companies keep doing it to

1688
01:33:21,880 --> 01:33:24,600
Speaker 4:  themselves. Magical Leap was like, we've hacked the GPU of your brain. But

1689
01:33:24,600 --> 01:33:28,560
Speaker 4:  if they had just said like, we built this kind of neat thing that you

1690
01:33:28,800 --> 01:33:32,120
Speaker 4:  probably can't buy for a long time. Like it, it might be in much better shape

1691
01:33:32,120 --> 01:33:32,280
Speaker 4:  now

1692
01:33:32,280 --> 01:33:35,040
Speaker 1:  Because they don't have, they don't have editors. This is, this is like,

1693
01:33:35,110 --> 01:33:39,000
Speaker 1:  like if those, if the marketing people who wrote all of this stuff had an

1694
01:33:39,000 --> 01:33:42,640
Speaker 1:  editor to be like, does it really hack the G p U of your brain?

1695
01:33:42,640 --> 01:33:43,480
Speaker 1:  They go, oh

1696
01:33:44,360 --> 01:33:47,320
Speaker 4:  No, they don't need an editor. I've always said that when I get out of journalism,

1697
01:33:47,330 --> 01:33:51,200
Speaker 4:  my next career is gonna be to be the consultant that you pay a lot of money

1698
01:33:51,200 --> 01:33:54,400
Speaker 4:  to sit in the room and tell you all your ideas are bad. Like if you need

1699
01:33:54,560 --> 01:33:57,080
Speaker 4:  somebody to tell your boss that this is actually not as cool as they think

1700
01:33:57,080 --> 01:34:00,360
Speaker 4:  it is, I will do that for the low low price of $25,000.

1701
01:34:01,670 --> 01:34:02,160
Speaker 3:  Like,

1702
01:34:02,160 --> 01:34:05,680
Speaker 4:  Like I will sit there, I'll tell you your names are stupid and that this

1703
01:34:05,680 --> 01:34:09,000
Speaker 4:  thing isn't as cool as you think it is and you should probably cool it for

1704
01:34:09,000 --> 01:34:11,400
Speaker 4:  a minute. And I'm gonna make a fortune. It's gonna be great.

1705
01:34:11,420 --> 01:34:12,440
Speaker 1:  I'm so happy for you.

1706
01:34:12,460 --> 01:34:15,960
Speaker 4:  I'm just looking through these humane slides and it's deeply hilarious. The,

1707
01:34:15,960 --> 01:34:19,520
Speaker 4:  the first slide says, what is it? And then it says cloud connected site enabled

1708
01:34:19,530 --> 01:34:23,400
Speaker 4:  AI platform with server side app ecosystem. And then three

1709
01:34:23,400 --> 01:34:25,040
Speaker 4:  slides later, you realize it's a camera.

1710
01:34:28,750 --> 01:34:32,400
Speaker 1:  It's just so blurry too. That's like,

1711
01:34:32,400 --> 01:34:35,720
Speaker 4:  Yeah, that's the thing. It's like, dear leakers, if you're gonna take pictures

1712
01:34:35,720 --> 01:34:39,000
Speaker 4:  of things, just press the focus on your, on your camera. It's so easy.

1713
01:34:39,000 --> 01:34:40,440
Speaker 4:  Smartphone cameras are so good though.

1714
01:34:40,940 --> 01:34:44,760
Speaker 1:  Any leak, I get super blurry, usually in

1715
01:34:44,760 --> 01:34:48,120
Speaker 1:  black and white. Usually like three 20 by 200

1716
01:34:48,230 --> 01:34:50,600
Speaker 1:  pixels. You need a microscope.

1717
01:34:51,070 --> 01:34:55,000
Speaker 3:  Okay. So Imran Chery, who is the CEO of Humane,

1718
01:34:55,640 --> 01:34:59,240
Speaker 3:  he's one of the founders. He just keeps saying things like, this will be

1719
01:34:59,240 --> 01:35:03,160
Speaker 3:  the best human experience ever. Humane is the next shift

1720
01:35:03,160 --> 01:35:06,880
Speaker 3:  between humans and computing. The best human experience ever. It's technology

1721
01:35:06,880 --> 01:35:09,920
Speaker 3:  that improves the human experience that is born from good intention. Products

1722
01:35:09,920 --> 01:35:13,040
Speaker 3:  have put us back in touch with ourselves each other and the world around

1723
01:35:13,040 --> 01:35:16,600
Speaker 3:  us and experiences that are built on trust with interactions that feel magical

1724
01:35:16,600 --> 01:35:20,440
Speaker 3:  and bring joy. That's a lot, right? Like, just like at the end of the day,

1725
01:35:20,440 --> 01:35:24,040
Speaker 3:  that's a lot, you know, and it's like, phones are pretty good. So like

1726
01:35:24,140 --> 01:35:27,760
Speaker 3:  the the just the hype here of like, what are you gonna deliver? And then

1727
01:35:27,760 --> 01:35:31,360
Speaker 3:  the list of partners is crazy. Like they're partnered with LG and Volvo cars

1728
01:35:31,380 --> 01:35:35,240
Speaker 3:  and it's like to do what? And I, I just think there's no

1729
01:35:35,240 --> 01:35:38,760
Speaker 3:  way you can build up a company like this and not have whatever

1730
01:35:38,960 --> 01:35:42,880
Speaker 3:  first version of a first product be a let down a hundred percent. Because

1731
01:35:42,880 --> 01:35:46,760
Speaker 3:  the first version of any first product is defined by the compromises you

1732
01:35:46,760 --> 01:35:50,160
Speaker 3:  made to ship it out the door. Yep. All right. Last little lightning round

1733
01:35:50,160 --> 01:35:53,880
Speaker 3:  piece. David, you were really into Allison's vivo X 90 Pro versus

1734
01:35:53,880 --> 01:35:55,840
Speaker 3:  Samsung S 23 Ultra camera comparison.

1735
01:35:56,380 --> 01:35:59,830
Speaker 4:  Yeah. It's just very good and everyone should read it. She basically went

1736
01:35:59,840 --> 01:36:03,710
Speaker 4:  to try to figure out in the world of smartphone

1737
01:36:03,710 --> 01:36:07,670
Speaker 4:  cameras, is it better to have a lot of pixels or a big sensor essentially,

1738
01:36:08,070 --> 01:36:12,030
Speaker 4:  which is the sort of eternal camera war. And she landed in

1739
01:36:12,030 --> 01:36:14,870
Speaker 4:  this very funny sort of existential place that I don't wanna totally spoil,

1740
01:36:14,870 --> 01:36:18,190
Speaker 4:  but it's basically like everything is actually a hundred times more complicated

1741
01:36:18,190 --> 01:36:21,750
Speaker 4:  than you think. And it does without quite saying, it boil all the way down

1742
01:36:21,750 --> 01:36:22,830
Speaker 4:  to like, what's a photograph?

1743
01:36:22,830 --> 01:36:23,310
Speaker 3:  Yeah.

1744
01:36:23,890 --> 01:36:27,590
Speaker 4:  But it's, it's really good. And she ends up sort of meditating on like what

1745
01:36:27,590 --> 01:36:31,350
Speaker 4:  makes these things work and why this stuff is hard and

1746
01:36:31,350 --> 01:36:34,550
Speaker 4:  sort of how the whole imaging pipeline has changed as this tech has changed.

1747
01:36:34,550 --> 01:36:38,150
Speaker 4:  Again, I don't wanna split it, but it's, it's, it's really good and was one

1748
01:36:38,150 --> 01:36:41,430
Speaker 4:  of the sort of VIRs things I'd read in a while. Cause you could, she started

1749
01:36:41,430 --> 01:36:44,870
Speaker 4:  with one question and ended in like a total explosion of

1750
01:36:44,920 --> 01:36:48,550
Speaker 4:  gadgets and technology and it's, it's a really fun read and

1751
01:36:48,600 --> 01:36:52,510
Speaker 4:  spoiler alert, the Samsung camera ends up being substantiate better.

1752
01:36:53,170 --> 01:36:53,590
Speaker 3:  But

1753
01:36:53,590 --> 01:36:54,790
Speaker 4:  It's a good read. Everyone should go read it.

1754
01:36:54,890 --> 01:36:58,870
Speaker 3:  All right. We have gone so far over, if you're listening to this in your

1755
01:36:58,870 --> 01:37:02,790
Speaker 3:  car, just know that the humane section went on for like 25

1756
01:37:02,790 --> 01:37:06,150
Speaker 3:  more minutes and we honestly, we just had to cut it cuz we just kept on looking

1757
01:37:06,150 --> 01:37:09,470
Speaker 3:  at their marketing materials and being like, what is this? So if you need

1758
01:37:09,470 --> 01:37:13,270
Speaker 3:  to experience the part that was cut, just hit pause. Just, I dunno. Look

1759
01:37:13,270 --> 01:37:16,390
Speaker 3:  at a flower, be like, what is this? That's what we did.

1760
01:37:16,860 --> 01:37:19,190
Speaker 3:  Well we gazed at Humane for while.

1761
01:37:21,120 --> 01:37:24,830
Speaker 3:  We are gonna be at South by Southwest on Sunday. If you are in Texas at the

1762
01:37:24,830 --> 01:37:28,550
Speaker 3:  show, we're doing a live vergecast March 12th, 2:30 PM

1763
01:37:28,550 --> 01:37:32,070
Speaker 3:  It's free and open to the public. It's in, I believe it's in Slacks

1764
01:37:32,070 --> 01:37:35,670
Speaker 3:  space. Yeah, that's gonna be fun. So come see us at South by Southwest.

1765
01:37:35,730 --> 01:37:39,550
Speaker 3:  You can call the Vergecast hotline. Eight six six Verge

1766
01:37:39,550 --> 01:37:42,510
Speaker 3:  11. David, you're back. You're gonna be with us at So by

1767
01:37:42,510 --> 01:37:46,150
Speaker 4:  Southwest. I'm back. I'm gonna be there. Richard, I'm I'm, I'm very sorry

1768
01:37:46,160 --> 01:37:50,030
Speaker 4:  to be coming back and to be doing a terrible Richard impression

1769
01:37:50,030 --> 01:37:53,990
Speaker 4:  for a long time on the podcast. But for everyone who is very sad that Richard

1770
01:37:53,990 --> 01:37:56,800
Speaker 4:  is gonna be on the show, a a little less. Don't worry, Richard, you're gonna

1771
01:37:56,800 --> 01:38:00,080
Speaker 4:  be here a lot still. I'd like you better than NEI or

1772
01:38:00,080 --> 01:38:03,400
Speaker 3:  Alex. Richard, I've decided that you should take over the Vergecast TikTok

1773
01:38:03,400 --> 01:38:06,760
Speaker 3:  account, which doesn't exist, but if it did, it would just be Richard, you

1774
01:38:06,760 --> 01:38:07,520
Speaker 3:  down. Yes.

1775
01:38:07,730 --> 01:38:11,520
Speaker 5:  Do it. Yes, that is, that's all I'm doing now. As long as I can do it from

1776
01:38:11,520 --> 01:38:12,000
Speaker 5:  this room.

1777
01:38:12,090 --> 01:38:15,000
Speaker 3:  Ah, that's fine. You gotta do the, the dancing dogs thing.

1778
01:38:16,060 --> 01:38:19,800
Speaker 3:  All right, we gotta end this before I have more ideas. So LA this week Alex,

1779
01:38:19,800 --> 01:38:20,440
Speaker 3:  what's going on with that?

1780
01:38:20,650 --> 01:38:24,240
Speaker 1:  So this week it's gonna be, well, this coming week it's gonna be tiny.

1781
01:38:24,240 --> 01:38:28,160
Speaker 1:  Makes Things, who is a key cap

1782
01:38:28,400 --> 01:38:31,960
Speaker 1:  designer for? For mechanical keyboards. It's a very fun discussion. Ashley

1783
01:38:31,960 --> 01:38:33,480
Speaker 1:  Scada has a wonderful time with it.

1784
01:38:34,070 --> 01:38:37,720
Speaker 3:  Very cool. All right, that's it. We've gone so far over. That's ver chest

1785
01:38:37,720 --> 01:38:38,280
Speaker 3:  rock and roll.

1786
01:38:41,740 --> 01:38:45,360
Speaker 15:  And that's a wrap for Vergecast this week. Thanks for listening. If you

1787
01:38:45,360 --> 01:38:48,760
Speaker 15:  enjoy the show, subscribe in the podcast app of your choice or tell a friend,

1788
01:38:48,860 --> 01:38:52,680
Speaker 15:  you can send us feedback at vergecast@theverge.com. This show is

1789
01:38:52,920 --> 01:38:56,680
Speaker 15:  produced by me, Liam James, and our senior audio director, Andrew Marino.

1790
01:38:56,680 --> 01:39:00,440
Speaker 15:  This episode was edited and mixed by Amanda Rose Smith. Our

1791
01:39:00,440 --> 01:39:04,280
Speaker 15:  editorial director is Brooke Min, and our executive producer is Eleanor

1792
01:39:04,280 --> 01:39:07,920
Speaker 15:  Donovan. The Verge Cast is a production of the Verge and Box Media

1793
01:39:07,920 --> 01:39:10,960
Speaker 15:  Podcast Network. And that's it. We'll see you next week.

