1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: c41f6241-e502-410c-9b30-47e490ab2794
Status: Done
Stage: Done
Title: The race to win AI â€” and hack iMessage
Audio URL: https://jfe93e.s3.amazonaws.com/1662191836486278507/-1100543975420941019/s93290-US-5167s-1702041883.mp3
Description: The Verge's Nilay Patel, Alex Cranz, and Dan Seifert discuss Google Gemini's attempt to compete with ChatGPT, Beeper Mini bringing iMessage to Android, and shakeups in the podcast industry, and much more.

2
00:01:21,075 --> 00:01:24,585
Speaker 4:  Hello and Welcome. To Vergecast, the flagship podcast of Samsung

3
00:01:24,915 --> 00:01:25,905
Speaker 4:  Decks enthusiasts

4
00:01:26,565 --> 00:01:27,025
Speaker 5:  And me

5
00:01:27,405 --> 00:01:31,185
Speaker 4:  And Alex Cranz. Hi, I'm Neli. I'm your friend. Alex. Cranz is here. I'm your

6
00:01:31,205 --> 00:01:33,825
Speaker 5:  Don. Don't know what Dex is. Yeah, no, I've used it. I've used

7
00:01:33,905 --> 00:01:37,665
Speaker 4:  It. You gotta find out. David Pierce refuses to use Dex.

8
00:01:37,925 --> 00:01:41,425
Speaker 4:  So we've replaced him with Dan Siefert who's gonna show us his deck set up

9
00:01:41,425 --> 00:01:41,665
Speaker 4:  today.

10
00:01:41,925 --> 00:01:42,785
Speaker 6:  I'm the Dex Defender.

11
00:01:43,535 --> 00:01:47,185
Speaker 4:  It's coming, actually, David's just on vacation. Yeah, but it for a moment,

12
00:01:47,325 --> 00:01:50,745
Speaker 4:  you thought that I was so hardcore into Samsung decks

13
00:01:51,215 --> 00:01:54,185
Speaker 4:  that I clipped my friend from his own show, didn't you? Yeah,

14
00:01:54,985 --> 00:01:56,105
Speaker 5:  I, I would've believed it.

15
00:01:56,215 --> 00:01:57,985
Speaker 4:  It's like that's who we are now. Yeah.

16
00:01:58,205 --> 00:02:01,105
Speaker 5:  You, you and Dan are both like very passionate dex

17
00:02:01,305 --> 00:02:02,585
Speaker 4:  Defenders in different directions.

18
00:02:02,785 --> 00:02:06,505
Speaker 5:  Totally different directions. That's what's, and David's like. No. Yeah.

19
00:02:06,685 --> 00:02:09,945
Speaker 4:  If You don't have a strong opinion about Samsung Dex, he can't be a pro or

20
00:02:10,045 --> 00:02:10,265
Speaker 4:  con.

21
00:02:10,685 --> 00:02:13,505
Speaker 5:  I'm, I'm forming one right now. So don. Don't get ejected from the room.

22
00:02:14,375 --> 00:02:15,185
Speaker 5:  It's going. It's coming.

23
00:02:15,285 --> 00:02:18,825
Speaker 4:  No, no. David is on a very well deserved vacation. Dan is filling in for

24
00:02:18,825 --> 00:02:20,185
Speaker 4:  him. Hi Dan. How you doing? I'm All

25
00:02:20,185 --> 00:02:24,105
Speaker 6:  Right? I am not recording through Dex, to be clear, we'll get

26
00:02:24,105 --> 00:02:25,505
Speaker 6:  into it. Not the right tool for the job.

27
00:02:25,825 --> 00:02:28,665
Speaker 4:  I saw Dan in the office the other day and he goes, look at this. And he pulls

28
00:02:28,665 --> 00:02:32,265
Speaker 4:  out what, by all accounts, looks like a laptop and

29
00:02:32,555 --> 00:02:35,505
Speaker 4:  we'll, we'll let people look at it in a minute. It's, I mean, it's nuts.

30
00:02:35,505 --> 00:02:38,905
Speaker 4:  And he is got his like, phone ed on the side and he is like, it's Dex. And

31
00:02:38,905 --> 00:02:41,545
Speaker 4:  I was like, that's awesome. And I was like, you have to come on The Vergecast

32
00:02:41,545 --> 00:02:45,425
Speaker 4:  and talk about it. And the first thing Dan said to me was, I will not

33
00:02:45,485 --> 00:02:47,465
Speaker 4:  record through this. I don't trust it enough.

34
00:02:49,255 --> 00:02:53,025
Speaker 4:  He's just like, nothing mission critical is happening here. Dan, show us

35
00:02:53,695 --> 00:02:57,585
Speaker 4:  your just frankly absurd galaxy fold Samsung

36
00:02:57,775 --> 00:02:59,285
Speaker 4:  deck laptop set up. It's

37
00:02:59,285 --> 00:03:01,485
Speaker 6:  Good. Alright, I'm gonna try and show it to the camera as best as I can.

38
00:03:01,745 --> 00:03:03,645
Speaker 4:  But remember, it's a radio show. It's a radio

39
00:03:03,645 --> 00:03:04,005
Speaker 6:  Show. But,

40
00:03:04,005 --> 00:03:07,605
Speaker 4:  So if you're in your car right now, pull over and close your eyes. And in

41
00:03:07,605 --> 00:03:11,445
Speaker 4:  your mind's eye, imagine what Dan is saying. Or alternatively,

42
00:03:11,445 --> 00:03:14,045
Speaker 4:  pull over and watch this on YouTube. Those are your two choices. Yeah.

43
00:03:14,665 --> 00:03:18,485
Speaker 6:  So this is like not a new thing. To be clear, I bought a

44
00:03:18,485 --> 00:03:21,445
Speaker 6:  next doc, which is AOC thing.

45
00:03:22,195 --> 00:03:25,325
Speaker 6:  It's been out for a couple of years. This idea has been out for like, well

46
00:03:25,325 --> 00:03:29,205
Speaker 6:  over a decade. You plug your phone into it, it's a laptop looking thing,

47
00:03:29,205 --> 00:03:31,805
Speaker 6:  but there's no guts inside of it. There's no computer inside of it. It's

48
00:03:31,805 --> 00:03:35,685
Speaker 6:  just a touch screen. It keyboard, track pad battery, and you plug

49
00:03:35,725 --> 00:03:39,085
Speaker 6:  your phone into it. But what I did was I got this

50
00:03:39,525 --> 00:03:40,565
Speaker 6:  magnetic mount,

51
00:03:42,275 --> 00:03:44,005
Speaker 4:  It's like a folding MagSafe mount

52
00:03:44,265 --> 00:03:48,245
Speaker 6:  So I put a MagSafe. If anyone's been following me on any

53
00:03:48,275 --> 00:03:51,525
Speaker 6:  threads or, or mast on, you might've seen that. I put a MagSafe ring on the

54
00:03:51,525 --> 00:03:55,485
Speaker 6:  back of my Z fold and then I bought this magnetic mount that I stuck to

55
00:03:55,485 --> 00:03:59,325
Speaker 6:  the back of the next dock. And so now I've got a deck set up

56
00:03:59,635 --> 00:04:03,405
Speaker 6:  with my phone on the side and it, it's effectively

57
00:04:03,565 --> 00:04:06,365
Speaker 6:  a dual screen decks. Yeah, that's what

58
00:04:06,365 --> 00:04:07,845
Speaker 4:  I'm calling it. It's the world's worst chrome.

59
00:04:07,875 --> 00:04:11,805
Speaker 5:  Wait, is it a dual screen or a, a triple screen? It's dual. Like is

60
00:04:11,805 --> 00:04:12,165
Speaker 5:  the decks.

61
00:04:12,275 --> 00:04:13,565
Speaker 6:  It's dual. See there's two.

62
00:04:14,165 --> 00:04:17,055
Speaker 5:  Yeah. But the, the fold I almost feel like is a, a dual screen

63
00:04:17,055 --> 00:04:20,135
Speaker 4:  Already. Technically it's triple screen. 'cause the back of the fold has

64
00:04:20,215 --> 00:04:21,415
Speaker 4:  a screen that's not being used.

65
00:04:21,635 --> 00:04:24,855
Speaker 6:  If I could display something on the screen for people sitting across from

66
00:04:24,855 --> 00:04:25,735
Speaker 6:  me at the coffee shop,

67
00:04:26,175 --> 00:04:29,615
Speaker 4:  I am actually astonished that Dex doesn't put up a full screen

68
00:04:29,955 --> 00:04:33,055
Speaker 4:  ad on the back of the fold screen. That's like you're witnessing the power

69
00:04:33,075 --> 00:04:34,415
Speaker 4:  of Samsung decks. Yes.

70
00:04:34,435 --> 00:04:35,495
Speaker 6:  Now go buy a fridge.

71
00:04:37,205 --> 00:04:41,135
Speaker 6:  That would be quite wonderful actually. But no, it's, it's, it's a dual screen

72
00:04:41,135 --> 00:04:44,615
Speaker 6:  thing. I got my phone on one side. The cool thing about this setup is that

73
00:04:44,615 --> 00:04:48,455
Speaker 6:  you can use the phone as a phone. And so like that looks like a

74
00:04:48,455 --> 00:04:51,255
Speaker 6:  phone. Then on the other side is the Dex interface.

75
00:04:51,555 --> 00:04:55,495
Speaker 5:  It is also significantly better than what you were rocking.

76
00:04:55,635 --> 00:04:59,175
Speaker 4:  No, it is, it is such a vast improvement over my attempt to use Dex.

77
00:04:59,475 --> 00:05:02,215
Speaker 4:  The problem with it is that you still have to use a Galaxy fold.

78
00:05:02,635 --> 00:05:04,735
Speaker 5:  You have to buy this fake laptop. I

79
00:05:04,735 --> 00:05:06,495
Speaker 6:  Don't have a problem with that, but yeah,

80
00:05:07,015 --> 00:05:10,815
Speaker 4:  I, my, I did not enjoy one minute of using the Galaxy fold.

81
00:05:12,085 --> 00:05:15,895
Speaker 4:  Just the every piece of that just made me, and I, that's not to say I don't

82
00:05:15,895 --> 00:05:19,295
Speaker 4:  enjoy using Android. I like using Android. The

83
00:05:19,475 --> 00:05:22,975
Speaker 4:  Galaxy Fold is a very particular device Yes. With very

84
00:05:22,975 --> 00:05:26,455
Speaker 4:  particular demands. And I just didn't like it. It's

85
00:05:26,455 --> 00:05:28,455
Speaker 6:  Got a particular set of skills. We

86
00:05:28,455 --> 00:05:31,655
Speaker 4:  Could say that. Yeah. And the skills are being clunkier than a regular phone.

87
00:05:32,195 --> 00:05:36,175
Speaker 6:  Ah, maybe. but it could do a lot more than a regular phone. You know,

88
00:05:36,255 --> 00:05:39,535
Speaker 6:  I think like, just to like back up on the Dex conversation here.

89
00:05:40,415 --> 00:05:44,255
Speaker 6:  I think there are like two things that are appealing about Dex. One

90
00:05:44,275 --> 00:05:48,015
Speaker 6:  is what you've been trying to do, Eli, which is like, I'm going ultra lightweight.

91
00:05:48,155 --> 00:05:51,295
Speaker 6:  I'm just traveling with my phone and I roll into the office. Yeah. Plug into

92
00:05:51,295 --> 00:05:55,215
Speaker 6:  a hotel desk and I have a desktop set up with a keyboard, mouse, and

93
00:05:55,215 --> 00:05:58,805
Speaker 6:  a big screen there. That is one dream. Yeah. The other way, the other path

94
00:05:58,805 --> 00:06:02,005
Speaker 6:  that's interesting to me at least is the setup that I've got here, which

95
00:06:02,005 --> 00:06:05,805
Speaker 6:  is like, you could say, well, you're just carrying around as much as

96
00:06:06,285 --> 00:06:09,445
Speaker 6:  a MacBook error and a phone. Anyways, the difference is

97
00:06:10,245 --> 00:06:13,285
Speaker 6:  I don't have to like sync between two different devices here. Everything's

98
00:06:13,285 --> 00:06:17,085
Speaker 6:  running off the phone. All of my data is running off the phone and it's using

99
00:06:17,085 --> 00:06:19,965
Speaker 6:  my phone's internet connection. So what this is doing is essentially giving

100
00:06:19,965 --> 00:06:23,605
Speaker 6:  me a laptop like experience with integrated cellular that I can't really

101
00:06:23,625 --> 00:06:27,085
Speaker 6:  get through Apple or really through a lot of other parties. So that is like

102
00:06:27,085 --> 00:06:30,485
Speaker 6:  the interesting thing. All that said, both paths

103
00:06:31,145 --> 00:06:34,405
Speaker 6:  can lead to madness and there's a lot of junk involved

104
00:06:35,065 --> 00:06:38,765
Speaker 6:  in either one of them. I just find it pretty fascinating. A, that It works

105
00:06:38,765 --> 00:06:42,685
Speaker 6:  at all and B, how far it's come since I first experienced Dex way back in

106
00:06:42,685 --> 00:06:44,645
Speaker 6:  like 2018. It is, it is wildly

107
00:06:44,945 --> 00:06:48,525
Speaker 5:  You, you don't find it fascinating. No, you are

108
00:06:48,555 --> 00:06:50,165
Speaker 5:  delighted by it. I'm,

109
00:06:50,505 --> 00:06:53,845
Speaker 6:  I'm delighted by gadgets. Even if they don't look, look as well as some other

110
00:06:53,845 --> 00:06:55,285
Speaker 6:  solutions. I was getting this, they let me

111
00:06:55,785 --> 00:06:59,325
Speaker 5:  Dms from you about this thing. You're just like, look at it. It works. Yeah,

112
00:06:59,325 --> 00:07:01,045
Speaker 5:  it looks cool. It's very cool at it. It looks cool as hell.

113
00:07:01,135 --> 00:07:05,005
Speaker 4:  Again. My my the beginning of my Dex journey started

114
00:07:05,065 --> 00:07:07,045
Speaker 4:  by knowing Dan had been Dex pilled. Yeah.

115
00:07:07,065 --> 00:07:10,605
Speaker 5:  But then what happened when you saw that there was like a fake laptop involved?

116
00:07:11,075 --> 00:07:14,525
Speaker 4:  Well, so first I was like, okay, this is so much closer Yeah.

117
00:07:15,025 --> 00:07:18,725
Speaker 4:  To what I thought I wanted. Right. And then he showed me the next stock,

118
00:07:18,725 --> 00:07:22,565
Speaker 4:  which is the most aggressively 16 by nine laptop in the world. Yeah.

119
00:07:22,795 --> 00:07:26,405
Speaker 4:  Like the amount of bezel that is on the bottom of that display. You can

120
00:07:26,405 --> 00:07:27,605
Speaker 5:  See it from here. It's,

121
00:07:27,605 --> 00:07:29,565
Speaker 6:  It's, it's a good inch below the display of

122
00:07:29,645 --> 00:07:33,565
Speaker 4:  Be, you could make that laptop four, three just by reclaiming bezels. Yes.

123
00:07:33,665 --> 00:07:37,085
Speaker 4:  Yes. It's, it's a lot of bezel. And then

124
00:07:37,715 --> 00:07:40,285
Speaker 4:  it's still decks, which is clunky and, and what

125
00:07:40,285 --> 00:07:42,605
Speaker 5:  Have you left the laptop at work and

126
00:07:42,605 --> 00:07:46,125
Speaker 4:  Just, yeah. What if I just had a desk with a laptop on it that I left here

127
00:07:46,125 --> 00:07:50,085
Speaker 4:  like I used to do in the before time. That's,

128
00:07:50,085 --> 00:07:51,285
Speaker 4:  that's where we're going. But

129
00:07:51,285 --> 00:07:54,285
Speaker 5:  See if someone steals this one, they're not gonna get important neli secrets.

130
00:07:54,315 --> 00:07:56,565
Speaker 6:  Yeah. You can't log into it if there's no phone. Yeah.

131
00:07:56,795 --> 00:07:58,685
Speaker 5:  It's just the fake laptop.

132
00:07:58,835 --> 00:08:02,605
Speaker 4:  Look, I I know it's the, the dream is that you just walk around

133
00:08:03,075 --> 00:08:06,965
Speaker 4:  with a cool phone. Yeah. Just plug it it into stuff and having it turn

134
00:08:06,965 --> 00:08:10,165
Speaker 4:  into your thing. Yeah. That's the dream. We all agree. That's the dream.

135
00:08:10,285 --> 00:08:13,165
Speaker 4:  A hundred percent. You throw it in a couple, your car, the car lights up

136
00:08:13,165 --> 00:08:16,605
Speaker 4:  and it's your phone. Yeah. You can, you can sort of get there, but you have

137
00:08:16,605 --> 00:08:19,405
Speaker 4:  to experience CarPlay for better or worse. It's

138
00:08:19,405 --> 00:08:19,845
Speaker 5:  Great. You,

139
00:08:19,845 --> 00:08:22,925
Speaker 4:  You, you come to the office, you throw it on a, a magnetic charger,

140
00:08:23,875 --> 00:08:27,525
Speaker 4:  like a pad screen lights up, you're doing all your stuff.

141
00:08:27,965 --> 00:08:31,245
Speaker 4:  Everyone knows what the dream is. Yeah. I get emails by people who are like,

142
00:08:31,325 --> 00:08:35,085
Speaker 4:  I feel you on the dream. And then you sit down and you're like, I have to

143
00:08:35,085 --> 00:08:38,925
Speaker 4:  use this galaxy fold. Which again, like the

144
00:08:38,925 --> 00:08:41,245
Speaker 4:  screen, the screen is just like a bubbly, wavy experience.

145
00:08:41,365 --> 00:08:45,285
Speaker 6:  I, I mean, I don't know if it was like your specific one or

146
00:08:45,445 --> 00:08:45,925
Speaker 6:  whatever, but like,

147
00:08:45,925 --> 00:08:46,925
Speaker 5:  No, yours is two Dan.

148
00:08:47,245 --> 00:08:49,125
Speaker 6:  I mean, so if you look at mine,

149
00:08:50,085 --> 00:08:50,885
Speaker 5:  I can see it from here.

150
00:08:51,195 --> 00:08:55,125
Speaker 6:  Five. If you're looking at it off axis, then yeah, you can see that crease

151
00:08:55,185 --> 00:08:58,045
Speaker 6:  and stuff like that. But when you're holding it straight on, you really don't

152
00:08:58,045 --> 00:09:01,685
Speaker 6:  see the crease. And when the screen is on and you're like experiencing

153
00:09:01,685 --> 00:09:05,605
Speaker 6:  content, you don't see the, the crease. It just disappears. It just

154
00:09:05,605 --> 00:09:07,925
Speaker 6:  disappears. Like I've read like a hundred books on it this year. The

155
00:09:07,925 --> 00:09:11,885
Speaker 4:  Pixel fold, which has I think the better aspect ratio

156
00:09:12,515 --> 00:09:13,525
Speaker 4:  when it's full. See,

157
00:09:13,565 --> 00:09:15,005
Speaker 6:  I disagree entirely because

158
00:09:15,365 --> 00:09:18,925
Speaker 4:  I want to use it as a phone a lot of the time. And the galaxy fold does not

159
00:09:18,925 --> 00:09:21,725
Speaker 4:  lend itself to being used as a phone. Yeah. 'cause it's too tall and too

160
00:09:21,725 --> 00:09:25,525
Speaker 4:  skinny. So you're always unfolding it. The Pixel fold, at least folds in

161
00:09:25,525 --> 00:09:28,205
Speaker 4:  that direction. And it got a big update this week along with the rest of

162
00:09:28,205 --> 00:09:30,725
Speaker 4:  Pixel updates, which we'll talk about. There's actual news this week, like

163
00:09:30,735 --> 00:09:34,685
Speaker 4:  quite a lot of it. But we're gonna do the first 20 minutes on Dex

164
00:09:35,105 --> 00:09:38,885
Speaker 4:  anyway, the Pixel fold got an update this week that forces

165
00:09:39,065 --> 00:09:43,045
Speaker 4:  any app to work on. Its on its version of a folding display at full

166
00:09:43,045 --> 00:09:45,865
Speaker 4:  screen. Maybe I'll try that. but it doesn't have a dex mode.

167
00:09:46,125 --> 00:09:49,105
Speaker 6:  No, you can't plug the Pixel fold into anything. It doesn't have video out

168
00:09:49,105 --> 00:09:49,545
Speaker 6:  at all. Like,

169
00:09:49,545 --> 00:09:53,145
Speaker 4:  Come on, turn it into a Chromebook. Let's do this first party decks. What

170
00:09:53,145 --> 00:09:54,625
Speaker 5:  If you just like slap it into the back

171
00:09:54,685 --> 00:09:57,425
Speaker 4:  Of one the flagship podcast of requesting Google make decks,

172
00:10:00,045 --> 00:10:00,545
Speaker 5:  Do it Google

173
00:10:00,925 --> 00:10:04,625
Speaker 4:  All. right. That's that. That's one thing. So the, the decks experiments

174
00:10:04,945 --> 00:10:08,865
Speaker 4:  continue a pace. I don't recommend them, but if you have

175
00:10:08,865 --> 00:10:11,905
Speaker 4:  strong opinions about Dex, we wanna hear from you two. And I just wanna mention

176
00:10:11,905 --> 00:10:15,785
Speaker 4:  this before we begin. There's a big Supreme court case about the social

177
00:10:15,795 --> 00:10:19,625
Speaker 4:  media moderation laws that were passed in Texas and Florida, which by I

178
00:10:19,725 --> 00:10:22,545
Speaker 4:  I'm just gonna tell you, they're blatantly unconstitutional. Yeah. There's

179
00:10:22,545 --> 00:10:24,785
Speaker 4:  pure violations of the First Amendment. They're government speech regulations,

180
00:10:25,125 --> 00:10:28,025
Speaker 4:  but they're at the Supreme court. Supreme court's gonna, whatever

181
00:10:29,125 --> 00:10:32,985
Speaker 4:  amicus briefs are being filed in these cases. One is by public

182
00:10:32,985 --> 00:10:34,865
Speaker 4:  knowledge, which we, those

183
00:10:34,865 --> 00:10:36,025
Speaker 5:  Are like supporting briefs,

184
00:10:36,025 --> 00:10:38,345
Speaker 4:  Right? The supporting briefs not from the parties, it's just people with

185
00:10:38,345 --> 00:10:41,945
Speaker 4:  strong opinions. Filing briefs is Supreme court. So you look at the dockets,

186
00:10:42,025 --> 00:10:45,305
Speaker 4:  a bunch of people are filing them. Public knowledge, which is an organization

187
00:10:45,305 --> 00:10:48,905
Speaker 4:  that we have talked to a lot. Folks from Public Knowledge you have encountered

188
00:10:48,905 --> 00:10:51,865
Speaker 4:  on The Verge many, many times. John Bergmayer, public Knowledge, you have

189
00:10:51,985 --> 00:10:54,545
Speaker 4:  probably encountered in our stories or our podcast in the past. He sent me

190
00:10:54,545 --> 00:10:58,065
Speaker 4:  an email today. He is like, you're in our brief. And they cited Welcome to

191
00:10:58,065 --> 00:11:01,945
Speaker 4:  hell. Elon. Yes. And the Supreme Court brief today, which

192
00:11:01,945 --> 00:11:05,905
Speaker 4:  means Welcome to hell. Elon is now part of our government's history.

193
00:11:06,855 --> 00:11:10,465
Speaker 4:  Like it's just, it's on, it's in, it's in the docket on a pivotal

194
00:11:10,515 --> 00:11:11,585
Speaker 4:  First Amendment case.

195
00:11:12,165 --> 00:11:15,825
Speaker 5:  I'm When do you think like law students are gonna start having to read? It's

196
00:11:15,945 --> 00:11:16,825
Speaker 5:  required reading for 'em.

197
00:11:16,895 --> 00:11:20,785
Speaker 4:  When my mom read this, she, she didn't even call me. She was so upset at

198
00:11:20,785 --> 00:11:23,705
Speaker 4:  the number of F-bombs in the story that she called my sister.

199
00:11:24,685 --> 00:11:28,465
Speaker 4:  And my sister had to call me to call my mother who then

200
00:11:28,465 --> 00:11:32,025
Speaker 4:  said, why did you use some such language? And now,

201
00:11:32,285 --> 00:11:36,225
Speaker 4:  now Clarence Thomas is gonna read that shit. And I just, I'm just, I'm

202
00:11:36,225 --> 00:11:39,905
Speaker 4:  just, anything can happen. That's my message to the Youth of America. Any,

203
00:11:40,185 --> 00:11:44,145
Speaker 4:  anything can, can happen. But I'm, I'm actually the these cases are, are

204
00:11:44,165 --> 00:11:48,065
Speaker 4:  big deals. What's inside of it is do social networks have the right to

205
00:11:48,305 --> 00:11:50,985
Speaker 4:  moderate their networks? Do they have their own First Amendment rights to

206
00:11:50,985 --> 00:11:53,885
Speaker 4:  make choices on their networks? I think the answer has to be yes. It doesn't

207
00:11:53,885 --> 00:11:57,405
Speaker 4:  matter which side of the aisle you're on. The answer has to be yes.

208
00:11:57,635 --> 00:12:01,505
Speaker 4:  Because that way you can get things like subreddits. Yeah.

209
00:12:01,605 --> 00:12:04,745
Speaker 4:  And you need things like subreddits. You need, maybe you need something like

210
00:12:05,225 --> 00:12:08,825
Speaker 4:  X that is moderated in one very specific way and something that is different

211
00:12:08,845 --> 00:12:12,505
Speaker 4:  and to let people decide. So that's the heart of this case,

212
00:12:13,085 --> 00:12:14,545
Speaker 4:  but it is just very funny to me. I

213
00:12:14,545 --> 00:12:16,745
Speaker 5:  Think it's great. I'm very excited for

214
00:12:16,745 --> 00:12:20,065
Speaker 4:  You. I'm just, again, I, I just hope Clarence Thomas, I describe the Supreme

215
00:12:20,065 --> 00:12:22,585
Speaker 4:  Court in this piece as a group of uncool weirdos.

216
00:12:24,145 --> 00:12:26,185
Speaker 5:  I mean, I think most of 'em will read that and be like, fair.

217
00:12:26,745 --> 00:12:27,905
Speaker 4:  I, I hope so.

218
00:12:28,695 --> 00:12:29,945
Speaker 5:  Most of them. Not to Clarence Thomas.

219
00:12:30,025 --> 00:12:32,465
Speaker 4:  I feel like I can go through the nine and be like, who will, who will see

220
00:12:32,465 --> 00:12:36,385
Speaker 4:  themselves and who will like, Alito is gonna be pissed. Yeah. Like Alito

221
00:12:36,385 --> 00:12:38,265
Speaker 4:  is like, look at these Jordans. I'm cool as shit.

222
00:12:38,695 --> 00:12:41,785
Speaker 5:  Kagan's gonna be like, I get it. Understood.

223
00:12:41,975 --> 00:12:45,785
Speaker 4:  Just if anyone can AI generate for me to photograph of Samuel Alito

224
00:12:45,785 --> 00:12:49,705
Speaker 4:  pointing at as Jordans saying, I'm cool as shit. I'm not sure what

225
00:12:49,705 --> 00:12:51,225
Speaker 4:  we'll do with it, but I will accept it

226
00:12:52,575 --> 00:12:56,225
Speaker 5:  Just into your heart. Just happy to experience it.

227
00:12:56,455 --> 00:12:59,985
Speaker 4:  Same later in the Black Jordans. Okay. There is a lot of news this week.

228
00:13:00,435 --> 00:13:03,105
Speaker 4:  Let's start with Google. We, we've already been talking about Google Big

229
00:13:03,105 --> 00:13:06,305
Speaker 4:  News this week. They launched Gemini. It's the new AI model. They've been

230
00:13:06,305 --> 00:13:09,105
Speaker 4:  talking about it for a while. They started talking about it even when they

231
00:13:09,185 --> 00:13:12,785
Speaker 4:  launched Bard the first time, even at io, they were saying, we have this

232
00:13:12,785 --> 00:13:15,985
Speaker 4:  new model called Gemini that they've been doing demos of it. It is finally

233
00:13:16,095 --> 00:13:19,975
Speaker 4:  here. It is obviously meant to be the

234
00:13:19,995 --> 00:13:23,855
Speaker 4:  big step change competitor to chat s GPT in particular. s GPT

235
00:13:23,855 --> 00:13:27,615
Speaker 4:  four. Yeah. David talked to Sundar Phai and

236
00:13:27,615 --> 00:13:31,575
Speaker 4:  Demi Sabas who runs Google DeepMind, the head of AI over there. They're,

237
00:13:31,685 --> 00:13:35,375
Speaker 4:  they keep talking about benchmarks, which I, I would like to get your opinions

238
00:13:35,375 --> 00:13:39,095
Speaker 4:  on. We've reviewed many products. There's,

239
00:13:39,095 --> 00:13:42,985
Speaker 4:  there's an importance of benchmarks in the world. I

240
00:13:42,995 --> 00:13:46,905
Speaker 4:  don't know what an AI model benchmark is, but they talked about

241
00:13:46,905 --> 00:13:50,145
Speaker 4:  it a lot. They talked about it a lot on 30 out, 32 benchmarks.

242
00:13:51,085 --> 00:13:53,225
Speaker 4:  Gemini Beats, s GPT four. That's like

243
00:13:53,785 --> 00:13:55,545
Speaker 5:  A gamer's nexus. Number of benchmarks

244
00:13:55,545 --> 00:13:59,025
Speaker 4:  To run. Yeah. I don't know man. So we should talk about that, what that means.

245
00:13:59,025 --> 00:14:02,865
Speaker 4:  And if that is a useful measure for us as we can figure out like

246
00:14:02,885 --> 00:14:05,865
Speaker 4:  how all of us should evaluate different AI systems. But that is their claim.

247
00:14:06,085 --> 00:14:10,045
Speaker 4:  30 outta 32. Sam Altman, you're back. Guess what you

248
00:14:10,045 --> 00:14:12,285
Speaker 4:  got fired again. Like I, don Dunno.

249
00:14:14,245 --> 00:14:17,325
Speaker 4:  Sundar told David that eventually Gemini will be integrated into search.

250
00:14:17,355 --> 00:14:20,005
Speaker 4:  It's ad products and a Chrome, like this is the thing they're gonna build

251
00:14:20,005 --> 00:14:23,885
Speaker 4:  on. It's in Bard. You can play with Bard. I

252
00:14:23,885 --> 00:14:27,285
Speaker 4:  wanna talk about Bard in a minute. And then the main, the main main thing

253
00:14:27,285 --> 00:14:31,005
Speaker 4:  about Gemini is that it is multimodal from the jump. Right?

254
00:14:31,345 --> 00:14:35,055
Speaker 4:  So it understands video and audio. It can spit some of that stuff

255
00:14:35,275 --> 00:14:38,775
Speaker 4:  out. There's a really fun video that Google released where a person is drawing

256
00:14:38,815 --> 00:14:41,735
Speaker 4:  a picture of a duck and it just sort of figures out that it's looking at

257
00:14:41,735 --> 00:14:43,455
Speaker 4:  a duck. Cool.

258
00:14:43,555 --> 00:14:44,335
Speaker 5:  That's cool as

259
00:14:44,335 --> 00:14:47,815
Speaker 4:  Hell. I would, I would posit that hotdog, not hotdog again,

260
00:14:48,175 --> 00:14:51,885
Speaker 4:  remains the baseline framework to understand the entire AI industry.

261
00:14:53,105 --> 00:14:56,445
Speaker 4:  That's a duck. Yeah. You know what I mean? It's a duck.

262
00:14:57,345 --> 00:15:00,845
Speaker 4:  So it's cool. It's like fun to play with. It's cool. The addition of multimodal

263
00:15:00,845 --> 00:15:03,925
Speaker 4:  capabilities is what really happened this year in ai. That was the big step

264
00:15:03,925 --> 00:15:07,805
Speaker 4:  change. And then obviously Google has new chips. It's more

265
00:15:08,005 --> 00:15:09,885
Speaker 4:  efficient. They're excited about all that

266
00:15:09,885 --> 00:15:13,565
Speaker 5:  Aspect. The multimodal stuff that's not actually live for, for

267
00:15:13,875 --> 00:15:17,565
Speaker 5:  most people. That's only like, for like businesses. Right.

268
00:15:17,705 --> 00:15:18,045
Speaker 5:  So these

269
00:15:18,045 --> 00:15:21,605
Speaker 4:  Are the these are the three models. Yeah. So there's Gemini Nano, which runs

270
00:15:21,995 --> 00:15:25,325
Speaker 4:  only on the Pixel eight pro. And Google's very excited about this.

271
00:15:25,945 --> 00:15:29,925
Speaker 4:  Now the phone is the best phone for ai, da da. Yeah. So it's only in Pixel

272
00:15:29,925 --> 00:15:33,845
Speaker 4:  eight Pro is Gemini Nano. That's the smallest version of the new model.

273
00:15:33,865 --> 00:15:37,405
Speaker 4:  It can run on the Pixel, eights, tensor processing, all that stuff. Then

274
00:15:37,405 --> 00:15:41,245
Speaker 4:  there's Gemini Pro, which is what you can go use in Bard today. Right.

275
00:15:41,625 --> 00:15:44,125
Speaker 4:  And then there's Gemini Ultra, which is not out yet. Okay.

276
00:15:44,145 --> 00:15:47,965
Speaker 5:  And, but that's the one like, because the pro version is still

277
00:15:47,965 --> 00:15:51,925
Speaker 5:  just in Bard. Like that's the only way we can currently access it. And Bard

278
00:15:51,925 --> 00:15:53,365
Speaker 5:  is still just text-based.

279
00:15:53,435 --> 00:15:57,405
Speaker 6:  Yeah. The the pro version is still a chat bot type of thing where you

280
00:15:57,405 --> 00:16:00,845
Speaker 6:  type in, it gives you typed responses back. And Ultra is the one that involves

281
00:16:00,845 --> 00:16:03,765
Speaker 6:  vision and pictures and video and stuff like that. And you're right,

282
00:16:04,595 --> 00:16:08,325
Speaker 6:  Alex, that is like the difference now. And so we can't really experience

283
00:16:08,465 --> 00:16:12,365
Speaker 6:  the multimodal aspect of this just yet. Ultra is coming

284
00:16:12,385 --> 00:16:15,805
Speaker 6:  out next year according to Google. And it will most likely

285
00:16:16,305 --> 00:16:20,045
Speaker 6:  be used for the more enterprise applications that are the higher

286
00:16:20,425 --> 00:16:22,125
Speaker 6:  demand, higher intensity stuff. Well that,

287
00:16:22,125 --> 00:16:25,685
Speaker 5:  That's the part that like Google is the most excited about, like over and

288
00:16:25,685 --> 00:16:28,005
Speaker 5:  over again. Yeah. Beside that and the benchmarks, they're like, yeah, it's

289
00:16:28,005 --> 00:16:30,485
Speaker 5:  really fast and you do all this stuff and you can't see any of it yet. Well

290
00:16:30,485 --> 00:16:33,885
Speaker 6:  It's, it's the new thing, right? Right. Like, like the, the chat interface

291
00:16:33,895 --> 00:16:37,845
Speaker 6:  we've had all year with chat s GPT four and, and the others as well

292
00:16:37,845 --> 00:16:41,765
Speaker 6:  as Bard. So like it a better chat interface is great. Appreciate

293
00:16:41,765 --> 00:16:44,805
Speaker 6:  it. But like the new thing is the multimodal thing. So I. That's understandable.

294
00:16:44,865 --> 00:16:47,925
Speaker 6:  Why Google is most excited about that. That is like the thing that if you

295
00:16:47,925 --> 00:16:51,845
Speaker 6:  wanna put your, on your like predicting hat, like a robot is gonna use a

296
00:16:51,855 --> 00:16:55,725
Speaker 6:  multimodal LLM AI interface in order to navigate the world. So like

297
00:16:55,725 --> 00:16:58,485
Speaker 6:  that's like the exciting futurist stuff. So like, I get it. And

298
00:16:58,485 --> 00:17:02,325
Speaker 4:  That's basically what de said in our piece. You can see how

299
00:17:02,325 --> 00:17:05,605
Speaker 4:  we would get to robotics with a model like Gemini. Or at least they can see

300
00:17:05,605 --> 00:17:09,405
Speaker 4:  it. What we can see is Google Park. Right. But you can see

301
00:17:09,405 --> 00:17:13,085
Speaker 4:  how a robot looking at something would be able to make some interpretations

302
00:17:13,085 --> 00:17:16,935
Speaker 4:  of it, spit out some new commands and go. So that, this

303
00:17:16,935 --> 00:17:19,415
Speaker 4:  brings me back to like, how do we evaluate this stuff? I've been thinking

304
00:17:19,415 --> 00:17:20,415
Speaker 4:  about this a lot. You've

305
00:17:20,415 --> 00:17:21,335
Speaker 5:  Been playing with it a whole lot

306
00:17:21,355 --> 00:17:24,495
Speaker 4:  Too. I, it's, I'm addicted to playing with Bard. 'cause there's nothing funnier

307
00:17:24,495 --> 00:17:28,135
Speaker 4:  than asking a Google product how it will impact search. You know, it's just

308
00:17:28,135 --> 00:17:31,615
Speaker 4:  like, it's, they gotta dance around it. So, I think playing with Bard is

309
00:17:31,615 --> 00:17:35,255
Speaker 4:  really interesting. I think the connection that Bard has, or lack of

310
00:17:35,255 --> 00:17:39,135
Speaker 4:  connection that Bard has to the Google search generative experience is

311
00:17:39,135 --> 00:17:42,735
Speaker 4:  really interesting. So Bard is supposed to be

312
00:17:43,415 --> 00:17:47,015
Speaker 4:  a pretty self-contained experience. Yeah. You open the chat bot, you ask

313
00:17:47,015 --> 00:17:50,485
Speaker 4:  it for stuff, it can summarize things for you. They can watch a YouTube video

314
00:17:50,545 --> 00:17:53,805
Speaker 4:  for you. Again, huge problems with that idea.

315
00:17:54,475 --> 00:17:57,125
Speaker 4:  Like if the robot's watching the YouTube video for you, does the YouTube

316
00:17:57,125 --> 00:18:00,285
Speaker 4:  creator receive any money? don don't know the answer to that question. don

317
00:18:00,285 --> 00:18:01,445
Speaker 4:  don't think Google knows the answer to that question.

318
00:18:01,445 --> 00:18:02,685
Speaker 5:  CliffNotes knows the answer problem.

319
00:18:03,165 --> 00:18:07,125
Speaker 4:  Maybe So, I've been playing with Bart a lot Bar so

320
00:18:07,125 --> 00:18:10,205
Speaker 4:  far. Barge just has confidently hallucinated at me left and right. Yeah.

321
00:18:11,045 --> 00:18:14,925
Speaker 4:  I asked it why a Google executive would be upset at The Verge, I

322
00:18:14,925 --> 00:18:18,485
Speaker 4:  won't name names this time. You can go look at my threads post. And it like

323
00:18:18,555 --> 00:18:21,845
Speaker 4:  made a list of answers and then it confidently hallucinated

324
00:18:22,445 --> 00:18:26,285
Speaker 4:  complete with a link to YouTube. Yes. A Vergecast interview that

325
00:18:26,305 --> 00:18:27,165
Speaker 4:  has never occurred.

326
00:18:29,105 --> 00:18:31,285
Speaker 4:  It just took us to The Vergecast channel page. Aw,

327
00:18:31,615 --> 00:18:33,325
Speaker 5:  Thank you for the promotion. Bard.

328
00:18:33,495 --> 00:18:37,165
Speaker 4:  Great. I but that to me is so nuts. And then I

329
00:18:37,175 --> 00:18:41,085
Speaker 4:  asked, why did you do this? Yeah. And it apologized to me

330
00:18:41,755 --> 00:18:45,645
Speaker 4:  like, I'm very sorry. I misinterpreted some facts. I assumed this had happened.

331
00:18:46,165 --> 00:18:50,005
Speaker 4:  I read some like titles of other Vergecast,

332
00:18:50,255 --> 00:18:54,125
Speaker 4:  which random like not even relevant. Like even in the realm of relevance.

333
00:18:54,465 --> 00:18:57,925
Speaker 4:  And it's like, but but it turns out on, on further examination, like

334
00:18:58,315 --> 00:19:01,045
Speaker 4:  this didn't happen. And I was like, why do you do this? And I was like, I'm

335
00:19:01,045 --> 00:19:02,365
Speaker 4:  every day I'm getting better. Like you. That's

336
00:19:02,365 --> 00:19:06,005
Speaker 5:  How I, what I say whenever I like file a really bad blog. Yeah. And I get

337
00:19:06,005 --> 00:19:08,605
Speaker 5:  hard edits. I'm like, don't look, I'm working on it day every day. I

338
00:19:08,605 --> 00:19:11,565
Speaker 4:  Get better. I didn't, I didn't read the source material. Yeah. I'm very sorry.

339
00:19:11,865 --> 00:19:12,085
Speaker 4:  I'm

340
00:19:12,085 --> 00:19:12,405
Speaker 5:  Very sorry.

341
00:19:12,705 --> 00:19:16,685
Speaker 4:  You put that up against 30 outta 32 benchmarks and it's

342
00:19:16,685 --> 00:19:20,605
Speaker 4:  like, wait, there's only one benchmark, right? Yeah. Does it lie

343
00:19:20,605 --> 00:19:24,005
Speaker 4:  to you all the time? Can you trust what it says?

344
00:19:24,525 --> 00:19:25,965
Speaker 5:  I don't think they're benchmarking that.

345
00:19:26,285 --> 00:19:29,405
Speaker 4:  I, it appears not. I think there are benchmarking things like can it do math?

346
00:19:29,495 --> 00:19:29,845
Speaker 4:  Right?

347
00:19:30,075 --> 00:19:33,165
Speaker 5:  Because a lot of the benchmarks that seem to be around coding and so there

348
00:19:33,165 --> 00:19:35,845
Speaker 5:  was a ton of coding benchmarks and that's really where it sounded like Google

349
00:19:36,345 --> 00:19:39,765
Speaker 5:  is the most excited about it, is it's gonna put a whole lot of

350
00:19:40,345 --> 00:19:42,965
Speaker 5:  coders out of jobs 'cause it can do it as well or better.

351
00:19:44,345 --> 00:19:48,085
Speaker 5:  And then not a lot of conversation about the hallucinations, which for me

352
00:19:48,185 --> 00:19:51,165
Speaker 5:  and you, and I think most people is like, that's what I actually care about.

353
00:19:51,995 --> 00:19:54,725
Speaker 5:  Like, I'm happy it can do Python really, really well, but I need to know

354
00:19:54,725 --> 00:19:58,565
Speaker 5:  if it's gonna lie to me and destroy the world. Or just lie to me and,

355
00:19:58,625 --> 00:20:01,525
Speaker 5:  and, and keep showing me fake Vergecast videos.

356
00:20:01,905 --> 00:20:05,165
Speaker 4:  I'm gonna read you the, the some of the benchmarks. Okay. Okay. There's

357
00:20:05,325 --> 00:20:09,285
Speaker 4:  MMLU, which is a massive multitask language understanding. Oh, it

358
00:20:09,285 --> 00:20:13,245
Speaker 4:  scores a 90% compared to s GPT four is 86%. Ooh, that means something

359
00:20:13,245 --> 00:20:15,845
Speaker 4:  to you. Yeah. There's big bench hard.

360
00:20:17,585 --> 00:20:18,685
Speaker 4:  That's, that's called

361
00:20:20,245 --> 00:20:22,845
Speaker 4:  these the, the, that's a reasoning one. That's the one we put on

362
00:20:22,845 --> 00:20:23,085
Speaker 5:  The gaming

363
00:20:23,085 --> 00:20:26,965
Speaker 4:  Laptops. Big bench hard. Right? It's a diverse set

364
00:20:26,965 --> 00:20:30,565
Speaker 4:  of challenging tasks requiring multi-step reasoning. Gemini did 83 point

365
00:20:30,625 --> 00:20:34,205
Speaker 4:  Gemini Ultra. Mind you 83.6%. GP four is

366
00:20:34,205 --> 00:20:37,885
Speaker 4:  83.1. There's something called drop, which is reading comprehension

367
00:20:37,905 --> 00:20:41,605
Speaker 4:  82.4 for Gemini Ultra 80.9 for s GPT four.

368
00:20:42,685 --> 00:20:46,485
Speaker 4:  I swear to God this isn't a blog post that Google published. There's a reasoning

369
00:20:46,485 --> 00:20:48,845
Speaker 4:  benchmark for AI systems called Hella swag.

370
00:20:50,505 --> 00:20:54,285
Speaker 6:  All of these sound like the like skills comprehension

371
00:20:54,285 --> 00:20:57,685
Speaker 6:  tests my kids go through in elementary school where they take the state tests

372
00:20:57,945 --> 00:21:00,965
Speaker 6:  and they're like, are you at grade level? Are you above grade level? Are

373
00:21:00,965 --> 00:21:03,045
Speaker 6:  you behind grade level? Yeah. That's what all of these sound like. Are you

374
00:21:03,045 --> 00:21:03,165
Speaker 6:  at

375
00:21:03,165 --> 00:21:04,485
Speaker 4:  Hella swag? Yeah.

376
00:21:04,485 --> 00:21:08,045
Speaker 6:  It's like what is your hella swag level? Are you at, are you at

377
00:21:08,045 --> 00:21:11,965
Speaker 6:  acceptable hella swag? Are you hella, hella swag? Are you

378
00:21:11,965 --> 00:21:12,565
Speaker 6:  just swag?

379
00:21:12,675 --> 00:21:15,245
Speaker 4:  Yeah. Gemini is just swag. 87.8,

380
00:21:15,705 --> 00:21:19,485
Speaker 4:  95.3. Hella swag score for s GPT four. Let's go.

381
00:21:19,885 --> 00:21:23,205
Speaker 4:  I would remind you again that s GPT four is made by a company that is in

382
00:21:23,205 --> 00:21:27,125
Speaker 4:  pure turmoil fired and rehired A CEO in

383
00:21:27,125 --> 00:21:28,165
Speaker 4:  a matter of days. But

384
00:21:28,165 --> 00:21:28,365
Speaker 6:  It's

385
00:21:28,365 --> 00:21:32,005
Speaker 4:  Swag. It's super swag. There's some other ones. There's math ones

386
00:21:33,185 --> 00:21:37,165
Speaker 4:  GSM eight K 94.4% for Gemini

387
00:21:37,165 --> 00:21:40,925
Speaker 4:  92.0. So you could just read these. They're all in Google's blog posts. We

388
00:21:40,925 --> 00:21:43,805
Speaker 4:  will link to it. My point is, you look at this

389
00:21:45,025 --> 00:21:48,445
Speaker 4:  and with a benchmark test for a gaming laptop,

390
00:21:49,795 --> 00:21:53,675
Speaker 4:  I I can draw some conclusions about, I don't know how fast the

391
00:21:53,675 --> 00:21:57,435
Speaker 4:  laptop is. Yeah. How well it will play Shadow of the Tomb Raider. Yeah.

392
00:21:57,855 --> 00:22:00,115
Speaker 6:  So, well a game people love the play the best.

393
00:22:00,535 --> 00:22:04,315
Speaker 4:  People love it when we benchmark shadow the tomb writer, nobody loves

394
00:22:04,555 --> 00:22:08,355
Speaker 4:  anything more. It's a, when we benchmark shadow the tomb writer. but it,

395
00:22:08,365 --> 00:22:12,315
Speaker 4:  those things are related to what you might do. Right. And

396
00:22:12,455 --> 00:22:15,675
Speaker 4:  I'm, I'm just reading these benchmarks for Gemini and I understand why Google's

397
00:22:15,675 --> 00:22:19,155
Speaker 4:  proud of them. Yes, it is true. On 30 out of 32,

398
00:22:20,095 --> 00:22:23,915
Speaker 4:  the number in their column is blue. And on two of 32,

399
00:22:23,915 --> 00:22:26,955
Speaker 4:  the number in s GPT column is blue. That great you won.

400
00:22:28,805 --> 00:22:32,625
Speaker 4:  It doesn't mean anything to me yet. And then in actually using the

401
00:22:32,625 --> 00:22:36,395
Speaker 4:  product, I find myself saying, well if I

402
00:22:36,395 --> 00:22:38,635
Speaker 4:  can't trust it, it doesn't matter. Yeah. It's,

403
00:22:38,655 --> 00:22:41,995
Speaker 6:  It reminds me of the battery benchmark testing. Like

404
00:22:42,095 --> 00:22:43,675
Speaker 5:  Yes, I was about to say the same. Like,

405
00:22:43,675 --> 00:22:47,515
Speaker 6:  Manufacturers do rundown benchmark tests, all of them do this on laptops,

406
00:22:47,515 --> 00:22:51,035
Speaker 6:  mobile devices, whatever. Whether they're Apple, HP, Dell, whoever. And they

407
00:22:51,035 --> 00:22:54,915
Speaker 6:  will come out saying 22 hours of video playback time, which means

408
00:22:54,915 --> 00:22:58,515
Speaker 6:  nothing when my laptop dies in five hours of me using it

409
00:22:58,975 --> 00:22:59,195
Speaker 6:  for

410
00:22:59,195 --> 00:23:01,755
Speaker 5:  Work. 'cause you, you look at it and you see there's usually an asterisk

411
00:23:01,755 --> 00:23:03,915
Speaker 5:  and it's like, we've turned off the wifi, we've turned off the Bluetooth,

412
00:23:04,025 --> 00:23:07,475
Speaker 5:  weve turned off the video Soul video. Like yeah, we, we, the screen might

413
00:23:07,475 --> 00:23:11,395
Speaker 5:  not even be on, but we did it. And, and it's the same thing here

414
00:23:11,445 --> 00:23:14,795
Speaker 5:  where it is actually really, really hard to test a battery because there,

415
00:23:14,795 --> 00:23:18,475
Speaker 5:  because there are so many variables and in the same way there's so many

416
00:23:18,755 --> 00:23:22,355
Speaker 5:  variables with hallucination. So it's, it's like, it's really hard. They

417
00:23:22,355 --> 00:23:25,875
Speaker 5:  can't even figure out how to make something to test. If it's hallucinating,

418
00:23:25,875 --> 00:23:28,875
Speaker 5:  how are they gonna make a benchmark Yeah. To test if it's hallucinating.

419
00:23:29,225 --> 00:23:32,515
Speaker 4:  Yeah. I mean I I I think it is fascinating that they have a benchmark for

420
00:23:32,515 --> 00:23:35,915
Speaker 4:  understanding infographics. I think that's cool.

421
00:23:36,745 --> 00:23:40,595
Speaker 4:  Like someone had to come up with that benchmark. Yeah. And, and someone had

422
00:23:40,595 --> 00:23:44,475
Speaker 4:  to point out that Gemini Ultra gets an 80.3 on

423
00:23:44,475 --> 00:23:47,605
Speaker 4:  that benchmark. Nailed it. Whereas the s GPT four gets

424
00:23:47,605 --> 00:23:51,525
Speaker 4:  75.1. We can talk about the actual product. I'm, I'm focused on this

425
00:23:51,755 --> 00:23:55,605
Speaker 4:  because I think there's a tendency with all tech products to try

426
00:23:55,605 --> 00:23:59,325
Speaker 4:  to find some objective measure that will say that Apple is definitively better

427
00:23:59,325 --> 00:24:03,205
Speaker 4:  than Microsoft or whatever it is. Windows Drools.

428
00:24:03,435 --> 00:24:07,365
Speaker 4:  Yeah. Look at this benchmark. Like we live in it and I'm just

429
00:24:07,365 --> 00:24:11,245
Speaker 4:  trying to apply that instinctively to being shown some benchmarks.

430
00:24:11,665 --> 00:24:12,725
Speaker 4:  And I'm like, but I don't,

431
00:24:13,565 --> 00:24:17,285
Speaker 5:  I think it's so hard to do with AI because AI is like, especially large

432
00:24:17,485 --> 00:24:20,925
Speaker 5:  language models so nebulous. It is so vast,

433
00:24:21,135 --> 00:24:24,445
Speaker 5:  right? Yeah. Like, like the amount of stuff it's ingesting and then that

434
00:24:24,445 --> 00:24:26,325
Speaker 5:  it can like recreate is enormous.

435
00:24:26,665 --> 00:24:30,005
Speaker 4:  We are very close to being like, I'm gonna measure Gemini's skull and tell

436
00:24:30,005 --> 00:24:32,445
Speaker 4:  you how smart it is. Yeah. Right. Like it's, it's like

437
00:24:32,895 --> 00:24:35,965
Speaker 5:  Right there. It's like, oh, do we wanna do that?

438
00:24:36,665 --> 00:24:40,445
Speaker 4:  So there, there's just some, some weirdness here. But at the same time,

439
00:24:40,595 --> 00:24:44,285
Speaker 4:  knowing that one of these is good or worse at decoding infographics,

440
00:24:45,725 --> 00:24:49,685
Speaker 4:  I shared a, a post with Andrew Moreno, our engineer the other day, where

441
00:24:49,685 --> 00:24:52,925
Speaker 4:  someone was uploading all of the manuals to old Roland

442
00:24:52,925 --> 00:24:54,285
Speaker 4:  synthesizers to

443
00:24:54,285 --> 00:24:56,045
Speaker 5:  GP That would be something you two would talk about.

444
00:24:56,045 --> 00:24:59,965
Speaker 4:  And then asking it how to make the Sounds on Cure records. And

445
00:24:59,965 --> 00:25:02,845
Speaker 4:  it would just read the manual because those manuals are impenetrable. Yeah.

446
00:25:02,945 --> 00:25:06,885
Speaker 4:  And it would just like spit out some settings for various songs. That

447
00:25:06,885 --> 00:25:09,485
Speaker 4:  is the coolest shit in the entire world. Were were they accurate though?

448
00:25:09,765 --> 00:25:12,285
Speaker 4:  I don't know. It was just a threads post about somebody who was excited,

449
00:25:12,285 --> 00:25:15,885
Speaker 4:  but it was cool. but it's like, I'm certain it got closer than if you were

450
00:25:15,885 --> 00:25:19,645
Speaker 4:  just ice cold reading the manual. Right. Especially a manual

451
00:25:19,645 --> 00:25:21,685
Speaker 4:  that that that, that's impenetrable. I mean

452
00:25:21,705 --> 00:25:24,565
Speaker 6:  If it gave you some like Depeche mode settings when you asked for the Cure,

453
00:25:24,565 --> 00:25:25,965
Speaker 6:  that would not be very good. Right.

454
00:25:27,185 --> 00:25:30,425
Speaker 4:  I mean, that would cause a Holy War. Let's be fair. Careful. That's my point.

455
00:25:31,485 --> 00:25:35,305
Speaker 4:  But I, there's, there's some of that which I think is so cool that

456
00:25:35,305 --> 00:25:39,265
Speaker 4:  these tools can do. And don don't know how to

457
00:25:39,745 --> 00:25:42,865
Speaker 4:  evaluate a company telling me, I don't know how to make the connection between

458
00:25:43,245 --> 00:25:46,825
Speaker 4:  the, the benchmarks are better and the capabilities are better.

459
00:25:47,185 --> 00:25:50,025
Speaker 5:  I think it's because it's really, it's hard for them to do. So they're like,

460
00:25:50,025 --> 00:25:52,945
Speaker 5:  okay, well I can lean on benchmarks because this is like something I can

461
00:25:53,225 --> 00:25:56,385
Speaker 5:  actually say. I don't have to just be like, doesn't it feel nicer?

462
00:25:56,955 --> 00:25:59,585
Speaker 5:  Which you get a lot of times with with gadgets. Yeah. They always are like,

463
00:25:59,635 --> 00:26:03,425
Speaker 5:  gimme those, the subjective things. And largely with, with

464
00:26:03,765 --> 00:26:07,705
Speaker 5:  ai it is largely subjective. Like, okay, yeah, it's cool that it can do

465
00:26:07,705 --> 00:26:11,465
Speaker 5:  python and stuff better, but the the big stuff, the stuff that most people

466
00:26:11,465 --> 00:26:15,265
Speaker 5:  are gonna be using it for is all that the subjective stuff. And you can't

467
00:26:15,455 --> 00:26:19,345
Speaker 5:  test that. Like, it feels like you more have to do like a

468
00:26:19,505 --> 00:26:22,705
Speaker 5:  research project. Like it's more like anthropology or something, I feel like.

469
00:26:22,705 --> 00:26:26,665
Speaker 5:  Yeah. Than it is like mathematics and, and computations.

470
00:26:26,795 --> 00:26:29,785
Speaker 4:  Right. Do these models have different personalities? Right? Do they, are

471
00:26:29,785 --> 00:26:32,825
Speaker 4:  they better at different things? 'cause their cultures are like, you do start

472
00:26:32,825 --> 00:26:36,585
Speaker 4:  to get into some very deep questions about the nature of intelligence and

473
00:26:36,585 --> 00:26:40,385
Speaker 4:  then you're like, someone asked it if I was handsome and I was like,

474
00:26:40,625 --> 00:26:40,745
Speaker 4:  Hmm.

475
00:26:43,065 --> 00:26:45,845
Speaker 4:  It like literally said like, beauty is in the eye of the holder. And I was

476
00:26:45,845 --> 00:26:48,645
Speaker 4:  like, well you got a little bit of personality there. Whew.

477
00:26:50,105 --> 00:26:51,965
Speaker 5:  All. right. I see how it is. Damn.

478
00:26:52,155 --> 00:26:55,165
Speaker 4:  Yeah. It's like his contributions are vast but I No, no.

479
00:26:57,825 --> 00:27:00,045
Speaker 4:  So anyway, people should play with it. I'm curious what people think of it.

480
00:27:00,725 --> 00:27:04,445
Speaker 4:  There is obviously the future of Google's business

481
00:27:04,505 --> 00:27:08,305
Speaker 4:  is here, right? The future of the search business, which is the cash cow

482
00:27:08,305 --> 00:27:12,235
Speaker 4:  for Google is sitting right in this product. And I still

483
00:27:12,365 --> 00:27:16,085
Speaker 4:  don't know how that's gonna work. And I don't know if Google

484
00:27:16,265 --> 00:27:18,125
Speaker 4:  yet knows how it's gonna work. How is it

485
00:27:18,125 --> 00:27:21,245
Speaker 5:  Working in the Pixel? I haven't tried the Pixel version yet. And I'm just

486
00:27:21,245 --> 00:27:22,285
Speaker 5:  curious like, so

487
00:27:22,285 --> 00:27:25,565
Speaker 4:  The Pixel a pro is only, there's two things today. It's auto summarization

488
00:27:25,625 --> 00:27:29,165
Speaker 4:  in the recorder app and smart reply in the keyboard. Keyboard are now Gemini

489
00:27:29,195 --> 00:27:29,485
Speaker 4:  nano.

490
00:27:29,795 --> 00:27:31,685
Speaker 5:  Okay. Yeah. I mean,

491
00:27:33,215 --> 00:27:36,755
Speaker 4:  And you can really feel that 29th benchmark. Yeah. When you're using smart

492
00:27:36,755 --> 00:27:40,595
Speaker 4:  reply in the Yeah. Pixel a keyboard. I mean, look, those are auto

493
00:27:40,725 --> 00:27:42,755
Speaker 4:  reply, auto complete. That stuff is really important.

494
00:27:43,275 --> 00:27:44,635
Speaker 5:  That's true. That is true. Like, but

495
00:27:44,635 --> 00:27:48,565
Speaker 4:  The AI stuff they've been doing, the recorder app is neat. And like for,

496
00:27:48,825 --> 00:27:49,565
Speaker 4:  you know, a lot

497
00:27:49,565 --> 00:27:53,205
Speaker 5:  Of our reporters like it like, like a lot of our reporters are like, oh yeah,

498
00:27:53,205 --> 00:27:55,565
Speaker 5:  I'll use a Pixel phone to just record because don don't have to worry about

499
00:27:55,565 --> 00:27:59,045
Speaker 5:  all the variety, wide variety of transcription services

500
00:27:59,355 --> 00:28:02,885
Speaker 5:  that cost a lot of money and also use ai. Yeah. So you can just do it that

501
00:28:02,885 --> 00:28:06,805
Speaker 5:  way. That like, that's genuinely useful. But for a very small group of people,

502
00:28:06,945 --> 00:28:07,365
Speaker 5:  I'd imagine

503
00:28:07,745 --> 00:28:10,885
Speaker 4:  Google is always thinking about the, the, the journalists, hardworking journalists

504
00:28:10,985 --> 00:28:13,645
Speaker 4:  of the world when they make the Pixel features. But if you're recording a

505
00:28:13,645 --> 00:28:15,645
Speaker 4:  meeting and it summarizes the meaning for you and that gets meaningfully

506
00:28:15,645 --> 00:28:18,765
Speaker 4:  better. That's fair. That's great. And, and if that happens locally and you're

507
00:28:18,765 --> 00:28:22,565
Speaker 4:  not sending your enterprise work product off to a cloud

508
00:28:22,565 --> 00:28:24,045
Speaker 4:  service that's good for you

509
00:28:25,015 --> 00:28:27,565
Speaker 5:  Gonna do all my CES briefings this way. It's

510
00:28:27,565 --> 00:28:30,485
Speaker 4:  Just like, throw the phone down, be like, talk to this robot, let's go. It'll

511
00:28:30,605 --> 00:28:31,645
Speaker 4:  summarize what you have to say for me

512
00:28:33,465 --> 00:28:36,325
Speaker 4:  anyway. But that, so that's the big news of the week. Like this is the future

513
00:28:36,325 --> 00:28:39,645
Speaker 4:  of Google. You can just go play with Bard. It's neat.

514
00:28:40,155 --> 00:28:43,845
Speaker 4:  There's other AI news this week. So Bing Dear your Suite

515
00:28:43,875 --> 00:28:47,645
Speaker 4:  Bing announced something called Deep Search. So the

516
00:28:49,115 --> 00:28:52,245
Speaker 4:  Bing has always, I can't believe I'm say this, we started out with Dex. I'm

517
00:28:52,245 --> 00:28:56,205
Speaker 4:  going to go to Bing. There's always been one really fascinating part of the

518
00:28:56,235 --> 00:28:59,725
Speaker 4:  Bing search product as it relates to s GPT four.

519
00:28:59,925 --> 00:29:02,205
Speaker 5:  I just wanna sit with that sentence for a minute.

520
00:29:03,075 --> 00:29:06,925
Speaker 4:  It's, they've been doing So I don't know if it has been good or it's worked

521
00:29:06,945 --> 00:29:10,605
Speaker 4:  or it's taken one point of market share. But they've always been doing something

522
00:29:10,605 --> 00:29:13,365
Speaker 4:  really interesting, which they call search orchestration.

523
00:29:14,425 --> 00:29:17,485
Speaker 4:  Now what it's gonna do is take that one step farther. It's going to read

524
00:29:17,485 --> 00:29:21,285
Speaker 4:  your search query. Microsoft's example is how do point systems work in Japan.

525
00:29:21,555 --> 00:29:25,005
Speaker 4:  It's gonna figure out all the things that could mean, and it's gonna go search

526
00:29:25,005 --> 00:29:27,965
Speaker 4:  for those things and lace them together. So you can figure out if you mean

527
00:29:27,965 --> 00:29:31,725
Speaker 4:  credit card point system or weird social credit systems or whatever

528
00:29:31,885 --> 00:29:35,485
Speaker 4:  it is. And it's gonna lace this here so it'll take more time. But it's actually

529
00:29:35,485 --> 00:29:39,405
Speaker 4:  sort of like expanding your query for you. Yeah. And doing a

530
00:29:39,405 --> 00:29:42,325
Speaker 4:  bigger, deeper search of the web web. I mean it's, it's, which I think is

531
00:29:42,485 --> 00:29:42,965
Speaker 4:  fascinating. Yeah.

532
00:29:42,965 --> 00:29:45,565
Speaker 5:  I feel like, you know, looking at it and, and seeing what they did there.

533
00:29:45,765 --> 00:29:49,685
Speaker 5:  I think that's a great example of the loyalty programs because it is something

534
00:29:49,685 --> 00:29:53,645
Speaker 5:  huge. It is nebulous. And if you don't have like the card, the

535
00:29:53,645 --> 00:29:57,205
Speaker 5:  points guy or whatever for, for your region, that is

536
00:29:57,315 --> 00:30:01,125
Speaker 5:  genuinely useful. You want that, that summary and, and like

537
00:30:01,145 --> 00:30:04,565
Speaker 5:  that's hard to do on your own. Yeah, you can, but it's obnoxious.

538
00:30:04,705 --> 00:30:07,525
Speaker 4:  So what's really fascinating to me about this is that

539
00:30:08,635 --> 00:30:11,935
Speaker 4:  if you'll remember when when Chat s GPT launched and Bing launched, there

540
00:30:11,935 --> 00:30:15,535
Speaker 4:  was that explosion of interest in prompt engineering. Yeah. And we

541
00:30:16,195 --> 00:30:19,295
Speaker 4:  had lots of conversations with people, lots of executives are on decoder

542
00:30:19,295 --> 00:30:21,935
Speaker 4:  saying Prompt engineering is just a thing that's gonna happen in the middle.

543
00:30:22,705 --> 00:30:24,335
Speaker 4:  There need to be other, well join

544
00:30:25,285 --> 00:30:27,215
Speaker 5:  Just did that great piece on, on prompt engineering.

545
00:30:27,245 --> 00:30:30,815
Speaker 4:  Yeah. And everyone, there's this theory that that's like a local, that's

546
00:30:30,815 --> 00:30:33,775
Speaker 4:  like a flash in the pan moment. Yes. And then you look at what Deep Search

547
00:30:33,775 --> 00:30:37,415
Speaker 4:  is doing and it is mechanically taking your query

548
00:30:37,595 --> 00:30:41,375
Speaker 4:  to the Bing search engine and rewriting it to be a longer prompt.

549
00:30:41,755 --> 00:30:45,215
Speaker 4:  So it takes, how do point systems work in Japan and it

550
00:30:45,855 --> 00:30:49,655
Speaker 4:  rewrites the prompt to Bing as provide an explanation for how various loyalty

551
00:30:49,685 --> 00:30:52,495
Speaker 4:  card programs work in Japan, including the benefits requirements, limitations

552
00:30:52,495 --> 00:30:56,375
Speaker 4:  each. And then it goes on, it's like a full paragraph long prompt. And you

553
00:30:56,375 --> 00:31:00,175
Speaker 4:  see that Microsoft has learned that it, it should just automate

554
00:31:00,175 --> 00:31:04,015
Speaker 4:  prompt engineering for you. And that's how it should constantly talk to the

555
00:31:04,325 --> 00:31:05,255
Speaker 4:  LLMs. It's

556
00:31:05,255 --> 00:31:07,055
Speaker 6:  A, it's another job claimed by AI

557
00:31:08,285 --> 00:31:10,175
Speaker 5:  Created and claimed in the same year.

558
00:31:11,155 --> 00:31:15,015
Speaker 4:  And you know, now that we know more about particularly how, how Bing

559
00:31:15,065 --> 00:31:18,975
Speaker 4:  works, like the huge Meta prompt that it feeds into s

560
00:31:19,075 --> 00:31:23,055
Speaker 4:  GPT is crazy. That's just that the one that killed Sydney

561
00:31:23,125 --> 00:31:26,735
Speaker 4:  basically. Yeah. And killed the personality and puts the guide rails is just

562
00:31:26,775 --> 00:31:30,725
Speaker 4:  a Meta prompt that is appended to your query. And

563
00:31:30,725 --> 00:31:34,605
Speaker 4:  So don don't know if that's how Google is managing Bard. don don't know.

564
00:31:34,605 --> 00:31:38,125
Speaker 4:  Like that's how they all work. But this is very much how Microsoft is starting

565
00:31:38,125 --> 00:31:42,045
Speaker 4:  to manage Bing, which is fascinating. It's hysterical.

566
00:31:42,865 --> 00:31:45,885
Speaker 4:  And this of this deep search tool just like kind of an extension of that.

567
00:31:45,955 --> 00:31:46,245
Speaker 4:  Yeah.

568
00:31:46,355 --> 00:31:50,005
Speaker 5:  Well, and I appreciate that. It's, it's pretty candid about it. I'm curious

569
00:31:50,075 --> 00:31:53,725
Speaker 5:  like in practice how often it's gonna show you that whole search prompt so

570
00:31:53,725 --> 00:31:57,325
Speaker 5:  that eventually you, you can figure that out and be like, okay, well So I,

571
00:31:57,325 --> 00:32:00,525
Speaker 5:  just do a whole paragraph now instead of being like, tell me how to fix it.

572
00:32:01,735 --> 00:32:04,885
Speaker 5:  Which is probably useful for people. Yeah. I mean I would do that. I don't

573
00:32:04,885 --> 00:32:07,405
Speaker 5:  know. I'm sure most people would just be like, tell me how to fix it. 'cause

574
00:32:07,405 --> 00:32:08,805
Speaker 5:  that's faster and easier. But yeah.

575
00:32:08,805 --> 00:32:12,765
Speaker 4:  So, but The race to to, to your point Yeah. The race, to

576
00:32:12,765 --> 00:32:16,605
Speaker 4:  just answer the question continues a pace. And I think for Google,

577
00:32:17,105 --> 00:32:20,765
Speaker 4:  the Gemini stuff is exciting. It shows they're in the game. They're, they're

578
00:32:20,765 --> 00:32:23,885
Speaker 4:  excited about it. Very obviously Sundar, you know, did a press tour, the

579
00:32:23,885 --> 00:32:26,965
Speaker 4:  whole thing. But how they turn that into money is still a huge open question.

580
00:32:27,635 --> 00:32:31,445
Speaker 4:  Yeah. And I, I just dunno the answer. But if the end result is you ask the

581
00:32:31,445 --> 00:32:34,525
Speaker 4:  LMA question, it just tells you the answer, whether it's going through this

582
00:32:34,525 --> 00:32:38,325
Speaker 4:  like secondary prompt engineering exercise or not. Or it's passing the

583
00:32:38,325 --> 00:32:40,765
Speaker 4:  hella swag test Yeah. Or whatever it's doing.

584
00:32:42,315 --> 00:32:45,605
Speaker 4:  They gotta put ads in there somewhere. They gotta, they gotta make some money.

585
00:32:46,045 --> 00:32:49,685
Speaker 4:  I have seen some people say they think that Gemini Ultra will be a

586
00:32:49,925 --> 00:32:53,285
Speaker 4:  subscription product the way that s GPT four is a subscription product. s

587
00:32:53,285 --> 00:32:54,925
Speaker 4:  GPT 3.5 is not, or hell

588
00:32:55,075 --> 00:32:56,885
Speaker 5:  Grok is a subscription product.

589
00:32:57,465 --> 00:33:00,325
Speaker 4:  Gr also launched this week. Yeah, don't, it's fine.

590
00:33:02,115 --> 00:33:05,405
Speaker 4:  Last two little bits of AI news, lemme take a break. Apple also made some

591
00:33:05,405 --> 00:33:08,725
Speaker 4:  AI news this week, which is the first time Apple has made any AI news

592
00:33:09,325 --> 00:33:09,645
Speaker 4:  really?

593
00:33:10,405 --> 00:33:10,645
Speaker 5:  Baby

594
00:33:10,645 --> 00:33:14,365
Speaker 4:  Steps, baby steps. They released a new model framework called MLX

595
00:33:14,995 --> 00:33:18,525
Speaker 4:  that allows you to run various kinds of models and various

596
00:33:19,005 --> 00:33:22,885
Speaker 4:  coding languages like PyTorch on their chips using their

597
00:33:22,885 --> 00:33:24,085
Speaker 4:  memory architecture ideas.

598
00:33:24,485 --> 00:33:27,245
Speaker 5:  I bet that was an internal tool that they're like, it's good enough, we can

599
00:33:27,245 --> 00:33:30,525
Speaker 5:  now make it public. Because they, that that's been a big deal at Apple is

600
00:33:30,715 --> 00:33:34,045
Speaker 5:  they don't wanna actually use all the other AI tools, but they want their

601
00:33:34,125 --> 00:33:37,525
Speaker 5:  own a to I tools. Yeah. So they've been having to like, how do we build our

602
00:33:37,525 --> 00:33:40,725
Speaker 5:  own Bard and Gemini and

603
00:33:40,995 --> 00:33:41,285
Speaker 4:  Yeah.

604
00:33:41,945 --> 00:33:43,245
Speaker 5:  Why are these names all well,

605
00:33:43,245 --> 00:33:47,205
Speaker 4:  And Apple is also leaning more into the open source world. Yeah. So

606
00:33:47,265 --> 00:33:50,405
Speaker 4:  if you are, if you, you know, you're open source researcher, you want to

607
00:33:50,405 --> 00:33:54,085
Speaker 4:  use Meta's Llama, which is open source, you wanna run an Apple silicon, you

608
00:33:54,085 --> 00:33:57,405
Speaker 4:  now have a framework to do that that Apple is providing and supporting. Will

609
00:33:57,405 --> 00:33:59,205
Speaker 4:  that get you anywhere? Like, I, I don't know,

610
00:33:59,465 --> 00:34:03,125
Speaker 5:  I'm curious to see how well the Silicon handles it because just how

611
00:34:03,125 --> 00:34:07,005
Speaker 5:  different all the different architectures handle ai. And it's particularly

612
00:34:07,005 --> 00:34:10,805
Speaker 5:  like that stuff is like the Apple silicon is

613
00:34:10,805 --> 00:34:14,645
Speaker 5:  very specifically built for a specific type of processing and it's good at

614
00:34:14,645 --> 00:34:17,165
Speaker 5:  the other stuff. We've seen how good it's with video. And I'm just really

615
00:34:17,165 --> 00:34:20,925
Speaker 5:  curious if that translates as like GPU kind of translates. I

616
00:34:20,925 --> 00:34:24,045
Speaker 4:  Think you're right. Like Apple has very particular GPU ideas. Yes. But they

617
00:34:24,045 --> 00:34:27,365
Speaker 4:  also have very particular neural engine ideas. Yeah. And we, we've just never

618
00:34:27,365 --> 00:34:31,045
Speaker 4:  seen anyone attack that part of their chip to go head head-to-head with like

619
00:34:31,045 --> 00:34:32,445
Speaker 4:  an Nvidia. Yeah. Because

620
00:34:32,705 --> 00:34:36,085
Speaker 5:  AI g Yeah. All they have to do is is say like, yeah, it it opens your phone

621
00:34:36,085 --> 00:34:38,765
Speaker 5:  real fast. It's really good at it and it's super smart and it's like, cool.

622
00:34:39,405 --> 00:34:42,125
Speaker 5:  I have no way to ever test any Apple product. That's why we do,

623
00:34:42,125 --> 00:34:43,765
Speaker 4:  Here's what you do. You run shadow of the tune. Yeah.

624
00:34:43,765 --> 00:34:46,365
Speaker 5:  I was like, that's why we got shadows of the tomb reader. It's the only thing

625
00:34:46,365 --> 00:34:49,445
Speaker 5:  that works, the only way to test an Apple product.

626
00:34:49,675 --> 00:34:52,845
Speaker 4:  Okay. And then the last little piece of AI news, I will just remind everyone

627
00:34:52,845 --> 00:34:56,805
Speaker 4:  again and again and again, these companies are running rampant with

628
00:34:56,805 --> 00:35:00,725
Speaker 4:  copyrighted information to train their systems. No one knows if

629
00:35:00,725 --> 00:35:04,645
Speaker 4:  it's legal. They're insistent that they are, but all of them, all

630
00:35:04,645 --> 00:35:08,605
Speaker 4:  of this money coin flip fair use lawsuit could take it

631
00:35:08,605 --> 00:35:12,325
Speaker 4:  all down. It is just true. It's, it's a total coin

632
00:35:12,355 --> 00:35:16,085
Speaker 4:  flip. You might have some opinions. I have some opinions. Our company has

633
00:35:16,085 --> 00:35:20,005
Speaker 4:  some opinions. Hai has some opinions. I know s Andela

634
00:35:20,025 --> 00:35:23,205
Speaker 4:  has some opinion. I've asked all of them and they're like, yeah, the legal

635
00:35:23,205 --> 00:35:27,125
Speaker 4:  process will have to pay out Getty's lawsuit, Getty

636
00:35:27,125 --> 00:35:31,045
Speaker 4:  image's, lawsuit against Stability. AI is not going go into trial in the

637
00:35:31,065 --> 00:35:34,525
Speaker 4:  UK. And they obviously have suit here too. The law in the UK different than

638
00:35:34,525 --> 00:35:38,445
Speaker 4:  the in United States. This is just a gigantic time

639
00:35:38,475 --> 00:35:41,885
Speaker 4:  bomb in the middle of the AI boom. Yeah. Is that no one knows that this training

640
00:35:41,885 --> 00:35:45,645
Speaker 4:  data is very used. Again, I I have an opinion. I think it is

641
00:35:45,885 --> 00:35:49,805
Speaker 4:  probably not. And I am not that person. That's not

642
00:35:49,805 --> 00:35:53,525
Speaker 4:  how it came up at all. That's not that it's a surprising opinion

643
00:35:53,585 --> 00:35:57,325
Speaker 4:  for me. But the idea that you can just take all of this stuff just to

644
00:35:57,325 --> 00:36:01,125
Speaker 4:  hoover it up and somehow create billions of dollars of value for your

645
00:36:01,125 --> 00:36:01,845
Speaker 4:  users out of it.

646
00:36:02,315 --> 00:36:03,125
Speaker 5:  That seems wrong

647
00:36:03,275 --> 00:36:06,645
Speaker 4:  Without any, any return just on its face.

648
00:36:07,305 --> 00:36:10,125
Speaker 4:  It seems like you're gonna go to a court without argument and something there

649
00:36:10,125 --> 00:36:13,845
Speaker 4:  is gonna happen that you cannot predict. Yeah. Weird. Just we, and so we'll

650
00:36:13,845 --> 00:36:16,245
Speaker 4:  see. I don't know. don don't know. And the courts are not predictable.

651
00:36:17,105 --> 00:36:20,365
Speaker 5:  You're, we're all gonna get like 50 cents for our tweets. Yeah.

652
00:36:20,505 --> 00:36:21,125
Speaker 4:  That's what's gonna

653
00:36:21,125 --> 00:36:24,045
Speaker 5:  Happen. Sorry. Here's your 50 cents. We used your tweets.

654
00:36:24,045 --> 00:36:26,725
Speaker 4:  Google has to send you a penny Every time anybody uses Bar

655
00:36:26,905 --> 00:36:29,445
Speaker 5:  Man. Those, those, those fanfic writers gonna make bank

656
00:36:29,625 --> 00:36:32,765
Speaker 4:  And the lawsuits are just gonna keep happening because in particular in this

657
00:36:32,765 --> 00:36:36,365
Speaker 4:  country, fair use is not a precedent setting decision.

658
00:36:36,615 --> 00:36:40,085
Speaker 4:  Every single fair use case evaluated on its merits de novo, like

659
00:36:40,675 --> 00:36:44,245
Speaker 4:  it's supposed to be case by case. It's in the law. So you can just keep filing

660
00:36:44,345 --> 00:36:46,525
Speaker 4:  the lawsuits until something else happens. Could

661
00:36:46,685 --> 00:36:48,085
Speaker 5:  Somebody just make a law at some point?

662
00:36:48,925 --> 00:36:52,885
Speaker 4:  I one would hope I don Dunno if you've been paying attention to

663
00:36:52,885 --> 00:36:53,805
Speaker 4:  the state of our government,

664
00:36:55,075 --> 00:36:55,605
Speaker 5:  Just fix

665
00:36:55,605 --> 00:36:58,845
Speaker 4:  It. Doesn't seem one day doesn't seem likely. One

666
00:36:58,845 --> 00:36:59,005
Speaker 5:  Day

667
00:36:59,505 --> 00:37:02,365
Speaker 4:  George Santos is on cameo. That's the state of our government.

668
00:37:02,755 --> 00:37:03,925
Speaker 5:  He's not in the government anymore.

669
00:37:03,995 --> 00:37:05,565
Speaker 4:  Well, he's on cameo. Yeah.

670
00:37:05,715 --> 00:37:07,085
Speaker 5:  Just good pivot.

671
00:37:07,345 --> 00:37:10,765
Speaker 4:  All, right. We gotta take a break. I'm gonna sign up for Cameo. We'll be

672
00:37:10,765 --> 00:37:11,045
Speaker 4:  right back.

673
00:39:22,075 --> 00:39:25,655
Speaker 4:  All right? We're back. All, right? We're, we're off the AI Benchmark news.

674
00:39:25,655 --> 00:39:28,175
Speaker 4:  Yeah, we're done. Now it's time for hacks. We're hacks

675
00:39:28,355 --> 00:39:28,575
Speaker 6:  And

676
00:39:28,575 --> 00:39:32,535
Speaker 4:  Snacks, hacks and freaks with a pH. Actually a pretty

677
00:39:32,535 --> 00:39:35,975
Speaker 4:  important, what would you call it, Dan? A workaround.

678
00:39:36,775 --> 00:39:40,575
Speaker 6:  Reverse engineering workaround. Yeah. Yeah. But there's like solution.

679
00:39:40,805 --> 00:39:43,375
Speaker 6:  There's some spoofing happening there too, right?

680
00:39:43,605 --> 00:39:47,535
Speaker 4:  Yeah. Okay, Sonos, let's get into it. Sorry. So Beeper, which is a long

681
00:39:47,895 --> 00:39:51,615
Speaker 4:  standing iMessage workaround that for

682
00:39:51,865 --> 00:39:55,575
Speaker 4:  years basically until just recently involved you signing into

683
00:39:56,125 --> 00:39:59,455
Speaker 4:  your iCloud account on a Mac Mini in the cloud as a relay service

684
00:40:00,395 --> 00:40:04,295
Speaker 4:  now has reversed engineered iMessage and they say they can

685
00:40:04,295 --> 00:40:06,095
Speaker 4:  do it natively. Dan, what's going on here? Yeah,

686
00:40:06,155 --> 00:40:10,015
Speaker 6:  So it's a, it's a fascinating story as, as Neli

687
00:40:10,015 --> 00:40:13,735
Speaker 6:  just said, you know, beeper's been around for a while, but over the

688
00:40:13,735 --> 00:40:17,535
Speaker 6:  summer a developer posted proof of

689
00:40:17,535 --> 00:40:21,015
Speaker 6:  concept to GitHub that they had reverse engineered the

690
00:40:21,015 --> 00:40:24,215
Speaker 6:  iMessage protocol and was able to send messages directly from

691
00:40:24,685 --> 00:40:27,935
Speaker 6:  basically any device Linux Windows, Android,

692
00:40:28,835 --> 00:40:32,175
Speaker 6:  two Apple's iMessage servers without having to use a relay server.

693
00:40:32,835 --> 00:40:36,495
Speaker 6:  And when Beeper found out about this Beeper, who is

694
00:40:36,775 --> 00:40:40,215
Speaker 6:  headed by former Pebble, CEO, Eric Micki

695
00:40:40,215 --> 00:40:41,255
Speaker 4:  Pebble, the smartwatch company,

696
00:40:41,315 --> 00:40:43,975
Speaker 6:  Pebble the Smartwatch. Yes, you do have to clarify. There are like eight

697
00:40:43,975 --> 00:40:47,855
Speaker 6:  failed Pebbles. Now don't name your future company Pebble. That's all

698
00:40:48,195 --> 00:40:51,615
Speaker 6:  my, my advice to anyone. He reached out to this developer,

699
00:40:51,975 --> 00:40:55,215
Speaker 6:  contracted with him, turns out it's a 16-year-old high school kid. Yes.

700
00:40:55,625 --> 00:40:58,815
Speaker 6:  Hires him Part-time to develop this into

701
00:40:59,735 --> 00:41:03,655
Speaker 6:  a full fledged app. So now what we have today is a new app

702
00:41:03,775 --> 00:41:07,615
Speaker 6:  called, they're calling it Beeper. Mini for now it is an iMessage client

703
00:41:07,615 --> 00:41:11,015
Speaker 6:  for Android. And it is exactly what that says. It is

704
00:41:11,715 --> 00:41:15,655
Speaker 6:  you, you install it on your Android phone. You don't even have to sign in

705
00:41:15,655 --> 00:41:19,375
Speaker 6:  with an Apple id. It talks to Apple servers, takes your phone number

706
00:41:19,435 --> 00:41:23,095
Speaker 6:  and turns it into a blue bubble on IO iOS

707
00:41:23,095 --> 00:41:26,775
Speaker 6:  devices or Mac, whoever you're messaging. And it does it all locally

708
00:41:26,775 --> 00:41:30,495
Speaker 6:  without a server relay server involved. And the way that they kind of reverse

709
00:41:30,735 --> 00:41:33,805
Speaker 6:  engineered it is a fascinating process. I strongly, strongly recommend going

710
00:41:33,805 --> 00:41:37,685
Speaker 6:  to check out Snazzy Hugh's video on it because he explains step by step,

711
00:41:37,985 --> 00:41:41,725
Speaker 6:  and frankly it's above my head how it all works. But they end up

712
00:41:41,965 --> 00:41:45,925
Speaker 6:  spoofing serial numbers of real Apple devices, which

713
00:41:45,925 --> 00:41:49,125
Speaker 6:  is a technique that's been around for a long time in the Macintosh world

714
00:41:49,505 --> 00:41:53,485
Speaker 6:  and in other applications in order to get Apple software to run on things

715
00:41:53,485 --> 00:41:57,165
Speaker 6:  that maybe Apple doesn't formally approve. Apple's kind of just

716
00:41:57,165 --> 00:42:00,885
Speaker 6:  always ignored it and left it alone. But they're using this now

717
00:42:00,945 --> 00:42:04,765
Speaker 6:  to basically spoof iMessage onto Android and allow you to

718
00:42:04,785 --> 00:42:08,245
Speaker 6:  be having completely, you know, full, fully

719
00:42:08,315 --> 00:42:12,285
Speaker 6:  supported, for the most part, bluebe conversations on an Android phone.

720
00:42:12,345 --> 00:42:15,685
Speaker 6:  And it's, it's fascinating 'cause It works incredibly well. Yeah, because

721
00:42:15,785 --> 00:42:18,805
Speaker 5:  You've used it Jake I know who wrote the piece Yeah. Has been using it and

722
00:42:18,805 --> 00:42:19,645
Speaker 5:  you, you really like it.

723
00:42:19,925 --> 00:42:23,085
Speaker 6:  I think it's great. Like I, I was, I, I switched my sim fully

724
00:42:23,635 --> 00:42:27,445
Speaker 6:  from an iPhone to an Android phone and nobody noticed,

725
00:42:27,755 --> 00:42:31,525
Speaker 6:  like nothing skipped a beat. Like I am still a blue bubble to all of the

726
00:42:31,525 --> 00:42:35,485
Speaker 6:  iPhone contacts I've ever had. And now I can message with

727
00:42:35,565 --> 00:42:39,365
Speaker 6:  RCS and Google Messages app to Android users and

728
00:42:39,805 --> 00:42:43,285
Speaker 6:  I like don't get left outta group messages. I don't get missed

729
00:42:43,285 --> 00:42:47,245
Speaker 6:  notifications on reactions. I, if I wanted to send voice

730
00:42:47,245 --> 00:42:50,965
Speaker 6:  messages I could. Like all of those features are supported. It's just

731
00:42:51,205 --> 00:42:51,485
Speaker 6:  fascinating

732
00:42:51,555 --> 00:42:54,525
Speaker 5:  When somebody says congratulations. Do you also now get the balloons

733
00:42:54,865 --> 00:42:58,685
Speaker 6:  So you don't get the iMessage reactions? I think that's called, you

734
00:42:58,685 --> 00:43:01,885
Speaker 6:  don't hit that. I believe they said they were working on that. They're working

735
00:43:01,885 --> 00:43:05,765
Speaker 6:  on actually integrating FaceTime somehow, which I don't know how

736
00:43:05,765 --> 00:43:09,605
Speaker 6:  they're gonna do. And the one thing that they don't ever anticipate ever

737
00:43:09,605 --> 00:43:12,325
Speaker 6:  being able to support are the iMessage apps and games which,

738
00:43:12,785 --> 00:43:13,485
Speaker 5:  Oh no, sorry,

739
00:43:13,515 --> 00:43:14,245
Speaker 6:  Yeah. Big loss.

740
00:43:14,705 --> 00:43:16,965
Speaker 4:  Oh no, not iMessage Apps and games. The

741
00:43:16,965 --> 00:43:20,885
Speaker 6:  IMessage experience that most people think about on their

742
00:43:20,885 --> 00:43:23,325
Speaker 6:  iPhones is now fully replicated on Android.

743
00:43:23,595 --> 00:43:27,525
Speaker 4:  What happens if you have a mixed group of some Android phones,

744
00:43:27,875 --> 00:43:30,645
Speaker 4:  some Beeper Mini and some iPhones, you just fall back to

745
00:43:30,765 --> 00:43:34,085
Speaker 6:  Sms. So the Beeper Mini is going to act as an iMessage in that and the iPhones

746
00:43:34,085 --> 00:43:36,325
Speaker 6:  are gonna act as an iMessage in that and everything's just gonna fall back

747
00:43:36,325 --> 00:43:39,885
Speaker 6:  to SMS. And so that would go through your SMS app, probably Google

748
00:43:39,885 --> 00:43:43,245
Speaker 6:  messages on your Android phone. 'cause it's just gonna be an SMS conversation

749
00:43:43,475 --> 00:43:47,085
Speaker 5:  When you text someone, are you getting the texts both to your Bieber app

750
00:43:47,145 --> 00:43:49,485
Speaker 5:  and to the regular text app? No. Oh, that's

751
00:43:49,485 --> 00:43:53,365
Speaker 6:  Cool. If you are iMessaging someone that see the app can like tell if

752
00:43:53,365 --> 00:43:57,285
Speaker 6:  you're talking to an iMessage client and so it

753
00:43:57,285 --> 00:44:01,085
Speaker 6:  just, your iMessage conversation stays entirely within Ber Mini. If someone

754
00:44:01,135 --> 00:44:04,925
Speaker 6:  sends you a text message, it will come through your text

755
00:44:04,925 --> 00:44:07,445
Speaker 6:  message number through Google Messages. So,

756
00:44:07,835 --> 00:44:11,405
Speaker 5:  Well, I was, I was thinking like the, the, the, the, the example Neil I had

757
00:44:11,405 --> 00:44:14,405
Speaker 5:  where he was like, okay, what happens if you've got a Beeper person and an

758
00:44:14,405 --> 00:44:18,285
Speaker 5:  Android person and an i i iMessage person? Then where

759
00:44:18,285 --> 00:44:20,725
Speaker 5:  does that message, like it goes to the Beeper app because

760
00:44:20,945 --> 00:44:23,325
Speaker 4:  No, it goes to ssm it falls back to it.

761
00:44:23,325 --> 00:44:26,885
Speaker 6:  It you in that scenario, you the Beeper Mini user are using

762
00:44:27,125 --> 00:44:31,005
Speaker 6:  SMS. Yeah. And so the, the, like, the annoying part of this is that you

763
00:44:31,085 --> 00:44:34,165
Speaker 6:  now have two apps for messaging. You have your iMessage app and you have

764
00:44:34,165 --> 00:44:37,965
Speaker 6:  your Google Messages app. And beeper's plan is

765
00:44:37,965 --> 00:44:41,605
Speaker 6:  to, the original Beeper app was like, kind of like an an all in one message

766
00:44:41,605 --> 00:44:45,005
Speaker 6:  service. So all it integrated all of your message services. Beeper Mini is

767
00:44:45,125 --> 00:44:48,245
Speaker 6:  strictly iMessage for now. Their plan is to integrate all of those other

768
00:44:48,355 --> 00:44:51,845
Speaker 6:  plugins into the Mini app, eventually drop the Mini name

769
00:44:52,345 --> 00:44:55,925
Speaker 6:  and Sunset. The old app is the, the ultimate plan. But for today you, you're

770
00:44:55,925 --> 00:44:56,485
Speaker 6:  using two apps

771
00:44:56,745 --> 00:44:59,765
Speaker 4:  And the claim here, which I think is important, we don't know if it's true,

772
00:44:59,785 --> 00:45:03,605
Speaker 4:  but the claim is that Apple can't stop it without completely rebuilding the

773
00:45:03,605 --> 00:45:04,525
Speaker 4:  iMessage protocol. Yeah.

774
00:45:05,745 --> 00:45:09,405
Speaker 5:  I'm I'm really curious. I think because I keep getting stuck on the spoofing

775
00:45:09,405 --> 00:45:12,685
Speaker 5:  part of this, like with Hack Andt toss, I used to, I I built a lot of Hack

776
00:45:12,685 --> 00:45:16,605
Speaker 5:  Andt tos when I was younger. I love it. It's a fairly small community. So

777
00:45:16,605 --> 00:45:18,205
Speaker 5:  it was like, okay Apple, we, we were all like, well

778
00:45:18,205 --> 00:45:20,805
Speaker 4:  Apple, the police are coming now. Yeah. We understand that Craig Gregory

779
00:45:20,805 --> 00:45:22,845
Speaker 4:  just was listening to this. He just called the police. Yeah.

780
00:45:23,185 --> 00:45:25,645
Speaker 5:  My poor dog's getting arrested as we speak at home.

781
00:45:27,345 --> 00:45:30,885
Speaker 5:  But, but it was, it was super easy to do. It was a lot of fun. but it was

782
00:45:30,885 --> 00:45:34,085
Speaker 5:  also understood that like, it's a very small community so it wasn't really

783
00:45:34,125 --> 00:45:37,205
Speaker 5:  a big deal and it wasn't like a bunch of money was exchanging hands. You

784
00:45:37,205 --> 00:45:39,925
Speaker 5:  weren't being like, build me a Macintosh. 'cause as soon as you did that,

785
00:45:40,295 --> 00:45:41,845
Speaker 5:  apple came down. You own like

786
00:45:41,845 --> 00:45:45,605
Speaker 6:  Well, so the difference there is with Hack andt tos, it's usually you have

787
00:45:45,605 --> 00:45:49,245
Speaker 6:  to go acquire Apple's software and install it on a device

788
00:45:49,385 --> 00:45:53,365
Speaker 6:  and there's no real legal way to get that software

789
00:45:53,365 --> 00:45:57,175
Speaker 6:  if you're getting like OSS 10 leopard or whatever. Yeah.

790
00:45:57,205 --> 00:46:00,095
Speaker 6:  Without getting it from Apple. And Apple's not gonna give it to you if You

791
00:46:00,095 --> 00:46:02,855
Speaker 6:  don't have a max. So you have to like basically torrent it. Well

792
00:46:02,855 --> 00:46:06,455
Speaker 5:  That's why we all, like everybody I knew who did it had a Mac,

793
00:46:06,675 --> 00:46:09,735
Speaker 5:  we just wanted to also have a tiny Dell latitude that

794
00:46:09,875 --> 00:46:11,095
Speaker 4:  Can I, can I tell you a story from a youth?

795
00:46:11,725 --> 00:46:12,015
Speaker 5:  Yeah.

796
00:46:12,355 --> 00:46:15,655
Speaker 4:  So there was a company in Florida called S Star. Do you remember this? Yes,

797
00:46:15,735 --> 00:46:19,095
Speaker 4:  I do. And it was like two kids and they figured out how to build Macintosh's

798
00:46:19,315 --> 00:46:23,135
Speaker 4:  and they did in early like internet marketing

799
00:46:23,335 --> 00:46:26,735
Speaker 4:  campaign where like, take down the man run OSS 10 on yours side star, we

800
00:46:26,735 --> 00:46:30,505
Speaker 4:  can do it. And they had all these like I would call them

801
00:46:30,565 --> 00:46:34,545
Speaker 4:  Reddit caliber legal theories Yes. About how it would be legal and how

802
00:46:34,545 --> 00:46:38,185
Speaker 4:  they would defeat Apple in court and they would, you know, I had a s side

803
00:46:38,185 --> 00:46:42,065
Speaker 4:  star review, a S star for End Gadget. It was just a pc. Yeah,

804
00:46:42,245 --> 00:46:45,665
Speaker 4:  it was, I was like, I was like, what am I supposed to review here? Like it

805
00:46:45,665 --> 00:46:49,545
Speaker 4:  was just a noisy ass tower PC that like sometimes

806
00:46:49,755 --> 00:46:51,745
Speaker 4:  boots up into OSS 10. That's what

807
00:46:51,745 --> 00:46:52,065
Speaker 5:  I used

808
00:46:52,065 --> 00:46:56,025
Speaker 4:  To build and sometimes does nothing. It it

809
00:46:56,025 --> 00:46:59,025
Speaker 4:  was exciting. But they had all these theories that like if you owned a copy

810
00:46:59,045 --> 00:47:03,025
Speaker 4:  of the operating system, you weren't committing copyright

811
00:47:03,025 --> 00:47:04,985
Speaker 4:  infringement or breaching the contract by

812
00:47:04,985 --> 00:47:08,865
Speaker 5:  That's what we would all say in the, it was like Tony Mack 86 X

813
00:47:08,875 --> 00:47:12,225
Speaker 5:  forum Yeah. Or whatever. We'd all be like, oh yeah, yeah, we're we're fine

814
00:47:12,225 --> 00:47:15,385
Speaker 5:  because we already own it. Like, I went out and I had, I had the physical

815
00:47:15,385 --> 00:47:19,345
Speaker 5:  copy of each DV cd Yeah. For the OSS that you could have until they stopped

816
00:47:19,985 --> 00:47:23,905
Speaker 5:  distributing 'em. And we were like, we got this. But we also generally,

817
00:47:23,965 --> 00:47:26,025
Speaker 5:  unlike S Star, weren't charging for it.

818
00:47:26,325 --> 00:47:29,525
Speaker 4:  No S star is like charging money and got but this, this is like, like folk

819
00:47:29,635 --> 00:47:33,445
Speaker 4:  copyright law. Yeah. Like you've convinced yourself that if you just

820
00:47:33,465 --> 00:47:37,405
Speaker 4:  buy the CD you can make, you can send as many MP threes to your

821
00:47:37,405 --> 00:47:38,605
Speaker 4:  friends as you want. Yeah. It is.

822
00:47:38,835 --> 00:47:42,125
Speaker 5:  Same thing with torrents. They're always like, no, no, we're fine. We're

823
00:47:42,125 --> 00:47:45,405
Speaker 4:  Fine. Yeah. And it, and it is all just like you're, you are concocting like

824
00:47:45,445 --> 00:47:49,365
Speaker 4:  a moral argument that somewhere some money has

825
00:47:49,365 --> 00:47:50,765
Speaker 4:  changed hands. So, I can do whatever think

826
00:47:50,765 --> 00:47:52,045
Speaker 5:  Clarence Thomas will ignore. Yeah.

827
00:47:52,155 --> 00:47:54,085
Speaker 4:  It's Who knows what's gonna happen man.

828
00:47:55,705 --> 00:47:58,925
Speaker 4:  But, but my end of mys star story is they, they pitched themselves a bunch

829
00:47:59,065 --> 00:48:01,565
Speaker 4:  and they, you know, they were compelling. They were like young kids. They

830
00:48:01,565 --> 00:48:03,685
Speaker 4:  started a business, they were taking on the man. They gotten all this attention

831
00:48:04,185 --> 00:48:07,805
Speaker 4:  and some like local Florida Alt Weekly

832
00:48:08,695 --> 00:48:12,245
Speaker 4:  wrote this piece about how they were taken on Apple and who knew what happened.

833
00:48:12,265 --> 00:48:15,525
Speaker 4:  Oh. And So I wrote it up in Eng Gadget. I was like, I can't believe they

834
00:48:15,525 --> 00:48:19,325
Speaker 4:  conned. I called, I called it a puff piece. Yeah. I was likes a big puff

835
00:48:19,325 --> 00:48:23,165
Speaker 4:  piece about side star like fun. Look at these guys. But they're doomed.

836
00:48:23,385 --> 00:48:27,085
Speaker 4:  And the reporter and I I was like a baby blogger. Yeah. The

837
00:48:27,245 --> 00:48:30,405
Speaker 4:  reporter wrote me just like the most hammer email,

838
00:48:31,325 --> 00:48:35,205
Speaker 4:  like, how dare you, I would never write a puff piece. These are

839
00:48:35,205 --> 00:48:38,405
Speaker 4:  valid issues. And I was like, I don know how to break this to you. Like this

840
00:48:38,405 --> 00:48:41,965
Speaker 4:  company's not gonna make like five minutes. And sure enough, apple sued them.

841
00:48:42,205 --> 00:48:46,125
Speaker 4:  Then it went away immediately. And I was like, that was crazy. but it

842
00:48:46,125 --> 00:48:50,085
Speaker 4:  was, it was all based on this argument that like, if you did one right thing

843
00:48:50,155 --> 00:48:53,965
Speaker 4:  once, then you could do the wrong thing as many times as you wanted. Yeah.

844
00:48:54,145 --> 00:48:58,085
Speaker 4:  And I think the difference with Beeper is they're not using any of Apple's

845
00:48:58,085 --> 00:49:01,845
Speaker 4:  code. Right? They're not, they're just sending Apple a number.

846
00:49:02,615 --> 00:49:05,005
Speaker 4:  Right. That happens to be a serial number.

847
00:49:06,385 --> 00:49:10,275
Speaker 6:  Yeah. That's tough. And the, the reverse engineering is legal

848
00:49:10,535 --> 00:49:14,195
Speaker 6:  and protected. Like that is like a, a valid thing to do. It's particular,

849
00:49:14,315 --> 00:49:17,635
Speaker 6:  particularly when it comes to enabling interoperability, which is like the

850
00:49:17,635 --> 00:49:21,595
Speaker 6:  whole hinging thing here, enables interoperability for

851
00:49:21,635 --> 00:49:23,075
Speaker 6:  iMessage on Android devices.

852
00:49:23,565 --> 00:49:26,195
Speaker 4:  There is another law that could get in their way.

853
00:49:27,745 --> 00:49:30,795
Speaker 4:  It's just like, it's there, it's always lurking in the background. It's like

854
00:49:30,795 --> 00:49:34,195
Speaker 4:  one of the worst laws in the books. It's a computer fraud and abuse act

855
00:49:35,015 --> 00:49:38,905
Speaker 4:  that says if you wrongfully gain access to a system that is

856
00:49:38,945 --> 00:49:39,785
Speaker 4:  a criminal penalty.

857
00:49:39,975 --> 00:49:43,865
Speaker 5:  Well, this was how all the bios, they would reverse engineer the bios

858
00:49:43,865 --> 00:49:46,905
Speaker 5:  back in the eighties and you're like, had to be in a different room from

859
00:49:46,905 --> 00:49:48,265
Speaker 5:  the people reverse engineering it. Right.

860
00:49:48,855 --> 00:49:51,905
Speaker 6:  This is Cranz, this is a plot point of halt and catch fire.

861
00:49:52,045 --> 00:49:55,985
Speaker 5:  It is a plot point, but it's also true. It really happened. That's why it

862
00:49:55,985 --> 00:49:57,305
Speaker 5:  was such a good plot point, one

863
00:49:57,305 --> 00:50:00,745
Speaker 6:  Of the best shows ever made. but it is a, a whole plot line of it. It's very

864
00:50:00,745 --> 00:50:01,145
Speaker 6:  cool. I

865
00:50:01,305 --> 00:50:03,945
Speaker 5:  Remember being really excited. I was like, they're doing it, they're doing

866
00:50:04,415 --> 00:50:04,905
Speaker 5:  Bios law.

867
00:50:05,765 --> 00:50:09,625
Speaker 6:  But you know, again, it's a, the, the technical side of this is really

868
00:50:09,625 --> 00:50:13,585
Speaker 6:  kind of above my head, but Quinn over at snazzy q in his

869
00:50:13,585 --> 00:50:17,305
Speaker 6:  breakdown video, and he, like, he installs the open source

870
00:50:17,415 --> 00:50:21,145
Speaker 6:  code on a Linux laptop and connects to the protocol and like

871
00:50:21,145 --> 00:50:25,065
Speaker 6:  does the thing as It works to show what it's doing behind the

872
00:50:25,065 --> 00:50:29,005
Speaker 6:  like polished app that you see on Android. And it's really quite fascinating.

873
00:50:29,035 --> 00:50:32,965
Speaker 6:  Yeah. He makes a point that spoofing the serial numbers does have

874
00:50:33,005 --> 00:50:36,845
Speaker 6:  a number of legitimate use cases and there's no way for Apple

875
00:50:36,945 --> 00:50:40,685
Speaker 6:  to know whether this serial number that you are sending them

876
00:50:41,145 --> 00:50:45,045
Speaker 6:  is the 2015 iMac 21.5

877
00:50:45,075 --> 00:50:48,565
Speaker 6:  inch model that it was originally, or it's your Android phone. So course

878
00:50:48,565 --> 00:50:52,445
Speaker 6:  Apple can't tell that. So if Apple were to like turn

879
00:50:52,445 --> 00:50:56,005
Speaker 6:  that off, it would break a lot of things for legitimate users. So that's

880
00:50:56,005 --> 00:50:57,805
Speaker 6:  kind of where the the rub is.

881
00:50:58,065 --> 00:51:00,845
Speaker 4:  But because the code is public, because the activity is public, apple could

882
00:51:00,845 --> 00:51:04,245
Speaker 4:  certainly sue Beeper and say you are improperly

883
00:51:04,355 --> 00:51:08,325
Speaker 4:  accessing the iMessage servers that you are not supposed to have access to.

884
00:51:08,625 --> 00:51:12,365
Speaker 4:  And there is a long line of cases, like everything in America

885
00:51:12,755 --> 00:51:16,405
Speaker 4:  have total coin flip outcomes once you hit the Supreme court.

886
00:51:17,135 --> 00:51:21,085
Speaker 4:  Right. Like at and t won a case and the characters involved in

887
00:51:21,085 --> 00:51:24,965
Speaker 4:  the case are somewhat unsavory. But at and t won a case for someone who

888
00:51:24,965 --> 00:51:28,325
Speaker 4:  was just hitting the at t website to do lookups over and over again.

889
00:51:28,825 --> 00:51:32,725
Speaker 4:  And that was A-C-F-A-A case. LinkedIn just lost a case to

890
00:51:32,725 --> 00:51:36,685
Speaker 4:  an analytics company called hiq that was scraping the

891
00:51:36,885 --> 00:51:40,325
Speaker 4:  LinkedIn database. And it's like, well that seems wrong with an IQ one. The

892
00:51:40,325 --> 00:51:43,525
Speaker 4:  Supreme court just took another case where a police officer improperly did

893
00:51:43,525 --> 00:51:46,765
Speaker 4:  a lookup, like someone paid him money to use the police database to do a

894
00:51:46,765 --> 00:51:50,485
Speaker 4:  lookup. I don know, but he had, he was authorized to use the database. He

895
00:51:50,485 --> 00:51:54,085
Speaker 4:  just did it in an unapproved way. And like you just, like, if there's a server

896
00:51:54,185 --> 00:51:57,565
Speaker 4:  on the internet and you talk to it and it tells you something, there's a

897
00:51:57,565 --> 00:52:00,965
Speaker 4:  million different ways to parse out whether that is legal or not legal.

898
00:52:01,185 --> 00:52:04,925
Speaker 5:  So does, how big is beeper's legal fund, I think is the real question we

899
00:52:04,925 --> 00:52:05,365
Speaker 5:  need to be asking

900
00:52:05,565 --> 00:52:08,565
Speaker 4:  The que here's, there's a couple questions right next to this. The EU decided

901
00:52:08,565 --> 00:52:12,445
Speaker 4:  this week that Apple did not have to treat iMessage

902
00:52:12,545 --> 00:52:16,005
Speaker 4:  as a, a platform that has to be interoperable. Like did Meta

903
00:52:16,355 --> 00:52:17,325
Speaker 4:  with WhatsApp, did

904
00:52:17,325 --> 00:52:19,645
Speaker 5:  They decide or they just leaned in that I thought they've just leaned in

905
00:52:19,645 --> 00:52:20,125
Speaker 5:  that direction.

906
00:52:20,125 --> 00:52:20,765
Speaker 4:  They've signaled

907
00:52:21,045 --> 00:52:21,805
Speaker 5:  Signaled Yeah.

908
00:52:22,365 --> 00:52:25,205
Speaker 4:  European politics. There's a lot of signaling posturing. Yeah. You rotate

909
00:52:25,245 --> 00:52:25,845
Speaker 4:  a piece of cheese

910
00:52:26,025 --> 00:52:28,685
Speaker 5:  And everybody's like, yes, thank you, thank you, thank you so much.

911
00:52:28,835 --> 00:52:30,885
Speaker 4:  It's like, oh, debris has turned to the left. Thank you. I message will not

912
00:52:30,885 --> 00:52:33,645
Speaker 4:  be a gatekeeper service. Like that's like, it seems like that's not gonna

913
00:52:33,645 --> 00:52:36,685
Speaker 4:  happen. That is almost certainly because

914
00:52:38,135 --> 00:52:42,005
Speaker 4:  Apple agreed to adopt RRCs. Right, right. Which was the gambit. And

915
00:52:42,005 --> 00:52:44,885
Speaker 4:  and I think we all saw that as the trade. Like there's the threat of this

916
00:52:44,885 --> 00:52:48,125
Speaker 4:  big interop regulation. Or they could do RRCs and say, look, it's interoperable

917
00:52:48,125 --> 00:52:51,645
Speaker 4:  this way. Great. They did it. So that's sort of the background here.

918
00:52:51,835 --> 00:52:55,205
Speaker 4:  Like Apple's gonna say, look, there's an interoperable way it's coming, we're

919
00:52:55,205 --> 00:52:59,045
Speaker 4:  gonna use it. Maybe only four people ever use paper and the, or maybe

920
00:52:59,045 --> 00:53:01,685
Speaker 4:  they just, Apple's pretty litigious. Maybe they just send a threat to this

921
00:53:01,685 --> 00:53:05,405
Speaker 4:  company and say, stop it. But the need to stop it

922
00:53:05,785 --> 00:53:09,645
Speaker 4:  or Apple's desire to stop it is going to cause problems. Yeah. Because

923
00:53:09,645 --> 00:53:13,535
Speaker 4:  they don't actually have the RCS implementation yet. And so

924
00:53:13,595 --> 00:53:17,095
Speaker 4:  to say we we're gonna keep people locked out of our service while we work

925
00:53:17,095 --> 00:53:19,535
Speaker 4:  on this other thing. I think it's just gonna be, and it's an indie developer

926
00:53:19,535 --> 00:53:23,015
Speaker 4:  that's really well liked. It got a lot of press because a lot of Android

927
00:53:23,015 --> 00:53:25,540
Speaker 4:  people in this country really wanna send high messages and they're gonna

928
00:53:25,540 --> 00:53:28,885
Speaker 4:  pay Beeper $2 a month or whatever it is to, to do it. They should have solved

929
00:53:28,885 --> 00:53:32,645
Speaker 4:  this problem a million years ago. They should have found a way to do this

930
00:53:32,665 --> 00:53:36,125
Speaker 4:  on their terms a million years ago because now they're doing it on the terms

931
00:53:36,145 --> 00:53:39,725
Speaker 4:  of the European Union and somewhat improbably on the terms

932
00:53:41,425 --> 00:53:44,685
Speaker 4:  Kowski and Beeper Mini. Which is just weird.

933
00:53:45,035 --> 00:53:45,765
Speaker 5:  It's a delight.

934
00:53:46,345 --> 00:53:50,245
Speaker 4:  And this is a 16-year-old kid who reverse engineering the protocol and is

935
00:53:50,245 --> 00:53:54,185
Speaker 4:  like spare time. Like that's a weird place for the richest company

936
00:53:54,185 --> 00:53:55,185
Speaker 4:  in the world to be Yeah.

937
00:53:55,405 --> 00:53:56,745
Speaker 5:  Go after that 16-year-old kid.

938
00:53:57,655 --> 00:54:00,905
Speaker 4:  This is the thing, you wanna file the CFA lawsuit against the 16-year-old

939
00:54:00,905 --> 00:54:04,505
Speaker 4:  kid for a reverse engineering thing. Like you're the bad guy. That's just

940
00:54:04,625 --> 00:54:05,225
Speaker 4:  straight up. You're the bad

941
00:54:05,225 --> 00:54:08,345
Speaker 5:  Guy. Yeah. I mean that's what Sony did, right? With the, I think it was a

942
00:54:08,365 --> 00:54:08,745
Speaker 5:  PSS three.

943
00:54:09,175 --> 00:54:11,425
Speaker 4:  Yeah. This is the legend of Geo of George Hots.

944
00:54:11,425 --> 00:54:13,345
Speaker 5:  Yeah. Yeah. Like mm. Don't maybe don't do that.

945
00:54:13,895 --> 00:54:16,305
Speaker 4:  Well, the George Hots did work, it did work in Twitter for five minutes.

946
00:54:18,445 --> 00:54:22,265
Speaker 4:  All. right. So that's that other big piece of news we should talk about this

947
00:54:22,265 --> 00:54:26,105
Speaker 4:  week. It seems like podcast industry is in turmoil. Spotify just had

948
00:54:26,105 --> 00:54:29,345
Speaker 4:  layoffs. They're canceling really popular shows, including a show that won

949
00:54:29,905 --> 00:54:33,785
Speaker 4:  a Pulitzer Prize. They canceled Heavyweight, the title laid off 10 percent

950
00:54:33,785 --> 00:54:37,225
Speaker 4:  of its staff. It just seems like in general podcasts,

951
00:54:37,815 --> 00:54:40,665
Speaker 4:  they had the big tech moment where all the money from the big tech companies

952
00:54:40,665 --> 00:54:44,185
Speaker 4:  particularly Spotify, rushed in. Yes. And now the Tide has

953
00:54:44,415 --> 00:54:48,185
Speaker 5:  Come back out. It's like Spotify rushed in with zero plan. And

954
00:54:48,185 --> 00:54:52,065
Speaker 5:  then when the, the gravy train like did not continue the plan,

955
00:54:52,265 --> 00:54:55,985
Speaker 5:  continue the plan was celebrities. The plan was own this

956
00:54:55,985 --> 00:54:59,905
Speaker 5:  entire industry as quickly as possible, like grow so fast,

957
00:55:00,005 --> 00:55:03,585
Speaker 5:  so big that nobody can stop us and we're a Tidal wave. And then like,

958
00:55:03,875 --> 00:55:06,785
Speaker 5:  we'll be supported by all our ad dollars and the ad dollars are like, no,

959
00:55:06,995 --> 00:55:08,705
Speaker 5:  we're not gonna support you that much. Right.

960
00:55:08,705 --> 00:55:11,865
Speaker 4:  And they bought an ad tech company. Yeah. And they wanted to do dynamic insertion

961
00:55:11,865 --> 00:55:12,425
Speaker 4:  of ads because they were

962
00:55:12,425 --> 00:55:14,625
Speaker 5:  Trying to own the whole ad tech industry side of Spotify

963
00:55:15,035 --> 00:55:18,585
Speaker 4:  Disclosure. Our ads are served by Spotify, sadd tech platform,

964
00:55:18,775 --> 00:55:19,385
Speaker 4:  megaphone

965
00:55:19,475 --> 00:55:20,705
Speaker 5:  Disclosure. We're a podcast,

966
00:55:22,385 --> 00:55:25,425
Speaker 4:  I don't even know what I'm disclosing there. Like someone uploads this to

967
00:55:25,425 --> 00:55:28,145
Speaker 4:  this thing and we use it. Yeah. It's great. Someone else runs the ads, but

968
00:55:28,175 --> 00:55:32,105
Speaker 4:  it's true. There's a disclosure. The whole story to me is they thought

969
00:55:32,105 --> 00:55:35,985
Speaker 4:  they could take a big, rich, open ecosystem and

970
00:55:35,985 --> 00:55:39,865
Speaker 4:  turn it into a very closed one. Yes. You could turn Spotify in

971
00:55:39,865 --> 00:55:42,545
Speaker 4:  the open podcasting ecosystem into something that looked a lot more like

972
00:55:42,545 --> 00:55:45,035
Speaker 4:  YouTube. And I, I think it just didn't work.

973
00:55:45,035 --> 00:55:48,715
Speaker 5:  Yeah. I, I a hundred percent agree. I think they, they fail. Like, and we

974
00:55:48,715 --> 00:55:52,155
Speaker 5:  all kind of knew this, remember Ashley came on, Ashley Carmen now at Bloomberg

975
00:55:52,285 --> 00:55:53,755
Speaker 5:  broke a lot of this stuff about Spotify,

976
00:55:53,885 --> 00:55:55,195
Speaker 4:  Nobel Trader Ashley Carmen, yeah.

977
00:55:55,675 --> 00:55:59,635
Speaker 5:  Horrible trader. But came on this very podcast like what, two years ago talking

978
00:55:59,635 --> 00:56:02,075
Speaker 5:  about this. And we were all like, Ooh, this doesn't sound like it's gonna

979
00:56:02,225 --> 00:56:06,155
Speaker 5:  work for Spotify. It feels like they're just ignoring everything else

980
00:56:06,165 --> 00:56:10,155
Speaker 5:  about this and why this is a bad idea. It feels like we were All right. High

981
00:56:10,155 --> 00:56:12,515
Speaker 5:  five all of us two years ago. Yes.

982
00:56:13,145 --> 00:56:17,115
Speaker 4:  Yeah. I mean obviously they've held onto Joe Rogan. His deal is up

983
00:56:17,115 --> 00:56:19,715
Speaker 4:  for renewal. We have been told. So we're tracking That

984
00:56:19,855 --> 00:56:21,395
Speaker 5:  Did not hold onto Prince Harry and Meghan,

985
00:56:21,495 --> 00:56:24,445
Speaker 4:  Meghan and Harry didn't make it. You know, there's something interesting

986
00:56:24,445 --> 00:56:27,925
Speaker 4:  there. You know, the, the tech industry loves Talk about going direct. Yeah.

987
00:56:28,275 --> 00:56:30,725
Speaker 4:  Like, loves to talk about going direct. You don't need these journalists

988
00:56:30,725 --> 00:56:34,245
Speaker 4:  or Pepsi. And it's like if you go direct and you have nothing to say,

989
00:56:34,665 --> 00:56:37,405
Speaker 4:  no one will listen to you and you will have gone direct to no one. Which

990
00:56:37,405 --> 00:56:40,125
Speaker 4:  is truly the Harry and Meghan story. Like

991
00:56:40,955 --> 00:56:42,445
Speaker 4:  they're out of things to say.

992
00:56:42,795 --> 00:56:45,605
Speaker 5:  Yeah. They, they did the book. We were all like, thank you. This is actually

993
00:56:45,605 --> 00:56:47,565
Speaker 5:  all we wanted from you. Yeah. We just wanted the tea.

994
00:56:47,705 --> 00:56:51,565
Speaker 4:  And I'm not even someone who, like, I'm Indian American. My people

995
00:56:51,565 --> 00:56:55,205
Speaker 4:  have fled the British twice. Like we just get out and I,

996
00:56:55,725 --> 00:56:59,125
Speaker 4:  I do not care about any of this, but it's like even the people I know who

997
00:56:59,225 --> 00:57:03,125
Speaker 4:  do care, and we have them on our staff, Liz Lippa and Sarah Jog love

998
00:57:03,125 --> 00:57:05,685
Speaker 4:  some royal family drama and they're like, whatever we're done with this.

999
00:57:06,145 --> 00:57:09,845
Speaker 4:  And like that to me is you need some tension

1000
00:57:10,025 --> 00:57:14,005
Speaker 4:  to tell a good story. Yeah. And like that's, you buy a bunch of the celebrities

1001
00:57:14,245 --> 00:57:17,725
Speaker 4:  directly, you're not gonna have any tension. Every celebrity podcast is like

1002
00:57:17,765 --> 00:57:20,165
Speaker 4:  a celebrity and then someone else just needling them. Well,

1003
00:57:20,165 --> 00:57:24,085
Speaker 5:  Or there's there, the new trend now is it's the d-list

1004
00:57:24,085 --> 00:57:27,645
Speaker 5:  celebrities that were on the shows with the really big folks. They all get

1005
00:57:27,765 --> 00:57:30,645
Speaker 5:  together and then talk trash about the big folks. Yeah. And then sometimes

1006
00:57:30,645 --> 00:57:34,605
Speaker 5:  talk about like how they slept with the entire cast. And you're like a lot

1007
00:57:34,605 --> 00:57:35,325
Speaker 5:  of Disney channel

1008
00:57:37,435 --> 00:57:41,405
Speaker 5:  your face. We're like, why don't get into the podcast

1009
00:57:41,455 --> 00:57:43,685
Speaker 5:  scene guys. There's so many, like Disney channel

1010
00:57:43,855 --> 00:57:46,245
Speaker 4:  Tells we're ending this podcast before we, before we go that way.

1011
00:57:46,485 --> 00:57:50,045
Speaker 5:  Yeah. We're we're, we won't do that. It's wild though. That's the new trend

1012
00:57:50,045 --> 00:57:51,485
Speaker 5:  for celebrity podcasts. Yeah.

1013
00:57:51,785 --> 00:57:55,285
Speaker 4:  All of that seems like it didn't work. Just to be clear. Like Spotify burned

1014
00:57:55,285 --> 00:57:59,245
Speaker 4:  millions of dollars in this. They torched Gimlet, which was a darling,

1015
00:57:59,245 --> 00:58:02,885
Speaker 4:  it was failing as a company. And obviously they sold the Spotify for

1016
00:58:03,245 --> 00:58:07,205
Speaker 4:  tons and tons of money that they had no plan themselves to, to gain because

1017
00:58:07,205 --> 00:58:10,845
Speaker 4:  they were failing as a company. So good, good on them. but it also broke

1018
00:58:10,865 --> 00:58:14,365
Speaker 4:  Gimlet. It broke reply all, it broke the culture of that company

1019
00:58:15,145 --> 00:58:19,045
Speaker 4:  at, at some point. Like the mergers are just bad. The acquisitions are

1020
00:58:19,045 --> 00:58:22,965
Speaker 4:  just bad. And I think this feels like they bought Gimlet, they bought podcast,

1021
00:58:23,075 --> 00:58:26,845
Speaker 4:  they bought Anchor, they bought Megaphone, and they had no plan to munge

1022
00:58:26,845 --> 00:58:30,525
Speaker 4:  them all to They bought the ringer. Yep. And the plan to mu them all together

1023
00:58:31,415 --> 00:58:32,365
Speaker 4:  seems like it just failed.

1024
00:58:33,025 --> 00:58:33,245
Speaker 5:  Yes.

1025
00:58:33,745 --> 00:58:36,725
Speaker 4:  But the stock is up and they turn their first ever profit. And it's like,

1026
00:58:36,725 --> 00:58:37,485
Speaker 4:  is that all that matters?

1027
00:58:38,425 --> 00:58:40,325
Speaker 5:  Ooh. If you, if you like money. Yeah.

1028
00:58:40,475 --> 00:58:43,245
Speaker 4:  Yeah. I think we're, I think we're, I don't think podcasts are going anywhere.

1029
00:58:43,465 --> 00:58:46,165
Speaker 4:  You can see some of 'em are still growing. You can see money is flowing to

1030
00:58:46,165 --> 00:58:49,325
Speaker 4:  some categories in them, but it, it feels like we're returning

1031
00:58:50,185 --> 00:58:53,685
Speaker 4:  to a much more sustainable place to grow the podcast industry. Yes.

1032
00:58:54,275 --> 00:58:57,655
Speaker 5:  It was very unsustainable for a while. And now it's gonna be like, we are

1033
00:58:57,655 --> 00:59:01,095
Speaker 5:  only gonna support podcasts where people actually say something interesting

1034
00:59:01,865 --> 00:59:02,655
Speaker 4:  Maybe just,

1035
00:59:02,915 --> 00:59:04,095
Speaker 5:  And, and also Joe Rogan

1036
00:59:05,915 --> 00:59:08,775
Speaker 4:  And then other thing, Spotify and all the other big podcast players are doing

1037
00:59:09,075 --> 00:59:11,895
Speaker 4:  is they're, they're focusing on chat shows.

1038
00:59:12,925 --> 00:59:16,475
Speaker 4:  Influencer, you know, the, the, the solo podcast where the

1039
00:59:16,475 --> 00:59:19,595
Speaker 4:  influencers just ranted the screen, but it looks like a podcast. Yeah. A

1040
00:59:19,595 --> 00:59:21,245
Speaker 4:  deeply fast. Like that's a media PhD.

1041
00:59:21,705 --> 00:59:23,125
Speaker 5:  That's gonna be my spinoff. If

1042
00:59:23,125 --> 00:59:26,485
Speaker 4:  There are any media, PhD, any media studies students that are pursuing a

1043
00:59:26,485 --> 00:59:30,205
Speaker 4:  media studies PhD, I would read your dissertation on the,

1044
00:59:30,265 --> 00:59:34,075
Speaker 4:  the one person podcast where they just talk the whole time.

1045
00:59:34,865 --> 00:59:35,515
Speaker 5:  What do they do?

1046
00:59:36,835 --> 00:59:40,755
Speaker 4:  I just, I I like to talk. Yeah, I do that. I

1047
00:59:40,755 --> 00:59:42,035
Speaker 4:  love it mean that's same. That's it's my favorite.

1048
00:59:42,035 --> 00:59:44,875
Speaker 6:  That's the AM radio model, right? Like that was the Rush Limbaugh model.

1049
00:59:45,015 --> 00:59:48,675
Speaker 6:  It was the Alex Jones model. Just talk to the microphone for three hours

1050
00:59:48,875 --> 00:59:48,955
Speaker 6:  straight.

1051
00:59:49,065 --> 00:59:53,045
Speaker 4:  Yeah. I'm just dying to know in podcasting to

1052
00:59:53,065 --> 00:59:56,725
Speaker 4:  do that on your own and then to like close your laptop

1053
00:59:56,865 --> 00:59:58,285
Speaker 4:  lid and be like,

1054
00:59:59,045 --> 01:00:00,805
Speaker 5:  I did it. Good

1055
01:00:00,805 --> 01:00:04,045
Speaker 4:  Job. There's, there's something in there about like that personality making

1056
01:00:04,045 --> 01:00:07,685
Speaker 4:  that kind of content with that kind of distribution that I promise you as

1057
01:00:07,685 --> 01:00:08,405
Speaker 4:  a PhD thesis.

1058
01:00:09,105 --> 01:00:09,325
Speaker 5:  I'd

1059
01:00:09,325 --> 01:00:12,805
Speaker 4:  Read it like there's some feedback loop in there that I just want to know

1060
01:00:12,805 --> 01:00:13,125
Speaker 4:  more about.

1061
01:00:13,275 --> 01:00:15,845
Speaker 5:  Just send it to Neela. Send it to all of us. Honestly. I wanna read that

1062
01:00:15,845 --> 01:00:15,965
Speaker 5:  too.

1063
01:00:16,635 --> 01:00:20,445
Speaker 4:  Well do it. Go get your PhD. That's what I'm telling you. That's a good use

1064
01:00:20,445 --> 01:00:24,125
Speaker 4:  of money. And then title, obviously, obviously laying Off Its staff. Again,

1065
01:00:24,125 --> 01:00:27,685
Speaker 4:  another Jack Dorsey brilliantly managed company. Yeah. We love

1066
01:00:27,685 --> 01:00:28,805
Speaker 5:  It. It had Beyonce for a

1067
01:00:28,805 --> 01:00:31,685
Speaker 4:  While. It did. And then last piece of little media news and we'll take a

1068
01:00:31,685 --> 01:00:35,405
Speaker 4:  break. Apple is munging together. It's iTunes movies and TV shows

1069
01:00:35,505 --> 01:00:39,205
Speaker 4:  app into the proper Apple tv, TV app.

1070
01:00:39,785 --> 01:00:40,965
Speaker 4:  So now we have to use it.

1071
01:00:41,025 --> 01:00:44,805
Speaker 5:  And it was already sort of done that way. Yeah. So it's just like,

1072
01:00:44,805 --> 01:00:48,685
Speaker 5:  they're just like cleaning up the crumbs. Like the people who haven't

1073
01:00:48,685 --> 01:00:51,565
Speaker 5:  really touched their workflow in 20 years are gonna be like, oh no, how am

1074
01:00:51,565 --> 01:00:54,965
Speaker 5:  I gonna like watch my old Aquaman episodes from 2006?

1075
01:00:55,355 --> 01:00:59,325
Speaker 5:  That sucks for them. But also the rest of us have been living now

1076
01:00:59,815 --> 01:01:01,325
Speaker 5:  where you just use the one app.

1077
01:01:02,115 --> 01:01:02,405
Speaker 4:  Yeah.

1078
01:01:03,345 --> 01:01:04,005
Speaker 5:  I'm judging people.

1079
01:01:04,275 --> 01:01:07,445
Speaker 4:  What I'm doing is serious. What you mean is Plex Alex's Plex app?

1080
01:01:07,465 --> 01:01:10,285
Speaker 5:  No, it's the Apple TV app. Sure.

1081
01:01:11,285 --> 01:01:14,165
Speaker 4:  By the way, there was a, a piece of news this week. Very distressing. Sony's

1082
01:01:14,165 --> 01:01:17,445
Speaker 4:  just deleting TV shows that people bought. Yeah. On PlayStation accounts.

1083
01:01:17,495 --> 01:01:18,045
Speaker 5:  We're gonna talk

1084
01:01:18,045 --> 01:01:20,125
Speaker 4:  About it later. We'll take a break. We'll get back, we'll talk about that.

1085
01:03:26,015 --> 01:03:28,835
Speaker 4:  All right? We're back sliding around time. Tell us about the Sony thing.

1086
01:03:28,835 --> 01:03:29,115
Speaker 4:  Earlier

1087
01:03:29,115 --> 01:03:31,755
Speaker 5:  This week, a lot of PlayStation users noticed that they were just getting

1088
01:03:31,975 --> 01:03:35,595
Speaker 5:  banned out of the blue. Like not a lot of people say, oh, I'm getting

1089
01:03:35,595 --> 01:03:39,475
Speaker 5:  banned. I don't know what happened. And you're like, no, you do. This

1090
01:03:39,475 --> 01:03:42,275
Speaker 5:  wasn't the case. They were just like totally outright band. They didn't know

1091
01:03:42,275 --> 01:03:45,235
Speaker 5:  what was happening. It was a whole lot of people, which was the other part

1092
01:03:45,235 --> 01:03:49,155
Speaker 5:  of this. And so j Peters and Tom Warren looked into it and, and

1093
01:03:49,155 --> 01:03:52,915
Speaker 5:  eventually Sony was like, oops, our bad. And just slowly has been giving

1094
01:03:52,915 --> 01:03:56,315
Speaker 5:  everybody their account access back. And it was all just an accident. It

1095
01:03:56,315 --> 01:04:00,195
Speaker 5:  was just like a a a bug and they, they, they screwed up. but it also just

1096
01:04:00,195 --> 01:04:03,395
Speaker 5:  immediately reminded everyone, particularly when paired with the fact that

1097
01:04:04,105 --> 01:04:07,875
Speaker 5:  Sony also recently said, okay, a lot of this content you purchased from

1098
01:04:07,875 --> 01:04:11,115
Speaker 5:  Discovery Plus you will not have access to it anymore. We've changed some

1099
01:04:11,115 --> 01:04:14,915
Speaker 5:  of our licensing. It's just like a big reminder that you

1100
01:04:14,915 --> 01:04:18,795
Speaker 5:  don't own anything you buy digitally. Yeah. You, you don't own any of it.

1101
01:04:18,985 --> 01:04:22,875
Speaker 5:  It's not yours. It's all licenses. It's all fake owner ownership.

1102
01:04:23,575 --> 01:04:26,675
Speaker 5:  And and Sony just accidentally reminded their entire

1103
01:04:27,785 --> 01:04:31,355
Speaker 5:  like customer's base. Yeah. Which is not what you wanna do when you are

1104
01:04:31,455 --> 01:04:35,275
Speaker 5:  highly dependent on all of, on all of them buying shit on your,

1105
01:04:35,275 --> 01:04:35,795
Speaker 5:  your stores.

1106
01:04:35,825 --> 01:04:38,315
Speaker 4:  They just radicalize a lot of people into buying that dis drive.

1107
01:04:38,385 --> 01:04:39,355
Speaker 5:  Yeah. Which is

1108
01:04:39,405 --> 01:04:42,715
Speaker 4:  Maybe this is all a plot to get people to buy external dis drive. Yeah.

1109
01:04:42,715 --> 01:04:44,795
Speaker 5:  They're just trying to like move those disk drives. I'm like, All. right.

1110
01:04:45,335 --> 01:04:47,435
Speaker 4:  You're losing all, if someone opened a closet, they're like, we have a lot

1111
01:04:47,495 --> 01:04:48,355
Speaker 4:  of Blu-ray drives

1112
01:04:50,215 --> 01:04:51,675
Speaker 4:  way more than we thought You guys

1113
01:04:52,095 --> 01:04:55,195
Speaker 5:  All. right. Pull the disco plus stuff. Let's go. We got this

1114
01:04:55,455 --> 01:04:58,235
Speaker 4:  Dr. Pimple popper's outta here. We gotta move these drives.

1115
01:04:59,215 --> 01:05:03,075
Speaker 5:  But Jay wrote a really great piece just kind of lamenting it and and he's

1116
01:05:03,235 --> 01:05:06,995
Speaker 5:  absolutely right. Don't, like, if you really wanna own something

1117
01:05:07,095 --> 01:05:10,275
Speaker 5:  and you wanna own it for a long time, don't just buy the digital version.

1118
01:05:11,015 --> 01:05:14,635
Speaker 5:  And a lot of times you can just go buy a DVD or a Blu-ray and get the digital

1119
01:05:14,635 --> 01:05:18,245
Speaker 5:  version. Then you have both Yeah. For the same amount of money. And

1120
01:05:18,475 --> 01:05:21,485
Speaker 4:  Look, I'm building a new home theater right now in the new house. Ooh. I'm

1121
01:05:21,485 --> 01:05:23,685
Speaker 4:  really thinking about putting a Blu-ray player in it. I don't know why

1122
01:05:24,765 --> 01:05:27,985
Speaker 5:  Do it. I I've got one. Use it once a year. I you just,

1123
01:05:27,985 --> 01:05:28,465
Speaker 4:  I know you do.

1124
01:05:29,825 --> 01:05:31,105
Speaker 5:  I plug it into my, my computer.

1125
01:05:31,105 --> 01:05:34,505
Speaker 4:  Yeah. Use it once a year to rip legal media to your

1126
01:05:35,025 --> 01:05:35,905
Speaker 4:  Plex server. You

1127
01:05:35,905 --> 01:05:39,425
Speaker 5:  Know, it's, it's folk folk copyright law. And we don't need to talk about

1128
01:05:39,425 --> 01:05:39,985
Speaker 5:  it too much here.

1129
01:05:39,985 --> 01:05:42,905
Speaker 4:  I've got a Blueray player that's been running Mac OSS nine for a decade.

1130
01:05:45,495 --> 01:05:47,825
Speaker 4:  It's great. All. right. Dan, what's your lightning round?

1131
01:05:48,425 --> 01:05:52,185
Speaker 6:  I got two. Okay. Ooh. Can I do both now or, yeah. All. right. The first one

1132
01:05:52,245 --> 01:05:55,425
Speaker 6:  is, Allison did a review of the Razr,

1133
01:05:56,435 --> 01:06:00,385
Speaker 6:  which is not to be confused with the Razr plus it is Motorola's

1134
01:06:00,565 --> 01:06:04,465
Speaker 6:  budget flip phone. Turns out it's not a very good phone. I'm just gonna start

1135
01:06:04,465 --> 01:06:07,865
Speaker 6:  off by saying that, but what's really fascinating to me about it is

1136
01:06:08,425 --> 01:06:12,225
Speaker 6:  this is priced at 700 bucks and because Motorola discounts things

1137
01:06:12,465 --> 01:06:16,345
Speaker 6:  a hundred percent of the time, all the time, you can buy for $500,

1138
01:06:16,345 --> 01:06:19,825
Speaker 6:  which means this is a flip phone with a folding screen

1139
01:06:20,165 --> 01:06:23,905
Speaker 6:  for $500. Which is kind of like a fascinating thing to me that we are already

1140
01:06:24,045 --> 01:06:27,585
Speaker 6:  at that point of affordability of these kind of flip devices.

1141
01:06:28,205 --> 01:06:31,425
Speaker 6:  The cameras aren't great. The processors can be a little slow. The outside

1142
01:06:31,425 --> 01:06:35,345
Speaker 6:  screen is not very useful. It's not a phone I would recommend anyone buy,

1143
01:06:35,565 --> 01:06:39,505
Speaker 6:  but it's pretty cool that like we've gone from, these are all a thousand

1144
01:06:39,565 --> 01:06:43,345
Speaker 6:  or $1,400 to $500 in just a couple

1145
01:06:43,345 --> 01:06:47,225
Speaker 6:  years. So that was my first one. Yeah,

1146
01:06:47,935 --> 01:06:51,265
Speaker 4:  It's true. And we, we, the second that first Galaxy Fold came out, we're

1147
01:06:51,265 --> 01:06:54,385
Speaker 4:  like, oh, the cost curve on this is gonna go oop. Yeah. What's interesting

1148
01:06:54,385 --> 01:06:57,805
Speaker 4:  is the technology curve has kind of stopped,

1149
01:06:58,495 --> 01:07:02,085
Speaker 4:  right? Like the screens are better, they're more durable. That was the big

1150
01:07:02,085 --> 01:07:05,245
Speaker 4:  thing. But they look largely the same. They're

1151
01:07:05,245 --> 01:07:05,845
Speaker 5:  Still lumpy.

1152
01:07:06,435 --> 01:07:10,285
Speaker 4:  Well, there's lumpy, but even just like the way the materials look

1153
01:07:10,285 --> 01:07:10,805
Speaker 4:  and feel.

1154
01:07:11,035 --> 01:07:14,285
Speaker 6:  Yeah. They still are soft kind of plastic. Yeah. It doesn't feel like hard

1155
01:07:14,285 --> 01:07:14,885
Speaker 6:  glass. Yeah.

1156
01:07:15,115 --> 01:07:18,725
Speaker 4:  Yeah. And that was the, there was some, there was a lot of talk about bendy

1157
01:07:18,725 --> 01:07:20,365
Speaker 4:  glass in the beginning. Do you remember this? Yes.

1158
01:07:20,655 --> 01:07:22,325
Speaker 6:  Ultra thin glass. Yeah. Yeah.

1159
01:07:22,335 --> 01:07:23,685
Speaker 5:  Where is it? I wanna

1160
01:07:23,685 --> 01:07:27,165
Speaker 6:  See it. Well, it's all in there. It just, well the, the way they work is

1161
01:07:27,165 --> 01:07:31,085
Speaker 6:  there's a layer of ultra thin glass and then on top of that is a soft plastic

1162
01:07:31,085 --> 01:07:34,165
Speaker 6:  screen protector. And that's what you touch. Yeah. And that's what provides

1163
01:07:34,165 --> 01:07:36,645
Speaker 6:  that kind of not so great tactile experience.

1164
01:07:36,945 --> 01:07:39,405
Speaker 4:  As with most things, technology kind of like make it better and keep the

1165
01:07:39,405 --> 01:07:42,565
Speaker 4:  cost the same. Or you can make, keep it the same. Keep bring the cost down.

1166
01:07:42,585 --> 01:07:45,845
Speaker 4:  And we are very much on the keep it the same, bring the cost down part of

1167
01:07:45,845 --> 01:07:49,075
Speaker 4:  the curve. There's not the step change into the part.

1168
01:07:49,075 --> 01:07:52,795
Speaker 6:  Particularly for the flip designs. The fold designs are

1169
01:07:52,795 --> 01:07:56,595
Speaker 6:  still very expensive. The one plus open

1170
01:07:56,595 --> 01:08:00,155
Speaker 6:  came out earlier this year and that is available for around $1,500.

1171
01:08:00,375 --> 01:08:04,115
Speaker 6:  That's kinda like the low price for these folding

1172
01:08:04,155 --> 01:08:07,475
Speaker 6:  phones. But the flip phones, and I think it's part of

1173
01:08:07,975 --> 01:08:11,755
Speaker 6:  who these are marketed to, folding phones are marketed to like Uber,

1174
01:08:11,895 --> 01:08:15,565
Speaker 6:  do everything nerds like me. And then the flip phones are marketed to people

1175
01:08:15,565 --> 01:08:18,525
Speaker 6:  who want something a little bit more fashionable, a little bit more compact,

1176
01:08:18,645 --> 01:08:22,525
Speaker 6:  discreet, don't wanna spend 10 to 12 hours a day staring at

1177
01:08:22,525 --> 01:08:26,125
Speaker 6:  their phone like I do. And, and wanna make it more of like an intentional

1178
01:08:26,125 --> 01:08:29,405
Speaker 6:  device. And so they don't need the fastest processor, they don't need the

1179
01:08:29,405 --> 01:08:32,205
Speaker 6:  highest end camera system. They don't need the bills and whistles to run

1180
01:08:32,255 --> 01:08:36,205
Speaker 6:  decks and things like that. even that, I think Motorola lets

1181
01:08:36,205 --> 01:08:39,685
Speaker 6:  you run its version of Dex, which is called ready for on its flip phones.

1182
01:08:40,225 --> 01:08:42,125
Speaker 6:  So, hey, that's the thing you could do, Eli.

1183
01:08:42,305 --> 01:08:46,045
Speaker 4:  Hey, I wanna see that next doc with a Motorola flip.

1184
01:08:46,435 --> 01:08:49,045
Speaker 4:  Yeah, let's do it. Yeah. Bad camera, slow processor.

1185
01:08:50,615 --> 01:08:53,645
Speaker 4:  Great. Okay. You all knew this was gonna be my lightning round.

1186
01:08:54,585 --> 01:08:58,565
Speaker 4:  You knew it. There was no choice except for this story to

1187
01:08:58,565 --> 01:09:01,765
Speaker 4:  be my lightning round item, which is the photo of the woman in the, in the

1188
01:09:01,865 --> 01:09:03,245
Speaker 4:  bridal gown. Like

1189
01:09:03,285 --> 01:09:07,125
Speaker 5:  I saw it and I, I, as soon as the news broke, what, earlier this week, I

1190
01:09:07,125 --> 01:09:07,485
Speaker 5:  was like, Hmm,

1191
01:09:07,905 --> 01:09:10,125
Speaker 4:  You know what? I'm coming. The news broke a couple weeks ago. Did you? A

1192
01:09:10,125 --> 01:09:12,845
Speaker 4:  couple weeks ago. And then OpenAI happened and we forgot about it. Yeah.

1193
01:09:12,865 --> 01:09:16,005
Speaker 4:  So this photo, there's a photo of a woman she's trying on a wedding dress.

1194
01:09:16,375 --> 01:09:19,005
Speaker 4:  She's in the bridal shots. one of those, there's mirrors all around her.

1195
01:09:19,005 --> 01:09:21,805
Speaker 4:  Yeah. Like you do. So you can see yourself from all the angles and she's

1196
01:09:21,805 --> 01:09:25,575
Speaker 4:  making a different pose in all the mirrors. And then in person, she's a British

1197
01:09:25,935 --> 01:09:29,855
Speaker 4:  comedian. She posted her Instagram story. She said, this is crazy. I've

1198
01:09:29,855 --> 01:09:33,375
Speaker 4:  never had anything like this happen. The immediate

1199
01:09:33,465 --> 01:09:37,375
Speaker 4:  theorizing about AI photo composites

1200
01:09:37,375 --> 01:09:41,295
Speaker 4:  started happening. Smart HDR, she said she went to the Apple store. Someone,

1201
01:09:41,765 --> 01:09:45,295
Speaker 4:  some Apple store employee told her this was Apple beta testing a competitor,

1202
01:09:45,415 --> 01:09:47,495
Speaker 4:  a best take on Google, which makes no sense.

1203
01:09:49,005 --> 01:09:51,975
Speaker 4:  This is all true. This all happened. Right. This is all in her Instagram

1204
01:09:51,975 --> 01:09:54,775
Speaker 4:  stories and Instagram post. Yeah. Tom Warren, because she's in the UK. Tom

1205
01:09:54,775 --> 01:09:57,175
Speaker 4:  Warren reached out to her. I was like, we gotta get the actual photo we got.

1206
01:09:57,175 --> 01:10:01,015
Speaker 4:  And then he reached out to her, he got the photo, we were talking

1207
01:10:01,015 --> 01:10:04,775
Speaker 4:  about it. Then the opening eye news broke. Tom is our Microsoft

1208
01:10:05,175 --> 01:10:09,015
Speaker 4:  reporter. He and I got very distracted, very busy. We stopped

1209
01:10:09,015 --> 01:10:12,775
Speaker 4:  paying attention to the woman in her wedding dress for a minute. The, the

1210
01:10:12,805 --> 01:10:16,775
Speaker 4:  Post came back this week. People saw it

1211
01:10:16,775 --> 01:10:20,455
Speaker 4:  again, all the same amount of theorizing that happened, people calling it

1212
01:10:20,455 --> 01:10:24,215
Speaker 4:  fake, a publicity, not social media. And she said, and we had

1213
01:10:24,575 --> 01:10:28,375
Speaker 4:  the file and nothing about the file indicates that it's fake. Okay. Like

1214
01:10:29,155 --> 01:10:32,655
Speaker 4:  we were, Tom was sent the uncompressed un

1215
01:10:33,255 --> 01:10:37,055
Speaker 4:  seemingly unaltered original photo off the iPhone. And we were

1216
01:10:37,055 --> 01:10:39,615
Speaker 4:  looking at it, we were trying to figure out, we were like gone to ask Apple

1217
01:10:39,845 --> 01:10:43,825
Speaker 4:  because it is very odd Yeah. That she's making three

1218
01:10:43,825 --> 01:10:46,225
Speaker 4:  different poses in the mirrors. And so everyone's trying to like figure this

1219
01:10:46,225 --> 01:10:50,175
Speaker 4:  out. Again, a lot of people claiming that it's fake. It turns

1220
01:10:50,275 --> 01:10:54,255
Speaker 4:  out someone else had taken the photo and they had the camera

1221
01:10:54,655 --> 01:10:58,535
Speaker 4:  accidentally in Panorama mode. Oh yeah. So it actually did stitch together

1222
01:10:58,535 --> 01:11:02,015
Speaker 4:  several frames across to make it panorama. But if you

1223
01:11:02,335 --> 01:11:05,975
Speaker 4:  don't move the camera enough and You don't get a wide enough picture,

1224
01:11:06,515 --> 01:11:08,975
Speaker 4:  the iPhone does not append the Panorama label. Yeah.

1225
01:11:09,075 --> 01:11:12,855
Speaker 6:  Oh. The only tell, and I, I, I think

1226
01:11:14,125 --> 01:11:17,965
Speaker 6:  there's a YouTuber, I Fondo, his name is Farouk. He's the one who kind of

1227
01:11:17,965 --> 01:11:20,765
Speaker 6:  like popularized or, or, or, or told the world about this

1228
01:11:21,355 --> 01:11:25,285
Speaker 6:  reasoning how it worked. But the only tell is that the resolution of the

1229
01:11:25,285 --> 01:11:29,045
Speaker 6:  final image is not the same as the resolution that is captured

1230
01:11:29,065 --> 01:11:33,005
Speaker 6:  by the sensor. And so the photos app does not

1231
01:11:33,005 --> 01:11:36,845
Speaker 6:  say Panorama because it's not a panoramic view. It's too

1232
01:11:37,955 --> 01:11:41,885
Speaker 6:  tall and narrow. It's a vertically composed shot, but the

1233
01:11:42,065 --> 01:11:45,565
Speaker 6:  pixels are different. And so that is like the tell there that is in panoramic

1234
01:11:45,565 --> 01:11:49,485
Speaker 6:  mode. Farouk was able to replicate this very quickly as soon as

1235
01:11:49,485 --> 01:11:52,805
Speaker 6:  he figured that out by putting his phone in panoramic mode and like doing

1236
01:11:52,925 --> 01:11:56,725
Speaker 6:  a very, like a, a another shot just that same way and was able to

1237
01:11:56,725 --> 01:11:59,485
Speaker 6:  replicate it in instantly. So it's, it's kind of fascinating. What's really

1238
01:11:59,685 --> 01:12:03,405
Speaker 6:  fascinating to me is like the stitching is like perfect. Which

1239
01:12:03,405 --> 01:12:05,525
Speaker 4:  Is like, because the cam 'cause the camera isn't moving. Yeah. I didn't

1240
01:12:05,525 --> 01:12:08,725
Speaker 5:  Know you could do that. I thought like you, because it always is like, move

1241
01:12:08,745 --> 01:12:12,525
Speaker 5:  the camera. That's what my phone sounds like to me. But it's, it's always

1242
01:12:12,525 --> 01:12:14,445
Speaker 5:  telling me to move the camera. So I'm always like, do I

1243
01:12:14,445 --> 01:12:17,325
Speaker 6:  Think it just tells that Alex that tells you how well people follow directions

1244
01:12:17,325 --> 01:12:18,485
Speaker 6:  on their devices when they're just

1245
01:12:18,845 --> 01:12:19,525
Speaker 5:  Mashing button. Can I just ignore that?

1246
01:12:20,185 --> 01:12:21,565
Speaker 6:  You could just ignore it. Yeah.

1247
01:12:21,905 --> 01:12:25,165
Speaker 4:  One Apple should just label all Panorama photos as panoramas. Yeah. That

1248
01:12:25,165 --> 01:12:28,485
Speaker 4:  seems like an easy fix to the solution. But two, the

1249
01:12:28,595 --> 01:12:32,245
Speaker 4:  expectation that AI is just gonna munge with reality

1250
01:12:32,905 --> 01:12:34,205
Speaker 4:  is everywhere now.

1251
01:12:34,915 --> 01:12:38,885
Speaker 5:  Well, I don't think the expectation is, the reality is like that, that that's

1252
01:12:38,885 --> 01:12:41,805
Speaker 5:  the reality of the situation. But like, I think people are still, because

1253
01:12:41,805 --> 01:12:44,165
Speaker 5:  that's why everybody thought it was a fake. 'cause everybody's like, you're

1254
01:12:44,245 --> 01:12:48,125
Speaker 5:  a liar. You did this on purpose, you used Photoshop or, or Panorama or

1255
01:12:48,285 --> 01:12:51,805
Speaker 5:  whatever. And it's like, no, she just accidentally did it. Yeah. Like,

1256
01:12:52,265 --> 01:12:55,645
Speaker 4:  But even if you, even if you think this is the world's greatest publicity

1257
01:12:55,645 --> 01:12:58,765
Speaker 4:  stunt Yeah. Targeted to a very small community, very

1258
01:12:58,765 --> 01:12:59,005
Speaker 5:  Small group.

1259
01:13:00,185 --> 01:13:03,925
Speaker 4:  It relies on an understanding that AI

1260
01:13:04,085 --> 01:13:06,565
Speaker 4:  exists Mm. And is doing photo stuff. Mm.

1261
01:13:06,565 --> 01:13:07,565
Speaker 5:  That's true. That's true.

1262
01:13:07,735 --> 01:13:11,485
Speaker 4:  Right? It's not like it's either ghosts in the building, like No, no. It's

1263
01:13:11,485 --> 01:13:15,365
Speaker 4:  like, oh, the, the iPhone cameras AI took this

1264
01:13:15,365 --> 01:13:19,285
Speaker 4:  completely unbelievable picture and it AI generated you. And

1265
01:13:19,285 --> 01:13:22,005
Speaker 4:  like people will believe that that's true. Yeah. And a lot of people believe

1266
01:13:22,005 --> 01:13:24,725
Speaker 4:  that it's true. Such that other people were debunking it like the whole thing.

1267
01:13:25,145 --> 01:13:28,885
Speaker 4:  And in the meantime it was a totally different lane Yeah.

1268
01:13:29,145 --> 01:13:30,725
Speaker 4:  Of photography. Yeah.

1269
01:13:30,845 --> 01:13:34,485
Speaker 5:  'cause because a lot of the theories were around it was doing that thing

1270
01:13:34,485 --> 01:13:37,525
Speaker 5:  where it chooses the best shot of you and it just happened to assume she

1271
01:13:37,525 --> 01:13:39,165
Speaker 5:  was three different people. Right.

1272
01:13:39,165 --> 01:13:42,565
Speaker 4:  It, the mirror had confused sort of like some sort of like best take. Yeah.

1273
01:13:42,665 --> 01:13:46,445
Speaker 4:  But Apple smarty share does not work like this at all. And even Google Best

1274
01:13:46,445 --> 01:13:50,165
Speaker 4:  Take does not work like this at all. Apple smarty share stacks seven frames

1275
01:13:50,165 --> 01:13:52,365
Speaker 4:  in like half a second. She would've had to move her hands so fast.

1276
01:13:53,275 --> 01:13:53,565
Speaker 5:  Just

1277
01:13:54,635 --> 01:13:58,485
Speaker 4:  Like, like totally insanely too fast. Like that's why I was like, we gotta

1278
01:13:58,485 --> 01:14:02,045
Speaker 4:  get the original file. There's no way that an iPhone just generate this.

1279
01:14:02,205 --> 01:14:04,925
Speaker 4:  'cause I was not thinking about Panorama mode. Yeah. So it's a Photoshop.

1280
01:14:04,925 --> 01:14:08,725
Speaker 4:  We, we might have been able to tell, but the thing that got me was she sent

1281
01:14:08,725 --> 01:14:09,965
Speaker 4:  it to Tom right away. Yeah.

1282
01:14:10,465 --> 01:14:10,685
Speaker 5:  Tom

1283
01:14:10,685 --> 01:14:13,525
Speaker 4:  Reached it's weird. Reached out and she was like, here you go. And that,

1284
01:14:13,675 --> 01:14:16,805
Speaker 4:  that like, to me like you are a reporter long enough. Like, oh, there's some

1285
01:14:16,805 --> 01:14:20,645
Speaker 4:  things where if there's a hesitation there. Yeah. It's like you

1286
01:14:20,645 --> 01:14:22,565
Speaker 4:  only can get a compressed one then you're like, is

1287
01:14:22,565 --> 01:14:22,965
Speaker 5:  This off the

1288
01:14:22,965 --> 01:14:25,365
Speaker 4:  Record? And then you blame WhatsApp. Like there's all this stuff that usually

1289
01:14:25,365 --> 01:14:27,645
Speaker 4:  happens. Yeah. When you request an original and she was just like, here you

1290
01:14:27,645 --> 01:14:30,885
Speaker 4:  go. Okay. So I was like All. right. There's something here that don don't

1291
01:14:30,885 --> 01:14:34,285
Speaker 4:  understand and the, the panorama. What is interesting, the, the thing that's

1292
01:14:34,455 --> 01:14:38,125
Speaker 4:  truly fascinating to me is that the culture is ready to

1293
01:14:38,125 --> 01:14:40,925
Speaker 4:  receive AI fakery as an explanation for anything.

1294
01:14:41,735 --> 01:14:42,025
Speaker 5:  Yeah.

1295
01:14:42,325 --> 01:14:44,945
Speaker 4:  And like, I'm just telling the, the what is a photo apocalypse is like well

1296
01:14:44,945 --> 01:14:48,385
Speaker 4:  and truly here because you can tell anyone

1297
01:14:48,935 --> 01:14:52,865
Speaker 4:  that a photo has been AI faked and they, the chances of

1298
01:14:52,865 --> 01:14:56,465
Speaker 4:  them believing you are just steadily going up. Yeah. Even if it doesn't turn

1299
01:14:56,465 --> 01:14:56,945
Speaker 4:  out to be the case.

1300
01:14:56,965 --> 01:14:59,505
Speaker 5:  That's one of my, all my photos now are gonna be fakes. You don't know.

1301
01:15:00,375 --> 01:15:00,985
Speaker 4:  They already

1302
01:15:01,045 --> 01:15:04,145
Speaker 5:  Are. They already are. I haven't taken a real photo in 20 years. All. right.

1303
01:15:04,145 --> 01:15:07,545
Speaker 4:  I've got a couple other ones just to go through quickly.

1304
01:15:08,165 --> 01:15:12,035
Speaker 4:  One, this is maybe my favorite story of the year. Windows

1305
01:15:12,215 --> 01:15:15,915
Speaker 4:  has an issue that is just renaming printers to HP LaserJet across the board.

1306
01:15:17,295 --> 01:15:18,235
Speaker 5:  The only printer you need.

1307
01:15:18,385 --> 01:15:20,275
Speaker 4:  It's a very good, it's just

1308
01:15:20,555 --> 01:15:20,755
Speaker 5:  Advertising.

1309
01:15:20,825 --> 01:15:24,195
Speaker 4:  It's like, will AI kill us all? Or will the HP smart app

1310
01:15:25,555 --> 01:15:29,475
Speaker 4:  worm, its away under literally every computer on the planet and like begin

1311
01:15:29,475 --> 01:15:30,755
Speaker 4:  taking out centrifuges

1312
01:15:30,935 --> 01:15:31,835
Speaker 5:  And buying ink

1313
01:15:32,395 --> 01:15:36,235
Speaker 4:  And buying ink. Like the problem isn't paperclips, the problem is in cartridges.

1314
01:15:36,975 --> 01:15:40,795
Speaker 4:  So Microsoft says it's looking into it. It's Windows 10 11 printers being

1315
01:15:41,075 --> 01:15:45,035
Speaker 4:  randomly renamed to HP LaserJet. Some issues related to printer

1316
01:15:45,315 --> 01:15:48,035
Speaker 4:  configurations are being observed on Windows devices which have access to

1317
01:15:48,035 --> 01:15:49,795
Speaker 4:  the store. It's just very good.

1318
01:15:49,945 --> 01:15:50,635
Speaker 5:  It's so good.

1319
01:15:52,115 --> 01:15:55,395
Speaker 4:  Everyone just has the HP smart app. Now your printer isn an HP LaserJet and

1320
01:15:55,395 --> 01:15:56,595
Speaker 4:  that's, you're gonna like it.

1321
01:15:56,705 --> 01:16:00,605
Speaker 5:  Yeah. We, we do say buy a laser printer, but we usually say

1322
01:16:00,605 --> 01:16:01,565
Speaker 5:  brother, not not

1323
01:16:02,045 --> 01:16:05,605
Speaker 4:  Official statement. Most printers are being named as HP LaserJet M

1324
01:16:05,605 --> 01:16:09,285
Speaker 4:  1 0 1 dash M 1 0 6. The icons might also be changed.

1325
01:16:09,525 --> 01:16:09,765
Speaker 4:  It's

1326
01:16:11,385 --> 01:16:12,045
Speaker 5:  Oh, that's so

1327
01:16:12,045 --> 01:16:15,645
Speaker 4:  Good. It's very good. Then just real quickly,

1328
01:16:15,865 --> 01:16:19,845
Speaker 4:  we are gonna cover Epic VGO in much more detail on the Wednesday show. Sean

1329
01:16:19,845 --> 01:16:23,725
Speaker 4:  Hollister will be on the show. He's been in the courtroom, but this

1330
01:16:23,725 --> 01:16:27,645
Speaker 4:  is really important for this case. Google has gotten himself into an

1331
01:16:27,885 --> 01:16:31,685
Speaker 4:  enormous amount of trouble with this judge for deleting records throughout

1332
01:16:31,685 --> 01:16:31,965
Speaker 4:  this case.

1333
01:16:32,025 --> 01:16:33,605
Speaker 5:  Ooh. That's a no-no. Like an

1334
01:16:33,845 --> 01:16:37,525
Speaker 4:  Enormous amount of trouble. The judge is furious. Last Friday, he said he

1335
01:16:37,525 --> 01:16:41,285
Speaker 4:  would investigate Google personally for quote, intentionally and

1336
01:16:41,285 --> 01:16:45,085
Speaker 4:  systematically suppressing evidence. He called it a frontal assault

1337
01:16:45,105 --> 01:16:48,845
Speaker 4:  on the Fair Administration of justice. And he said, I'm gonna get to the

1338
01:16:48,845 --> 01:16:52,525
Speaker 4:  bottom of who is responsible on my own outside this trial. Yo

1339
01:16:53,045 --> 01:16:53,565
Speaker 4:  I, don Dunno what kind of,

1340
01:16:54,645 --> 01:16:57,805
Speaker 5:  I like, I I've been in, I've, I've been in enough companies that are, that

1341
01:16:58,045 --> 01:17:00,805
Speaker 5:  are like getting lawsuits and stuff. When you're told to retain all your

1342
01:17:00,805 --> 01:17:04,765
Speaker 5:  records that you just never think to not, you're just like,

1343
01:17:04,765 --> 01:17:06,565
Speaker 5:  yeah, and, and my mess is gonna be out there.

1344
01:17:06,665 --> 01:17:09,820
Speaker 4:  And Sundar was asking like, can I set this chat to auto delete? They were

1345
01:17:09,820 --> 01:17:13,805
Speaker 4:  deleting stuff left and right. They admitted in court that they were

1346
01:17:13,805 --> 01:17:17,485
Speaker 4:  just deleting stuff. At one point the judge called in Google's

1347
01:17:17,485 --> 01:17:20,925
Speaker 4:  general counsel and made him answer to why these policies were, he's furious

1348
01:17:20,925 --> 01:17:24,645
Speaker 4:  about this. That's great. I will investigate this on my own outside this

1349
01:17:24,645 --> 01:17:27,805
Speaker 4:  trial. It's a very funny threat. Like, he's gonna get a magnifying glass,

1350
01:17:27,855 --> 01:17:30,925
Speaker 4:  start walking his ropes off. He's he puts on a leather jacket. Yeah.

1351
01:17:31,425 --> 01:17:32,645
Speaker 5:  Little fedora. And he's like,

1352
01:17:32,645 --> 01:17:36,405
Speaker 4:  Let's go. He's like a seventies bad cop. You know, it's gonna

1353
01:17:36,405 --> 01:17:36,685
Speaker 4:  Your

1354
01:17:36,835 --> 01:17:39,005
Speaker 5:  Driving his old ass car. Exactly.

1355
01:17:39,115 --> 01:17:42,765
Speaker 4:  He's like, he's got a muscle. He's got a GTO and a magnifying glass. He's

1356
01:17:42,765 --> 01:17:46,565
Speaker 4:  like, where are the records? don don't know what that will lead to. But

1357
01:17:46,595 --> 01:17:49,725
Speaker 4:  importantly, he has told the jury,

1358
01:17:50,505 --> 01:17:53,845
Speaker 4:  not that they have to, but they may infer

1359
01:17:54,535 --> 01:17:58,285
Speaker 4:  wrongdoing on the part of Google if there's a question that the missing records

1360
01:17:58,285 --> 01:17:59,605
Speaker 4:  would've answered.

1361
01:18:00,035 --> 01:18:00,325
Speaker 5:  Okay.

1362
01:18:00,415 --> 01:18:03,365
Speaker 4:  Right. So he's, and and that's like a pretty loaded suggestion.

1363
01:18:03,725 --> 01:18:07,525
Speaker 5:  I was like that. I mean it's like, well that's fair, but also, Ooh, that's

1364
01:18:07,525 --> 01:18:08,165
Speaker 5:  bad for Google.

1365
01:18:08,495 --> 01:18:12,205
Speaker 4:  Right. So the the idea here is that the, the jury is gonna consider, and

1366
01:18:12,205 --> 01:18:15,685
Speaker 4:  it really, it really seems like Google might lose this case.

1367
01:18:15,915 --> 01:18:19,725
Speaker 4:  Yeah. In a way that maybe at the end of Apple, you know, I I still think

1368
01:18:20,035 --> 01:18:23,885
Speaker 4:  Epic walked away with one important, just the way the legal

1369
01:18:23,885 --> 01:18:26,405
Speaker 4:  system works. They want a bunch of stuff and they want to appeal whatever.

1370
01:18:26,545 --> 01:18:29,885
Speaker 4:  But Apple is like, we just run our business and that's it. Google, there's

1371
01:18:29,885 --> 01:18:33,525
Speaker 4:  all this evidence and there's much deleted evidence. All this stuff. It

1372
01:18:33,525 --> 01:18:37,405
Speaker 4:  really seems like epic mounted a much stronger case with Google. Yeah. And

1373
01:18:37,425 --> 01:18:41,385
Speaker 4:  now the jury is being sent and they are allowed to

1374
01:18:41,595 --> 01:18:45,515
Speaker 4:  infer whatever Google was hiding was bad. Which is a

1375
01:18:45,515 --> 01:18:48,115
Speaker 4:  just a big deal. It might come to nothing. It might not come to nothing.

1376
01:18:48,305 --> 01:18:52,075
Speaker 4:  It's just worth noting the judge is furious. Like this is the

1377
01:18:52,075 --> 01:18:55,155
Speaker 4:  shadiest thing Google has done and the judge is furious about it and he has

1378
01:18:55,155 --> 01:18:55,955
Speaker 4:  told the jury about it

1379
01:18:56,095 --> 01:18:58,995
Speaker 5:  And it's gonna make all the, the appeals really messy to I 'cause I just

1380
01:18:58,995 --> 01:19:01,555
Speaker 5:  assumed they will all be appealed. Whatever the decision is.

1381
01:19:01,615 --> 01:19:05,235
Speaker 4:  Oh, whatever the decision is appealed. It, it all just, what you appeal is

1382
01:19:05,235 --> 01:19:06,035
Speaker 4:  the law. Yeah.

1383
01:19:06,185 --> 01:19:06,475
Speaker 5:  Okay.

1384
01:19:06,535 --> 01:19:09,075
Speaker 4:  So the facts remain the facts. And so

1385
01:19:09,505 --> 01:19:12,995
Speaker 5:  Just, and this is why you don't delete your records. Right? Yeah.

1386
01:19:13,795 --> 01:19:14,515
Speaker 5:  'cause this will happen.

1387
01:19:14,965 --> 01:19:18,555
Speaker 4:  Right. But the, an appeals court does not to get, to go back and say,

1388
01:19:19,335 --> 01:19:21,395
Speaker 4:  the jury's finding a fact we wrong.

1389
01:19:21,395 --> 01:19:21,995
Speaker 5:  Yeah. Right.

1390
01:19:22,265 --> 01:19:25,155
Speaker 4:  They get to say that the law is wrong and we should change the law or like

1391
01:19:25,155 --> 01:19:28,675
Speaker 4:  this other thing. Okay. So that's, that's a little, it's a little law schooly,

1392
01:19:28,675 --> 01:19:30,035
Speaker 5:  Technical All. right. I see it. I see the text.

1393
01:19:30,615 --> 01:19:34,355
Speaker 4:  But so here the inference of the jury was you might appeal, this was a wrong

1394
01:19:34,355 --> 01:19:38,155
Speaker 4:  inference to give the jury or whatever, but he didn't, he didn't

1395
01:19:38,395 --> 01:19:40,635
Speaker 4:  instruct them to think one way or another. He said they were just allowed

1396
01:19:40,635 --> 01:19:44,275
Speaker 4:  to, which is a very important instruction. Anyway. I would just say the Epic

1397
01:19:44,755 --> 01:19:48,275
Speaker 4:  v Google case, we're gonna talk about much more with Sean on Wednesday.

1398
01:19:48,695 --> 01:19:51,315
Speaker 4:  Get into it. But that was the one that stuck out to me this week is like,

1399
01:19:51,315 --> 01:19:54,355
Speaker 4:  oh, there's something there. All. right. And then the last one I just wanna

1400
01:19:54,355 --> 01:19:58,275
Speaker 4:  call out Alison Johnson, second call for her today has a

1401
01:19:58,275 --> 01:20:01,875
Speaker 4:  big piece as part of our infrastructure package about just 5G

1402
01:20:02,855 --> 01:20:06,235
Speaker 4:  and the fact that it hasn't paid off for anyone.

1403
01:20:07,085 --> 01:20:11,045
Speaker 4:  And she, she basically listened to all the big carriers earnings calls

1404
01:20:11,305 --> 01:20:14,125
Speaker 4:  and talk and how they're talking about their investments, what the investors

1405
01:20:14,395 --> 01:20:18,285
Speaker 4:  want. There's nothing there. Like, it's basically like they

1406
01:20:18,285 --> 01:20:21,885
Speaker 4:  might compete with fixed broadband. So you, instead of having

1407
01:20:22,405 --> 01:20:26,325
Speaker 4:  whatever ISP you have, you might get a 5G fixed wireless device. They

1408
01:20:26,325 --> 01:20:30,005
Speaker 4:  seem excited about that. They're excited about enterprise customers buying

1409
01:20:30,135 --> 01:20:34,005
Speaker 4:  fixed 5G networks, which is hard 'cause you gotta have an enterprise

1410
01:20:34,005 --> 01:20:37,645
Speaker 4:  sales team, which many of them don't. And then they can do what Verizon is

1411
01:20:37,645 --> 01:20:39,525
Speaker 4:  calling pricing actions. Hmm.

1412
01:20:40,055 --> 01:20:40,405
Speaker 5:  Which

1413
01:20:40,405 --> 01:20:44,285
Speaker 4:  Means one thing, I hate it. The action is turning the price

1414
01:20:44,345 --> 01:20:47,165
Speaker 4:  up. That's the action you can take.

1415
01:20:47,745 --> 01:20:51,645
Speaker 5:  You know what we can do? You got faster internet now you pay a hundred dollars

1416
01:20:51,715 --> 01:20:52,685
Speaker 5:  more. Enjoy.

1417
01:20:53,405 --> 01:20:56,285
Speaker 4:  I will remind everyone, we actually got a note this week about Project Jenna

1418
01:20:56,495 --> 01:21:00,405
Speaker 4:  Fivey, the ill faded attempt to turn Dish Network into a mobile

1419
01:21:00,405 --> 01:21:01,285
Speaker 4:  carrier. Still

1420
01:21:01,285 --> 01:21:02,005
Speaker 5:  Technically a,

1421
01:21:02,755 --> 01:21:06,645
Speaker 4:  They they have it. They've, I believe Allison points this

1422
01:21:06,645 --> 01:21:10,405
Speaker 4:  out. They've technically hit their coverage goals, but they've done it by

1423
01:21:10,525 --> 01:21:13,565
Speaker 4:  leasing space on at and t and T-Mobile's network. So they have not actually

1424
01:21:13,565 --> 01:21:16,605
Speaker 4:  built a nationwide wireless network.

1425
01:21:17,445 --> 01:21:18,215
Speaker 5:  It's just Mitchell.

1426
01:21:18,725 --> 01:21:21,375
Speaker 4:  It's just Mitchell. He's out there on the trail.

1427
01:21:22,635 --> 01:21:26,495
Speaker 4:  Our own wonderful Mitchell Clark, who we tried desperately to use Project

1428
01:21:26,515 --> 01:21:30,455
Speaker 4:  Gen five sis. We, this whole thing was a boondoggle. Yeah. It

1429
01:21:30,455 --> 01:21:33,455
Speaker 4:  cost a lot of money. It put all these carriers in debt. It consolidated us

1430
01:21:33,455 --> 01:21:36,855
Speaker 4:  down from four to three, well, three and project Gen five sis.

1431
01:21:37,875 --> 01:21:40,735
Speaker 4:  And now we're doing pricing actions. Like we should just see it for what

1432
01:21:40,735 --> 01:21:43,935
Speaker 4:  it is. You can read Allison's piece link to it. It is great. It is very

1433
01:21:44,425 --> 01:21:48,375
Speaker 4:  clear-eyed and direct about what has happened in a way that is not

1434
01:21:48,375 --> 01:21:50,815
Speaker 4:  just me ranting and raving and like makes the argument really well. It's

1435
01:21:50,815 --> 01:21:52,575
Speaker 4:  good. You should read it. Send it to all your friends

1436
01:21:53,195 --> 01:21:53,695
Speaker 5:  In Lena

1437
01:21:53,695 --> 01:21:56,415
Speaker 4:  Khan and then whatever carrier you have, switch to another one.

1438
01:21:57,395 --> 01:22:00,935
Speaker 4:  That's, that's my advice. That's my end of the year advice for our chat listeners.

1439
01:22:01,135 --> 01:22:03,655
Speaker 4:  Whatever you have, just switch to another one. Make 'em all Feel it. Be like,

1440
01:22:03,655 --> 01:22:04,335
Speaker 4:  why is this happening?

1441
01:22:04,595 --> 01:22:06,575
Speaker 5:  Oh, just do the churn. Yeah.

1442
01:22:06,575 --> 01:22:07,295
Speaker 4:  Just turn 'em up.

1443
01:22:07,305 --> 01:22:10,615
Speaker 5:  Churn moment. It's a churn moment. Let's do it. Just

1444
01:22:10,615 --> 01:22:13,135
Speaker 4:  We I'm just saying we just gotta create the appearance of some competition.

1445
01:22:13,205 --> 01:22:13,495
Speaker 4:  Yeah.

1446
01:22:13,685 --> 01:22:17,255
Speaker 5:  Yeah. I I really, I'm excited to go to at t

1447
01:22:18,795 --> 01:22:19,135
Speaker 5:  I'm not

1448
01:22:19,555 --> 01:22:21,895
Speaker 4:  No, it, I mean I'm, I'm just thinking about this advice that

1449
01:22:21,895 --> 01:22:23,775
Speaker 5:  Seems hard. You're like, no, don't actually do that. I don

1450
01:22:23,905 --> 01:22:26,215
Speaker 4:  Don't just do whatever feels right in your heart. That's The, Verge Chest,

1451
01:22:26,215 --> 01:22:28,975
Speaker 4:  everybody. That's my message this holiday season. Whatever's in your heart,

1452
01:22:28,995 --> 01:22:32,895
Speaker 4:  do it. Oh, speaking of the holidays by the way. Yeah. Holiday spectacular

1453
01:22:33,435 --> 01:22:36,455
Speaker 4:  coming up again. We've done HTMI,

1454
01:22:37,175 --> 01:22:38,135
Speaker 4:  we've done Bluetooth

1455
01:22:38,515 --> 01:22:39,375
Speaker 5:  Failed at Jeopardy.

1456
01:22:39,795 --> 01:22:43,455
Speaker 4:  We did not do a good job with Bluetooth jeopardy this year by

1457
01:22:44,325 --> 01:22:48,095
Speaker 4:  just popular demand, just wave of demand. The

1458
01:22:48,215 --> 01:22:51,975
Speaker 4:  Vergecast, holiday spectacular is USBC. Yes. We've got the

1459
01:22:51,975 --> 01:22:55,695
Speaker 4:  guests lined up. We got the ideas, we got the plug Fest

1460
01:22:55,695 --> 01:22:59,415
Speaker 4:  coming and we're gonna do another game show this year because Andrew

1461
01:22:59,415 --> 01:23:00,735
Speaker 4:  insists that we do a game show.

1462
01:23:02,375 --> 01:23:04,935
Speaker 4:  I believe it's the price is right. Are we allowed to say the

1463
01:23:06,705 --> 01:23:10,195
Speaker 4:  Yeah. We're allowed to say it's a game show. That is not,

1464
01:23:10,705 --> 01:23:12,315
Speaker 4:  it's not The price is right. If

1465
01:23:12,315 --> 01:23:14,155
Speaker 5:  Don don't have a a giant wheel,

1466
01:23:15,925 --> 01:23:19,795
Speaker 4:  We're gonna up the ante this year. All of us are gonna be playing for one

1467
01:23:19,795 --> 01:23:23,555
Speaker 4:  of you, a Vergecast listener and whoever wins, it's a big bag of swag.

1468
01:23:23,575 --> 01:23:27,435
Speaker 4:  So here's what we need from you call the hotline. Eight six six Verge. One

1469
01:23:27,435 --> 01:23:31,075
Speaker 4:  one. That's 8 6 6 8 3 7 4 3 1 1.

1470
01:23:31,425 --> 01:23:35,345
Speaker 4:  Tell us your name and your favorite USBC gadget. We'll

1471
01:23:35,345 --> 01:23:38,985
Speaker 4:  put all the names in a hat. We'll pick 'em out. We'll play we'll.

1472
01:23:38,995 --> 01:23:40,865
Speaker 4:  We'll, we'll do it. We're gonna

1473
01:23:40,865 --> 01:23:41,585
Speaker 5:  Compete for you.

1474
01:23:42,095 --> 01:23:45,465
Speaker 4:  Yeah. I'll represent you. Alex will represent someone else. So I'm so sorry.

1475
01:23:45,605 --> 01:23:48,825
Speaker 4:  And then whoever wins gets a big bag of Verge merch.

1476
01:23:49,325 --> 01:23:51,185
Speaker 5:  I'm actually doing a lot of USB research right

1477
01:23:51,185 --> 01:23:53,985
Speaker 4:  Now. it actually, this just says some VERGE merch, so whoever, it's some

1478
01:23:54,225 --> 01:23:54,705
Speaker 4:  VERGE merch.

1479
01:23:55,715 --> 01:23:56,225
Speaker 5:  Could be a

1480
01:23:56,225 --> 01:23:56,825
Speaker 4:  Small bag.

1481
01:23:56,825 --> 01:23:58,705
Speaker 5:  Depends on how bad your person does. I've,

1482
01:23:58,705 --> 01:24:02,505
Speaker 6:  I've seen the merch. The merch is good. It's quality merch,

1483
01:24:03,005 --> 01:24:04,145
Speaker 6:  so it'll be a good price.

1484
01:24:04,525 --> 01:24:08,505
Speaker 5:  Are you prepping to to, to help your, your listener? Yeah.

1485
01:24:08,695 --> 01:24:12,505
Speaker 5:  Yeah. I'm, I'm reading all up. I'm gonna know some specs. Oh boy. I'm gonna

1486
01:24:12,505 --> 01:24:13,425
Speaker 5:  know what OMS mean.

1487
01:24:14,805 --> 01:24:17,225
Speaker 4:  All right. She's got it.

1488
01:24:17,445 --> 01:24:19,505
Speaker 5:  I'm ready. Let's go. I got

1489
01:24:19,505 --> 01:24:22,705
Speaker 4:  You. Alex is gonna do some high school level electrical

1490
01:24:23,905 --> 01:24:27,785
Speaker 4:  research. It's gonna be amazing. No, that's it. That's come out the USBC

1491
01:24:27,785 --> 01:24:31,065
Speaker 4:  holiday spectacular. one of our silliest yearly traditions

1492
01:24:31,495 --> 01:24:34,785
Speaker 4:  back and forth. The USBC. Tell us your favorite USBC gadget.

1493
01:24:34,835 --> 01:24:38,705
Speaker 4:  8 6 6 of Virgin one. One. We'll pick some people, we'll play for them

1494
01:24:38,845 --> 01:24:42,425
Speaker 4:  The winner. Get some merch. Sounds pretty good. Call the number. That's it.

1495
01:24:42,445 --> 01:24:43,985
Speaker 4:  That's The Vergecast Rock and Roll.

1496
01:24:49,965 --> 01:24:53,145
Speaker 1:  And that's a wrap for Vergecast this week. Hey, we'd love to hear from you.

1497
01:24:53,145 --> 01:24:56,985
Speaker 1:  Give us a call at eight six six Verge one. One The Vergecast

1498
01:24:57,005 --> 01:25:00,785
Speaker 1:  is a production of The Verge and Vox Media Podcast Network. The show is

1499
01:25:00,985 --> 01:25:04,865
Speaker 1:  produced by Andrew Marino and Liam James. This episode was mixed and edited

1500
01:25:04,885 --> 01:25:07,545
Speaker 1:  by Xander Adams. And that's it. We'll see you next week.

