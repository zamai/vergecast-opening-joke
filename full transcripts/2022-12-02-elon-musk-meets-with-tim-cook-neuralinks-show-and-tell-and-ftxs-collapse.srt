1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 113b45d0-720a-11ed-863d-3705d666b03c
Status: Done
Stage: Done
Title: Elon Musk meets with Tim Cook, Neuralink's show and tell, and FTX's collapse
Audio URL: https://jfe93e.s3.amazonaws.com/-1407168016826313377/6158705326674101002/s93290-US-5255s-1669962206.mp3
Description: The Verge's Nilay Patel, Alex Cranz, and Alex Heath discuss this week in Elon Musk, everything that went wrong with FTX, and the latest gadget news.

2
00:00:00,260 --> 00:00:03,940
Speaker 1:  Today in the Verge cast, the fake war between Twitter and Apple. Then Sam

3
00:00:03,940 --> 00:00:07,620
Speaker 1:  Bankman, free of ftx, just can't stop admitting to fraud. And of course,

4
00:00:07,620 --> 00:00:10,580
Speaker 1:  all the catching news from this week that's coming up right after

5
00:00:10,580 --> 00:00:12,330
Speaker 1:  this.

6
00:01:23,980 --> 00:01:27,860
Speaker 4:  Hello. Welcome to the Ro Cast, the flagship podcast, talking to

7
00:01:27,860 --> 00:01:31,760
Speaker 4:  the New York Times. Even though your lawyer says, don't do

8
00:01:31,760 --> 00:01:34,800
Speaker 4:  that, I'm your friend Eli, Alex Franz is here.

9
00:01:34,800 --> 00:01:38,580
Speaker 5:  I'm your friend who thinks you should always do that. Do whatever the lawyer

10
00:01:38,580 --> 00:01:40,170
Speaker 5:  says. Do the opposite. I,

11
00:01:40,170 --> 00:01:43,810
Speaker 4:  I have to encourage the audience to stop listening to this podcast immediately.

12
00:01:43,810 --> 00:01:45,430
Speaker 4:  I don't know what else to tell you. Just

13
00:01:45,430 --> 00:01:48,980
Speaker 5:  It just, just if it's like, if it's of journalistic value to me

14
00:01:48,980 --> 00:01:50,460
Speaker 5:  personally, do the opposite.

15
00:01:50,460 --> 00:01:52,220
Speaker 4:  Yeah. Alex Heath is here.

16
00:01:52,220 --> 00:01:55,540
Speaker 6:  Hey, I'm, you know, I'm actually coming around to hating free speech in

17
00:01:55,540 --> 00:02:00,290
Speaker 6:  America.

18
00:02:00,290 --> 00:02:02,450
Speaker 4:  It's really quite, quite tiresome.

19
00:02:02,450 --> 00:02:04,450
Speaker 6:  Yeah, it's becoming annoying, honestly.

20
00:02:04,450 --> 00:02:07,940
Speaker 4:  Yeah, you know, I think we should just shut it down. Let's, let's go back

21
00:02:07,940 --> 00:02:11,220
Speaker 4:  to what the founders intended, which was quite honestly not the free speech

22
00:02:11,220 --> 00:02:14,090
Speaker 4:  that you expect today. That's a different podcast. We can get into it later.

23
00:02:14,090 --> 00:02:17,860
Speaker 4:  I will note for the listener, it's to Alex's today know

24
00:02:17,860 --> 00:02:21,680
Speaker 4:  David Pierce. David and his family produced a

25
00:02:21,680 --> 00:02:25,500
Speaker 4:  child. Congratulations. David, tell me what said child

26
00:02:25,500 --> 00:02:28,820
Speaker 4:  is named. I can only assume that he's named the

27
00:02:28,820 --> 00:02:32,780
Speaker 4:  baby Bluetooth 2.1 plus EDR Pierce.

28
00:02:32,780 --> 00:02:33,530
Speaker 4:  That's just my guess.

29
00:02:33,530 --> 00:02:36,480
Speaker 6:  He's holding up different cables going, this is

30
00:02:36,480 --> 00:02:40,380
Speaker 6:  sbt, this is three

31
00:02:40,380 --> 00:02:44,370
Speaker 4:  S b A Pierce, but David not be here for the next few weeks.

32
00:02:44,370 --> 00:02:47,220
Speaker 4:  Congrats to David. We're gonna have a bunch of people filling in. It's gonna

33
00:02:47,220 --> 00:02:51,060
Speaker 4:  be a good time for everyone except David who's not gonna get any sleep. Yeah,

34
00:02:51,060 --> 00:02:52,740
Speaker 5:  But but he got a baby out of it.

35
00:02:52,740 --> 00:02:54,260
Speaker 4:  You got a baby out. Don't

36
00:02:54,260 --> 00:02:57,370
Speaker 6:  Say that. Childbirth I've heard is amazing.

37
00:02:57,370 --> 00:03:01,040
Speaker 4:  Well, David do, he just had to, to like, anyhow, congrats David

38
00:03:01,040 --> 00:03:04,730
Speaker 4:  Tweet at him. I'm sure he'll like to hear from you. Okay,

39
00:03:04,730 --> 00:03:08,150
Speaker 4:  so let's, why are we talking about the Tiresomeness free speech for America?

40
00:03:08,150 --> 00:03:12,090
Speaker 4:  It's because Elon and Twitter and Apple went at it again this week.

41
00:03:12,090 --> 00:03:15,760
Speaker 4:  We gotta talk about that. Sam Bankman Freed won't stop

42
00:03:15,760 --> 00:03:19,680
Speaker 4:  talking to reporters. What Ftx like just won't, that

43
00:03:19,680 --> 00:03:20,880
Speaker 2:  Will not be free speech

44
00:03:20,880 --> 00:03:23,840
Speaker 4:  For him. Yes. This is the speech that will put him in jail. It will lead

45
00:03:23,840 --> 00:03:27,480
Speaker 4:  him directly to not being free. And I, you know, I was at the deal book conference

46
00:03:27,480 --> 00:03:30,880
Speaker 4:  for that big interview with Andrea Sorkin. Well, where by the way, speaking

47
00:03:30,880 --> 00:03:34,620
Speaker 4:  of Free Speech America, Mike Pence said, first I revere the Constitution

48
00:03:34,620 --> 00:03:37,240
Speaker 4:  and then was asked about content moderation was like, well you can't shout

49
00:03:37,240 --> 00:03:41,100
Speaker 4:  fire in a crowd theater. Can I just say for the record, for the VER has audience,

50
00:03:41,100 --> 00:03:44,200
Speaker 4:  the fire in a crowded theater line. I'm sure you've heard me or Addie say

51
00:03:44,200 --> 00:03:47,890
Speaker 4:  this before in the show. That line is just a throwaway line

52
00:03:47,890 --> 00:03:51,430
Speaker 4:  in a Supreme Court case called Shank in which the Supreme Court

53
00:03:51,430 --> 00:03:55,400
Speaker 4:  held the government could arrest you for telling people not to go into

54
00:03:55,400 --> 00:03:56,650
Speaker 4:  the military.

55
00:03:56,650 --> 00:04:00,160
Speaker 6:  We are what, less than five minutes in. I'm just so you knew I was already

56
00:04:00,160 --> 00:04:02,280
Speaker 6:  talking about fire in a crowded theater.

57
00:04:02,280 --> 00:04:04,120
Speaker 4:  It's gone. It's, it's just like driving me crazy. This

58
00:04:04,120 --> 00:04:04,520
Speaker 6:  Episode's

59
00:04:04,520 --> 00:04:08,480
Speaker 4:  Over that case was overturned in another case called Brandenburg. So it's

60
00:04:08,480 --> 00:04:11,280
Speaker 4:  like this like throwaway line. A case got overturned and everyone keeps saying

61
00:04:11,280 --> 00:04:14,320
Speaker 4:  it tries bonkers. Yesterday, Mike Pence, the former vice president of the

62
00:04:14,320 --> 00:04:17,240
Speaker 4:  United States was, you know, he was doing Mike Pence. He's like, well, you

63
00:04:17,240 --> 00:04:21,090
Speaker 4:  know, you can't say fire. And I out loud was like,

64
00:04:21,090 --> 00:04:25,000
Speaker 4:  Ugh. In like a row of reporters who all looked at me. So

65
00:04:25,000 --> 00:04:26,840
Speaker 4:  Mike, if you're listening I can walk you through

66
00:04:26,840 --> 00:04:30,360
Speaker 6:  It. The best part of this was SPF and Mike Pence were on stage together,

67
00:04:30,360 --> 00:04:30,910
Speaker 6:  right?

68
00:04:30,910 --> 00:04:34,520
Speaker 4:  Yeah. At the same time. Yeah, no, they were not on stage together. Same time

69
00:04:34,520 --> 00:04:38,080
Speaker 4:  they were nearly back to back. Impressive conference. Incredible lineup of

70
00:04:38,080 --> 00:04:41,640
Speaker 4:  speakers. Again, I believe that Mike Pence is a listener of this show.

71
00:04:41,640 --> 00:04:42,840
Speaker 6:  Absolutely. Very

72
00:04:42,840 --> 00:04:44,800
Speaker 4:  Sharp feelings about htm I, CEC

73
00:04:44,800 --> 00:04:48,440
Speaker 6:  Pence and spf. Really two excellent figures.

74
00:04:48,440 --> 00:04:52,110
Speaker 6:  Two excellent public figures that we should all aspire to be one day.

75
00:04:52,110 --> 00:04:53,110
Speaker 4:  Yeah

76
00:04:53,110 --> 00:04:54,260
Speaker 2:  Baby.

77
00:04:54,260 --> 00:04:56,920
Speaker 4:  You know, I keep telling this, I told this show maybe a hundred trips yesterday.

78
00:04:56,920 --> 00:05:00,470
Speaker 4:  It's like, I know my limit as a reporter is like a tech reporter.

79
00:05:00,470 --> 00:05:04,300
Speaker 4:  Like I can't cross over into politics or general news

80
00:05:04,300 --> 00:05:08,120
Speaker 4:  cuz I just can't figure out how to pretend that I care about what Mike

81
00:05:08,120 --> 00:05:11,820
Speaker 4:  Pence has to say. Like I just can't, I can't turn it on.

82
00:05:11,820 --> 00:05:13,080
Speaker 4:  I'm like, yep, there, there's,

83
00:05:13,080 --> 00:05:15,880
Speaker 6:  Well he has a really great book about his time in office. Eli.

84
00:05:15,880 --> 00:05:18,200
Speaker 4:  Yeah, don't read it. Andrew Ross can actually did it.

85
00:05:18,200 --> 00:05:19,810
Speaker 6:  It's free speech. He should read it.

86
00:05:19,810 --> 00:05:22,920
Speaker 4:  So the book is called, so Help Me God. And yesterday Sorkin was, he was saying

87
00:05:22,920 --> 00:05:26,080
Speaker 4:  goodbye to Pence. He looked at him and said, so help me God Thank you. Which

88
00:05:26,080 --> 00:05:29,890
Speaker 4:  was deeply funny. Wow. Okay. Wow. We'll get to SPF

89
00:05:29,890 --> 00:05:33,840
Speaker 4:  on that stage and all the interviews and what's going on at FTX in a

90
00:05:33,840 --> 00:05:37,680
Speaker 4:  bit. Let's start with Twitter, apple Tim Cook

91
00:05:37,680 --> 00:05:41,480
Speaker 4:  giving Elon a tour of the Apple campus, which

92
00:05:41,480 --> 00:05:44,800
Speaker 4:  was a weird outcome of this whole thing. It was just a weird

93
00:05:44,800 --> 00:05:48,270
Speaker 4:  week of like the culture war and

94
00:05:48,270 --> 00:05:52,240
Speaker 4:  Elon wanting to launch Twitter Blue and the Apple tax all

95
00:05:52,240 --> 00:05:53,200
Speaker 4:  just colliding.

96
00:05:53,200 --> 00:05:54,600
Speaker 6:  Ron DeSantis. Ron

97
00:05:54,600 --> 00:05:58,440
Speaker 4:  Desant just like the most crazy that you could get. Heath,

98
00:05:58,440 --> 00:05:59,690
Speaker 4:  what's going on?

99
00:05:59,690 --> 00:06:03,560
Speaker 6:  Oh, what is going on? It looks like Musk and Cook squashed the

100
00:06:03,560 --> 00:06:07,400
Speaker 6:  beef Musk started the week saying Apple, you know, do they

101
00:06:07,400 --> 00:06:10,960
Speaker 6:  hate free speech in America? No. Spoiler alert, they hate it in China, not

102
00:06:10,960 --> 00:06:14,720
Speaker 6:  America. Yeah. But saying this and then you know, complaining about the

103
00:06:14,720 --> 00:06:18,200
Speaker 6:  30%. This was a few days after Phil Shiller had

104
00:06:18,200 --> 00:06:22,000
Speaker 6:  mysteriously, you know, the head of the app store deleted his Twitter account

105
00:06:22,000 --> 00:06:25,880
Speaker 6:  after Trump had been reinstated. The vibes were starting to shift between

106
00:06:25,880 --> 00:06:29,720
Speaker 6:  Apple and Twitter. Why is this important? Our listeners are smart

107
00:06:29,720 --> 00:06:33,600
Speaker 6:  but I should just say Twitter, wolves probably ceased to exist if Apple ever

108
00:06:33,600 --> 00:06:37,400
Speaker 6:  decided to kick it off of its app store. So Apple is its most critical

109
00:06:37,400 --> 00:06:41,240
Speaker 6:  source of distribution. Also taxing Blue. The

110
00:06:41,240 --> 00:06:44,810
Speaker 6:  subscription product that Elon is essentially betting the future of the company

111
00:06:44,810 --> 00:06:48,640
Speaker 6:  on. And so there was some speculation as to is he critiquing Apple

112
00:06:48,640 --> 00:06:52,520
Speaker 6:  because he's mad about the 30% or has Apple done this thing that it does

113
00:06:52,520 --> 00:06:56,060
Speaker 6:  sometimes quietly behind the scenes with apps

114
00:06:56,060 --> 00:06:59,720
Speaker 6:  and say, Hey, we don't like what we're seeing on here.

115
00:06:59,720 --> 00:07:03,400
Speaker 6:  There's too much, you know, x I think you all Roth

116
00:07:03,400 --> 00:07:06,960
Speaker 6:  Twitter's former head of trust and safety had said it in New York Times op-ed,

117
00:07:06,960 --> 00:07:09,680
Speaker 6:  that, you know, there were people at Apple who had raised concerns about

118
00:07:09,680 --> 00:07:13,490
Speaker 6:  there being too much nudity on the platform before for

119
00:07:13,490 --> 00:07:16,920
Speaker 6:  example. So you know, Musk comes in, he fires a lot of the, you

120
00:07:16,920 --> 00:07:20,490
Speaker 6:  know, moderators talks about letting pretty much anything

121
00:07:20,490 --> 00:07:24,410
Speaker 6:  go amnesty for all the band accounts. I could imagine Apple got concerned,

122
00:07:24,410 --> 00:07:28,200
Speaker 6:  Twitter is wanting to push an update for the new to Relaunch Blue, which

123
00:07:28,200 --> 00:07:31,680
Speaker 6:  got delayed again this week. But Apple's tied up in all that. And they have

124
00:07:31,680 --> 00:07:35,360
Speaker 6:  the power to actually keep the Twitter app from being updated

125
00:07:35,360 --> 00:07:39,320
Speaker 6:  until Twitter meets whatever their specific slash

126
00:07:39,320 --> 00:07:42,600
Speaker 6:  vague demands are that they don't publicly articulate because they're

127
00:07:42,600 --> 00:07:46,480
Speaker 6:  Apple somehow this all led to Elon Musk and Tim

128
00:07:46,480 --> 00:07:50,360
Speaker 6:  Cook walking Apple Park together around, have you been

129
00:07:50,360 --> 00:07:54,060
Speaker 6:  there to that, to that specific body of water? Eli? Yes. Or a Kranz?

130
00:07:54,060 --> 00:07:57,920
Speaker 6:  Yes. It's beautiful. So I imagine like if you're an Apple engineer and you're

131
00:07:57,920 --> 00:08:01,440
Speaker 6:  out there taking lunch, taking a call and maybe that's like a normal thing

132
00:08:01,440 --> 00:08:05,000
Speaker 6:  to see. I, I doubt it, but I would've loved to have seen the entourage or

133
00:08:05,000 --> 00:08:05,130
Speaker 6:  laugh.

134
00:08:05,130 --> 00:08:09,080
Speaker 5:  So it was definitely Tim Cook cuz we, I saw the photo and I saw

135
00:08:09,080 --> 00:08:10,760
Speaker 5:  the shadow. Would we confirm

136
00:08:10,760 --> 00:08:14,600
Speaker 6:  This? Yeah, there was some shadow analysis done and it looked like him. What

137
00:08:14,600 --> 00:08:16,920
Speaker 5:  If we had like a cardboard stand-in? It

138
00:08:16,920 --> 00:08:20,760
Speaker 6:  Could not even be just given the state of Twitter. You know, that could have

139
00:08:20,760 --> 00:08:23,120
Speaker 6:  been a fake account that tweeted that. We don't actually know that that was

140
00:08:23,120 --> 00:08:24,640
Speaker 6:  Musk. I

141
00:08:24,640 --> 00:08:28,520
Speaker 4:  Will say that we were told Apple employees had seen the two

142
00:08:28,520 --> 00:08:32,280
Speaker 4:  of them walk around together, like very specifically like

143
00:08:32,280 --> 00:08:35,800
Speaker 4:  that. Like they did it that way so that it would get out.

144
00:08:35,800 --> 00:08:39,680
Speaker 4:  Like they made a show of the two of them walking around such that other

145
00:08:39,680 --> 00:08:43,400
Speaker 4:  people would see them walking around to so that they wouldn't have to confirm

146
00:08:43,400 --> 00:08:45,220
Speaker 4:  it officially. Which is,

147
00:08:45,220 --> 00:08:48,960
Speaker 5:  And we assume it was because he wanted to talk about the 30%, which

148
00:08:48,960 --> 00:08:52,440
Speaker 5:  Twitter wouldn't actually have to pay because it's less for these kind of

149
00:08:52,440 --> 00:08:52,960
Speaker 5:  subscriptions.

150
00:08:52,960 --> 00:08:55,440
Speaker 4:  Well it's 30% the first year. So there, there this is like,

151
00:08:55,440 --> 00:08:56,760
Speaker 5:  But then it like drops,

152
00:08:56,760 --> 00:09:00,640
Speaker 4:  Right? It drops to 15 in the second year. This is when I say

153
00:09:00,640 --> 00:09:03,880
Speaker 4:  like this whole story is out of

154
00:09:03,880 --> 00:09:07,800
Speaker 4:  control. We've done this before. I've been here, I

155
00:09:07,800 --> 00:09:11,000
Speaker 4:  live here, I built a, I have a vacation home in the app

156
00:09:11,000 --> 00:09:14,920
Speaker 4:  store like Tim Sweeney, you know, he

157
00:09:14,920 --> 00:09:18,600
Speaker 4:  sails the ship here once a year to yell about it. Like

158
00:09:18,600 --> 00:09:22,520
Speaker 4:  we spend a lot of time talking about these policies. They're not

159
00:09:22,520 --> 00:09:25,920
Speaker 4:  great. I don't think that the vast majority of the tech

160
00:09:25,920 --> 00:09:29,840
Speaker 4:  industry loves the duopoly power of Apple and Google when

161
00:09:29,840 --> 00:09:33,280
Speaker 4:  it comes to their stores and especially these fees for in-app purchases.

162
00:09:33,280 --> 00:09:37,080
Speaker 4:  Right? And I know that that's true because there

163
00:09:37,080 --> 00:09:40,270
Speaker 4:  were trials about it because

164
00:09:40,270 --> 00:09:43,900
Speaker 4:  Epic sued these companies over those policies.

165
00:09:43,900 --> 00:09:47,520
Speaker 4:  The trial took a month, apple won the Google one is like

166
00:09:47,520 --> 00:09:51,400
Speaker 4:  ongoing. The Apple one is all the way up at the court of appeals. They've

167
00:09:51,400 --> 00:09:55,160
Speaker 4:  already had arguments like that's where we're all the way

168
00:09:55,160 --> 00:09:58,500
Speaker 4:  there and now it's because of Elon. We're like starting at the beginning

169
00:09:58,500 --> 00:10:02,340
Speaker 4:  and he's literally tweeting, did you know Apple charges a fee?

170
00:10:02,340 --> 00:10:06,160
Speaker 4:  And it's, to me it's, there's an element of

171
00:10:06,160 --> 00:10:10,030
Speaker 4:  bad faith embedded in that you don't say, well

172
00:10:10,030 --> 00:10:12,230
Speaker 4:  that's like the most gentle way of saying

173
00:10:12,230 --> 00:10:15,800
Speaker 5:  I have a question though. Was the 30%, the 30% is the first year you're on,

174
00:10:15,800 --> 00:10:17,920
Speaker 5:  you're on the app store, right? Like the first year you have the

175
00:10:17,920 --> 00:10:19,710
Speaker 4:  For a subscription product. Yes.

176
00:10:19,710 --> 00:10:23,600
Speaker 5:  Didn't Twitter already launch this launch this subscription

177
00:10:23,600 --> 00:10:24,410
Speaker 5:  product?

178
00:10:24,410 --> 00:10:28,200
Speaker 4:  So the Twitter blue, which was I blew is $4 a month. I paid for that version

179
00:10:28,200 --> 00:10:31,940
Speaker 4:  of Blue cuz that was the one that on our site and many others

180
00:10:31,940 --> 00:10:35,760
Speaker 4:  got like blocked the ads. So if you clicked on a link to our site

181
00:10:35,760 --> 00:10:38,800
Speaker 4:  from Twitter and you were paying for Twitter Blue, we wouldn't show you the

182
00:10:38,800 --> 00:10:42,120
Speaker 4:  ads and we would get like, you know, sense we would get, we would click pennies

183
00:10:42,120 --> 00:10:44,760
Speaker 4:  from you. This is part of your Twitter blue subscription. Thank you. The

184
00:10:44,760 --> 00:10:47,960
Speaker 4:  Spotify, the business model that Spotify has used to make so many artists

185
00:10:47,960 --> 00:10:51,840
Speaker 4:  Rich had finally come to publishing by your $4 a month Twitter

186
00:10:51,840 --> 00:10:55,040
Speaker 4:  blue subscription. But I was paying for that one cuz I thought it was nice

187
00:10:55,040 --> 00:10:58,080
Speaker 4:  to pay the publishers that I visit most often

188
00:10:58,080 --> 00:11:01,480
Speaker 4:  directly. Was I mostly paying the company that I work for? Yes,

189
00:11:01,480 --> 00:11:05,200
Speaker 4:  but I was paying for that one and that one was indeed an in-app

190
00:11:05,200 --> 00:11:08,400
Speaker 4:  purchase. And I had talked to Cavan BPO who

191
00:11:08,400 --> 00:11:12,230
Speaker 4:  was two heads of product ago. Alex.

192
00:11:12,230 --> 00:11:15,510
Speaker 4:  Yeah, actually, yeah,

193
00:11:15,510 --> 00:11:19,090
Speaker 4:  yeah. I dunno how to describe it. Kaban was the head of product of Twitter.

194
00:11:19,090 --> 00:11:22,960
Speaker 4:  He was, he was reasonably successful for a Twitter, had a product under

195
00:11:22,960 --> 00:11:26,720
Speaker 4:  Dorsey and he was on decoder and I spent a lot of time asking

196
00:11:26,720 --> 00:11:30,200
Speaker 4:  him about the 30%, 15% fee. Yeah.

197
00:11:30,200 --> 00:11:34,020
Speaker 4:  Because everything Twitter wanted to do at that time

198
00:11:34,020 --> 00:11:37,640
Speaker 4:  ran into the fee, this is Twitter Blue

199
00:11:37,640 --> 00:11:41,220
Speaker 4:  expanding it. This is, they were gonna do a competitor, a sub stack,

200
00:11:41,220 --> 00:11:44,500
Speaker 4:  you know, the swirl of NFT nonsense

201
00:11:44,500 --> 00:11:48,480
Speaker 4:  was raging. It was like NFT summer. And I was like, what are you gonna do

202
00:11:48,480 --> 00:11:52,410
Speaker 4:  about these fees? And he was very clear in that interview.

203
00:11:52,410 --> 00:11:55,240
Speaker 4:  We are not, not in the business of skirting the platform real. So we're gonna

204
00:11:55,240 --> 00:11:58,600
Speaker 4:  pay the money and try to build our businesses the right way. And maybe if

205
00:11:58,600 --> 00:12:01,900
Speaker 4:  we get enough leverage we can go talk to Apple. So that's where Twitter

206
00:12:01,900 --> 00:12:05,880
Speaker 4:  was this new version of Blue $8. He

207
00:12:05,880 --> 00:12:09,480
Speaker 4:  needs every one of those pennies to make up for the lost advertising revenue.

208
00:12:09,480 --> 00:12:09,840
Speaker 4:  Right.

209
00:12:09,840 --> 00:12:13,640
Speaker 5:  But my question is, did Apple restart the clock was Apple

210
00:12:13,640 --> 00:12:17,320
Speaker 5:  like, oh, new owner. All right, we're back to 30%. You gotta wait a whole

211
00:12:17,320 --> 00:12:17,810
Speaker 5:  year.

212
00:12:17,810 --> 00:12:20,840
Speaker 4:  No, no, no, no. Cuz it's a new product. It doesn't matter.

213
00:12:20,840 --> 00:12:22,200
Speaker 5:  Oh, it doesn't matter. Okay.

214
00:12:22,200 --> 00:12:25,960
Speaker 4:  Right. It's the consumer, it's not the company. So I sign

215
00:12:25,960 --> 00:12:29,480
Speaker 4:  up the first year that I subscribe to you Alex

216
00:12:29,480 --> 00:12:33,400
Speaker 4:  Kranz, and that purchase Apple will take 30%. The second year

217
00:12:33,400 --> 00:12:36,880
Speaker 4:  of my subscription to you is 15%. Okay. But that's per product,

218
00:12:36,880 --> 00:12:37,790
Speaker 4:  per customer.

219
00:12:37,790 --> 00:12:38,630
Speaker 5:  Okay.

220
00:12:38,630 --> 00:12:41,880
Speaker 6:  Yeah. I, I actually think we're maybe overplaying the importance of the

221
00:12:41,880 --> 00:12:45,560
Speaker 6:  30%. Elon has even talked internally since he took over about

222
00:12:45,560 --> 00:12:49,400
Speaker 6:  how they're intentionally only doing blue through iOS because they want to

223
00:12:49,400 --> 00:12:52,920
Speaker 6:  use Apple's payments layer and security

224
00:12:52,920 --> 00:12:56,760
Speaker 6:  because they don't have it in house. They don't have the ability to do

225
00:12:56,760 --> 00:13:00,450
Speaker 6:  it. So I don't actually think Musk has a problem with the 30%.

226
00:13:00,450 --> 00:13:04,360
Speaker 6:  If anything, he was probably sending out grenades because a conversation

227
00:13:04,360 --> 00:13:08,160
Speaker 6:  had started to happen where Apple was going. And this is exposing the reality

228
00:13:08,160 --> 00:13:11,840
Speaker 6:  of Silicon Valley, which is that Apple is Silicon Valley's strongest

229
00:13:11,840 --> 00:13:15,480
Speaker 6:  speech regulator. They just don't call themselves that. And that's because

230
00:13:15,480 --> 00:13:19,400
Speaker 6:  they routinely will go to a social network if they don't like what they're

231
00:13:19,400 --> 00:13:22,320
Speaker 6:  seeing or they don't like the direction something is going. I mean they booted

232
00:13:22,320 --> 00:13:24,550
Speaker 6:  Parlor, this is the most famous example of them actually.

233
00:13:24,550 --> 00:13:27,030
Speaker 5:  Whoa, whoa, whoa. That's not the most famous example.

234
00:13:27,030 --> 00:13:28,480
Speaker 6:  What is the most famous example?

235
00:13:28,480 --> 00:13:30,550
Speaker 5:  Movie gate at Tumblr?

236
00:13:30,550 --> 00:13:31,070
Speaker 4:  Yeah.

237
00:13:31,070 --> 00:13:33,440
Speaker 6:  Okay. I I know it all comes back to Tum. It

238
00:13:33,440 --> 00:13:35,630
Speaker 5:  Always comes back to Tumblr. Always.

239
00:13:35,630 --> 00:13:38,760
Speaker 6:  I would say Parlor in the moment it was in was a bigger deal. Yeah. But,

240
00:13:38,760 --> 00:13:42,720
Speaker 6:  but Apple is, Silicon Valley's defacto speech are

241
00:13:42,720 --> 00:13:46,360
Speaker 6:  this because of the way they leveraged the store. What probably happened

242
00:13:46,360 --> 00:13:50,000
Speaker 6:  around the time Schiller deleted his account was Twitter got a message

243
00:13:50,000 --> 00:13:53,720
Speaker 6:  saying, Hey, we're noticing the direction that the site's

244
00:13:53,720 --> 00:13:57,080
Speaker 6:  going. All the reports we saw early on about the spike in

245
00:13:57,080 --> 00:14:00,800
Speaker 6:  racist tweets, hateful tweets, you fired all your

246
00:14:00,800 --> 00:14:04,560
Speaker 6:  moderators. We have concerns here. And guess what Twitter's trying to queue

247
00:14:04,560 --> 00:14:08,520
Speaker 6:  in the revamp of Blue, which they need to push an update for which

248
00:14:08,520 --> 00:14:11,600
Speaker 6:  Apple can hold. And they do this all the time where they don't say we're

249
00:14:11,600 --> 00:14:15,120
Speaker 6:  gonna remove you. They say, ah, this update, you know, it would be a shame

250
00:14:15,120 --> 00:14:19,040
Speaker 6:  if it never, you know, came out. And that's probably

251
00:14:19,040 --> 00:14:22,440
Speaker 6:  what was going on. And you know, Elon actually

252
00:14:22,440 --> 00:14:26,280
Speaker 6:  responded to our own Jake Kas earlier in the week when Jake

253
00:14:26,280 --> 00:14:30,000
Speaker 6:  asked directly, is Apple threatening you all or making

254
00:14:30,000 --> 00:14:33,840
Speaker 6:  moderation demands? And he said yes. And so that

255
00:14:33,840 --> 00:14:37,680
Speaker 6:  conversation with Cook was probably Elon saying, no, look like

256
00:14:37,680 --> 00:14:41,560
Speaker 6:  I care about this stuff. You know, I don't want the bad stuff and

257
00:14:41,560 --> 00:14:45,320
Speaker 6:  Cook going, okay, okay now gimme my 30% and, and Musk

258
00:14:45,320 --> 00:14:45,600
Speaker 6:  left.

259
00:14:45,600 --> 00:14:49,440
Speaker 5:  So definitely just real quick, it definitely definitely wasn't

260
00:14:49,440 --> 00:14:53,120
Speaker 5:  him going and begging Tim Cook to do what Tim Cook has repeatedly

261
00:14:53,120 --> 00:14:56,950
Speaker 5:  refused to do and buy Twitter.

262
00:14:56,950 --> 00:15:00,920
Speaker 6:  I don't Well it's kind of amazing that this is what got Elon a meeting

263
00:15:00,920 --> 00:15:04,720
Speaker 6:  with Tim Cook because if we all remember there was some reporting, I don't

264
00:15:04,720 --> 00:15:07,600
Speaker 6:  remember if this was two years ago, three years ago, about how there were

265
00:15:07,600 --> 00:15:11,040
Speaker 6:  conversations where Elon maybe wanted Apple to look at buying Tesla many

266
00:15:11,040 --> 00:15:14,840
Speaker 6:  years ago when it was struggling and Tim Cook like didn't answer his

267
00:15:14,840 --> 00:15:18,680
Speaker 6:  call. Yeah. And, and Cook was like, we've never spoken and

268
00:15:18,680 --> 00:15:22,200
Speaker 6:  it only took buying, you know, Twitter for 44 billion to get a meeting with

269
00:15:22,200 --> 00:15:22,360
Speaker 6:  Cook.

270
00:15:22,360 --> 00:15:26,000
Speaker 4:  So. Well no, we can, we can unpack that further. So I think Alex, the, the

271
00:15:26,000 --> 00:15:29,640
Speaker 4:  general sweep of what you've laid out is correct. Right. What

272
00:15:29,640 --> 00:15:33,450
Speaker 4:  we also know is that what for Facebook

273
00:15:33,450 --> 00:15:37,240
Speaker 4:  or Instagram or any of the big companies, it's,

274
00:15:37,240 --> 00:15:40,800
Speaker 4:  it's not just an irregular series of conversations with Apple,

275
00:15:40,800 --> 00:15:44,680
Speaker 4:  right? Yes. These, if you run an app like Twitter or Instagram or whatever

276
00:15:44,680 --> 00:15:47,600
Speaker 4:  it is, your relationship with App

277
00:15:47,600 --> 00:15:51,480
Speaker 4:  Review, like you're in each other's pockets. Yes. Cause those

278
00:15:51,480 --> 00:15:54,040
Speaker 4:  companies are pushing updates constantly. That's why their release notes

279
00:15:54,040 --> 00:15:57,990
Speaker 4:  are so bad in their apps. Like it's just like bug figs is and other improvements,

280
00:15:57,990 --> 00:16:01,320
Speaker 4:  it's because they're, they're just like hundreds of updates, right. That

281
00:16:01,320 --> 00:16:04,880
Speaker 4:  go into these apps constantly and they wanna push them out really fast to

282
00:16:04,880 --> 00:16:08,290
Speaker 4:  support whatever they're doing at the other companies.

283
00:16:08,290 --> 00:16:11,960
Speaker 4:  There's basically an entire staff of people that just

284
00:16:11,960 --> 00:16:15,880
Speaker 4:  manages Apple. Right? Like you're in charge of these

285
00:16:15,880 --> 00:16:19,600
Speaker 4:  app reviewers, you're going to Phil Short, Eddie Q are your best friends,

286
00:16:19,600 --> 00:16:23,400
Speaker 4:  take 'em out to dinner, take 'em out to like get it done. Yeah. Elon

287
00:16:23,400 --> 00:16:27,270
Speaker 4:  fired all those people. So there's a, there's

288
00:16:27,270 --> 00:16:30,440
Speaker 4:  I would say like yes, maybe Apple's a little worried Yes.

289
00:16:30,440 --> 00:16:34,000
Speaker 4:  Whatever. At the same time the way they express those

290
00:16:34,000 --> 00:16:37,970
Speaker 4:  concerns and the very true implicit threat

291
00:16:37,970 --> 00:16:41,840
Speaker 4:  of if you don't meet our demands we can kick you off the

292
00:16:41,840 --> 00:16:45,620
Speaker 4:  store. Elon just doesn't have the people C can translate

293
00:16:45,620 --> 00:16:49,330
Speaker 4:  the Apple weirdness for him Yeah.

294
00:16:49,330 --> 00:16:53,000
Speaker 4:  To manage that relationship. Yeah. And I think this just quickly

295
00:16:53,000 --> 00:16:56,760
Speaker 4:  spiraled out of control where Apple is probably saying

296
00:16:56,760 --> 00:17:00,320
Speaker 4:  stuff that almost always says that's, that's my like vague

297
00:17:00,320 --> 00:17:03,960
Speaker 4:  understanding of it. That from Apple's perspective, this was just the normal

298
00:17:03,960 --> 00:17:06,920
Speaker 4:  course of business. And like if you're not used to them,

299
00:17:06,920 --> 00:17:10,560
Speaker 4:  mafia sort of threat is like very threatening.

300
00:17:10,560 --> 00:17:11,000
Speaker 4:  Yeah.

301
00:17:11,000 --> 00:17:13,280
Speaker 6:  You gotta go make your pilgrimage if you're,

302
00:17:13,280 --> 00:17:16,800
Speaker 4:  Yeah. So Elon was like, they threatened me and Apple's like no, no, this

303
00:17:16,800 --> 00:17:20,080
Speaker 4:  is just the basic, this is just like the foundational threat.

304
00:17:20,080 --> 00:17:23,880
Speaker 5:  So we didn't even take this mad out of the car, we left it, we're just

305
00:17:23,880 --> 00:17:25,800
Speaker 5:  knocking. We're just saying hi, what's,

306
00:17:25,800 --> 00:17:28,080
Speaker 6:  He's like, can I tell you about a thing called app tracking

307
00:17:28,080 --> 00:17:30,010
Speaker 6:  transparency?

308
00:17:30,010 --> 00:17:33,560
Speaker 4:  So like, so here's what we did. We destroyed ME'S business

309
00:17:33,560 --> 00:17:37,200
Speaker 4:  overnight and made it seem like we're the good guys. That's what we're able

310
00:17:37,200 --> 00:17:37,560
Speaker 4:  to do to

311
00:17:37,560 --> 00:17:41,160
Speaker 6:  You. It's just, this is such a strange dynamic because as we also found out

312
00:17:41,160 --> 00:17:44,760
Speaker 6:  this week and it, it makes perfect sense to where, I wish I would've just

313
00:17:44,760 --> 00:17:48,410
Speaker 6:  thought of this earlier. Apple is Twitter's largest advertiser. Yeah.

314
00:17:48,410 --> 00:17:51,800
Speaker 6:  So not only is Twitter totally reliant on Apple to

315
00:17:51,800 --> 00:17:55,360
Speaker 6:  survive from a distribution perspective, they also need their

316
00:17:55,360 --> 00:17:58,110
Speaker 6:  money to just like pay the bills.

317
00:17:58,110 --> 00:18:01,680
Speaker 4:  This is the question mark I have. I don't know why Apple is Twitter's biggest

318
00:18:01,680 --> 00:18:03,240
Speaker 4:  advertiser. I don't know what they get out of it because

319
00:18:03,240 --> 00:18:06,840
Speaker 6:  They hate Facebook. Where else are they going to advertise on social? So

320
00:18:06,840 --> 00:18:10,720
Speaker 6:  I mean like Apple famously will not even put Facebook in like

321
00:18:10,720 --> 00:18:14,560
Speaker 6:  an app store list of like apps you need for the holidays. Like Apple

322
00:18:14,560 --> 00:18:17,960
Speaker 6:  will not touch Facebook or any of their properties. They also don't really

323
00:18:17,960 --> 00:18:19,280
Speaker 6:  care about targeting as we

324
00:18:19,280 --> 00:18:20,290
Speaker 4:  See.

325
00:18:20,290 --> 00:18:24,150
Speaker 6:  So if you're, if you're them like Twitter's actually the perfect platform.

326
00:18:24,150 --> 00:18:28,120
Speaker 6:  It's like just a brandy advertising like thing

327
00:18:28,120 --> 00:18:31,560
Speaker 6:  for events and live stuff which they do all the time that promoted

328
00:18:31,560 --> 00:18:35,160
Speaker 6:  hashtags. It makes perfect sense that Apple would actually be Twitter's

329
00:18:35,160 --> 00:18:38,140
Speaker 6:  largest advertiser. I'm just kicking myself that I didn't think of it sooner

330
00:18:38,140 --> 00:18:41,920
Speaker 4:  And now and that spend is going down, although there is some reporting that

331
00:18:41,920 --> 00:18:42,440
Speaker 4:  it has gone up.

332
00:18:42,440 --> 00:18:46,400
Speaker 6:  Well you can't just, Twitter is not plug and play like Facebook is where

333
00:18:46,400 --> 00:18:49,760
Speaker 6:  it's a lot of direct response advertisers that are running like

334
00:18:49,760 --> 00:18:53,640
Speaker 6:  hyper, you know, measurable campaigns that can be turned or on or off

335
00:18:53,640 --> 00:18:57,080
Speaker 6:  at a dime. Twitter's much more brand centric. We've talked about this on

336
00:18:57,080 --> 00:19:01,000
Speaker 6:  past shows and you can't, you can't just claw back everything immediately.

337
00:19:01,000 --> 00:19:04,880
Speaker 6:  Although it seems very real that Apple has significantly clawed back at spend

338
00:19:04,880 --> 00:19:05,650
Speaker 6:  though not all of it.

339
00:19:05,650 --> 00:19:08,940
Speaker 4:  So that's one piece, right. Which is the

340
00:19:08,940 --> 00:19:12,760
Speaker 4:  overreacting to the threat of app store

341
00:19:12,760 --> 00:19:16,000
Speaker 4:  control. Which is very funny.

342
00:19:16,000 --> 00:19:19,840
Speaker 4:  Like I, I think app store control is bad. I think if you have listened to

343
00:19:19,840 --> 00:19:23,440
Speaker 4:  the show for more than five minutes, you know that I think Apple's control

344
00:19:23,440 --> 00:19:27,360
Speaker 4:  of innovation on its phone is maybe a little bit more than

345
00:19:27,360 --> 00:19:29,760
Speaker 4:  it should be. Yeah. And that's like me being

346
00:19:29,760 --> 00:19:33,360
Speaker 4:  nice, but it's still there and it's also

347
00:19:33,360 --> 00:19:36,920
Speaker 4:  just everyone knows it. Like we've, we've done 15

348
00:19:36,920 --> 00:19:38,130
Speaker 4:  rounds of this story.

349
00:19:38,130 --> 00:19:41,800
Speaker 5:  It was kind of like when like your parent calls you after an Apple

350
00:19:41,800 --> 00:19:45,110
Speaker 5:  event and says, well did you hear they had a new iPhone? And you're like,

351
00:19:45,110 --> 00:19:47,720
Speaker 5:  yeah, yeah, yeah, yeah definitely. Like

352
00:19:47,720 --> 00:19:50,480
Speaker 4:  Is this, but then actually my mom lately is like, what does the new one do?

353
00:19:50,480 --> 00:19:51,850
Speaker 4:  And I have to be like

354
00:19:51,850 --> 00:19:53,930
Speaker 6:  Dynamic island

355
00:19:53,930 --> 00:19:56,910
Speaker 5:  Parents are not impressed by the dynamic island.

356
00:19:56,910 --> 00:19:58,520
Speaker 4:  It's not a point for that

357
00:19:58,520 --> 00:20:00,710
Speaker 6:  Black black box on the top. Now you can't move.

358
00:20:00,710 --> 00:20:04,230
Speaker 4:  I will say that my mom, first of all, my mom cried

359
00:20:04,230 --> 00:20:07,760
Speaker 4:  when Steve Jobs died. It's a real fact. She was very sad about it. And now

360
00:20:07,760 --> 00:20:11,000
Speaker 4:  lately she, whenever she's unhappy with her phone, she's like, Steve Chop

361
00:20:11,000 --> 00:20:13,820
Speaker 4:  would've never signed a film like this. It's like perfect.

362
00:20:13,820 --> 00:20:17,410
Speaker 6:  Can you imagine Steve Jobs negotiating with Elon this week?

363
00:20:17,410 --> 00:20:21,240
Speaker 4:  He wouldn't. All I can imagine I would spend the rest of the show just writing

364
00:20:21,240 --> 00:20:22,600
Speaker 4:  out that negotiation. He

365
00:20:22,600 --> 00:20:22,840
Speaker 5:  Would've

366
00:20:22,840 --> 00:20:25,600
Speaker 4:  Destroyed it. Cause he wouldn't put up with any of it. This is actually,

367
00:20:25,600 --> 00:20:29,480
Speaker 4:  I think the important thing, this is why Elon ended up on

368
00:20:29,480 --> 00:20:33,130
Speaker 4:  the Apple campus because Tim Cook is

369
00:20:33,130 --> 00:20:36,970
Speaker 4:  an underrated, savvy political operator. Right.

370
00:20:36,970 --> 00:20:40,680
Speaker 4:  If you think about Tim Cook and what he accomplished over the past five

371
00:20:40,680 --> 00:20:44,400
Speaker 4:  years, yet we can name a lot of things actually at the top of the

372
00:20:44,400 --> 00:20:48,200
Speaker 4:  list is managing Donald Trump, Foxcon and China

373
00:20:48,200 --> 00:20:52,080
Speaker 4:  through a trade war and coming out having manufactured and

374
00:20:52,080 --> 00:20:54,520
Speaker 4:  shipped war iPhones than ever before. Cause that was not

375
00:20:54,520 --> 00:20:57,520
Speaker 4:  a guaranteed situation at all. Well it's

376
00:20:57,520 --> 00:20:59,360
Speaker 5:  Not going great for him with Foxcon right now,

377
00:20:59,360 --> 00:21:02,320
Speaker 4:  But it's not, it's, it's going very badly with him for Foxcon right now.

378
00:21:02,320 --> 00:21:06,000
Speaker 4:  But in terms of his understanding Yeah. Of how to

379
00:21:06,000 --> 00:21:09,650
Speaker 4:  manage that kind of personality,

380
00:21:09,650 --> 00:21:12,880
Speaker 4:  he has more practice than maybe any business owner in America.

381
00:21:12,880 --> 00:21:16,340
Speaker 4:  Right. And Alex, he, well

382
00:21:16,340 --> 00:21:20,320
Speaker 4:  and two Alex's and he keeps reminding me a lot

383
00:21:20,320 --> 00:21:23,000
Speaker 4:  of what we're seeing from Elon right now tracks with Trump. Like it's very

384
00:21:23,000 --> 00:21:26,560
Speaker 4:  reminiscent of Trump. Yeah. Yeah. So I don't know this for

385
00:21:26,560 --> 00:21:30,450
Speaker 4:  sure, but I have spent over a decade paying a lot of attention

386
00:21:30,450 --> 00:21:34,000
Speaker 4:  to Apple and knowing a lot of people in and around there

387
00:21:34,000 --> 00:21:37,840
Speaker 4:  like, you know, sometimes I'll just be in my house like pouring

388
00:21:37,840 --> 00:21:40,400
Speaker 4:  coffee and my wife will walk into the room and be like, why are you tense?

389
00:21:40,400 --> 00:21:43,000
Speaker 4:  And I haven't said a word to her and we haven't been in the same room for

390
00:21:43,000 --> 00:21:46,960
Speaker 4:  more than 10 seconds and she knows, and the vibe's coming off

391
00:21:46,960 --> 00:21:50,880
Speaker 4:  of Apple were, were that right? Like you just pay a lot of attention

392
00:21:50,880 --> 00:21:52,640
Speaker 4:  to this company, you see. They

393
00:21:52,640 --> 00:21:56,040
Speaker 6:  Were like, I'm charging my mouse right now and it's upside down and I'm just

394
00:21:56,040 --> 00:21:58,540
Speaker 6:  pissed.

395
00:21:58,540 --> 00:22:01,680
Speaker 4:  And my sense is he started doing these tweets about Apple on free speech

396
00:22:01,680 --> 00:22:05,030
Speaker 4:  and the store and the 30% and they wanted to come out

397
00:22:05,030 --> 00:22:09,000
Speaker 4:  storming and basically being like, yeah, it's our

398
00:22:09,000 --> 00:22:12,360
Speaker 4:  store 30% like our way or the highway, we just beat

399
00:22:12,360 --> 00:22:16,310
Speaker 4:  Epic screw you. And then the weird

400
00:22:16,310 --> 00:22:20,280
Speaker 4:  g p tweets started and Ted Cruz lit up and Ron DeSantis lit up and

401
00:22:20,280 --> 00:22:24,040
Speaker 4:  Mike Lee who co-sponsored the antitrust bills lit up.

402
00:22:24,040 --> 00:22:28,000
Speaker 4:  Tucker Carlson did a segment and the culture war started a

403
00:22:28,000 --> 00:22:31,470
Speaker 4:  McKenna wrote a great piece about this Apple, like Elon drove

404
00:22:31,470 --> 00:22:34,740
Speaker 4:  Apple into the most

405
00:22:34,740 --> 00:22:38,640
Speaker 4:  unpredictable ideologically incoherent part of America, which is the Go

406
00:22:38,640 --> 00:22:42,600
Speaker 4:  P culture war. And they realized, oh this somehow this is going

407
00:22:42,600 --> 00:22:45,840
Speaker 4:  to end with a bill that allows side loading on the app.

408
00:22:45,840 --> 00:22:49,620
Speaker 4:  Yeah. And they decided that instead of going on offense,

409
00:22:49,620 --> 00:22:53,560
Speaker 4:  Tim Cook would be a politician and he would charm Elon with a walker

410
00:22:53,560 --> 00:22:57,000
Speaker 4:  in a circle around the campus. And they get, and I'm pretty sure that that

411
00:22:57,000 --> 00:23:00,560
Speaker 4:  is just the, the flow of that decision that occurred because

412
00:23:00,560 --> 00:23:03,960
Speaker 4:  unlike Epic and Fortnite, when they went fully on

413
00:23:03,960 --> 00:23:07,920
Speaker 4:  offense, they see this other thing, this other thing that Elon

414
00:23:07,920 --> 00:23:11,680
Speaker 4:  has a handle into, which is just the wildness of the culture

415
00:23:11,680 --> 00:23:15,490
Speaker 4:  war. Like Fortnite did not get a Tucker Carlson segment about free speech.

416
00:23:15,490 --> 00:23:19,370
Speaker 6:  No, no. I mean what did Ron DeSantis say? It was basically like if Twitter

417
00:23:19,370 --> 00:23:23,320
Speaker 6:  is banned by Apple, you know, we need to regulate Apple.

418
00:23:23,320 --> 00:23:24,600
Speaker 6:  Yeah. I mean that was the direct

419
00:23:24,600 --> 00:23:27,440
Speaker 4:  Yeah. He was like, Congress should respond to this like raw demonstration

420
00:23:27,440 --> 00:23:31,400
Speaker 4:  of monopoly power and it's like, first of all, it's

421
00:23:31,400 --> 00:23:35,000
Speaker 4:  not that I'm not sympathetic to it. Yeah, right. We've had

422
00:23:35,000 --> 00:23:38,800
Speaker 4:  like David Ci and Amy Klobuchar like have been on this show

423
00:23:38,800 --> 00:23:42,780
Speaker 4:  talking about their antitrust builds. Yeah, I get it. But

424
00:23:42,780 --> 00:23:46,610
Speaker 4:  the, the solution is like market competition. It's not,

425
00:23:46,610 --> 00:23:50,600
Speaker 4:  we should punish Apple because they pissed off Elon. And when you're, I I

426
00:23:50,600 --> 00:23:54,160
Speaker 4:  just think that level of unhinged actually made Apple

427
00:23:54,160 --> 00:23:57,920
Speaker 4:  change its tactic away from what they did with Epic.

428
00:23:57,920 --> 00:23:59,440
Speaker 4:  Which is we'll see you in court.

429
00:23:59,440 --> 00:24:02,450
Speaker 5:  Like what's gonna happen though because we also have

430
00:24:02,450 --> 00:24:06,410
Speaker 5:  Ireland who is saying you suck

431
00:24:06,410 --> 00:24:10,040
Speaker 5:  to Twitter and is it seems ready to like fine it into

432
00:24:10,040 --> 00:24:12,050
Speaker 5:  oblivion. So we have like we have

433
00:24:12,050 --> 00:24:15,040
Speaker 4:  So wait, wait actually let's organize this conversation. Okay. So I think

434
00:24:15,040 --> 00:24:17,320
Speaker 4:  Keith was saying let's put a bone out. Yeah. We should talk about the rest

435
00:24:17,320 --> 00:24:17,560
Speaker 4:  of Twitter.

436
00:24:17,560 --> 00:24:21,080
Speaker 6:  Okay. And, and to put a bow on this, you know, with how smooth Tim is

437
00:24:21,080 --> 00:24:24,960
Speaker 6:  Elon tweets after the meeting goes, look we resolved this

438
00:24:24,960 --> 00:24:28,480
Speaker 6:  misunderstanding was the word he used where like two days before, maybe even

439
00:24:28,480 --> 00:24:32,000
Speaker 6:  a day before he was tweeting at Jake and other people being like, apple hates

440
00:24:32,000 --> 00:24:35,920
Speaker 6:  free speech in America. He meets with Tim Cook for 30 minutes and

441
00:24:35,920 --> 00:24:39,680
Speaker 6:  is like, it was a misunderstanding. Tim was clear that Apple never

442
00:24:39,680 --> 00:24:43,200
Speaker 6:  considered banning us. Everything's chill and then he follows Tim Cook on

443
00:24:43,200 --> 00:24:44,000
Speaker 6:  Twitter and then it's

444
00:24:44,000 --> 00:24:47,690
Speaker 4:  Like he deletes his, I'm gonna go to war with you tweets. Right, right.

445
00:24:47,690 --> 00:24:51,000
Speaker 6:  So like if you, if you're gonna comment the king, you best not miss. I mean

446
00:24:51,000 --> 00:24:54,000
Speaker 6:  that was the lesson I think for Elon and Apple this week.

447
00:24:54,000 --> 00:24:54,390
Speaker 4:  Yeah.

448
00:24:54,390 --> 00:24:56,920
Speaker 5:  Wait, who's the king in this scenario? Tim

449
00:24:56,920 --> 00:24:58,320
Speaker 4:  Cook. It's Tim Cook. Is

450
00:24:58,320 --> 00:24:58,680
Speaker 5:  It because

451
00:24:58,680 --> 00:24:59,850
Speaker 6:  Tim Cook? Absolutely.

452
00:24:59,850 --> 00:25:03,760
Speaker 5:  No. Cuz Elon threw a giant tantrum and got what he couldn't get for

453
00:25:03,760 --> 00:25:05,710
Speaker 5:  years, which was a meeting with Tim Cook.

454
00:25:05,710 --> 00:25:08,680
Speaker 4:  That's not, he's the richest fan in the world. If he really wants a meeting

455
00:25:08,680 --> 00:25:09,880
Speaker 4:  with Tim Cook, he can get a meeting with

456
00:25:09,880 --> 00:25:13,560
Speaker 6:  Tim also. Like Tim Cook didn't come to Twitter, apple, you know, like, like

457
00:25:13,560 --> 00:25:17,080
Speaker 6:  Elon came to Apple. Like there's this, Tim Cook's not

458
00:25:17,080 --> 00:25:19,780
Speaker 6:  gonna go meet. Yeah.

459
00:25:19,780 --> 00:25:23,200
Speaker 4:  Tim Cook is not wandering the, the desolate empty halls with

460
00:25:23,200 --> 00:25:27,120
Speaker 4:  Twitter. He's like, we're not even getting

461
00:25:27,120 --> 00:25:29,080
Speaker 4:  in the building, we're gonna walk around outside

462
00:25:29,080 --> 00:25:31,310
Speaker 5:  Kitchen sink sitting over there.

463
00:25:31,310 --> 00:25:35,200
Speaker 4:  Yeah. I mean that's the, I mean we have no idea what was said in this

464
00:25:35,200 --> 00:25:38,840
Speaker 4:  conversation, but Microsoft has tried for years to get out of the 30%

465
00:25:38,840 --> 00:25:42,680
Speaker 4:  cut. Microsoft has tried for years to evade after rules around game

466
00:25:42,680 --> 00:25:46,440
Speaker 4:  streaming and give Apple and they can't get there. And so I I think

467
00:25:46,440 --> 00:25:50,400
Speaker 4:  you'd, there's no way that Elon got anything outta the deal and I have

468
00:25:50,400 --> 00:25:54,150
Speaker 4:  no idea what Tim traded ahead to

469
00:25:54,150 --> 00:25:56,920
Speaker 4:  make him tweet what he tweeted right there. There has to be, they're both

470
00:25:56,920 --> 00:26:00,800
Speaker 4:  savvy business people. Yeah. They're not bad at this. They had to

471
00:26:00,800 --> 00:26:03,840
Speaker 4:  have come, he didn't just tell him, he like smelled good and he was like,

472
00:26:03,840 --> 00:26:07,680
Speaker 4:  oh I forgive you. Like he was, they exchanged something and we have no idea

473
00:26:07,680 --> 00:26:08,120
Speaker 4:  what that

474
00:26:08,120 --> 00:26:11,280
Speaker 6:  Exchange was. The most logical explanation was Apple was threatening to keep

475
00:26:11,280 --> 00:26:14,990
Speaker 6:  Twitter's app update in purgatory because of concerns about content moderation.

476
00:26:14,990 --> 00:26:18,920
Speaker 6:  Elon assured Tim that he had a handle on it, which

477
00:26:18,920 --> 00:26:22,540
Speaker 6:  debatable, but he obviously assured Tim and they left the meeting

478
00:26:22,540 --> 00:26:26,200
Speaker 6:  Tim going, okay we won't, we won't keep you in purgatory. That's the most

479
00:26:26,200 --> 00:26:30,120
Speaker 6:  likely explanation of what happened. I actually think 30% was

480
00:26:30,120 --> 00:26:32,840
Speaker 6:  maybe not raised at all. I would be shocked if it actually was cuz like that's

481
00:26:32,840 --> 00:26:35,870
Speaker 6:  not, that's a non-negotiable thing. Right. That's

482
00:26:35,870 --> 00:26:39,790
Speaker 5:  Well it is negotiable depending on who you are.

483
00:26:39,790 --> 00:26:40,280
Speaker 5:  Just,

484
00:26:40,280 --> 00:26:44,200
Speaker 4:  It's, yeah. It's negotiable. If you get a bunch of right wing members

485
00:26:44,200 --> 00:26:47,870
Speaker 4:  of Congress to sign in Charville,

486
00:26:47,870 --> 00:26:51,560
Speaker 4:  it's right there and it's, it was on an unlikely

487
00:26:51,560 --> 00:26:55,080
Speaker 4:  outcome. Yeah. Right, right. Like that's, and I, I think

488
00:26:55,080 --> 00:26:57,800
Speaker 4:  Apple recognized that and that's why they played it this way instead of the

489
00:26:57,800 --> 00:27:00,720
Speaker 4:  way that they have been playing. By the way Apple's position this whole time

490
00:27:00,720 --> 00:27:04,600
Speaker 4:  has been clear since the EPIC trial. Yeah. You can do

491
00:27:04,600 --> 00:27:07,680
Speaker 4:  side loading on our store. Yeah, you can whatever the stuff we're forced

492
00:27:07,680 --> 00:27:11,240
Speaker 4:  to in South Korea and other countries, developers still have to pay us

493
00:27:11,240 --> 00:27:15,000
Speaker 4:  the money. Right. Right. It's not just you can get around us, it's

494
00:27:15,000 --> 00:27:18,640
Speaker 4:  what we actually care about is the money and the decision, at least in

495
00:27:18,640 --> 00:27:22,330
Speaker 4:  this country. The judge basically said, yeah,

496
00:27:22,330 --> 00:27:25,840
Speaker 4:  apple is entitled to being paid for its intellectual property and its

497
00:27:25,840 --> 00:27:29,410
Speaker 4:  effort developing iOS. So even if the bill has passed Apple is,

498
00:27:29,410 --> 00:27:32,520
Speaker 4:  they've been pretty clear and consistent this whole time and they have rolled

499
00:27:32,520 --> 00:27:36,280
Speaker 4:  out this system in other countries that require, you know, other kinds of

500
00:27:36,280 --> 00:27:39,640
Speaker 4:  in-app purchasing systems to be present in iOS. The Apple still wants a cut,

501
00:27:39,640 --> 00:27:42,200
Speaker 4:  they don't really care. Yeah. You might not use your credit card process

502
00:27:42,200 --> 00:27:45,640
Speaker 4:  processor. What Apple's getting it's, it's money and I think that's actually

503
00:27:45,640 --> 00:27:48,440
Speaker 4:  the non-negotiable part, whether it's in-app purchases or whatever else.

504
00:27:48,440 --> 00:27:52,340
Speaker 4:  And I think Elon is, is smart. I think we can agree on that.

505
00:27:52,340 --> 00:27:55,960
Speaker 4:  But coming late to the game and pointing right at Tim Cook's

506
00:27:55,960 --> 00:27:59,720
Speaker 4:  services revenue line and being like, what if Les is like, you

507
00:27:59,720 --> 00:28:01,390
Speaker 4:  gotta try harder than that,

508
00:28:01,390 --> 00:28:04,880
Speaker 6:  That's a reality of life. The sun will rise and Apple will get its money.

509
00:28:04,880 --> 00:28:05,360
Speaker 6:  Yeah,

510
00:28:05,360 --> 00:28:09,120
Speaker 4:  Exactly. All right, let's talk about Twitter itself. If you've been reporting

511
00:28:09,120 --> 00:28:11,240
Speaker 4:  on it. Yes. What's the vibe in there right

512
00:28:11,240 --> 00:28:14,990
Speaker 6:  Now? Oh, well I think Monday was like the perfect like

513
00:28:14,990 --> 00:28:18,640
Speaker 6:  just microcosm of life inside Twitter. So Elon sends this

514
00:28:18,640 --> 00:28:22,600
Speaker 6:  email at like 3:00 AM as he's prone to do, saying

515
00:28:22,600 --> 00:28:26,380
Speaker 6:  we're gonna do code reviews again, bring your lines of code,

516
00:28:26,380 --> 00:28:30,020
Speaker 6:  which any engineer will tell you is an absurd

517
00:28:30,020 --> 00:28:33,920
Speaker 6:  exercise. And reminded again that he expects managers to be coding as well.

518
00:28:33,920 --> 00:28:37,480
Speaker 6:  Engineering managers. I think his direct quote was being unable to do so

519
00:28:37,480 --> 00:28:41,350
Speaker 6:  as like a calvary captain who can't ride a horse. Does he like, and

520
00:28:41,350 --> 00:28:41,840
Speaker 6:  does

521
00:28:41,840 --> 00:28:45,200
Speaker 5:  He know how like anything

522
00:28:45,200 --> 00:28:48,960
Speaker 5:  works outside of like the Elon Musk crafted

523
00:28:48,960 --> 00:28:50,040
Speaker 5:  world? Does he just understand

524
00:28:50,040 --> 00:28:52,400
Speaker 6:  He's the richest man in the world, Kranz. He knows all, he knows all, he

525
00:28:52,400 --> 00:28:52,600
Speaker 6:  knows

526
00:28:52,600 --> 00:28:53,120
Speaker 5:  Everything. He

527
00:28:53,120 --> 00:28:56,900
Speaker 6:  Knows everything. We respect Capitalism in America and free speech

528
00:28:56,900 --> 00:29:00,200
Speaker 6:  and in that order. So anyway, he sends this email, everyone's like

529
00:29:00,200 --> 00:29:03,400
Speaker 6:  frantically trying to figure out what this means. Does this mean more people

530
00:29:03,400 --> 00:29:07,160
Speaker 6:  are about to get fired? The code review doesn't happen. So everyone shows

531
00:29:07,160 --> 00:29:10,840
Speaker 6:  up to Twitter. San Francisco offices amazing for the Elon code review

532
00:29:10,840 --> 00:29:14,800
Speaker 6:  Monday evening. It does. He's not the, the no one can find Elon. There's

533
00:29:14,800 --> 00:29:18,360
Speaker 6:  no code reviews that happen. The fire alarm does get pulled and a bunch of

534
00:29:18,360 --> 00:29:21,730
Speaker 6:  engineers end up spending about an hour standing outside of Twitter's office

535
00:29:21,730 --> 00:29:24,400
Speaker 6:  as they figure out what goes on with the fire alarm. So that was like just

536
00:29:24,400 --> 00:29:26,320
Speaker 6:  Monday and then

537
00:29:26,320 --> 00:29:27,940
Speaker 4:  Progressively fire alarm got pulled.

538
00:29:27,940 --> 00:29:28,550
Speaker 6:  Yes.

539
00:29:28,550 --> 00:29:29,320
Speaker 4:  That's really

540
00:29:29,320 --> 00:29:32,960
Speaker 6:  Good. So that's, that's just like, and and then you have this

541
00:29:32,960 --> 00:29:35,720
Speaker 6:  remarkable thing where you have, and I think Kranz you were wanting to mention

542
00:29:35,720 --> 00:29:39,360
Speaker 6:  this earlier. Yeah. Twitter's VP of public policy who's based in

543
00:29:39,360 --> 00:29:43,280
Speaker 6:  Ireland, sued the company to keep them from

544
00:29:43,280 --> 00:29:47,120
Speaker 6:  firing her over the hardcore that she didn't say check the

545
00:29:47,120 --> 00:29:51,000
Speaker 6:  yes to from a couple weeks ago. And she won. Like this is the first

546
00:29:51,000 --> 00:29:54,960
Speaker 6:  example of a VP that I I've ever seen suing

547
00:29:54,960 --> 00:29:58,800
Speaker 6:  to stay employed. Have, have we heard of this? Has this is this, I mean it's

548
00:29:58,800 --> 00:30:02,520
Speaker 5:  Very common in like Europe because they have much stronger labor

549
00:30:02,520 --> 00:30:06,440
Speaker 5:  laws there. So I think we've seen this repeatedly with

550
00:30:06,440 --> 00:30:10,320
Speaker 5:  Twitter in Europe is that he has no grasp of labor laws there and he doesn't

551
00:30:10,320 --> 00:30:11,560
Speaker 5:  understand that. Like no, absolutely he

552
00:30:11,560 --> 00:30:14,360
Speaker 6:  Can't just fire. But I'm saying, but I'm saying a high ranking executive

553
00:30:14,360 --> 00:30:17,400
Speaker 6:  suing a company to stay employed. Right.

554
00:30:17,400 --> 00:30:21,360
Speaker 4:  Again, I think this is like a very European in America we solve our problems

555
00:30:21,360 --> 00:30:21,720
Speaker 4:  with cash.

556
00:30:21,720 --> 00:30:22,600
Speaker 6:  Yeah, that's true.

557
00:30:22,600 --> 00:30:25,080
Speaker 4:  Right. So you're like, you're mad at your company in America, you see them,

558
00:30:25,080 --> 00:30:28,600
Speaker 4:  you're like, pay me however much money I would've made the next year of employment

559
00:30:28,600 --> 00:30:32,560
Speaker 4:  and then I'm done with you. Other countries, other legal systems, you,

560
00:30:32,560 --> 00:30:35,360
Speaker 4:  other remedies are available. Like,

561
00:30:35,360 --> 00:30:37,270
Speaker 5:  No, you have to hire me back.

562
00:30:37,270 --> 00:30:40,610
Speaker 4:  Yeah, you're gonna hire me back. I still work here.

563
00:30:40,610 --> 00:30:44,480
Speaker 6:  So it's just, it's just, I think it's an, and like she

564
00:30:44,480 --> 00:30:48,320
Speaker 6:  was, she was technically like employed still under European law,

565
00:30:48,320 --> 00:30:51,080
Speaker 6:  but like had been locked out of her systems and she, she's just like toiling

566
00:30:51,080 --> 00:30:55,040
Speaker 6:  her thumbs. This is a VP of public policy being like, and now she's apparently

567
00:30:55,040 --> 00:30:55,720
Speaker 6:  back in the slack.

568
00:30:55,720 --> 00:30:57,080
Speaker 4:  It's like amazing. Well I can

569
00:30:57,080 --> 00:31:01,000
Speaker 5:  Tell someone Germany, there's is either Germany or France, there's a

570
00:31:01,000 --> 00:31:04,840
Speaker 5:  number of Twitter engineers who are also suing because they also got

571
00:31:04,840 --> 00:31:07,360
Speaker 5:  fired and you can't fire them. You

572
00:31:07,360 --> 00:31:08,080
Speaker 6:  Can't just do

573
00:31:08,080 --> 00:31:10,880
Speaker 5:  That. Yeah. You have to give like a ton of notice and pay them out and all

574
00:31:10,880 --> 00:31:13,960
Speaker 5:  of this. And they're like, no you, you broke the law. We're we're not America.

575
00:31:13,960 --> 00:31:17,800
Speaker 5:  Yeah. So he's, but he's also struggling. Like he's struggling with the labor

576
00:31:17,800 --> 00:31:21,320
Speaker 5:  law there, but didn't the EU commissioner this week,

577
00:31:21,320 --> 00:31:24,640
Speaker 5:  one of the EU commissioners say we're gonna like, what

578
00:31:24,640 --> 00:31:28,480
Speaker 4:  Was it? Yeah, they've gotta have the data controllers that they, I mean the

579
00:31:28,480 --> 00:31:32,310
Speaker 4:  EU is a very regulated environment, especially as it pertains to privacy

580
00:31:32,310 --> 00:31:36,040
Speaker 4:  issues. And they're like, who all the people are gone. So get on

581
00:31:36,040 --> 00:31:39,760
Speaker 5:  Your game. He told Mr. Briton, so this is from the Irish times. Mr.

582
00:31:39,760 --> 00:31:43,240
Speaker 5:  Retton told Mr. Musk he must adhere to a checklist of rules

583
00:31:43,240 --> 00:31:46,640
Speaker 5:  including ditching an arbitrary approach to reinstating band

584
00:31:46,640 --> 00:31:50,600
Speaker 5:  users pursuing disinformation just aggressively and agreeing to an

585
00:31:50,600 --> 00:31:53,870
Speaker 5:  extensive independent audit of the platform by next year.

586
00:31:53,870 --> 00:31:55,080
Speaker 6:  None of that's gonna happen.

587
00:31:55,080 --> 00:31:58,800
Speaker 5:  So I mean you say that, but the EU has a pretty good record of

588
00:31:58,800 --> 00:32:02,440
Speaker 5:  like bodying tech companies

589
00:32:02,440 --> 00:32:04,920
Speaker 6:  Finds, which I mean that's he

590
00:32:04,920 --> 00:32:06,960
Speaker 5:  Fines for a company that needs to make how

591
00:32:06,960 --> 00:32:10,070
Speaker 6:  Much money. Yeah, that has no money. Yeah, I know that's,

592
00:32:10,070 --> 00:32:13,720
Speaker 5:  I think Ireland's the risk dark horse in this, this race for,

593
00:32:13,720 --> 00:32:16,280
Speaker 5:  for Elon, he keeps ignoring the world

594
00:32:16,280 --> 00:32:20,120
Speaker 6:  Exist. Whether the FTC decides fines, any evidence that they

595
00:32:20,120 --> 00:32:23,520
Speaker 6:  have actually violated their compliance for, you know,

596
00:32:23,520 --> 00:32:26,960
Speaker 6:  requirements in the eu. If either one of those, those

597
00:32:26,960 --> 00:32:30,800
Speaker 6:  regulators decides to act on Twitter, that could legitimately put it outta

598
00:32:30,800 --> 00:32:31,320
Speaker 6:  business. Right.

599
00:32:31,320 --> 00:32:34,620
Speaker 5:  Yeah. And so instead he's like, I'm gonna pick a fight with

600
00:32:34,620 --> 00:32:35,670
Speaker 5:  Tim.

601
00:32:35,670 --> 00:32:39,360
Speaker 6:  Yeah, well he did wear a suit for the meeting with the eu so

602
00:32:39,360 --> 00:32:41,070
Speaker 6:  maybe he is taking that seriously.

603
00:32:41,070 --> 00:32:44,920
Speaker 4:  Elon is not bad at getting government money. Yeah, yeah. In fact

604
00:32:44,920 --> 00:32:45,840
Speaker 4:  it might be his greatest

605
00:32:45,840 --> 00:32:48,910
Speaker 6:  Skill. It is. Tesla's the way Tesla makes money Yeah. Is

606
00:32:48,910 --> 00:32:52,770
Speaker 4:  Carbon credits and grants and SpaceX is a government contractor.

607
00:32:52,770 --> 00:32:56,440
Speaker 4:  So it's, I don't think that, I think we might, I might be saying that Tim

608
00:32:56,440 --> 00:32:59,400
Speaker 4:  Cook is an underrated political operator. That's the main thing he does.

609
00:32:59,400 --> 00:33:02,960
Speaker 4:  It's true. Elon is a pretty good political operator too. The difference

610
00:33:02,960 --> 00:33:06,720
Speaker 4:  is Elon's businesses are monopolies, right? Like

611
00:33:06,720 --> 00:33:10,600
Speaker 4:  where are you gonna go nasa, right? Like the sls like not doing it for

612
00:33:10,600 --> 00:33:14,480
Speaker 4:  you. Like you got one choice, where are you gonna get Like, like

613
00:33:14,480 --> 00:33:18,160
Speaker 4:  who are you gonna buy your carbon credits from Tesla. So there's just like

614
00:33:18,160 --> 00:33:21,600
Speaker 4:  an element and if you're like a state governor and you want prove that you're

615
00:33:21,600 --> 00:33:24,800
Speaker 4:  green, like you, you have a supercharge put in, right? Yeah.

616
00:33:24,800 --> 00:33:28,350
Speaker 4:  Like I think there's like a, there's just a difference in

617
00:33:28,350 --> 00:33:32,000
Speaker 4:  complexity that both of them face. And I think fundamentally

618
00:33:32,000 --> 00:33:35,920
Speaker 4:  the EU stuff, he's, he's about to learn what it

619
00:33:35,920 --> 00:33:39,160
Speaker 4:  takes to run a business there. And there's a reason that that a lot of these,

620
00:33:39,160 --> 00:33:43,040
Speaker 4:  like when we talk about regulation in this country, like the VCs jump

621
00:33:43,040 --> 00:33:45,720
Speaker 4:  out the world to be like there's a reason there's no innovative companies

622
00:33:45,720 --> 00:33:49,600
Speaker 4:  in Europe. Which is not true. But that's the argument is the re

623
00:33:49,600 --> 00:33:52,960
Speaker 4:  the regulatory environment is so insane that you can't do it. I think Elon

624
00:33:52,960 --> 00:33:55,800
Speaker 4:  is trying to run this thing like a scrappy startup, but it is actually like

625
00:33:55,800 --> 00:33:59,620
Speaker 4:  a world historically important communications platform

626
00:33:59,620 --> 00:34:03,440
Speaker 4:  and the Europeans are, they care about it a lot. Yeah. What else is going

627
00:34:03,440 --> 00:34:06,510
Speaker 4:  on inside of Twitter Alex? Is it, is it settled down?

628
00:34:06,510 --> 00:34:10,360
Speaker 6:  I would say it's become very siloed. So like in inside Twitter

629
00:34:10,360 --> 00:34:13,880
Speaker 6:  you used to be able to browse any Slack channels. See basically what any

630
00:34:13,880 --> 00:34:17,520
Speaker 6:  team is working on that is stopped. So channels have all been set private.

631
00:34:17,520 --> 00:34:21,360
Speaker 6:  He's doing these like inserting different language and different

632
00:34:21,360 --> 00:34:25,000
Speaker 6:  emails to try to find leakers. Edicts are still being

633
00:34:25,000 --> 00:34:28,720
Speaker 6:  mysteriously passed down from Tesla. People inside the company

634
00:34:28,720 --> 00:34:32,520
Speaker 6:  about what Elon wants. The internal directory is not online. So

635
00:34:32,520 --> 00:34:36,140
Speaker 6:  there's no, nobody really has any understanding of like who reports to who,

636
00:34:36,140 --> 00:34:39,760
Speaker 6:  how orgs are set up. It's been communicated like in a team siloed

637
00:34:39,760 --> 00:34:43,430
Speaker 6:  environment but not broadly. And you know, he said that like

638
00:34:43,430 --> 00:34:47,400
Speaker 6:  this transitional period, he may get a lot of things wrong, but

639
00:34:47,400 --> 00:34:51,320
Speaker 6:  you know, the idea is that in the near future

640
00:34:51,320 --> 00:34:54,680
Speaker 6:  all this will become more visible, it'll make more sense and then he'll step

641
00:34:54,680 --> 00:34:58,560
Speaker 6:  back and appoint a CEO I guess. Which, you know, I can't wait

642
00:34:58,560 --> 00:35:02,520
Speaker 6:  to see who that is. But yeah, I would say right now it's still people just

643
00:35:02,520 --> 00:35:05,800
Speaker 6:  going if, if you're not working on an Elon project, right? Which is like

644
00:35:05,800 --> 00:35:09,640
Speaker 6:  encrypting dms, competing with YouTube by

645
00:35:09,640 --> 00:35:13,440
Speaker 6:  adding video to Twitter and doing monetization blue, the revamp

646
00:35:13,440 --> 00:35:16,720
Speaker 6:  of blue and verification. If you're not working on something like that or

647
00:35:16,720 --> 00:35:20,440
Speaker 6:  cost cutting, you're kind of twiddling your thumbs and trying

648
00:35:20,440 --> 00:35:23,440
Speaker 6:  to understand who your manager may or may not be tomorrow.

649
00:35:23,440 --> 00:35:27,320
Speaker 4:  There is a lot of noise in, you know, wave

650
00:35:27,320 --> 00:35:30,680
Speaker 4:  five of layoffs that Twitter wouldn't survive the World

651
00:35:30,680 --> 00:35:33,910
Speaker 4:  Cup. Things were gonna start breaking. Has that started happening?

652
00:35:33,910 --> 00:35:36,640
Speaker 6:  Yeah. I'm glad you brought this up cuz like literally as we were talking

653
00:35:36,640 --> 00:35:39,910
Speaker 6:  I got got another notification from a, from a musk boy

654
00:35:39,910 --> 00:35:43,400
Speaker 6:  like referencing one of my tweets where I said, you know, Twitter employees

655
00:35:43,400 --> 00:35:46,840
Speaker 6:  were telling me they expect the site to stop breaking and everyone's dunking,

656
00:35:46,840 --> 00:35:50,360
Speaker 6:  you know, still waiting on this like yada yada. I just also like if you're

657
00:35:50,360 --> 00:35:53,160
Speaker 6:  a musk boy and you're listening to this, like your experience with Twitter

658
00:35:53,160 --> 00:35:57,050
Speaker 6:  is not indicative of everyone else's experience with Twitter.

659
00:35:57,050 --> 00:36:00,080
Speaker 6:  So like just because you're not experiencing something breaking doesn't mean

660
00:36:00,080 --> 00:36:03,920
Speaker 6:  stuff isn't breaking. We've seen like my timeline's gone bonkers a couple

661
00:36:03,920 --> 00:36:05,770
Speaker 6:  times. I don't know about you guys where like all

662
00:36:05,770 --> 00:36:07,200
Speaker 5:  My notifications don't work.

663
00:36:07,200 --> 00:36:11,160
Speaker 6:  Notifications have been breaking. There was a a moment where SMS verification

664
00:36:11,160 --> 00:36:15,040
Speaker 6:  wasn't working. There's been little glitches all over and I do

665
00:36:15,040 --> 00:36:18,640
Speaker 6:  think we as the media, the the, the week of the first

666
00:36:18,640 --> 00:36:22,340
Speaker 6:  purge where half of the employees were fired, we did maybe

667
00:36:22,340 --> 00:36:25,920
Speaker 6:  buy a little bit into the hysteria of like, cuz we all have this weird relationship

668
00:36:25,920 --> 00:36:29,040
Speaker 6:  with Twitter too, where we're all just like, oh what happens? I was part

669
00:36:29,040 --> 00:36:32,480
Speaker 6:  of a Twitter space that went on for hours where it was like, what is Twitter

670
00:36:32,480 --> 00:36:36,200
Speaker 6:  meant to you? What's gonna mean when it's gone yada yada. And I can

671
00:36:36,200 --> 00:36:39,160
Speaker 6:  understand people trying to latch onto that and say the media like wants

672
00:36:39,160 --> 00:36:43,040
Speaker 6:  this thing to fail and wants Elon to fail. And

673
00:36:43,040 --> 00:36:46,640
Speaker 6:  I would just like, I can only speak for how I report, but I think for all

674
00:36:46,640 --> 00:36:49,560
Speaker 6:  the people who are reporting on like what's happening inside Twitter, Casey,

675
00:36:49,560 --> 00:36:52,880
Speaker 6:  Zoe, et cetera, we're just relaying what employees are telling

676
00:36:52,880 --> 00:36:56,480
Speaker 6:  us. And there were a lot of current

677
00:36:56,480 --> 00:37:00,440
Speaker 6:  and former Twitter employees with direct knowledge who were very,

678
00:37:00,440 --> 00:37:04,070
Speaker 6:  very concerned based on the cuts Musk made, that it would lead to a catastrophic

679
00:37:04,070 --> 00:37:08,030
Speaker 6:  outage very quickly. That's not like a reporter

680
00:37:08,030 --> 00:37:11,680
Speaker 6:  saying, oh I'm like pontificating or just like assuming this is gonna happen.

681
00:37:11,680 --> 00:37:15,440
Speaker 6:  This is, I'm just like, I'm saying what employees are telling me so you can

682
00:37:15,440 --> 00:37:19,160
Speaker 6:  trust that or you cannot, that's fine. Like you don't have to whatever media's

683
00:37:19,160 --> 00:37:22,920
Speaker 6:  fake. But that's, that was the real

684
00:37:22,920 --> 00:37:26,440
Speaker 6:  concern and it's actually amazing that hasn't happened. I think it's a testament

685
00:37:26,440 --> 00:37:30,360
Speaker 6:  to the people who already were maintaining Twitter, the fail safes that

686
00:37:30,360 --> 00:37:34,160
Speaker 6:  were in place when you have a service this large and you have

687
00:37:34,160 --> 00:37:37,760
Speaker 6:  any level of competency in how it's run, which, you know, Twitter didn't

688
00:37:37,760 --> 00:37:41,640
Speaker 6:  have as much competency as it should have, but it did have a lot, there

689
00:37:41,640 --> 00:37:45,360
Speaker 6:  are a lot of fail safes and just ways that, you know, the service can,

690
00:37:45,360 --> 00:37:49,220
Speaker 6:  can stay operational even on, you know, a skeleton crew.

691
00:37:49,220 --> 00:37:53,160
Speaker 6:  But that said, there are, you know, glitches and this isn't gonna

692
00:37:53,160 --> 00:37:56,640
Speaker 6:  mean that like Twitter won't break at some point. It very, very well could.

693
00:37:56,640 --> 00:38:00,440
Speaker 6:  Musk has like been pretty open about that. So I just wanted to address that

694
00:38:00,440 --> 00:38:03,200
Speaker 6:  cuz like I'm still getting at messages about that. Well

695
00:38:03,200 --> 00:38:07,120
Speaker 5:  Also the World Cup just started, right? Like we're not even to the ones where

696
00:38:07,120 --> 00:38:11,000
Speaker 5:  people like line up and pack in the bars. I mean

697
00:38:11,000 --> 00:38:13,760
Speaker 5:  I guess some of them are, we've seen some of that but like we're, we're just

698
00:38:13,760 --> 00:38:17,320
Speaker 5:  in the beginnings of the real crunch period for the World Cup

699
00:38:17,320 --> 00:38:19,020
Speaker 5:  traffic for them. Yeah.

700
00:38:19,020 --> 00:38:22,360
Speaker 6:  And it may, it may go off great and that will be great if Twitter doesn't

701
00:38:22,360 --> 00:38:26,200
Speaker 6:  break. I don't want it to break, but there's, you know, there's

702
00:38:26,200 --> 00:38:28,560
Speaker 6:  a lot of institutional knowledge that's gone. Yeah, like we were just talking

703
00:38:28,560 --> 00:38:30,920
Speaker 6:  about with the app store stuff, you know, there's a lot of people that like

704
00:38:30,920 --> 00:38:33,260
Speaker 6:  there was a moment where the wifi went out,

705
00:38:33,260 --> 00:38:34,230
Speaker 5:  FTC regulations,

706
00:38:34,230 --> 00:38:38,040
Speaker 6:  Compliance. Like there was a moment where Elon was in the New York

707
00:38:38,040 --> 00:38:41,480
Speaker 6:  office and the wifi went out because like the server room where the wifi

708
00:38:41,480 --> 00:38:44,240
Speaker 6:  was overheated and no one knew how to get in there and fix it cause like

709
00:38:44,240 --> 00:38:47,280
Speaker 6:  he'd fire the person who knew how. So there's gonna be stuff like that that

710
00:38:47,280 --> 00:38:50,390
Speaker 6:  just happens and that's, that's what Elon bought and that's what he did.

711
00:38:50,390 --> 00:38:54,240
Speaker 4:  Yeah, I think the, will it break right away that that

712
00:38:54,240 --> 00:38:58,200
Speaker 4:  particular day was bonkers. Like it's software. Like I

713
00:38:58,200 --> 00:39:01,030
Speaker 4:  think we've all experienced software that just sort of putters along.

714
00:39:01,030 --> 00:39:03,440
Speaker 5:  Yeah, there was definitely a hysteria.

715
00:39:03,440 --> 00:39:04,640
Speaker 6:  There was a hysteria

716
00:39:04,640 --> 00:39:04,880
Speaker 4:  And

717
00:39:04,880 --> 00:39:07,720
Speaker 5:  I think people were acknowledging it at the time. I think everybody was even

718
00:39:07,720 --> 00:39:11,640
Speaker 5:  being like, I'm hysterical and I don't know what's happening. But like, so

719
00:39:11,640 --> 00:39:15,600
Speaker 5:  I think people were pretty candid about it and it is just part

720
00:39:15,600 --> 00:39:19,480
Speaker 5:  of that conversation where, where there's a both sides of them to this

721
00:39:19,480 --> 00:39:22,560
Speaker 5:  whole thing. Everybody has to have like a team, they have to be Team Elon

722
00:39:22,560 --> 00:39:24,880
Speaker 5:  or team Twitter or something. It's like

723
00:39:24,880 --> 00:39:25,900
Speaker 4:  No team Twitter,

724
00:39:25,900 --> 00:39:26,830
Speaker 5:  You don't,

725
00:39:26,830 --> 00:39:30,720
Speaker 4:  Well so Elon keeps tweeting the numbers are up. Right, right. Engage,

726
00:39:30,720 --> 00:39:34,520
Speaker 4:  time is up that users have gone up using the metric that he said was

727
00:39:34,520 --> 00:39:38,360
Speaker 4:  totally fake, very confusing. I've

728
00:39:38,360 --> 00:39:41,320
Speaker 4:  experienced the flip and I know a lot of people who are kind of on the flip

729
00:39:41,320 --> 00:39:44,760
Speaker 4:  side of things where I took it off my phone. Yeah. Because my experience

730
00:39:44,760 --> 00:39:48,680
Speaker 4:  of Twitter, in addition to just stuff breaking, like when my notifications

731
00:39:48,680 --> 00:39:52,280
Speaker 4:  break, they break in the most deeply hilarious way. They just

732
00:39:52,280 --> 00:39:55,870
Speaker 4:  recommend tweets from Elon

733
00:39:55,870 --> 00:39:59,280
Speaker 4:  Like that that's, and I don't follow Elon, it's just like, here's another

734
00:39:59,280 --> 00:40:02,760
Speaker 4:  tweet you might like. And it's like, no, you got this wrong. I don't need

735
00:40:02,760 --> 00:40:06,090
Speaker 4:  more of this. This is why I took it off my phone. But I know a lot of people

736
00:40:06,090 --> 00:40:10,000
Speaker 4:  in the past week or so who are like my experience

737
00:40:10,000 --> 00:40:13,640
Speaker 4:  of Twitter is becoming more negative because he hasn't even let everybody

738
00:40:13,640 --> 00:40:17,560
Speaker 4:  back on yet. But the people who remain are

739
00:40:17,560 --> 00:40:21,440
Speaker 4:  like more inclined to yell at one another and they're more inclined to

740
00:40:21,440 --> 00:40:25,120
Speaker 4:  test the limits of what is and isn't allowed anymore. And it's just

741
00:40:25,120 --> 00:40:28,800
Speaker 4:  noisier. And more people are on Twitter talking about Twitter, which is just

742
00:40:28,800 --> 00:40:32,560
Speaker 4:  the worst. And that to me is the real danger. Yeah, yeah.

743
00:40:32,560 --> 00:40:36,360
Speaker 4:  Right. Is that the people you need to make it vibrant,

744
00:40:36,360 --> 00:40:39,370
Speaker 4:  we'll get driven off or they'll quit or they'll find something new

745
00:40:39,370 --> 00:40:43,230
Speaker 4:  or I think maybe what might be the healthiest outcome

746
00:40:43,230 --> 00:40:46,920
Speaker 4:  will all just stop being addicted to social media feeds in

747
00:40:46,920 --> 00:40:50,760
Speaker 4:  this specific way and like something else will emerge. Which is

748
00:40:50,760 --> 00:40:54,400
Speaker 4:  really unusual if you just think about the number of times that that

749
00:40:54,400 --> 00:40:58,360
Speaker 4:  kind of shift has even been possible over the last decade or

750
00:40:58,360 --> 00:41:02,280
Speaker 4:  so. It's maybe three, like at best three I'm

751
00:41:02,280 --> 00:41:04,880
Speaker 4:  thinking it's like Friendster to

752
00:41:04,880 --> 00:41:08,700
Speaker 4:  MySpace. MySpace to to Facebook

753
00:41:08,700 --> 00:41:12,360
Speaker 4:  and then the emergence of Twitter and then maybe

754
00:41:12,360 --> 00:41:16,320
Speaker 4:  most recently the emergence of TikTok. Right. And like I I

755
00:41:16,320 --> 00:41:19,760
Speaker 4:  said three and I, the friend started in MySpace. MySpace to Facebook. That

756
00:41:19,760 --> 00:41:21,920
Speaker 4:  just is one that all happened in like 24

757
00:41:21,920 --> 00:41:24,680
Speaker 6:  Months. Yeah I think snaps in there. There's there's some other shifts in

758
00:41:24,680 --> 00:41:25,950
Speaker 6:  there. But

759
00:41:25,950 --> 00:41:29,120
Speaker 5:  A lot of shifts though, right? Like I think one of the earliest ones wasn't

760
00:41:29,120 --> 00:41:32,520
Speaker 5:  even Friendster. It was, it was Live Journal. Live Journal was a social media

761
00:41:32,520 --> 00:41:35,800
Speaker 5:  platform. It was was really big, just was a different kind of social media

762
00:41:35,800 --> 00:41:38,800
Speaker 5:  platform. And then everybody was like, oh, Russia's bought it. We gotta kill

763
00:41:38,800 --> 00:41:42,430
Speaker 5:  it, we gotta leave this place. We can't have the Russians on us. This was

764
00:41:42,430 --> 00:41:46,120
Speaker 5:  what, 2009 or something? And it didn't die

765
00:41:46,120 --> 00:41:49,640
Speaker 5:  rapidly. I think that like, I would honestly say live journalists, the most

766
00:41:49,640 --> 00:41:53,360
Speaker 5:  similar analogy to this where suddenly got a new owner, everybody

767
00:41:53,360 --> 00:41:57,080
Speaker 5:  started to really question what they were doing on the service, why they

768
00:41:57,080 --> 00:42:00,920
Speaker 5:  were doing it, and whether they were like being good people by using

769
00:42:00,920 --> 00:42:04,320
Speaker 5:  this service owned by people who were potentially not good and might not

770
00:42:04,320 --> 00:42:08,080
Speaker 5:  use their data correctly. And then what happened was it's a long slow

771
00:42:08,080 --> 00:42:11,440
Speaker 5:  death. There were a ton of clones. Everybody said dream with this is the

772
00:42:11,440 --> 00:42:12,180
Speaker 5:  new future

773
00:42:12,180 --> 00:42:13,210
Speaker 4:  And dream with

774
00:42:13,210 --> 00:42:16,920
Speaker 5:  No it means I'm sure people use it. And then a bunch of people migrated to

775
00:42:16,920 --> 00:42:20,690
Speaker 5:  Tumblr but it took what, three or four or five years for that to happen.

776
00:42:20,690 --> 00:42:23,880
Speaker 5:  It just happens like this long slow thing. We saw the same thing with Tumblr.

777
00:42:23,880 --> 00:42:27,760
Speaker 5:  Like we've seen this happen with these smaller social media platforms, not

778
00:42:27,760 --> 00:42:30,940
Speaker 5:  just the big ones. And in those smaller platforms where you do see these

779
00:42:30,940 --> 00:42:34,840
Speaker 5:  big changes that upset the, the majority of the

780
00:42:34,840 --> 00:42:38,280
Speaker 5:  users, it's not a big sudden shift because people

781
00:42:38,280 --> 00:42:42,200
Speaker 5:  don't operate that way. Like Tumblr died and everybody said pillow

782
00:42:42,200 --> 00:42:45,810
Speaker 5:  fort's the new thing and the same thing that's happening now with hi social

783
00:42:45,810 --> 00:42:48,400
Speaker 5:  is happened with Pillow Fork where it couldn't handle

784
00:42:48,400 --> 00:42:50,200
Speaker 6:  Fort what are you, what are you even talking? Yeah,

785
00:42:50,200 --> 00:42:52,400
Speaker 4:  Alex is just making up service names. You're just

786
00:42:52,400 --> 00:42:53,400
Speaker 6:  Saying words was it

787
00:42:53,400 --> 00:42:54,360
Speaker 5:  Was, and I'm it's still

788
00:42:54,360 --> 00:42:57,980
Speaker 4:  Exists. She's like cluck a duck that huge, huge few minute. But it but

789
00:42:57,980 --> 00:43:01,600
Speaker 5:  But it was the same thing that happened though where they just said where

790
00:43:01,600 --> 00:43:05,240
Speaker 5:  everybody's like, yeah we're gonna go to this. It broke it and it's

791
00:43:05,240 --> 00:43:08,800
Speaker 5:  slowly coming back. But like we've seen a time, time again with these

792
00:43:08,800 --> 00:43:12,720
Speaker 5:  smaller platforms that it isn't a sudden migration. It is always a very

793
00:43:12,720 --> 00:43:13,440
Speaker 5:  slow thing.

794
00:43:13,440 --> 00:43:17,240
Speaker 6:  No, yeah, people will experiment. You know, I noticed that Tap Bots

795
00:43:17,240 --> 00:43:20,560
Speaker 6:  the maker of one of the best original Twitter clients tweet bot, they're

796
00:43:20,560 --> 00:43:23,620
Speaker 6:  building a Macon client now. I actually just got on the beta. Thank you Paul.

797
00:43:23,620 --> 00:43:27,200
Speaker 6:  And like there is interesting activity happening on

798
00:43:27,200 --> 00:43:31,000
Speaker 6:  Macon. I don't think Macon's gonna necessarily like take the world by

799
00:43:31,000 --> 00:43:34,600
Speaker 6:  storm. I think people don't wanna organize it or understand servers. Like

800
00:43:34,600 --> 00:43:38,480
Speaker 6:  that's just an inherent Yeah. Human nature thing to like not give

801
00:43:38,480 --> 00:43:41,740
Speaker 6:  a shit about servers, but,

802
00:43:41,740 --> 00:43:42,930
Speaker 4:  But

803
00:43:42,930 --> 00:43:46,750
Speaker 6:  At Macon's trying, there will be other stuff, but

804
00:43:46,750 --> 00:43:50,410
Speaker 6:  I think like Twitter is really elon's to,

805
00:43:50,410 --> 00:43:54,290
Speaker 6:  to mess up. Like either it will get fined out of existence or

806
00:43:54,290 --> 00:43:58,160
Speaker 6:  he will not have anyone left who can actually

807
00:43:58,160 --> 00:44:01,600
Speaker 6:  make it better and he's not able to hire for some reason. Which I think he

808
00:44:01,600 --> 00:44:04,040
Speaker 6:  actually will. I think he actually, I've actually gotten random people emailing

809
00:44:04,040 --> 00:44:07,520
Speaker 6:  me being like, do you know how I can apply to work at Twitter? Wow. Yeah.

810
00:44:07,520 --> 00:44:08,860
Speaker 6:  Like people, engineers,

811
00:44:08,860 --> 00:44:12,470
Speaker 4:  You print out the last 50 pages, print out your code, just go over,

812
00:44:12,470 --> 00:44:14,480
Speaker 4:  just hold em up above your head. Like say, or you

813
00:44:14,480 --> 00:44:18,440
Speaker 5:  Just show up to one of his show ints. Like we had a Neurolink event this

814
00:44:18,440 --> 00:44:22,200
Speaker 5:  week where almost nothing happened. He showed a bunch of old

815
00:44:22,200 --> 00:44:25,600
Speaker 5:  videos and then he was like, maybe I'll stick a chip in my head one year

816
00:44:25,600 --> 00:44:27,280
Speaker 5:  and you could watch him. I was watching, wait,

817
00:44:27,280 --> 00:44:30,440
Speaker 4:  Hold on, let's take a break. We come back, we'll talk about

818
00:44:30,440 --> 00:44:34,360
Speaker 4:  event seamlessly transition from monkeys wirelessly charging

819
00:44:34,360 --> 00:44:38,120
Speaker 4:  their brains to Sandbank. We're gonna take a break.

820
00:44:38,120 --> 00:44:39,720
Speaker 4:  I'm gonna figure out that transition. We'll be right

821
00:44:39,720 --> 00:44:46,550
Speaker 4:  back.

822
00:46:48,900 --> 00:46:52,670
Speaker 4:  Okay, we're back. Let's talk about near link briefly. We're

823
00:46:52,670 --> 00:46:56,610
Speaker 4:  all Musk all the time. So you have the event. He did announce some things,

824
00:46:56,610 --> 00:47:00,070
Speaker 4:  but the most improbable is that he will start

825
00:47:00,070 --> 00:47:02,840
Speaker 4:  implanting brain implants in people within six months.

826
00:47:02,840 --> 00:47:06,520
Speaker 5:  He originally promised in 2020 to do the brain implants.

827
00:47:06,520 --> 00:47:10,140
Speaker 5:  So they were like, they were like, I think it was 20 18, 20

828
00:47:10,140 --> 00:47:14,090
Speaker 5:  19. He said 2020 we're gonna be implanting these in humans. And

829
00:47:14,090 --> 00:47:17,990
Speaker 5:  then 2020 came and then they're like, actually it's gonna be 2022.

830
00:47:17,990 --> 00:47:21,750
Speaker 5:  And then Decem what? November 30th, 2022. They were

831
00:47:21,750 --> 00:47:25,030
Speaker 5:  like, no, no, no, it's, it's six fronts, six months from now. But the majority

832
00:47:25,030 --> 00:47:29,000
Speaker 5:  of the time for the Neurolink conversation was spent on like saying

833
00:47:29,000 --> 00:47:32,660
Speaker 5:  we really don't do the monkeys enjoy being tested on.

834
00:47:32,660 --> 00:47:36,120
Speaker 5:  We're totally fine because Neurolink has been getting a lot of flack for

835
00:47:36,120 --> 00:47:40,000
Speaker 5:  the fact that it does a lot of animal testing. And it's like sometimes the

836
00:47:40,000 --> 00:47:41,640
Speaker 5:  monkeys die. Don't worry about it. We're gonna put chips in people's brains.

837
00:47:41,640 --> 00:47:45,370
Speaker 4:  Thousands of monkeys have died is what writers reported today. USA Today.

838
00:47:45,370 --> 00:47:49,320
Speaker 5:  So many. Also you can control the mouse with

839
00:47:49,320 --> 00:47:51,700
Speaker 5:  your brain slower than you could with your hand.

840
00:47:51,700 --> 00:47:54,640
Speaker 4:  All I'm gonna tell you is the single most important part of this entire demo,

841
00:47:54,640 --> 00:47:57,640
Speaker 4:  which was all for recruiting. And they were very open about it. Come work,

842
00:47:57,640 --> 00:48:01,400
Speaker 4:  go work it. And you're like, if you're wanna be the cutting edge of monkeys

843
00:48:01,400 --> 00:48:05,120
Speaker 4:  typing with their brains, they like got deep into chargers. So like, here's

844
00:48:05,120 --> 00:48:08,520
Speaker 4:  the problem, we need to, it needs to be convenient, it needs to deliver a

845
00:48:08,520 --> 00:48:11,840
Speaker 4:  lot of power and go fast. We also can't heat your brain up more than two

846
00:48:11,840 --> 00:48:15,720
Speaker 4:  degrees or we'll kill you. That's fair. That's

847
00:48:15,720 --> 00:48:19,280
Speaker 4:  like this is raw. Like I wish more tech companies were this

848
00:48:19,280 --> 00:48:21,980
Speaker 4:  raw stating the problem.

849
00:48:21,980 --> 00:48:25,900
Speaker 6:  You know, thermals are a huge issue and a lot of technology

850
00:48:25,900 --> 00:48:28,680
Speaker 6:  and when you put that in the brain and you heat the brain, you gotta be

851
00:48:28,680 --> 00:48:31,500
Speaker 4:  Careful. They were like, so here's our solution. And they showed this like

852
00:48:31,500 --> 00:48:35,360
Speaker 4:  you gotta watch this video. Like this was, this was the president

853
00:48:35,360 --> 00:48:39,180
Speaker 4:  is was not Elon, it was like a Neurolink engineering manager. Yeah.

854
00:48:39,180 --> 00:48:42,520
Speaker 4:  And this was his life. He was dead serious about this.

855
00:48:42,520 --> 00:48:46,360
Speaker 4:  Like it, I gotta charge you up in more than 15 minutes. The battery has

856
00:48:46,360 --> 00:48:50,120
Speaker 4:  to last all day and I can't, I can't boil your

857
00:48:50,120 --> 00:48:53,840
Speaker 4:  brain and your skull. It's a very challenging problem. And he is like, so

858
00:48:53,840 --> 00:48:57,680
Speaker 4:  here's what we've done. There's a lever that delivers

859
00:48:57,680 --> 00:49:01,200
Speaker 4:  banana smoothie and the monkeys have learned to charge their own

860
00:49:01,200 --> 00:49:04,600
Speaker 4:  brains by standing under this wireless charger. And they're like, here's

861
00:49:04,600 --> 00:49:07,880
Speaker 4:  this monkey. And he goes and he is just like drinking a smoothie and there's

862
00:49:07,880 --> 00:49:10,400
Speaker 4:  a graph and the graph goes up. He's like, see, it's

863
00:49:10,400 --> 00:49:14,160
Speaker 4:  charging, watching this. I'm like, one this

864
00:49:14,160 --> 00:49:17,280
Speaker 4:  rules, like, I honestly wish more Apple events featured

865
00:49:17,280 --> 00:49:19,360
Speaker 4:  this exact situation.

866
00:49:19,360 --> 00:49:21,950
Speaker 5:  Monkeys drinking smoothies, wirelessly charging.

867
00:49:21,950 --> 00:49:25,480
Speaker 4:  Yeah. Like Samsung used to be close to this. They really toned it

868
00:49:25,480 --> 00:49:29,240
Speaker 4:  down. There was a time when any Samsung event would veer right

869
00:49:29,240 --> 00:49:32,440
Speaker 4:  into also in addition to washers, dryers, nuclear

870
00:49:32,440 --> 00:49:36,190
Speaker 4:  submarines, a fleet of charging monkeys.

871
00:49:36,190 --> 00:49:39,200
Speaker 4:  Like it was always right there. Little smoothies. They've really toned it

872
00:49:39,200 --> 00:49:43,000
Speaker 4:  down since I'm just saying this was like that part of this event the whole

873
00:49:43,000 --> 00:49:45,080
Speaker 4:  time I was like, all events should be like this. Yeah.

874
00:49:45,080 --> 00:49:48,480
Speaker 6:  Just do we think the, do we think the monkeys could learn how to code and

875
00:49:48,480 --> 00:49:49,600
Speaker 6:  then they could be at No,

876
00:49:49,600 --> 00:49:53,320
Speaker 5:  He, he addressed this. He addressed it. He was like the

877
00:49:53,320 --> 00:49:56,760
Speaker 5:  monkeys because he's doing the demo where the monkeys drink in the smoothie

878
00:49:56,760 --> 00:49:59,800
Speaker 5:  and it's moving the mouse and typing and he is like, I just want you to understand

879
00:49:59,800 --> 00:50:03,680
Speaker 5:  they're typing gibberish. We do plan to one day maybe make

880
00:50:03,680 --> 00:50:04,970
Speaker 5:  them type.

881
00:50:04,970 --> 00:50:05,950
Speaker 6:  That'll be huge.

882
00:50:05,950 --> 00:50:09,680
Speaker 5:  Yeah. Like he definitely, but it was very clearly a joke,

883
00:50:09,680 --> 00:50:10,740
Speaker 5:  sadly. Yeah,

884
00:50:10,740 --> 00:50:14,120
Speaker 4:  The monkeys get pissed when the code review gets canceled. I just lose their

885
00:50:14,120 --> 00:50:15,110
Speaker 4:  pronouns.

886
00:50:15,110 --> 00:50:17,520
Speaker 5:  I worked, I filed it, saving my job.

887
00:50:17,520 --> 00:50:20,560
Speaker 4:  Speaking of illegal things with monkeys, oh there

888
00:50:20,560 --> 00:50:24,460
Speaker 6:  It is. There's this segue. Yes, that's a good one. That's really good. So

889
00:50:24,460 --> 00:50:26,280
Speaker 6:  you, you were in are

890
00:50:26,280 --> 00:50:29,200
Speaker 4:  Monkeys in the The Bahamas. That's what I was like. I was like there's gotta

891
00:50:29,200 --> 00:50:30,560
Speaker 4:  be monkeys in The Bahamas. Speaking

892
00:50:30,560 --> 00:50:34,520
Speaker 6:  Of tropical animals. Bahamas. Yeah. Yeah. So Eli,

893
00:50:34,520 --> 00:50:37,760
Speaker 6:  you were in beautiful New York City this week to

894
00:50:37,760 --> 00:50:41,160
Speaker 6:  watch Andrew Ross Sorkin of the New York Times do his

895
00:50:41,160 --> 00:50:45,080
Speaker 6:  annual deal book conference and he had none other than

896
00:50:45,080 --> 00:50:49,040
Speaker 6:  the illustrious Sam Bakeman freed there virtually. He was the closer,

897
00:50:49,040 --> 00:50:52,960
Speaker 6:  a pretty remarkable interview. We watched it. You were in the room. Can you

898
00:50:52,960 --> 00:50:55,840
Speaker 6:  just describe what it was like being in the room for this truly bizarre moment?

899
00:50:55,840 --> 00:50:59,400
Speaker 6:  And we should note that like people were mad that Sorkin was even doing

900
00:50:59,400 --> 00:51:03,280
Speaker 6:  this interview, right? Because SPF is, I think we can all say here,

901
00:51:03,280 --> 00:51:07,200
Speaker 6:  like probably a criminal. Yeah, allegedly. And yeah, so there was

902
00:51:07,200 --> 00:51:10,000
Speaker 6:  like a debate about whether this interview should even happen and then it

903
00:51:10,000 --> 00:51:11,370
Speaker 6:  does happen. And then, and what was that like?

904
00:51:11,370 --> 00:51:15,200
Speaker 4:  It was strange. I, I will candidly admit that I feel

905
00:51:15,200 --> 00:51:19,080
Speaker 4:  a sense of smugness about all of crypto because we

906
00:51:19,080 --> 00:51:23,020
Speaker 4:  have been so skeptical of it this whole time. And so

907
00:51:23,020 --> 00:51:26,920
Speaker 4:  the way we have covered it, I think is a little more detached than people

908
00:51:26,920 --> 00:51:30,680
Speaker 4:  want us to be. Like we're just not as mad about it. And I, I

909
00:51:30,680 --> 00:51:34,040
Speaker 4:  recognize that people have had their lives destroyed and I am mad for those

910
00:51:34,040 --> 00:51:37,440
Speaker 4:  people on, on their behalf. And that's actually how Andrew opened the interview

911
00:51:37,440 --> 00:51:40,440
Speaker 4:  with Sam. He's like, here's some letters I got from people whose lives have

912
00:51:40,440 --> 00:51:44,240
Speaker 4:  been destroyed. His life savings are taken away. But just from the verges

913
00:51:44,240 --> 00:51:47,480
Speaker 4:  of consumer site, it's not a financial services site, it's on a business

914
00:51:47,480 --> 00:51:51,400
Speaker 4:  site where a consumer technology site. And so we, we just covered it,

915
00:51:51,400 --> 00:51:55,320
Speaker 4:  sort of a remove, like it's a caper to us I think. So it was interesting

916
00:51:55,320 --> 00:51:59,200
Speaker 4:  to go into that audience and the DealBook audience, it's, it's

917
00:51:59,200 --> 00:52:01,720
Speaker 4:  the code conference. Like it's the closest parallel to

918
00:52:01,720 --> 00:52:03,360
Speaker 6:  It. Bill Ackman's in the room asking,

919
00:52:03,360 --> 00:52:06,320
Speaker 4:  Yeah, all these big investors are in there, major businessmen are in there,

920
00:52:06,320 --> 00:52:10,000
Speaker 4:  major politicians in there. Pretty cool to be in that room. Like that was

921
00:52:10,000 --> 00:52:13,840
Speaker 4:  neat. And for most of the day, like you're in a

922
00:52:13,840 --> 00:52:17,600
Speaker 4:  large theater with a lot of important people. There's just like a

923
00:52:17,600 --> 00:52:21,230
Speaker 4:  layer of background noise in the room. No matter who's being interviewed,

924
00:52:21,230 --> 00:52:24,880
Speaker 4:  Reid Hastings is on stage talking about the future of Netflix. There's sort

925
00:52:24,880 --> 00:52:27,800
Speaker 4:  of like a layer of background noise. People are getting up. But like I got

926
00:52:27,800 --> 00:52:30,800
Speaker 4:  up in the middle and took a phone call. People are typing, there's some like

927
00:52:30,800 --> 00:52:34,480
Speaker 4:  murmurs, there's reactions to the interview. You know, it's very polite and

928
00:52:34,480 --> 00:52:37,990
Speaker 4:  respectful and people are focused. But there's sort of like this layer of

929
00:52:37,990 --> 00:52:41,800
Speaker 4:  background activity happening in the room, right? Yeah. It's a big

930
00:52:41,800 --> 00:52:45,680
Speaker 4:  theater. You get to Sam and it's just pin drop silent, like

931
00:52:45,680 --> 00:52:49,520
Speaker 4:  no one's even moving. Like no, no one

932
00:52:49,520 --> 00:52:53,080
Speaker 4:  knows what to do and it's remote and Sam

933
00:52:53,080 --> 00:52:57,070
Speaker 4:  can't perceive the room. Like this is the,

934
00:52:57,070 --> 00:53:01,000
Speaker 4:  here's the hard limit of a Zoom conversation, right?

935
00:53:01,000 --> 00:53:04,920
Speaker 4:  Like he's looking into his webcam and he can see Andrew os

936
00:53:04,920 --> 00:53:08,780
Speaker 4:  Sorkin and he can probably hear the room and Sorkin is on stage

937
00:53:08,780 --> 00:53:11,560
Speaker 4:  and I was sitting off to the side so I could see what Sorkin was looking

938
00:53:11,560 --> 00:53:15,250
Speaker 4:  at. He didn't have a monitor that he could not see Sam, Sam was behind him.

939
00:53:15,250 --> 00:53:18,930
Speaker 4:  So he was just looking into the camera to create the illusion

940
00:53:18,930 --> 00:53:22,200
Speaker 4:  of eye contact. This is exactly what I am doing right now. I am staring down

941
00:53:22,200 --> 00:53:25,240
Speaker 4:  the barrel of a camera lens to make it look like I'm looking at the, the

942
00:53:25,240 --> 00:53:28,800
Speaker 4:  two Alex's. But I'm looking at my camera lens and I was like, oh,

943
00:53:28,800 --> 00:53:32,320
Speaker 4:  Andrew Serkin is a CNBC anchor. Like he's just falling

944
00:53:32,320 --> 00:53:36,160
Speaker 4:  back on his cable news training to

945
00:53:36,160 --> 00:53:40,040
Speaker 4:  create intimacy even though he is dead aware of what's happening

946
00:53:40,040 --> 00:53:43,160
Speaker 4:  in this room. And yes, there's what happened on, we talked about the interview

947
00:53:43,160 --> 00:53:47,010
Speaker 4:  and Sam and the scam and all that stuff. I just, from a creation

948
00:53:47,010 --> 00:53:50,830
Speaker 4:  of a cultural moment using technology standpoint,

949
00:53:50,830 --> 00:53:54,680
Speaker 4:  I was just like blown away. Like I, I've never experienced anything

950
00:53:54,680 --> 00:53:57,480
Speaker 4:  like that and I've been to a million of these conferences. We've done a million

951
00:53:57,480 --> 00:54:01,380
Speaker 4:  interviews. I host an interview show remotely.

952
00:54:01,380 --> 00:54:05,110
Speaker 4:  But that mismatch between, here's this room

953
00:54:05,110 --> 00:54:08,160
Speaker 4:  full of bankers and executives and

954
00:54:08,160 --> 00:54:11,960
Speaker 4:  politicians just tensed at the, on the edge

955
00:54:11,960 --> 00:54:15,630
Speaker 4:  of their seat all kind of like, you should shut up.

956
00:54:15,630 --> 00:54:16,120
Speaker 4:  Like

957
00:54:16,120 --> 00:54:17,550
Speaker 5:  Shut up.

958
00:54:17,550 --> 00:54:19,400
Speaker 6:  That's the amazing thing. And

959
00:54:19,400 --> 00:54:21,720
Speaker 4:  He's just like video chatting.

960
00:54:21,720 --> 00:54:23,200
Speaker 5:  You just having a time. Didn't

961
00:54:23,200 --> 00:54:27,120
Speaker 6:  Sorkin's, didn't Sorkin ask at one point like what are your lawyers advising

962
00:54:27,120 --> 00:54:29,960
Speaker 6:  you? I mean he did like that was the big question we all had was

963
00:54:29,960 --> 00:54:33,000
Speaker 4:  Like this was like the most incredible mumble side of all time. He was like,

964
00:54:33,000 --> 00:54:35,640
Speaker 4:  are your lawyers telling you to talk to? He's like, they are not. And he

965
00:54:35,640 --> 00:54:38,560
Speaker 4:  just kept talking.

966
00:54:38,560 --> 00:54:41,700
Speaker 6:  Cause there were times where Sam would look off to the side of the camera

967
00:54:41,700 --> 00:54:45,320
Speaker 6:  and you know, Liz and I and others were in Slack and we're all talking and

968
00:54:45,320 --> 00:54:48,560
Speaker 6:  we're like, man, is he looking at his talking points? Is he looking at a

969
00:54:48,560 --> 00:54:52,150
Speaker 6:  lawyer who's going no. Like what is, what is going through this guy?

970
00:54:52,150 --> 00:54:55,320
Speaker 5:  I think he was just doing, there's a thing I do it a lot, a lot of people

971
00:54:55,320 --> 00:54:59,120
Speaker 5:  do where you sometimes will like look away when you're talking and and trying

972
00:54:59,120 --> 00:55:02,160
Speaker 5:  to get over whatever conversation you're supposed to have. And I think that's

973
00:55:02,160 --> 00:55:04,350
Speaker 5:  just a tick of his that he has.

974
00:55:04,350 --> 00:55:05,560
Speaker 6:  Yeah, it

975
00:55:05,560 --> 00:55:09,280
Speaker 4:  Was just very strange. Strange. I mean he, from what I can tell, he, he continues

976
00:55:09,280 --> 00:55:12,920
Speaker 4:  to just admit to frauds. Like he won't stop

977
00:55:12,920 --> 00:55:15,990
Speaker 4:  admitting to frauds, which seems like a huge problem.

978
00:55:15,990 --> 00:55:19,560
Speaker 6:  Well he said he didn't intend to do fraud. Oh yeah, I

979
00:55:19,560 --> 00:55:20,100
Speaker 6:  believe.

980
00:55:20,100 --> 00:55:24,040
Speaker 5:  And he apologized to everybody's losing their money. He's like, I just wanna

981
00:55:24,040 --> 00:55:27,520
Speaker 5:  do right by my customers. And I was like, well you know where you could done

982
00:55:27,520 --> 00:55:28,870
Speaker 5:  that. Yeah,

983
00:55:28,870 --> 00:55:32,720
Speaker 6:  Yeah. But it was like this weird exercise of like, I don't know how

984
00:55:32,720 --> 00:55:36,560
Speaker 6:  the thing I made works. It was like the common refrain he would

985
00:55:36,560 --> 00:55:40,440
Speaker 6:  go to. It was like, it was like he was pointing to some boogeyman that wasn't

986
00:55:40,440 --> 00:55:44,160
Speaker 6:  him that he couldn't name because he's obviously the

987
00:55:44,160 --> 00:55:47,600
Speaker 6:  culprits. Right? And so what are you gonna do if you're also like enough

988
00:55:47,600 --> 00:55:51,400
Speaker 6:  of a psychopath to put yourself in a public interview in this moment you're

989
00:55:51,400 --> 00:55:54,880
Speaker 6:  gonna just like invent something to blame that you

990
00:55:54,880 --> 00:55:57,600
Speaker 6:  can't describe. I mean is that a fair read? I don't, I don't know how else

991
00:55:57,600 --> 00:55:58,800
Speaker 6:  to describe you

992
00:55:58,800 --> 00:55:59,160
Speaker 4:  Handled

993
00:55:59,160 --> 00:56:01,320
Speaker 5:  It. I was talking with Liz Bunch about this yesterday. We were trying to

994
00:56:01,320 --> 00:56:04,680
Speaker 5:  figure out why is this man coming and talking to everybody repeatedly. Wait,

995
00:56:04,680 --> 00:56:07,800
Speaker 4:  Before we go any farther with this, let's just back up a little bit. Keith,

996
00:56:07,800 --> 00:56:11,100
Speaker 4:  can you tell us just the elevator version of what's going on with

997
00:56:11,100 --> 00:56:11,910
Speaker 4:  ftx?

998
00:56:11,910 --> 00:56:15,880
Speaker 6:  Sure. This is probably important. So FTX basically

999
00:56:15,880 --> 00:56:19,860
Speaker 6:  started as this hedge fund called Alameda Research. They

1000
00:56:19,860 --> 00:56:23,400
Speaker 6:  did a very basic thing and made a lot of money doing it where they basically

1001
00:56:23,400 --> 00:56:27,240
Speaker 6:  traded the difference between the price of crypto in one country versus

1002
00:56:27,240 --> 00:56:30,880
Speaker 6:  the next, I believe it was maybe Japan and the US for a while. Sam

1003
00:56:30,880 --> 00:56:34,760
Speaker 6:  Bakeman freed young dude with seems like other really

1004
00:56:34,760 --> 00:56:37,880
Speaker 6:  young people, some of which he had extra, you know, kind of relationships

1005
00:56:37,880 --> 00:56:41,130
Speaker 6:  with are all running this thing. It's like a classic like

1006
00:56:41,130 --> 00:56:44,240
Speaker 6:  finance bro, like pounding Red Bulls

1007
00:56:44,240 --> 00:56:47,940
Speaker 6:  like at your desk all day thing. And

1008
00:56:47,940 --> 00:56:51,740
Speaker 6:  FTX gets created as Alameda is taking off

1009
00:56:51,740 --> 00:56:55,480
Speaker 6:  and you know, I'll skip all the, all the intricacies. What essentially how

1010
00:56:55,480 --> 00:56:58,880
Speaker 6:  it all came down is there was a obvious, you know, massive collapse in the

1011
00:56:58,880 --> 00:57:02,860
Speaker 6:  price of cryptocurrency and essentially a run on the bank happened on

1012
00:57:02,860 --> 00:57:06,790
Speaker 6:  ftx. And the problem was is that FTX didn't actually have the money

1013
00:57:06,790 --> 00:57:10,600
Speaker 6:  that its depositors, that its customers put with

1014
00:57:10,600 --> 00:57:14,240
Speaker 6:  them because Alameda research took that money to

1015
00:57:14,240 --> 00:57:17,800
Speaker 6:  back the bets that had lost all of its money on, as a hedge fund

1016
00:57:17,800 --> 00:57:21,480
Speaker 6:  betting on certain crypto assets that plummeted. And

1017
00:57:21,480 --> 00:57:25,440
Speaker 6:  so Sam did the, you know, one of the worst things you could possibly

1018
00:57:25,440 --> 00:57:29,120
Speaker 6:  do in finance and what is actually legal if you're like a fully

1019
00:57:29,120 --> 00:57:33,020
Speaker 6:  regulated financial institution, which FTX was not, it was based in The

1020
00:57:33,020 --> 00:57:36,800
Speaker 6:  Bahamas. All this is very relevant now because it was very clear he was trying

1021
00:57:36,800 --> 00:57:39,600
Speaker 6:  to skirt regulation and he doesn't actually care about regulation even though

1022
00:57:39,600 --> 00:57:43,360
Speaker 6:  he was saying he was the one who cared about the most. And yeah, FTX ended

1023
00:57:43,360 --> 00:57:47,120
Speaker 6:  up not having the money to be able to give people their, their deposits.

1024
00:57:47,120 --> 00:57:51,080
Speaker 6:  And so the whole thing came crashing down 10 plus billion. You know, this

1025
00:57:51,080 --> 00:57:54,920
Speaker 6:  was a guy who was the largest or one of the largest donors in the

1026
00:57:54,920 --> 00:57:55,840
Speaker 6:  midterms to

1027
00:57:55,840 --> 00:57:57,200
Speaker 4:  Both sides. It turned out to

1028
00:57:57,200 --> 00:58:01,080
Speaker 6:  Both sides. He says like, you know, he was the youngest billionaire of

1029
00:58:01,080 --> 00:58:04,440
Speaker 6:  his stature. I think he was the richest, you know, billionaire under 30 for

1030
00:58:04,440 --> 00:58:08,240
Speaker 6:  a minute on paper. And now he says he's got, he's broken, you know, but we

1031
00:58:08,240 --> 00:58:10,600
Speaker 6:  don't actually know that there's been a lot of reporting that money was taken

1032
00:58:10,600 --> 00:58:14,440
Speaker 6:  out and it's unclear a lot of home bought that sort of thing. So

1033
00:58:14,440 --> 00:58:16,080
Speaker 6:  that's like the, that's the elevator

1034
00:58:16,080 --> 00:58:19,720
Speaker 4:  Story of the Yeah. And Liz has been doing great work covering FTX on the

1035
00:58:19,720 --> 00:58:23,390
Speaker 4:  site just for our purposes again, our,

1036
00:58:23,390 --> 00:58:26,720
Speaker 4:  it's a financial story at the end of the day. It's a, yeah, you started an

1037
00:58:26,720 --> 00:58:30,680
Speaker 4:  unregulated bank and then did the shadiest things that an unregulated

1038
00:58:30,680 --> 00:58:34,480
Speaker 4:  bank could do and the amount of technology involved. Yes,

1039
00:58:34,480 --> 00:58:37,920
Speaker 4:  crypto has some interesting tech baked into it, but like at the end of the

1040
00:58:37,920 --> 00:58:41,760
Speaker 4:  day it's, it's like a bank story. So yes, we've cover it, but I'm watching

1041
00:58:41,760 --> 00:58:45,270
Speaker 4:  this interview and what actually really struck me is

1042
00:58:45,270 --> 00:58:49,000
Speaker 4:  crypto, crypto in general. I don't if

1043
00:58:49,000 --> 00:58:52,800
Speaker 4:  you remember what I think of as crypto summer was hailed as like

1044
00:58:52,800 --> 00:58:56,680
Speaker 4:  the next gigantic turn for the tech industry and we all

1045
00:58:56,680 --> 00:59:00,400
Speaker 4:  had to hear about web three in Terminable and just

1046
00:59:00,400 --> 00:59:04,060
Speaker 4:  for an endless amount of crypto stuff occurred.

1047
00:59:04,060 --> 00:59:07,160
Speaker 4:  And Washington scenario was like, oh this, this is the moment where it's

1048
00:59:07,160 --> 00:59:10,440
Speaker 4:  dead. Right Where he, he, yeah. He talks to the Times yesterday he talked

1049
00:59:10,440 --> 00:59:14,420
Speaker 4:  to New York Mag, our sister publication, he was on Good Morning America this

1050
00:59:14,420 --> 00:59:17,920
Speaker 4:  morning and he's like, I need, I owe it to my customers to explain

1051
00:59:17,920 --> 00:59:21,680
Speaker 4:  what happened. To explain every prosecutor in every state

1052
00:59:21,680 --> 00:59:24,990
Speaker 4:  and the country is like, and you should keep talking.

1053
00:59:24,990 --> 00:59:25,490
Speaker 6:  Yeah.

1054
00:59:25,490 --> 00:59:29,480
Speaker 4:  Because everything you say is admissible in any discrepancy in

1055
00:59:29,480 --> 00:59:32,040
Speaker 4:  what you say, we're gonna hold up in front of a jury and used to put you

1056
00:59:32,040 --> 00:59:35,920
Speaker 4:  in jail. And it just feels like maybe the entire industry is

1057
00:59:35,920 --> 00:59:39,760
Speaker 4:  tainted in irrevocable way because of all of this

1058
00:59:39,760 --> 00:59:43,340
Speaker 4:  now. Right? I mean if you remember the Super Bowl with to like all the crypto

1059
00:59:43,340 --> 00:59:47,240
Speaker 4:  ads, like Tom Brady was a FTX spokesman. He made an ad with

1060
00:59:47,240 --> 00:59:51,000
Speaker 4:  Giselle and the entire ad was basically like you should be in our Ponzi scheme,

1061
00:59:51,000 --> 00:59:54,750
Speaker 4:  there was no mention of utility. It was just him being like, are you in

1062
00:59:54,750 --> 00:59:56,640
Speaker 4:  over and over again to his famous friends?

1063
00:59:56,640 --> 01:00:00,360
Speaker 6:  Well and we saw what that did to Tom and Giselle and you know, that's

1064
01:00:00,360 --> 01:00:00,800
Speaker 6:  a

1065
01:00:00,800 --> 01:00:01,000
Speaker 4:  Metaphor

1066
01:00:01,000 --> 01:00:02,000
Speaker 6:  For what it's

1067
01:00:02,000 --> 01:00:03,900
Speaker 4:  Doing. He's not having a good year,

1068
01:00:03,900 --> 01:00:04,320
Speaker 6:  Not

1069
01:00:04,320 --> 01:00:04,840
Speaker 5:  A great year

1070
01:00:04,840 --> 01:00:07,390
Speaker 4:  For Tom. It's not the best year Tommy's life.

1071
01:00:07,390 --> 01:00:08,100
Speaker 6:  Yeah.

1072
01:00:08,100 --> 01:00:11,240
Speaker 4:  But fundamentally like do you, do you, do you think that that's the case

1073
01:00:11,240 --> 01:00:14,930
Speaker 4:  that this moment for crypto has just come to an end

1074
01:00:14,930 --> 01:00:17,870
Speaker 4:  in the next moment? I mean there might be an next moment. There has been

1075
01:00:17,870 --> 01:00:21,480
Speaker 4:  some interesting technology developed, but I have heard

1076
01:00:21,480 --> 01:00:25,360
Speaker 4:  more from vindicated skeptics than I have heard from people

1077
01:00:25,360 --> 01:00:26,990
Speaker 4:  who are like, we'll come back from this.

1078
01:00:26,990 --> 01:00:30,880
Speaker 5:  I talked to a friend who was like an executive at one of these big crypto

1079
01:00:30,880 --> 01:00:34,760
Speaker 5:  companies and he got laid off because they, it was running out of money

1080
01:00:34,760 --> 01:00:37,320
Speaker 5:  because so many of these companies were like, we're gonna throw a bunch of

1081
01:00:37,320 --> 01:00:40,480
Speaker 5:  investment at it and see what happens. And it's like, wait, just giant Ponzi

1082
01:00:40,480 --> 01:00:44,220
Speaker 5:  schemes, eventually your money goes somewhere and it never comes back.

1083
01:00:44,220 --> 01:00:47,760
Speaker 5:  And I was like, is crypto kind of done with the collapse of ftx? And he's

1084
01:00:47,760 --> 01:00:51,600
Speaker 5:  like, I don't see how it can recover. It just really, yeah, he's like,

1085
01:00:51,600 --> 01:00:55,470
Speaker 5:  I just do not see how it happens after this. And I think

1086
01:00:55,470 --> 01:00:59,440
Speaker 5:  even people in the crypto community always

1087
01:00:59,440 --> 01:01:03,170
Speaker 5:  kind of knew that a big chunk of this is a Ponzi scheme because this money

1088
01:01:03,170 --> 01:01:07,040
Speaker 5:  is fake money and it doesn't, there's no like, there's no gold standard,

1089
01:01:07,040 --> 01:01:09,400
Speaker 5:  there's no, there's nothing at the other end saying this

1090
01:01:09,400 --> 01:01:12,160
Speaker 4:  Is real. All money is fake money. Did you just advocate for the gold standard

1091
01:01:12,160 --> 01:01:13,140
Speaker 4:  on the Verge cast?

1092
01:01:13,140 --> 01:01:16,530
Speaker 5:  Yes, I did.

1093
01:01:16,530 --> 01:01:18,960
Speaker 4:  By that standard. All, all money is fake money. But

1094
01:01:18,960 --> 01:01:22,820
Speaker 5:  I mean, you know, there's no difference between this money

1095
01:01:22,820 --> 01:01:26,800
Speaker 5:  and the goal that Ash and I are currently mining on World of Warcraft

1096
01:01:26,800 --> 01:01:30,680
Speaker 5:  as we pretend to be Little Dragons. Like what's the difference? Both of

1097
01:01:30,680 --> 01:01:33,880
Speaker 5:  them can theoretically be used to buy goods and as more

1098
01:01:33,880 --> 01:01:36,760
Speaker 6:  People, well one you can actually use for something and World of Warcraft,

1099
01:01:36,760 --> 01:01:37,440
Speaker 6:  that's it.

1100
01:01:37,440 --> 01:01:40,640
Speaker 5:  Yeah. One I can go and I buy mats to make my dragons

1101
01:01:40,640 --> 01:01:44,530
Speaker 5:  stronger. The other one I can hopefully get some cash for

1102
01:01:44,530 --> 01:01:48,480
Speaker 5:  if I traded in crypto. And like, I think they all

1103
01:01:48,480 --> 01:01:52,410
Speaker 5:  kind of were aware that the bottom could drop out of this at any time.

1104
01:01:52,410 --> 01:01:55,990
Speaker 5:  If anybody wants to run on the bank, a totally unregulated bank

1105
01:01:55,990 --> 01:01:59,870
Speaker 5:  will be destroyed. And so like, yeah, I think it's done.

1106
01:01:59,870 --> 01:02:03,840
Speaker 6:  I, I think, I don't think it's done. I think what we saw in this last

1107
01:02:03,840 --> 01:02:07,440
Speaker 6:  wave was a lot of key infrastructure tech was built

1108
01:02:07,440 --> 01:02:11,320
Speaker 6:  like layers of blockchains were built with no use cases on top

1109
01:02:11,320 --> 01:02:15,120
Speaker 6:  of them. So it was a Ponzi scheme because once you buy a bunch

1110
01:02:15,120 --> 01:02:18,960
Speaker 6:  of whatever, what are you gonna do with it? Right? Yeah. Except, you know,

1111
01:02:18,960 --> 01:02:22,120
Speaker 6:  know certain illicit things that I, you know, obviously have no idea what

1112
01:02:22,120 --> 01:02:25,920
Speaker 6:  those are. So, so if if you, if if that's the only

1113
01:02:25,920 --> 01:02:29,440
Speaker 6:  use case, it is a Ponzi scheme. And so I am actually

1114
01:02:29,440 --> 01:02:32,840
Speaker 6:  seeing interesting startups, there's a lot of VC money deployed into

1115
01:02:32,840 --> 01:02:36,560
Speaker 6:  crypto into these startups that are actually trying to build use

1116
01:02:36,560 --> 01:02:40,440
Speaker 6:  cases. And I, I think, you know, we saw some of that in gaming. It

1117
01:02:40,440 --> 01:02:43,240
Speaker 6:  didn't really go anywhere. There was, it was kind of a brief moment but

1118
01:02:43,240 --> 01:02:47,000
Speaker 5:  Where, where are the use cases you're seeing that like could go

1119
01:02:47,000 --> 01:02:49,750
Speaker 5:  somewhere all was gaming and it went Payments, payments.

1120
01:02:49,750 --> 01:02:53,720
Speaker 6:  I think we'll see some of the large social apps. Elon has talked, I

1121
01:02:53,720 --> 01:02:54,600
Speaker 6:  know it's like, you know,

1122
01:02:54,600 --> 01:02:55,830
Speaker 4:  All way back around.

1123
01:02:55,830 --> 01:02:59,680
Speaker 6:  Yeah, all the way back around. But like Twitter will add, crypto Telegram

1124
01:02:59,680 --> 01:03:03,390
Speaker 6:  is adding crypto, I think Metas apps, they're already doing

1125
01:03:03,390 --> 01:03:06,720
Speaker 6:  NFTs on Polygon. I think they will probably have some kind of crypto payment

1126
01:03:06,720 --> 01:03:10,680
Speaker 6:  feature within three years. But there there is a payments layer

1127
01:03:10,680 --> 01:03:14,480
Speaker 6:  where it does make sense to eliminate a middleman

1128
01:03:14,480 --> 01:03:18,000
Speaker 6:  if you can. And like if you use one of these tokens that

1129
01:03:18,000 --> 01:03:21,560
Speaker 6:  actually can move quickly and a chain that actually is performative,

1130
01:03:21,560 --> 01:03:25,260
Speaker 6:  like it does make sense as a payment mechanism. You just have to have

1131
01:03:25,260 --> 01:03:27,900
Speaker 6:  the network effects for that. And no one's done that yet.

1132
01:03:27,900 --> 01:03:31,560
Speaker 5:  How does it make sense to go and invest, go

1133
01:03:31,560 --> 01:03:35,400
Speaker 5:  find a crypto that I feel good about, find an app

1134
01:03:35,400 --> 01:03:39,290
Speaker 5:  that I wanna use to invest in it. Invest

1135
01:03:39,290 --> 01:03:42,830
Speaker 5:  my my my cash, my my my legal Tinder

1136
01:03:42,830 --> 01:03:46,760
Speaker 5:  that is regulated. Then go like how is that

1137
01:03:46,760 --> 01:03:50,040
Speaker 5:  faster and easier than Apple Pay or my

1138
01:03:50,040 --> 01:03:50,830
Speaker 5:  Amex?

1139
01:03:50,830 --> 01:03:54,280
Speaker 6:  It's not. But like that you're describing is the retail

1140
01:03:54,280 --> 01:03:58,000
Speaker 6:  covid fed STEMI bubble mania that we had

1141
01:03:58,000 --> 01:04:01,640
Speaker 6:  that was like the perfect cocktail of people wanting to speculate in crypto.

1142
01:04:01,640 --> 01:04:04,960
Speaker 6:  Right. And a bunch of companies being opportunistic about you know, prime.

1143
01:04:04,960 --> 01:04:08,640
Speaker 5:  But I'm saying like now that crypto's been pretty poisoned in public

1144
01:04:08,640 --> 01:04:10,520
Speaker 5:  Yeah. View, right? Like most

1145
01:04:10,520 --> 01:04:12,660
Speaker 6:  People definitely on a retail level. Yeah.

1146
01:04:12,660 --> 01:04:16,060
Speaker 5:  How does it go, how does it come back from that? Like on the retail level,

1147
01:04:16,060 --> 01:04:19,920
Speaker 5:  how am I gonna get my best friend who has no idea what a crypto

1148
01:04:19,920 --> 01:04:21,640
Speaker 5:  wallet is to go and use

1149
01:04:21,640 --> 01:04:24,600
Speaker 6:  That? I mean it has to move outta speculation. It has to move out of like

1150
01:04:24,600 --> 01:04:27,320
Speaker 6:  you're buying this thing because it may go up one day. It has to be like,

1151
01:04:27,320 --> 01:04:30,960
Speaker 6:  oh I actually need this to like send someone money on Twitter or on

1152
01:04:30,960 --> 01:04:31,520
Speaker 6:  Telegram or

1153
01:04:31,520 --> 01:04:35,250
Speaker 4:  This is the thing that, that truly struck me about watching Sam

1154
01:04:35,250 --> 01:04:39,000
Speaker 4:  in person book and watching the other interviews. There are like two stories

1155
01:04:39,000 --> 01:04:42,960
Speaker 4:  in tech right now, right? There's Elon and Twitter and there's ftx. Yeah.

1156
01:04:42,960 --> 01:04:46,950
Speaker 4:  And we are cover, we might be over covering Elon and Twitter and we are

1157
01:04:46,950 --> 01:04:50,800
Speaker 4:  covering to a certain degree FTX and crypto because there's a tech

1158
01:04:50,800 --> 01:04:54,640
Speaker 4:  element to it. But when you peel back the layers, you have

1159
01:04:54,640 --> 01:04:58,610
Speaker 4:  be a finance expert to really understand what happened at ftx.

1160
01:04:58,610 --> 01:05:02,040
Speaker 4:  To really catch him in the, in the fraud that everyone alleges that he's

1161
01:05:02,040 --> 01:05:06,000
Speaker 4:  committing. Which you probably did there. I cannot find the part

1162
01:05:06,000 --> 01:05:09,570
Speaker 4:  where it's like, and here's the thing they did technically

1163
01:05:09,570 --> 01:05:13,540
Speaker 4:  that created the fraud. It's all just the shell game

1164
01:05:13,540 --> 01:05:17,480
Speaker 4:  of an unregulated bank. And then people saying I want my money

1165
01:05:17,480 --> 01:05:20,960
Speaker 4:  and the bank saying, sorry we spent it on my girlfriend's hedge fund. Which

1166
01:05:20,960 --> 01:05:22,200
Speaker 4:  is an incredible outcome by the

1167
01:05:22,200 --> 01:05:25,480
Speaker 5:  Way. It was just, it's a wonderful life. Yeah. Just the whole

1168
01:05:25,480 --> 01:05:29,440
Speaker 5:  scene. But this is the tech You ready for the tech element

1169
01:05:29,440 --> 01:05:31,240
Speaker 5:  of it? Yeah, it happened

1170
01:05:31,240 --> 01:05:33,450
Speaker 5:  online.

1171
01:05:33,450 --> 01:05:37,360
Speaker 4:  We used to a long time ago at the beginning of the Verge when we had

1172
01:05:37,360 --> 01:05:40,400
Speaker 4:  like vet stories, so to decide whether we were gonna write about them, we

1173
01:05:40,400 --> 01:05:43,600
Speaker 4:  had to draw a line that's like, we can't do this just because someone tweeted

1174
01:05:43,600 --> 01:05:46,840
Speaker 4:  about it. Yeah. Like that, that's not, that doesn't make it a text story.

1175
01:05:46,840 --> 01:05:47,320
Speaker 4:  That's just something

1176
01:05:47,320 --> 01:05:48,920
Speaker 6:  How that has changed.

1177
01:05:48,920 --> 01:05:51,200
Speaker 4:  Yeah. Now it's like all day, every day as people are tweeting, we have to

1178
01:05:51,200 --> 01:05:53,920
Speaker 4:  react to it. We should actually talk about this part cuz I did get a bunch

1179
01:05:53,920 --> 01:05:56,540
Speaker 4:  of questions and I said we would talk about the Verge asked a little bit

1180
01:05:56,540 --> 01:06:00,070
Speaker 4:  the notion that just by interviewing Sam Bankman free,

1181
01:06:00,070 --> 01:06:03,740
Speaker 4:  you're perpetuating this fraud. I I like

1182
01:06:03,740 --> 01:06:07,720
Speaker 4:  fundamentally our job is to talk to people. So it seems, and I understand

1183
01:06:07,720 --> 01:06:09,760
Speaker 4:  that you don't wanna platform like there's people you don't wanna platform.

1184
01:06:09,760 --> 01:06:13,240
Speaker 4:  But at this moment it's like, well he's the bad guy,

1185
01:06:13,240 --> 01:06:17,080
Speaker 4:  right? He's the villain. Like you, you want to know if you can get the villain

1186
01:06:17,080 --> 01:06:20,800
Speaker 4:  to admit the villa and like, but he did him speaking is actually like

1187
01:06:20,800 --> 01:06:24,640
Speaker 4:  a public service in its way. Like if, if you are a good interviewer, I dunno,

1188
01:06:24,640 --> 01:06:25,350
Speaker 4:  what do you guys think?

1189
01:06:25,350 --> 01:06:28,640
Speaker 6:  I find it bizarre. I mean I guess I can understand if you don't work in the

1190
01:06:28,640 --> 01:06:31,920
Speaker 6:  media thinking that the media is like aiding and embedding him if they're

1191
01:06:31,920 --> 01:06:35,840
Speaker 6:  giving him a platform. But I mean why, why would you

1192
01:06:35,840 --> 01:06:38,740
Speaker 6:  not? Because you think that he doesn't deserve

1193
01:06:38,740 --> 01:06:40,050
Speaker 4:  The attention. Like,

1194
01:06:40,050 --> 01:06:41,120
Speaker 6:  Or that the attention,

1195
01:06:41,120 --> 01:06:44,300
Speaker 5:  I think it's really down to like how that platform, how you use that platform,

1196
01:06:44,300 --> 01:06:44,720
Speaker 5:  how

1197
01:06:44,720 --> 01:06:45,120
Speaker 4:  You use it,

1198
01:06:45,120 --> 01:06:48,680
Speaker 5:  Right? Like if if he'd gone up there with somebody who was a really soft

1199
01:06:48,680 --> 01:06:52,240
Speaker 5:  interviewer who was just like, tell me, okay, now what's your day like now

1200
01:06:52,240 --> 01:06:54,310
Speaker 5:  that you've bankrupted your company

1201
01:06:54,310 --> 01:06:57,000
Speaker 4:  That's going on bomb is escaping the

1202
01:06:57,000 --> 01:07:00,920
Speaker 5:  Feds. Like what kinda plastic fern is that that you have looming over

1203
01:07:00,920 --> 01:07:02,320
Speaker 5:  your head for this entire interview?

1204
01:07:02,320 --> 01:07:06,280
Speaker 4:  Yeah, I don't, I haven't seen that. I have seen a lot of cred like

1205
01:07:06,280 --> 01:07:07,360
Speaker 4:  credulous interview.

1206
01:07:07,360 --> 01:07:09,890
Speaker 5:  Yeah. And that's the thing is that's why I think it's okay. Like I think

1207
01:07:09,890 --> 01:07:13,450
Speaker 5:  we, we've gotten, we've seen a lot of interviews with bad actors like this

1208
01:07:13,450 --> 01:07:16,860
Speaker 5:  in the past where they go and they give their sob story and there's no pushback.

1209
01:07:16,860 --> 01:07:20,680
Speaker 5:  But Sorkin was like, to his credit, pushing back. Yeah. Really

1210
01:07:20,680 --> 01:07:21,680
Speaker 5:  consistently. Oh

1211
01:07:21,680 --> 01:07:24,280
Speaker 4:  Yeah, the last, the last you should all watch. Actually there was a very

1212
01:07:24,280 --> 01:07:27,280
Speaker 4:  funny like very verge moment in this

1213
01:07:27,280 --> 01:07:30,920
Speaker 4:  interview. He's coming to the end and he

1214
01:07:30,920 --> 01:07:34,760
Speaker 4:  asks a question and he is like, so you had no CFO and

1215
01:07:34,760 --> 01:07:38,520
Speaker 4:  no board of directors. Did you, did you think that was a problem? And

1216
01:07:38,520 --> 01:07:41,300
Speaker 4:  again, this is a room full of bankers and people who have invested in FTX

1217
01:07:41,300 --> 01:07:44,920
Speaker 4:  who all should have seen the lack of a CFO and the lack of a board of directors,

1218
01:07:44,920 --> 01:07:48,630
Speaker 4:  a giant waving red flag, spend the money anyway. And Sam goes,

1219
01:07:48,630 --> 01:07:52,320
Speaker 4:  I think we had too many boards and the call drops. And

1220
01:07:52,320 --> 01:07:55,920
Speaker 4:  so everyone thinks that he did this on purpose,

1221
01:07:55,920 --> 01:07:59,880
Speaker 4:  right? That he's like yanked the plug or like his lawyers have finally stormed

1222
01:07:59,880 --> 01:08:02,880
Speaker 4:  into the room and like thrown the laptop out the window. And I'm looking

1223
01:08:02,880 --> 01:08:04,980
Speaker 4:  at it, I'm like, oh that's the elga cam link.

1224
01:08:04,980 --> 01:08:06,540
Speaker 6:  Did you stand up and yell at

1225
01:08:06,540 --> 01:08:09,940
Speaker 4:  His camera? Just died. That's all.

1226
01:08:09,940 --> 01:08:10,680
Speaker 6:  I'm the tech

1227
01:08:10,680 --> 01:08:14,520
Speaker 4:  Expert. Yeah. I was like, I can check the Delgado. It's just like, and

1228
01:08:14,520 --> 01:08:18,000
Speaker 4:  everyone's like, oh my God, is he coming back? And I was like, no dude, that's

1229
01:08:18,000 --> 01:08:19,800
Speaker 4:  just the

1230
01:08:19,800 --> 01:08:21,560
Speaker 5:  Computer just timed down.

1231
01:08:21,560 --> 01:08:25,080
Speaker 4:  He'll be back like this dude can't shut up he'll. And lo and behold he came

1232
01:08:25,080 --> 01:08:28,920
Speaker 4:  back and I encourage everyone to just watch the last five

1233
01:08:28,920 --> 01:08:32,560
Speaker 4:  minutes of this interview on the Times this site. And it's also, it's, it's

1234
01:08:32,560 --> 01:08:36,200
Speaker 4:  all over TikTok. Like this is, this thing has been free rebooted everywhere

1235
01:08:36,200 --> 01:08:40,120
Speaker 4:  sort just like mash. And he ends by saying, are you lying? Which is, I

1236
01:08:40,120 --> 01:08:43,840
Speaker 4:  think I'm gonna end every decoder interview by being like, so are you lying?

1237
01:08:43,840 --> 01:08:46,890
Speaker 6:  We'll note that S SPF did not give a quick

1238
01:08:46,890 --> 01:08:50,840
Speaker 6:  no, which is never a good sign that you're

1239
01:08:50,840 --> 01:08:54,760
Speaker 6:  actually not lying. I did think that the awkward clapping at the

1240
01:08:54,760 --> 01:08:57,720
Speaker 6:  end was like a little, I understand that that's like a conference thing that

1241
01:08:57,720 --> 01:09:01,550
Speaker 6:  you always clap. But like it was really funny to see people like

1242
01:09:01,550 --> 01:09:04,790
Speaker 6:  clapping as SPF was like leaving but I

1243
01:09:04,790 --> 01:09:06,720
Speaker 5:  Clapping for him. Clapped. They were like, good

1244
01:09:06,720 --> 01:09:10,560
Speaker 4:  Interview. No I know they're for Andrew also. You can't see this. You

1245
01:09:10,560 --> 01:09:14,240
Speaker 4:  couldn't see this on the stream show. But then this all ends and he is like,

1246
01:09:14,240 --> 01:09:17,920
Speaker 4:  all right, so last thing you know, here are some Broadway

1247
01:09:17,920 --> 01:09:21,080
Speaker 4:  performers to close this out. And it was like rapping. It was like Broadway

1248
01:09:21,080 --> 01:09:24,520
Speaker 4:  rap. It was just, it was just a very odd

1249
01:09:24,520 --> 01:09:26,480
Speaker 4:  moment. Very surreal. All

1250
01:09:26,480 --> 01:09:27,680
Speaker 5:  Right cause that was the last interview of

1251
01:09:27,680 --> 01:09:31,230
Speaker 4:  The day. That was, yeah and there was, I, I would just, from what I

1252
01:09:31,230 --> 01:09:34,920
Speaker 4:  gathered from various people there, there was a lot of

1253
01:09:34,920 --> 01:09:36,710
Speaker 4:  skepticism that SPF would show up.

1254
01:09:36,710 --> 01:09:39,530
Speaker 5:  Yeah cuz he booked this before

1255
01:09:39,530 --> 01:09:43,360
Speaker 4:  He booked all this before he said he was gonna do it but he's in The

1256
01:09:43,360 --> 01:09:45,070
Speaker 4:  Bahamas, he doesn't have to do it. Yeah.

1257
01:09:45,070 --> 01:09:48,880
Speaker 5:  That poor events planner who is working on this thing and

1258
01:09:48,880 --> 01:09:52,000
Speaker 5:  they're like, we're gonna have this great triumphant final interview with

1259
01:09:52,000 --> 01:09:55,880
Speaker 5:  the guy who did ftx. He's into all this altruism, it's gonna

1260
01:09:55,880 --> 01:09:58,600
Speaker 5:  be so lovely. And then we're gonna have these dancers come out and it's gonna

1261
01:09:58,600 --> 01:10:02,360
Speaker 5:  be this great moment Then just going, do I get rid of the

1262
01:10:02,360 --> 01:10:05,870
Speaker 5:  dancers? Like what do I do? How do we follow this now?

1263
01:10:05,870 --> 01:10:06,360
Speaker 4:  Yeah

1264
01:10:06,360 --> 01:10:07,660
Speaker 5:  It was shout out to that dude.

1265
01:10:07,660 --> 01:10:11,040
Speaker 4:  You should go watch just at least the last 10 minutes of it just cuz Andrew

1266
01:10:11,040 --> 01:10:13,800
Speaker 4:  did such a good job and like it was so weird. It was so

1267
01:10:13,800 --> 01:10:17,760
Speaker 4:  weird. Truly one of the weirdest moments. All right, we

1268
01:10:17,760 --> 01:10:21,000
Speaker 4:  gotta take a break and come back. We'll do a tiny little gadget lightning

1269
01:10:21,000 --> 01:10:22,240
Speaker 4:  around and we'll get out here. We'll be right

1270
01:10:22,240 --> 01:10:28,170
Speaker 4:  back.

1271
01:12:21,510 --> 01:12:25,210
Speaker 4:  All right, we're back. We need like a pallet cleanser here. We gotta talk

1272
01:12:25,210 --> 01:12:28,490
Speaker 4:  about some gadgets and some buttons and knobs and bleeps and bloops. Alex,

1273
01:12:28,490 --> 01:12:29,170
Speaker 4:  we got for us?

1274
01:12:29,170 --> 01:12:32,970
Speaker 5:  Yeah. All right. I'm not gonna talk about it too much because

1275
01:12:32,970 --> 01:12:36,770
Speaker 5:  David and I talked about it a whole bunch recently in a recorded

1276
01:12:36,770 --> 01:12:40,610
Speaker 5:  episode before the baby came. But the Amazon

1277
01:12:40,610 --> 01:12:44,490
Speaker 5:  Kindle scribe came out this week. I reviewed it. If

1278
01:12:44,490 --> 01:12:48,370
Speaker 5:  you really, really, really, really, really want a Kindle that you can write

1279
01:12:48,370 --> 01:12:51,440
Speaker 5:  on, go for it. Otherwise don't just skip

1280
01:12:51,440 --> 01:12:52,940
Speaker 5:  it.

1281
01:12:52,940 --> 01:12:56,760
Speaker 4:  I'm not Alex and I like art edit meeting was like I reviewed the Kindle scribe

1282
01:12:56,760 --> 01:12:59,160
Speaker 4:  and like I, you know I'm on the show with you. I know how you feel about

1283
01:12:59,160 --> 01:13:02,480
Speaker 4:  ein. Yeah, I would describe the look on your face as

1284
01:13:02,480 --> 01:13:04,200
Speaker 4:  pure devastation.

1285
01:13:04,200 --> 01:13:08,160
Speaker 5:  It's pretty, it's pretty bummer. Pretty big bummer. Why

1286
01:13:08,160 --> 01:13:11,630
Speaker 5:  it's bad. I think it's bad because the software is bad.

1287
01:13:11,630 --> 01:13:15,480
Speaker 5:  Amazon has gotten really complacent with its software design and is

1288
01:13:15,480 --> 01:13:19,440
Speaker 5:  like, yeah you'll enjoy this slop cuz you need it. Cuz

1289
01:13:19,440 --> 01:13:23,360
Speaker 5:  we sell the eBooks. That's kind of the funny monopoly guys for using it.

1290
01:13:23,360 --> 01:13:27,240
Speaker 5:  Yeah, that's how they are. No but but it just like

1291
01:13:27,240 --> 01:13:30,890
Speaker 5:  shoved a bunch of stuff in your face. It kept showing me like comics to buy

1292
01:13:30,890 --> 01:13:34,800
Speaker 5:  on my black and white e-reader. It was just bad at recommending

1293
01:13:34,800 --> 01:13:38,520
Speaker 5:  stuff and the, the note taking elements of it were like

1294
01:13:38,520 --> 01:13:42,080
Speaker 5:  pretty unfulfilling. And the fact that the largest

1295
01:13:42,080 --> 01:13:45,600
Speaker 5:  cloud computing company in the world still has you

1296
01:13:45,600 --> 01:13:48,280
Speaker 5:  emailing yourself in order to sync

1297
01:13:48,280 --> 01:13:51,040
Speaker 5:  documents that just

1298
01:13:51,040 --> 01:13:52,820
Speaker 5:  seems,

1299
01:13:52,820 --> 01:13:55,680
Speaker 4:  Hey, it's still not as bad as horizon work. Yeah, I'll

1300
01:13:55,680 --> 01:13:59,600
Speaker 5:  Tell you that. That's true. It's like, it's like three below it

1301
01:13:59,600 --> 01:14:03,040
Speaker 5:  but it was just, it was just a, a big bummer and

1302
01:14:03,040 --> 01:14:06,600
Speaker 5:  you'll have to stay tuned for an upcoming episode of the Wednesday show where

1303
01:14:06,600 --> 01:14:10,520
Speaker 5:  I talk all about it. It's really great. But also there was a new track ball

1304
01:14:10,520 --> 01:14:14,440
Speaker 5:  mouse. David's not here to like stop all of my better. Like stop

1305
01:14:14,440 --> 01:14:14,560
Speaker 5:  me.

1306
01:14:14,560 --> 01:14:17,440
Speaker 4:  Yeah. I can really, I'm looking at this rundown and I'm like, oh this Alex

1307
01:14:17,440 --> 01:14:21,360
Speaker 4:  made this rundown of gadgets. This is a real, you can tell that

1308
01:14:21,360 --> 01:14:22,840
Speaker 4:  David wasn't here this week. It's,

1309
01:14:22,840 --> 01:14:26,580
Speaker 5:  It's, this is very exciting because for years the track ball space

1310
01:14:26,580 --> 01:14:30,520
Speaker 5:  was totally undeveloped. We didn't have a lot of track balls. They

1311
01:14:30,520 --> 01:14:33,330
Speaker 5:  were all wired. It was horrible.

1312
01:14:33,330 --> 01:14:36,120
Speaker 4:  Finally, track ball space was

1313
01:14:36,120 --> 01:14:37,390
Speaker 4:  undeveloped.

1314
01:14:37,390 --> 01:14:38,560
Speaker 5:  Kensington said

1315
01:14:38,560 --> 01:14:41,440
Speaker 4:  No it's actually not crypto you guys, it's track balls.

1316
01:14:41,440 --> 01:14:42,760
Speaker 5:  Balls. That's

1317
01:14:42,760 --> 01:14:46,360
Speaker 4:  The future. Like the hot VC money is going into the track ball space. Kensington

1318
01:14:46,360 --> 01:14:50,020
Speaker 5:  And Logitech are just like, send us all your cash. Invest in us,

1319
01:14:50,020 --> 01:14:50,960
Speaker 5:  but New

1320
01:14:50,960 --> 01:14:54,720
Speaker 4:  Wireless. Who is the SPF of track balls? Clarence, Steve Kensington?

1321
01:14:54,720 --> 01:14:55,160
Speaker 4:  No, it's

1322
01:14:55,160 --> 01:14:58,120
Speaker 5:  The guy who makes poopy. Oh okay. No, the poopy guys are actually lovely.

1323
01:14:58,120 --> 01:14:58,880
Speaker 5:  They're, they're,

1324
01:14:58,880 --> 01:15:01,120
Speaker 4:  They're the track ball looks sick and I kind of want one, I gotta be honest

1325
01:15:01,120 --> 01:15:03,520
Speaker 4:  with you. It looks sick. Yeah. Do they still do the thing where they make

1326
01:15:03,520 --> 01:15:07,040
Speaker 4:  custom track ball balls with like eight balls and things? Yes. Track ball

1327
01:15:07,040 --> 01:15:09,900
Speaker 4:  balls. Yeah. No this is like a hot, like when I was like eighth grade, like

1328
01:15:09,900 --> 01:15:11,280
Speaker 4:  the custom track now now

1329
01:15:11,280 --> 01:15:15,200
Speaker 5:  You, you build your own track ball and then you, I know a guy who takes

1330
01:15:15,200 --> 01:15:18,960
Speaker 5:  like steel ball bearings and he polishes them and then he like colors

1331
01:15:18,960 --> 01:15:22,740
Speaker 5:  them with metal. I don't know, I'm not a metaler just,

1332
01:15:22,740 --> 01:15:26,160
Speaker 5:  but he does stuff and so he's got his own little fancy custom a track

1333
01:15:26,160 --> 01:15:30,080
Speaker 5:  balls. But if you don't wanna do that you can get

1334
01:15:30,080 --> 01:15:33,820
Speaker 5:  this new wireless version of the Slim Blade, which is a great name.

1335
01:15:33,820 --> 01:15:37,320
Speaker 4:  I'm reading the actual press release for this product. Can I just read you

1336
01:15:37,320 --> 01:15:38,580
Speaker 4:  the headline of this press release?

1337
01:15:38,580 --> 01:15:39,460
Speaker 5:  Yes.

1338
01:15:39,460 --> 01:15:43,240
Speaker 4:  Kensington's Slim Blade Pro takes track balls to the next

1339
01:15:43,240 --> 01:15:43,900
Speaker 4:  level.

1340
01:15:43,900 --> 01:15:45,280
Speaker 5:  Yes, I believe

1341
01:15:45,280 --> 01:15:48,320
Speaker 4:  It. They had a meeting like this got sent around. They're like, what's the

1342
01:15:48,320 --> 01:15:51,600
Speaker 4:  headline of a press release? And they're like, do it the next level, next

1343
01:15:51,600 --> 01:15:52,090
Speaker 4:  level.

1344
01:15:52,090 --> 01:15:52,440
Speaker 5:  No

1345
01:15:52,440 --> 01:15:56,180
Speaker 4:  One's stopped. I love it. No one's stopped. I'm buying one of these.

1346
01:15:56,180 --> 01:16:00,030
Speaker 4:  Why is the track ball encrypted? Right. You know, so

1347
01:16:00,030 --> 01:16:01,120
Speaker 4:  I guess the Bluetooth I guess.

1348
01:16:01,120 --> 01:16:04,670
Speaker 5:  Yeah, you wanna have the Bluetooth encrypted then what else?

1349
01:16:04,670 --> 01:16:08,390
Speaker 5:  Yeah, Allison Johnson reviewed the, or checked out the new

1350
01:16:08,390 --> 01:16:12,150
Speaker 5:  GenY Covert doc mini, which lets you like

1351
01:16:12,150 --> 01:16:15,880
Speaker 5:  dock a lot of your different game systems very easily. And

1352
01:16:15,880 --> 01:16:19,370
Speaker 5:  historically those docs for like the Switch are these giant

1353
01:16:19,370 --> 01:16:20,560
Speaker 5:  devices. Like it's a

1354
01:16:20,560 --> 01:16:22,910
Speaker 4:  Big plus these things like the size of an iPhone charger.

1355
01:16:22,910 --> 01:16:26,440
Speaker 5:  Yeah. And so it's just cool. It's just

1356
01:16:26,440 --> 01:16:29,960
Speaker 5:  nice. I was, when the switch first came out, everybody was complaining about

1357
01:16:29,960 --> 01:16:33,840
Speaker 5:  how they couldn't just plug a USBC cord in and you still can't, you still

1358
01:16:33,840 --> 01:16:37,680
Speaker 5:  can't just like plug a USBC to H D M I cord into your TV and

1359
01:16:37,680 --> 01:16:38,780
Speaker 5:  have a doc.

1360
01:16:38,780 --> 01:16:42,240
Speaker 4:  But that does seem like amis. But this thing looks cool. This is a great

1361
01:16:42,240 --> 01:16:42,830
Speaker 4:  gadget.

1362
01:16:42,830 --> 01:16:43,320
Speaker 5:  Yeah.

1363
01:16:43,320 --> 01:16:46,720
Speaker 4:  Just very, very close. This is like the rare Indiegogo that like really went

1364
01:16:46,720 --> 01:16:47,640
Speaker 4:  off. Yeah

1365
01:16:47,640 --> 01:16:50,440
Speaker 5:  Cuz Genie's been, they've, they've had a couple of these. This is, this is

1366
01:16:50,440 --> 01:16:54,400
Speaker 5:  the newest one. It's only $50 and like

1367
01:16:54,400 --> 01:16:58,320
Speaker 5:  you can just check it in your purse, which is what she did. You guys

1368
01:16:58,320 --> 01:17:01,960
Speaker 5:  I guess would put it in your cargo pants. Your, your

1369
01:17:01,960 --> 01:17:03,520
Speaker 5:  fanny pack. I don't what what

1370
01:17:03,520 --> 01:17:07,280
Speaker 4:  How did, how did you know that's what I wear every day. Is it

1371
01:17:07,280 --> 01:17:09,470
Speaker 4:  because I live in Southern California

1372
01:17:09,470 --> 01:17:10,760
Speaker 5:  Just with flip flops,

1373
01:17:10,760 --> 01:17:11,720
Speaker 4:  Your board shorts.

1374
01:17:11,720 --> 01:17:14,920
Speaker 5:  That's actually what Alex is wearing right now. You guys can't see it but

1375
01:17:14,920 --> 01:17:15,240
Speaker 5:  looking

1376
01:17:15,240 --> 01:17:17,720
Speaker 6:  Great. That was a probing, that was a very revealing,

1377
01:17:17,720 --> 01:17:21,110
Speaker 4:  You were just like, throw out cargo pants and see how they react.

1378
01:17:21,110 --> 01:17:24,880
Speaker 4:  That's right. Look, I appreciate an extra pocket. Yeah, I feel like we, we

1379
01:17:24,880 --> 01:17:28,800
Speaker 4:  need to talk about the UFI thing. Maybe we should have Sean come on a Wednesday

1380
01:17:28,800 --> 01:17:32,470
Speaker 4:  show and like really get into it. But Sean Holster I would say

1381
01:17:32,470 --> 01:17:36,440
Speaker 4:  very annoyed with ufe. There's a story that UFE

1382
01:17:36,440 --> 01:17:40,180
Speaker 4:  security cameras can just be accessed by a vlc, the app vlc. Yeah.

1383
01:17:40,180 --> 01:17:44,150
Speaker 4:  You could basically just type a URL in the VLC and start streaming your camera

1384
01:17:44,150 --> 01:17:44,720
Speaker 4:  sick.

1385
01:17:44,720 --> 01:17:45,280
Speaker 6:  Which

1386
01:17:45,280 --> 01:17:49,200
Speaker 4:  Is not great. It's a little bit harder than that. There needs to be, have

1387
01:17:49,200 --> 01:17:52,640
Speaker 4:  been an event that triggered the camera, all this stuff. But UFE is out there

1388
01:17:52,640 --> 01:17:55,820
Speaker 4:  being like our cameras are fully encrypted and safe end to end encrypted

1389
01:17:55,820 --> 01:17:59,040
Speaker 4:  And so he asked him for a statement and he is like, this is impossible. And

1390
01:17:59,040 --> 01:18:01,440
Speaker 4:  then he did it and it worked

1391
01:18:01,440 --> 01:18:05,290
Speaker 6:  Well. Okay. So I have s they're through home kit

1392
01:18:05,290 --> 01:18:09,050
Speaker 6:  though. Like they're through my home app and I don't use the UFI app, therefore

1393
01:18:09,050 --> 01:18:11,170
Speaker 6:  I'm safe. Right. Cause if it goes through home

1394
01:18:11,170 --> 01:18:11,930
Speaker 5:  Kips camera

1395
01:18:11,930 --> 01:18:13,610
Speaker 6:  App, if it goes through Apple Home Kit, isn't it?

1396
01:18:13,610 --> 01:18:17,370
Speaker 5:  It's real bad. Like yeah, gin's talked about this a few times,

1397
01:18:17,370 --> 01:18:21,140
Speaker 5:  but the, the Home Kip camera situation is,

1398
01:18:21,140 --> 01:18:24,210
Speaker 5:  is not one she would recommend. I

1399
01:18:24,210 --> 01:18:26,490
Speaker 6:  Gotta go guys, I problem

1400
01:18:26,490 --> 01:18:29,510
Speaker 5:  Everybody just start like randomizing

1401
01:18:29,510 --> 01:18:33,330
Speaker 5:  UFI camera links and you'll, you'll be like, hello?

1402
01:18:33,330 --> 01:18:36,340
Speaker 5:  And you'll see Alex's cargo pants. It's gonna be great.

1403
01:18:36,340 --> 01:18:39,800
Speaker 6:  So even if, even if you had your UFI routed through home kit,

1404
01:18:39,800 --> 01:18:42,200
Speaker 6:  you're still susceptible to this.

1405
01:18:42,200 --> 01:18:45,730
Speaker 4:  I think it is unclear at this time. Home kit secure video is supposed to

1406
01:18:45,730 --> 01:18:49,610
Speaker 4:  be encrypted. Right. But the VLC thing is just

1407
01:18:49,610 --> 01:18:53,420
Speaker 4:  going to the camera. Right? So

1408
01:18:53,420 --> 01:18:57,310
Speaker 4:  it's like maybe the connection from the camera to home kit to the cloud service

1409
01:18:57,310 --> 01:19:01,300
Speaker 4:  to your phone, all that is encrypted. But if you can just talk

1410
01:19:01,300 --> 01:19:04,100
Speaker 4:  to the camera directly, it'll just give you a video file.

1411
01:19:04,100 --> 01:19:05,860
Speaker 6:  Would thread have kept this from

1412
01:19:05,860 --> 01:19:08,410
Speaker 6:  happening?

1413
01:19:08,410 --> 01:19:11,980
Speaker 4:  I mean I don't, we we got a bunch of cameras outside and I think cameras

1414
01:19:11,980 --> 01:19:15,460
Speaker 4:  inside are really weird and I have always picked the ring

1415
01:19:15,460 --> 01:19:19,300
Speaker 4:  cameras not because I like love the entire

1416
01:19:19,300 --> 01:19:22,740
Speaker 4:  ring ethos of like, what if we terrify old people into having cameras outside

1417
01:19:22,740 --> 01:19:23,190
Speaker 4:  their house?

1418
01:19:23,190 --> 01:19:24,940
Speaker 6:  No. Yeah. You like bad software. I

1419
01:19:24,940 --> 01:19:28,860
Speaker 4:  Love it. It's the best. Yeah. But it's also that I, I know that Amazon

1420
01:19:28,860 --> 01:19:32,500
Speaker 4:  will probably like last a long time and they are fair

1421
01:19:32,500 --> 01:19:36,340
Speaker 4:  and they are gonna run, they're gonna make their own software and run AWS

1422
01:19:36,340 --> 01:19:37,010
Speaker 4:  directly and like,

1423
01:19:37,010 --> 01:19:38,940
Speaker 5:  I mean not if the Kindle's any indication

1424
01:19:38,940 --> 01:19:40,340
Speaker 4:  All these other companies that are

1425
01:19:40,340 --> 01:19:41,490
Speaker 5:  Sorry.

1426
01:19:41,490 --> 01:19:45,100
Speaker 4:  That's true. But I can you VLC into a Kindle. Like

1427
01:19:45,100 --> 01:19:47,660
Speaker 4:  there's just a part of these other companies where it's like they're just

1428
01:19:47,660 --> 01:19:51,580
Speaker 4:  buying commodity bits and bobs off the shelf Yeah. And assembling them

1429
01:19:51,580 --> 01:19:55,220
Speaker 4:  into products and it's like that's where the security consequences come from.

1430
01:19:55,220 --> 01:19:58,220
Speaker 4:  Whereas at least for the Ring, it's like I know they're a company that will

1431
01:19:58,220 --> 01:19:59,540
Speaker 4:  like last a long time because

1432
01:19:59,540 --> 01:20:03,060
Speaker 5:  You feel, I think you feel the appeal was, it wasn't one of these other

1433
01:20:03,060 --> 01:20:06,920
Speaker 5:  companies it could use Home Kit. You could just have it attached to your,

1434
01:20:06,920 --> 01:20:10,730
Speaker 5:  your local storage and not have to have any kind of cloud at all. Which is,

1435
01:20:10,730 --> 01:20:14,340
Speaker 5:  as someone who loves a server, I'm a huge fan,

1436
01:20:14,340 --> 01:20:18,040
Speaker 5:  but it just like, you still have to, there's still security. You still have

1437
01:20:18,040 --> 01:20:21,010
Speaker 5:  to think about these things. There's still ways to hack this stuff and Yeah,

1438
01:20:21,010 --> 01:20:24,880
Speaker 4:  By typing the address of the camera into VLC and accessing

1439
01:20:24,880 --> 01:20:28,850
Speaker 4:  an unencrypted stream. Perfect. Beautiful. I saw a TikTok

1440
01:20:28,850 --> 01:20:31,280
Speaker 4:  of somebody just like talking to their Plex server the other day. I forgot

1441
01:20:31,280 --> 01:20:35,040
Speaker 4:  to send it to you, but now this is because of our relationship here. Yeah.

1442
01:20:35,040 --> 01:20:38,230
Speaker 4:  TikTok is like, we need to start showing him Plex content.

1443
01:20:38,230 --> 01:20:39,880
Speaker 5:  I I'm so happy for you.

1444
01:20:39,880 --> 01:20:42,210
Speaker 6:  Kranz, do you have a Mastodon server?

1445
01:20:42,210 --> 01:20:42,590
Speaker 4:  No,

1446
01:20:42,590 --> 01:20:46,440
Speaker 5:  I was looking into putting one on my s sonology or like my S Sonology server.

1447
01:20:46,440 --> 01:20:50,400
Speaker 5:  That's what I use. And then I like read about three

1448
01:20:50,400 --> 01:20:54,260
Speaker 5:  lines into how to create a Macon server

1449
01:20:54,260 --> 01:20:56,250
Speaker 5:  and that was the end.

1450
01:20:56,250 --> 01:20:59,720
Speaker 6:  So as a lover of servers, you can't even get behind Mastodon. So I think

1451
01:20:59,720 --> 01:21:01,560
Speaker 6:  Macon's, domed we can on

1452
01:21:01,560 --> 01:21:02,920
Speaker 5:  That. It's dimmed guys go to Disor.

1453
01:21:02,920 --> 01:21:06,480
Speaker 4:  No, Macon is gonna be, what's going to happen to Macon is gonna be

1454
01:21:06,480 --> 01:21:10,400
Speaker 4:  incredible. Someone is gonna centralize a Macon instance and

1455
01:21:10,400 --> 01:21:13,720
Speaker 4:  that's gonna become the service and everyone else, they're gonna have like

1456
01:21:13,720 --> 01:21:17,600
Speaker 4:  fake interoperability with other MA on servers. But everyone's

1457
01:21:17,600 --> 01:21:20,920
Speaker 4:  gonna join Twitter clone.com, you know who it is, which is

1458
01:21:20,920 --> 01:21:24,680
Speaker 4:  Macedon and then it's gonna have all the same problems as

1459
01:21:24,680 --> 01:21:28,480
Speaker 5:  You know who it is. Who's that? It's all full circle. So this

1460
01:21:28,480 --> 01:21:32,320
Speaker 5:  little company has so small social media company we've never talked

1461
01:21:32,320 --> 01:21:35,520
Speaker 5:  about on this show before. I definitely have never talked about, has announced

1462
01:21:35,520 --> 01:21:39,280
Speaker 5:  that they're gonna support Mastodon instances. So you'll be able to log in

1463
01:21:39,280 --> 01:21:41,680
Speaker 5:  with your Tumblr account a Mastodon.

1464
01:21:41,680 --> 01:21:42,640
Speaker 4:  That's pretty good. It's

1465
01:21:42,640 --> 01:21:45,190
Speaker 5:  Gonna be Tumblr. Just, just embrace it guys. I'm sorry.

1466
01:21:45,190 --> 01:21:48,960
Speaker 4:  I feel like Matt Mullen like who's the CEO of Automatic, which owns WordPress

1467
01:21:48,960 --> 01:21:52,680
Speaker 4:  and Tumblr. Yeah, I think he sends this blood in the water.

1468
01:21:52,680 --> 01:21:53,140
Speaker 6:  Yeah,

1469
01:21:53,140 --> 01:21:56,720
Speaker 4:  You have the feeling. He's like, oh, I went through this app store review

1470
01:21:56,720 --> 01:21:59,320
Speaker 4:  shit with with Tumblr. Like you can't hurt

1471
01:21:59,320 --> 01:22:03,160
Speaker 5:  Me. He bought that for, how much money did Yahoo lose when they sold it to

1472
01:22:03,160 --> 01:22:03,280
Speaker 5:  him?

1473
01:22:03,280 --> 01:22:06,810
Speaker 4:  It was like 80 billion. It was crazy. It was like the full amount. Yeah.

1474
01:22:06,810 --> 01:22:07,230
Speaker 5:  So

1475
01:22:07,230 --> 01:22:10,600
Speaker 6:  Well this is, this is Yahoo loves to do this. I don't think they've ever

1476
01:22:10,600 --> 01:22:12,000
Speaker 6:  made money on anything. So

1477
01:22:12,000 --> 01:22:13,790
Speaker 5:  Automatic is gonna make some money.

1478
01:22:13,790 --> 01:22:14,710
Speaker 6:  Yeah,

1479
01:22:14,710 --> 01:22:18,360
Speaker 4:  98.1% loss. Yeah, they bought it sounds right.

1480
01:22:18,360 --> 01:22:22,120
Speaker 4:  They bought it for 1.1 million and they sold it

1481
01:22:22,120 --> 01:22:25,470
Speaker 4:  for 20 million. A well below 20 million.

1482
01:22:25,470 --> 01:22:28,400
Speaker 6:  That was a Marissa Mayor special I think. Yeah,

1483
01:22:28,400 --> 01:22:28,520
Speaker 5:  It

1484
01:22:28,520 --> 01:22:32,400
Speaker 4:  Was. It was, yeah. Yeah. One hair strategy was buying every app to get

1485
01:22:32,400 --> 01:22:32,920
Speaker 4:  talent in the

1486
01:22:32,920 --> 01:22:34,640
Speaker 5:  Door in between Zamboni drives.

1487
01:22:34,640 --> 01:22:37,930
Speaker 4:  Actually neither of you know this story. When we first started The Verge,

1488
01:22:37,930 --> 01:22:41,800
Speaker 4:  we had this like horrible office in New York City and fifth Avenue. It

1489
01:22:41,800 --> 01:22:45,680
Speaker 4:  was small. I, I feel very fondly for it, but objectively it was like crap.

1490
01:22:45,680 --> 01:22:47,890
Speaker 5:  Didn't you guys do the Verge cast in like a closet?

1491
01:23:23,880 --> 01:23:27,240
Speaker 5:  Last one, I'm just gonna tease the fact that we're working on this review.

1492
01:23:27,240 --> 01:23:30,840
Speaker 5:  The Oceanic Plus app for the Apple Watch Ultra is now out for

1493
01:23:30,840 --> 01:23:32,200
Speaker 5:  our scuba divers in the audience.

1494
01:23:32,200 --> 01:23:36,080
Speaker 4:  I'm only bringing this up because I, what I've heard about our Apple Watch

1495
01:23:36,080 --> 01:23:37,400
Speaker 4:  Ultra Review video, it's

1496
01:23:37,400 --> 01:23:38,030
Speaker 5:  Gonna win an Oscar.

1497
01:23:38,030 --> 01:23:41,520
Speaker 4:  It's, I mean this is the highest budget thing. This a Marvel movie at this

1498
01:23:41,520 --> 01:23:44,910
Speaker 4:  point. Full billion dollar avatar Stand back

1499
01:23:44,910 --> 01:23:47,920
Speaker 4:  verges Apple Watch Ultra Review is coming. We're gonna, we're gonna throw

1500
01:23:47,920 --> 01:23:49,310
Speaker 4:  it out of an airplane.

1501
01:23:49,310 --> 01:23:52,510
Speaker 6:  I was gonna say, did we do any skydiving for this one?

1502
01:23:52,510 --> 01:23:56,240
Speaker 4:  I, there's, there's, I know that there's an attempt to crash a car. I don't

1503
01:23:56,240 --> 01:23:57,850
Speaker 4:  know if actually happened.

1504
01:23:57,850 --> 01:23:58,540
Speaker 6:  Oh,

1505
01:23:58,540 --> 01:24:01,400
Speaker 4:  And now we're trying to dive with it, so it's gonna be stunning. We were

1506
01:24:01,400 --> 01:24:05,320
Speaker 4:  waiting for this, but that review is coming and we'll see. We'll

1507
01:24:05,320 --> 01:24:08,320
Speaker 4:  see if, we'll see if the dive button does everything that we ever hoped it

1508
01:24:08,320 --> 01:24:08,750
Speaker 4:  would do.

1509
01:24:08,750 --> 01:24:11,520
Speaker 5:  V and Becca have been working really hard on it sounds like it's gonna be

1510
01:24:11,520 --> 01:24:12,150
Speaker 5:  a lot of fun.

1511
01:24:12,150 --> 01:24:15,680
Speaker 4:  Yeah, it does. I mean, again, we've just been, every time I hear about it

1512
01:24:15,680 --> 01:24:17,920
Speaker 4:  I'm like, huh, that's a new problem that we have

1513
01:24:17,920 --> 01:24:21,800
Speaker 6:  To like, we need a 2003 Ford Fiat that we can

1514
01:24:21,800 --> 01:24:22,520
Speaker 6:  just destroy.

1515
01:24:22,520 --> 01:24:25,440
Speaker 5:  Does anyone have an oxygen tank? Who Scuba

1516
01:24:25,440 --> 01:24:29,040
Speaker 4:  Certified the company can sign this insurance waiver. And I'm like, I don't

1517
01:24:29,040 --> 01:24:31,800
Speaker 4:  think any of them are gonna do that actually. Like we might have to hire

1518
01:24:31,800 --> 01:24:33,690
Speaker 4:  a new lawyer and lie to them

1519
01:24:33,690 --> 01:24:36,680
Speaker 6:  To pull. Yeah, just pull, just pull an E on and have them self

1520
01:24:36,680 --> 01:24:40,270
Speaker 4:  Certified. That's great.

1521
01:24:40,270 --> 01:24:44,000
Speaker 4:  Last thing, just, this is a very funny headline. Kanu has

1522
01:24:44,000 --> 01:24:47,400
Speaker 4:  repurposed its electric pickup truck for the army. I encourage you to go

1523
01:24:47,400 --> 01:24:50,760
Speaker 4:  look at the canoe pickup truck. It's adorable. And then try to imagine this

1524
01:24:50,760 --> 01:24:52,910
Speaker 4:  thing as a weapon of war.

1525
01:24:52,910 --> 01:24:53,520
Speaker 11:  That's

1526
01:24:53,520 --> 01:24:57,280
Speaker 4:  A very, it's very good. It's a very good idea. Fully.

1527
01:24:57,280 --> 01:25:01,240
Speaker 4:  That's it. That's V cast. We back, we, we've got grand plans

1528
01:25:01,240 --> 01:25:04,000
Speaker 4:  in David's absence. He was the one who really kept this thing on the rails

1529
01:25:04,000 --> 01:25:07,630
Speaker 4:  and as you can tell, even with two hours notice,

1530
01:25:07,630 --> 01:25:11,540
Speaker 4:  it's already going sideways. But tweeted him. Tom, congratulations.

1531
01:25:11,540 --> 01:25:15,240
Speaker 4:  You can tweet at us. I met Reckless. Alex is Alex h Kranz.

1532
01:25:15,240 --> 01:25:18,760
Speaker 4:  Heath is Alex E. Heath. Very confusing. You two. You both. We

1533
01:25:18,760 --> 01:25:22,040
Speaker 5:  Like to use our, our middle names. Good job.

1534
01:25:22,040 --> 01:25:25,400
Speaker 4:  We're back on Wednesday. Actually, this is like the last episode David did

1535
01:25:25,400 --> 01:25:28,960
Speaker 4:  before he took off. David and Alex are gonna talk about 15 years of the

1536
01:25:28,960 --> 01:25:32,880
Speaker 4:  Kindle. Yeah, Russell Brandon is gonna join us. He did a big project with

1537
01:25:32,880 --> 01:25:36,680
Speaker 4:  Consumer Reports, mapping out broadband. That's really cool. Last thing

1538
01:25:36,680 --> 01:25:40,400
Speaker 4:  we're working on our end of year wrap ups. Call into our hotline.

1539
01:25:40,400 --> 01:25:43,600
Speaker 4:  Eight six six Verge

1540
01:25:43,600 --> 01:25:47,480
Speaker 4:  11. 8 6 6 8. 3 7, 4 3,

1541
01:25:47,480 --> 01:25:51,240
Speaker 4:  1, 1. Tell us who you think your winners and losers of

1542
01:25:51,240 --> 01:25:54,120
Speaker 4:  2022 are. Here's a challenge show. You can't pick meta for either one. Oh,

1543
01:25:54,120 --> 01:25:54,280
Speaker 4:  that's rough. Yeah, it's, it's tough.

1544
01:25:54,280 --> 01:25:55,630
Speaker 5:  Can you put Elon,

1545
01:25:55,630 --> 01:25:59,520
Speaker 4:  I the people are gonna call, alright, Vox pop vox day

1546
01:25:59,520 --> 01:25:59,960
Speaker 4:  or

1547
01:25:59,960 --> 01:26:02,970
Speaker 11:  Whatever

1548
01:26:02,970 --> 01:26:06,760
Speaker 4:  To let the people speak. Call the number. Eight,

1549
01:26:06,760 --> 01:26:10,250
Speaker 4:  six, six Verge

1550
01:26:10,250 --> 01:26:13,800
Speaker 4:  1-866-837-FOUR 3 1 1. Winners and losers of 2022. But you

1551
01:26:13,800 --> 01:26:16,680
Speaker 4:  can't pick meta. All right. That's tough. I would've to think about that

1552
01:26:16,680 --> 01:26:18,800
Speaker 4:  for a while, but call the number and we'll, we'll, we'll let you know What

1553
01:26:18,800 --> 01:26:19,520
Speaker 4:  people say.

1554
01:26:19,520 --> 01:26:20,200
Speaker 1:  Sbs both

1555
01:26:20,200 --> 01:26:24,040
Speaker 4:  Sides. That's truly the highs and

1556
01:26:24,040 --> 01:26:25,680
Speaker 4:  lows. All right. That's it. That's V

1557
01:26:25,680 --> 01:26:30,180
Speaker 4:  Cast

1558
01:26:30,180 --> 01:26:34,040
Speaker 1:  And that's a wrap for Vergecast this week. Thanks for listening. If you enjoy

1559
01:26:34,040 --> 01:26:37,640
Speaker 1:  the show, subscribe in the podcast app of your choice or tell a friend, you

1560
01:26:37,640 --> 01:26:41,520
Speaker 1:  can send us feedback at vergecast@theverge.com. This show is produced

1561
01:26:41,520 --> 01:26:45,120
Speaker 1:  by me, Liam James, and our senior audio director, Andrew Marino.

1562
01:26:45,120 --> 01:26:48,880
Speaker 1:  This episode was edited and mixed by Amanda Rose

1563
01:26:48,880 --> 01:26:52,720
Speaker 1:  Smith. Our editorial director is Brooke Miners and our executive producer

1564
01:26:52,720 --> 01:26:56,640
Speaker 1:  is Eleanor Donovan. The Verge Cast is a production of the Verge and Box

1565
01:26:56,640 --> 01:26:59,120
Speaker 1:  Media podcast network. And that's it. We'll see you next

1566
01:26:59,120 --> 01:27:03,740
Speaker 1:  week.

