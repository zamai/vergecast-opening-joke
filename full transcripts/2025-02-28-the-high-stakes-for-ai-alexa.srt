1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 726210cd-7462-445b-b951-7718e69840f6
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/2952958397474485805/8884620625306920806/s93290-US-6933s-1740963673.mp3
Description: AI will fix everything, right? In this episode, friend of The Verge (and Waveform co-host) David Imel joins Nilay and David to talk all about Alexa Plus, and the AI-powered voice assistant Amazon thinks can do everything from turn on your lights to order your friend an Uber. The hosts also talk about the other gadgets of the week, from the wild new Sigma BF camera to the boring iPhone 16E. Finally, in the lightning round, they talk about TikTok becoming YouTube and YouTube becoming TikTok and Instagram becoming YouTube and TikTok, plus the latest in Brendan Carr being a dummy and what's coming next from Automattic, DOGE, and everything.

2
00:00:32,465 --> 00:00:35,535
Speaker 4:  Hello and welcome to Our Chest, the flagship podcast with being free with

3
00:00:35,535 --> 00:00:35,775
Speaker 4:  Prime.

4
00:00:37,635 --> 00:00:41,615
Speaker 4:  Who knows? Maybe it's, maybe it's $20, maybe it's Prime is $15 and this

5
00:00:41,615 --> 00:00:42,255
Speaker 4:  comes for the Ride.

6
00:00:42,525 --> 00:00:45,855
Speaker 5:  That one feels slightly too plausible to me and I I don't like it.

7
00:00:46,015 --> 00:00:46,855
Speaker 4:  That, that We're free with Prime.

8
00:00:46,865 --> 00:00:49,135
Speaker 5:  We're free with Prime. Like we might be, I honestly

9
00:00:49,135 --> 00:00:50,975
Speaker 4:  Don't know at, at the rate we're going What's,

10
00:00:50,975 --> 00:00:52,415
Speaker 5:  What is free with Prime? Yeah.

11
00:00:52,555 --> 00:00:56,495
Speaker 4:  Bundle us in. Jeff. We support Free markets on the,

12
00:00:57,085 --> 00:00:59,775
Speaker 4:  there's a lot to talk about this week. An awful lot to talk about. I'm your

13
00:00:59,775 --> 00:01:03,085
Speaker 4:  friend Neil David Pierce is here. Hello. And I've got a guest in studio.

14
00:01:03,085 --> 00:01:06,285
Speaker 4:  David Amel, the co-host of the Waveform podcast is joining me today.

15
00:01:06,375 --> 00:01:07,445
Speaker 5:  How's it going? It's

16
00:01:07,445 --> 00:01:10,085
Speaker 4:  Good here. It's good. I just like, I just want more human beings physically

17
00:01:10,395 --> 00:01:11,325
Speaker 4:  present with me.

18
00:01:11,325 --> 00:01:12,365
Speaker 5:  Understandable. And Pierce

19
00:01:12,695 --> 00:01:14,285
Speaker 4:  Won't say yes to that idea.

20
00:01:14,735 --> 00:01:17,045
Speaker 5:  We're, we're legally not allowed to be in the same

21
00:01:17,045 --> 00:01:18,485
Speaker 4:  Room. He, you need to stay in your green screen basically.

22
00:01:18,505 --> 00:01:22,365
Speaker 5:  No, it's like, you know how they like won't put the whole group

23
00:01:22,465 --> 00:01:25,405
Speaker 5:  on a plane, like just in case something happens like you and I can't be in

24
00:01:25,405 --> 00:01:29,125
Speaker 5:  the same room just in case we have to be several hundred miles away

25
00:01:29,125 --> 00:01:29,685
Speaker 5:  because the end

26
00:01:29,875 --> 00:01:31,805
Speaker 4:  This, this isn't the right time in America for plane jokes, David.

27
00:01:33,485 --> 00:01:36,605
Speaker 4:  I was just on a flight and it landed and everybody burst into applause. And

28
00:01:36,605 --> 00:01:39,925
Speaker 4:  that is a, you wanna, it's, it's a real thing. You wanna temp check on the

29
00:01:39,925 --> 00:01:43,765
Speaker 4:  country. Yeah. It's the amount of clapping when planes land is, is going

30
00:01:43,765 --> 00:01:43,965
Speaker 4:  up.

31
00:01:44,365 --> 00:01:47,885
Speaker 5:  I got a new plane story in Slack every single time I arrived at the airport

32
00:01:48,365 --> 00:01:50,405
Speaker 5:  and I had to remind everyone, I'm now at the airport,

33
00:01:52,185 --> 00:01:55,125
Speaker 4:  So going on. All right. A lot happened this week.

34
00:01:55,355 --> 00:01:57,965
Speaker 5:  Wait, first Neli, you have to tell us where you went on vacation because

35
00:01:58,225 --> 00:02:00,325
Speaker 5:  as always happens when you go on vacation,

36
00:02:01,835 --> 00:02:05,525
Speaker 5:  some single digit but not insignificant percentage of The

37
00:02:05,645 --> 00:02:08,645
Speaker 5:  Vergecast audience believes that you have quit your job and we'll never ever

38
00:02:08,645 --> 00:02:12,285
Speaker 5:  come back. So can we just, can we just tell the people

39
00:02:12,535 --> 00:02:15,885
Speaker 5:  about your vacation and that you have triumphantly returned?

40
00:02:16,985 --> 00:02:17,205
Speaker 4:  No.

41
00:02:17,555 --> 00:02:17,845
Speaker 5:  Okay.

42
00:02:18,625 --> 00:02:19,325
Speaker 4:  That's the answer

43
00:02:19,465 --> 00:02:20,605
Speaker 5:  Is neli back. Who knows?

44
00:02:21,125 --> 00:02:23,605
Speaker 4:  I think it's, you want to be at a place in your life where people are like,

45
00:02:23,605 --> 00:02:27,525
Speaker 4:  there's a secret furious plot to defend Aate you every time you take a a

46
00:02:27,525 --> 00:02:27,645
Speaker 4:  break.

47
00:02:27,805 --> 00:02:30,765
Speaker 5:  I, I literally got an email last week that was like, well, NELI seems like

48
00:02:30,765 --> 00:02:33,965
Speaker 5:  he's about to retire. And then they just sort of went on with the rest of

49
00:02:33,965 --> 00:02:35,165
Speaker 5:  their question. I was like, hold on,

50
00:02:36,805 --> 00:02:40,765
Speaker 4:  I might be, you never know. No, we went to Turks and Caicos. It was,

51
00:02:42,315 --> 00:02:45,845
Speaker 4:  it's like Max's winter break. So we went to the beach and we sat on island

52
00:02:45,945 --> 00:02:49,725
Speaker 4:  and then everyone else on that island at that beach was also from

53
00:02:49,985 --> 00:02:53,845
Speaker 4:  New York, which is the whole state is on winter break. So all

54
00:02:53,845 --> 00:02:57,285
Speaker 4:  of the children of New York were on this one small British island.

55
00:02:58,305 --> 00:03:01,365
Speaker 4:  It was great. We caught a, we, we dove for a cog shell, but we did the whole

56
00:03:01,365 --> 00:03:01,885
Speaker 4:  thing. It was just

57
00:03:01,885 --> 00:03:03,885
Speaker 5:  A lot of like little kids going, I'm walking here

58
00:03:04,595 --> 00:03:05,205
Speaker 4:  Basically

59
00:03:05,585 --> 00:03:06,445
Speaker 6:  On the beach. Love

60
00:03:06,445 --> 00:03:09,605
Speaker 4:  That. Basically Max made a bunch of friends. It was delight. My phone service

61
00:03:09,705 --> 00:03:13,605
Speaker 4:  was bad, which was important. Perfect. This is a thing I look for Yeah. In

62
00:03:13,605 --> 00:03:17,325
Speaker 4:  destinations now is it was at t's roaming agreement. Not quite as

63
00:03:17,325 --> 00:03:19,725
Speaker 4:  rock solid as it should be. Yeah, that's where we're going.

64
00:03:20,285 --> 00:03:24,245
Speaker 6:  I use the satellite texting feature on the iPhone quite a bit in the

65
00:03:24,245 --> 00:03:25,245
Speaker 6:  last few months. That's

66
00:03:25,245 --> 00:03:25,765
Speaker 4:  Not great, man.

67
00:03:25,995 --> 00:03:29,765
Speaker 6:  Well, yeah, it's, it's great to not have the service. It is

68
00:03:29,765 --> 00:03:33,445
Speaker 6:  surprising that it works at all. Yeah, but you know, I, it, I'm probably

69
00:03:33,555 --> 00:03:37,485
Speaker 6:  Apple's like perfect boy for that because no one has ever used

70
00:03:37,485 --> 00:03:38,365
Speaker 6:  it except for me. So

71
00:03:38,795 --> 00:03:42,645
Speaker 4:  Have you seen the conspiracy theories? They, they launched the trial of

72
00:03:42,645 --> 00:03:46,325
Speaker 4:  letting T-Mobile iPhones connect to starlink. So now there are

73
00:03:46,325 --> 00:03:49,565
Speaker 4:  conspiracy theories online that Elon Musk is spying on you on your iPhone.

74
00:03:49,985 --> 00:03:50,205
Speaker 4:  But

75
00:03:50,315 --> 00:03:54,005
Speaker 6:  Yeah, I don't, I don't have Google Fi, you know, so I'm just using the baseline

76
00:03:54,095 --> 00:03:57,685
Speaker 6:  Apple free feature probably has nothing to do with Elon, but

77
00:03:57,705 --> 00:03:59,165
Speaker 4:  That's very good. Yeah. Does

78
00:03:59,165 --> 00:04:00,365
Speaker 6:  It work well? Oh, it well.

79
00:04:00,645 --> 00:04:03,405
Speaker 4:  Hmm. Is it RCS? Is it SMS? Is it I what? What's the story?

80
00:04:03,435 --> 00:04:07,045
Speaker 6:  Well, it only works with iMessage. Okay. Of course. Which is very dumb.

81
00:04:07,235 --> 00:04:11,005
Speaker 6:  Extremely dumb. But it works fine. They have,

82
00:04:11,005 --> 00:04:14,205
Speaker 4:  Wait, so if you're like in an emergency and you need to text somebody with

83
00:04:14,205 --> 00:04:17,685
Speaker 4:  an Android phone, it's like, sorry, you're a green bubble, you're gonna die.

84
00:04:17,745 --> 00:04:21,445
Speaker 6:  That's a great question. I think in the emergency SOS

85
00:04:21,715 --> 00:04:24,925
Speaker 6:  like version of it, it will send an SMS and it will ping off of that satellite.

86
00:04:24,925 --> 00:04:28,565
Speaker 6:  I got you. But there are much, there are not that many satellites, right.

87
00:04:28,565 --> 00:04:32,045
Speaker 6:  That they're actually using because they just go over pretty quickly. Yeah.

88
00:04:32,145 --> 00:04:35,725
Speaker 6:  So you have to wait a few minutes every time, like every five minutes it

89
00:04:35,725 --> 00:04:38,605
Speaker 6:  just goes over the hill and you have to wait another five minutes and then

90
00:04:38,605 --> 00:04:42,165
Speaker 6:  you can connect to it again. Yeah. And then if you're in a car, even ha it

91
00:04:42,165 --> 00:04:45,805
Speaker 6:  has like a glass roof or something. Or if there is one single tree, you cannot,

92
00:04:46,285 --> 00:04:49,805
Speaker 6:  you cannot text via satellite. So it, it works. And

93
00:04:50,165 --> 00:04:53,525
Speaker 6:  I did need to use it in a semi-emergency where someone at home was having

94
00:04:53,605 --> 00:04:57,045
Speaker 6:  a problem and it was really great for me. Hey, that's great. Hashtag not

95
00:04:57,045 --> 00:04:58,485
Speaker 6:  sponsored. So Yeah,

96
00:04:59,265 --> 00:05:02,725
Speaker 4:  See it's spicy here on the, there you go. That's very cool.

97
00:05:03,605 --> 00:05:07,045
Speaker 4:  I just sign up for horrible roaming agreements and be like, my phone isn't

98
00:05:07,045 --> 00:05:09,965
Speaker 4:  working and then I'd stop thinking about the news for

99
00:05:09,965 --> 00:05:13,485
Speaker 6:  A week. Yeah. Roaming your arenas sound terrible. I've had Google Fi since

100
00:05:13,485 --> 00:05:17,445
Speaker 6:  like 2017 and it is overpriced when you live in

101
00:05:17,445 --> 00:05:21,085
Speaker 6:  the United States. But it is great when you have to think about nothing ever

102
00:05:21,185 --> 00:05:23,805
Speaker 6:  at all. Yeah. In other countries. But then Google

103
00:05:23,805 --> 00:05:26,565
Speaker 5:  Periodically forgets that you exist for several years at a

104
00:05:26,565 --> 00:05:27,925
Speaker 6:  Time. That's true. And you're like, can

105
00:05:28,125 --> 00:05:29,165
Speaker 5:  I have new features? Google

106
00:05:29,185 --> 00:05:32,605
Speaker 6:  And Google says, no, no. Yeah, we can have nothing. And then they just rebrand

107
00:05:32,605 --> 00:05:34,365
Speaker 6:  the name of the service and move on. Yeah,

108
00:05:34,585 --> 00:05:35,005
Speaker 4:  That's

109
00:05:35,005 --> 00:05:36,605
Speaker 6:  Pretty, don't give you any new features.

110
00:05:36,755 --> 00:05:37,525
Speaker 4:  That seems about right.

111
00:05:37,555 --> 00:05:37,845
Speaker 6:  Yeah.

112
00:05:38,715 --> 00:05:41,845
Speaker 4:  Lots talk about this week there was an Amazon Alexa event.

113
00:05:42,885 --> 00:05:45,175
Speaker 4:  They announced Alexa plus we should talk all about that

114
00:05:46,665 --> 00:05:50,015
Speaker 4:  Panas pane. Literally in the middle of the event while he was announcing

115
00:05:50,015 --> 00:05:52,975
Speaker 4:  Alexa Plus looked at me in the eye and said, Hey, how you doing? It's one

116
00:05:52,975 --> 00:05:56,375
Speaker 4:  of the weirdest and funniest moments at any event I've ever had in my entire

117
00:05:56,375 --> 00:06:00,325
Speaker 4:  life. Very good. Very panus. Only me by the way. That only

118
00:06:00,445 --> 00:06:02,725
Speaker 4:  happened once. And it was to me, he looked at me dead in the eye, said, Hey,

119
00:06:02,725 --> 00:06:06,645
Speaker 4:  how you doing? And I was like, Hey. And then he went on, he continued announcing

120
00:06:06,645 --> 00:06:09,405
Speaker 4:  Alexa plus go watch the video. He d you can see him do

121
00:06:09,405 --> 00:06:10,485
Speaker 6:  It. Did they put it up?

122
00:06:12,215 --> 00:06:13,675
Speaker 4:  It wasn't livestream. There's no videos. There wasn't a live

123
00:06:13,675 --> 00:06:16,155
Speaker 6:  Stream. Yeah. It was really painful for us when we were trying to cover this.

124
00:06:16,275 --> 00:06:18,555
Speaker 4:  I didn't realize, I just said go watch video. 'cause I just assume everything

125
00:06:18,555 --> 00:06:19,955
Speaker 4:  is available. But I don't think they, oh

126
00:06:19,955 --> 00:06:23,235
Speaker 5:  No. Well and I think Panos at one point at the beginning of the event said

127
00:06:23,505 --> 00:06:26,275
Speaker 5:  like, welcome to everybody watching from home. And I was like, well

128
00:06:27,535 --> 00:06:30,155
Speaker 5:  my guy You are used to Microsoft events. Yeah, yeah.

129
00:06:30,535 --> 00:06:32,435
Speaker 6:  We just let read your live blog and I,

130
00:06:32,535 --> 00:06:35,515
Speaker 4:  All right, well I might be lying about Panos Fane looking me dead in the

131
00:06:35,515 --> 00:06:38,555
Speaker 4:  eye in the middle of his presentation and saying, Hey, how are you doing?

132
00:06:38,695 --> 00:06:40,035
Speaker 4:  But I promise you it happened.

133
00:06:40,035 --> 00:06:41,955
Speaker 6:  There are like 20 people that can confirm that. Yeah,

134
00:06:42,715 --> 00:06:46,275
Speaker 4:  Apple announced a very boring iPhone, which we will talk about for a very

135
00:06:46,275 --> 00:06:49,035
Speaker 4:  boring amount of time. A very appropriate amount time. But it'll be exciting.

136
00:06:49,135 --> 00:06:51,755
Speaker 4:  That's what I meant to say. I don't know about that. There's a Sigma camera

137
00:06:52,185 --> 00:06:56,075
Speaker 4:  that David, I need to yell about at length. There's some framework stuff.

138
00:06:56,075 --> 00:06:59,595
Speaker 4:  We got a lightning round. Brendan Carr. I'm back from vacation buddy.

139
00:07:00,765 --> 00:07:04,345
Speaker 4:  I didn't forget about you. It's got it's packed show. Let's start with Alexa.

140
00:07:05,925 --> 00:07:09,545
Speaker 4:  The, it's what we expected. I will tell you Ponos is on

141
00:07:09,695 --> 00:07:12,865
Speaker 4:  decoder on Monday. So I've talked to him at length about this. And what I

142
00:07:12,865 --> 00:07:15,985
Speaker 4:  mean by what we expected is everybody saw chat, GBT

143
00:07:16,645 --> 00:07:20,585
Speaker 4:  or LLMs in general and they thought, boy, this is how the, these

144
00:07:20,585 --> 00:07:23,945
Speaker 4:  voice assistants should have worked this whole time. And now they announced

145
00:07:23,985 --> 00:07:26,865
Speaker 4:  a version Alexa that approximates that. Yeah.

146
00:07:27,015 --> 00:07:30,705
Speaker 6:  Well notably none of the assistants for the home have had it yet.

147
00:07:30,895 --> 00:07:33,545
Speaker 6:  Yeah. So it's actually a big deal that they're finally bringing it to something.

148
00:07:34,045 --> 00:07:34,785
Speaker 4:  It is a big deal.

149
00:07:36,745 --> 00:07:39,905
Speaker 4:  I think the most important thing to note here is

150
00:07:41,115 --> 00:07:44,525
Speaker 4:  outside of phones, Alexa has the biggest user

151
00:07:45,115 --> 00:07:48,965
Speaker 4:  base installed base of devices that have AI now,

152
00:07:50,155 --> 00:07:54,025
Speaker 4:  which is just nothing else has gotten there. Yeah. Like Google

153
00:07:54,205 --> 00:07:58,185
Speaker 4:  has sort of rolled out some stuff to some bits and bobs of phone

154
00:07:58,185 --> 00:08:01,425
Speaker 4:  apps. Yeah. But like Google home devices do not have Gemini.

155
00:08:02,485 --> 00:08:02,775
Speaker 6:  True

156
00:08:02,905 --> 00:08:05,735
Speaker 4:  Apple Home pods. They have Siri, which, which

157
00:08:06,125 --> 00:08:06,415
Speaker 6:  It's

158
00:08:06,635 --> 00:08:10,175
Speaker 4:  Not a thing. Yeah. There is the humane pin.

159
00:08:12,085 --> 00:08:13,495
Speaker 4:  Dear sweet humane pin

160
00:08:13,715 --> 00:08:16,255
Speaker 6:  Humane. Yeah. HP stands for humane pin. By the way,

161
00:08:16,635 --> 00:08:19,815
Speaker 5:  My, my close personal friend, my dead humane pin

162
00:08:20,525 --> 00:08:24,295
Speaker 4:  Pice did not know that the humane pin had been canceled. When I said, I was

163
00:08:24,295 --> 00:08:27,855
Speaker 4:  like, you got the big installed base and you know, it's not like you were

164
00:08:27,935 --> 00:08:30,255
Speaker 4:  sweating the humane pin. He is like, well they're part of HP now. And I was

165
00:08:30,255 --> 00:08:32,175
Speaker 4:  like, no, they're not. And that was the end of that.

166
00:08:34,195 --> 00:08:38,095
Speaker 4:  But like that the, the idea was that voice

167
00:08:38,095 --> 00:08:41,055
Speaker 4:  assistance would be this big platform shift. We'd create a new generation

168
00:08:41,055 --> 00:08:43,935
Speaker 4:  devices that would take over the phone that has absolutely not played out.

169
00:08:43,965 --> 00:08:47,325
Speaker 4:  Yeah. But there's a lot of echo devices out there.

170
00:08:48,275 --> 00:08:51,655
Speaker 4:  And so this is kind of a big deal. Like just from that standpoint, I

171
00:08:51,655 --> 00:08:55,325
Speaker 5:  Think it hasn't played out, actually doesn't give these things

172
00:08:55,495 --> 00:08:59,285
Speaker 5:  quite enough. Credit people use Alexa a

173
00:08:59,305 --> 00:09:03,205
Speaker 5:  lot. Like, like a lot. It's, it's a running joke that

174
00:09:03,205 --> 00:09:06,845
Speaker 5:  people use it for, you know, music and timers and their lights.

175
00:09:06,985 --> 00:09:10,975
Speaker 5:  And it's largely true, but like the, the idea that

176
00:09:10,975 --> 00:09:14,775
Speaker 5:  people would interact with technology in a different and

177
00:09:14,775 --> 00:09:18,735
Speaker 5:  voice first way like happened it, it came to pass. It is a

178
00:09:18,735 --> 00:09:22,495
Speaker 5:  fully mainstream device and interaction method now.

179
00:09:22,795 --> 00:09:26,575
Speaker 5:  And that's some combination of I think what Apple

180
00:09:26,635 --> 00:09:30,575
Speaker 5:  did with Siri early on and then Google Assistant and Alexa.

181
00:09:30,675 --> 00:09:34,495
Speaker 5:  But I think especially as you talk about like standalone, I talk

182
00:09:34,515 --> 00:09:38,455
Speaker 5:  to my house, things like that happened. It worked. We, we can, we can

183
00:09:38,455 --> 00:09:41,295
Speaker 5:  argue for days about how useful it is and I think the answer is it's not

184
00:09:41,295 --> 00:09:45,255
Speaker 5:  that useful. But like it, it worked at like Amazon did the thing

185
00:09:45,555 --> 00:09:49,375
Speaker 5:  and now the question is like, can we take this behavior

186
00:09:49,375 --> 00:09:53,135
Speaker 5:  that we've trained people and point it at something? Yeah. And I think

187
00:09:53,165 --> 00:09:55,855
Speaker 5:  that is the open question and that is what Alexa Plus is trying to be. It's

188
00:09:55,855 --> 00:09:58,215
Speaker 5:  like, okay, we've now taught you that it's possible to talk to your technology.

189
00:09:58,515 --> 00:10:02,215
Speaker 5:  Now we have to give you things to do with it. And that was always gonna be

190
00:10:02,215 --> 00:10:05,655
Speaker 5:  the hard part and remains the hard part. And I have 1000 questions about

191
00:10:05,655 --> 00:10:09,495
Speaker 5:  what Amazon is trying to do here. But like I, I think it did come to pass

192
00:10:09,675 --> 00:10:12,575
Speaker 5:  in a real way, and this is like the opportunity that Amazon has where they're

193
00:10:12,575 --> 00:10:14,495
Speaker 5:  like, there are a lot of people who are used to talking to their devices

194
00:10:14,555 --> 00:10:16,495
Speaker 5:  now we have to give them something to do with it.

195
00:10:16,805 --> 00:10:19,815
Speaker 4:  Yeah. And that's what I mean by it's, well I don't mean to diminish it by

196
00:10:19,815 --> 00:10:23,455
Speaker 4:  saying it's as expected. What I mean to say is they put out

197
00:10:23,455 --> 00:10:26,615
Speaker 4:  commercials at the Super Bowl with celebrities in them talking to their Alexas.

198
00:10:26,745 --> 00:10:30,695
Speaker 4:  Right. And then people tried to do that and it didn't work because the classic

199
00:10:30,845 --> 00:10:34,695
Speaker 4:  because, and I think at the event a bunch of Amazon executives

200
00:10:34,695 --> 00:10:38,615
Speaker 4:  called it Alexa speak, where you trained yourself to talk to the

201
00:10:38,705 --> 00:10:42,535
Speaker 4:  Alexa or the Google Home or whatever it was in like Robot voice. Yep.

202
00:10:42,675 --> 00:10:45,895
Speaker 4:  And like give it ordered commands. Yeah. Because it's just a computer at

203
00:10:45,895 --> 00:10:49,815
Speaker 4:  the end of the day and it needs like structured commands. And now it's like,

204
00:10:50,075 --> 00:10:53,775
Speaker 4:  oh because there's an LOM, because there's some AI

205
00:10:53,775 --> 00:10:57,615
Speaker 4:  natural language input, you can just talk to it and then also

206
00:10:57,635 --> 00:11:01,255
Speaker 4:  it can figure out what you want and talk back to you naturally. And now you're

207
00:11:01,255 --> 00:11:04,015
Speaker 4:  in this conversation with this thing that can like maybe do stuff. And so

208
00:11:04,015 --> 00:11:07,935
Speaker 4:  that's like the big idea of Alexa plus is like total reboot

209
00:11:07,935 --> 00:11:08,375
Speaker 4:  of Alexa

210
00:11:10,045 --> 00:11:13,615
Speaker 4:  with not one, but like multiple AI models underneath it.

211
00:11:14,075 --> 00:11:17,895
Speaker 4:  The hard part as I understand it, was building the system

212
00:11:18,705 --> 00:11:22,515
Speaker 4:  that figures out what AI model to use when, because you don't wanna

213
00:11:22,515 --> 00:11:26,275
Speaker 4:  light up like all of anthropic to turn off your lights. Right.

214
00:11:27,135 --> 00:11:30,235
Speaker 4:  So like that, that was very much the hard part. That's what everyone is telling

215
00:11:30,235 --> 00:11:33,475
Speaker 4:  me is like they have all these different models they can use all these different

216
00:11:33,475 --> 00:11:37,435
Speaker 4:  ways they can do this stuff and they, they call it orchestration.

217
00:11:37,855 --> 00:11:40,915
Speaker 4:  So you issue it a command and then it figures out how to do it. And then

218
00:11:41,585 --> 00:11:44,915
Speaker 4:  they don't wanna call them apps. So they keep using this term experts.

219
00:11:46,185 --> 00:11:49,405
Speaker 4:  So it's like the photos expert will show you your photos and it's like what

220
00:11:49,405 --> 00:11:51,965
Speaker 4:  is what? And that is just an Amazon language.

221
00:11:52,195 --> 00:11:55,245
Speaker 5:  It's like an actual term of art in the AI community. Yeah. Like one of the

222
00:11:55,245 --> 00:11:58,005
Speaker 5:  things they call this problem is the mixture of experts problem. Yeah. Where

223
00:11:58,005 --> 00:12:00,445
Speaker 5:  it's like if we, if we turn on the whole system every time you have to do

224
00:12:00,645 --> 00:12:02,125
Speaker 5:  anything that's way too much work. No,

225
00:12:02,125 --> 00:12:05,325
Speaker 4:  No. That's the a this is what No, no, no, no, no. That's the AI community

226
00:12:05,385 --> 00:12:09,125
Speaker 4:  is using experts as a term of art in that way. Amazon

227
00:12:09,185 --> 00:12:13,165
Speaker 4:  is like when you ask it for photos, the photos expert

228
00:12:13,215 --> 00:12:13,845
Speaker 4:  shows you

229
00:12:13,845 --> 00:12:14,365
Speaker 5:  Photos. Oh right. No,

230
00:12:14,365 --> 00:12:16,765
Speaker 4:  I agree. It's like, and what they mean there is like, there's an app.

231
00:12:17,505 --> 00:12:20,445
Speaker 5:  It is absurd. Like don't get me wrong, it's like, it's like

232
00:12:21,085 --> 00:12:22,245
Speaker 4:  Everyone's just using words however they want.

233
00:12:22,245 --> 00:12:25,325
Speaker 5:  Yeah. Amazon tried to make skills happen and that didn't work and now they're

234
00:12:25,325 --> 00:12:25,565
Speaker 5:  trying to make

235
00:12:25,565 --> 00:12:27,885
Speaker 4:  Experts happen. I think. I think they wanted to not use skills again.

236
00:12:28,395 --> 00:12:30,045
Speaker 5:  Yeah. Because that went so poorly.

237
00:12:30,385 --> 00:12:31,845
Speaker 4:  So anyway, it's the

238
00:12:31,845 --> 00:12:35,815
Speaker 5:  Whole system. Although ironically skills is actually a better explanation

239
00:12:35,815 --> 00:12:39,495
Speaker 5:  of what Amazon is trying to do this time. Yeah. Last time it was just apps.

240
00:12:40,075 --> 00:12:41,295
Speaker 5:  Now it's actual skills.

241
00:12:42,485 --> 00:12:44,935
Speaker 6:  They can just keep calling it that because no one knew they were called that

242
00:12:44,935 --> 00:12:46,535
Speaker 6:  before. No. So it's fine, they

243
00:12:46,535 --> 00:12:50,335
Speaker 4:  Wanna make this break, but it's all, this is like very clever, right? You

244
00:12:50,335 --> 00:12:52,895
Speaker 4:  can just naturally speak to Alexa.

245
00:12:54,295 --> 00:12:57,965
Speaker 4:  Panos gave a bunch of demos on stage. Other people from Amazon gave a bunch

246
00:12:57,965 --> 00:13:01,845
Speaker 4:  of demos on stage at this event. They were all live. Importantly,

247
00:13:01,905 --> 00:13:04,725
Speaker 4:  he was only talking to echo show devices. So the

248
00:13:04,725 --> 00:13:08,645
Speaker 4:  8, 10, 15, 21 are getting this first, his point

249
00:13:08,645 --> 00:13:11,885
Speaker 4:  of view is that screens are important and you want a screen, he wants to

250
00:13:11,885 --> 00:13:15,085
Speaker 4:  put a screen in your house. And the big change

251
00:13:16,105 --> 00:13:20,045
Speaker 4:  for Amazon is Alexa used to be on everything. Like you buy

252
00:13:20,045 --> 00:13:21,645
Speaker 4:  a smoke detector with Alexa in it. Yeah,

253
00:13:21,805 --> 00:13:22,445
Speaker 6:  I remember that event.

254
00:13:23,305 --> 00:13:26,765
Speaker 4:  It was crazy. And now they're like, they're cutting down the product line.

255
00:13:26,765 --> 00:13:29,565
Speaker 4:  There is gonna be some new hardware eventually we are told.

256
00:13:30,665 --> 00:13:33,205
Speaker 4:  But they're cutting down the product line. They wanna put a screen in your

257
00:13:33,205 --> 00:13:35,565
Speaker 4:  house that's in the center of your living room or wherever your kitchen,

258
00:13:35,985 --> 00:13:39,725
Speaker 4:  you talk to it, it shows you stuff. You, you, you have a device

259
00:13:40,425 --> 00:13:43,965
Speaker 4:  and that is the centerpiece of their strategy. And then it, it is smart and

260
00:13:43,965 --> 00:13:47,845
Speaker 4:  it can do things, everything from tell your kids a story to, I think this

261
00:13:47,845 --> 00:13:50,005
Speaker 4:  is really fascinating. Like

262
00:13:51,315 --> 00:13:55,035
Speaker 4:  automatically great smart home routines for you. So you're like around

263
00:13:55,035 --> 00:13:58,155
Speaker 4:  bedtime, do bedtime stuff and it's like, okay, I'm gonna din the lights and

264
00:13:58,155 --> 00:14:00,395
Speaker 4:  play some music and turn on your security system and we'll just like come

265
00:14:00,395 --> 00:14:00,995
Speaker 4:  up with some ideas

266
00:14:01,585 --> 00:14:02,555
Speaker 6:  That will go right every time.

267
00:14:04,475 --> 00:14:08,155
Speaker 4:  I have a lot of questions about how that's gonna work. And then it has some,

268
00:14:09,315 --> 00:14:11,955
Speaker 4:  I don't wanna say age agentic 'cause there's a lot of ways for this to work,

269
00:14:11,975 --> 00:14:15,475
Speaker 4:  but it has some cap, it has some ability to do stuff out in the world.

270
00:14:16,055 --> 00:14:19,955
Speaker 4:  So you can have it book an Uber for your friend, which is a we

271
00:14:19,955 --> 00:14:22,915
Speaker 4:  can, we can pull apart that demo piece by piece. I would like. 'cause it

272
00:14:22,915 --> 00:14:23,435
Speaker 4:  was very complicated.

273
00:14:23,435 --> 00:14:24,035
Speaker 6:  Hello to Rabbit

274
00:14:24,495 --> 00:14:27,915
Speaker 4:  Out there. Yeah, exactly. So that was APIs. So with Uber and DoorDash and

275
00:14:27,915 --> 00:14:31,395
Speaker 4:  a handful of others, they're just using the boring old APIs,

276
00:14:31,645 --> 00:14:33,315
Speaker 4:  which is how most computers work.

277
00:14:33,675 --> 00:14:36,395
Speaker 6:  Interesting. I thought the age agentic stuff was going to be a big part of

278
00:14:36,395 --> 00:14:36,875
Speaker 6:  this. And

279
00:14:36,875 --> 00:14:40,395
Speaker 4:  Then the age stuff is, they called for like a dish dishwasher

280
00:14:40,475 --> 00:14:44,315
Speaker 4:  repair. Right. So if, If you like run some service

281
00:14:45,105 --> 00:14:48,555
Speaker 4:  like Thumbtack was the one they, and you don't want to build a bunch of APIs.

282
00:14:48,585 --> 00:14:52,525
Speaker 4:  Yeah. You can just say to Amazon, it's okay for Alexa to click around on

283
00:14:52,525 --> 00:14:56,125
Speaker 4:  our website and the agent can do that. And then there's like a middle

284
00:14:56,225 --> 00:14:59,895
Speaker 4:  ground where you're like, you can like

285
00:15:00,085 --> 00:15:01,535
Speaker 4:  Suno the music service.

286
00:15:01,565 --> 00:15:03,735
Speaker 6:  Yeah. Yeah. Creating songs out of nothing.

287
00:15:03,805 --> 00:15:06,455
Speaker 4:  Yeah. Where it's like it's still, it's gotta do some API stuff but it can

288
00:15:06,455 --> 00:15:10,415
Speaker 4:  still click around on the website. Weird. Like weird, weird stuff.

289
00:15:11,755 --> 00:15:14,295
Speaker 4:  And a lot of the demos of that capability,

290
00:15:15,875 --> 00:15:19,115
Speaker 4:  I I were less believable in the moment. Yeah.

291
00:15:19,585 --> 00:15:20,235
Speaker 6:  Just like Rabbit.

292
00:15:21,445 --> 00:15:21,795
Speaker 4:  Right.

293
00:15:22,075 --> 00:15:25,155
Speaker 6:  I know that they're partners but my question with any of the agentic stuff

294
00:15:25,155 --> 00:15:28,915
Speaker 6:  is what happens. Like are they actually just targeting certain

295
00:15:28,915 --> 00:15:32,755
Speaker 6:  areas of the site or are they doing recognition of the buttons? Like Rabbit

296
00:15:32,755 --> 00:15:35,955
Speaker 6:  always says it was recognition. As soon as one of these websites changes

297
00:15:35,955 --> 00:15:39,675
Speaker 6:  their website, everything breaks. Yep. That happened before. Could see it

298
00:15:39,675 --> 00:15:40,155
Speaker 6:  happening again.

299
00:15:40,265 --> 00:15:43,795
Speaker 4:  Well, so Rabbit's pitch was it could go to any website. Yeah. And

300
00:15:43,935 --> 00:15:47,595
Speaker 4:  really they had just like card coded itself to like Uber and Spotify. Yeah.

301
00:15:48,595 --> 00:15:52,555
Speaker 4:  Amazon's pitch is a little different, which is that people will come to

302
00:15:52,775 --> 00:15:56,395
Speaker 4:  Amazon right. And they will say, we would like our

303
00:15:56,395 --> 00:16:00,275
Speaker 4:  website to be part of your agentic system. So presumably there's

304
00:16:00,275 --> 00:16:04,195
Speaker 4:  not like the incentives are aligned more so to make sure the

305
00:16:04,195 --> 00:16:07,115
Speaker 4:  agent can use the website consistently or like you'll maybe you'll build

306
00:16:07,155 --> 00:16:10,675
Speaker 4:  a special or website and Yeah. That's even less of a lift than building an

307
00:16:10,675 --> 00:16:14,475
Speaker 4:  API but you can still do it. Yeah. I dunno. But I do know that the

308
00:16:14,635 --> 00:16:18,555
Speaker 4:  straight up book, my friend in Uber at JFK made

309
00:16:18,555 --> 00:16:19,395
Speaker 4:  no sense. Yeah,

310
00:16:19,985 --> 00:16:20,275
Speaker 6:  Yeah.

311
00:16:20,345 --> 00:16:21,715
Speaker 4:  Like no sense how do I

312
00:16:21,715 --> 00:16:23,435
Speaker 6:  Know what pickup zone to go to? Yeah, yeah,

313
00:16:23,435 --> 00:16:26,355
Speaker 5:  Yeah. I mean there are a hundred things about that demo that don't make any

314
00:16:26,355 --> 00:16:28,675
Speaker 5:  sense. Like, and and and the way I've come to think about all the age agentic

315
00:16:28,675 --> 00:16:29,315
Speaker 5:  stuff is there's like, well

316
00:16:29,315 --> 00:16:31,515
Speaker 4:  Tell people what the demo is. 'cause apparently there's no livestream change.

317
00:16:31,625 --> 00:16:34,315
Speaker 5:  Well I'll, I'll I'll get there. But the, the, I think the way to think about

318
00:16:34,315 --> 00:16:38,035
Speaker 5:  the age agentic stuff in general is like there's a set of things that are

319
00:16:38,035 --> 00:16:41,875
Speaker 5:  just like knobs that some app can expose in an API

320
00:16:41,935 --> 00:16:45,795
Speaker 5:  and rather than try to fake your website, you should just use their API and

321
00:16:45,795 --> 00:16:49,675
Speaker 5:  Amazon has the business deals to do that, right? So like if

322
00:16:49,675 --> 00:16:52,635
Speaker 5:  I don't have to use ticketmaster.com and I can just access the Ticketmaster

323
00:16:52,875 --> 00:16:56,395
Speaker 5:  database victory, right? Like that is, that's still agentic and that's still

324
00:16:56,665 --> 00:17:00,635
Speaker 5:  good. That is the correct answer. In the middle there's the stuff that is

325
00:17:00,835 --> 00:17:04,715
Speaker 5:  like solvable internet problems, right? That it's like go to Bing

326
00:17:04,715 --> 00:17:08,435
Speaker 5:  and click on the first result is like a, a thing chat GPT does all the time

327
00:17:08,435 --> 00:17:11,595
Speaker 5:  when you're an operator. Right. That or like scan down this page for things

328
00:17:11,595 --> 00:17:15,515
Speaker 5:  with five star results. These are like tractable problems for ai. And

329
00:17:15,515 --> 00:17:18,595
Speaker 5:  then there's the thing that's just like, ah, we'll figure it out. Like AI

330
00:17:18,595 --> 00:17:22,555
Speaker 5:  is smart, it'll figure it out and we will see what happens. The problem with

331
00:17:22,555 --> 00:17:25,915
Speaker 5:  all of those is there are a billion edge cases to every single one. Right.

332
00:17:26,055 --> 00:17:29,795
Speaker 5:  And lemme see if I remember the demo correctly. For Uber it was, it

333
00:17:29,795 --> 00:17:33,715
Speaker 5:  started with booking a restaurant reservation. Yep. Successfully booked

334
00:17:33,715 --> 00:17:37,035
Speaker 5:  the restaurant reservation through OpenTable, which is presumably just an

335
00:17:37,035 --> 00:17:40,755
Speaker 5:  API that Alexa has access to, again, fairly tractable problem,

336
00:17:40,845 --> 00:17:44,755
Speaker 5:  right? Like there are times there is a restaurant, I notice how many people

337
00:17:44,785 --> 00:17:48,555
Speaker 5:  like it can click the dropdowns for you in the API. Fine. The next thing

338
00:17:48,555 --> 00:17:52,405
Speaker 5:  was my friend is coming from JFK, can you book

339
00:17:52,405 --> 00:17:55,485
Speaker 5:  an Uber to pick them up and I guess bring them to the restaurant.

340
00:17:55,675 --> 00:17:59,045
Speaker 4:  Okay. Right there. I just wanna say right there a fully

341
00:17:59,265 --> 00:18:03,045
Speaker 4:  insane thing to say to any, any another

342
00:18:03,045 --> 00:18:06,765
Speaker 4:  human being to your friend who's landing at JFK I've booked you

343
00:18:07,005 --> 00:18:09,145
Speaker 4:  an Uber. Uber, why?

344
00:18:10,125 --> 00:18:10,865
Speaker 5:  Yes. Right?

345
00:18:11,765 --> 00:18:15,145
Speaker 4:  Yes. You know who can book an Uber, use your phone. Anyone with a phone,

346
00:18:15,335 --> 00:18:15,625
Speaker 4:  like

347
00:18:16,375 --> 00:18:20,345
Speaker 6:  Yeah. I will say I have a, a friend who is an, an assistant for

348
00:18:20,385 --> 00:18:23,985
Speaker 6:  a hedge fund manager and this is stuff that she does

349
00:18:24,205 --> 00:18:27,705
Speaker 6:  all the time. And so I see an end case

350
00:18:28,035 --> 00:18:32,025
Speaker 6:  where way in the future the, the idea of a lot of

351
00:18:32,025 --> 00:18:35,745
Speaker 6:  these AI platforms is like, what if we could take this job that people do

352
00:18:36,085 --> 00:18:39,545
Speaker 6:  and get rid of it? Yeah. Yeah. And so in this universe

353
00:18:39,815 --> 00:18:43,185
Speaker 6:  it's sort of like, just automate this job away. Right.

354
00:18:43,965 --> 00:18:44,185
Speaker 6:  But

355
00:18:44,795 --> 00:18:48,385
Speaker 4:  Right. But I but I'm saying the command, I need an Uber or I would like to

356
00:18:48,385 --> 00:18:51,945
Speaker 4:  have a car pick me up. Yeah. Your hedge fund manager friend. Yeah,

357
00:18:53,015 --> 00:18:56,905
Speaker 4:  boss. Your hedge fund manager. In this example, the hedge fund manager just

358
00:18:56,905 --> 00:19:00,545
Speaker 4:  says out loud, I need a car. And then a person uses the Uber app. Yeah.

359
00:19:00,685 --> 00:19:04,625
Speaker 4:  In this case they would just, they would still just tell their own

360
00:19:04,885 --> 00:19:07,025
Speaker 4:  AI Yeah. To book them a car.

361
00:19:07,375 --> 00:19:07,665
Speaker 6:  Yeah.

362
00:19:08,415 --> 00:19:11,385
Speaker 4:  It's, it, I, that was the part that got me like right there in that demo

363
00:19:11,725 --> 00:19:15,305
Speaker 4:  was like, I'm gonna send my friend a car at JFK is in, in like,

364
00:19:15,645 --> 00:19:19,485
Speaker 4:  in a very abstract sense. Makes a lot of sense and then keep

365
00:19:19,485 --> 00:19:20,445
Speaker 4:  going. Right.

366
00:19:20,445 --> 00:19:20,845
Speaker 5:  Well, but there

367
00:19:20,845 --> 00:19:23,085
Speaker 4:  Are, but just that instinct was like very confusing to me.

368
00:19:23,235 --> 00:19:26,845
Speaker 5:  Also, David, to your point, like in, in that system where I'm the assistant

369
00:19:26,845 --> 00:19:30,285
Speaker 5:  working with somebody, odds are overwhelmingly good that we share an Uber

370
00:19:30,285 --> 00:19:34,005
Speaker 5:  account that your picture is going to be there somewhere that you're an authorized

371
00:19:34,005 --> 00:19:37,365
Speaker 5:  user that it's gonna pop up on your phone to tell you where to go. So like

372
00:19:37,615 --> 00:19:41,445
Speaker 5:  these, these systems exist that I know what terminal you're at

373
00:19:41,445 --> 00:19:42,965
Speaker 5:  and have a way to tell people what terminal,

374
00:19:42,965 --> 00:19:43,605
Speaker 6:  Like Right.

375
00:19:43,995 --> 00:19:47,925
Speaker 5:  There's a, there's a shared universe of information that exists in that world

376
00:19:47,925 --> 00:19:51,085
Speaker 5:  that does not exist in my friend Molly is flying into JFK.

377
00:19:51,325 --> 00:19:52,445
Speaker 6:  Right? Right. And so,

378
00:19:52,985 --> 00:19:56,605
Speaker 5:  So, but in all of this, okay, now I have a, a series of this

379
00:19:56,605 --> 00:19:58,925
Speaker 4:  Super sounds like you're about to do a drug deal. By the way, every time

380
00:19:58,925 --> 00:20:01,005
Speaker 4:  you say my friend Molly is the JF k my,

381
00:20:01,565 --> 00:20:04,765
Speaker 5:  That was, I forget who it was and I'm sorry, but somebody in our slack was

382
00:20:04,765 --> 00:20:08,405
Speaker 5:  like, this definitely ends with just a bag of drugs being delivered to your

383
00:20:08,605 --> 00:20:11,925
Speaker 4:  Restaurants. This is starting to come into focus. Alright.

384
00:20:12,225 --> 00:20:15,845
Speaker 5:  But so it raises all these questions, right? Like, okay, where at J-F-K-J-F-K

385
00:20:15,845 --> 00:20:19,085
Speaker 5:  is an enormous airport with lots of terminals and lots of different pickup

386
00:20:19,085 --> 00:20:22,885
Speaker 5:  points at each of those terminals. How is it going to figure that

387
00:20:22,885 --> 00:20:26,125
Speaker 5:  out? How is it going to tell the Uber driver? And then how is it gonna communicate

388
00:20:26,125 --> 00:20:29,485
Speaker 5:  that information to Molly who is completely looped out of this whole set

389
00:20:29,485 --> 00:20:30,285
Speaker 5:  of information We

390
00:20:30,285 --> 00:20:33,885
Speaker 6:  Need to normalize just doing really basic tasks yourself. This takes

391
00:20:33,885 --> 00:20:34,365
Speaker 5:  Click the button

392
00:20:34,695 --> 00:20:38,485
Speaker 4:  Three seconds in the demo. It was like, I've booked a car

393
00:20:38,545 --> 00:20:42,005
Speaker 4:  to pick up your friend Molly at JFK and at no point. And then I think

394
00:20:42,385 --> 00:20:46,365
Speaker 4:  the next command was like, text Molly this information. Right. But like I

395
00:20:46,485 --> 00:20:49,845
Speaker 4:  I, I'm assuming some of our listeners have never landed at JFK.

396
00:20:50,665 --> 00:20:54,205
Speaker 4:  It is a huge sprawling, ridiculous

397
00:20:54,205 --> 00:20:57,845
Speaker 4:  airport and it's uber pickup situation is

398
00:20:57,895 --> 00:21:00,165
Speaker 4:  among the worst I believe in the world. Yeah.

399
00:21:00,165 --> 00:21:02,445
Speaker 5:  It's very bad. Yeah. Second to LA Yeah.

400
00:21:02,635 --> 00:21:05,885
Speaker 4:  Like LA is like you're going to a different city Yeah. To get on this Uber.

401
00:21:06,275 --> 00:21:09,245
Speaker 4:  Like have you, have you thought about standing in a parking lot six miles

402
00:21:09,245 --> 00:21:13,085
Speaker 4:  away from the airport? Yeah. Like that's LA Yep. JFK is almost as bad.

403
00:21:13,085 --> 00:21:16,565
Speaker 4:  Yeah. I, I just landed back at JFK and I had to get on a train to another

404
00:21:16,805 --> 00:21:19,925
Speaker 4:  terminal to walk up a flight of stairs to go to another weird parking lot.

405
00:21:20,385 --> 00:21:23,725
Speaker 4:  And no one is, was happy about that. The Uber driver was like, I went to

406
00:21:23,725 --> 00:21:27,405
Speaker 4:  the first terminal and I was like, the app is, it's all bad. Yeah. Yeah.

407
00:21:27,425 --> 00:21:31,405
Speaker 4:  And the idea that Alexa collapsed that to JFK Right. Pano said all of the

408
00:21:31,415 --> 00:21:34,725
Speaker 4:  demos are real, I'm I'm sure in some universe

409
00:21:35,425 --> 00:21:39,165
Speaker 4:  it just picked the first result for JFK in the Uber app and it was like at

410
00:21:39,165 --> 00:21:41,005
Speaker 4:  the cargo terminal or something. The

411
00:21:41,005 --> 00:21:44,605
Speaker 5:  Way that that ends is there is an Uber circling JFK

412
00:21:44,605 --> 00:21:46,165
Speaker 5:  endlessly looking for your friend Mike

413
00:21:46,165 --> 00:21:47,725
Speaker 4:  Powering down the runways who

414
00:21:47,805 --> 00:21:51,525
Speaker 5:  I would point out does not have access to your Uber account because you

415
00:21:51,525 --> 00:21:54,205
Speaker 5:  don't share an Uber account with your friend Molly. Because why would you

416
00:21:54,205 --> 00:21:57,645
Speaker 5:  do that? And so your friend Molly actually has no way to contact this Uber

417
00:21:57,645 --> 00:22:00,445
Speaker 5:  driver. So actually what you've done is you've invented a more complicated

418
00:22:00,885 --> 00:22:03,525
Speaker 5:  situation to solve than If you had just done it yourself.

419
00:22:04,265 --> 00:22:07,445
Speaker 4:  And I just wanna point out, by the way, this is the simplest case of the

420
00:22:07,445 --> 00:22:10,045
Speaker 4:  integration where everything happened with APIs.

421
00:22:10,475 --> 00:22:10,765
Speaker 5:  Yeah.

422
00:22:10,975 --> 00:22:14,045
Speaker 4:  Right? Like Uber has APIs that are exposed to Amazon in this way.

423
00:22:14,785 --> 00:22:18,485
Speaker 4:  The OpenTable has APIs that are exposed to Amazon this way. The next

424
00:22:18,705 --> 00:22:21,845
Speaker 4:  one where it was slightly more agentic

425
00:22:22,745 --> 00:22:26,405
Speaker 4:  was I to me is like where it all starts to fall apart.

426
00:22:26,975 --> 00:22:30,965
Speaker 4:  Right. Because the Uber case you can solve you, you can solve

427
00:22:30,965 --> 00:22:34,805
Speaker 4:  it, right. You, Molly can send you some Uber access code or give you

428
00:22:34,805 --> 00:22:35,565
Speaker 4:  access to her account.

429
00:22:35,635 --> 00:22:38,645
Speaker 5:  It's also the kind of thing you're never gonna do. And in the ca in the real

430
00:22:38,765 --> 00:22:42,485
Speaker 5:  case where it's like, book me an Uber to go to the airport, perfectly

431
00:22:42,485 --> 00:22:45,925
Speaker 5:  solvable problem. Like that is, that is a thing that will work. Yeah.

432
00:22:46,855 --> 00:22:50,085
Speaker 5:  Again, normalize doing basic things yourself. Yeah. No, that's what I mean.

433
00:22:50,395 --> 00:22:53,845
Speaker 5:  It's like if Molly were just to get off and be like, Alexa, I'm, I'm at

434
00:22:54,405 --> 00:22:58,045
Speaker 5:  terminal five. Can you get me an Uber to this restaurant? Like that is, that

435
00:22:58,045 --> 00:23:01,565
Speaker 5:  is actually a thing that every step of the way is a solvable problem for

436
00:23:01,705 --> 00:23:01,925
Speaker 5:  ai.

437
00:23:02,275 --> 00:23:05,645
Speaker 4:  Yeah. Especially If you have access to Uber. The problem the,

438
00:23:06,035 --> 00:23:09,125
Speaker 4:  I'll talk about the age agentic one 'cause I'm more curious about how they

439
00:23:09,125 --> 00:23:12,125
Speaker 4:  will solve some of those problems. The problem is that, you know, who would

440
00:23:12,125 --> 00:23:16,085
Speaker 4:  also love that deal is Lyft. Right? And so you're saying book

441
00:23:16,085 --> 00:23:19,925
Speaker 4:  me an Uber and that means one thing. But If you say, book me a car, now Amazon

442
00:23:19,925 --> 00:23:23,845
Speaker 4:  gets to pick what service or it gets to, and this is what they really

443
00:23:23,845 --> 00:23:27,045
Speaker 4:  don't want to have happen. It gets to go look at both services and say the

444
00:23:27,045 --> 00:23:30,885
Speaker 4:  Lyft is $5 cheaper than the Uber. Do you want me to book you the Lyft? And

445
00:23:30,885 --> 00:23:34,725
Speaker 4:  like I do that on my phone right now and the apps can't stop me. But

446
00:23:34,845 --> 00:23:38,605
Speaker 4:  there's nothing stopping Uber from saying Amazon, we wanna be

447
00:23:38,605 --> 00:23:42,485
Speaker 4:  exclusive here. Right. And I I I always call this the DoorDash problem. Like,

448
00:23:42,695 --> 00:23:46,245
Speaker 4:  these service providers get commodified in these interfaces and there's no

449
00:23:46,245 --> 00:23:50,225
Speaker 4:  incentive for them to participate unless Amazon pays them money. And

450
00:23:50,225 --> 00:23:53,905
Speaker 4:  then now we start making deals that prevent you from competing. Right? Like

451
00:23:54,125 --> 00:23:57,955
Speaker 4:  you can just see this, it's really fascinating. It's really interesting.

452
00:23:57,985 --> 00:24:01,435
Speaker 4:  It's what everybody wants to have like a butler to booking cars for them

453
00:24:01,435 --> 00:24:05,275
Speaker 4:  left and right and then actually making it work requires a bunch

454
00:24:05,275 --> 00:24:08,475
Speaker 4:  of companies to basically take themselves out of the loop.

455
00:24:09,095 --> 00:24:12,875
Speaker 4:  And it's unclear right now as to why, If you like order me a

456
00:24:13,075 --> 00:24:16,915
Speaker 4:  sandwich and DoorDash never gets to show you an ad or upsell you on

457
00:24:16,965 --> 00:24:20,675
Speaker 4:  fries or get you to sign up for DoorDash plus or whatever they call it,

458
00:24:20,775 --> 00:24:21,155
Speaker 4:  why would they

459
00:24:21,155 --> 00:24:21,435
Speaker 5:  Pay part of

460
00:24:21,435 --> 00:24:24,195
Speaker 4:  It? Why would they do it? Yeah. Right. Because they all, their margins are

461
00:24:24,195 --> 00:24:27,035
Speaker 4:  just crushed and now they're just a commodity provider of sandwiches. Yep.

462
00:24:27,745 --> 00:24:30,395
Speaker 4:  Next to whoever else. And like I don't, I just dunno why they'll do it. We'll

463
00:24:30,395 --> 00:24:34,235
Speaker 5:  See, I don't know. But If you, If you then get to be the exclusive commodity

464
00:24:34,595 --> 00:24:37,585
Speaker 5:  provider of sandwiches, that's a pretty good business

465
00:24:38,715 --> 00:24:40,535
Speaker 5:  for one company. It's a pretty good

466
00:24:40,695 --> 00:24:43,135
Speaker 4:  Business. It's a great business for one company that has no growth potential,

467
00:24:43,265 --> 00:24:47,175
Speaker 4:  right? Yeah. Like, like you will be forever as only

468
00:24:47,195 --> 00:24:49,655
Speaker 4:  as big as the sandwich market inside of the Amazon Alexa

469
00:24:49,675 --> 00:24:50,255
Speaker 5:  App. Yep.

470
00:24:50,425 --> 00:24:53,535
Speaker 4:  Maybe that's all you aspire to. And that's fine. David, listen

471
00:24:53,635 --> 00:24:54,295
Speaker 5:  Me, I have gold.

472
00:24:55,435 --> 00:24:59,375
Speaker 4:  The harder one was when they were like, my dishwasher and my stove is

473
00:24:59,375 --> 00:25:03,255
Speaker 4:  broken. Find me or repair person for my Meade appliance meal

474
00:25:03,255 --> 00:25:05,695
Speaker 4:  appliance is by the way, very expensive, very expensive to fix. So this is

475
00:25:05,695 --> 00:25:09,535
Speaker 4:  a perfect, only Amazon executives have this specific problem kind of demo.

476
00:25:09,995 --> 00:25:13,705
Speaker 4:  And it went onto a website called Thumbtack, which like has a list

477
00:25:13,885 --> 00:25:17,835
Speaker 4:  of repair people just like Angie's List or any of

478
00:25:17,835 --> 00:25:21,115
Speaker 4:  these other billion websites that are like this. And I'm sitting there watching

479
00:25:21,115 --> 00:25:24,395
Speaker 4:  that demo and it did it, right? It clicked around the website, it found a

480
00:25:24,395 --> 00:25:27,155
Speaker 4:  service provider with some reviews and said they're gonna come at eight in

481
00:25:27,155 --> 00:25:29,795
Speaker 4:  the morning at the end. And I was like, that's great. 'cause now they don't

482
00:25:29,795 --> 00:25:32,915
Speaker 4:  have to use those websites. And then the reality of all of those websites

483
00:25:32,915 --> 00:25:36,755
Speaker 4:  is you go on there to find a plumber or a repair person for your

484
00:25:36,755 --> 00:25:40,435
Speaker 4:  dishwasher or whoever, and they don't give a shit about those websites. And

485
00:25:40,435 --> 00:25:44,395
Speaker 4:  they have not actually handed their business over to Thumbtack and

486
00:25:44,395 --> 00:25:48,195
Speaker 4:  let Thumbtack run their schedule or their billing or their customer relationships.

487
00:25:48,265 --> 00:25:52,115
Speaker 4:  They've just listed themselves there. 'cause they wanna be in some SEO

488
00:25:52,815 --> 00:25:56,555
Speaker 4:  result for people searching for repairmen. And then you call and then they

489
00:25:56,555 --> 00:26:00,435
Speaker 4:  run their own business and it's like, oh, Amazon depends on that

490
00:26:00,435 --> 00:26:04,375
Speaker 4:  whole ecosystem actually working. Right? And like there's

491
00:26:04,375 --> 00:26:07,455
Speaker 4:  nothing Alexa can do about the fact that it mostly doesn't work.

492
00:26:08,335 --> 00:26:10,905
Speaker 4:  Like If you, If you go on some of these websites, like sometimes yes the

493
00:26:10,905 --> 00:26:14,305
Speaker 4:  house painter comes and they actually let their, those kinds of middlemen

494
00:26:14,705 --> 00:26:18,625
Speaker 4:  services run their business. But for the most part they're like, I

495
00:26:18,625 --> 00:26:21,865
Speaker 4:  don't want anything to do. It's like, I want you to pay me in cash Under

496
00:26:21,865 --> 00:26:24,065
Speaker 4:  the table is like the end result of most

497
00:26:24,065 --> 00:26:27,305
Speaker 5:  Of those interactions. Well, and it's specifically because all of those businesses

498
00:26:27,455 --> 00:26:31,185
Speaker 5:  have been chopped off at the knees by middleman after middleman, after

499
00:26:31,185 --> 00:26:35,145
Speaker 5:  middleman after middleman. And so I mean you're, you're starting to

500
00:26:35,145 --> 00:26:38,665
Speaker 5:  see this with restaurants and stuff in the DoorDash universe where they're

501
00:26:38,665 --> 00:26:42,505
Speaker 5:  just like, no, like I, I will deliver my own food by paying

502
00:26:42,625 --> 00:26:45,725
Speaker 5:  a high teenager to drive it to your house because that is actually a business

503
00:26:45,805 --> 00:26:49,565
Speaker 5:  I can afford. And so like all this stuff has been so

504
00:26:49,565 --> 00:26:53,125
Speaker 5:  centralized that it's actually broken for the

505
00:26:53,285 --> 00:26:56,165
Speaker 5:  businesses themselves and they're starting to run away from it. But because

506
00:26:56,165 --> 00:26:58,525
Speaker 5:  it has been so centralized and this is the bet that Amazon and everybody

507
00:26:58,525 --> 00:27:02,405
Speaker 5:  else is making, it's really hard to decentralize it because

508
00:27:02,465 --> 00:27:06,005
Speaker 5:  now everybody is used to being on those platforms. And so, like if you're

509
00:27:06,075 --> 00:27:09,925
Speaker 5:  Uber Eats or DoorDash, if you're a restaurant now you have to make the

510
00:27:09,945 --> 00:27:13,885
Speaker 5:  bet that people will go find my restaurant rather than just pick the next

511
00:27:13,885 --> 00:27:17,805
Speaker 5:  best thing on the platform. And I think how that shakes out remains to

512
00:27:17,805 --> 00:27:20,965
Speaker 5:  be seen. But like it's pretty clear which one of those things Alexa is betting

513
00:27:20,965 --> 00:27:24,565
Speaker 5:  on, which is that platform convenience, which you can make it even more convenient

514
00:27:24,905 --> 00:27:28,885
Speaker 5:  by abstracting it all the way to order me a pizza or find me a repairman

515
00:27:29,755 --> 00:27:33,645
Speaker 5:  will outweigh actually having successful businesses on the other

516
00:27:33,645 --> 00:27:33,845
Speaker 5:  side.

517
00:27:34,195 --> 00:27:38,065
Speaker 4:  Yeah. And I I think this is just like, this is the problem. Like

518
00:27:38,425 --> 00:27:41,865
Speaker 4:  I should just write a piece called the DoorDash problem. Like why would you

519
00:27:41,865 --> 00:27:45,665
Speaker 4:  wanna run the pipes between you and the sandwich in a world

520
00:27:45,665 --> 00:27:49,105
Speaker 4:  where that is becoming the most, the least

521
00:27:49,105 --> 00:27:52,465
Speaker 4:  differentiated part of the entire experience. Yeah. Right. If you run

522
00:27:53,215 --> 00:27:56,025
Speaker 4:  Thumbtack, and I'm sorry if there's like a, we have a bunch of listeners

523
00:27:56,025 --> 00:27:59,545
Speaker 4:  who work at Thumbtack. I mean, I'm, I'm proud of you and

524
00:27:59,965 --> 00:28:02,385
Speaker 4:  you're doing a good job every day, another victory.

525
00:28:03,765 --> 00:28:07,585
Speaker 4:  But like what, what about Thumbtack is

526
00:28:07,585 --> 00:28:10,145
Speaker 4:  making it better on both sides of that equation that isn't gonna just get

527
00:28:10,145 --> 00:28:13,865
Speaker 4:  completely erased by the fact that Alexa's just clicking on your website

528
00:28:13,865 --> 00:28:17,675
Speaker 4:  for you. Great. Like someone will figure that out.

529
00:28:17,975 --> 00:28:21,315
Speaker 4:  And that's like, so that's the hardest stuff that they demoed. It's not rolling

530
00:28:21,315 --> 00:28:21,875
Speaker 4:  out at first.

531
00:28:23,935 --> 00:28:27,465
Speaker 4:  They're gonna roll that over time. What is rolling out first on the Echo

532
00:28:27,465 --> 00:28:30,785
Speaker 4:  show devices is like an even harder problem, which is we're gonna automate

533
00:28:30,785 --> 00:28:31,345
Speaker 4:  your smartphone.

534
00:28:33,085 --> 00:28:36,745
Speaker 4:  And it's like, oh, like no part of this is easy. Is that a harder

535
00:28:36,745 --> 00:28:37,065
Speaker 5:  Problem?

536
00:28:38,515 --> 00:28:42,175
Speaker 4:  So PATOS told me and someone De Dakota on Monday, he's like,

537
00:28:42,635 --> 00:28:46,495
Speaker 4:  the Alexa smart home ecosystem was already so good

538
00:28:47,475 --> 00:28:51,355
Speaker 4:  that everything we demoed required no new code. Right? Alexa Plus could

539
00:28:51,355 --> 00:28:54,995
Speaker 4:  just like push all the buttons and twist all the knobs any way it wanted

540
00:28:54,995 --> 00:28:58,155
Speaker 4:  to and make its own routines because that stuff has just been ready to go

541
00:28:58,155 --> 00:29:02,115
Speaker 4:  for so long. So they yes, I think they think it's good.

542
00:29:02,115 --> 00:29:05,675
Speaker 4:  What I mean by it's harder is you buy this new device,

543
00:29:06,295 --> 00:29:10,105
Speaker 4:  you plop it down in your kitchen and then now you have a smart home.

544
00:29:10,105 --> 00:29:13,865
Speaker 4:  That's the promise. But the reality is you've gotta

545
00:29:14,005 --> 00:29:17,905
Speaker 4:  add everything to your Alexa smart home system. Yes. All those cloud

546
00:29:17,905 --> 00:29:21,825
Speaker 4:  accounts have to sync every, some stuff you're

547
00:29:21,825 --> 00:29:25,665
Speaker 4:  controlling in an app on your iPhone. Another thing, you're right, like you

548
00:29:25,825 --> 00:29:29,675
Speaker 4:  actually have to still do the setup to make the magic happen and

549
00:29:29,675 --> 00:29:32,835
Speaker 4:  nothing about the setup has gotten particularly easier here. And you need

550
00:29:32,835 --> 00:29:33,515
Speaker 4:  to decide where you

551
00:29:33,515 --> 00:29:33,995
Speaker 5:  Wanna set it

552
00:29:33,995 --> 00:29:37,915
Speaker 4:  Up on and and then you need to decide where your automations and routines

553
00:29:37,915 --> 00:29:39,955
Speaker 4:  live. Right. And if that's gonna be Amazon forever.

554
00:29:40,305 --> 00:29:44,285
Speaker 6:  Yeah. Are they Amazon or are they on Google Home? Are they on the manufacturer's

555
00:29:44,285 --> 00:29:47,765
Speaker 6:  website? Yeah, there's like five different places that you could potentially

556
00:29:47,825 --> 00:29:49,005
Speaker 6:  set up all of these devices.

557
00:29:49,415 --> 00:29:50,805
Speaker 5:  David, are you a smart home guy?

558
00:29:51,755 --> 00:29:54,485
Speaker 6:  Minimally. I live in a Brooklyn basement. What

559
00:29:54,485 --> 00:29:54,725
Speaker 5:  Do you have?

560
00:29:55,365 --> 00:29:58,805
Speaker 6:  I pretty much completely put everything on

561
00:29:59,955 --> 00:30:03,685
Speaker 6:  HomeKit I guess. I guess it's called HomeKit. Yeah. Because I have Eve stuff.

562
00:30:03,865 --> 00:30:07,645
Speaker 6:  Mm. So, but it is only Eve smart plugs and smart

563
00:30:07,665 --> 00:30:10,765
Speaker 6:  blinds. I got them because of Matter

564
00:30:11,325 --> 00:30:15,205
Speaker 6:  famously does not really work, which is cool, but

565
00:30:15,205 --> 00:30:19,005
Speaker 6:  it at least it's all in the same thing. But I also do have a

566
00:30:19,525 --> 00:30:23,485
Speaker 6:  singular Google Home Hub mini that I was

567
00:30:23,525 --> 00:30:26,965
Speaker 6:  dreaming of being able to tell to make my blinds go up and down

568
00:30:27,725 --> 00:30:29,045
Speaker 6:  famously still does not work.

569
00:30:30,315 --> 00:30:33,245
Speaker 5:  This is the Yeah, this is the like what a perfect smart home scenario. We're

570
00:30:33,245 --> 00:30:37,005
Speaker 5:  like, okay, I bought all the pieces. Yeah. And each of the things does the

571
00:30:37,005 --> 00:30:40,965
Speaker 5:  things that are required for this puzzle to fit together and yet it

572
00:30:40,965 --> 00:30:44,885
Speaker 5:  doesn't for some unknowable technical reason. Yeah. That will never, ever

573
00:30:44,885 --> 00:30:45,285
Speaker 5:  get solved.

574
00:30:45,445 --> 00:30:49,205
Speaker 6:  I set up a routine that automates my blinds, that's all that I really care

575
00:30:49,205 --> 00:30:52,005
Speaker 6:  about. And then I have a widget on my phone that turns my lights on and off.

576
00:30:52,105 --> 00:30:55,445
Speaker 6:  And I really don't care to make it more automated than that.

577
00:30:56,085 --> 00:30:59,725
Speaker 5:  I think that's good. And truthfully, I think like a, I think that is

578
00:31:00,155 --> 00:31:04,085
Speaker 5:  most people's smart home desire, right? Yeah. Like I want one thing to

579
00:31:04,085 --> 00:31:07,885
Speaker 5:  happen when I do another thing is I genuinely believe the extent of most

580
00:31:07,885 --> 00:31:10,605
Speaker 5:  people's smart home wishes. Yeah. And that's also a thing that something

581
00:31:10,605 --> 00:31:14,085
Speaker 5:  like Alexa Plus is well positioned to do pretty well because

582
00:31:15,235 --> 00:31:18,845
Speaker 5:  what, what these routines and things have is a like massive

583
00:31:19,275 --> 00:31:23,005
Speaker 5:  user interface problem. It's the same thing like a rail on apple shortcuts

584
00:31:23,005 --> 00:31:26,725
Speaker 5:  all the time. And it's like, it's this massively powerful thing buried

585
00:31:26,725 --> 00:31:29,685
Speaker 5:  behind what amounts to like a scripting language. And you need to go through

586
00:31:29,725 --> 00:31:33,645
Speaker 5:  a series of really complicated like if then statements. Yep. So to be able

587
00:31:33,645 --> 00:31:37,565
Speaker 5:  to just say to this system, Hey, every time I turn off my alarm clock,

588
00:31:37,715 --> 00:31:40,965
Speaker 5:  turn the lights on in the bathroom is like that's actually a thing that a

589
00:31:40,965 --> 00:31:44,885
Speaker 5:  system like an LLM is well positioned to understand what

590
00:31:44,885 --> 00:31:48,565
Speaker 5:  that means. And then if Amazon has done a as good a job as

591
00:31:48,765 --> 00:31:52,205
Speaker 5:  P is saying, which I think reasonably probably has of

592
00:31:52,205 --> 00:31:56,165
Speaker 5:  understanding all of those endpoints, it can actually put all

593
00:31:56,165 --> 00:31:59,125
Speaker 5:  of that together in a way that strikes me as like it would work. Right. And

594
00:31:59,125 --> 00:32:02,445
Speaker 5:  then I'm just at a point where all I have to do is learn how to explain what

595
00:32:02,485 --> 00:32:06,125
Speaker 5:  I want rather than like program it in detail in the Alexa app. But

596
00:32:06,125 --> 00:32:09,885
Speaker 4:  So that even that explain what I want the, you know, their examples were

597
00:32:09,915 --> 00:32:13,365
Speaker 4:  come up with a bedtime routine and it was like

598
00:32:13,895 --> 00:32:16,325
Speaker 4:  Alexa just was like, I don't know, I'm gonna play some music. I'm gonna turn

599
00:32:16,325 --> 00:32:19,825
Speaker 4:  off these lights, I'm gonna dim these other lights. Call it a bedtime routine.

600
00:32:19,985 --> 00:32:22,225
Speaker 5:  I really don't think that's a real use case. This is one of the things that

601
00:32:22,225 --> 00:32:24,865
Speaker 5:  drives me the craziest about all of these things is it's like what? Like

602
00:32:25,015 --> 00:32:28,825
Speaker 5:  it's, I, I still have this picture on my desktop for some

603
00:32:29,025 --> 00:32:32,945
Speaker 5:  reason from, for like years of this Apple event from

604
00:32:32,945 --> 00:32:35,985
Speaker 5:  years ago, I think it was an iPad launch where they had this picture they

605
00:32:35,985 --> 00:32:38,705
Speaker 5:  were showing like the lifestyle photos they always show and it was a, it

606
00:32:38,705 --> 00:32:42,485
Speaker 5:  was a guy sitting in like the crook of two beams on the Brooklyn

607
00:32:42,485 --> 00:32:46,405
Speaker 5:  Bridge sketching on his iPad. And I was just like, no one does this

608
00:32:46,805 --> 00:32:47,605
Speaker 5:  like talk about your

609
00:32:47,605 --> 00:32:48,965
Speaker 4:  Products. You didn't do that when you lived in New York.

610
00:32:51,685 --> 00:32:53,885
Speaker 5:  I did it the once and they took my picture and they paid me for it and then

611
00:32:53,885 --> 00:32:57,805
Speaker 5:  I went home. It's fine. But it's just like all of these things is Jake,

612
00:32:58,245 --> 00:33:02,005
Speaker 5:  I, I spend a lot of time wondering if part of the problem

613
00:33:02,035 --> 00:33:05,565
Speaker 5:  here is that no one actually understands what any regular human would ever

614
00:33:05,565 --> 00:33:08,405
Speaker 5:  want to do with these products. Because the idea that I'm gonna come home

615
00:33:08,405 --> 00:33:12,285
Speaker 5:  one day and be like, Alexa, make up a bed bedtime routine. I'm so sorry to

616
00:33:12,285 --> 00:33:15,245
Speaker 5:  everybody who's hearing a say Alexa over and over by the way. Wait, you

617
00:33:15,245 --> 00:33:18,005
Speaker 4:  Never, you never just ask a computer to make it nice when you're sleepy.

618
00:33:18,385 --> 00:33:18,605
Speaker 4:  No.

619
00:33:19,475 --> 00:33:19,765
Speaker 6:  Yeah.

620
00:33:20,135 --> 00:33:23,245
Speaker 5:  Never. And no one is going to and the idea that I'm gonna ask it to and then

621
00:33:23,245 --> 00:33:26,605
Speaker 5:  I'm going to live with what it creates for me for the rest of my life is

622
00:33:26,605 --> 00:33:30,125
Speaker 5:  just preposterous. And so I hate this stuff now. Yeah. 'cause it's like show

623
00:33:30,125 --> 00:33:33,205
Speaker 5:  me this product as it's going to actually work for people instead of like

624
00:33:33,285 --> 00:33:36,485
Speaker 5:  a fake thing that seems vaguely impressive until you poke at it at all.

625
00:33:36,915 --> 00:33:40,645
Speaker 6:  Yeah. It seems to me that most of these companies extrapolate this stuff

626
00:33:40,665 --> 00:33:44,565
Speaker 6:  to the furthest degree where they're like, how can we reduce as much friction

627
00:33:44,585 --> 00:33:48,365
Speaker 6:  as possible between the user and doing what they want to do And they just

628
00:33:48,365 --> 00:33:52,245
Speaker 6:  forget that people don't wanna just give up complete control to these systems.

629
00:33:52,245 --> 00:33:55,965
Speaker 6:  Yeah. The famous book me a travel itinerary

630
00:33:56,105 --> 00:33:59,885
Speaker 6:  and book my plane and book my hotel, nobody wants to do that. And

631
00:33:59,905 --> 00:34:03,165
Speaker 6:  yet every company uses it as their example. Luckily

632
00:34:04,065 --> 00:34:07,965
Speaker 6:  Amazon did not actually have them book the itinerary. They just

633
00:34:07,965 --> 00:34:10,685
Speaker 6:  made the itinerary. Which is better. That is better. I

634
00:34:10,685 --> 00:34:11,285
Speaker 5:  Agree. I like that.

635
00:34:11,625 --> 00:34:14,765
Speaker 6:  But still that is like the extrapolated version of that, right? Like nobody

636
00:34:14,955 --> 00:34:18,545
Speaker 6:  even in the home, nobody wants you to bedtime routine.

637
00:34:18,905 --> 00:34:21,825
Speaker 6:  I don't know what it's gonna be. Let's just find out if that's gonna be the

638
00:34:21,825 --> 00:34:25,665
Speaker 6:  case, let me like test five of them out and then I will pick. People don't

639
00:34:25,825 --> 00:34:29,465
Speaker 6:  actually wanna just give up complete control to a system like this. Especially

640
00:34:29,465 --> 00:34:31,985
Speaker 6:  when it's completely random, you don't know what it's gonna be. Totally.

641
00:34:32,095 --> 00:34:32,385
Speaker 6:  Well,

642
00:34:32,385 --> 00:34:33,865
Speaker 4:  So I have many things to say.

643
00:34:34,135 --> 00:34:34,425
Speaker 6:  Okay.

644
00:34:35,525 --> 00:34:37,065
Speaker 4:  I'm sorry. I'm sorry to everyone.

645
00:34:39,365 --> 00:34:43,145
Speaker 4:  One, I think the hard part here is not the reduction of friction. It's letting

646
00:34:43,145 --> 00:34:46,785
Speaker 4:  people know they can do this stuff at all. And that I think requires,

647
00:34:47,005 --> 00:34:47,425
Speaker 4:  but does

648
00:34:47,425 --> 00:34:47,985
Speaker 6:  Anyone want to

649
00:34:48,725 --> 00:34:52,185
Speaker 4:  Yes. To some, to some broad approximation

650
00:34:52,855 --> 00:34:56,465
Speaker 4:  just have stuff happen is a thing people want, like

651
00:34:57,095 --> 00:35:00,425
Speaker 4:  when I get home, turn on the lights is nice. Yeah.

652
00:35:01,225 --> 00:35:05,115
Speaker 4:  It's just nice. Right. And I am convinced that like my family does not

653
00:35:05,115 --> 00:35:08,995
Speaker 4:  know how lights turn on or off anymore because many lights in our

654
00:35:08,995 --> 00:35:12,555
Speaker 4:  house just turn on or off throughout the day. Interesting. Like we have,

655
00:35:12,935 --> 00:35:16,395
Speaker 4:  we have Hugh Lights in our kitchen and they're in adaptive mode. So they

656
00:35:16,395 --> 00:35:18,475
Speaker 4:  just go from cool in the morning to warm at night.

657
00:35:20,205 --> 00:35:21,725
Speaker 4:  I think this is the coolest shit in the world. No,

658
00:35:21,725 --> 00:35:22,965
Speaker 6:  That's great. Someday Max

659
00:35:22,965 --> 00:35:25,845
Speaker 5:  Is gonna go to college and like call you from her dorm room being like, why

660
00:35:25,845 --> 00:35:26,445
Speaker 5:  is it dark?

661
00:35:27,305 --> 00:35:31,285
Speaker 4:  So Jen Tey told us that her kids, her teenage children don't know how

662
00:35:31,285 --> 00:35:32,725
Speaker 4:  to use house keys. Oh

663
00:35:32,725 --> 00:35:33,045
Speaker 6:  My God.

664
00:35:34,695 --> 00:35:35,885
Speaker 4:  Which is incredible. We're

665
00:35:35,885 --> 00:35:37,525
Speaker 5:  Ruining future generations. Neli.

666
00:35:37,545 --> 00:35:41,525
Speaker 4:  But, so I got a text from Becky and she was like, the

667
00:35:41,525 --> 00:35:45,285
Speaker 4:  light, the kitchen is the wrong color. And I was like, this is victory. I'm

668
00:35:45,285 --> 00:35:48,405
Speaker 4:  getting divorced now, but this is victory. The kitchen is the wrong color.

669
00:35:48,405 --> 00:35:51,125
Speaker 4:  Like the, the lights are warm in the morning. And she's like, why is it so

670
00:35:51,125 --> 00:35:54,805
Speaker 4:  orange in here? And I was like, I've won and I've also lost in like equal

671
00:35:54,805 --> 00:35:58,765
Speaker 4:  measure. Yep. So it's true that people like it when things just sort

672
00:35:58,765 --> 00:36:02,525
Speaker 4:  of like happen the right way at the right time. Sure. And I think most people

673
00:36:02,525 --> 00:36:06,285
Speaker 4:  cannot express that in structured if then statements.

674
00:36:06,415 --> 00:36:09,885
Speaker 4:  Right? Like if I come home between these times,

675
00:36:10,675 --> 00:36:14,365
Speaker 4:  turn on lights when garage opens is people

676
00:36:14,665 --> 00:36:15,485
Speaker 4:  do not speak that way.

677
00:36:15,725 --> 00:36:18,845
Speaker 5:  And going through every single little thing in your home and having to create

678
00:36:18,845 --> 00:36:20,885
Speaker 5:  an, if that statement is just really tedious.

679
00:36:21,145 --> 00:36:24,765
Speaker 4:  But you can say, when I get home, turn the lights on and Alexa figures out

680
00:36:24,765 --> 00:36:28,605
Speaker 4:  how to script that for you. That I think is very powerful. Yes. The, the

681
00:36:28,715 --> 00:36:32,685
Speaker 4:  jump is getting people to even understand that this is now

682
00:36:32,845 --> 00:36:36,765
Speaker 4:  a thing you can ask for. And then delivering it in a way

683
00:36:36,765 --> 00:36:40,205
Speaker 4:  that is consistently good enough that they, they tell their friends about

684
00:36:40,205 --> 00:36:43,205
Speaker 4:  it and then their friends buy Alexa and a bunch of smart lights and like,

685
00:36:43,525 --> 00:36:46,685
Speaker 4:  I don't know about any of that. Right. Like the comparison that I have to,

686
00:36:46,685 --> 00:36:49,925
Speaker 4:  that is like, I keep talking, I always talk about the local news test. Okay.

687
00:36:50,075 --> 00:36:53,525
Speaker 4:  Like what piece of technology will like break through on the local news

688
00:36:54,145 --> 00:36:57,045
Speaker 4:  And like the first iPhone was like, look at this, you could pinch to Zoom

689
00:36:57,185 --> 00:37:00,365
Speaker 4:  and like that was all you needed. And then they sold all the iPhones. This

690
00:37:00,365 --> 00:37:03,685
Speaker 4:  one's like, here's what you do, you buy this weird screen, it can talk to

691
00:37:03,685 --> 00:37:07,005
Speaker 4:  you like a person and tell you stories. Also you need to change all of the

692
00:37:07,005 --> 00:37:10,205
Speaker 4:  light bulbs in your ass. And it's like, well this is just, what are we doing?

693
00:37:10,425 --> 00:37:10,645
Speaker 4:  And

694
00:37:10,645 --> 00:37:13,405
Speaker 5:  To your point, you know what that thing was the first time around with Alexa

695
00:37:13,585 --> 00:37:16,725
Speaker 5:  was music. Yeah, yeah. Was you can have it play music just by asking for

696
00:37:16,725 --> 00:37:19,245
Speaker 5:  It was like, oh that's crazy. That was, that was the breakthrough thing.

697
00:37:19,245 --> 00:37:22,805
Speaker 5:  Yeah. Yeah. And I, I think everybody has wanted the smart home to be that

698
00:37:22,835 --> 00:37:26,805
Speaker 5:  next thing and it hasn't been. But but so

699
00:37:26,805 --> 00:37:29,805
Speaker 5:  now the question is like, if you've made it easier to the point where you

700
00:37:29,805 --> 00:37:33,565
Speaker 5:  can just do this as quickly as asking for it,

701
00:37:33,565 --> 00:37:35,125
Speaker 5:  like maybe it becomes that thing.

702
00:37:35,195 --> 00:37:38,605
Speaker 4:  Yeah. And I do think there are an awful lot of people out there who have

703
00:37:38,605 --> 00:37:42,405
Speaker 4:  bought gov, light strips or weird smart bulbs.

704
00:37:42,435 --> 00:37:46,365
Speaker 4:  There's an awful lot of smart locks out there. Like some of this

705
00:37:46,365 --> 00:37:49,965
Speaker 4:  stuff is ready to go. Yeah. And to be linked together in automations like

706
00:37:49,965 --> 00:37:53,885
Speaker 4:  this. And I like, you know, AI is good at coding

707
00:37:53,945 --> 00:37:56,285
Speaker 4:  and like really what we're talking about is like write a little script for

708
00:37:56,285 --> 00:38:00,245
Speaker 4:  me. Okay. Like there some of this all

709
00:38:00,245 --> 00:38:03,165
Speaker 4:  clicks together but I'm still just at like, you have to get people to even

710
00:38:03,395 --> 00:38:03,845
Speaker 4:  want it.

711
00:38:04,605 --> 00:38:08,565
Speaker 5:  I also, I cannot stop thinking about how important cameras are to all

712
00:38:08,565 --> 00:38:12,125
Speaker 5:  of this and how many feelings this is going to make people feel about cameras.

713
00:38:12,315 --> 00:38:15,645
Speaker 5:  Like one of the demos was being able to ask

714
00:38:16,665 --> 00:38:19,445
Speaker 5:  if somebody had walked the dog recently I think. And it'll actually like

715
00:38:19,605 --> 00:38:22,365
Speaker 5:  comb back through your security camera data to see, oh no

716
00:38:22,525 --> 00:38:25,565
Speaker 4:  Actually I know how that one works. There's another demo that was scarier

717
00:38:25,565 --> 00:38:26,485
Speaker 4:  from the camera sense.

718
00:38:26,625 --> 00:38:28,885
Speaker 5:  Oh okay. Tell me more. You were there. I wasn't there. Let

719
00:38:28,885 --> 00:38:31,405
Speaker 4:  Me know. Someone has walked the dog recently is

720
00:38:32,585 --> 00:38:36,005
Speaker 4:  that's just Amazon owns a bunch of stuff including Ring. Yeah. So If you

721
00:38:36,005 --> 00:38:39,805
Speaker 4:  have ring cameras today without any of this Alexa stuff, it will detect

722
00:38:39,915 --> 00:38:43,765
Speaker 4:  pets, it will detect people, it will detect packages. That's a service that

723
00:38:43,765 --> 00:38:46,725
Speaker 4:  you have to get from Ring as part of the Ring service. But that's just a

724
00:38:46,725 --> 00:38:50,565
Speaker 4:  ring video search product that Alexa as an API can just

725
00:38:50,565 --> 00:38:54,385
Speaker 4:  call. So that wasn't Alexa doing any of that. That was just

726
00:38:54,385 --> 00:38:57,345
Speaker 4:  ring. Okay. And it was just being expressed through the Echo show.

727
00:38:57,475 --> 00:39:01,465
Speaker 5:  Still a little creepy how accessible you've made the archive

728
00:39:01,465 --> 00:39:04,305
Speaker 5:  of that recording. But, but sure. Fair enough. What was the other demo?

729
00:39:04,575 --> 00:39:07,905
Speaker 4:  It's the same accessible ness as it is in the Ring app today.

730
00:39:08,415 --> 00:39:12,225
Speaker 4:  Sure. Right. Like if especially 'cause they they already owned it.

731
00:39:12,695 --> 00:39:12,985
Speaker 4:  Yeah,

732
00:39:13,055 --> 00:39:13,945
Speaker 5:  Yeah. No, that's, that's

733
00:39:13,945 --> 00:39:16,625
Speaker 4:  Fair. Like, like the problems with ring accessibility are like, and then

734
00:39:16,625 --> 00:39:19,585
Speaker 4:  they send it to the cops. Like that's a different Right there is that but

735
00:39:19,585 --> 00:39:23,065
Speaker 4:  like inside of your ring archive, like it gets indexed and

736
00:39:23,065 --> 00:39:26,225
Speaker 4:  searchable. The one you're thinking about I believe

737
00:39:27,005 --> 00:39:30,305
Speaker 4:  is when you see my daughter play this music

738
00:39:30,805 --> 00:39:32,825
Speaker 4:  and that one is very creepy to me.

739
00:39:33,085 --> 00:39:37,065
Speaker 5:  Oh, that is creepy. I don't like that at all. Yep. And that thing is

740
00:39:37,065 --> 00:39:40,565
Speaker 5:  like, again, so much of what we're describing works

741
00:39:40,905 --> 00:39:44,605
Speaker 5:  way better If you have cameras, If you have lots of cameras

742
00:39:44,675 --> 00:39:47,525
Speaker 5:  that do lots of things really convincingly like the

743
00:39:48,955 --> 00:39:52,005
Speaker 5:  play music or turn on the lights when I get home thing. Like

744
00:39:52,785 --> 00:39:56,365
Speaker 5:  you can do that a bunch of ways, but the actual cleanest and most reliable

745
00:39:56,465 --> 00:40:00,085
Speaker 5:  way to do that, to know that it's you coming home is cameras

746
00:40:00,705 --> 00:40:04,685
Speaker 5:  and this, this, this system in general a requires a

747
00:40:04,795 --> 00:40:08,405
Speaker 5:  vast amount of data to really work. And one of the things that Panos talked

748
00:40:08,405 --> 00:40:11,485
Speaker 5:  about a bunch and that Amazon is making very clear is like it's going to

749
00:40:11,505 --> 00:40:15,085
Speaker 5:  ask and remember a lot of information about you. You can forward

750
00:40:15,145 --> 00:40:19,005
Speaker 5:  emails, you can send, IM like, Alexa would like to know every single thing

751
00:40:19,005 --> 00:40:22,285
Speaker 5:  that happens to you all the time. Always everywhere. All the time. And like

752
00:40:22,285 --> 00:40:25,605
Speaker 5:  on the one hand, fine, Google has that data anyway just by virtue of like

753
00:40:25,665 --> 00:40:29,205
Speaker 5:  we are all alive. But Amazon wants it too.

754
00:40:30,275 --> 00:40:33,415
Speaker 5:  And it wants your camera data and the more data you give it, the better this

755
00:40:33,415 --> 00:40:37,375
Speaker 5:  system will be. And that, that linear scale

756
00:40:37,435 --> 00:40:40,615
Speaker 5:  is going to be deeply fascinating to see people try to walk through.

757
00:40:41,005 --> 00:40:44,015
Speaker 4:  It's just so funny because I can tell that you have not tried to set up any

758
00:40:44,015 --> 00:40:47,335
Speaker 4:  smart home automations. Do you know what the best way to know that your home

759
00:40:47,335 --> 00:40:51,255
Speaker 4:  is? Amazon has no access to it. It's when your fucking phone

760
00:40:51,255 --> 00:40:52,455
Speaker 4:  connects to your wifi network.

761
00:40:52,835 --> 00:40:54,575
Speaker 5:  Amazon owns Euro so Sure they do.

762
00:40:55,235 --> 00:40:59,155
Speaker 4:  Oh that's interesting. But that's like too creepy. That's like one

763
00:40:59,155 --> 00:41:03,035
Speaker 4:  step too creepy. But like that is how a bunch of home kit automation.

764
00:41:03,105 --> 00:41:03,395
Speaker 4:  Sure.

765
00:41:03,395 --> 00:41:04,075
Speaker 5:  No, you're right. That's

766
00:41:04,075 --> 00:41:07,835
Speaker 4:  Good point. Right. So like when you do, if you've ever set up a home kit

767
00:41:07,835 --> 00:41:11,435
Speaker 4:  automation. Yeah. Right. There's run this when no one's home or just I'm

768
00:41:11,435 --> 00:41:15,115
Speaker 4:  home or anyone is home and all it's looking for is whether various

769
00:41:15,265 --> 00:41:18,915
Speaker 4:  devices signed in I iCloud or on your network. Hmm. You can do, I think there's

770
00:41:18,915 --> 00:41:21,675
Speaker 4:  a little bit of geofencing in there, but it's, it's the network connection

771
00:41:21,675 --> 00:41:25,315
Speaker 4:  that like tells you you're home. And

772
00:41:25,665 --> 00:41:29,595
Speaker 4:  it's funny 'cause the other day my wife and I were both

773
00:41:29,615 --> 00:41:32,995
Speaker 4:  not home and Max came home and none of the lights turned on

774
00:41:33,435 --> 00:41:36,005
Speaker 4:  because she doesn't have an iCloud device. Ooh.

775
00:41:36,545 --> 00:41:37,805
Speaker 6:  She doesn't know how to turn the lights on.

776
00:41:37,825 --> 00:41:40,245
Speaker 4:  So she No, she turned on the lights, but they were on, I would say wrong.

777
00:41:40,265 --> 00:41:41,125
Speaker 4:  Go. Well Max is

778
00:41:41,125 --> 00:41:42,165
Speaker 5:  Just sitting in the dark.

779
00:41:42,925 --> 00:41:45,205
Speaker 4:  I was like, why are the lights wrong? Is actually what I

780
00:41:45,205 --> 00:41:47,645
Speaker 5:  Said. She's like, now I need an iPhone. Yeah.

781
00:41:47,645 --> 00:41:51,285
Speaker 4:  Basically. But it's really interesting to think, oh

782
00:41:51,365 --> 00:41:54,485
Speaker 4:  they'll, they'll link Arrow into this and know like network states of devices.

783
00:41:55,395 --> 00:41:59,165
Speaker 4:  There's a lot they can do. Did was this compelling to you?

784
00:41:59,675 --> 00:42:03,565
Speaker 6:  Yeah, in some ways. I mean the fact that the Echoes

785
00:42:03,565 --> 00:42:07,085
Speaker 6:  were sort of the first ways that people interacted with any form of

786
00:42:07,085 --> 00:42:10,845
Speaker 6:  voice-based ai Yeah. I think was interesting to me because Amazon was so

787
00:42:10,845 --> 00:42:14,645
Speaker 6:  early to that and then they were so late to everything else. And so

788
00:42:15,035 --> 00:42:19,005
Speaker 6:  this like dream of my mother can set up something and come home and start

789
00:42:19,005 --> 00:42:22,965
Speaker 6:  talking to her smart speaker and it actually does things instead of

790
00:42:22,965 --> 00:42:26,765
Speaker 6:  me having to teach her voice lessons or like Yeah.

791
00:42:27,085 --> 00:42:30,685
Speaker 6:  Specific lessons on how to talk to the AI is a big thing.

792
00:42:31,145 --> 00:42:34,765
Speaker 6:  The automations I if they work is going to be the giant

793
00:42:35,165 --> 00:42:39,125
Speaker 6:  question. Yeah. I would love it If you could ask it to have an,

794
00:42:39,265 --> 00:42:43,125
Speaker 6:  an automation and then it just randomly it creates a bunch that you

795
00:42:43,125 --> 00:42:47,005
Speaker 6:  can pick from. Yeah. Because I just, I don't know. I understand some

796
00:42:47,125 --> 00:42:50,365
Speaker 6:  people probably just want things to be made for them and just be developed,

797
00:42:50,665 --> 00:42:54,165
Speaker 6:  but having no, no say in any of the development of these things and just

798
00:42:54,165 --> 00:42:57,845
Speaker 6:  letting it do things for you just feels very sketch almost as sketch

799
00:42:57,985 --> 00:43:01,525
Speaker 6:  as the pickup my friend from JFK, you know what I mean? I don't know if it

800
00:43:01,525 --> 00:43:03,165
Speaker 6:  will work. This is the thing. That's

801
00:43:03,165 --> 00:43:06,885
Speaker 5:  One reason that I think pushing really hard towards screen

802
00:43:06,885 --> 00:43:09,845
Speaker 5:  devices is really smart for Amazon. Yes. Because it just lets it do that

803
00:43:09,845 --> 00:43:13,005
Speaker 5:  kind of stuff where it's gonna be able to be like, Hey, here's the thing

804
00:43:13,005 --> 00:43:16,945
Speaker 5:  I was gonna do. Make sure this is make sure we're cool. Like

805
00:43:16,945 --> 00:43:20,785
Speaker 5:  is this, is this what you want? Is this your grocery order? Like do you want

806
00:43:20,785 --> 00:43:24,465
Speaker 5:  this or this? Like, it's the kind of sort of quick back and forth.

807
00:43:24,885 --> 00:43:25,865
Speaker 6:  Did they show any of that?

808
00:43:26,635 --> 00:43:30,215
Speaker 4:  Yes, they did. The grocery demo in particular, one

809
00:43:30,475 --> 00:43:34,015
Speaker 4:  was like so far from what anyone would ever do, but also the coolest one.

810
00:43:34,085 --> 00:43:37,815
Speaker 4:  Yeah. So they were like, go to Amazon Fresh, I wanna do this

811
00:43:37,815 --> 00:43:41,615
Speaker 4:  recipe, here's ingest. Like I wanna make these cookies and start filling

812
00:43:41,615 --> 00:43:44,775
Speaker 4:  it out. And then he was talking to it

813
00:43:45,345 --> 00:43:48,775
Speaker 4:  while he was like clicking quantities on the screen. Yeah. And so he was

814
00:43:48,775 --> 00:43:52,575
Speaker 4:  adjusting one row of data while it was like adding this. That's kind of so,

815
00:43:52,675 --> 00:43:56,535
Speaker 4:  and it was just like very cool, like multimodal.

816
00:43:56,715 --> 00:43:57,815
Speaker 6:  Are people gonna do that?

817
00:43:58,375 --> 00:43:59,815
Speaker 4:  I I don't, I have no idea. It's a

818
00:43:59,815 --> 00:44:01,015
Speaker 6:  Big question. Gen

819
00:44:01,175 --> 00:44:04,615
Speaker 5:  Tuy will and no one else. Yeah. But that is the kind of interaction

820
00:44:04,885 --> 00:44:08,455
Speaker 5:  that If you can get it makes all of this stuff work better. Right. Right.

821
00:44:08,615 --> 00:44:10,975
Speaker 5:  'cause it's like the, the first time you ask a question and you get like

822
00:44:10,975 --> 00:44:14,375
Speaker 5:  a 600 word long spoken answer, you're like, this is nothing.

823
00:44:15,215 --> 00:44:15,735
Speaker 5:  I hate this.

824
00:44:15,995 --> 00:44:17,895
Speaker 6:  That's the part that it needs to fix. Yeah.

825
00:44:17,895 --> 00:44:20,815
Speaker 5:  But then it's, and and this is the thing, I, I've always gotten a kick outta

826
00:44:20,815 --> 00:44:23,895
Speaker 5:  this in, in like sci-fi and stuff. Like, they always just gravitate towards,

827
00:44:24,035 --> 00:44:27,135
Speaker 5:  let me show you. Right. And then it's like a put it put, put it on a screen

828
00:44:27,235 --> 00:44:30,815
Speaker 5:  and I can look at it, which is like better movie making than listening to

829
00:44:30,815 --> 00:44:34,365
Speaker 5:  something talk for four minutes. But it's also just better user experience.

830
00:44:34,365 --> 00:44:36,845
Speaker 5:  It's like, do you want this or this? And I don't have to show them or I don't

831
00:44:36,845 --> 00:44:37,925
Speaker 5:  have to read them to you. I can show them

832
00:44:37,925 --> 00:44:41,285
Speaker 6:  To you. Right. Famously, the Google Home Minis that every carrier on the

833
00:44:41,285 --> 00:44:45,165
Speaker 6:  planet throws 15 of you at at Christmas. Every single time you

834
00:44:45,165 --> 00:44:48,365
Speaker 6:  ask it, what's the weather? Or turn the light on it goes. Just so you know,

835
00:44:48,585 --> 00:44:52,125
Speaker 6:  in the morning we can also do this. Just ask me what to do every single time.

836
00:44:52,125 --> 00:44:55,525
Speaker 6:  Every time. And I just want, okay, bing, you know, that's it.

837
00:44:55,625 --> 00:44:58,245
Speaker 5:  Or just turn the light on. What If you didn't talk? And then I knew it worked

838
00:44:58,245 --> 00:44:59,605
Speaker 5:  because the light was on. What

839
00:44:59,605 --> 00:45:03,125
Speaker 6:  If you didn't talk? Yeah. That's a visual cue. I, I think as long as you

840
00:45:03,125 --> 00:45:06,885
Speaker 6:  have some sort of cue, which is like why the screen is important, especially

841
00:45:06,885 --> 00:45:10,245
Speaker 6:  when you're having it do these tasks that you cannot see because they're

842
00:45:10,395 --> 00:45:12,805
Speaker 6:  APIs or because they're like age agentic or whatever.

843
00:45:13,305 --> 00:45:16,525
Speaker 4:  Oh. This is one of the coolest parts of the whole thing. They call them lexicons.

844
00:45:16,845 --> 00:45:17,365
Speaker 6:  I do like that.

845
00:45:17,785 --> 00:45:20,845
Speaker 4:  So the little blue bar on the bottom of the screen turns into like, line

846
00:45:20,845 --> 00:45:24,445
Speaker 4:  animations told me that he wants sort to be like 200, but now they're 33

847
00:45:24,445 --> 00:45:28,325
Speaker 4:  because he's approving all of them individually. Okay. Which is

848
00:45:28,325 --> 00:45:31,965
Speaker 4:  great. That's cool. I love it. That's good. They're very cute. And then Alexa

849
00:45:31,965 --> 00:45:35,765
Speaker 4:  just sort of picks whatever kind it wants. Mm. Like it turns into like a

850
00:45:35,765 --> 00:45:39,565
Speaker 4:  little line drawing of music notes or like a picture of Oh, if it thinks

851
00:45:39,565 --> 00:45:42,445
Speaker 4:  it's arguing with you, it shows you a ping pong paddle going back and forth.

852
00:45:43,765 --> 00:45:44,685
Speaker 4:  'cause you're, you know, I

853
00:45:44,685 --> 00:45:45,525
Speaker 6:  Don't wanna argue with

854
00:45:45,795 --> 00:45:47,525
Speaker 4:  Some fear. It's all this is great. Like,

855
00:45:47,725 --> 00:45:49,685
Speaker 5:  I hate that. I really like that. But I really like that

856
00:45:50,075 --> 00:45:53,885
Speaker 4:  It's, it was like easily the cutest part of the whole thing. It, and

857
00:45:53,885 --> 00:45:57,805
Speaker 4:  so they're, they're trying to show these interactions. Look, we gotta

858
00:45:57,805 --> 00:46:00,725
Speaker 4:  get the stuff, like I said, but it, you'll listen to this on what Friday

859
00:46:01,145 --> 00:46:04,995
Speaker 4:  or sometime after that On Tuesday. POTUS will be on the Coter Monday.

860
00:46:05,305 --> 00:46:09,115
Speaker 4:  Even more about the Neo Alexa and how it works. There's a bunch of

861
00:46:09,275 --> 00:46:11,995
Speaker 4:  questions about what models it's using when, how they're managing all that

862
00:46:11,995 --> 00:46:13,755
Speaker 4:  cost. Andro is involved. Yeah.

863
00:46:14,235 --> 00:46:15,715
Speaker 6:  Which they're a major investor in, right? Yeah.

864
00:46:15,715 --> 00:46:18,035
Speaker 4:  They're a major investor and they built their own model called Novo, which

865
00:46:18,035 --> 00:46:19,075
Speaker 4:  they're using. Does

866
00:46:19,075 --> 00:46:20,955
Speaker 6:  Anyone know anything about the Novo model? The

867
00:46:20,955 --> 00:46:23,555
Speaker 4:  Rumor is that they were trying to build this for a long time and it was delayed.

868
00:46:23,555 --> 00:46:24,155
Speaker 6:  Yeah, I remember that.

869
00:46:24,255 --> 00:46:26,875
Speaker 4:  And then they had Philanthropics swoop in to help them.

870
00:46:27,395 --> 00:46:29,635
Speaker 5:  Hmm. And we should say we should take a break. We've been talking about this

871
00:46:29,635 --> 00:46:30,395
Speaker 5:  for way too long, but

872
00:46:32,215 --> 00:46:36,155
Speaker 5:  all evidence and reporting so far suggests that

873
00:46:36,155 --> 00:46:39,275
Speaker 5:  Alexa plus is super late and sucks. And so

874
00:46:40,065 --> 00:46:44,035
Speaker 5:  this thing is not shipping until at least several weeks from

875
00:46:44,055 --> 00:46:48,035
Speaker 5:  now. We've seen a few demos that Amazon did as

876
00:46:48,115 --> 00:46:50,635
Speaker 5:  I wasn't at the event, but everything I understand is it was all super on

877
00:46:50,635 --> 00:46:54,435
Speaker 5:  rails. It's all canned. So like, I actually think the big picture ideas

878
00:46:54,545 --> 00:46:58,275
Speaker 5:  here from Amazon are both really ambitious and pretty close to

879
00:46:58,285 --> 00:47:02,115
Speaker 5:  Right. And If you made me bet right now, I would say I bet

880
00:47:02,115 --> 00:47:05,875
Speaker 5:  it's not any good. Yeah. Yeah. But I sincerely hope I'm wrong and we will

881
00:47:05,875 --> 00:47:06,475
Speaker 5:  see. I'll be better.

882
00:47:06,695 --> 00:47:09,915
Speaker 4:  I'm very curious, again, to underline what David is saying,

883
00:47:10,575 --> 00:47:13,715
Speaker 4:  all of the demos were canned. Yeah. We were not allowed to just like freely

884
00:47:13,715 --> 00:47:15,275
Speaker 4:  talk to this thing. Mm. So, who knows?

885
00:47:15,415 --> 00:47:19,075
Speaker 5:  And for months, like I, I would, I would also remind you that this thing

886
00:47:19,435 --> 00:47:23,395
Speaker 5:  launched the first time 18 months ago, and Dave

887
00:47:23,545 --> 00:47:27,355
Speaker 5:  Limp, we've had a whole regime change on this team

888
00:47:27,565 --> 00:47:30,605
Speaker 5:  since this thing launched. The first, first time. Amazon has been talking

889
00:47:30,605 --> 00:47:33,965
Speaker 5:  about this for a long time. And for, I mean, a year, the, the

890
00:47:34,195 --> 00:47:37,125
Speaker 5:  reporting and everything we've been hearing has been that this thing is not

891
00:47:37,125 --> 00:47:40,765
Speaker 5:  very good and it has been massively delayed. And I think

892
00:47:40,775 --> 00:47:43,525
Speaker 5:  there is a, there is an argument to be made that Amazon is launching this

893
00:47:43,525 --> 00:47:47,485
Speaker 5:  now because it had to, not because it's ready. And I hope

894
00:47:47,505 --> 00:47:50,525
Speaker 5:  I'm wrong and I'm very curious to try this thing. But like, what

895
00:47:50,525 --> 00:47:53,925
Speaker 6:  Is the primary pressure, do you think? Like who, who are they worried about

896
00:47:54,145 --> 00:47:57,125
Speaker 6:  coming after them? Because Google's not doing anything age agentic right

897
00:47:57,125 --> 00:48:00,445
Speaker 6:  now. Google's smart Home is still Google Assistant, which is Yeah. The artist

898
00:48:00,445 --> 00:48:03,005
Speaker 6:  formerly known as, you know. And it's not really doing anything.

899
00:48:04,205 --> 00:48:07,445
Speaker 4:  I think, I think everybody's still worried about ti If you find yourself

900
00:48:07,445 --> 00:48:11,285
Speaker 4:  talking to advanced voice mode instead of Alexa. Yeah. You're not switching

901
00:48:11,285 --> 00:48:11,725
Speaker 4:  back. Yep.

902
00:48:11,725 --> 00:48:15,165
Speaker 5:  Yeah. And operator is out there. Google is doing stuff like Project Mariner

903
00:48:15,165 --> 00:48:15,565
Speaker 5:  is real

904
00:48:16,005 --> 00:48:18,405
Speaker 4:  Operator is not out there. Yeah. Operator's out there in the way that like,

905
00:48:19,235 --> 00:48:23,005
Speaker 4:  like a, like a baby goat is out there just like stumbling over shit. Like

906
00:48:23,005 --> 00:48:23,485
Speaker 4:  it doesn't matter.

907
00:48:23,885 --> 00:48:27,485
Speaker 5:  I used Operator today. You know what, what, what I can't use today is Alexa.

908
00:48:28,115 --> 00:48:28,965
Speaker 6:  Yeah. What did you use

909
00:48:28,965 --> 00:48:32,925
Speaker 5:  It for? I used it as a test to see if it could

910
00:48:32,925 --> 00:48:34,885
Speaker 5:  buy me something on Amazon and it could not.

911
00:48:36,155 --> 00:48:40,125
Speaker 4:  Baby goat baby. I'm saying Yes, it is good. There's a toddler out

912
00:48:40,125 --> 00:48:43,165
Speaker 4:  in the world who's just falling over itself all the time.

913
00:48:44,325 --> 00:48:47,245
Speaker 4:  I think they're a little, probably a little worried about Apple. Right. That's

914
00:48:47,245 --> 00:48:51,205
Speaker 4:  the larger context to this is Apple's way of doing Agentic stuff

915
00:48:51,225 --> 00:48:54,685
Speaker 4:  is gonna be app intense with Siri on the phone. It has perfect access to

916
00:48:54,685 --> 00:48:58,005
Speaker 4:  all those apps. Those developers can get strong armed into playing ball.

917
00:48:58,115 --> 00:49:02,045
Speaker 4:  Apple's very good at that. And particular Apple's gonna do

918
00:49:02,045 --> 00:49:04,085
Speaker 4:  some iPad on a robot arm in their ass.

919
00:49:04,085 --> 00:49:04,925
Speaker 6:  Right. Like, that is true.

920
00:49:05,795 --> 00:49:09,325
Speaker 4:  There's a lot there that is gonna be difficult. Can Apple actually pull any

921
00:49:09,325 --> 00:49:13,285
Speaker 4:  of that off? We don't know. Siri is getting worse by the day. Somehow.

922
00:49:14,845 --> 00:49:18,745
Speaker 4:  I think they, they just like needed to put it, put the

923
00:49:18,745 --> 00:49:22,705
Speaker 4:  stake in the ground. Yeah. And say, actually we put l like AI

924
00:49:22,705 --> 00:49:26,145
Speaker 4:  capabilities into Alexa in the way that everybody wanted us to. Yeah.

925
00:49:26,325 --> 00:49:29,785
Speaker 5:  And Panas has said this to us before, Eli, but I think I I suspect probably

926
00:49:29,785 --> 00:49:33,665
Speaker 5:  said it to you on the decoder too, is like, they see this as like a

927
00:49:33,665 --> 00:49:35,545
Speaker 5:  full on platform shift. Oh

928
00:49:35,545 --> 00:49:39,265
Speaker 4:  Yeah. He, yeah. He very much said that in like the most intense panas

929
00:49:39,365 --> 00:49:39,585
Speaker 4:  way.

930
00:49:39,635 --> 00:49:43,545
Speaker 5:  There is a sense now that missing, missing this would be like missing mobile

931
00:49:43,545 --> 00:49:47,385
Speaker 5:  15 years ago. Yeah. Right. In the sense that it, like, it, it crowned a

932
00:49:47,385 --> 00:49:50,905
Speaker 5:  generation of trillion dollar companies and killed everybody else. Yeah.

933
00:49:50,905 --> 00:49:53,865
Speaker 5:  And there, there is right or wrong real belief in the industry that this

934
00:49:53,865 --> 00:49:57,785
Speaker 5:  is that moment again. And there is a sense that you cannot afford to be

935
00:49:57,785 --> 00:49:58,905
Speaker 5:  late at all because

936
00:51:06,675 --> 00:51:10,445
Speaker 6:  They've got 200 worldwide, 200 million. They just need to keep

937
00:51:10,445 --> 00:51:14,365
Speaker 6:  growing that number because it accelerated very fast at first. Yeah. It's

938
00:51:14,565 --> 00:51:17,205
Speaker 6:  starting to peter off, even though it's still one of the most popular service

939
00:51:17,225 --> 00:51:17,685
Speaker 6:  in the world.

940
00:51:19,605 --> 00:51:23,445
Speaker 6:  I, I don't know who the user is that is like, I don't

941
00:51:23,445 --> 00:51:26,405
Speaker 6:  have Prime, but I want Alexa, LLM

942
00:51:27,785 --> 00:51:29,845
Speaker 6:  who is, who are you? I don't know who you

943
00:51:29,845 --> 00:51:31,445
Speaker 4:  Are. You know us. Let us know. Maybe

944
00:51:31,505 --> 00:51:35,045
Speaker 6:  The like really hardcore AI heads that just want to try everything.

945
00:51:35,545 --> 00:51:39,445
Speaker 6:  But I also don't know I they wouldn't have Prime. We'll find out, I

946
00:51:39,445 --> 00:51:40,685
Speaker 6:  guess, eventually. Yeah.

947
00:51:40,995 --> 00:51:44,925
Speaker 4:  Yeah. But it, they, if anyone can do it, it's Amazon. 'cause they have

948
00:51:44,925 --> 00:51:48,085
Speaker 4:  scale, if anyone can make the platform shift happen. Yeah. Because they already

949
00:51:48,085 --> 00:51:51,645
Speaker 4:  have the microphones in everybody's house. Yeah. They've already like, and

950
00:51:51,645 --> 00:51:53,085
Speaker 4:  they own that whole platform tip to tail.

951
00:51:53,265 --> 00:51:56,525
Speaker 6:  It was probably a way for them to say it's $20 because everyone else is $20.

952
00:51:56,705 --> 00:52:00,605
Speaker 6:  And in that way they're, they're kind of saying we're just as good in

953
00:52:00,605 --> 00:52:03,845
Speaker 6:  every way. But you can get it If you have Prime for cheaper. Yeah.

954
00:52:04,115 --> 00:52:07,845
Speaker 4:  Well, I'm, I'm excited to see just how chaotic it is.

955
00:52:08,775 --> 00:52:12,765
Speaker 4:  We'll see again. And next week on Decoder Panos answers a bunch more questions

956
00:52:13,265 --> 00:52:17,045
Speaker 4:  in like, classically intense Panos in that way. It was, it was a fun conversation.

957
00:52:17,235 --> 00:52:21,125
Speaker 6:  Also, we finally get to do the assistant like battles between

958
00:52:21,125 --> 00:52:24,805
Speaker 6:  all of the major assistants. Well, once Siri is actually like,

959
00:52:24,905 --> 00:52:25,365
Speaker 6:  out out.

960
00:52:25,825 --> 00:52:26,845
Speaker 4:  So never, never.

961
00:52:27,005 --> 00:52:27,125
Speaker 5:  I

962
00:53:20,955 --> 00:53:23,995
Speaker 4:  just us listing things we asked Siri to do that they cannot do. It'd

963
00:53:23,995 --> 00:53:26,045
Speaker 5:  Be the longest VERGE cast episode in history

964
00:53:26,155 --> 00:53:28,645
Speaker 6:  That used to be able to do and to no longer do.

965
00:53:29,565 --> 00:53:33,405
Speaker 4:  I asked it how many days until something the other day and it a, it was like,

966
00:53:33,405 --> 00:53:35,725
Speaker 4:  do you want me to ask Chad gt? It's rough.

967
00:53:36,025 --> 00:53:38,445
Speaker 6:  And Chad GT famously is not good at math. Yeah.

968
00:53:38,685 --> 00:53:40,325
Speaker 4:  I was like, this is the most powerful phone in history.

969
00:53:40,515 --> 00:53:41,725
Speaker 6:  Nice. Like

970
00:53:44,325 --> 00:53:47,085
Speaker 4:  Speaking of iPhones, we should probably talk about the iPhone 16 E at some

971
00:53:47,085 --> 00:53:50,365
Speaker 4:  point. But actually I want to talk about the Sigma bf this camera.

972
00:53:50,765 --> 00:53:54,325
Speaker 5:  I just wanna say it's very telling that the iPhone 16 E is handily

973
00:53:55,065 --> 00:53:58,885
Speaker 5:  the second most interesting gadget that came out this week. Which in part

974
00:53:58,955 --> 00:54:00,285
Speaker 5:  says something about, I would

975
00:54:00,285 --> 00:54:03,325
Speaker 4:  Say third, I just think we're like legally obligated to be like there was

976
00:54:03,325 --> 00:54:03,845
Speaker 4:  a new wifi iPhone.

977
00:54:04,005 --> 00:54:07,085
Speaker 5:  You're right. It is. It is at least third. It might be, it might be fourth

978
00:54:07,175 --> 00:54:10,525
Speaker 5:  given some of the framework stuff, but it's certainly not first. And I think

979
00:54:10,725 --> 00:54:11,965
Speaker 5:  Sigma is clearly, first

980
00:54:12,385 --> 00:54:15,645
Speaker 4:  My proposed headline for Allison's review was no one should care about this

981
00:54:15,645 --> 00:54:19,565
Speaker 4:  phone. They didn't, they didn't go with it. She did go with it's fine and

982
00:54:19,565 --> 00:54:23,365
Speaker 4:  give it a seven, which is the most seven headline in the

983
00:54:23,365 --> 00:54:24,725
Speaker 4:  history of headlines. Yep.

984
00:54:25,445 --> 00:54:26,805
Speaker 6:  I still dunno who's gonna buy this thing.

985
00:54:27,505 --> 00:54:29,045
Speaker 4:  So what, what's going on here

986
00:54:29,395 --> 00:54:30,965
Speaker 6:  With the, the camera or the phone?

987
00:54:31,425 --> 00:54:34,725
Speaker 4:  Oh well I still dunno who's gonna buy this thing. Yeah. Actually applies

988
00:54:34,725 --> 00:54:38,005
Speaker 4:  to both. Let's start That's extreme. That is true. Let's start that.

989
00:54:38,145 --> 00:54:38,685
Speaker 6:  That's true.

990
00:54:40,015 --> 00:54:42,165
Speaker 4:  Let's start with the camera. 'cause it's vastly more interesting than the

991
00:54:42,165 --> 00:54:45,965
Speaker 4:  iPhone. Okay. Then we can come back to the iPhone Sigma BF is, it's just

992
00:54:46,085 --> 00:54:49,085
Speaker 4:  a beautiful camera. Right? And it seems like no one should buy it.

993
00:54:49,155 --> 00:54:53,085
Speaker 6:  Yeah. There's a new camera from Sigma. It is a Japanese camera brand that

994
00:54:53,085 --> 00:54:56,605
Speaker 6:  has made famously extremely weird cameras. Yeah. They have done very weird

995
00:54:56,605 --> 00:54:59,765
Speaker 6:  things with sensors. They made something called a phon sensor, which has

996
00:55:00,155 --> 00:55:03,925
Speaker 6:  different pixels on the color filter array all on the same pixel. You get

997
00:55:03,925 --> 00:55:06,325
Speaker 6:  better quality. They did not do that with this camera because they got rid

998
00:55:06,325 --> 00:55:08,245
Speaker 6:  of it a while ago. And everyone is sad about that.

999
00:55:08,725 --> 00:55:11,245
Speaker 5:  Sigma stuff is generally pretty good, right? Like it's a, it's yes, they're

1000
00:55:11,245 --> 00:55:13,165
Speaker 5:  weird but they make good cameras. Right. Is my impression.

1001
00:55:13,165 --> 00:55:16,365
Speaker 6:  Yes. Okay. They're weird. They're good. They're part of the LM Mount Alliance,

1002
00:55:16,845 --> 00:55:20,565
Speaker 6:  which Panasonic and Leica are also part of. So that's nice. Weirdly enough,

1003
00:55:20,625 --> 00:55:24,245
Speaker 6:  you don't really see them on the street almost ever. Yeah. Mostly because

1004
00:55:24,245 --> 00:55:27,605
Speaker 6:  they're so weird. And I think that people just go, when you're going hiking

1005
00:55:27,665 --> 00:55:31,645
Speaker 6:  in Utah, you see a hundred million of the cheapest canon camera and

1006
00:55:31,645 --> 00:55:35,205
Speaker 6:  the cheapest Nikon camera sounds right. Sigma always does weird stuff. That's

1007
00:55:35,205 --> 00:55:38,885
Speaker 6:  kind of their angle. They released a camera this week called the BF does

1008
00:55:38,885 --> 00:55:42,605
Speaker 6:  not stand for boyfriend or best friend. It stands for

1009
00:55:42,605 --> 00:55:46,405
Speaker 6:  beautiful foolishness. Really? Really, really. I love this. So

1010
00:55:47,115 --> 00:55:50,885
Speaker 6:  this is kind of like when someone says, I know that this is stupid,

1011
00:55:51,145 --> 00:55:54,885
Speaker 6:  but, and in that way it's very difficult to critique.

1012
00:55:55,625 --> 00:55:58,605
Speaker 6:  You know what I mean? It's like, there are many things about this camera

1013
00:55:58,605 --> 00:56:02,485
Speaker 6:  that I'm like, but they're like, we know that

1014
00:56:02,485 --> 00:56:06,325
Speaker 6:  it's dumb. Yeah. But here it is. Anyway. And you have to respect that in

1015
00:56:06,325 --> 00:56:10,165
Speaker 6:  a way. Right. So this is a full frame, 24 megapixel camera.

1016
00:56:10,595 --> 00:56:13,925
Speaker 6:  They tried to remove as many buttons as physically possible.

1017
00:56:14,385 --> 00:56:18,125
Speaker 6:  It is machined out of a block of aluminum they can make nine per day.

1018
00:56:19,625 --> 00:56:22,965
Speaker 6:  So it's not a high yield kit, which not that many people are gonna buy it

1019
00:56:23,060 --> 00:56:26,995
Speaker 6:  anyway, so that's probably fine. Famously Fujifilm can

1020
00:56:26,995 --> 00:56:30,795
Speaker 6:  only make 15,000 x 100 sixes per week. And that still was not enough

1021
00:56:31,155 --> 00:56:34,835
Speaker 6:  because they had over a million oders in China alone on the first day.

1022
00:56:35,055 --> 00:56:39,035
Speaker 6:  Wow. So this camera, I don't, I don't even know to say what it

1023
00:56:39,035 --> 00:56:42,715
Speaker 6:  looks like. It is just a small block of aluminum in a, in a weird way.

1024
00:56:43,935 --> 00:56:47,435
Speaker 6:  It has a LCD screen on the back that does not tilt.

1025
00:56:47,665 --> 00:56:49,955
Speaker 4:  This is my o This is actually my only complaint about this camera.

1026
00:56:50,265 --> 00:56:51,475
Speaker 6:  That it has no EVF?

1027
00:56:51,815 --> 00:56:53,275
Speaker 4:  No, the, the screen doesn't tilt.

1028
00:56:53,335 --> 00:56:55,235
Speaker 6:  Oh. Oh, okay. Well I don't,

1029
00:56:55,495 --> 00:56:58,515
Speaker 4:  And I have a very specific reason why, but that Okay. Im like, I love you.

1030
00:56:58,815 --> 00:57:01,795
Speaker 4:  I'm buying this camera. I'm mad that the screen doesn't tilt. Yeah. It's

1031
00:57:01,795 --> 00:57:04,515
Speaker 4:  a very, very minor complaint in, in the scheme of things. It's, I

1032
00:57:04,515 --> 00:57:07,435
Speaker 6:  Don't think it's that minor. Yeah. I think screens should tilt even though

1033
00:57:07,435 --> 00:57:11,235
Speaker 6:  they break easier. Yeah. It has no viewfinder. That is also

1034
00:57:11,515 --> 00:57:12,355
Speaker 6:  horrible in my opinion.

1035
00:57:12,715 --> 00:57:13,395
Speaker 4:  I feel nothing about that.

1036
00:57:13,395 --> 00:57:17,355
Speaker 5:  Especially for a $2,000 camera. Like the, the, the number of people

1037
00:57:17,415 --> 00:57:20,875
Speaker 5:  who would, can afford that camera want to buy that camera

1038
00:57:21,255 --> 00:57:25,155
Speaker 5:  and have strong, like, visceral feelings about

1039
00:57:25,175 --> 00:57:27,555
Speaker 5:  how far away from your eye you should hold your camera. Like

1040
00:57:27,625 --> 00:57:27,915
Speaker 6:  Yeah.

1041
00:57:28,805 --> 00:57:29,935
Speaker 5:  It's just one group of people.

1042
00:57:30,045 --> 00:57:33,975
Speaker 6:  It's just that that makes it with, with no articulating, articulating

1043
00:57:33,975 --> 00:57:37,935
Speaker 6:  viewfinder and no like EVF or OVF. You

1044
00:57:37,935 --> 00:57:39,015
Speaker 6:  can only do this. Yep.

1045
00:57:39,035 --> 00:57:41,215
Speaker 4:  That's, that's, and this is why I think the screen should tilt.

1046
00:57:41,325 --> 00:57:41,615
Speaker 6:  Yeah.

1047
00:57:41,995 --> 00:57:42,495
Speaker 4:  That's it.

1048
00:57:42,755 --> 00:57:46,415
Speaker 6:  Any other angle than right in front of you. Yeah. You know what I mean? It

1049
00:57:46,415 --> 00:57:50,175
Speaker 6:  has this neural kind of jog wheel on the back that you're supposed to do

1050
00:57:50,175 --> 00:57:53,975
Speaker 6:  most of the stuff through. It has a play button. It has a

1051
00:57:54,045 --> 00:57:57,855
Speaker 6:  menu button for go into the menus. The menu looks not

1052
00:57:57,855 --> 00:57:59,855
Speaker 6:  great. Not great. Yeah.

1053
00:58:00,155 --> 00:58:04,055
Speaker 4:  You see Seb from Allied was like, yeah, looking at this interface is why

1054
00:58:04,095 --> 00:58:05,415
Speaker 4:  I make camera apps. Yeah, yeah.

1055
00:58:06,955 --> 00:58:07,175
Speaker 6:  Yes.

1056
00:58:07,525 --> 00:58:08,215
Speaker 4:  It's not great.

1057
00:58:09,315 --> 00:58:12,615
Speaker 6:  Has an extra little screen that tells you like the aperture and things like

1058
00:58:12,615 --> 00:58:16,535
Speaker 6:  that. Even though I just, I hate when you hide the aperture behind

1059
00:58:16,615 --> 00:58:20,495
Speaker 6:  a sub menu. It's horrible for cameras. I don't know. I

1060
00:58:20,495 --> 00:58:23,215
Speaker 6:  think that the, the biggest reason that people really like this camera is

1061
00:58:23,215 --> 00:58:27,135
Speaker 6:  because it is super basic. It is just a square

1062
00:58:27,155 --> 00:58:29,775
Speaker 6:  of aluminum with no, no, no. A couple little neural parts.

1063
00:58:30,195 --> 00:58:31,695
Speaker 5:  No. Let me tell you why people like this camera

1064
00:58:31,845 --> 00:58:33,055
Speaker 6:  Because aluminum people like

1065
00:58:33,095 --> 00:58:35,375
Speaker 5:  This camera. 'cause it is sexy as hell and I want it. So

1066
00:58:37,245 --> 00:58:38,935
Speaker 4:  Yeah. This is like, yeah, this

1067
00:58:38,935 --> 00:58:42,215
Speaker 5:  To me is like, imagine like a cave painting of a camera where it's like,

1068
00:58:42,245 --> 00:58:45,775
Speaker 5:  yeah, you go back like 8,000 years and it's like, oh, someone in,

1069
00:58:46,075 --> 00:58:49,855
Speaker 5:  you know, someone just drew a camera and it, this is the first camera that

1070
00:58:49,855 --> 00:58:53,095
Speaker 5:  anyone ever imagined that's this camera. And I love it for that.

1071
00:58:53,685 --> 00:58:53,975
Speaker 6:  Yeah.

1072
00:58:54,735 --> 00:58:58,055
Speaker 4:  I will say the fact that it doesn't have s a memory card slot. Yeah. And

1073
00:58:58,055 --> 00:59:01,855
Speaker 4:  it has a built in SSD is like, oh, this thing has a,

1074
00:59:02,035 --> 00:59:02,975
Speaker 4:  has a shelf life.

1075
00:59:03,315 --> 00:59:06,495
Speaker 6:  Oh yeah. You're either gonna have to get it serviced, which I'm not really

1076
00:59:06,495 --> 00:59:09,335
Speaker 6:  sure how they're gonna get inside of it when it's a solid block of aluminum

1077
00:59:09,335 --> 00:59:13,255
Speaker 6:  without taking a lot of stuff off of it. Or you're just gonna have

1078
00:59:13,255 --> 00:59:17,175
Speaker 6:  to get a new one. But hopefully it doesn't die before. You know, memory

1079
00:59:17,185 --> 00:59:21,055
Speaker 6:  cards famously die a lot. Yeah. But at least you can put a new memory

1080
00:59:21,125 --> 00:59:21,605
Speaker 6:  card in.

1081
00:59:21,705 --> 00:59:24,485
Speaker 4:  So here's my argument in favor of this except for the tilting screen, which

1082
00:59:24,485 --> 00:59:27,725
Speaker 4:  I agree is a huge problem. Okay. I again, 'cause I mostly take pictures of

1083
00:59:27,725 --> 00:59:31,685
Speaker 4:  a 6-year-old who is notably down here. Right. So I'm always shooting

1084
00:59:31,745 --> 00:59:35,445
Speaker 4:  at like hip height, which means I wanna tilt the screen up. Yeah. That's

1085
00:59:35,445 --> 00:59:37,805
Speaker 4:  it. That's like I, I need to solve that problem. This camera doesn't solve

1086
00:59:37,805 --> 00:59:40,125
Speaker 4:  that problem. It is sex as hell And I do want it,

1087
00:59:41,925 --> 00:59:45,605
Speaker 4:  I think it is like well beyond time for a cam

1088
00:59:45,705 --> 00:59:49,565
Speaker 4:  camera manufacturer to get rid of like

1089
00:59:49,565 --> 00:59:53,365
Speaker 4:  camera controls as we know them. Like as a person who mostly shoots

1090
00:59:53,625 --> 00:59:57,565
Speaker 4:  an ancient Nikon D 7,500, still the greatest hands on

1091
00:59:57,565 --> 00:59:58,285
Speaker 4:  camera ever made.

1092
01:00:00,855 --> 01:00:04,465
Speaker 4:  It's like fine. And there's just a million buttons on it. And I know what

1093
01:00:04,465 --> 01:00:07,545
Speaker 4:  they all do. And the reason I've never upgraded that camera is 'cause I know

1094
01:00:07,545 --> 01:00:10,385
Speaker 4:  where all those buttons are and I know what they all do. Right. And that's,

1095
01:00:10,495 --> 01:00:14,385
Speaker 4:  it's cool. Like I like having that relationship with that camera and I've

1096
01:00:14,405 --> 01:00:17,945
Speaker 4:  got most of them set so I never have to touch them again.

1097
01:00:18,505 --> 01:00:21,665
Speaker 4:  I just know where they are. And the reality is, if I could just set them

1098
01:00:21,765 --> 01:00:25,745
Speaker 4:  and then set this one dial to mostly ever control shutter speed, I'd be

1099
01:00:25,745 --> 01:00:25,905
Speaker 4:  fine.

1100
01:00:26,415 --> 01:00:26,705
Speaker 6:  Yeah.

1101
01:00:27,115 --> 01:00:29,705
Speaker 4:  Right, right. Or like exposure compensation. The

1102
01:00:29,705 --> 01:00:33,625
Speaker 5:  Only problem with that approach is you, you want that camera, but to be

1103
01:00:33,655 --> 01:00:37,265
Speaker 5:  like the size and quality of like a

1104
01:00:37,375 --> 01:00:41,225
Speaker 5:  Sony RX 100. Yeah. Right. Like give me all of what you just described a

1105
01:00:41,225 --> 01:00:44,985
Speaker 5:  basically designed to shoot in auto super simple all in one

1106
01:00:44,985 --> 01:00:48,905
Speaker 5:  piece. More or less unbreakable thing. That, that is like a really

1107
01:00:49,005 --> 01:00:52,825
Speaker 5:  fun, cool point and shoot. And I think it'd be gangbusters. I'd be all over

1108
01:00:52,825 --> 01:00:53,705
Speaker 5:  that thing. Yeah.

1109
01:00:53,785 --> 01:00:57,265
Speaker 6:  You're kind of describing X 100 in a, in a few ways. That's

1110
01:00:57,265 --> 01:00:59,705
Speaker 4:  What I mean. That's why people love them. But this one, to me, I just like,

1111
01:00:59,985 --> 01:01:03,585
Speaker 4:  I just like the idea that Sigma's, like we have no history of

1112
01:01:04,665 --> 01:01:08,425
Speaker 4:  Nikon F Series S SLRs to honor. That's fair. Like screw it.

1113
01:01:08,425 --> 01:01:10,065
Speaker 4:  We're just changing how the controls work.

1114
01:01:10,335 --> 01:01:14,305
Speaker 6:  Have you seen the old Sigma cameras? 'cause they're much weirder

1115
01:01:14,305 --> 01:01:16,425
Speaker 6:  than this. Yes. They're really, really weird.

1116
01:01:17,535 --> 01:01:20,665
Speaker 4:  Like, it's funny 'cause Sigma started out as like a, like a lens brand. Yeah.

1117
01:01:20,665 --> 01:01:22,465
Speaker 4:  And they were like, screw it, we can do whatever we want. Yeah.

1118
01:01:22,605 --> 01:01:26,225
Speaker 5:  It would be a lot more compelling in that way. You just described Neli if

1119
01:01:26,225 --> 01:01:29,905
Speaker 5:  the menu was better. Yeah. It's like here's a really usable thing unless

1120
01:01:29,905 --> 01:01:30,865
Speaker 5:  you have to do anything.

1121
01:01:31,415 --> 01:01:34,985
Speaker 6:  Have you guys driven the EQS? The, the new one? The electric one? Yes.

1122
01:01:35,245 --> 01:01:35,665
Speaker 6:  You've

1123
01:01:35,665 --> 01:01:39,025
Speaker 4:  Used, it's like being in a Korean nightclub on wheels. Yeah. I dunno how

1124
01:01:39,025 --> 01:01:39,545
Speaker 4:  else to describe it.

1125
01:01:39,705 --> 01:01:42,465
Speaker 6:  But you've used the infotainment system, right? Yeah. Yeah. It's like Windows

1126
01:01:42,465 --> 01:01:43,505
Speaker 6:  95. Yeah.

1127
01:01:43,505 --> 01:01:47,065
Speaker 4:  It's ev No one has good ideas about software design. No. And like the fact

1128
01:01:47,065 --> 01:01:50,985
Speaker 4:  that most products are now our software means that we live in a, like

1129
01:01:51,025 --> 01:01:54,825
Speaker 4:  a world of crime. Yeah. But yeah, I I see what you're saying that yeah,

1130
01:01:55,135 --> 01:01:56,465
Speaker 4:  it's pretty and I just want it on the shelf.

1131
01:01:56,465 --> 01:01:57,425
Speaker 6:  Right. I understand. I understand.

1132
01:01:57,505 --> 01:02:01,225
Speaker 4:  I want, I want to put a $2,000 knick-knack on my shelf. Also, the fact that

1133
01:02:01,245 --> 01:02:04,625
Speaker 4:  you, it is removable lenses means that it will never actually be as small

1134
01:02:04,625 --> 01:02:04,985
Speaker 4:  as it looks.

1135
01:02:05,205 --> 01:02:05,945
Speaker 6:  That's true.

1136
01:02:06,525 --> 01:02:10,385
Speaker 5:  But this is also like David, I feel like we are, we're in such an era where

1137
01:02:10,385 --> 01:02:14,265
Speaker 5:  like the camera is both a tool and an accessory, right? Yeah. And this is

1138
01:02:14,265 --> 01:02:17,505
Speaker 5:  like, this is the X 100 story, right? Where like a lot of people who bought

1139
01:02:17,545 --> 01:02:20,645
Speaker 5:  X one hundreds bought them not to shoot with them, but to be shot shooting

1140
01:02:20,645 --> 01:02:21,045
Speaker 5:  with them

1141
01:02:21,275 --> 01:02:22,365
Speaker 6:  Like a Leica. Yeah.

1142
01:02:22,365 --> 01:02:25,445
Speaker 5:  It's like it's a creator camera because I want you to see me using it. And

1143
01:02:25,445 --> 01:02:28,085
Speaker 5:  I, it's like a, it's a fashion accessory as much as anything. And I feel

1144
01:02:28,085 --> 01:02:30,925
Speaker 5:  like this is Sigma just kind of acknowledging the same thing and they're

1145
01:02:30,925 --> 01:02:34,125
Speaker 5:  like, yeah, you'll take some pictures with this, but it's also gonna look

1146
01:02:34,125 --> 01:02:35,965
Speaker 5:  cool as hell. And that's like 60% of the

1147
01:02:35,965 --> 01:02:39,765
Speaker 6:  People. I was thinking about that in a lot of ways because the M 11 is over

1148
01:02:39,795 --> 01:02:43,725
Speaker 6:  $9,000 for the body. This is 2000. So

1149
01:02:43,775 --> 01:02:47,525
Speaker 6:  there you go. Think of the savings much more affordable. Looks very

1150
01:02:47,525 --> 01:02:51,325
Speaker 6:  beautiful. People will ask you, what is that? It shoots about two and a half

1151
01:02:51,325 --> 01:02:54,525
Speaker 6:  hours of video If you wanna do the highest quality video and then you have

1152
01:02:54,525 --> 01:02:58,325
Speaker 6:  to offload it. I do like this idea of offloading everything onto

1153
01:02:58,395 --> 01:03:02,325
Speaker 6:  your computer from the USBC port and not having to worry

1154
01:03:02,325 --> 01:03:06,085
Speaker 6:  about an SD card at all. Because SD cards are sort of

1155
01:03:06,085 --> 01:03:09,885
Speaker 6:  like, I don't know, Bluetooth standards or wifi standards where you gotta

1156
01:03:09,885 --> 01:03:13,645
Speaker 6:  read the little three or the nine on it and there's no five for some reason.

1157
01:03:14,305 --> 01:03:17,245
Speaker 6:  And you just have to decide what is the speed and the fact that you can just

1158
01:03:17,245 --> 01:03:20,565
Speaker 6:  plug it into USBC port and then into your computer. Very nice.

1159
01:03:22,145 --> 01:03:23,885
Speaker 6:  But you know, that comes with its trade offs.

1160
01:03:24,355 --> 01:03:27,525
Speaker 4:  It's not great that this conversation has inspired me to start searching

1161
01:03:27,525 --> 01:03:28,245
Speaker 4:  for an X 100.

1162
01:03:30,675 --> 01:03:31,125
Speaker 6:  Good luck.

1163
01:03:32,005 --> 01:03:32,845
Speaker 4:  I mean, they're very

1164
01:03:32,845 --> 01:03:33,285
Speaker 6:  Hard to find.

1165
01:03:33,565 --> 01:03:35,925
Speaker 4:  I can pay a $700 premium for one right now.

1166
01:03:36,115 --> 01:03:39,325
Speaker 6:  Yeah. Yeah. Or you could get the five, which is not that different. But,

1167
01:03:39,545 --> 01:03:41,485
Speaker 4:  You know, let's just wrap up the show. I've got

1168
01:03:42,425 --> 01:03:42,965
Speaker 6:  That's busy.

1169
01:03:43,315 --> 01:03:45,085
Speaker 4:  Alright, let's talk about the iPhone briefly.

1170
01:03:45,345 --> 01:03:46,605
Speaker 6:  Can I say one more thing? Yeah, of

1171
01:03:46,605 --> 01:03:46,725
Speaker 4:  Course.

1172
01:03:47,145 --> 01:03:51,045
Speaker 6:  The LCD has a, has a sub, like a, a sub bezel. And I just

1173
01:03:51,045 --> 01:03:51,965
Speaker 6:  want to acknowledge that

1174
01:03:53,315 --> 01:03:56,525
Speaker 4:  None of the press photos show the LTD on it. Does it? Well

1175
01:03:56,545 --> 01:03:59,485
Speaker 6:  It doesn't show it on, but it shows it, it shows the sub bezel.

1176
01:03:59,675 --> 01:03:59,965
Speaker 4:  Yeah.

1177
01:03:59,965 --> 01:04:03,525
Speaker 6:  I see it. Which is not something Apple would've done. I just want to acknowledge

1178
01:04:03,525 --> 01:04:03,725
Speaker 6:  that

1179
01:04:04,625 --> 01:04:05,445
Speaker 4:  I'm buying all the cake. Oh

1180
01:04:05,445 --> 01:04:08,485
Speaker 5:  No, it's bad. You're right. I just looked and it, you're right. How

1181
01:04:08,485 --> 01:04:10,885
Speaker 6:  Does that make you feel? Do you not want it anymore?

1182
01:04:11,235 --> 01:04:14,965
Speaker 4:  Have you bought an RX 100? Take pictures of a kid yet? No. This is the single

1183
01:04:15,285 --> 01:04:17,565
Speaker 4:  greatest purchase you can make If you parent. Yes. It's the right choice.

1184
01:04:17,565 --> 01:04:20,285
Speaker 4:  Buy one of those. Like everyone's always happy with the photos. No one's

1185
01:04:20,285 --> 01:04:21,885
Speaker 4:  ever sad. Yeah. The screen tilts.

1186
01:04:22,985 --> 01:04:23,275
Speaker 6:  Yeah.

1187
01:04:23,385 --> 01:04:26,595
Speaker 4:  They're, they're, I would, I would not say they're indestructible. Like they're

1188
01:04:26,595 --> 01:04:29,955
Speaker 4:  very destructible, but like they're tough enough, you know? Yeah.

1189
01:04:31,255 --> 01:04:33,355
Speaker 6:  You don't have to worry about interchangeable lenses. Yeah.

1190
01:04:33,355 --> 01:04:36,475
Speaker 4:  They're, they're great, but like they are in fact destructible. Like you

1191
01:04:36,475 --> 01:04:40,315
Speaker 4:  get some dust near that lens mechanism. Yeah. You don't have an S 100 anymore.

1192
01:04:40,705 --> 01:04:44,675
Speaker 4:  It's all, it's all over. Okay. But they're, I think all these

1193
01:04:44,675 --> 01:04:48,275
Speaker 4:  cameras are ultimately David's point kind of competing with the concept of

1194
01:04:48,275 --> 01:04:49,675
Speaker 6:  The R accessory kind of.

1195
01:04:49,945 --> 01:04:53,675
Speaker 4:  Well no, it's the RX 100. It solves the most problems

1196
01:04:53,895 --> 01:04:57,675
Speaker 4:  in that zone. Yeah. And it's, it's very hard to solve the pro

1197
01:04:57,675 --> 01:04:59,515
Speaker 4:  like all the problems better than that camera does.

1198
01:04:59,545 --> 01:05:03,355
Speaker 6:  Yeah. I also wanna acknowledge that they made an RX one a long time

1199
01:05:03,415 --> 01:05:07,155
Speaker 6:  ago, which was full frame and they just never updated it. Yeah. And it's

1200
01:05:07,155 --> 01:05:10,595
Speaker 6:  been around for a long time and they could be dominating this space, but

1201
01:05:10,595 --> 01:05:11,995
Speaker 6:  they decide not to for

1202
01:05:11,995 --> 01:05:14,995
Speaker 5:  Some reason. I've loved that camera. Yeah, it's great. Holy crap. I loved

1203
01:05:14,995 --> 01:05:15,635
Speaker 5:  the RX one.

1204
01:05:15,775 --> 01:05:19,455
Speaker 6:  It was great. It was fantastic. And it hasn't been updated in like over five

1205
01:05:19,455 --> 01:05:23,375
Speaker 6:  years, so I don't really know what they're doing. No. Leica is

1206
01:05:23,375 --> 01:05:26,855
Speaker 6:  like the only one right now that makes a full frame fixed lens camera. Weird.

1207
01:05:27,165 --> 01:05:30,775
Speaker 6:  Yeah. And it costs $6,000 and no one can afford it. See the

1208
01:05:30,855 --> 01:05:33,175
Speaker 5:  Sigma's cheap man. What are we doing here? Yeah,

1209
01:05:33,175 --> 01:05:36,335
Speaker 4:  You're getting one. It's an impulse purchase. We did call one in for a review,

1210
01:05:36,995 --> 01:05:40,815
Speaker 4:  so we did not go on the influencer trip to Japan that everyone

1211
01:05:40,815 --> 01:05:44,575
Speaker 4:  else wanted because we had this annoying ethics policy. But we did ask for

1212
01:05:44,575 --> 01:05:47,015
Speaker 4:  a review unit. I think someone's getting it.

1213
01:05:47,205 --> 01:05:49,895
Speaker 5:  Yeah, well they can make nine a day. So presumably we'll get it in

1214
01:05:50,235 --> 01:05:53,015
Speaker 5:  2034. We'll get one. It'll be awesome. Someone

1215
01:05:53,075 --> 01:05:56,975
Speaker 4:  On our team is, is getting one. And, and then I'm gonna, I'm

1216
01:05:56,975 --> 01:06:00,335
Speaker 4:  gonna look at it with a love in my eyes. My, you know, like cartoons with

1217
01:06:00,335 --> 01:06:01,095
Speaker 4:  my eyes in

1218
01:06:01,095 --> 01:06:01,535
Speaker 5:  My hearts.

1219
01:06:02,845 --> 01:06:05,335
Speaker 4:  Alright, we should talk about this iPhone. It's a, it's like amazing how

1220
01:06:05,335 --> 01:06:07,415
Speaker 4:  much we want to avoid talking about the iPhone 16 E

1221
01:06:07,605 --> 01:06:08,575
Speaker 6:  Yeah. I

1222
01:06:08,575 --> 01:06:11,695
Speaker 4:  Know we have some virtual listeners who just totally tune out when we talk

1223
01:06:11,695 --> 01:06:15,415
Speaker 4:  about cameras. I was much happier talking about the camera than I'm gonna

1224
01:06:15,415 --> 01:06:16,815
Speaker 4:  be talking about the iPhone 16 E

1225
01:06:17,265 --> 01:06:20,455
Speaker 5:  Never has a phone been so thoroughly exactly

1226
01:06:21,685 --> 01:06:23,495
Speaker 5:  what we expected it to be. Oh,

1227
01:06:23,495 --> 01:06:26,215
Speaker 4:  That's, I was gonna say, never has a phone been so thoroughly. Exactly. Not

1228
01:06:26,215 --> 01:06:26,375
Speaker 4:  it.

1229
01:06:28,005 --> 01:06:31,895
Speaker 6:  Yeah. Yeah. It's funny because on social media, usually the few

1230
01:06:31,895 --> 01:06:35,695
Speaker 6:  days after a new iPhone comes out, people are trying to justify the reasons

1231
01:06:35,835 --> 01:06:39,735
Speaker 6:  why they want to upgrade. I've not seen one thing about

1232
01:06:39,735 --> 01:06:43,535
Speaker 6:  this from anybody saying why you should get this necessarily

1233
01:06:43,635 --> 01:06:45,055
Speaker 6:  except for people that are insane. No. And

1234
01:06:45,055 --> 01:06:48,855
Speaker 5:  On the one hand, look, I like this phone is so clearly not meant for those

1235
01:06:48,855 --> 01:06:50,375
Speaker 5:  people. Yeah. And that's

1236
01:06:50,375 --> 01:06:51,535
Speaker 6:  Fine. That's fair enough. Right? Like,

1237
01:06:51,535 --> 01:06:55,415
Speaker 5:  It it's good point. It just, it's, this is a, a, a thing that Apple I

1238
01:06:55,415 --> 01:06:59,255
Speaker 5:  think struggles with is that it operates at such scale and with so much attention

1239
01:06:59,365 --> 01:07:03,255
Speaker 5:  that everything it launches is ostensibly geared

1240
01:07:03,255 --> 01:07:06,935
Speaker 5:  towards everyone everywhere. And this is just so

1241
01:07:07,115 --> 01:07:10,975
Speaker 5:  not that. Right. Like, I, I don't think anyone who is considering a

1242
01:07:11,035 --> 01:07:14,655
Speaker 5:  pro phone will ever look twice at this. Right. Like, Mila, you're, you're

1243
01:07:14,815 --> 01:07:17,175
Speaker 5:  proposed headline. No one should ever have to care about this. I actually

1244
01:07:17,175 --> 01:07:20,855
Speaker 5:  think it's like very descriptive because this is for people who don't care

1245
01:07:20,855 --> 01:07:24,695
Speaker 5:  about their phone. This is like, I, I want, I want to have a phone,

1246
01:07:25,035 --> 01:07:25,455
Speaker 5:  but it's

1247
01:07:25,525 --> 01:07:29,455
Speaker 4:  Five ninety nine nine. If you're that person, you

1248
01:07:29,455 --> 01:07:31,655
Speaker 4:  should buy a used iPhone 15

1249
01:07:32,545 --> 01:07:33,685
Speaker 5:  Or a new iPhone 15.

1250
01:07:34,225 --> 01:07:35,525
Speaker 4:  Oh. If you

1251
01:07:35,525 --> 01:07:37,525
Speaker 6:  Buy used 15 Pro for like the same amount.

1252
01:07:37,525 --> 01:07:40,605
Speaker 4:  Right. And you'll get Mag safe and you'll get way better cameras and like,

1253
01:07:41,305 --> 01:07:42,445
Speaker 4:  you'll, you'll just pick a half.

1254
01:07:42,625 --> 01:07:43,925
Speaker 5:  No Apple Intelligence neli.

1255
01:07:44,345 --> 01:07:45,365
Speaker 6:  That's a plus. I can,

1256
01:07:45,525 --> 01:07:48,445
Speaker 4:  I I cannot be bothered to what end.

1257
01:07:49,355 --> 01:07:49,645
Speaker 5:  Yeah.

1258
01:07:50,725 --> 01:07:54,285
Speaker 4:  I I think Apple really thought Apple Intelligence was gonna drive a, a huge

1259
01:07:54,285 --> 01:07:54,965
Speaker 4:  cycle. And

1260
01:07:55,265 --> 01:07:58,165
Speaker 5:  It was the Supercycle, this was the que this was the thing last year. Do

1261
01:07:58,165 --> 01:08:00,485
Speaker 5:  you remember this? They were talking about the supercycle of smartphone upgrades

1262
01:08:00,485 --> 01:08:04,165
Speaker 5:  because of Apple intelligence. Yeah. And Old Boy is that not the thing?

1263
01:08:04,475 --> 01:08:07,245
Speaker 6:  Well, have you noticed that the billboards have changed? They used to be

1264
01:08:07,245 --> 01:08:10,765
Speaker 6:  Hello Apple Intelligence? I don't see those anymore at all. Now it's

1265
01:08:11,025 --> 01:08:13,925
Speaker 6:  all Gen Moji billboards because they know that's what people actually care

1266
01:08:13,925 --> 01:08:16,245
Speaker 6:  about. Do they though? It's all I care about.

1267
01:08:17,705 --> 01:08:21,285
Speaker 4:  Do you, so is this just a phone that can get Gen Moji? Is that

1268
01:08:21,435 --> 01:08:21,765
Speaker 4:  this is

1269
01:08:22,195 --> 01:08:23,805
Speaker 5:  Your cheapest gen Moji access pretty

1270
01:08:24,005 --> 01:08:24,285
Speaker 6:  Wait, okay.

1271
01:08:24,515 --> 01:08:27,405
Speaker 5:  Hold on. I no longer care about the 16 e David. I need to know everything

1272
01:08:27,405 --> 01:08:28,765
Speaker 5:  about your Gen Moji life.

1273
01:08:28,965 --> 01:08:29,325
Speaker 6:  Oh God.

1274
01:08:29,435 --> 01:08:31,525
Speaker 5:  What are your use cases for Gen Moji? How

1275
01:08:31,525 --> 01:08:32,045
Speaker 6:  Long do you have?

1276
01:08:34,805 --> 01:08:38,265
Speaker 6:  I'm frustrated by Gen Moji and the same reason that I'm delighted by Gen

1277
01:08:38,335 --> 01:08:42,245
Speaker 6:  Moji. Okay. In that it's just like they,

1278
01:08:42,245 --> 01:08:46,205
Speaker 6:  they tried to make Gen Moji exactly like emoji in every possible way.

1279
01:08:46,865 --> 01:08:50,765
Speaker 6:  And in that way it's very useful for regular people as

1280
01:08:50,765 --> 01:08:54,525
Speaker 6:  long as they know where the button is, which it's glowing. So I hope that

1281
01:08:54,525 --> 01:08:58,205
Speaker 6:  they know where it is. But they look like Apple emoji 'cause they're trained

1282
01:08:58,205 --> 01:09:02,085
Speaker 6:  on that apple emoji character set and there just aren't emojis for

1283
01:09:02,085 --> 01:09:05,805
Speaker 6:  everything. Like Unicode, they add three or four a year, everyone has to

1284
01:09:05,805 --> 01:09:09,725
Speaker 6:  vote on them. That's great. But when you wanna make very specific

1285
01:09:09,825 --> 01:09:12,845
Speaker 6:  things, you know, like stickers, I think were one of the biggest

1286
01:09:14,405 --> 01:09:18,045
Speaker 6:  upgrades to the iPhone in a very long time. Or at least to iMessage. Because

1287
01:09:18,045 --> 01:09:20,925
Speaker 6:  when you can press and hold on something, make a custom sticker, everyone

1288
01:09:20,955 --> 01:09:24,725
Speaker 6:  uses that. People love it. That is cool. Gen Moji is like that, but

1289
01:09:24,915 --> 01:09:28,725
Speaker 6:  it's more, it's like, it, it, it abstracts it away a little bit so that

1290
01:09:28,725 --> 01:09:32,405
Speaker 6:  it's more usable with people that you do not have that specific

1291
01:09:32,405 --> 01:09:33,285
Speaker 6:  relationship with.

1292
01:09:33,635 --> 01:09:36,645
Speaker 5:  What was the last Gen Moji you made? We're doing this now.

1293
01:09:36,905 --> 01:09:39,325
Speaker 6:  Oh gosh. All right. I'm gonna look right now. I I

1294
01:09:40,075 --> 01:09:43,685
Speaker 4:  I've never made a gen emoji. Maybe I should buy an iPhone 16.

1295
01:09:43,715 --> 01:09:47,445
Speaker 5:  Yeah. Like is this in your day to day? Like you're just, you're just out

1296
01:09:47,445 --> 01:09:48,765
Speaker 5:  here. Gen moji up a storm.

1297
01:09:49,165 --> 01:09:49,565
Speaker 6:  I, I

1298
01:09:49,615 --> 01:09:53,325
Speaker 5:  Don't like do you wanna get dinner and you're like, Jen Moji make me a person

1299
01:09:53,545 --> 01:09:53,965
Speaker 5:  eating

1300
01:09:53,965 --> 01:09:57,685
Speaker 4:  Spaghetti. But is that how you invoke a Gen moji? You have to say Jen Moji.

1301
01:09:58,785 --> 01:09:59,005
Speaker 6:  Jen

1302
01:09:59,035 --> 01:10:00,285
Speaker 4:  Moji, Jen Moji, gen Moji.

1303
01:10:02,145 --> 01:10:05,605
Speaker 6:  I'm not sure if we can put this in the show, but If you just say, If you

1304
01:10:05,605 --> 01:10:08,485
Speaker 6:  just Gen Moji gun, it will make you a gun.

1305
01:10:09,675 --> 01:10:12,845
Speaker 6:  Cool. I just wanted to test that. Very strange. So

1306
01:10:12,845 --> 01:10:14,565
Speaker 4:  You're just sending cartoons of guns to you?

1307
01:10:15,905 --> 01:10:18,725
Speaker 6:  Oh, laughing, crying, throwing up. Very good one.

1308
01:10:19,065 --> 01:10:20,245
Speaker 4:  Oh, this is your Gen Moji. These

1309
01:10:20,245 --> 01:10:23,205
Speaker 6:  Are, these are Gen moji. This is, this is one I'm saying they mix stickers,

1310
01:10:23,345 --> 01:10:27,285
Speaker 6:  gen moji and emoji in the same area of the keyboard because

1311
01:10:27,285 --> 01:10:30,005
Speaker 6:  they want people to think of them as the exact same thing. I will

1312
01:10:30,005 --> 01:10:32,925
Speaker 5:  Say I like laughing, crying, throwing up as a gen moji. That's pretty

1313
01:10:32,925 --> 01:10:36,565
Speaker 6:  Good. It's quite good. I I will send it to you because it is very good.

1314
01:10:37,905 --> 01:10:40,005
Speaker 4:  I'm just gonna send you some guns. Just,

1315
01:10:40,565 --> 01:10:41,245
Speaker 5:  I wanted just

1316
01:10:41,245 --> 01:10:42,885
Speaker 4:  In the middle of the night, David, get ready.

1317
01:10:43,045 --> 01:10:45,925
Speaker 6:  I just wanted to test how many different types of guns I would make. And

1318
01:10:45,925 --> 01:10:48,325
Speaker 6:  it's a lot. You could do a pipe.

1319
01:10:48,715 --> 01:10:49,245
Speaker 4:  Wait, so,

1320
01:10:49,785 --> 01:10:53,365
Speaker 6:  Oh, this one is good. This is the, the pumpkin and the devil

1321
01:10:53,575 --> 01:10:56,645
Speaker 6:  emoji mixed and I use them for Halloween. That's very good.

1322
01:10:57,645 --> 01:11:01,125
Speaker 4:  I do like that you're just spamming David with like the worst emoji I've

1323
01:11:01,125 --> 01:11:01,205
Speaker 4:  ever.

1324
01:11:01,275 --> 01:11:02,045
Speaker 5:  This is fantastic.

1325
01:11:04,345 --> 01:11:08,325
Speaker 4:  That's very good. So again, to just bring this all

1326
01:11:08,325 --> 01:11:12,165
Speaker 4:  the way around, our thesis is that people will buy a $600, no not

1327
01:11:12,165 --> 01:11:14,965
Speaker 4:  good iPhone to send cartoons of guns.

1328
01:11:16,505 --> 01:11:20,485
Speaker 6:  No, but, but I have noticed all of the billboards have changed

1329
01:11:20,485 --> 01:11:23,645
Speaker 6:  to Gen Moji billboards. Yeah. And I think that they looked at Apple Intelligence

1330
01:11:23,785 --> 01:11:27,365
Speaker 6:  and before it was just so abstract. Before it was just, hello Apple Intelligence

1331
01:11:27,365 --> 01:11:31,245
Speaker 6:  iPhone 16. Now it's Gen Moji it, that's their

1332
01:11:31,525 --> 01:11:35,405
Speaker 6:  whole thing. Yeah. It has lasted longer than the, than the Apple Intelligence

1333
01:11:35,545 --> 01:11:38,845
Speaker 6:  ads. Like there are more Gen Moji ads. They have lasted a longer period of

1334
01:11:38,845 --> 01:11:38,885
Speaker 6:  time.

1335
01:11:38,955 --> 01:11:41,965
Speaker 4:  It's funny 'cause they, they started all those ads before you could get Apple

1336
01:11:41,965 --> 01:11:45,485
Speaker 4:  Intelligence and then people got Apple Intelligence and and they stopped

1337
01:11:45,805 --> 01:11:48,245
Speaker 4:  advertising it. Yeah. And yeah, I see, I see what you're

1338
01:11:48,245 --> 01:11:51,405
Speaker 6:  Saying. My experience with Apple Intelligence outside of Gen Moji was that

1339
01:11:51,765 --> 01:11:55,645
Speaker 6:  I took a script that I had in Apple Notes

1340
01:11:56,305 --> 01:12:00,165
Speaker 6:  and I did the rewrite feature intending to revert back to the

1341
01:12:00,165 --> 01:12:03,805
Speaker 6:  old script because, you know, I was just testing it and then it

1342
01:12:03,805 --> 01:12:07,605
Speaker 6:  crashed Apple Notes and then I could not revert it to my

1343
01:12:07,605 --> 01:12:10,365
Speaker 6:  actual script. And that was my only copy of the script.

1344
01:12:11,635 --> 01:12:15,125
Speaker 6:  Woof. And that was my mistake. So I just, I don't think people really

1345
01:12:15,555 --> 01:12:16,405
Speaker 6:  care about this. Can

1346
01:12:16,405 --> 01:12:20,005
Speaker 4:  I? But the only true feeling I have about the 16 e

1347
01:12:20,545 --> 01:12:24,075
Speaker 4:  is that not having Mag safe on it is criminal.

1348
01:12:24,175 --> 01:12:24,475
Speaker 6:  It is

1349
01:12:25,325 --> 01:12:29,015
Speaker 4:  Like almost all of the phone mounts in my house.

1350
01:12:29,315 --> 01:12:33,215
Speaker 4:  All of the batteries that I use now, like it's all MagSafe all the

1351
01:12:33,215 --> 01:12:37,095
Speaker 4:  way down the line in the car. I have one next to the mirror in

1352
01:12:37,095 --> 01:12:41,085
Speaker 4:  my bathroom and I just like put the phone on the next to that in the morning.

1353
01:12:41,155 --> 01:12:45,085
Speaker 4:  Yeah. Have it played YouTube TV at me. That's amazing. It's

1354
01:12:45,085 --> 01:12:48,885
Speaker 4:  like all of that is super fun and interesting. And that is the only like

1355
01:12:49,185 --> 01:12:52,845
Speaker 4:  really great accessory ecosystem that Apple's ever created. Yeah.

1356
01:12:53,225 --> 01:12:56,205
Speaker 4:  And they're just like the cheap phone, the $600 phone can't have it.

1357
01:12:56,585 --> 01:13:00,045
Speaker 6:  Why are people are now going to go into the Apple store, they're gonna buy

1358
01:13:00,045 --> 01:13:03,485
Speaker 6:  an iPhone 16 e they're gonna go over and they're gonna look at the mag safe

1359
01:13:03,675 --> 01:13:07,485
Speaker 6:  charger because everyone wants that MagSafe wireless

1360
01:13:07,485 --> 01:13:11,095
Speaker 6:  charger that is $50. And the Apple employer's

1361
01:13:11,455 --> 01:13:13,815
Speaker 6:  employees either gonna say, oh, that doesn't work with your phone, even though

1362
01:13:13,815 --> 01:13:17,775
Speaker 6:  it's new or they're not gonna know that. And then they're

1363
01:13:17,775 --> 01:13:20,415
Speaker 6:  gonna be like, I don't get this. Like, I have to hold it against my phone

1364
01:13:20,415 --> 01:13:23,415
Speaker 6:  and it charges at 7.5 watts. Like how does this work?

1365
01:13:24,315 --> 01:13:27,495
Speaker 6:  It just seems like a hor like why would you take this out? Yeah.

1366
01:13:27,495 --> 01:13:31,455
Speaker 4:  This is the, the one completely perplexing thing about this phone is MagSafe.

1367
01:13:31,455 --> 01:13:31,735
Speaker 4:  Yeah.

1368
01:13:31,735 --> 01:13:35,535
Speaker 5:  Yeah. I I I actually think you can make a pretty strong case for every

1369
01:13:35,535 --> 01:13:39,175
Speaker 5:  other one of the trade-offs. I think it, it lands a hundred dollars too expensive.

1370
01:13:39,655 --> 01:13:42,935
Speaker 5:  Like I really agree with Allison's takeaway, which is like the,

1371
01:13:43,635 --> 01:13:47,615
Speaker 5:  the idea of we need a cheaper iPhone and we're going

1372
01:13:47,615 --> 01:13:50,455
Speaker 5:  to make some sacrifices to get there. I think other than MagSafe, apple got

1373
01:13:50,475 --> 01:13:54,455
Speaker 5:  almost right, there are like a couple of little things about it, but whatever,

1374
01:13:54,455 --> 01:13:58,055
Speaker 5:  like it's, it got it mostly right. But I agree that the MagSafe thing just

1375
01:13:58,055 --> 01:14:01,015
Speaker 5:  sucks. And we, we talked a little bit about this last week and heard from

1376
01:14:01,015 --> 01:14:04,655
Speaker 5:  a bunch of people who were like, whatever, just buy a MagSafe case for your

1377
01:14:04,655 --> 01:14:08,415
Speaker 5:  phone and would I bet that Apple

1378
01:14:08,515 --> 01:14:12,125
Speaker 5:  is gonna sell you some of those? Sure. But like

1379
01:14:12,265 --> 01:14:13,845
Speaker 5:  that's not a solution to the

1380
01:14:13,845 --> 01:14:16,725
Speaker 6:  Problem. They just get rid of Max safe altogether and everything's Q2 and

1381
01:14:16,765 --> 01:14:17,285
Speaker 6:  Q2 ready.

1382
01:14:18,355 --> 01:14:22,325
Speaker 4:  That sounds like Apple. Yeah. I dunno it's a phone. Let us know if you're,

1383
01:14:22,345 --> 01:14:25,645
Speaker 4:  if you're the target market for this phone, who is the, but this is like

1384
01:14:25,865 --> 01:14:29,365
Speaker 4:  the weirdest iPhone launch. Yeah. I can remember

1385
01:14:29,995 --> 01:14:33,925
Speaker 4:  like never has an iPhone come out with such a Okay.

1386
01:14:34,475 --> 01:14:34,965
Speaker 6:  Come out out.

1387
01:14:34,965 --> 01:14:38,245
Speaker 5:  Do you think if this thing were $450 we'd be having a totally different conversation

1388
01:14:38,245 --> 01:14:38,565
Speaker 5:  about it?

1389
01:14:39,425 --> 01:14:39,645
Speaker 6:  Yes.

1390
01:14:39,785 --> 01:14:40,885
Speaker 4:  If it was 350.

1391
01:14:41,555 --> 01:14:41,845
Speaker 6:  Well,

1392
01:14:42,205 --> 01:14:45,965
Speaker 5:  I think that's unreal. That's like unrealistic for what phones cost right

1393
01:14:45,965 --> 01:14:49,205
Speaker 5:  now. Like Yeah. I don't know If you've heard of that. Tariffs Tar Neli Tariff.

1394
01:14:49,205 --> 01:14:50,365
Speaker 5:  Yeah. And tariffs. Like is

1395
01:14:50,365 --> 01:14:51,965
Speaker 6:  This the first tariff phone? That's the other question

1396
01:14:52,245 --> 01:14:55,285
Speaker 4:  I read. Ben Thompson makes the argument that this is the first tarone,

1397
01:14:56,105 --> 01:14:58,885
Speaker 4:  but we'll see. I mean like Tim Cook is, you know, we we're, we're gonna get

1398
01:14:58,885 --> 01:15:00,845
Speaker 4:  to it in the next segment. Yeah. And it's, it's part of the light your end.

1399
01:15:00,945 --> 01:15:03,485
Speaker 4:  Tim Cook is just throwing fake numbers at Donald Trump to get out of the

1400
01:15:03,485 --> 01:15:07,085
Speaker 4:  tariffs. So smart move. We'll see. We'll see if, and also every

1401
01:15:07,915 --> 01:15:11,765
Speaker 4:  realistically, no one ever buys this phone. Like, you go

1402
01:15:11,765 --> 01:15:15,445
Speaker 4:  to your Verizon store and Verizon's like this one. Yeah. And you just leave

1403
01:15:15,465 --> 01:15:16,205
Speaker 4:  and that's the end of that.

1404
01:15:16,205 --> 01:15:20,005
Speaker 6:  So did you, did you watch Marquez's review of it by the way? No. That he

1405
01:15:20,005 --> 01:15:22,845
Speaker 6:  has a ski at the beginning. It's like 90 seconds long and there's, he, one

1406
01:15:22,845 --> 01:15:26,325
Speaker 6:  of him plays the employee and one of an employees a customer.

1407
01:15:27,105 --> 01:15:31,085
Speaker 6:  And the customer's just asking, I want a phone that does exactly this. Exactly

1408
01:15:31,085 --> 01:15:34,645
Speaker 6:  this an employee just gives him everything but the 16 e because it just makes

1409
01:15:34,865 --> 01:15:38,165
Speaker 6:  no sense. And I just, again,

1410
01:15:38,675 --> 01:15:38,965
Speaker 4:  Yeah.

1411
01:15:39,585 --> 01:15:40,485
Speaker 6:  Who is this? I'll,

1412
01:15:40,485 --> 01:15:43,045
Speaker 4:  I'll go watch it. Apologies that it's like one of the few I haven't watched,

1413
01:15:43,065 --> 01:15:46,245
Speaker 4:  but it's like I don't wanna care about the 60. I just didn't give it the

1414
01:15:46,245 --> 01:15:46,405
Speaker 4:  time.

1415
01:15:46,875 --> 01:15:50,285
Speaker 5:  It's a way in the door. And then Apple can sell you more expensive things.

1416
01:15:50,605 --> 01:15:51,085
Speaker 4:  I do love the,

1417
01:15:51,085 --> 01:15:52,245
Speaker 6:  Except for Max Save accessories.

1418
01:15:52,245 --> 01:15:56,165
Speaker 4:  This is my favorite, my favorite ongoing like thesis about Apple

1419
01:15:56,545 --> 01:16:00,485
Speaker 4:  is that they have some products that don't exist. Like they just have

1420
01:16:00,485 --> 01:16:02,885
Speaker 4:  like this, the 16 e only exists on the website.

1421
01:16:02,915 --> 01:16:05,765
Speaker 5:  It's like the lobster at a diner. Like it's it's not there.

1422
01:16:06,125 --> 01:16:09,365
Speaker 4:  Yeah. It's like they're not manufacturing it, it's not real. It's like the

1423
01:16:09,525 --> 01:16:12,845
Speaker 4:  illusion of a phone, right. To get you to buy a more expensive phone. Yeah.

1424
01:16:12,875 --> 01:16:16,725
Speaker 4:  It's like, no, I think they're manufacturing the phone. We'll see. Alright,

1425
01:16:16,725 --> 01:16:19,525
Speaker 4:  we gotta take a break. We were supposed to talk about the framework laptop,

1426
01:16:19,525 --> 01:16:23,045
Speaker 4:  which looks really cool. But David tells me that framework, CEO Nro Patel

1427
01:16:23,045 --> 01:16:24,645
Speaker 4:  is coming on the show next week.

1428
01:16:24,715 --> 01:16:28,045
Speaker 5:  Yeah, he's coming. Sean and I are gonna hang out with NRO actually later

1429
01:16:28,045 --> 01:16:30,885
Speaker 5:  this afternoon and we're gonna have a lot to say, but like if I'll, I'll

1430
01:16:30,885 --> 01:16:33,965
Speaker 5:  put all the framework stuff in the show notes. I think that company is fascinating.

1431
01:16:34,265 --> 01:16:36,725
Speaker 5:  The desktop looks really cool. I'm especially excited about the framework

1432
01:16:36,725 --> 01:16:40,445
Speaker 5:  Laptop 12, which is their like lower end touchscreen

1433
01:16:40,585 --> 01:16:44,365
Speaker 5:  flippy one that I think is gonna be maybe the most kind of main streamy thing

1434
01:16:44,365 --> 01:16:48,245
Speaker 5:  framework has made yet This company's very exciting and I think up to

1435
01:16:48,245 --> 01:16:50,285
Speaker 5:  some really cool stuff. But yeah, we're gonna have lots more to talk about

1436
01:16:50,285 --> 01:16:51,605
Speaker 5:  on that one on Tuesday. Yep.

1437
01:16:51,995 --> 01:16:52,285
Speaker 6:  Cool.

1438
01:16:52,585 --> 01:16:54,445
Speaker 4:  All right, we're gonna take a break. We're gonna come back with lightning

1439
01:16:54,445 --> 01:16:55,525
Speaker 4:  round. We're right back.

1440
01:17:30,545 --> 01:17:33,925
Speaker 4:  All right, we're back. Lightning round unsponsored for flavor.

1441
01:17:36,225 --> 01:17:38,925
Speaker 4:  The people have started saying it to us, so we're gonna start saying it back

1442
01:17:38,925 --> 01:17:39,605
Speaker 4:  to you. It

1443
01:17:39,605 --> 01:17:42,765
Speaker 5:  Is marching up the charts of the most demanded merch in the history of The

1444
01:17:42,885 --> 01:17:44,485
Speaker 5:  Verge is an unsponsored for flavor

1445
01:17:45,125 --> 01:17:47,085
Speaker 4:  T-shirt. It doesn't mean anything,

1446
01:17:47,345 --> 01:17:48,685
Speaker 5:  It doesn't mean anything, but we're gonna

1447
01:17:48,685 --> 01:17:51,685
Speaker 4:  Make it. When people spon, we, you can't tell us what to do.

1448
01:17:52,915 --> 01:17:55,565
Speaker 4:  It's, it's their defining principle here at The Verge.

1449
01:17:55,585 --> 01:17:59,325
Speaker 5:  For some reason to me that that belongs on the bottom of a skateboard that

1450
01:17:59,325 --> 01:18:01,965
Speaker 5:  just says unsponsored for flavor. That's, that's where that goes.

1451
01:18:02,085 --> 01:18:05,885
Speaker 4:  I say you could throw away the entire, it's a long ethics policy on the

1452
01:18:05,885 --> 01:18:09,365
Speaker 4:  website. It's very complicated. You can throw it out and you can replace

1453
01:18:09,365 --> 01:18:13,325
Speaker 4:  it with, you can't tell us what to do. And that would pretty much get you

1454
01:18:13,325 --> 01:18:13,485
Speaker 4:  there

1455
01:18:15,055 --> 01:18:18,195
Speaker 4:  anyway. If you'd like to sponsor the lightning round, you can call someone

1456
01:18:18,215 --> 01:18:21,915
Speaker 4:  at Box Media and pay them money and then we will still do this. But today

1457
01:18:21,915 --> 01:18:25,875
Speaker 4:  we're unsponsored, which means there's not even a hint of corporate control

1458
01:18:27,075 --> 01:18:30,965
Speaker 4:  because you, again, to repeat myself, you, you can't

1459
01:18:30,965 --> 01:18:34,955
Speaker 4:  tell us what to do. Unsponsored for flavor. Okay, David,

1460
01:18:35,025 --> 01:18:35,635
Speaker 4:  take it away.

1461
01:18:35,865 --> 01:18:39,675
Speaker 5:  Okay. So the, the first thing here is that YouTube announced

1462
01:18:39,675 --> 01:18:43,275
Speaker 5:  this week that More than a billion people now watch podcasts

1463
01:18:43,495 --> 01:18:47,275
Speaker 5:  on YouTube. Which is a kind of a number we knew,

1464
01:18:47,405 --> 01:18:51,195
Speaker 5:  right? Like YouTube has been creeping up as the most important

1465
01:18:51,195 --> 01:18:55,155
Speaker 5:  podcast platform for some time. YouTube music exists,

1466
01:18:55,215 --> 01:18:59,115
Speaker 5:  but this is not YouTube music. This is YouTube. YouTube, YouTube, Maine

1467
01:18:59,215 --> 01:19:03,115
Speaker 5:  as they call it, which I forever think is very funny. And

1468
01:19:03,745 --> 01:19:07,715
Speaker 5:  basically YouTube is very proud of this fact. They're like,

1469
01:19:07,715 --> 01:19:11,115
Speaker 5:  we are, we are, we are a massively important podcast platform.

1470
01:19:11,955 --> 01:19:15,795
Speaker 5:  I think there are several dozen issues with the fact that YouTube is

1471
01:19:15,795 --> 01:19:19,395
Speaker 5:  this powerful a podcast platform in part because it's not a podcast

1472
01:19:19,795 --> 01:19:22,035
Speaker 5:  platform. Like there's a non-zero chance you're watching this on YouTube

1473
01:19:22,035 --> 01:19:25,915
Speaker 5:  right now. YouTube is not a podcast app for a bunch of reasons. You

1474
01:19:26,205 --> 01:19:29,835
Speaker 5:  can't get background audio playback unless you have YouTube premium.

1475
01:19:30,375 --> 01:19:33,875
Speaker 5:  You can't sort out shows correctly. The, the audio

1476
01:19:34,135 --> 01:19:37,555
Speaker 5:  versus video playback just sucks on YouTube. And YouTube's answer to this

1477
01:19:37,555 --> 01:19:41,155
Speaker 5:  is YouTube music. But again, no. And so

1478
01:19:41,875 --> 01:19:44,955
Speaker 5:  I just think we're, we're at this really interesting moment where YouTube

1479
01:19:45,735 --> 01:19:49,195
Speaker 5:  is both becoming the most popular podcast platform and is kind of changing

1480
01:19:49,195 --> 01:19:53,155
Speaker 5:  what podcasts are. Yeah. And it has changed it so much to the point where

1481
01:19:53,255 --> 01:19:57,155
Speaker 5:  now like Spotify is racing to do video

1482
01:19:57,975 --> 01:20:01,155
Speaker 5:  and it is because it's trying to catch up to YouTube in part because video

1483
01:20:01,215 --> 01:20:03,835
Speaker 5:  is very popular in part because video is very shareable and in part because

1484
01:20:03,835 --> 01:20:07,280
Speaker 5:  video is really discoverable in a way that audio is not. So

1485
01:20:07,955 --> 01:20:11,085
Speaker 5:  everybody now is turning to video. You

1486
01:20:11,085 --> 01:20:14,845
Speaker 6:  Didn't like the TikTok, Spotify thing for music where you heard a

1487
01:20:14,995 --> 01:20:17,525
Speaker 6:  clip of a song you've never heard before and decided you wanted to listen

1488
01:20:17,525 --> 01:20:18,005
Speaker 6:  to the whole thing.

1489
01:20:18,155 --> 01:20:21,885
Speaker 5:  What could possibly go wrong? No, it's a terrible user interface.

1490
01:20:21,985 --> 01:20:25,085
Speaker 5:  And I, I did this whole thing in the

1491
01:20:25,475 --> 01:20:28,045
Speaker 5:  installer or the newsletter I write last week where I basically was like,

1492
01:20:28,045 --> 01:20:31,725
Speaker 5:  tell me your music setup. And the overwhelming piece of feedback from people

1493
01:20:31,945 --> 01:20:35,845
Speaker 5:  was, I use Spotify, I hate Spotify. Yes. Which is like

1494
01:20:35,995 --> 01:20:39,965
Speaker 5:  precisely how I feel about Spotify. Like Perfect. No notes. And it's because

1495
01:20:40,145 --> 01:20:43,525
Speaker 5:  all of this stuff is trying desperately to chase YouTube.

1496
01:20:44,425 --> 01:20:47,365
Speaker 5:  And YouTube meanwhile is just out here flexing. It's like, yeah, If you want

1497
01:20:47,365 --> 01:20:51,005
Speaker 5:  to be relevant on the internet, you have to be on YouTube. And that is

1498
01:20:51,005 --> 01:20:54,845
Speaker 5:  increasingly true for people who make podcasts. And I think like Spotify's

1499
01:20:54,845 --> 01:20:58,805
Speaker 5:  number I think was that it had a hundred million podcast listeners and

1500
01:20:58,805 --> 01:21:02,085
Speaker 5:  Spotify is like what everybody thinks is either the most important or second

1501
01:21:02,325 --> 01:21:05,645
Speaker 5:  most important podcast platform next to Apple podcasts. And YouTube is just

1502
01:21:05,645 --> 01:21:07,405
Speaker 5:  out crushing everybody. It's nuts.

1503
01:21:07,535 --> 01:21:10,205
Speaker 4:  Lemme ask a foundational question.

1504
01:21:12,105 --> 01:21:12,875
Speaker 4:  What is a podcast?

1505
01:21:13,425 --> 01:21:16,255
Speaker 6:  Yeah, I was gonna, I was gonna ask that too

1506
01:21:17,095 --> 01:21:17,585
Speaker 4:  Because

1507
01:21:17,945 --> 01:21:18,065
Speaker 6:  I,

1508
01:21:18,365 --> 01:21:21,025
Speaker 4:  Are we just talking about YouTube videos that say their podcasts?

1509
01:21:22,105 --> 01:21:23,075
Speaker 6:  Well what is that then?

1510
01:21:23,965 --> 01:21:27,695
Speaker 4:  Well, I mean, we have been making this show for a long time and it is true.

1511
01:21:27,725 --> 01:21:28,215
Speaker 4:  Some people

1512
01:21:29,905 --> 01:21:33,895
Speaker 4:  watch it on YouTube, lots of people actually watch it YouTube. But I, I don't

1513
01:21:33,895 --> 01:21:37,615
Speaker 4:  know like what is the difference between waveform

1514
01:21:37,875 --> 01:21:39,335
Speaker 4:  and a regular Marquez video?

1515
01:21:41,615 --> 01:21:44,545
Speaker 4:  It's is it, is it just the microphones,

1516
01:21:44,605 --> 01:21:46,225
Speaker 6:  The editing, the microphones? I

1517
01:21:46,225 --> 01:21:46,425
Speaker 4:  Dunno.

1518
01:21:46,425 --> 01:21:47,985
Speaker 5:  But do you know who broke that distinction?

1519
01:21:48,375 --> 01:21:48,865
Speaker 4:  YouTube.

1520
01:21:48,865 --> 01:21:51,985
Speaker 5:  YouTube, yeah. This is, this is the point, right? Like what, what, what has

1521
01:21:52,225 --> 01:21:55,745
Speaker 5:  happened, and I think YouTube has actually done this to a lot of different

1522
01:21:55,745 --> 01:21:59,705
Speaker 5:  forms of art, is YouTube has just collapsed everything into YouTube and

1523
01:21:59,725 --> 01:22:03,705
Speaker 5:  now everything looks like YouTube and works like YouTube and follows YouTube's

1524
01:22:03,955 --> 01:22:07,505
Speaker 5:  particular like trends and systems and norms.

1525
01:22:07,855 --> 01:22:11,425
Speaker 5:  Because it's YouTube. Because YouTube is the only platform that matters and

1526
01:22:11,815 --> 01:22:13,585
Speaker 5:  thus everything has to be YouTube.

1527
01:22:14,315 --> 01:22:18,015
Speaker 6:  How do you categorize a late night show? Because that's a podcast

1528
01:22:18,435 --> 01:22:21,095
Speaker 6:  in the way that a YouTube show is a podcast.

1529
01:22:21,525 --> 01:22:24,895
Speaker 5:  It's a podcast but it's also just a bunch of YouTube clips in a row.

1530
01:22:24,925 --> 01:22:28,135
Speaker 4:  Yeah. I mean, no, cable news has just been podcasts for a long time. Yeah.

1531
01:22:28,135 --> 01:22:31,135
Speaker 4:  If you ever just like watch whatever cable news channel you wanna watch,

1532
01:22:31,155 --> 01:22:34,015
Speaker 4:  but you just like watch CNBC or CNN or M-S-N-B-C or Fox News or whatever,

1533
01:22:34,115 --> 01:22:36,935
Speaker 4:  you know. Oh, this is just the most chaotic podcast industry. Yeah.

1534
01:22:36,935 --> 01:22:37,695
Speaker 6:  Very unstructured

1535
01:22:38,875 --> 01:22:41,895
Speaker 4:  At all. It's just happening all at once all the time. A lot of

1536
01:22:41,895 --> 01:22:45,575
Speaker 5:  Them actually run podcasts that are just the full audio feed of the show.

1537
01:22:45,875 --> 01:22:48,695
Speaker 5:  It works horrible Six, I don't dunno if 60 Minutes still does it, but they

1538
01:22:48,695 --> 01:22:50,095
Speaker 5:  did for a long time and like it

1539
01:22:50,095 --> 01:22:53,295
Speaker 6:  Works well. 60 Minutes makes sense. Yeah. People can visualize things in

1540
01:22:53,295 --> 01:22:56,735
Speaker 6:  their heads. Is that different from an audio book? I don't know.

1541
01:22:57,755 --> 01:23:01,415
Speaker 4:  So we, I'm trying to remember the headline. The, the narrative

1542
01:23:01,575 --> 01:23:05,445
Speaker 4:  podcasts are running into audio book story was a big story. Yeah.

1543
01:23:05,625 --> 01:23:09,565
Speaker 4:  And then narrative PO podcast, like serial, like fell out of favor in

1544
01:23:09,565 --> 01:23:13,445
Speaker 4:  like a real way. Yeah. 'cause the, I I hear you on YouTube and

1545
01:23:13,445 --> 01:23:17,365
Speaker 4:  I'm, I I do love to criticize YouTube at basically any turn. But like really

1546
01:23:17,365 --> 01:23:20,925
Speaker 4:  what you're seeing here is platforms pushing everyone to lower

1547
01:23:21,385 --> 01:23:24,485
Speaker 4:  the cost of content. Yeah. Because they don't pay enough money.

1548
01:23:25,445 --> 01:23:29,225
Speaker 4:  And so like YouTube as if you're on like a YouTuber,

1549
01:23:29,565 --> 01:23:33,105
Speaker 4:  the amount of money you get from YouTube, from AdSense and the partner program

1550
01:23:33,325 --> 01:23:37,185
Speaker 4:  is just going down over time. The amount of views everybody's getting

1551
01:23:37,245 --> 01:23:41,185
Speaker 4:  is just going down over time. 'cause there's so many more YouTubers,

1552
01:23:41,515 --> 01:23:45,425
Speaker 4:  right? So everyone's just trying to make cheaper stuff and we've been

1553
01:23:45,425 --> 01:23:48,665
Speaker 4:  making the show for a long time. So I will just tell you like

1554
01:23:49,215 --> 01:23:52,985
Speaker 4:  hanging around talking is a very cheap way to make content. Like

1555
01:23:53,205 --> 01:23:56,585
Speaker 4:  we try hard, you know, we got like graphics, there's frame TVs everywhere.

1556
01:23:57,115 --> 01:23:59,855
Speaker 4:  Those weren't cheap. Lemme tell you,

1557
01:24:01,645 --> 01:24:04,495
Speaker 4:  Samsung's making a pretty penny off all the podcasters in this world with

1558
01:24:04,495 --> 01:24:07,615
Speaker 4:  the Frame TV graphics that are everywhere. But like, that's what's happening

1559
01:24:07,675 --> 01:24:10,855
Speaker 4:  is like we're just pushing the cost of content down. So we, YouTube was able

1560
01:24:10,875 --> 01:24:14,455
Speaker 4:  to take podcasts and say, really, we're gonna film your podcast

1561
01:24:14,875 --> 01:24:18,655
Speaker 4:  and now we're just gonna ingest hours more video from every

1562
01:24:18,655 --> 01:24:22,135
Speaker 4:  creator who's doing podcasts. They don't have to be scripted, they don't

1563
01:24:22,135 --> 01:24:26,025
Speaker 4:  have to be structured. We don't take cameras on location here. Here you go.

1564
01:24:26,025 --> 01:24:29,905
Speaker 4:  Here's hours and hours of more video. Yeah. What I don't

1565
01:24:29,905 --> 01:24:33,345
Speaker 4:  know is whether that's actually taking share away from Apple Podcasts.

1566
01:24:34,615 --> 01:24:38,375
Speaker 4:  I know why Spotify's scared, right? This is Spotify's big bet. And

1567
01:24:38,975 --> 01:24:42,915
Speaker 4:  they're losing to YouTube in one very specific way. Right. But

1568
01:24:42,915 --> 01:24:46,795
Speaker 4:  I don't know if like the, the Apple Podcast listener was

1569
01:24:46,795 --> 01:24:49,755
Speaker 4:  always an audio listener is like, screw it, I'm gonna watch this on YouTube

1570
01:24:49,755 --> 01:24:50,115
Speaker 4:  instead.

1571
01:24:50,305 --> 01:24:54,035
Speaker 5:  Yeah. I don't know. I, I have a lot of, I mean, we get a lot of anecdotal

1572
01:24:54,225 --> 01:24:57,555
Speaker 5:  information and feedback from people that I would say

1573
01:24:58,295 --> 01:25:02,155
Speaker 5:  by and large what we've heard from people who are like watching and listening

1574
01:25:02,155 --> 01:25:05,995
Speaker 5:  to this right now is that it is more sort of additive

1575
01:25:06,025 --> 01:25:09,835
Speaker 5:  than cannibalizing. Like there are definitely people who have found

1576
01:25:09,935 --> 01:25:11,995
Speaker 5:  the show on YouTube and only consume it on YouTube,

1577
01:25:13,655 --> 01:25:17,115
Speaker 5:  but we also get a lot of people who are like, oh, I listen to it while I'm

1578
01:25:17,115 --> 01:25:19,595
Speaker 5:  on a walk. And then it's like fun to watch clips. Or I watch the show later,

1579
01:25:19,675 --> 01:25:22,435
Speaker 5:  I put it on the TV while I'm in the, or like whatever. So I think it's,

1580
01:25:23,425 --> 01:25:26,155
Speaker 5:  from what we've heard so far and what we've seen in our data, they're not

1581
01:25:26,225 --> 01:25:30,075
Speaker 5:  kind of killing each other. But also right

1582
01:25:30,075 --> 01:25:34,035
Speaker 5:  now, if you're launching a new show, I absolutely guarantee you're spending

1583
01:25:34,035 --> 01:25:36,595
Speaker 5:  more of your time thinking about YouTube than you are thinking about Apple

1584
01:25:36,595 --> 01:25:39,115
Speaker 5:  Podcasts. And that to me is the real shift over time.

1585
01:25:39,835 --> 01:25:43,315
Speaker 6:  I think that people there, the shift towards passive consumption, like

1586
01:25:43,385 --> 01:25:47,075
Speaker 6:  needing just things to be playing at all periods of time that they can check

1587
01:25:47,075 --> 01:25:50,675
Speaker 6:  in on kind of passively and when they want to. We have a lot of people that

1588
01:25:50,675 --> 01:25:54,635
Speaker 6:  tell us, oh, I do the dishes while I have waveform on the tv. Yeah.

1589
01:25:54,695 --> 01:25:58,075
Speaker 6:  And I look over every now and then and I think some form of like

1590
01:25:58,595 --> 01:26:01,715
Speaker 6:  ingestion through their eyes while it's also being ingested through their

1591
01:26:01,715 --> 01:26:04,565
Speaker 6:  ears every now and then is like what people want. They just want things playing

1592
01:26:04,565 --> 01:26:07,405
Speaker 6:  all the time. There's a reason people leave their apartments, they go to

1593
01:26:07,405 --> 01:26:10,445
Speaker 6:  the subway, they realize they don't have their headphones with them and they

1594
01:26:10,445 --> 01:26:14,165
Speaker 6:  have a panic attack and people just need more longer things.

1595
01:26:14,275 --> 01:26:17,965
Speaker 6:  Yeah. Yeah. And the fact that they, the audio medium of podcasts has

1596
01:26:18,245 --> 01:26:21,565
Speaker 6:  companies that are like, don't worry, we made sure this is less than 10 minutes.

1597
01:26:22,385 --> 01:26:26,245
Speaker 6:  No one wants a less than 10 minutes po. Is anyone asking for that? Because

1598
01:26:26,245 --> 01:26:29,445
Speaker 6:  you can just pick it back up like nobody is asking for that. If anything,

1599
01:26:29,445 --> 01:26:31,445
Speaker 6:  people love the length of, you know, this show, people

1600
01:26:31,445 --> 01:26:33,845
Speaker 4:  Want a two hour Vergecast statement. That's what I'm telling you. That's

1601
01:26:33,845 --> 01:26:34,205
Speaker 6:  Exactly

1602
01:26:34,205 --> 01:26:36,045
Speaker 4:  Right. And we are very close to delivering it here.

1603
01:26:36,355 --> 01:26:37,285
Speaker 6:  I've never heard

1604
01:26:37,285 --> 01:26:40,205
Speaker 4:  In the lightning round that is already on 10 minutes on a single item. No

1605
01:26:40,325 --> 01:26:42,645
Speaker 6:  One's told me that they want a shorter one. That's all I'm saying.

1606
01:26:42,865 --> 01:26:46,405
Speaker 4:  All right David, we're changing your job. You're just doing Twitch streams

1607
01:26:46,405 --> 01:26:47,605
Speaker 4:  24 7 from now

1608
01:26:47,605 --> 01:26:49,125
Speaker 6:  On. Justin TV's back baby

1609
01:26:49,475 --> 01:26:52,725
Speaker 4:  From your green screen basement. I'm leaning into that conspiracy theory.

1610
01:26:52,725 --> 01:26:54,485
Speaker 4:  This David's basement's a green screen. I,

1611
01:26:54,965 --> 01:26:58,605
Speaker 5:  I have begun occasionally subtly moving things around in

1612
01:26:58,785 --> 01:27:02,125
Speaker 5:  my background and if anyone would like to tell me what those things are,

1613
01:27:03,355 --> 01:27:04,275
Speaker 5:  I welcome it. Alright.

1614
01:27:04,295 --> 01:27:06,835
Speaker 4:  Let me add up these next two lightning round items for you.

1615
01:27:07,395 --> 01:27:08,555
Speaker 6:  I forgot this was the lightning round.

1616
01:27:08,935 --> 01:27:12,675
Speaker 4:  We, so apparently, yeah, that's what I was told. Instagram reels may get

1617
01:27:12,675 --> 01:27:15,755
Speaker 4:  its own app. Makes sense. Presumably to compete more directly with TikTok.

1618
01:27:16,015 --> 01:27:19,035
Speaker 4:  And then TikTok is upgrading its desktop website

1619
01:27:19,455 --> 01:27:21,155
Speaker 6:  To compete with YouTube. They say to compete

1620
01:27:21,155 --> 01:27:23,155
Speaker 4:  With YouTube. What do you got

1621
01:27:24,645 --> 01:27:28,415
Speaker 6:  First one. Yep. Makes sense. I mean, I think

1622
01:27:28,515 --> 01:27:32,295
Speaker 6:  people go to Instagram for reels at this point. So

1623
01:27:32,455 --> 01:27:35,615
Speaker 4:  I think all of this is based about the TikTok band.

1624
01:27:35,725 --> 01:27:36,015
Speaker 6:  Yeah.

1625
01:27:36,815 --> 01:27:40,735
Speaker 4:  I think if, because remember TikTok is technically banned in

1626
01:27:40,735 --> 01:27:44,535
Speaker 4:  this country. Yeah. Like the law passed, the Supreme Court upheld it

1627
01:27:44,795 --> 01:27:48,255
Speaker 4:  and then Donald Trump was like, no, we're not doing that. Yeah. And the app

1628
01:27:48,255 --> 01:27:51,175
Speaker 4:  stores, apple and Google were like, that's too much risk. And then Pam Bondi,

1629
01:27:51,175 --> 01:27:54,335
Speaker 4:  the new attorney general, sent them a letter, which we have still not seen

1630
01:27:54,885 --> 01:27:58,735
Speaker 4:  that made them feel comfortable to put TikTok back. So now we're in this

1631
01:27:58,735 --> 01:28:01,975
Speaker 4:  weird period where this app that is banned,

1632
01:28:03,365 --> 01:28:07,335
Speaker 4:  they got a 75 day reprieve from the Trump administration of enforcement of

1633
01:28:07,335 --> 01:28:11,175
Speaker 4:  the law that's coming up in what, April. Right David? So

1634
01:28:11,335 --> 01:28:14,295
Speaker 4:  in April this app might go away again or it sold to,

1635
01:28:15,415 --> 01:28:19,295
Speaker 4:  I don't know, Don Jr. Limited whatever's gonna happen. Like I don't know

1636
01:28:19,295 --> 01:28:22,775
Speaker 4:  what's gonna happen. Yeah. And if that, what that moment,

1637
01:28:23,375 --> 01:28:27,175
Speaker 4:  whatever that moment is, will be a change. And so If you Instagram,

1638
01:28:27,175 --> 01:28:31,095
Speaker 4:  you have to be ready for it. Right. So here's reels like not Instagram

1639
01:28:32,095 --> 01:28:35,695
Speaker 4:  re like this much more direct competitor to TikTok. And if you're TikTok,

1640
01:28:36,415 --> 01:28:38,535
Speaker 4:  I think you have to be like, well you can't ban a website.

1641
01:28:38,765 --> 01:28:42,555
Speaker 6:  Yeah. Realistically, Instagram is just reels. I think

1642
01:28:42,555 --> 01:28:45,995
Speaker 6:  it's, it's almost just like a rebranding thing. And I wonder if it sticks

1643
01:28:45,995 --> 01:28:49,195
Speaker 6:  around because Instagram has tested having dedicated apps for things that

1644
01:28:49,195 --> 01:28:53,155
Speaker 6:  Instagram already does quite a few times and they've shut them down quite

1645
01:28:53,155 --> 01:28:53,955
Speaker 6:  a few times. Remember

1646
01:28:54,035 --> 01:28:55,555
Speaker 5:  IGTV, that was

1647
01:28:55,575 --> 01:28:57,275
Speaker 6:  Fun. That was a period of time

1648
01:28:57,945 --> 01:29:01,885
Speaker 4:  Someone very senior in Instagram told me recently that IGTV was

1649
01:29:01,885 --> 01:29:04,845
Speaker 4:  exactly the right idea. And the only thing that got wrong was the videos

1650
01:29:04,845 --> 01:29:05,445
Speaker 4:  were too long.

1651
01:29:05,745 --> 01:29:06,605
Speaker 5:  Oh, that's interesting.

1652
01:29:07,025 --> 01:29:10,125
Speaker 4:  He is like, we had TikTok, it was just long videos and what people wanted

1653
01:29:10,125 --> 01:29:10,725
Speaker 4:  was short videos.

1654
01:29:11,045 --> 01:29:14,885
Speaker 5:  I mean that's kind of true. They tried to do the like Hollywood thing and

1655
01:29:14,885 --> 01:29:17,965
Speaker 5:  it's actually like, no, just let people film videos of themselves. People

1656
01:29:17,965 --> 01:29:21,125
Speaker 4:  Want garbage. Yeah, right. Just set up some microphones and start a podcast

1657
01:29:21,295 --> 01:29:24,085
Speaker 4:  about Yeah. Gadgets and Brendan Carr and you're gonna be fine.

1658
01:29:24,125 --> 01:29:26,045
Speaker 6:  Famously why Quibi worked for sure.

1659
01:29:26,405 --> 01:29:29,245
Speaker 5:  Yeah. Dude, I think I disagree with you saying that Instagram is just reels.

1660
01:29:29,245 --> 01:29:31,845
Speaker 5:  And I actually think my theory about why this is happening, and I'm just

1661
01:29:31,845 --> 01:29:34,365
Speaker 5:  gonna throw this at you both and I'm curious what you think is I, so I watch

1662
01:29:34,365 --> 01:29:38,285
Speaker 5:  these Adam er, like a MA videos every week where they talk

1663
01:29:38,285 --> 01:29:41,885
Speaker 5:  about, he talks about like what's going on. And that man cannot

1664
01:29:41,985 --> 01:29:45,725
Speaker 5:  figure out what is the most important thing on Instagram, right? Like

1665
01:29:46,055 --> 01:29:49,045
Speaker 5:  there are stories which a lot of people watch and care very much about that

1666
01:29:49,045 --> 01:29:52,045
Speaker 5:  they are forever, like making more important in the product and then denigrating

1667
01:29:52,045 --> 01:29:55,965
Speaker 5:  in the product, there's the feed, which is like a dying thing, but is also

1668
01:29:55,965 --> 01:29:58,565
Speaker 5:  like the central pillar of Instagram. So they're trying to make the feed

1669
01:29:58,645 --> 01:30:02,285
Speaker 5:  a thing again and they're like, we, we wanna let it, we wanna let you post

1670
01:30:02,285 --> 01:30:05,125
Speaker 5:  to your feed without it being such a big deal to post to your feed. Right?

1671
01:30:05,145 --> 01:30:08,925
Speaker 5:  And I think Instagram has just producted itself into

1672
01:30:08,925 --> 01:30:12,005
Speaker 5:  total chaos. And I think a

1673
01:30:12,815 --> 01:30:16,485
Speaker 5:  knows that clearly the easiest thing to spin out and make its own is reels.

1674
01:30:16,485 --> 01:30:19,085
Speaker 5:  Because then you have an app that opens to video that is playing with the

1675
01:30:19,085 --> 01:30:22,085
Speaker 5:  volume on, which is really important. Yeah. And is a really important part

1676
01:30:22,085 --> 01:30:24,845
Speaker 5:  of why TikTok has been so successful, right? 'cause you open it up and it

1677
01:30:24,845 --> 01:30:28,285
Speaker 5:  is playing with the volume on. And that is not an that, you can't just turn

1678
01:30:28,285 --> 01:30:31,845
Speaker 5:  that on on Instagram, but you could, if it's just an app called Reels, right?

1679
01:30:32,225 --> 01:30:36,125
Speaker 5:  And then it also says, okay, now we understand what Instagram is. Again,

1680
01:30:36,405 --> 01:30:40,005
Speaker 5:  because no one knows what Instagram is anymore. You just post things,

1681
01:30:40,005 --> 01:30:43,645
Speaker 5:  places and hope that people see them, which is not a recipe for success.

1682
01:30:43,785 --> 01:30:46,205
Speaker 5:  And so now everybody's like, what happened to my reach? Where do I post if

1683
01:30:46,205 --> 01:30:49,525
Speaker 5:  I wanna reach people? And this like, this might actually help Instagram tell

1684
01:30:49,605 --> 01:30:52,365
Speaker 5:  a story about itself That makes sense for the first time in a long time.

1685
01:30:52,585 --> 01:30:56,445
Speaker 6:  Do you think they know what that will be? If a reels app launches though?

1686
01:30:57,065 --> 01:31:00,795
Speaker 6:  Because they fame meta famously just takes the best part of

1687
01:31:00,795 --> 01:31:04,475
Speaker 6:  every app from their competitors and then puts it in Instagram specifically.

1688
01:31:04,795 --> 01:31:08,355
Speaker 6:  Right? So now you know, they've got the Snapchat in Instagram, which is stories,

1689
01:31:08,495 --> 01:31:11,355
Speaker 6:  and they've got the reels in Instagram, which is TikTok, and then they've

1690
01:31:11,355 --> 01:31:13,915
Speaker 6:  got the Instagram and Instagram, which they have long forgotten about.

1691
01:31:14,395 --> 01:31:17,915
Speaker 5:  Right? Well, but I think that goes back to your point about it. It reels

1692
01:31:17,915 --> 01:31:21,875
Speaker 5:  is the most important part of Instagram. Like I think a, I would

1693
01:31:21,935 --> 01:31:25,035
Speaker 5:  bet that if this app still exists, reels will still be in Instagram and they'll

1694
01:31:25,035 --> 01:31:28,835
Speaker 5:  still be in Facebook. And then what Meta gets to say is actually

1695
01:31:28,935 --> 01:31:32,235
Speaker 5:  we have this video app, but we also have this gigantic distribution across

1696
01:31:32,235 --> 01:31:35,955
Speaker 5:  everywhere. Yeah. So it's like we have TikTok, but we also have TikTok

1697
01:31:36,235 --> 01:31:38,235
Speaker 5:  attached to Instagram. It's

1698
01:31:38,235 --> 01:31:39,875
Speaker 6:  Like the Fedi verse. But for one platform,

1699
01:31:40,035 --> 01:31:40,715
Speaker 5:  For one company.

1700
01:31:40,825 --> 01:31:41,115
Speaker 4:  Yeah.

1701
01:31:41,465 --> 01:31:44,235
Speaker 5:  It's, which is, which I would just point out is what we call a monopoly

1702
01:31:47,425 --> 01:31:51,355
Speaker 4:  Boosted TikTok videos everywhere you look on meta platforms. Yeah.

1703
01:31:51,695 --> 01:31:55,355
Speaker 4:  I'm telling you, I I think it's just so that when people lose access to TikTok,

1704
01:31:55,355 --> 01:31:58,155
Speaker 4:  again Meta can say, download a new app.

1705
01:31:58,665 --> 01:32:00,765
Speaker 5:  It's just TikTok. Yeah. No, I think that's right.

1706
01:32:00,925 --> 01:32:04,285
Speaker 4:  I think there's probably some conniving clever motivation, but then there's

1707
01:32:04,285 --> 01:32:08,165
Speaker 4:  also a very dumb thing, which is like, are you mad? Push this button. Yeah.

1708
01:32:08,225 --> 01:32:09,685
Speaker 4:  And that solves a lot of

1709
01:32:09,685 --> 01:32:10,565
Speaker 5:  Problems. Yeah, I totally agree.

1710
01:32:10,725 --> 01:32:13,845
Speaker 6:  I mean, wasn't Instagram notes supposed to be their Twitter competitor? Oh

1711
01:32:13,845 --> 01:32:15,325
Speaker 6:  yeah. Yeah. And then they just like, shut that down. Or

1712
01:32:15,395 --> 01:32:16,245
Speaker 4:  That became Threads.

1713
01:32:16,425 --> 01:32:17,965
Speaker 6:  Became threads. Okay.

1714
01:32:17,965 --> 01:32:18,125
Speaker 5:  Yeah.

1715
01:32:18,545 --> 01:32:21,405
Speaker 4:  Or are you mad at Twitter? Download this app and it worked for five minutes

1716
01:32:21,695 --> 01:32:24,925
Speaker 4:  until they're like, what if this algorithm was the worst? Yeah.

1717
01:32:25,575 --> 01:32:29,445
Speaker 4:  We'll see. End of that. Okay. We gotta do Po It's a lightning ran. So

1718
01:32:29,445 --> 01:32:30,765
Speaker 4:  we're gonna move through politics very quickly.

1719
01:32:32,425 --> 01:32:35,215
Speaker 4:  David, I'm assigning you to this job. 'cause I can't, you know.

1720
01:32:36,645 --> 01:32:40,575
Speaker 5:  Okay. I'm just gonna, I'm just gonna say a bunch of things in a row and

1721
01:32:40,575 --> 01:32:43,935
Speaker 5:  you can stop me whenever you feel like it. Does that sound good? Yeah. DOGE

1722
01:32:43,935 --> 01:32:47,775
Speaker 5:  remains insane. The, the big news of this past

1723
01:32:47,775 --> 01:32:51,755
Speaker 5:  week was that Elon Musk, a lot

1724
01:32:51,755 --> 01:32:55,035
Speaker 5:  of federal employees got an email telling them to respond with five bullets

1725
01:32:55,035 --> 01:32:58,315
Speaker 5:  about what they did. And then Elon Musk posted on X that if they didn't respond

1726
01:32:58,315 --> 01:33:01,675
Speaker 5:  to that email, they would take that as resignation. That's nothing

1727
01:33:02,255 --> 01:33:06,205
Speaker 5:  and is nothing. So a bunch of departments said, don't answer this

1728
01:33:06,205 --> 01:33:08,765
Speaker 5:  email. A bunch of departments said, answer this email. Everybody's up in

1729
01:33:08,765 --> 01:33:09,965
Speaker 5:  arms about it, nobody knows what to make of it.

1730
01:33:11,555 --> 01:33:15,525
Speaker 5:  Musk and then Donald Trump continue to kind of say it's a real

1731
01:33:15,525 --> 01:33:18,045
Speaker 5:  thing and people should do it, but it, it appears to be nothing except just

1732
01:33:18,045 --> 01:33:21,405
Speaker 5:  more abject chaos. DOGE

1733
01:33:22,655 --> 01:33:26,635
Speaker 5:  God only knows what it is or who works there. But the, the new thing that

1734
01:33:26,875 --> 01:33:30,715
Speaker 5:  happened this week was that Amy Gleason, who is formerly an employee at the

1735
01:33:30,715 --> 01:33:34,465
Speaker 5:  US Digital Service was I like

1736
01:33:34,995 --> 01:33:38,905
Speaker 5:  named Scapegoated. Like I don't, I don't know what word you want to use

1737
01:33:39,325 --> 01:33:42,825
Speaker 4:  In the executive order that creates DOGE. It says there will be a DOGE

1738
01:33:42,825 --> 01:33:43,425
Speaker 4:  administrator

1739
01:33:44,955 --> 01:33:48,605
Speaker 4:  that no one knew who that person was. Right. Like judges were asking United States

1740
01:33:48,925 --> 01:33:52,845
Speaker 4:  Attorneys General, who is the administrator of DOGE, and they'd

1741
01:33:52,925 --> 01:33:55,205
Speaker 4:  be like, I don't know that at this time. Right.

1742
01:33:55,435 --> 01:33:59,405
Speaker 5:  Because I think literally they didn't, and, and a lot of reporting from,

1743
01:33:59,405 --> 01:34:02,445
Speaker 5:  from us and Wired and others suggest that even the people who work there

1744
01:34:02,445 --> 01:34:05,485
Speaker 5:  didn't know who they were reporting to. Elon Musk is in every meaningful

1745
01:34:05,485 --> 01:34:09,445
Speaker 5:  way in charge, but he is not a government employee. So that's not how

1746
01:34:09,445 --> 01:34:09,805
Speaker 5:  that works.

1747
01:34:09,805 --> 01:34:12,725
Speaker 4:  Yeah. He's a special government employee. Sure. What is a photo, David? That's

1748
01:34:12,725 --> 01:34:12,965
Speaker 4:  where we are.

1749
01:34:12,995 --> 01:34:16,125
Speaker 5:  Yeah. I mean, knock yourself out. Yeah. Yeah. You can have whatever you want.

1750
01:34:16,985 --> 01:34:20,365
Speaker 5:  He was in a cabinet members meeting. Like, none of this is real anymore.

1751
01:34:20,565 --> 01:34:24,165
Speaker 6:  I don't know. I think the, the thing that makes all of this just break

1752
01:34:24,345 --> 01:34:28,005
Speaker 6:  and not, and weird and all the reporting kind of be weird, is that all of

1753
01:34:28,005 --> 01:34:31,285
Speaker 6:  this assumes that there are processes and things that you can and cannot

1754
01:34:31,385 --> 01:34:35,285
Speaker 6:  do when you're in certain positions. And they are just saying, none of that

1755
01:34:35,285 --> 01:34:38,285
Speaker 6:  matters. Correct. And we're gonna do what we want anyway. Yeah. And in certain

1756
01:34:38,285 --> 01:34:42,125
Speaker 6:  ways they're subverting these things and saying, okay, here's the administrator

1757
01:34:42,125 --> 01:34:45,965
Speaker 6:  because you asked so many times, but none of them matters for them. They

1758
01:34:45,965 --> 01:34:49,605
Speaker 6:  just do not care. So it's important that re the

1759
01:34:49,605 --> 01:34:52,245
Speaker 6:  reporting is happening, but also what do these facts mean?

1760
01:34:52,415 --> 01:34:55,645
Speaker 5:  Right? There's that paragraph in all of these stories that is like, this

1761
01:34:55,645 --> 01:34:58,885
Speaker 5:  breaks with longstanding norms and understanding of how these things, and

1762
01:34:58,885 --> 01:35:02,005
Speaker 5:  it's like, yeah, dude. Like every single other thing. Yeah. We've been here

1763
01:35:02,005 --> 01:35:05,005
Speaker 4:  For a while. No other president has had a full cabinet meeting where just

1764
01:35:05,035 --> 01:35:08,685
Speaker 4:  some guy wearing a shirt that reads tech support and wearing a baseball cap

1765
01:35:08,685 --> 01:35:11,925
Speaker 4:  with his fingers talked the most. Yeah. That was Elon in the cabinet meeting.

1766
01:35:12,145 --> 01:35:12,565
Speaker 4:  That's,

1767
01:35:12,565 --> 01:35:16,485
Speaker 5:  That's just so, okay. So then I say all of this, which led

1768
01:35:16,485 --> 01:35:19,485
Speaker 5:  to, I would say the funniest thing that happened this week,

1769
01:35:20,135 --> 01:35:24,085
Speaker 5:  which is in, in the Housing and Urban Development Department, somebody

1770
01:35:24,625 --> 01:35:28,365
Speaker 5:  put on TVs all around the department, an AI

1771
01:35:28,365 --> 01:35:30,685
Speaker 5:  generated video of President Trump

1772
01:35:31,915 --> 01:35:35,085
Speaker 5:  sucking on Elon Musk's feet. Like I don't know how else to say it other than

1773
01:35:35,085 --> 01:35:38,965
Speaker 5:  that. And it became, it became a whole thing. It

1774
01:35:38,965 --> 01:35:39,885
Speaker 5:  got shared a bunch of places

1775
01:35:41,425 --> 01:35:45,325
Speaker 5:  and it is, it is, it is hysterical. If you have not watched it. Don't,

1776
01:35:46,905 --> 01:35:48,445
Speaker 5:  but also I will put the link in the show.

1777
01:35:50,405 --> 01:35:54,165
Speaker 4:  Actually, the funniest part of this is it is an AI deep fake. And so

1778
01:35:54,315 --> 01:35:58,205
Speaker 4:  like Blue Sky had a content moderation controversy about it. 'cause

1779
01:35:58,205 --> 01:36:01,645
Speaker 4:  you're not supposed to share AI deep fakes. But then it was a newsworthy

1780
01:36:01,655 --> 01:36:05,085
Speaker 4:  video of a TV in a government agency being hacked.

1781
01:36:05,625 --> 01:36:09,165
Speaker 4:  So then they undid it and they're like, we're very sorry. We, we we've rethought

1782
01:36:09,165 --> 01:36:13,055
Speaker 4:  our moderation decision here. Just weird. Yeah.

1783
01:36:13,075 --> 01:36:16,775
Speaker 4:  But if there's anything that's gonna get us to an antide fake law, it's deep

1784
01:36:16,785 --> 01:36:20,415
Speaker 4:  fakes. That's true. This caliber. That's true. It's real weird.

1785
01:36:20,645 --> 01:36:24,615
Speaker 4:  Yeah. Okay. So that's like DOGE and everyone's reporting on DOGE and like

1786
01:36:24,615 --> 01:36:27,815
Speaker 4:  the Times say as a whole list of all the people who work there, it's long

1787
01:36:27,815 --> 01:36:31,135
Speaker 4:  and extensive. It's definitely a coup. I just wanna be as clear as I can

1788
01:36:31,135 --> 01:36:34,695
Speaker 4:  be. There's a weird coup happening in our government. Yep. And it's by weird

1789
01:36:34,825 --> 01:36:38,375
Speaker 4:  nerds. Okay. We're gonna keep, we're gonna keep reporting on it.

1790
01:36:38,885 --> 01:36:42,775
Speaker 4:  Then there's like the regular Trump stuff that also happened this week,

1791
01:36:43,135 --> 01:36:46,895
Speaker 4:  which I find very funny because it, it just rhymes with the Trump won.

1792
01:36:47,935 --> 01:36:51,775
Speaker 4:  So like Tim Cook had a meeting with, with Donald Trump

1793
01:36:52,075 --> 01:36:56,055
Speaker 4:  and promised him $500 billion of US investment. They put

1794
01:36:56,055 --> 01:36:59,415
Speaker 4:  out a press release about it. They said they're gonna build a school in Michigan

1795
01:36:59,515 --> 01:37:03,375
Speaker 4:  for manufacturing. They're gonna do, they're gonna build servers

1796
01:37:03,835 --> 01:37:07,675
Speaker 4:  for Apple Intelligence. I guess they're all just gonna do Gen Moji all

1797
01:37:07,675 --> 01:37:09,635
Speaker 4:  day long. They're gonna build those in Houston.

1798
01:37:10,015 --> 01:37:11,675
Speaker 5:  Yet those guns don't generate themselves.

1799
01:37:12,165 --> 01:37:15,915
Speaker 4:  Right. So Trump is happy. 'cause he got, you know, I think whenever Tim Cook

1800
01:37:15,915 --> 01:37:18,475
Speaker 4:  promises him American manufacturing, he's like, screw it. They're making

1801
01:37:18,475 --> 01:37:22,075
Speaker 4:  iPhones in Kansas. Like he doesn't know he's not paying attention. And Trump

1802
01:37:22,215 --> 01:37:26,155
Speaker 4:  won. Famously Tim Cook opened a factory that was already open

1803
01:37:26,575 --> 01:37:29,875
Speaker 4:  and invited Trump to the grand opening of the already open

1804
01:37:30,265 --> 01:37:34,195
Speaker 4:  factory where they were gonna start making the M Pro that they

1805
01:37:34,195 --> 01:37:37,715
Speaker 4:  had already been making at the factory. Yeah. Fantastic. It's f you can,

1806
01:37:37,735 --> 01:37:40,395
Speaker 4:  you can, it's, it's, you can go look at it. It's a very confusing

1807
01:37:40,635 --> 01:37:43,075
Speaker 5:  Situation. I'm glad that Tim Cook knows that he can do this. At least

1808
01:37:43,375 --> 01:37:47,315
Speaker 4:  Tim Cook is trapped on a treadmill of his own making. Yeah. Like he can never

1809
01:37:47,315 --> 01:37:50,035
Speaker 4:  retire. His job is to manage Donald Trump. Yeah. Forever.

1810
01:37:51,055 --> 01:37:54,395
Speaker 4:  Anyway, so they announced this 500 bill investment, which is great. I, I

1811
01:37:54,745 --> 01:37:57,165
Speaker 4:  want Apple to invest in the United States. I think we should manufacture

1812
01:37:57,165 --> 01:38:00,165
Speaker 4:  more things here. All this is good, great for the economy. We should build

1813
01:38:00,165 --> 01:38:03,885
Speaker 4:  manufacturing centers of excellence in Detroit all day long. I have no

1814
01:38:04,125 --> 01:38:07,125
Speaker 4:  qualms with any of the things that they're doing, the substantive things

1815
01:38:07,125 --> 01:38:10,725
Speaker 4:  that they're doing. What I will point out is that the Wall Street Journal,

1816
01:38:10,865 --> 01:38:14,245
Speaker 4:  Rupert Murdoch's, wall Street Journal looked at the numbers

1817
01:38:16,075 --> 01:38:17,575
Speaker 4:  and they're like, these numbers are fake.

1818
01:38:18,695 --> 01:38:18,815
Speaker 5:  I

1819
01:38:18,815 --> 01:38:21,935
Speaker 4:  Love that. So I'm just gonna read you this paragraph in the Wall Street Journal.

1820
01:38:22,445 --> 01:38:25,895
Speaker 4:  Apple's $500 billion is mostly already on the books, is the headline.

1821
01:38:26,145 --> 01:38:29,775
Speaker 4:  Apple spent about $1.1 trillion in the past four fiscal years on total

1822
01:38:29,775 --> 01:38:33,615
Speaker 4:  operating expenses and capital expenditures. Wall Street expects

1823
01:38:33,615 --> 01:38:37,175
Speaker 4:  nearly 1.3 trillion in total expending over the next four years according

1824
01:38:37,175 --> 01:38:40,815
Speaker 4:  to consensus estimates. While Apple doesn't break out expenses per

1825
01:38:41,015 --> 01:38:44,975
Speaker 4:  geography, about 43% of its revenue comes from America. Assuming the

1826
01:38:44,975 --> 01:38:47,895
Speaker 4:  US constitutes the bulk of that number. If spending is in line with revenue,

1827
01:38:49,175 --> 01:38:53,025
Speaker 4:  then a rough figure of 40% of projected global spending through 2028

1828
01:38:53,375 --> 01:38:57,255
Speaker 4:  equates to about $505 billion. So If you just

1829
01:38:57,365 --> 01:38:58,895
Speaker 4:  math out how Apple spends money,

1830
01:39:00,695 --> 01:39:01,645
Speaker 4:  there you go. They

1831
01:39:01,645 --> 01:39:05,525
Speaker 5:  Used Apple Intelligence to rewrite their expenses and show Donald Trump the

1832
01:39:05,525 --> 01:39:05,725
Speaker 5:  expense.

1833
01:39:05,835 --> 01:39:07,525
Speaker 4:  This is just the money they were gonna spend. They

1834
01:39:07,525 --> 01:39:11,285
Speaker 5:  Took an Excel spreadsheet or I said numbers, spreadsheet and, and said

1835
01:39:11,285 --> 01:39:14,725
Speaker 5:  Apple Intelligence make this a press release. Yeah. And that's what it was.

1836
01:39:14,865 --> 01:39:18,725
Speaker 4:  You can argue with this, right? You can say Apple almost certainly does not

1837
01:39:19,015 --> 01:39:22,365
Speaker 4:  spend, does not invest in line with where revenue comes from. Right. They

1838
01:39:22,365 --> 01:39:25,085
Speaker 4:  do most of the manufacturing in China and, and other places overseas. Like

1839
01:39:25,145 --> 01:39:28,725
Speaker 4:  you can see all the stuff. But what you're, the, the, the

1840
01:39:28,955 --> 01:39:32,645
Speaker 4:  plan from Apple is always the same is they manage Trump

1841
01:39:32,745 --> 01:39:36,565
Speaker 4:  in particular because they cannot accept tariffs. So they manage

1842
01:39:36,565 --> 01:39:40,205
Speaker 4:  Trump in particular by, by making him promises that they have already

1843
01:39:40,275 --> 01:39:43,925
Speaker 4:  made to themselves and they just reannounce things and somehow Tim Cook has

1844
01:39:43,925 --> 01:39:47,085
Speaker 4:  just made an art of this. It is wild.

1845
01:39:47,315 --> 01:39:50,445
Speaker 5:  Yeah. I mean it's the show is the thing. Right. And there's a, there's a

1846
01:39:50,445 --> 01:39:53,165
Speaker 5:  bunch of really fun details in all of it though. Like, I think Apple's plan

1847
01:39:53,235 --> 01:39:57,085
Speaker 5:  that they said was to hire 20,000 people over the next four years, which

1848
01:39:57,085 --> 01:40:00,805
Speaker 5:  is roughly in line with Apple's ongoing hiring plans. They hire

1849
01:40:00,805 --> 01:40:04,645
Speaker 5:  about 5,000 people a year. Incredible. They were gonna, there was like a

1850
01:40:04,645 --> 01:40:08,525
Speaker 5:  big thing. They were gonna spend a bunch of money with TSMC in Arizona, apple

1851
01:40:08,585 --> 01:40:11,365
Speaker 5:  is already the largest customer of TSMC in Arizona. It's like

1852
01:40:12,425 --> 01:40:15,645
Speaker 5:  all you have to do is look at it, but you get to write the thing that's like,

1853
01:40:15,645 --> 01:40:19,205
Speaker 5:  thank you Donald Trump. We're spending $500 billion and like e everybody

1854
01:40:19,355 --> 01:40:23,005
Speaker 5:  wins. Right? Like is it, is it ruthless in calculating and not really true?

1855
01:40:23,475 --> 01:40:26,925
Speaker 5:  Yeah. But it's, it's, I feel the same way about it that I do about the, everybody

1856
01:40:28,035 --> 01:40:30,845
Speaker 5:  sending a million dollars to go to the inauguration. It's like

1857
01:40:31,925 --> 01:40:35,805
Speaker 5:  I get it. Like it is obviously straightforwardly good business and also

1858
01:40:35,805 --> 01:40:36,965
Speaker 5:  you should feel bad about yourself.

1859
01:40:37,155 --> 01:40:40,345
Speaker 4:  Yeah. It's just weird. 'cause there's this big split between, you know,

1860
01:40:40,935 --> 01:40:44,155
Speaker 4:  like classic Trump corruption, you know, like

1861
01:40:44,905 --> 01:40:47,495
Speaker 4:  these, he's a real estate developer so you gotta spend money on his party,

1862
01:40:48,195 --> 01:40:50,455
Speaker 4:  you know, and it's like, oh, he is a club promoter. You gotta do some like

1863
01:40:50,455 --> 01:40:54,235
Speaker 4:  club promoting stuff. Like great, you know, like Trump won, like we,

1864
01:40:54,295 --> 01:40:58,115
Speaker 4:  we lived it and this is substantially better than, for example, Foxcon

1865
01:40:58,115 --> 01:41:01,235
Speaker 4:  announcing LCD factory in Wisconsin that they never built. Right.

1866
01:41:02,045 --> 01:41:05,355
Speaker 4:  Apple announced some stuff, it's already doing great. That's right next to

1867
01:41:05,355 --> 01:41:08,635
Speaker 4:  the DOGE corruption, which is like weird secrets

1868
01:41:09,255 --> 01:41:13,195
Speaker 4:  and like straightforwardly illegal and unconstitutional power grabs by

1869
01:41:13,225 --> 01:41:15,395
Speaker 4:  Elon Musk that everyone's just like, oh that's new.

1870
01:41:16,395 --> 01:41:17,845
Speaker 5:  There's a good one of those this week

1871
01:41:18,065 --> 01:41:20,765
Speaker 4:  In fact. Yeah, this FAA thing. Yeah. What's going on there?

1872
01:41:21,225 --> 01:41:25,205
Speaker 5:  So basically the, the short version of it is it looks like the

1873
01:41:25,285 --> 01:41:29,205
Speaker 5:  FAA which has been kind of infiltrated with

1874
01:41:29,205 --> 01:41:32,765
Speaker 5:  SpaceX employees who have showed up to, you know, quote unquote fix the FAA

1875
01:41:33,585 --> 01:41:37,565
Speaker 5:  may take a $2.4 billion contract that it

1876
01:41:37,585 --> 01:41:41,445
Speaker 5:  had given to Verizon in order to do, I don't know,

1877
01:41:41,525 --> 01:41:45,125
Speaker 5:  FAA things, I don't pretend to know what the FAA does, but there was

1878
01:41:45,125 --> 01:41:48,925
Speaker 5:  $2.4 billion that now they would like to give to starlink

1879
01:41:48,955 --> 01:41:52,565
Speaker 5:  instead. And there's been a big focus

1880
01:41:52,905 --> 01:41:56,325
Speaker 5:  of a lot of very good reporting over the last couple of weeks about the very

1881
01:41:56,565 --> 01:42:00,405
Speaker 5:  straightforward ways in which DOGE is going into departments

1882
01:42:00,405 --> 01:42:04,085
Speaker 5:  that either regulate Elon Musk's companies and destroying them or

1883
01:42:04,515 --> 01:42:08,325
Speaker 5:  give money to Elon Musk's companies and taking more money from them.

1884
01:42:09,145 --> 01:42:12,925
Speaker 5:  And this is just, this is just that again, and like this is

1885
01:42:13,135 --> 01:42:16,925
Speaker 5:  money that was give was awarded to

1886
01:42:16,925 --> 01:42:20,845
Speaker 5:  Verizon that is now being reconsidered. And a bunch of people who work for

1887
01:42:21,025 --> 01:42:24,765
Speaker 5:  SpaceX are now at the FAA saying, oh actually this money should go to

1888
01:42:24,785 --> 01:42:28,485
Speaker 5:  SpaceX. And everybody's like, isn't that corruption? And it's like, yes

1889
01:42:29,345 --> 01:42:30,525
Speaker 5:  and no one, and who cares?

1890
01:42:30,905 --> 01:42:33,645
Speaker 4:  So here's how Elon is justifying this, which is a delight.

1891
01:42:34,945 --> 01:42:37,765
Speaker 4:  So I dunno if you've been noticing this, like it's not been great for air

1892
01:42:37,765 --> 01:42:41,485
Speaker 4:  travel in the United States lately. So Elon has decided to blame this not

1893
01:42:41,485 --> 01:42:45,445
Speaker 4:  on firing a bunch of FAA employees, which is a thing that he did

1894
01:42:46,095 --> 01:42:46,445
Speaker 4:  Weird,

1895
01:42:46,445 --> 01:42:47,925
Speaker 5:  Including the head of the FAA

1896
01:42:48,075 --> 01:42:51,005
Speaker 4:  What If you traumatize everybody who works at the FAA

1897
01:42:51,945 --> 01:42:54,485
Speaker 4:  and then you're like, but we made your internet connectivity a little bit

1898
01:42:54,485 --> 01:42:58,405
Speaker 4:  better. Do you think that will fix it? You know, I run a podcast

1899
01:42:58,405 --> 01:43:01,085
Speaker 4:  that's largely about management that has never come up as an idea.

1900
01:43:03,105 --> 01:43:06,965
Speaker 4:  So he's traumatized this workforce, he's stressed them, he's

1901
01:43:06,965 --> 01:43:10,845
Speaker 4:  cut them, they're, they're mad and then he's blaming all the

1902
01:43:10,845 --> 01:43:14,005
Speaker 4:  air traffic problems on a

1903
01:43:14,405 --> 01:43:17,285
Speaker 4:  communication system that is quote, breaking down very rapidly.

1904
01:43:18,305 --> 01:43:21,885
Speaker 4:  And also quote from Elon, not back up by the FAA itself,

1905
01:43:22,325 --> 01:43:25,725
Speaker 4:  FAA assessment is single digit months to catastrophic failure.

1906
01:43:26,115 --> 01:43:28,605
Speaker 4:  Putting air traveler safety at serious risk.

1907
01:43:30,465 --> 01:43:34,325
Speaker 4:  That's a big claim. Like you, you gotta back that one. Someone at the

1908
01:43:34,465 --> 01:43:38,205
Speaker 4:  FAA should be like, here's the report that says we are nine months

1909
01:43:38,275 --> 01:43:41,205
Speaker 4:  away from catastrophic air control failure.

1910
01:43:42,515 --> 01:43:45,765
Speaker 4:  That hasn't happened. Just putting that out there hasn't happened.

1911
01:43:46,275 --> 01:43:49,325
Speaker 5:  Also, you know, who didn't make that system is Verizon. Right?

1912
01:43:49,325 --> 01:43:53,165
Speaker 4:  They haven't started yet. Right. This is the new system. So it's

1913
01:43:53,235 --> 01:43:57,075
Speaker 4:  unclear what he thinks is breaking, he's saying

1914
01:43:57,075 --> 01:44:00,435
Speaker 4:  he's providing starlink terminals at no cost to taxpayer on an emergency

1915
01:44:00,435 --> 01:44:04,115
Speaker 4:  basis to restore air traffic control connectivity,

1916
01:44:04,295 --> 01:44:05,955
Speaker 6:  No cost to taxpayer. Right?

1917
01:44:05,985 --> 01:44:09,115
Speaker 4:  Well there's that, but it's also like, so wait, is it just internet access?

1918
01:44:09,275 --> 01:44:10,635
Speaker 4:  'cause that's what starlink is.

1919
01:44:11,145 --> 01:44:11,435
Speaker 6:  Yeah.

1920
01:44:11,935 --> 01:44:13,875
Speaker 4:  Are is it, are you saying that's

1921
01:44:13,875 --> 01:44:15,315
Speaker 6:  Not the system? That's just the internet?

1922
01:44:15,345 --> 01:44:19,255
Speaker 4:  Yeah. Are you saying Verizon can't put some Fios in at the

1923
01:44:19,255 --> 01:44:19,695
Speaker 4:  airport?

1924
01:44:22,765 --> 01:44:26,655
Speaker 4:  What are you, like, what are we talking about here? Like I know I have, I

1925
01:44:26,655 --> 01:44:29,575
Speaker 4:  have, I have many problems with our nation's ISPs.

1926
01:44:31,615 --> 01:44:35,575
Speaker 4:  I I think most of them are bad. I think if any is PCEO wants to come on

1927
01:44:35,575 --> 01:44:37,815
Speaker 4:  the show, I will look them in the eye and say, I think you did a bad job.

1928
01:44:38,715 --> 01:44:41,055
Speaker 4:  You're charging people too much money. Great.

1929
01:44:42,765 --> 01:44:46,645
Speaker 4:  Provisioning internet access at the airport is like actually not a problem

1930
01:44:46,955 --> 01:44:47,565
Speaker 4:  that they have.

1931
01:44:48,165 --> 01:44:51,965
Speaker 6:  I was gonna say, I don't think I've ever said poor Verizon before. Yeah.

1932
01:44:52,225 --> 01:44:56,165
Speaker 6:  In this, and we'll see, I still, you know, but in this case it's

1933
01:44:56,165 --> 01:44:56,245
Speaker 6:  like,

1934
01:44:56,945 --> 01:44:59,405
Speaker 4:  But he's taking a $2.4 billion contract for

1935
01:44:59,405 --> 01:45:01,845
Speaker 5:  Himself. There's just a lot of that going on right now. And there's like,

1936
01:45:01,845 --> 01:45:05,485
Speaker 5:  there was some really fun follow up on the

1937
01:45:05,485 --> 01:45:09,285
Speaker 5:  $400 million State Department planned to buy cyber trucks

1938
01:45:09,635 --> 01:45:12,685
Speaker 5:  that they originally tried to blame on the Biden administration, but it turns

1939
01:45:12,685 --> 01:45:15,685
Speaker 5:  out when it was the Biden administration it was $400,000 and then they made

1940
01:45:15,685 --> 01:45:18,205
Speaker 5:  it $400 million on the Trump administration and then they canceled the whole

1941
01:45:18,205 --> 01:45:21,105
Speaker 5:  thing. It's like, it's just, it's just

1942
01:45:21,735 --> 01:45:25,465
Speaker 5:  nakedly obvious what everyone is doing here. And the question is just,

1943
01:45:25,525 --> 01:45:29,105
Speaker 5:  is anyone going to stop them at this point? Yeah. And that to me feels like

1944
01:45:29,145 --> 01:45:29,985
Speaker 5:  a very open question.

1945
01:45:30,465 --> 01:45:34,265
Speaker 4:  I think Elon's drug use will stop it before

1946
01:45:34,425 --> 01:45:38,105
Speaker 4:  a person. Hmm. That's my, my current going theory.

1947
01:45:38,255 --> 01:45:38,545
Speaker 4:  It's

1948
01:45:38,545 --> 01:45:41,375
Speaker 6:  A period of time. Could be Yeah. A period of time.

1949
01:45:41,875 --> 01:45:45,775
Speaker 4:  My man's obviously like living hard right now. Yeah, yeah. I've seen

1950
01:45:45,775 --> 01:45:46,935
Speaker 4:  him on many stages talking.

1951
01:45:47,035 --> 01:45:50,695
Speaker 5:  All right, NELI, it's time for America's favorite segment. The podcast within

1952
01:45:50,815 --> 01:45:54,255
Speaker 5:  a podcast. We took a break last week and the people, the people demand it.

1953
01:45:54,815 --> 01:45:56,215
Speaker 4:  All right, let's wrap it up. It's

1954
01:45:56,215 --> 01:45:57,295
Speaker 5:  Time for Brendan Carr is a dummy,

1955
01:45:57,535 --> 01:46:01,055
Speaker 4:  A new segment here on America's favorite podcast about the FCC. Brendan Carr's

1956
01:46:01,055 --> 01:46:05,015
Speaker 4:  a dummy. So let me just say, I'm just gonna say

1957
01:46:05,015 --> 01:46:08,175
Speaker 4:  this sentence to you this week, Brendan Carr,

1958
01:46:08,985 --> 01:46:12,955
Speaker 4:  the chairman of the FCC has decided the best use

1959
01:46:13,535 --> 01:46:16,715
Speaker 4:  of his authority is an unelected

1960
01:46:16,965 --> 01:46:20,885
Speaker 4:  censorship cop is to attack a

1961
01:46:20,885 --> 01:46:21,885
Speaker 4:  country music festival.

1962
01:46:22,145 --> 01:46:24,125
Speaker 5:  That's not where I thought that sentence was go. That's the

1963
01:46:24,205 --> 01:46:26,125
Speaker 4:  Opposite. That what's doing thought that was gonna go. That's, that's what

1964
01:46:26,125 --> 01:46:29,165
Speaker 4:  our man is doing this week. I, I wanna be a hundred percent clear, this is

1965
01:46:29,205 --> 01:46:33,165
Speaker 4:  a real thing that the notable idiot Brendan Carr has decided to

1966
01:46:33,165 --> 01:46:36,685
Speaker 4:  do this week. So the I the iHeart Media runs the

1967
01:46:36,745 --> 01:46:40,645
Speaker 4:  iHeart Country Festival and he sent a letter

1968
01:46:40,705 --> 01:46:43,965
Speaker 4:  to Bob Pittman, the CEO of iHeart

1969
01:46:44,465 --> 01:46:47,325
Speaker 4:  saying, Hey, are you doing some Paola?

1970
01:46:48,305 --> 01:46:51,685
Speaker 4:  Are you saying if people take cheaper rates to play the iHeart Country

1971
01:46:52,125 --> 01:46:55,405
Speaker 4:  Festival, that you'll give them more airtime and iHeart radio stations

1972
01:46:56,345 --> 01:46:59,885
Speaker 4:  in a vacuum? This should be a great story in

1973
01:47:00,125 --> 01:47:00,845
Speaker 4:  1954,

1974
01:47:02,545 --> 01:47:06,485
Speaker 4:  in reality, I don't know if anyone has heard of this company called Spotify,

1975
01:47:06,855 --> 01:47:09,525
Speaker 4:  which just does naked payola all the time,

1976
01:47:10,905 --> 01:47:13,685
Speaker 4:  but because iHeart runs radio stations

1977
01:47:14,985 --> 01:47:18,925
Speaker 4:  and Brendan has regulatory control over the airwaves, he

1978
01:47:18,925 --> 01:47:22,845
Speaker 4:  gets to make political hay with a certain constituency by saying, I'm attacking

1979
01:47:22,845 --> 01:47:26,485
Speaker 4:  Country Music Festival to make sure there's no liberal corruption

1980
01:47:26,985 --> 01:47:30,925
Speaker 4:  in country music. No problem. That has played

1981
01:47:30,925 --> 01:47:33,445
Speaker 4:  country music for years now.

1982
01:47:34,755 --> 01:47:38,735
Speaker 4:  Just stupid. Like it's you iHeart's

1983
01:47:38,735 --> 01:47:42,535
Speaker 4:  a monopoly. Like Yeah dude, there's weird corruption in

1984
01:47:42,535 --> 01:47:46,415
Speaker 4:  iHeart media and Clear iHeart used to be Clear channel. If

1985
01:47:46,415 --> 01:47:49,655
Speaker 4:  you're like a nineties kid like me, clear Channel is like one of the most

1986
01:47:49,845 --> 01:47:53,815
Speaker 4:  nakedly corrupt media enterprises like in this country's history.

1987
01:47:54,445 --> 01:47:58,375
Speaker 4:  Yeah dude, they're, they're doing some payola at the Country Music festival.

1988
01:47:59,525 --> 01:48:02,695
Speaker 4:  Good job. Yeah, good job Brendan. He followed up, by the way, he had a closed

1989
01:48:02,695 --> 01:48:06,495
Speaker 4:  door meeting with Republican members of Congress to talk

1990
01:48:06,495 --> 01:48:10,215
Speaker 4:  about George Soros owning radio stations and what he can do about that.

1991
01:48:11,295 --> 01:48:14,895
Speaker 4:  I would just point out Rupert Murdoch also owns a bunch of radio

1992
01:48:14,895 --> 01:48:18,295
Speaker 4:  stations, TV stations in this country. He doesn't seem to be a problem. It's

1993
01:48:18,295 --> 01:48:21,775
Speaker 4:  definitely George Soros. So we're just doing partisan censorship

1994
01:48:22,275 --> 01:48:26,115
Speaker 4:  by Brennan Carter. None of this makes any sense because none of it

1995
01:48:26,115 --> 01:48:29,675
Speaker 4:  stands up to even the slightest bit of like intellectual scrutiny.

1996
01:48:30,135 --> 01:48:32,955
Speaker 4:  He just likes having the power of being an unelected censor.

1997
01:48:34,715 --> 01:48:38,055
Speaker 4:  And that brings us all the way to the stupidest thing that he's doing, which

1998
01:48:38,085 --> 01:48:41,855
Speaker 4:  he's making these noises about reinterpreting

1999
01:48:41,855 --> 01:48:43,015
Speaker 4:  Section two 30

2000
01:48:44,785 --> 01:48:47,845
Speaker 4:  to, I dunno, make it easier for him to put Mark Zuckerberg in jail or something.

2001
01:48:47,845 --> 01:48:51,525
Speaker 4:  Right. Section two 30 is a law that says the big companies are not liable

2002
01:48:51,545 --> 01:48:54,925
Speaker 4:  for what the users post on their platforms. So if I put something Instagram,

2003
01:48:54,945 --> 01:48:58,725
Speaker 4:  you can't sue Mark Zuckerberg over what is on my Instagram account. The whole

2004
01:48:58,925 --> 01:49:02,765
Speaker 4:  internet relies on this lawsuit. The our comment section relies on the S

2005
01:49:02,765 --> 01:49:06,685
Speaker 4:  law, existing Reddit, you name it next door. But he's like, we

2006
01:49:06,705 --> 01:49:10,165
Speaker 4:  got a reign in big tech and I will

2007
01:49:10,445 --> 01:49:12,405
Speaker 4:  reinterpret section two 30, unelected

2008
01:49:14,785 --> 01:49:18,655
Speaker 4:  deeply unstylish Brendan Carr will reinterpret

2009
01:49:19,125 --> 01:49:22,735
Speaker 4:  this law, which was written by the way, by people who are still alive.

2010
01:49:23,285 --> 01:49:27,115
Speaker 4:  Like Ron Wyden wrote section two 30. He was on decoder two weeks

2011
01:49:27,115 --> 01:49:30,195
Speaker 4:  ago. You could just ask him what he thinks it means, but Brendan Carr is

2012
01:49:30,195 --> 01:49:33,985
Speaker 4:  going just reinterpret it somehow he

2013
01:49:34,185 --> 01:49:36,985
Speaker 4:  released this in a story in the New York Post that I swear to you is written

2014
01:49:37,175 --> 01:49:41,105
Speaker 4:  like the worst LinkedIn poetry I've ever seen in my entire life.

2015
01:49:41,415 --> 01:49:44,425
Speaker 4:  Like just one sentence long paragraph in the story just says social media

2016
01:49:44,485 --> 01:49:47,565
Speaker 4:  has replaced chat rooms. End of sentence, end of paragraph.

2017
01:49:48,425 --> 01:49:48,645
Speaker 4:  Why

2018
01:49:50,195 --> 01:49:53,605
Speaker 4:  it's very confusing. We'll link to it. Just I want you to know this is some,

2019
01:49:53,605 --> 01:49:57,165
Speaker 4:  this is like the VO on poetry of policy writing in the New York Post. Like

2020
01:49:57,395 --> 01:50:01,245
Speaker 4:  it's so bad. And the idea is that he will somehow

2021
01:50:01,805 --> 01:50:04,445
Speaker 4:  reinterpret section two 30 to make Facebook a publisher and then everyone

2022
01:50:04,445 --> 01:50:07,925
Speaker 4:  can sue Facebook defamation. This is absolutely not how that law is supposed

2023
01:50:07,925 --> 01:50:11,645
Speaker 4:  to work. This is the height of stupidity from Brendan Carr. And I know this

2024
01:50:11,645 --> 01:50:15,485
Speaker 4:  because again, the guy who wrote the law talks to us all the time. He was

2025
01:50:15,485 --> 01:50:19,045
Speaker 4:  just on our shows like two weeks ago and this is not what he meant when he

2026
01:50:19,045 --> 01:50:19,525
Speaker 4:  wrote the law.

2027
01:50:19,805 --> 01:50:23,325
Speaker 5:  I do feel like it's dangerous for you to say at any time that this is the

2028
01:50:23,325 --> 01:50:27,085
Speaker 5:  height of Brendan Carr's stupidity because like it's still

2029
01:50:27,085 --> 01:50:29,365
Speaker 5:  early. My dude, we're only like six weeks into this.

2030
01:50:29,705 --> 01:50:32,885
Speaker 4:  That's true. Well look, he's gonna take down a country music festival first.

2031
01:50:33,875 --> 01:50:36,885
Speaker 4:  There's one thing you want the FCC of this country doing. It's attacking

2032
01:50:36,885 --> 01:50:39,765
Speaker 4:  the country music industry. What are you doing Anyway, Brendan, as always,

2033
01:50:40,165 --> 01:50:44,085
Speaker 4:  I know you listen, I I know your staff gives you readouts. I, I I I,

2034
01:50:44,155 --> 01:50:47,645
Speaker 4:  I've known it for years buddy, If you wanna come onto coder or, or come on

2035
01:50:47,645 --> 01:50:51,445
Speaker 4:  this show, you can tell us about your smart home setup. I bet it sucks. You're

2036
01:50:51,445 --> 01:50:55,145
Speaker 4:  welcome to, you're just not very smart Brendan. You're welcome to come on

2037
01:50:55,145 --> 01:50:58,985
Speaker 4:  the show and face an actual hostile interviewer who questions your use

2038
01:50:58,985 --> 01:51:02,185
Speaker 4:  of the governance's power to shut down speech that you don't like. 'cause

2039
01:51:02,185 --> 01:51:04,585
Speaker 4:  that's what you're doing every single time and we're just not gonna let you

2040
01:51:04,585 --> 01:51:08,335
Speaker 4:  off the hook. All right, that was our weekly segment. Brenda

2041
01:51:08,335 --> 01:51:08,935
Speaker 4:  Carr's dummy,

2042
01:51:08,955 --> 01:51:12,255
Speaker 5:  We need theme music. Brandon Keefer on our team, I will tell you has been

2043
01:51:12,365 --> 01:51:15,975
Speaker 5:  quietly creating theme music for Brenda Carr as a dummy. And

2044
01:51:16,415 --> 01:51:18,535
Speaker 5:  there is a chance we are going to roll that out at some point in the day

2045
01:51:18,535 --> 01:51:19,655
Speaker 5:  in your future. So get

2046
01:51:19,655 --> 01:51:23,455
Speaker 4:  Ready. Can you just imagine waking up and being like, huh, I should control

2047
01:51:23,455 --> 01:51:27,255
Speaker 4:  speech in this country. What I will do with that power that I've given myself

2048
01:51:27,355 --> 01:51:31,175
Speaker 4:  for no reason is attack a country music festival. Yeah. Run

2049
01:51:31,175 --> 01:51:32,175
Speaker 4:  by iHeart Media.

2050
01:51:32,395 --> 01:51:34,375
Speaker 5:  That's the consequential stuff right there. When

2051
01:51:34,375 --> 01:51:36,775
Speaker 4:  I think of complete corrupt

2052
01:51:38,395 --> 01:51:38,815
Speaker 4:  iHeart,

2053
01:51:39,595 --> 01:51:41,895
Speaker 5:  Go after Coachella first and then we'll talk, you know what I mean?

2054
01:51:41,895 --> 01:51:44,615
Speaker 4:  David, I'm gonna read you this sentence and you gotta tell me it's a pallet

2055
01:51:44,615 --> 01:51:48,415
Speaker 4:  cleanser for a two hour birch house. Okay. Automatic combines, beeper

2056
01:51:48,415 --> 01:51:50,775
Speaker 4:  and text.com messaging services. What does that

2057
01:51:50,775 --> 01:51:52,055
Speaker 5:  Mean? So this is two hours easily.

2058
01:51:54,715 --> 01:51:58,345
Speaker 5:  So we talked a lot on the show about beeper

2059
01:51:58,645 --> 01:52:02,625
Speaker 5:  the messaging app that ran afoul of Apple in some really interesting

2060
01:52:02,625 --> 01:52:06,465
Speaker 5:  and complicated ways. Beeper eventually sold to Automatic. The

2061
01:52:06,465 --> 01:52:10,265
Speaker 5:  company that owns wordpress.com, they'll email

2062
01:52:10,265 --> 01:52:14,225
Speaker 5:  me if I'm not stat specific about which part of WordPress automatic overseas

2063
01:52:15,255 --> 01:52:19,145
Speaker 5:  automatic kind of a mess because Matt Mullenweg is having a weird

2064
01:52:19,145 --> 01:52:22,145
Speaker 5:  time on the internet right now. They're in lawsuits. But anyway,

2065
01:52:23,375 --> 01:52:26,705
Speaker 5:  they made this big bet on messaging. They bought both beeper and this company

2066
01:52:26,855 --> 01:52:30,145
Speaker 5:  text.com, which is doing the same kind of thing that Beeper was doing.

2067
01:52:30,255 --> 01:52:33,465
Speaker 5:  Basically trying to like unify all of your messaging apps into one messaging

2068
01:52:33,465 --> 01:52:33,625
Speaker 5:  app.

2069
01:52:35,175 --> 01:52:38,865
Speaker 5:  Eric Midkowski, who was the head of beeper, at least as I

2070
01:52:38,865 --> 01:52:42,545
Speaker 5:  understood it, was going to run this whole new thing. The combination of

2071
01:52:42,545 --> 01:52:46,405
Speaker 5:  the text.com team and the beeper team at Automatic Eric Micki

2072
01:52:46,405 --> 01:52:49,565
Speaker 5:  since left and is now doing Pebble again. And so

2073
01:52:50,195 --> 01:52:53,685
Speaker 5:  Kean Aria who was running text.com is now in charge of this whole team

2074
01:52:54,065 --> 01:52:57,925
Speaker 5:  and they just put out betas of the first new apps, which

2075
01:52:57,925 --> 01:53:01,725
Speaker 5:  are essentially just reskinned text.com apps into

2076
01:53:02,485 --> 01:53:06,125
Speaker 5:  a thing that is now called Beeper. So Beeper is the new name, but text.com

2077
01:53:06,125 --> 01:53:09,885
Speaker 5:  appears to be the actual technology. They redid an

2078
01:53:09,885 --> 01:53:13,525
Speaker 5:  iPhone app, but they're still at this like unified messaging everywhere thing.

2079
01:53:14,125 --> 01:53:18,005
Speaker 5:  I downloaded the betas, they're as interesting and messy

2080
01:53:18,185 --> 01:53:22,165
Speaker 5:  as ever, but they appear to be still

2081
01:53:22,625 --> 01:53:26,485
Speaker 5:  for real at this game. I had a, I wondered if after all

2082
01:53:26,485 --> 01:53:30,445
Speaker 5:  of the Apple kerfuffle, if they would just spin out a different direction

2083
01:53:30,445 --> 01:53:34,045
Speaker 5:  and try to do something else in messaging. But Automatic appears to be

2084
01:53:34,405 --> 01:53:35,325
Speaker 5:  actually pushing towards this.

2085
01:53:35,975 --> 01:53:39,365
Speaker 4:  Huh? That all made sense. I think Brendan cars should arrest them.

2086
01:53:39,365 --> 01:53:41,725
Speaker 5:  There you go. I'm here to help. Also, before we go, I have some breaking

2087
01:53:41,755 --> 01:53:44,685
Speaker 5:  news. Yeah. Oh, Andy Jassy, the CEO of Amazon

2088
01:53:45,555 --> 01:53:49,005
Speaker 5:  said this afternoon on Bloomberg

2089
01:53:49,005 --> 01:53:51,765
Speaker 5:  television that Amazon is going to be releasing

2090
01:53:52,875 --> 01:53:55,805
Speaker 5:  some new Alexa devices this fall.

2091
01:53:57,205 --> 01:54:00,265
Speaker 5:  And he said the sentence, I think there's a sustainable business model,

2092
01:54:00,875 --> 01:54:02,065
Speaker 5:  which is always what you wanna hear.

2093
01:54:02,405 --> 01:54:05,105
Speaker 4:  That's good. That makes sense. That tracks what basically what pun us was

2094
01:54:05,105 --> 01:54:05,265
Speaker 4:  saying.

2095
01:54:05,535 --> 01:54:09,265
Speaker 5:  Yeah, so it's, it's, this is 2025,

2096
01:54:09,545 --> 01:54:13,385
Speaker 5:  I think in two runs just became the year. Alexa is either going to work

2097
01:54:13,485 --> 01:54:16,025
Speaker 5:  or collapse in a really fascinating way. Yeah,

2098
01:54:16,535 --> 01:54:19,265
Speaker 4:  It's definitely gonna turn on all the lights in your house full booking you

2099
01:54:19,265 --> 01:54:22,465
Speaker 4:  a ticket to Japan. It's you can get outta here

2100
01:54:22,565 --> 01:54:24,865
Speaker 5:  And then an Uber will show up and bring you to JFK. Yeah.

2101
01:54:25,245 --> 01:54:28,505
Speaker 4:  Or drugs. It's one or the other. Or drugs. All right. David, thank you so

2102
01:54:28,505 --> 01:54:30,545
Speaker 4:  much for being here. Thank you. That was incredible my man. Appreciate it.

2103
01:54:30,545 --> 01:54:34,385
Speaker 4:  We'll have you back soon. Other David, you're fun. Take it. That was it.

2104
01:54:34,385 --> 01:54:35,625
Speaker 4:  That was for chest rock and roll.

2105
01:54:41,285 --> 01:54:44,465
Speaker 9:  And that's it for The Vergecast this week. And hey, we'd love to hear from

2106
01:54:44,465 --> 01:54:48,105
Speaker 9:  you. Give us a call at eight six six VERGE one one.

2107
01:54:48,285 --> 01:54:51,665
Speaker 9:  The Vergecast is a production of The Verge and the Vox Media podcast network.

2108
01:54:51,965 --> 01:54:55,945
Speaker 9:  Our show's produced by Will Pour Eric Gomez and Brandon Keefer. And

2109
01:54:56,105 --> 01:54:57,345
Speaker 9:  that's it. We'll see you next week.

