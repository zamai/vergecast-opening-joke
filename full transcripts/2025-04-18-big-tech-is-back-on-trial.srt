1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 7ae83d1f-c660-4855-811b-24103221d636
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-3701131980461434292/-8130743035916934478/s93290-US-6844s-1744969534.mp3
Description: We promise, this episode is only a little bit about header bidding. Nilay and David are joined by The Verge’s Alex Heath to talk about some big news in tech regulation: Google lost its ad-tech monopoly trial, which could reshape both Google and the internet altogether. And that’s not the only monopoly news! Meta’s trial also started this week, and Alex was there to see Mark Zuckerberg and others try to defend Instagram, WhatsApp, and the company as a whole. After all that, we talk about OpenAI’s plans to build a social network, and how this company seems to never run out of ambition. Finally, in the lightning round, it’s time for another round of Brendan Carr is a Dummy, and some news about viral cameras and the Switch 2. Which we’ll be yeeting into our homes as soon as possible



2
00:01:46,145 --> 00:01:50,135
Speaker 5:  Hello and welcome to Vergecast the flagship podcast. Knowing what Facebook

3
00:01:50,135 --> 00:01:53,135
Speaker 5:  is just surprisingly complicated.

4
00:01:54,065 --> 00:01:56,655
Speaker 5:  We're gonna, we're gonna explain that in great detail. I'm your friend Neli

5
00:01:56,655 --> 00:01:57,935
Speaker 5:  David Pierce is here. Hey,

6
00:01:57,965 --> 00:02:00,975
Speaker 6:  It's gonna be a very short podcast if we have to attempt to explain what

7
00:02:01,135 --> 00:02:03,055
Speaker 5:  Facebook is or the world's longest podcast,

8
00:02:03,455 --> 00:02:04,775
Speaker 6:  Podcast ever. Yeah.

9
00:02:05,045 --> 00:02:08,815
Speaker 5:  Alex Heath is here direct from the the Meta and Antitrust trial.

10
00:02:09,035 --> 00:02:12,895
Speaker 5:  What's up Alex? I'm just over here on me. We guys come on in.

11
00:02:12,915 --> 00:02:13,615
Speaker 5:  The water's warm.

12
00:02:15,155 --> 00:02:18,655
Speaker 5:  The best part of any antitrust trial is when the accused monopoly

13
00:02:18,765 --> 00:02:22,615
Speaker 5:  insists that insane things are true competitors.

14
00:02:23,355 --> 00:02:27,335
Speaker 5:  So Comcast will be like, yes, like infrared internet

15
00:02:27,395 --> 00:02:30,815
Speaker 5:  is a real competitor to our fiber network. Whenever it's like that's not,

16
00:02:31,635 --> 00:02:33,695
Speaker 5:  and they're always like, we're so helpless and weak. And that's very much

17
00:02:33,695 --> 00:02:37,055
Speaker 5:  what Meta is doing in the, in the courtroom with other networks like me.

18
00:02:37,055 --> 00:02:40,535
Speaker 5:  We, so we gotta talk about that. Alex was in the courtroom with Lauren finer.

19
00:02:40,535 --> 00:02:43,935
Speaker 5:  Mark Zuckerberg was on the stand for a long time this week.

20
00:02:44,305 --> 00:02:47,215
Speaker 5:  We're gonna talk about all that. But what's wild

21
00:02:48,315 --> 00:02:52,155
Speaker 5:  is that while all that was happening, the Google

22
00:02:52,615 --> 00:02:56,555
Speaker 5:  Ad Tech antitrust case got a decision and the court

23
00:02:56,565 --> 00:03:00,405
Speaker 5:  ruled that Google has a monopoly in ad tech. And I don't even remember this.

24
00:03:00,465 --> 00:03:03,685
Speaker 5:  We forced David to go to that trial way back when

25
00:03:04,415 --> 00:03:08,085
Speaker 5:  David just briefly sum up what that trial was like.

26
00:03:08,395 --> 00:03:12,005
Speaker 6:  Sure. I should, I should say poor Lauren Finer had to go to a lot more of

27
00:03:12,005 --> 00:03:15,645
Speaker 6:  that one than I did. Yeah. I just had to go for a couple of days

28
00:03:16,435 --> 00:03:20,325
Speaker 6:  because she couldn't or just didn't want to. Or like, I think at

29
00:03:20,325 --> 00:03:23,445
Speaker 6:  some point you spend enough time listening to people explain how ad exchanges

30
00:03:23,445 --> 00:03:27,405
Speaker 6:  work and you're like, I can't do this anymore and I have to leave. But

31
00:03:27,405 --> 00:03:30,725
Speaker 6:  anyway, so basically this case was about

32
00:03:31,095 --> 00:03:31,685
Speaker 6:  three things.

33
00:03:33,265 --> 00:03:37,085
Speaker 6:  One was, did Google acquire its way

34
00:03:37,195 --> 00:03:40,285
Speaker 6:  into a monopoly in advertising technology?

35
00:03:41,345 --> 00:03:45,285
Speaker 6:  Two was is Google basically putting all

36
00:03:45,285 --> 00:03:49,245
Speaker 6:  the different pieces of its advertising puzzle together in a way that

37
00:03:49,245 --> 00:03:52,365
Speaker 6:  is illegal? And three is basically

38
00:03:53,035 --> 00:03:56,885
Speaker 6:  does the sort of breadth of Google as a, as a search engine,

39
00:03:56,905 --> 00:04:00,725
Speaker 6:  as a publishing engine for the rest of the internet, like is Google

40
00:04:00,945 --> 00:04:03,805
Speaker 6:  so big that it should not have this much power over how advertising works?

41
00:04:04,305 --> 00:04:08,285
Speaker 6:  And they spent, I mean just, just like weeks litigating

42
00:04:08,285 --> 00:04:12,205
Speaker 6:  like the deep tech of the ad stack. But what it really came down to

43
00:04:12,205 --> 00:04:16,085
Speaker 6:  is Google owns advertising on the internet in like a really real

44
00:04:16,185 --> 00:04:16,405
Speaker 6:  way.

45
00:04:16,635 --> 00:04:20,585
Speaker 5:  Wait, on the web. I wanna be careful about on the web. 'cause it's,

46
00:04:20,585 --> 00:04:24,505
Speaker 5:  it's, this is right up against Meta and like advertising

47
00:04:24,505 --> 00:04:25,065
Speaker 5:  in Meta apps.

48
00:04:25,375 --> 00:04:29,305
Speaker 6:  Well, and and not in substantial part of go Google's argument

49
00:04:29,325 --> 00:04:33,265
Speaker 6:  is that Meta exists. Yeah. But yeah, for the, for

50
00:04:33,265 --> 00:04:37,225
Speaker 6:  the open web in particular, Google essentially is the

51
00:04:37,585 --> 00:04:40,985
Speaker 6:  advertising engine behind everything. And it, it

52
00:04:40,985 --> 00:04:44,425
Speaker 6:  increasingly has controlled every piece of the advertising puzzle. It has

53
00:04:44,425 --> 00:04:48,265
Speaker 6:  controlled every market in this space for many, many years. And

54
00:04:48,365 --> 00:04:49,905
Speaker 6:  the overwhelming question was

55
00:04:51,445 --> 00:04:55,345
Speaker 6:  is is it a monopoly? And it actually turned into one of the more sort of

56
00:04:55,545 --> 00:04:59,425
Speaker 6:  straightforward monopoly cases we've had. I think like the

57
00:04:59,585 --> 00:05:02,545
Speaker 6:  question of is Google search a monopoly is really complicated. The question

58
00:05:02,545 --> 00:05:05,905
Speaker 6:  of is Meta a monopoly is really complicated in ways that we're gonna talk

59
00:05:05,905 --> 00:05:09,105
Speaker 6:  about. But like just sort of definitionally

60
00:05:10,375 --> 00:05:14,265
Speaker 6:  what Google has and did with It is

61
00:05:14,265 --> 00:05:17,345
Speaker 6:  like right down the middle of what we talk about when we talk about monopolies.

62
00:05:17,345 --> 00:05:21,265
Speaker 6:  Which is super interesting. And I think is part of the reason I think I certainly

63
00:05:21,265 --> 00:05:24,265
Speaker 6:  left the case being like, I think Google is gonna lose Yeah. This case.

64
00:05:24,565 --> 00:05:27,545
Speaker 5:  And we should also compare and contrast this to the other

65
00:05:28,375 --> 00:05:31,585
Speaker 5:  antitrust case Google Lost, which was about its dominance and search,

66
00:05:32,035 --> 00:05:32,385
Speaker 6:  Right?

67
00:05:32,725 --> 00:05:36,625
Speaker 5:  So Google was declared an illegal monopoly in search

68
00:05:36,745 --> 00:05:40,625
Speaker 5:  a while ago by a court. That case is headed to a phase called the Remedies

69
00:05:40,625 --> 00:05:43,705
Speaker 5:  trial, where you figure out what to do with it. Also this month, also this

70
00:05:43,705 --> 00:05:47,545
Speaker 5:  month the government wants Google to sell Chrome and maybe some

71
00:05:47,545 --> 00:05:51,105
Speaker 5:  other stuff. Google would not like to do that. And then this

72
00:05:51,555 --> 00:05:55,265
Speaker 5:  trial reached its opinion by the judge. Google has a

73
00:05:55,425 --> 00:05:58,925
Speaker 5:  monopoly, an illegal monopoly in advertising and in various ways will, which

74
00:05:58,925 --> 00:06:02,885
Speaker 5:  we'll talk about. And then that will proceed to a remedies trial. All of

75
00:06:02,885 --> 00:06:06,605
Speaker 5:  that is against, while the Meta antitrust case is like literally

76
00:06:06,605 --> 00:06:10,005
Speaker 5:  happening in real time, like it's, it's happening while we are talking, it'll

77
00:06:10,005 --> 00:06:12,125
Speaker 5:  be happening while you are listening to this. It will always be happening.

78
00:06:13,865 --> 00:06:17,035
Speaker 5:  And then sometime down the line there's gonna be an Apple antitrust case.

79
00:06:17,895 --> 00:06:21,755
Speaker 5:  So this is a lot of like Lena Khan and Jonathan Cantor stuff

80
00:06:22,755 --> 00:06:26,075
Speaker 5:  happening all at once inside the Trump administration, Which we can talk

81
00:06:26,075 --> 00:06:29,755
Speaker 5:  about. But Google in particular has now

82
00:06:30,065 --> 00:06:33,955
Speaker 5:  gone over two. Yeah. In like big ways, big meaningful ways.

83
00:06:33,995 --> 00:06:37,915
Speaker 5:  You'll note Google also when Epic sued Apple and Google for antitrust

84
00:06:37,975 --> 00:06:41,755
Speaker 5:  issues, Google was the one that lost there, which I think is, and Apple kind

85
00:06:41,755 --> 00:06:44,955
Speaker 5:  of got away with it still on appeal in various ways. Does

86
00:06:44,955 --> 00:06:47,355
Speaker 6:  Google just have bad lawyers? Like is that really the takeaway here?

87
00:06:47,445 --> 00:06:51,115
Speaker 5:  Again, I'm really interested in comparing, contrast this with Meta. My read

88
00:06:51,115 --> 00:06:55,075
Speaker 5:  on this is that Google's commitment to openness, and I'm

89
00:06:55,075 --> 00:06:59,035
Speaker 5:  putting openness in quotes, but it openness in Android on the web

90
00:06:59,285 --> 00:07:03,235
Speaker 5:  means that it has to influence lots of things that aren't Google. Hmm.

91
00:07:03,365 --> 00:07:06,435
Speaker 5:  Right. So with Android it has to convince Samsung what to do or whatever.

92
00:07:06,745 --> 00:07:10,035
Speaker 5:  With search, it has to convince a bunch of websites to like operate in search

93
00:07:10,035 --> 00:07:13,795
Speaker 5:  and be indexed or whatever. With ad networks, it has to convince a bunch

94
00:07:13,795 --> 00:07:17,635
Speaker 5:  of publishers and advertisers to play ball. And so it does that, it like

95
00:07:17,905 --> 00:07:21,675
Speaker 5:  uses its influence and there's emails and then there's

96
00:07:21,675 --> 00:07:24,635
Speaker 5:  deals and there's meeting notes and there's contracts and there's all this

97
00:07:24,635 --> 00:07:28,035
Speaker 5:  stuff you can go look at. And it's Google executives being like, if I turn

98
00:07:28,035 --> 00:07:31,795
Speaker 5:  this knob, the publishers will do that. And you have all this evidence

99
00:07:31,795 --> 00:07:35,155
Speaker 5:  they, they did the thing. Whereas, you know, with Apple or Meta

100
00:07:35,695 --> 00:07:38,235
Speaker 5:  Tim Cook or Mark Zuckerberg is like, I dunno, make number go up. And like

101
00:07:38,235 --> 00:07:41,915
Speaker 5:  some product manager does it and that's the end of that. And so I think Google

102
00:07:41,975 --> 00:07:45,395
Speaker 5:  is just like structurally at a disadvantage all the time. 'cause it's, it

103
00:07:45,395 --> 00:07:46,955
Speaker 5:  has to make deals to get what it wants.

104
00:07:47,295 --> 00:07:51,075
Speaker 7:  The business success of Google over the last 20 years could really be tied

105
00:07:51,175 --> 00:07:54,915
Speaker 7:  to tying this idea of monopoly, tying, tying products

106
00:07:55,075 --> 00:07:58,635
Speaker 7:  together to get leverage in another area, which is why the DOJ is pushing

107
00:07:58,735 --> 00:08:02,555
Speaker 7:  for Chrome specifically and changes to Android. We should

108
00:08:02,715 --> 00:08:06,555
Speaker 7:  probably also clarify though, this ad tech case, this doesn't attack Google

109
00:08:06,815 --> 00:08:10,755
Speaker 7:  ads on Google search. This is actually a much smaller part of

110
00:08:10,755 --> 00:08:14,395
Speaker 7:  their business. I think the status saw was it's like 10 to 12% right?

111
00:08:14,815 --> 00:08:18,795
Speaker 7:  Of the ads that they serve on other websites. That's specifically what

112
00:08:18,795 --> 00:08:19,475
Speaker 7:  this case is about.

113
00:08:19,705 --> 00:08:23,515
Speaker 5:  Yeah. And that it, that number's getting smaller too, right? Google makes

114
00:08:23,535 --> 00:08:26,875
Speaker 5:  its money on search. It makes its money in shopping, it makes its money on

115
00:08:26,875 --> 00:08:30,755
Speaker 5:  YouTube. Increasingly it's the part of the ecosystem where they monetize

116
00:08:30,775 --> 00:08:34,275
Speaker 5:  the entire web, which is what David was talking about. That number is getting

117
00:08:34,275 --> 00:08:37,555
Speaker 5:  smaller, but it's also under the most pressure because Google, well now we

118
00:08:37,555 --> 00:08:39,035
Speaker 5:  know Google has been a monopoly there.

119
00:08:39,125 --> 00:08:42,075
Speaker 6:  Right? But this is what I mean by it's, it's a more sort of straightforward

120
00:08:43,195 --> 00:08:45,515
Speaker 6:  monopoly case. 'cause the, the thing that a lot of these other ones have

121
00:08:45,515 --> 00:08:49,395
Speaker 6:  run into is what is the difference between me doing

122
00:08:49,395 --> 00:08:53,235
Speaker 6:  something that is good for my business and a monopoly

123
00:08:53,235 --> 00:08:56,565
Speaker 6:  action And that that's actually a, a hard thing to put together, especially

124
00:08:56,565 --> 00:09:00,285
Speaker 6:  for something like a free product. So like if I make my

125
00:09:00,285 --> 00:09:04,165
Speaker 6:  search engine better and it hurts my competition, is that,

126
00:09:04,225 --> 00:09:07,125
Speaker 6:  is that monopoly maintenance or is that good business? And it actually turns

127
00:09:07,125 --> 00:09:10,325
Speaker 6:  out the line there is very fine and really not obvious to figure out. But

128
00:09:10,325 --> 00:09:14,285
Speaker 6:  in this case it's like the, the basic finding of

129
00:09:14,285 --> 00:09:18,205
Speaker 6:  the case was, and, and I will attempt to do this without either

130
00:09:18,205 --> 00:09:21,925
Speaker 6:  being wrong or going way too deep on ad tech, both of which are very possible

131
00:09:21,925 --> 00:09:25,605
Speaker 6:  to do in this case, but that basically Google owned

132
00:09:26,105 --> 00:09:29,885
Speaker 6:  the part of the advertising sack that advertisers use,

133
00:09:30,265 --> 00:09:33,565
Speaker 6:  the part that publishers use and the part that connects the two things. Those

134
00:09:33,565 --> 00:09:37,205
Speaker 6:  are three separate products and Google owned them all. And basically the

135
00:09:37,205 --> 00:09:40,005
Speaker 6:  only way to get a good experience on any of them was to use all of them.

136
00:09:40,305 --> 00:09:43,445
Speaker 6:  And so everybody essentially agreed, and this was like the expert opinion

137
00:09:43,475 --> 00:09:46,725
Speaker 6:  over and over and over throughout the trial that these products suck, but

138
00:09:46,725 --> 00:09:50,645
Speaker 6:  you have no choice but to use them even though they're bad and

139
00:09:50,645 --> 00:09:54,445
Speaker 6:  more expensive. Because without one or

140
00:09:54,445 --> 00:09:58,165
Speaker 6:  without them all, you can't get one. Yeah. And that is like, that's a

141
00:09:58,365 --> 00:10:01,965
Speaker 6:  monopoly like that is that just, that's just it, right? That's, that's

142
00:10:02,245 --> 00:10:06,165
Speaker 6:  railroads and trains. Like It is, It is the oldest school version of how

143
00:10:06,165 --> 00:10:09,965
Speaker 6:  we talk about what monopoly tying is. And it's, and

144
00:10:09,965 --> 00:10:13,125
Speaker 6:  it's in such a more straightforward way than like, what does it mean that

145
00:10:13,265 --> 00:10:16,205
Speaker 6:  no one cares about any search engine except yours? You know what I mean?

146
00:10:16,395 --> 00:10:19,645
Speaker 5:  Well there's that. I mean, I'll just read you the conclusion from the opinion

147
00:10:19,775 --> 00:10:23,125
Speaker 5:  which tracks with what you're saying. But in a, you know, a more strident

148
00:10:23,125 --> 00:10:26,925
Speaker 5:  way, here It is, quote, for over a decade Google has tied its publisher ad

149
00:10:26,925 --> 00:10:30,605
Speaker 5:  server and ad exchange together through contractual policies and technological

150
00:10:30,605 --> 00:10:34,165
Speaker 5:  integration, which enabled the company to establish and protect its monopoly

151
00:10:34,165 --> 00:10:37,845
Speaker 5:  power in these two markets. Google further entrenched its monopoly power

152
00:10:38,065 --> 00:10:41,725
Speaker 5:  by imposing anti-competitive policies on its customers and eliminating desirable

153
00:10:41,725 --> 00:10:45,005
Speaker 5:  product features. It it goes on it, she's not happy.

154
00:10:46,545 --> 00:10:50,085
Speaker 5:  And really what, you know, it's so funny, we, I I opened the show with a

155
00:10:50,085 --> 00:10:53,005
Speaker 5:  joke about like what is Facebook? So much of this comes down to like what

156
00:10:53,005 --> 00:10:55,805
Speaker 5:  is the market is the market for search and competition with people searching

157
00:10:55,805 --> 00:10:59,485
Speaker 5:  on TikTok And you end up in these like existential minefields.

158
00:10:59,625 --> 00:11:03,405
Speaker 5:  And here again it's very simple 'cause there's only three products that do

159
00:11:03,405 --> 00:11:07,245
Speaker 5:  the thing. You can't be like, well I could replace this horse with an airplane.

160
00:11:07,245 --> 00:11:10,925
Speaker 5:  What is the market? It's like, nope. You, for here there's three products.

161
00:11:10,945 --> 00:11:14,645
Speaker 5:  One that displays the ads, one that goes and gets the bids from the advertisers

162
00:11:14,645 --> 00:11:17,885
Speaker 5:  about how much they'll pay and the systems that tie them all together. And

163
00:11:18,265 --> 00:11:21,565
Speaker 5:  you can't just replace those with anything. Like those are literal software

164
00:11:21,565 --> 00:11:25,485
Speaker 5:  products you have to go and buy and we know what the replacement

165
00:11:25,485 --> 00:11:28,125
Speaker 5:  products would be and they don't exist because Google killed them all. Like,

166
00:11:28,345 --> 00:11:30,605
Speaker 5:  It is very straightforward in a way that makes it easy to talk about. But

167
00:11:30,605 --> 00:11:33,965
Speaker 5:  then it's also ad tech and like I'm confident we've already lost a bunch

168
00:11:33,965 --> 00:11:37,125
Speaker 5:  of people. But the, the issue is like this is the money,

169
00:11:37,845 --> 00:11:41,495
Speaker 5:  like it, it's a small part of Google's money, but it's the money that

170
00:11:41,815 --> 00:11:45,455
Speaker 5:  funds the open web and the open web is Google, like

171
00:11:45,675 --> 00:11:49,255
Speaker 5:  Google search without things to search for is not a good product.

172
00:11:50,015 --> 00:11:53,480
Speaker 5:  Google's AI training that everyone's doing across the entire open web

173
00:11:53,635 --> 00:11:57,565
Speaker 5:  doesn't work if you crush this entire ecosystem. And that is more

174
00:11:57,565 --> 00:12:00,805
Speaker 5:  or less what has been happening. And one of the reasons it's been happening

175
00:12:01,465 --> 00:12:04,685
Speaker 5:  is because now by this ruling Google has been

176
00:12:04,975 --> 00:12:08,885
Speaker 5:  extracting more value than it's been giving back to these publishers. Disclosure.

177
00:12:08,965 --> 00:12:12,845
Speaker 5:  I should know by the way that we run a publisher and like we use DFP

178
00:12:12,905 --> 00:12:16,805
Speaker 5:  and our executives are very interested in the outcome of this case. We

179
00:12:16,805 --> 00:12:20,405
Speaker 5:  are far, far away from that. That is literally when you look at a VERGE webpage,

180
00:12:20,405 --> 00:12:24,365
Speaker 5:  there's like the stuff we make and the ads and the ads are run

181
00:12:24,365 --> 00:12:28,125
Speaker 5:  by another team and they and like literally other computers that are all

182
00:12:28,125 --> 00:12:29,645
Speaker 5:  tied up in Google systems. Shout

183
00:12:29,645 --> 00:12:33,325
Speaker 6:  Out to Ryan Pauley though a Vox Media executive who appears in the decision

184
00:12:33,525 --> 00:12:33,725
Speaker 6:  a couple

185
00:12:33,725 --> 00:12:37,685
Speaker 5:  Of times. Does he really? He does. Ah, that's a great concert baby.

186
00:12:38,145 --> 00:12:40,365
Speaker 5:  I'm gonna go upstairs and find, yeah, we were on a programmatic ad exchange.

187
00:12:40,385 --> 00:12:43,125
Speaker 5:  It is all tied up in this, you know, the thing that really got me and I,

188
00:12:43,225 --> 00:12:46,045
Speaker 5:  I'm gonna try to like make this real or

189
00:12:47,385 --> 00:12:51,125
Speaker 5:  at least tangible to people. 'cause ad tech is really complicated, like

190
00:12:51,675 --> 00:12:55,565
Speaker 5:  complicated and full of like pure hacks to

191
00:12:55,565 --> 00:12:58,445
Speaker 5:  get around Google that Google then crushed like this cat and mouse game,

192
00:12:59,175 --> 00:13:02,485
Speaker 5:  which is kind of neat, but it's also just like a bunch of ad people do an

193
00:13:02,485 --> 00:13:05,405
Speaker 5:  ad stuff to extract pennies at scale and, and your eyes just glaze over.

194
00:13:06,785 --> 00:13:10,445
Speaker 5:  But the way, the essential way it works is that you load up a VERGE webpage

195
00:13:10,945 --> 00:13:14,685
Speaker 5:  and you know the story comes from WordPress. That's the system we use

196
00:13:15,105 --> 00:13:18,605
Speaker 5:  and the advertising all comes from another set of systems,

197
00:13:19,305 --> 00:13:21,895
Speaker 5:  right? Double click for publishers is the one that they're always talking

198
00:13:21,895 --> 00:13:25,855
Speaker 5:  about in this decision DFP that goes out and says, I've got this ad space,

199
00:13:25,855 --> 00:13:29,735
Speaker 5:  does anyone wanna buy it? I'm gonna serve it to these demographics that

200
00:13:29,775 --> 00:13:33,595
Speaker 5:  I found on this website. An advertiser are supposed to bid on it

201
00:13:34,675 --> 00:13:38,135
Speaker 5:  and that's an auction. And so like whoever bids the most for the space And

202
00:13:38,135 --> 00:13:41,975
Speaker 5:  that scale wins or supposed to win. And what has been happening

203
00:13:41,975 --> 00:13:45,815
Speaker 5:  here with Google is the, because like David said, they

204
00:13:45,835 --> 00:13:49,775
Speaker 5:  own all the, the systems that interconnect, they just keep giving

205
00:13:49,775 --> 00:13:53,575
Speaker 5:  themselves advantages, right? So they run the software that delivers the

206
00:13:53,575 --> 00:13:57,415
Speaker 5:  ads to us. They run the bridge software in the middle and they run the

207
00:13:57,415 --> 00:14:01,295
Speaker 5:  supply software that the advertisers buy into. And the two

208
00:14:01,295 --> 00:14:05,135
Speaker 5:  things that jumped out to me or these policies they had, so it's an

209
00:14:05,135 --> 00:14:08,855
Speaker 5:  auction, right? Like just think about you at an auction. Google

210
00:14:08,955 --> 00:14:12,935
Speaker 5:  had a policy called First Look which required publishers to give

211
00:14:12,935 --> 00:14:16,815
Speaker 5:  Google the first right of refusal for every impression. So you're like, I'm

212
00:14:16,815 --> 00:14:19,215
Speaker 5:  gonna put this up for auction and Google like I want it. And that would just

213
00:14:19,215 --> 00:14:23,175
Speaker 5:  the end of that, right? And then they had a policy called Last Look,

214
00:14:23,785 --> 00:14:27,495
Speaker 5:  which gave Google the ability to see everyone else's bids in an

215
00:14:27,495 --> 00:14:30,095
Speaker 5:  otherwise sealed auction before it could bid.

216
00:14:31,365 --> 00:14:34,505
Speaker 5:  So you have this like sealed auction and Google can look at it and say, oh

217
00:14:34,505 --> 00:14:37,865
Speaker 5:  that is worth it and pay, right? So they had a, the first look and the last

218
00:14:37,865 --> 00:14:40,665
Speaker 5:  look on the auction sounds like a great business.

219
00:14:42,165 --> 00:14:45,945
Speaker 5:  It printed money. Like where do you think all the GPUs came from? They got

220
00:14:45,945 --> 00:14:49,545
Speaker 5:  slides in the office, man, like all of that Google, you know, like we can't

221
00:14:49,545 --> 00:14:53,085
Speaker 5:  figure out pixel phones, we can just just not do that forever because this

222
00:14:53,085 --> 00:14:56,885
Speaker 5:  is printing money. And every time a publisher would try to do

223
00:14:56,885 --> 00:15:00,845
Speaker 5:  something to stop it, they would do hacks, right? They would run

224
00:15:00,845 --> 00:15:04,685
Speaker 5:  their own auctions before opening up the auctions to Google's ad server

225
00:15:05,065 --> 00:15:07,405
Speaker 5:  and then Google would find a way to shut that down. Like that's the level

226
00:15:07,405 --> 00:15:11,285
Speaker 5:  of cat and mask game that was going on. Revenues just went down and

227
00:15:11,285 --> 00:15:14,845
Speaker 5:  Google search traffic is down. You're like, oh, the web that Google built

228
00:15:14,905 --> 00:15:18,245
Speaker 5:  is dying. It's under all of this pressure that we can see. But it was also

229
00:15:18,245 --> 00:15:20,485
Speaker 5:  under this massive revenue pressure this whole time.

230
00:15:20,985 --> 00:15:24,845
Speaker 7:  If Google loses control of this ad plumbing that fuels

231
00:15:24,945 --> 00:15:28,365
Speaker 7:  and funds a lot of the web, like we're talking about what happens next?

232
00:15:29,975 --> 00:15:31,035
Speaker 7:  Do we, do we have an idea?

233
00:15:31,315 --> 00:15:35,195
Speaker 6:  I mean the, the hopeful version is you get a, a huge teaming

234
00:15:35,215 --> 00:15:39,075
Speaker 6:  market of ad technology, right? That like there, there was this

235
00:15:39,135 --> 00:15:43,115
Speaker 6:  big push a few years ago now I, I dunno what is

236
00:15:43,115 --> 00:15:46,235
Speaker 6:  time, but there was this big push towards this thing called header bidding,

237
00:15:46,235 --> 00:15:49,835
Speaker 6:  which was essentially the idea that actually instead of just Google

238
00:15:49,925 --> 00:15:53,635
Speaker 6:  being able to bid in real time for ads and everybody else had to like

239
00:15:53,635 --> 00:15:55,635
Speaker 6:  submit them ahead ofs like this whole thing is insane.

240
00:15:55,635 --> 00:15:57,995
Speaker 5:  That was the hack I was talking about, right? I did my very best to not say

241
00:15:57,995 --> 00:15:59,915
Speaker 5:  header bidding. I, and then David just said header bidding,

242
00:15:59,935 --> 00:16:02,955
Speaker 6:  But header bidding. The, the whole idea was like we can use one line of code

243
00:16:02,955 --> 00:16:06,715
Speaker 6:  to essentially level the field and give everybody equal access to this, which

244
00:16:06,715 --> 00:16:10,115
Speaker 6:  means the advertisers are going to get the thing that they want and they're

245
00:16:10,115 --> 00:16:13,355
Speaker 6:  going to pay the most money for it and everybody wins and, and the money

246
00:16:13,355 --> 00:16:17,115
Speaker 6:  just keeps flowing. And in theory that's where,

247
00:16:17,115 --> 00:16:20,475
Speaker 6:  that's where this goes, right? Like the, the actual technology to make this

248
00:16:20,475 --> 00:16:24,075
Speaker 6:  stuff work is out there. It's just that Google has so

249
00:16:24,435 --> 00:16:28,355
Speaker 6:  thoroughly like subsumed all of the supply and demand inside of its

250
00:16:28,355 --> 00:16:32,115
Speaker 6:  own system that if you blow it out, in theory advertisers will get

251
00:16:32,115 --> 00:16:35,595
Speaker 6:  better placements, their ads and thus better performance on their ads. Publishers

252
00:16:35,595 --> 00:16:39,195
Speaker 6:  will get more money for their content. Like this is, this is the thing you

253
00:16:39,195 --> 00:16:43,115
Speaker 6:  are trying to pry open is just sitting there. The question

254
00:16:43,115 --> 00:16:43,275
Speaker 6:  is,

255
00:16:45,105 --> 00:16:48,805
Speaker 6:  is there any actual reality in which that works? Like Google

256
00:16:48,945 --> 00:16:52,325
Speaker 6:  is so far ahead, one of the things they talked about in this trial over and

257
00:16:52,325 --> 00:16:56,285
Speaker 6:  over was how high the switching costs are that like even these

258
00:16:56,525 --> 00:16:59,245
Speaker 6:  companies that know Google is charging them twice as much as some of its

259
00:16:59,245 --> 00:17:03,125
Speaker 6:  competition, which everyone agrees is a better product. You just, it's just

260
00:17:03,125 --> 00:17:06,525
Speaker 6:  not worth the hassle to leave because you're essentially just like throwing

261
00:17:06,625 --> 00:17:10,165
Speaker 6:  all of your money away while you try to switch ad platforms. So

262
00:17:10,485 --> 00:17:14,405
Speaker 6:  Google's bet forever has been people will stay because it's too annoying

263
00:17:14,425 --> 00:17:18,405
Speaker 6:  to leave. And even with all of this, it seems like there's a real

264
00:17:18,405 --> 00:17:22,245
Speaker 6:  chance that that is what happens and Google ends up being forced to spin

265
00:17:22,245 --> 00:17:26,085
Speaker 6:  off either, you know, one, one part of that pipeline.

266
00:17:27,845 --> 00:17:31,065
Speaker 6:  But I don't know, in in practice it seems very possible to me that not that

267
00:17:31,065 --> 00:17:32,425
Speaker 6:  much actually changes. First

268
00:17:32,585 --> 00:17:35,265
Speaker 5:  I wanna say that David did say header bidding and I should have just said

269
00:17:35,265 --> 00:17:38,345
Speaker 5:  it first and I did my very best to not say header bidding, which is if you

270
00:17:38,445 --> 00:17:42,345
Speaker 5:  ask the ad world and you say if you like go into ad world

271
00:17:42,345 --> 00:17:44,625
Speaker 5:  and you say header bidding, they all just like lose their minds. Like that's

272
00:17:44,625 --> 00:17:47,785
Speaker 5:  when they lost, they know it's when they lost. It's just this very weird

273
00:17:48,035 --> 00:17:51,885
Speaker 5:  wonky thing. But there are quotes that really back up what David

274
00:17:51,905 --> 00:17:55,645
Speaker 5:  is saying here from the opinion. I mean just straightforward,

275
00:17:55,715 --> 00:17:59,605
Speaker 5:  like again this judge did not play around quote, direct

276
00:17:59,605 --> 00:18:03,245
Speaker 5:  pricing evidence shows that Google could profitably price significantly

277
00:18:03,255 --> 00:18:06,485
Speaker 5:  above competitive levels because enough customers would keep buying those

278
00:18:06,485 --> 00:18:10,295
Speaker 5:  products and not go elsewhere, right? They were just raising the price and

279
00:18:10,295 --> 00:18:11,455
Speaker 5:  the switching costs were too high.

280
00:18:11,545 --> 00:18:15,135
Speaker 6:  Which by the way is like the most classic monopoly move

281
00:18:15,405 --> 00:18:19,375
Speaker 6:  ever. Get everybody in and then once they can't leave, raise the prices.

282
00:18:19,555 --> 00:18:22,935
Speaker 6:  It is like that's that's, that's the definition of monopoly.

283
00:18:23,635 --> 00:18:27,535
Speaker 5:  Yep. Adx, which is one of the Google products here, adx, is relatively

284
00:18:27,535 --> 00:18:31,095
Speaker 5:  high market share viewed in conjunction with high barriers to entry and expansion

285
00:18:31,095 --> 00:18:34,375
Speaker 5:  that exists for other ad exchanges supports the conclusion that Google has

286
00:18:34,395 --> 00:18:38,215
Speaker 5:  had and continues to maintain monopoly power. And then the last piece of

287
00:18:38,215 --> 00:18:41,945
Speaker 5:  the puzzle, which is really interesting is that

288
00:18:41,945 --> 00:18:45,835
Speaker 5:  Google also has the demand, right? And they have

289
00:18:45,835 --> 00:18:49,635
Speaker 5:  the demand because of search, which they also have monopoly in per

290
00:18:49,635 --> 00:18:53,395
Speaker 5:  another court. So the court says you can do all this switching

291
00:18:53,695 --> 00:18:57,355
Speaker 5:  but this big volume of advertisers is already buying Google search

292
00:18:57,535 --> 00:19:00,195
Speaker 5:  and Google's just like selling them this other product on the side. They're

293
00:19:00,235 --> 00:19:03,075
Speaker 5:  tying them together like you're saying Alex. So here's a quote. Google has

294
00:19:03,075 --> 00:19:06,875
Speaker 5:  been able to amass this unparalleled group of mostly small and

295
00:19:06,875 --> 00:19:10,595
Speaker 5:  medium sized advertisers in large part due to the dominance of search,

296
00:19:10,805 --> 00:19:14,395
Speaker 5:  which another district court has found to be the source of Google's monopoly

297
00:19:14,395 --> 00:19:17,955
Speaker 5:  power in the markets or general search services and general search text ads.

298
00:19:18,695 --> 00:19:21,955
Speaker 5:  So even if you can build a better system at returns, higher rates, Google

299
00:19:22,215 --> 00:19:26,035
Speaker 5:  has tied its dominance of the ad tech market to its dominance in search

300
00:19:26,255 --> 00:19:28,595
Speaker 5:  and people are buying the search ads and they said you wanna buy ads across

301
00:19:28,595 --> 00:19:31,875
Speaker 5:  the web when you're on the shoe review website. People say yes and Google

302
00:19:31,915 --> 00:19:35,635
Speaker 5:  extracts all of that money too. So you've reduced competition sort of across

303
00:19:35,655 --> 00:19:38,315
Speaker 5:  the board and there's all this evidence because Google has to make deals

304
00:19:38,315 --> 00:19:40,235
Speaker 5:  with everyone and there's all this evidence.

305
00:19:41,055 --> 00:19:44,995
Speaker 6:  But also to your point Alex, that that's in in, in

306
00:19:44,995 --> 00:19:48,075
Speaker 6:  that is the real threat to Google here, right? Because what you're saying

307
00:19:48,135 --> 00:19:51,795
Speaker 6:  is actually all of these things are so powerful in part because they are

308
00:19:51,795 --> 00:19:54,515
Speaker 6:  tied together, right? Because when you wanna buy search ads, now you're in

309
00:19:54,515 --> 00:19:57,395
Speaker 6:  our system and it's actually easier and faster and more efficient for you

310
00:19:57,395 --> 00:20:01,115
Speaker 6:  to buy AdWords ads on the rest of the web in the same way that you're building

311
00:20:01,895 --> 00:20:05,635
Speaker 6:  ads products for search. Now we have

312
00:20:06,075 --> 00:20:09,835
Speaker 6:  a big hole getting poked in the middle of search big

313
00:20:10,035 --> 00:20:13,595
Speaker 6:  questions about what's gonna happen there. And you have being forced to open

314
00:20:13,595 --> 00:20:16,515
Speaker 6:  up the ad tech stack like all of a sudden if I'm Google I'm looking at this

315
00:20:16,515 --> 00:20:20,075
Speaker 6:  as like yes it's a threat to that small piece of our revenue

316
00:20:20,225 --> 00:20:23,715
Speaker 6:  that is coming from this like open web advertising system,

317
00:20:24,455 --> 00:20:27,875
Speaker 6:  but this also this rolls right back into search ads, which is that's where

318
00:20:27,875 --> 00:20:30,755
Speaker 6:  the real money is. Like if, if you're Google, that's the money you're worried

319
00:20:30,755 --> 00:20:34,195
Speaker 6:  about. And this is, this is not exactly that but It is right next to it.

320
00:20:34,665 --> 00:20:35,875
Speaker 5:  It's also what are you gonna search?

321
00:20:36,425 --> 00:20:38,675
Speaker 6:  Well there's that. Yeah. Like

322
00:20:39,145 --> 00:20:42,755
Speaker 5:  What are you gonna search for real? What are you gonna search if you kill

323
00:20:42,815 --> 00:20:46,555
Speaker 5:  the web in this way, if you put the SEO pressure on it, you put the

324
00:20:46,735 --> 00:20:50,605
Speaker 5:  AI scraping pressure on it, the AI answers in search pressure

325
00:20:50,605 --> 00:20:54,485
Speaker 5:  on it, you've put this much revenue pressure on it, profit

326
00:20:54,485 --> 00:20:58,405
Speaker 5:  really making a webpage, which disclosure is the business we're

327
00:20:58,405 --> 00:21:02,365
Speaker 5:  in is crazy. Yeah. Like I've asked this

328
00:21:02,485 --> 00:21:06,405
Speaker 5:  question of so many different kinds of media executives

329
00:21:06,405 --> 00:21:10,245
Speaker 5:  of platform executives of like the CEO of Squarespace comes on decoder.

330
00:21:10,265 --> 00:21:12,405
Speaker 5:  I'm like, why would anyone make a website? And they're like, I don't know.

331
00:21:12,585 --> 00:21:16,285
Speaker 5:  And that's bad. Like that is the thing that is worst for Google.

332
00:21:16,425 --> 00:21:20,405
Speaker 5:  The only answer any of those people can ever really give me is to

333
00:21:20,405 --> 00:21:24,045
Speaker 5:  do e-commerce. You start websites to do e-commerce 'cause you

334
00:21:24,285 --> 00:21:27,565
Speaker 5:  don't wanna sell your product on the TikTok shop. So you wanna kick people

335
00:21:27,585 --> 00:21:30,205
Speaker 5:  to a website so you don't have to pay a bunch of platform fees

336
00:21:31,425 --> 00:21:35,405
Speaker 5:  Bad. Like that is, that is a nightmare for Google because the

337
00:21:35,425 --> 00:21:38,285
Speaker 5:  new information is getting published on the platforms that are decidedly

338
00:21:38,285 --> 00:21:42,125
Speaker 5:  closed to the Google search crawlers and the Google AI systems. It's bad

339
00:21:42,125 --> 00:21:46,085
Speaker 5:  for all of us because the open web is just under all this pressure that

340
00:21:46,085 --> 00:21:50,045
Speaker 5:  you can see every day and all the new information is on TikTok, which doesn't

341
00:21:50,045 --> 00:21:53,285
Speaker 5:  talk to Instagram, which doesn't talk to X. Which it's like

342
00:21:54,275 --> 00:21:57,845
Speaker 5:  there's a real thing here where it's like the future of Google's at risk

343
00:21:57,845 --> 00:22:01,285
Speaker 5:  but the future of the internet's at risk because the open system has been

344
00:22:01,315 --> 00:22:04,965
Speaker 5:  kind of crushed out of being, I dunno what's gonna happen next if I was,

345
00:22:05,025 --> 00:22:08,885
Speaker 5:  if I was Shai, I would call Larry Page and politely ask

346
00:22:08,885 --> 00:22:11,405
Speaker 5:  for permission to break up the company before the government does it first.

347
00:22:12,085 --> 00:22:14,625
Speaker 5:  That's what I would do. Like straight up that's what I would do. I would

348
00:22:14,625 --> 00:22:17,545
Speaker 5:  say, look, we're gonna sell YouTube and let YouTube eat something and we're

349
00:22:17,545 --> 00:22:21,345
Speaker 5:  gonna try to fix this web problem so that we

350
00:22:21,345 --> 00:22:24,145
Speaker 5:  don't lose to close systems because our entire

351
00:22:24,445 --> 00:22:28,415
Speaker 5:  self-conception has been about openness and if

352
00:22:28,675 --> 00:22:32,055
Speaker 5:  we lose openness because we crushed it out of existence, that will just be

353
00:22:32,055 --> 00:22:35,935
Speaker 5:  our fault. I don't think they're ever gonna do that. I, we did learn in the

354
00:22:35,935 --> 00:22:38,855
Speaker 5:  Meta trial that sometimes they think about splitting up their own companies

355
00:22:39,235 --> 00:22:42,455
Speaker 5:  and I would just say to all these executives, it would be better for you

356
00:22:42,455 --> 00:22:45,775
Speaker 5:  to do it on your own terms than have the government do it for you. But it's

357
00:22:45,775 --> 00:22:48,535
Speaker 5:  kind of like Google might be at that point where it would be better for them

358
00:22:48,535 --> 00:22:52,375
Speaker 5:  to do it themselves before letting two different district courts in

359
00:22:52,375 --> 00:22:54,815
Speaker 5:  two different remedies phases come to their own conclusions. This

360
00:22:54,815 --> 00:22:58,535
Speaker 7:  Feels like a make or break moment for Google in pretty much every way.

361
00:22:58,875 --> 00:23:02,695
Speaker 7:  So you've got them losing their monopoly power that they've

362
00:23:02,695 --> 00:23:06,295
Speaker 7:  used to build, build the best business in the history of the world

363
00:23:06,565 --> 00:23:10,295
Speaker 7:  over the last 20 years. You've got OpenAI and AI

364
00:23:10,295 --> 00:23:14,095
Speaker 7:  eating into search. You've got the internal cultural

365
00:23:14,735 --> 00:23:17,935
Speaker 7:  problems, which I've written about a lot over the last year

366
00:23:18,595 --> 00:23:22,535
Speaker 7:  and yeah, it feels like Google has to rise to this challenge or this

367
00:23:22,535 --> 00:23:24,495
Speaker 7:  may be the end of Google as we know it. Yeah,

368
00:23:24,735 --> 00:23:27,535
Speaker 5:  I think it absolutely is the end of Google as we know it, right? It it already

369
00:23:27,555 --> 00:23:27,775
Speaker 5:  is,

370
00:23:28,425 --> 00:23:32,015
Speaker 7:  Right, structurally, but I'm saying in terms of relevance, in terms of power,

371
00:23:32,075 --> 00:23:35,775
Speaker 7:  in terms of Google just being this on the Mount Rushmore, big tech just

372
00:23:35,775 --> 00:23:38,815
Speaker 7:  always being there. It feels like they are vulnerable.

373
00:23:39,165 --> 00:23:42,975
Speaker 6:  I've been wondering recently if that happened a while ago and we just

374
00:23:42,975 --> 00:23:46,805
Speaker 6:  didn't notice like, 'cause I think the, the certainly in terms of like

375
00:23:47,125 --> 00:23:51,045
Speaker 6:  relevance and, and sort of market power, it's still at the peak of

376
00:23:51,045 --> 00:23:54,285
Speaker 6:  everything. But I think I, I just think about sort of the company that Google

377
00:23:54,705 --> 00:23:58,445
Speaker 6:  was for a long time and like, I think a lot of people really rooted for Google

378
00:23:58,445 --> 00:24:02,245
Speaker 6:  because Google set itself up in a way that was like, okay, as as the web

379
00:24:02,425 --> 00:24:05,805
Speaker 6:  as an open accessible thing wins,

380
00:24:06,105 --> 00:24:09,685
Speaker 6:  Google will win, right? And I think, I think most people saw that as like

381
00:24:09,685 --> 00:24:12,565
Speaker 6:  a net good Google was like, okay, we wanna help people get online, we wanna

382
00:24:12,565 --> 00:24:15,325
Speaker 6:  give people things to do on the internet. We wanna give people access to

383
00:24:15,325 --> 00:24:19,125
Speaker 6:  lots of things. We're gonna make a ton of money and that's a pretty good

384
00:24:19,135 --> 00:24:22,565
Speaker 6:  trade. And, and it was like that was a pretty good trade.

385
00:24:22,705 --> 00:24:26,245
Speaker 7:  The mission statement was organize the world's information and make it universally

386
00:24:26,245 --> 00:24:30,085
Speaker 7:  accessible. And I think that last bit is what the industry at

387
00:24:30,085 --> 00:24:33,405
Speaker 7:  large loved and what right endeared a lot of goodwill to Google.

388
00:24:33,905 --> 00:24:37,445
Speaker 7:  And what these monopoly cases are showing is that once the money came in,

389
00:24:37,445 --> 00:24:40,925
Speaker 7:  it wasn't actually about making it universally accessible to everyone. It

390
00:24:40,925 --> 00:24:44,765
Speaker 7:  was about how can we benefit our constellation of products

391
00:24:44,765 --> 00:24:47,925
Speaker 7:  that we use and tie together to maintain dominance.

392
00:24:48,295 --> 00:24:52,165
Speaker 6:  Right? Totally. And I think somewhere along the way Google stopped being

393
00:24:52,165 --> 00:24:55,725
Speaker 6:  good for the internet and it just took us a long time to realize it.

394
00:24:56,585 --> 00:24:57,415
Speaker 7:  Yikes. I

395
00:24:57,415 --> 00:25:00,975
Speaker 5:  Gotta sit with that one for a while that that really does cut against

396
00:25:02,095 --> 00:25:03,295
Speaker 5:  everyone's conception of Google,

397
00:25:03,805 --> 00:25:05,455
Speaker 6:  Including Google's conception of Google.

398
00:25:05,815 --> 00:25:09,135
Speaker 5:  I have been harsher on Google than anyone these past few years and

399
00:25:10,135 --> 00:25:14,015
Speaker 5:  I, there's still the idealism within the company and

400
00:25:14,015 --> 00:25:17,895
Speaker 5:  I think the thing that Alex is pointing at is the money

401
00:25:18,005 --> 00:25:21,935
Speaker 5:  side of the company stopped being idealistic a long time ago, right?

402
00:25:21,935 --> 00:25:25,765
Speaker 5:  That is just a bunch of sharks and like that's advertising. Like I,

403
00:25:25,795 --> 00:25:28,325
Speaker 5:  have you ever met people in adv like they're sharks, like they're just trying

404
00:25:28,325 --> 00:25:31,845
Speaker 5:  to sell you nail polish in in sports cars and it's great, I love those things,

405
00:25:32,625 --> 00:25:36,365
Speaker 5:  but like Google's idealism to make great products

406
00:25:36,625 --> 00:25:40,565
Speaker 5:  and to funnel that money into whatever wacky idea or the contact lenses

407
00:25:40,635 --> 00:25:44,525
Speaker 5:  that could see like detect health problems. Like all of that started fading.

408
00:25:44,645 --> 00:25:47,445
Speaker 5:  'cause none of that started working and they weren't, they didn't find anything

409
00:25:47,445 --> 00:25:50,965
Speaker 5:  else to make money on except search. So they just turned the screws on search

410
00:25:50,965 --> 00:25:54,445
Speaker 5:  in this very specific way and the openness became their weakness in these

411
00:25:54,445 --> 00:25:57,725
Speaker 5:  antitrust cases. Like I said, I, if I, it was up to me, I would,

412
00:25:58,305 --> 00:26:01,725
Speaker 5:  you know, it, this is like the time for radical reinvention of Google and

413
00:26:01,725 --> 00:26:05,605
Speaker 5:  in particular to say the open web needs to be protected because

414
00:26:05,625 --> 00:26:09,445
Speaker 5:  if it dies or the next new person who has an

415
00:26:09,445 --> 00:26:12,565
Speaker 5:  idea to make an information will not do it on the web,

416
00:26:13,325 --> 00:26:17,305
Speaker 5:  that's death. Like I I I, that's just death. I I think I even

417
00:26:17,305 --> 00:26:20,305
Speaker 5:  asked Sundar Phai last year, like why would anybody start a website? And

418
00:26:20,305 --> 00:26:23,945
Speaker 5:  he was kinda like, well we have YouTube and that's not great. Like that's

419
00:26:23,945 --> 00:26:27,505
Speaker 5:  death. Yeah. And you gotta, you gotta do something to protect that

420
00:26:28,065 --> 00:26:31,585
Speaker 5:  feedback loop so that the web persists in a way that allows search to exist

421
00:26:31,925 --> 00:26:35,585
Speaker 5:  but also just allows more information to be published in open ways. I dunno

422
00:26:35,585 --> 00:26:39,025
Speaker 5:  what's gonna happen. Like there's a remedies phase, there's the search remedies

423
00:26:39,025 --> 00:26:42,905
Speaker 5:  phase. It's just wild that this existential problem

424
00:26:42,985 --> 00:26:46,885
Speaker 5:  for Google is literally coming up the week that Meta is also facing

425
00:26:46,905 --> 00:26:50,895
Speaker 5:  an antitrust trial and they seem to be in almost the

426
00:26:50,895 --> 00:26:54,615
Speaker 5:  exact opposite position where the government can't even describe what

427
00:26:54,815 --> 00:26:55,175
Speaker 5:  Facebook is.

428
00:26:55,405 --> 00:26:57,935
Speaker 7:  It's so funny, we're talking about this, I've been looking at my notes 'cause

429
00:26:57,985 --> 00:27:00,775
Speaker 7:  being in the courtroom, you know, you, you can't have a phone enough. So

430
00:27:00,775 --> 00:27:04,535
Speaker 7:  I've just been writing all these notes all week and Zuckerberg

431
00:27:04,815 --> 00:27:08,415
Speaker 7:  actually talked a lot about Google because he was getting asked about

432
00:27:08,725 --> 00:27:12,455
Speaker 7:  basically, and I don't know if we're officially segueing now, but the FTC

433
00:27:12,455 --> 00:27:15,975
Speaker 7:  was saying, do you think that Instagram and WhatsApp could have

434
00:27:16,285 --> 00:27:20,175
Speaker 7:  been as successful with another company? And Google was kind of

435
00:27:20,175 --> 00:27:24,135
Speaker 7:  the main example, and I don't have the exact quote but it was something along

436
00:27:24,135 --> 00:27:27,935
Speaker 7:  the lines of he said, well I think ability and execution are different

437
00:27:27,935 --> 00:27:30,695
Speaker 7:  things and ouch. He basically

438
00:27:32,245 --> 00:27:36,135
Speaker 7:  chat on Google's organizational structure and he

439
00:27:36,135 --> 00:27:38,975
Speaker 7:  was like, look, I think they're technically excellent. I think that they

440
00:27:39,505 --> 00:27:43,135
Speaker 7:  often struggle. He was basically like, it perplexes me

441
00:27:43,135 --> 00:27:46,735
Speaker 7:  sometimes the decisions they make because they have the ability

442
00:27:46,995 --> 00:27:50,175
Speaker 7:  and I think organizationally, I think he said they're challenged.

443
00:27:51,435 --> 00:27:54,255
Speaker 7:  And it's just funny in hindsight with like these two cases back to back,

444
00:27:54,675 --> 00:27:57,495
Speaker 5:  We should talk about the Meta case now. I know what's gonna happen to Google.

445
00:27:57,635 --> 00:28:00,535
Speaker 5:  We are gonna get the two remedies phases. Yeah. Google by the way says it's

446
00:28:00,535 --> 00:28:03,975
Speaker 5:  going to appeal and in its statement said we, we've won half the case.

447
00:28:04,535 --> 00:28:07,975
Speaker 5:  I hate to be a scold. There were three counts. Google

448
00:28:08,355 --> 00:28:11,175
Speaker 5:  got one dismissed and lost the other two that it's technically one third

449
00:28:12,475 --> 00:28:12,765
Speaker 7:  Math.

450
00:28:12,765 --> 00:28:15,005
Speaker 5:  Just putting that out there, just, just noting that.

451
00:28:15,145 --> 00:28:18,485
Speaker 6:  And it turns out that losing by a little and losing by a lot don't actually

452
00:28:18,485 --> 00:28:22,085
Speaker 6:  matter all that much in cases like these, it's not like the

453
00:28:22,085 --> 00:28:23,765
Speaker 6:  scoreboard doesn't really chart

454
00:28:23,795 --> 00:28:26,845
Speaker 5:  Over time. If Google has to sell addict and DFP, they have lost by a lot

455
00:28:27,025 --> 00:28:30,325
Speaker 5:  and that's the, that's what they're staring at. But the Meta case is fascinating,

456
00:28:30,325 --> 00:28:33,805
Speaker 5:  right? Not only because Mark Zuckerberg is apparently doing decoder bait

457
00:28:33,875 --> 00:28:37,485
Speaker 5:  live on stage in our nation's courtrooms, but because there

458
00:28:37,535 --> 00:28:41,005
Speaker 5:  isn't all of this contractual evidence that they were

459
00:28:41,485 --> 00:28:45,405
Speaker 5:  influencing the thing, even though everyone knows that Meta ties

460
00:28:45,505 --> 00:28:49,125
Speaker 5:  its products together to make a stronger ecosystem. Yeah. Like if you breathe

461
00:28:49,125 --> 00:28:52,885
Speaker 5:  at Instagram, that content ends up on five different platforms before

462
00:28:53,005 --> 00:28:56,565
Speaker 5:  you even like finish pressing the button. But that's Meta

463
00:28:56,565 --> 00:29:00,445
Speaker 5:  controls it all. So it's like fine. And I, I think the government has really,

464
00:29:00,505 --> 00:29:03,085
Speaker 5:  it appears the government has very much struggled in this case.

465
00:29:03,755 --> 00:29:07,745
Speaker 7:  Yeah, I would say so. First I just wanna talk about what it was like being

466
00:29:07,745 --> 00:29:11,505
Speaker 7:  there because there's something beautifully egalitarian

467
00:29:11,715 --> 00:29:15,145
Speaker 7:  about being in court for something like this. 'cause he knows Zuckerberg,

468
00:29:15,145 --> 00:29:18,785
Speaker 7:  he rolls like the president, right? He's, he's got a ton of bodyguards. He's

469
00:29:19,315 --> 00:29:23,145
Speaker 7:  third richest man on earth and you know, it's kind of, it was cool

470
00:29:23,285 --> 00:29:27,225
Speaker 7:  and, and made me have some hope for America just watching

471
00:29:27,225 --> 00:29:30,585
Speaker 7:  this all play out. So this judge, chief judge

472
00:29:30,805 --> 00:29:34,785
Speaker 7:  Boberg of the US district court of DC during

473
00:29:34,785 --> 00:29:38,585
Speaker 7:  like one of the breaks, like 10 minute breaks, he filed, you know,

474
00:29:38,585 --> 00:29:41,725
Speaker 7:  that he was possibly gonna hold the Trump administration in contempt over

475
00:29:42,305 --> 00:29:46,165
Speaker 7:  the, the El Salvador de deportations and, and the illegality and

476
00:29:46,405 --> 00:29:50,125
Speaker 7:  question marks around that. He, so he's got a lot going on trumpet.

477
00:29:50,365 --> 00:29:54,245
Speaker 7:  Trump has called him a, a left wing lunatic. The security in the court

478
00:29:54,245 --> 00:29:57,885
Speaker 7:  beyond just Zuck being there was very intense because of the fact that it

479
00:29:57,885 --> 00:30:00,845
Speaker 7:  was him doing the case. So it was really interesting to see this

480
00:30:02,385 --> 00:30:05,645
Speaker 7:  and you know, I expected, you know, I was there with a few other reporter

481
00:30:05,645 --> 00:30:09,605
Speaker 7:  friends and the first morning we expected, you know, throngs of

482
00:30:09,605 --> 00:30:13,285
Speaker 7:  cameras and lines of, of the public. 'cause you know, it's a public courtroom.

483
00:30:13,285 --> 00:30:17,125
Speaker 7:  Anyone can go in. I don't know if people realize this in this country, you

484
00:30:17,125 --> 00:30:19,765
Speaker 7:  can literally just walk into this courtroom.

485
00:30:19,895 --> 00:30:23,165
Speaker 6:  There was a guy, fun fact this, not to derail you, but there was a guy who

486
00:30:23,225 --> 00:30:25,885
Speaker 6:  sat in the courtroom every single day. I was there for the Google search

487
00:30:25,885 --> 00:30:29,805
Speaker 6:  trial and read a book. I I, I cannot explain to you why this man

488
00:30:29,805 --> 00:30:33,765
Speaker 6:  was there, but he just, he wore like cargo khaki pants and read what

489
00:30:33,765 --> 00:30:36,605
Speaker 6:  looked like a like John Grisham novel. Awesome. Every single day in court.

490
00:30:36,735 --> 00:30:37,085
Speaker 6:  Don't

491
00:30:37,085 --> 00:30:39,765
Speaker 7:  Know why. Yeah. I mean the marshals are very serious. Like no electronics,

492
00:30:39,765 --> 00:30:43,525
Speaker 7:  like very funny. Mike Isaac from The Times was wearing his Meta ray

493
00:30:43,525 --> 00:30:47,485
Speaker 7:  bands at one point and he almost got thrown out because they

494
00:30:47,485 --> 00:30:48,685
Speaker 7:  were like, is that recording?

495
00:30:50,365 --> 00:30:53,765
Speaker 7:  It's great, but perfect. It was very cool just watching it play out and the,

496
00:30:54,905 --> 00:30:58,605
Speaker 7:  the pomp and ceremony of it all, but also just like the, okay, this,

497
00:30:58,635 --> 00:31:01,885
Speaker 7:  this part of the government at least right now seems to be working

498
00:31:03,905 --> 00:31:07,605
Speaker 7:  and you know, Meta's got all these high price fancy lawyers. The

499
00:31:08,035 --> 00:31:11,885
Speaker 7:  FTCs team was, I would say fairly young. I was actually surprised to see

500
00:31:12,845 --> 00:31:16,405
Speaker 7:  everyone looked to be like kinda in their thirties and it, it was, it was

501
00:31:16,565 --> 00:31:19,725
Speaker 7:  interesting to see the dichotomy of, of the two sides, but it's like, it's

502
00:31:19,725 --> 00:31:23,645
Speaker 7:  literally me. A few other reporters like Joel Kaplan, I was

503
00:31:23,645 --> 00:31:27,485
Speaker 7:  sitting right behind Ferguson, the chair of the FTC the first

504
00:31:27,505 --> 00:31:31,045
Speaker 7:  day would not talk to the press, wouldn't really look at us.

505
00:31:32,745 --> 00:31:36,145
Speaker 7:  And so yeah, that was just like what it was like being in the room. It's

506
00:31:36,145 --> 00:31:39,785
Speaker 7:  this grand, you know, it's the chief judge's room, so it's just very grand

507
00:31:41,165 --> 00:31:45,145
Speaker 7:  and to watch Zuckerberg walk in, you know, he still manages

508
00:31:45,145 --> 00:31:49,105
Speaker 7:  to have like one bodyguard come into the room with him, but just to

509
00:31:49,105 --> 00:31:52,945
Speaker 7:  watch him be regulated to like a common man,

510
00:31:53,005 --> 00:31:56,425
Speaker 7:  you know, like he doesn't, he doesn't get to like leave first or

511
00:31:56,855 --> 00:32:00,585
Speaker 7:  come in last, right? He kind of filters out with everyone like shoulder to

512
00:32:00,665 --> 00:32:04,225
Speaker 7:  shoulder, you know, it was cool. But the case

513
00:32:04,245 --> 00:32:06,785
Speaker 7:  itself, I left DC

514
00:32:08,135 --> 00:32:11,275
Speaker 7:  really with the impression that our government does not understand how social

515
00:32:11,275 --> 00:32:15,115
Speaker 7:  media works. Which is a bummer because I think there's a lot of really interesting

516
00:32:15,275 --> 00:32:19,115
Speaker 7:  questions you should be asking about if you're the US about Meta power,

517
00:32:19,615 --> 00:32:23,435
Speaker 7:  should one company own this much of

518
00:32:23,435 --> 00:32:27,075
Speaker 7:  social media really control what fundamentally speech at this level.

519
00:32:28,095 --> 00:32:31,795
Speaker 7:  And unfortunately the way they're attacking it, I think is is it just makes

520
00:32:31,815 --> 00:32:35,715
Speaker 7:  no sense. It's not, it doesn't, anyone who actually uses the internet would

521
00:32:35,715 --> 00:32:39,685
Speaker 7:  look at this case and say it makes no sense. So basically

522
00:32:39,685 --> 00:32:42,525
Speaker 7:  the way the FTC is, you know, 'cause for an antitrust case you have to define

523
00:32:42,525 --> 00:32:45,005
Speaker 7:  the market, right? And this is actually where this case has struggled and

524
00:32:45,005 --> 00:32:48,925
Speaker 7:  where it got thrown out originally is the judge found that the FTC had

525
00:32:48,925 --> 00:32:52,485
Speaker 7:  not kind of properly defined the market. So they narrowed it down to what

526
00:32:52,485 --> 00:32:56,205
Speaker 7:  they think is the market that Meta competes in the us And do you wanna know

527
00:32:56,305 --> 00:32:58,165
Speaker 7:  the only other apps that are in that market?

528
00:32:58,315 --> 00:33:01,765
Speaker 6:  Wait, no, before we even get to that, I want you, I want you to explain what

529
00:33:01,765 --> 00:33:05,485
Speaker 6:  they think that market is because I I I have read a lot about this now. Yeah.

530
00:33:05,925 --> 00:33:09,045
Speaker 6:  I couldn't explain it to you, but use that in court. Like what, what is,

531
00:33:09,105 --> 00:33:10,525
Speaker 6:  how do they think about this market? They

532
00:33:10,525 --> 00:33:14,045
Speaker 7:  Have narrowed it to what they call personal social networking services.

533
00:33:14,345 --> 00:33:14,685
Speaker 7:  So like

534
00:33:14,865 --> 00:33:15,445
Speaker 6:  The hell does that mean?

535
00:33:16,005 --> 00:33:19,845
Speaker 7:  And I don't know, no one knows I've covered social media for 15 years. I've

536
00:33:19,845 --> 00:33:20,565
Speaker 7:  never heard of this before.

537
00:33:20,755 --> 00:33:24,005
Speaker 5:  Okay, wait, can I, and can I just add one more piece of information to that

538
00:33:24,005 --> 00:33:26,845
Speaker 5:  because I think this is, It is, you just mentioned that this case got thrown

539
00:33:26,845 --> 00:33:30,685
Speaker 5:  out once before. Yeah. Le Kahn's FTC got this case thrown out.

540
00:33:30,715 --> 00:33:34,245
Speaker 5:  Yeah. Judge Boberg threw out Lena Khan's version of this case saying the

541
00:33:34,365 --> 00:33:38,325
Speaker 5:  market was ill-defined and made no sense. Yeah. Andrew Ferguson,

542
00:33:39,195 --> 00:33:42,965
Speaker 5:  Trump's FTC chair Yeah. Is now in charge of this case

543
00:33:43,645 --> 00:33:46,445
Speaker 5:  pursuing it even though Mark Zuckerberg is in the White House every day and

544
00:33:46,445 --> 00:33:50,085
Speaker 5:  he's landed on whatever this definition is. Yeah. To cure the

545
00:33:50,085 --> 00:33:52,645
Speaker 5:  already muddled definition that Lena Kahn got through.

546
00:33:52,955 --> 00:33:56,205
Speaker 7:  Yeah. And there's also a narrative out there that this was the Biden administration's

547
00:33:56,205 --> 00:33:59,605
Speaker 7:  like lawsuit. It actually got first filed under the first Trump administration.

548
00:33:59,745 --> 00:34:03,445
Speaker 7:  So this has gone through now three administrations. So

549
00:34:03,445 --> 00:34:06,845
Speaker 7:  that's, that's their idea. So basically Meta competes for

550
00:34:07,035 --> 00:34:10,845
Speaker 7:  sharing between friends and family. That's the market they're trying to

551
00:34:10,865 --> 00:34:14,765
Speaker 7:  say they should break Meta up for. Okay. Okay. Guess guess they

552
00:34:14,765 --> 00:34:15,965
Speaker 7:  own the apps that are in this market

553
00:34:16,835 --> 00:34:18,885
Speaker 5:  Sharing between family and friends. Yeah.

554
00:34:20,925 --> 00:34:21,125
Speaker 5:  Facebook.

555
00:34:22,085 --> 00:34:23,285
Speaker 7:  Facebook Besides Facebook

556
00:34:24,315 --> 00:34:26,365
Speaker 6:  Like X seems like it would belong

557
00:34:28,795 --> 00:34:29,515
Speaker 5:  Snapchat. Yes.

558
00:34:30,675 --> 00:34:31,155
Speaker 6:  Snapchat's a good one.

559
00:34:31,585 --> 00:34:32,995
Speaker 7:  There's only one more besides

560
00:34:33,235 --> 00:34:35,395
Speaker 6:  Snapchat. I keep thinking of messaging apps that Meta already owns, which

561
00:34:35,395 --> 00:34:36,195
Speaker 6:  is a bit of a problem I suppose.

562
00:34:36,195 --> 00:34:38,075
Speaker 5:  It's not messaging, right? It's sharing

563
00:34:38,075 --> 00:34:39,635
Speaker 7:  Between No, no, it's not messaging. But if

564
00:34:39,645 --> 00:34:41,275
Speaker 6:  We're sharing between friends and family, that's where people

565
00:34:41,275 --> 00:34:43,515
Speaker 7:  Share. No, no, no, no. Not according to our government.

566
00:34:43,655 --> 00:34:44,715
Speaker 6:  Oh my God. Okay.

567
00:34:46,755 --> 00:34:48,805
Speaker 7:  Snapchat and one other Tumblr. No.

568
00:34:50,465 --> 00:34:52,485
Speaker 5:  Is it me we, is it the one you mentioned at the top? It's

569
00:34:52,485 --> 00:34:52,805
Speaker 7:  Mei. Oh

570
00:34:52,805 --> 00:34:55,925
Speaker 5:  It's what It is. Mei. I don't even know who Mei is. I just heard you say

571
00:34:55,925 --> 00:34:56,245
Speaker 5:  it before.

572
00:34:56,335 --> 00:35:00,005
Speaker 7:  Funny Meta's lead attorney asked Mark Zuckerberg that very question on the

573
00:35:00,005 --> 00:35:03,285
Speaker 7:  stand and he said he does not know. And he said, have you ever

574
00:35:03,805 --> 00:35:07,725
Speaker 7:  heard of it before this case? And he said, no, I checked my

575
00:35:07,725 --> 00:35:09,965
Speaker 7:  email. I've actually gotten pitches from Mei over the last

576
00:35:09,965 --> 00:35:12,125
Speaker 5:  Couple years. They, what have you been doing Alex? This

577
00:35:12,125 --> 00:35:12,205
Speaker 7:  Is,

578
00:35:12,235 --> 00:35:14,205
Speaker 5:  They are the greatest threat to Meta that exists.

579
00:35:14,355 --> 00:35:18,285
Speaker 7:  They have some kind of blockchain angle, of course Tim Burners Lee

580
00:35:18,285 --> 00:35:21,925
Speaker 7:  is involved. Frank McCort, who is also trying to put TikTok on the

581
00:35:21,925 --> 00:35:25,805
Speaker 7:  blockchain is an investor. So that's me. We, they have

582
00:35:25,815 --> 00:35:29,325
Speaker 7:  about 20 million I think something like that users worldwide.

583
00:35:31,005 --> 00:35:33,925
Speaker 7:  I have never used it, I have never met a person who has used it.

584
00:35:35,185 --> 00:35:39,045
Speaker 7:  But that is, that is the market according to the ftc. So on the, on its face,

585
00:35:39,705 --> 00:35:42,725
Speaker 7:  that's, that's just ridiculous. Right. And you, you know, I was talking to

586
00:35:42,725 --> 00:35:46,205
Speaker 7:  some other antitrust reporters who, who know the actual, you know, how the

587
00:35:46,365 --> 00:35:50,245
Speaker 7:  mechanics of this play out better and apparently the judge can define the

588
00:35:50,245 --> 00:35:53,965
Speaker 7:  market however he sees fit, you know, so it's not like the FTCs market is

589
00:35:54,175 --> 00:35:57,685
Speaker 7:  definitely gonna stick or that meta's rebuttal of it will stick. The judge

590
00:35:57,685 --> 00:36:01,405
Speaker 7:  may just be like, you're both wrong. And they probably are. Although I do

591
00:36:01,605 --> 00:36:04,925
Speaker 7:  actually buy Meta's argument a little more, which is that no, we compete

592
00:36:05,065 --> 00:36:08,685
Speaker 7:  across TikTok, iMessage, YouTube, X

593
00:36:08,885 --> 00:36:11,845
Speaker 7:  Telegram signal, et cetera, et cetera. I would say

594
00:36:13,335 --> 00:36:16,885
Speaker 7:  Zuckerberg spent a lot of time saying that YouTube and TikTok

595
00:36:16,895 --> 00:36:20,765
Speaker 7:  especially were his main competitors. And a lot of time

596
00:36:21,125 --> 00:36:24,365
Speaker 7:  I would say throwing like founder shade at Snapchat

597
00:36:25,585 --> 00:36:29,445
Speaker 7:  and saying like, yeah, I wish we would've made it work. I think they'd finally

598
00:36:29,445 --> 00:36:33,005
Speaker 7:  beat a billion users and they still aren't 10 years later, stuff like that.

599
00:36:33,145 --> 00:36:37,125
Speaker 7:  So, ouch. 'cause he, you know, it came out in the courtroom and it's

600
00:36:37,125 --> 00:36:41,005
Speaker 7:  been well covered, but that he, he tried to buy them as well so that this

601
00:36:41,005 --> 00:36:42,685
Speaker 7:  is the FTCs argument. And

602
00:36:45,025 --> 00:36:48,045
Speaker 7:  you know, I do think there are also looking at some interesting things around

603
00:36:48,045 --> 00:36:51,685
Speaker 7:  network effects around what happens when you reach this scale and

604
00:36:51,685 --> 00:36:55,285
Speaker 7:  there's so many people on a network and the switching cost is actually

605
00:36:55,435 --> 00:36:59,365
Speaker 7:  your friends not coming with you. And they talked about that a little bit,

606
00:36:59,865 --> 00:37:03,845
Speaker 7:  but I found their examination to

607
00:37:03,845 --> 00:37:07,645
Speaker 7:  be fairly meandering. There was a lot of like, do you

608
00:37:07,885 --> 00:37:11,725
Speaker 7:  remember that you wrote this Facebook blog post in 2008 about sharing on

609
00:37:11,725 --> 00:37:13,245
Speaker 7:  the newsfeed? Like stuff like that

610
00:37:14,865 --> 00:37:17,965
Speaker 7:  and meta's argument about the market to be much stronger.

611
00:37:18,395 --> 00:37:21,845
Speaker 6:  Yeah. It just feels like I just have a really hard time

612
00:37:22,575 --> 00:37:26,065
Speaker 6:  looking at this in any way that says Facebook doesn't

613
00:37:26,135 --> 00:37:30,025
Speaker 6:  compete with TikTok and taking that seriously.

614
00:37:30,375 --> 00:37:33,105
Speaker 6:  Like, it, it just, it just does. Yeah. Like it just does.

615
00:37:33,455 --> 00:37:36,225
Speaker 7:  Some of the most interesting evidence was actually in the opening arguments,

616
00:37:36,375 --> 00:37:40,065
Speaker 7:  Meta displayed some internal data and we have it on the site.

617
00:37:40,435 --> 00:37:43,505
Speaker 7:  We've got a, a stream that I and Lauren Finer have been contributing to.

618
00:37:43,665 --> 00:37:47,225
Speaker 7:  Everyone should go check it out. There's a lot in there. Meta actually showed

619
00:37:47,255 --> 00:37:51,185
Speaker 7:  data that when TikTok was briefly offline, you know, earlier

620
00:37:51,215 --> 00:37:54,825
Speaker 7:  this year because of the ban traffic searched to

621
00:37:55,265 --> 00:37:58,585
Speaker 7:  actually Facebook a little bit more than Instagram. And then they had like

622
00:37:58,985 --> 00:38:02,865
Speaker 7:  Snapchat way at the bottom, like Snapchat got like a percent and

623
00:38:03,185 --> 00:38:06,865
Speaker 7:  Snapchat actually got so mad about this that they had their lawyer in the

624
00:38:06,865 --> 00:38:10,385
Speaker 7:  courtroom a couple days later also because Meta didn't properly redact the

625
00:38:10,385 --> 00:38:14,265
Speaker 7:  slides for the public saying like,

626
00:38:14,265 --> 00:38:16,305
Speaker 7:  you're revealing our confidential information. Staff's

627
00:38:16,305 --> 00:38:18,905
Speaker 6:  Lawyer is like, don't tell anybody that nobody uses our products.

628
00:38:20,405 --> 00:38:24,305
Speaker 5:  The inside baseball, by the way is that Meta tried to threaten Alex

629
00:38:24,375 --> 00:38:26,945
Speaker 5:  into not publishing their unredacted slides. And I was like, that's not,

630
00:38:27,175 --> 00:38:30,985
Speaker 5:  it's just not our problem. Like if you email us unredacted slides, we can

631
00:38:30,985 --> 00:38:31,225
Speaker 5:  publish

632
00:38:31,335 --> 00:38:34,625
Speaker 7:  Them. Yeah. It's a tale as old as time, you know, this has happened in like

633
00:38:34,625 --> 00:38:38,565
Speaker 7:  every good case the Apple's lawyer was in there too, like saying we don't

634
00:38:38,565 --> 00:38:41,765
Speaker 7:  have faith Meta will, you know, not disclose our confi, you know, confidential

635
00:38:41,765 --> 00:38:44,605
Speaker 7:  info, which I'm sure Meta would love to, right? They they hate Apple, but

636
00:38:45,995 --> 00:38:49,365
Speaker 7:  yeah. And that's, that's, that's the high level of it. And I'm curious, like,

637
00:38:51,425 --> 00:38:55,325
Speaker 7:  I'm curious how much of this case is actually just naked politics because

638
00:38:55,525 --> 00:38:58,925
Speaker 7:  I was watching Ferguson on Fox Business after the first day

639
00:38:59,745 --> 00:39:03,365
Speaker 7:  and he point blank said, we are doing this to make sure

640
00:39:03,365 --> 00:39:07,285
Speaker 7:  2020 never happens again. And he didn't say exactly what that meant,

641
00:39:07,505 --> 00:39:11,405
Speaker 7:  but I think it means, you know, the Trump administration has been very

642
00:39:11,745 --> 00:39:13,645
Speaker 7:  mad about how Zuckerberg funded

643
00:39:15,225 --> 00:39:19,005
Speaker 7:  voting drive stuff, mail-in ballot initiatives

644
00:39:19,225 --> 00:39:22,645
Speaker 7:  during the election. He actually thinks that Zuckerberg somehow played a

645
00:39:22,645 --> 00:39:26,605
Speaker 7:  key role in, in him losing that race. And then you, you

646
00:39:26,605 --> 00:39:29,405
Speaker 7:  have Ferguson on, you know, the president's favorite news channel saying,

647
00:39:29,505 --> 00:39:32,885
Speaker 7:  you know, this case is to make sure that never happens again. So I think

648
00:39:32,885 --> 00:39:34,965
Speaker 7:  that kind of shows the motivation here.

649
00:39:35,485 --> 00:39:38,965
Speaker 5:  I wanna get to the, the substantive argument, but I am actually

650
00:39:39,365 --> 00:39:43,005
Speaker 5:  fascinated by all of that aspect of this case in particular

651
00:39:44,185 --> 00:39:48,115
Speaker 5:  because, you know, the Google case we're talking about that was argued under

652
00:39:48,115 --> 00:39:50,675
Speaker 5:  the Biden administration, it was filed on their first Trump administration

653
00:39:51,135 --> 00:39:53,955
Speaker 5:  argued under the Biden administration by Jonathan Cantor who has been on

654
00:39:53,955 --> 00:39:56,555
Speaker 5:  our shows before. I'm trying to get him to come back and actually talk about

655
00:39:56,555 --> 00:39:56,675
Speaker 5:  it,

656
00:39:58,445 --> 00:40:02,425
Speaker 5:  but you know, like I've asked Cantor like you're the assistant attorney general

657
00:40:02,445 --> 00:40:05,345
Speaker 5:  for antitrust, like how do you run your team? And he had like answers, you

658
00:40:05,345 --> 00:40:08,505
Speaker 5:  know, like, he's like, here's how I do decisions, here's how I like prioritize.

659
00:40:09,405 --> 00:40:13,245
Speaker 5:  And they were very good. Right? And that's the DOJ, which was

660
00:40:13,245 --> 00:40:17,125
Speaker 5:  basically a different law firm with a different boss. This case is the FTC,

661
00:40:17,295 --> 00:40:20,925
Speaker 5:  which was run by Lean Conn different law firm. Like that's the way to think

662
00:40:20,925 --> 00:40:24,085
Speaker 5:  about it. Like these, the DOJ and the FTC have different legal teams. They

663
00:40:24,085 --> 00:40:26,965
Speaker 5:  might have the same theories or the same goals, different lawyers, different

664
00:40:27,125 --> 00:40:31,045
Speaker 5:  legal teams, different relationships to the president, right? The

665
00:40:31,085 --> 00:40:34,845
Speaker 5:  DOJ is a law enforcement organization. The FTC is a law

666
00:40:34,845 --> 00:40:37,925
Speaker 5:  enforcement organization like in a civil way, right? Like they're just different.

667
00:40:38,545 --> 00:40:42,365
Speaker 5:  And Ferguson in particular is caught up. That new chair of the

668
00:40:42,365 --> 00:40:45,725
Speaker 5:  FTC under Trump, his democratic commissioners

669
00:40:46,115 --> 00:40:49,885
Speaker 5:  were fired. Like Trump fired them. They're suing him.

670
00:40:50,265 --> 00:40:53,805
Speaker 5:  It will go to the Supreme Court and like a hundred year old precedent

671
00:40:54,015 --> 00:40:57,845
Speaker 5:  about whether the president can just fire FTC commissioners is gonna

672
00:40:57,845 --> 00:41:01,425
Speaker 5:  come up for a review. So Ferguson is in this weird box, right?

673
00:41:01,885 --> 00:41:05,825
Speaker 5:  He has a boss who shouldn't be able to

674
00:41:05,825 --> 00:41:09,545
Speaker 5:  fire him, but has proven that he will and like break the law and like

675
00:41:09,805 --> 00:41:12,985
Speaker 5:  go fight at the Supreme Court under this

676
00:41:13,155 --> 00:41:16,105
Speaker 5:  conception that the president is a chief executive of the country and makes

677
00:41:16,105 --> 00:41:19,985
Speaker 5:  all the decisions, which is not true, but kind of true. It's like very

678
00:41:19,985 --> 00:41:22,985
Speaker 5:  weird, right? He's just in this weird spot and he is got this case that was

679
00:41:23,145 --> 00:41:26,945
Speaker 5:  argued by a bunch of his predecessors and now everyone else got

680
00:41:26,945 --> 00:41:29,745
Speaker 5:  fired too because of Doge. So he is got all these baby lawyers

681
00:41:30,845 --> 00:41:34,325
Speaker 5:  and he's, he, he has to play the role of like the fire breather that everyone

682
00:41:34,325 --> 00:41:37,605
Speaker 5:  else has to play now. And so of course he's on Fox business

683
00:41:37,975 --> 00:41:41,925
Speaker 5:  being like, the reason I'm pursuing this case is because Donald Trump

684
00:41:41,925 --> 00:41:45,845
Speaker 5:  didn't get a candy bar on January 6th, 2020 or like whatever It is,

685
00:41:45,845 --> 00:41:48,845
Speaker 5:  right? Right. But that's not why this case started. That's not why this case

686
00:41:48,845 --> 00:41:52,685
Speaker 5:  was pursued under Le Conn Biden. That's not why they kept the

687
00:41:52,685 --> 00:41:56,045
Speaker 5:  case going. That's not why they kept the case going. Even though Mark Zuckerberg

688
00:41:56,045 --> 00:42:00,015
Speaker 5:  has been in the Oval Office repeatedly saying that he'll make

689
00:42:00,055 --> 00:42:03,975
Speaker 5:  a deal for numbers that range from like $5 to

690
00:42:03,975 --> 00:42:07,695
Speaker 5:  like $3 trillion. Like just numbers. Yeah. Like me, like just a range of

691
00:42:07,695 --> 00:42:11,495
Speaker 5:  numbers. That's none of that's the real reason. But I think to

692
00:42:11,495 --> 00:42:15,175
Speaker 5:  keep Trump from firing him or making a deal or undercutting this

693
00:42:15,175 --> 00:42:18,215
Speaker 5:  populist antitrust movement that is pretty bipartisan,

694
00:42:19,205 --> 00:42:23,135
Speaker 5:  he's got to say this is about censorship or Andrew Ferguson has

695
00:42:23,135 --> 00:42:27,015
Speaker 5:  fully converted to Maga like our buddy Brennan Carr and it's about censorship.

696
00:42:27,015 --> 00:42:30,215
Speaker 5:  Like I don't, I, I truly don't know, but that's just the

697
00:42:30,825 --> 00:42:33,215
Speaker 5:  weird uncertainty inside all of this.

698
00:42:33,675 --> 00:42:36,935
Speaker 6:  He is very much doing the thing you have to do no matter how you feel about

699
00:42:36,935 --> 00:42:40,855
Speaker 6:  it. Like whe whether he is just a zealot who wants to win this case or is

700
00:42:40,855 --> 00:42:44,455
Speaker 6:  just actually purely in it for the politics, you would do the same thing,

701
00:42:44,785 --> 00:42:48,415
Speaker 6:  which makes it weird. Like that is the speech you give on Fox business,

702
00:42:48,795 --> 00:42:51,135
Speaker 6:  no matter how you feel about actually what's going on in this

703
00:42:51,135 --> 00:42:54,415
Speaker 7:  Case. Yeah. I mean he tells the world it, it's to keep, you know, J six,

704
00:42:54,435 --> 00:42:57,815
Speaker 7:  you know, Trump getting kicked off from happening again. But like inside

705
00:42:57,815 --> 00:43:01,695
Speaker 7:  the courtroom there was nothing about censorship, nothing. It was

706
00:43:01,695 --> 00:43:05,575
Speaker 7:  not in any of the FTCs arguments because it's not, you

707
00:43:05,695 --> 00:43:08,775
Speaker 7:  know, private companies can do whatever they want as it relates to speech.

708
00:43:09,015 --> 00:43:10,455
Speaker 7:  That's that's the constitution. That's

709
00:43:10,455 --> 00:43:11,215
Speaker 6:  How that works. Yeah.

710
00:43:11,395 --> 00:43:15,215
Speaker 7:  At least for now, and like me, we censorship

711
00:43:15,305 --> 00:43:18,935
Speaker 7:  never came up once in the three days Zuckerberg was on the stand.

712
00:43:19,655 --> 00:43:20,375
Speaker 6:  Interesting. Yeah.

713
00:43:20,535 --> 00:43:23,975
Speaker 5:  'cause the case is fundamentally about did you perceive Instagram to be a

714
00:43:23,975 --> 00:43:27,655
Speaker 5:  competitor and buy it to preclude competition? Right. Did you

715
00:43:27,815 --> 00:43:31,575
Speaker 5:  perceive WhatsApp to be a challenger and buy it to preclude

716
00:43:31,575 --> 00:43:32,575
Speaker 5:  competition? And

717
00:43:32,965 --> 00:43:36,575
Speaker 7:  They absolutely did. Yeah. I've been covering this company for a long time.

718
00:43:36,845 --> 00:43:39,695
Speaker 7:  Some of the emails they were showing and internal documents, like I actually

719
00:43:39,695 --> 00:43:43,175
Speaker 7:  like scooped back in the day. It was actually wild to watch like internal

720
00:43:43,455 --> 00:43:46,455
Speaker 7:  documents that I remember first publishing being shown in this courtroom.

721
00:43:46,485 --> 00:43:50,215
Speaker 7:  Like, and it was all about that. And It is totally true that yes, they

722
00:43:50,275 --> 00:43:53,655
Speaker 7:  saw Instagram and WhatsApp as competitors. They weren't

723
00:43:54,075 --> 00:43:57,135
Speaker 7:  direct competitors, but they foresaw them becoming that

724
00:43:58,155 --> 00:44:02,135
Speaker 7:  to the point that, you know, there's words like neutralized that Zuckerberg

725
00:44:02,135 --> 00:44:04,935
Speaker 7:  said, you know, that these famous emails that have now been out for a while,

726
00:44:05,335 --> 00:44:09,175
Speaker 7:  I was expecting the FTC to show some new evidence. And,

727
00:44:09,175 --> 00:44:12,735
Speaker 7:  and there were a couple things. I would say the only time inside the courtroom

728
00:44:12,735 --> 00:44:16,495
Speaker 7:  where like you could feel the Meta trial team bench kind of just like

729
00:44:16,715 --> 00:44:20,615
Speaker 7:  set up a little bit was when they started reading, they

730
00:44:20,615 --> 00:44:24,415
Speaker 7:  started having Zuckerberg read this memo to his exec team in 2018

731
00:44:24,985 --> 00:44:28,815
Speaker 7:  where he said, I think we should spin off Instagram. And literally said

732
00:44:28,965 --> 00:44:32,445
Speaker 7:  that companies tend to do better after they've been spun off.

733
00:44:32,865 --> 00:44:36,165
Speaker 5:  I'm telling you, man, do it before the government does it for you. Yeah.

734
00:44:36,185 --> 00:44:39,525
Speaker 5:  If you think you're so much smarter than all these government flunkies,

735
00:44:40,315 --> 00:44:41,295
Speaker 7:  You probably are. Yeah. Mark

736
00:44:41,295 --> 00:44:45,175
Speaker 5:  Zuckerberg's a smart guy. Do it in a way that meets your interests, that

737
00:44:45,175 --> 00:44:48,815
Speaker 5:  makes everybody money before the people you perceive you dumber to. You do

738
00:44:48,815 --> 00:44:52,215
Speaker 5:  it to you on behalf of the American people. Yeah. Just do it first.

739
00:44:52,935 --> 00:44:56,295
Speaker 5:  I I continue to believe that is the smartest answer for most of these companies.

740
00:44:56,715 --> 00:45:00,695
Speaker 5:  To do it in a way that satisfies the optics of all these people but preserves

741
00:45:00,695 --> 00:45:03,495
Speaker 5:  the business. Yeah. And like, I don't think, I don't think they will learn

742
00:45:03,495 --> 00:45:06,055
Speaker 5:  that lesson and I think we're gonna see a bunch of weird breakups coming,

743
00:45:06,515 --> 00:45:09,655
Speaker 5:  but it's just very funny that Mark saw it. Yeah. Right. He was like, oh,

744
00:45:09,695 --> 00:45:12,335
Speaker 5:  I should spin this out and let it become its own thing. Yeah. 'cause it'll

745
00:45:12,335 --> 00:45:12,655
Speaker 5:  go faster.

746
00:45:12,765 --> 00:45:16,495
Speaker 7:  Yeah. I mean, you can't deny, when you look at these lengthy

747
00:45:16,605 --> 00:45:19,695
Speaker 7:  like exec memos, he writes inside the court like he's a, he's a brilliant

748
00:45:19,705 --> 00:45:23,495
Speaker 7:  strategist. And in 2018 ahead of the Biden administration, he was writing

749
00:45:23,495 --> 00:45:27,175
Speaker 7:  to his team. I think especially with the

750
00:45:27,175 --> 00:45:30,495
Speaker 7:  Democratic administration, big tech's gonna get broken up.

751
00:45:31,095 --> 00:45:34,415
Speaker 7:  We should be thinking about this seriously and planning for it. And

752
00:45:35,555 --> 00:45:39,415
Speaker 7:  you know, he saw all this coming. And so at the same

753
00:45:39,415 --> 00:45:42,055
Speaker 7:  time though, he's like grinning and saying, I would totally buy WhatsApp

754
00:45:42,055 --> 00:45:46,015
Speaker 7:  again. It was awesome. Like, and that's the tension,

755
00:45:46,065 --> 00:45:49,615
Speaker 7:  right? Is like you have him acknowledging and the

756
00:45:49,655 --> 00:45:53,255
Speaker 7:  FCC presenting evidence that he knew that the company was gonna face these

757
00:45:53,255 --> 00:45:56,295
Speaker 7:  calls to get broken up. Broken up. And then I'm sitting in the courtroom

758
00:45:56,295 --> 00:46:00,255
Speaker 7:  and I'm watching the argument for doing it and I'm looking over at the

759
00:46:00,255 --> 00:46:03,015
Speaker 7:  Meta people and they're literally like sometimes high fiving as they walk

760
00:46:03,015 --> 00:46:06,295
Speaker 7:  out on breaks. Like they feel like this is a layup. Like they're just gonna

761
00:46:06,295 --> 00:46:10,095
Speaker 7:  crush this case. And that's, it's a bummer.

762
00:46:10,365 --> 00:46:14,295
Speaker 7:  It's a bummer for like taxpayers, it's a bummer for holding power

763
00:46:14,355 --> 00:46:18,095
Speaker 7:  to account. Like there is actually power here that needs to be addressed

764
00:46:18,095 --> 00:46:21,015
Speaker 7:  in some way. I think there's more interesting arguments to be made around

765
00:46:21,555 --> 00:46:25,175
Speaker 7:  interoperability. Why is there so much energy around the fedi verse?

766
00:46:25,285 --> 00:46:28,975
Speaker 7:  It's because people feel the actual cost of these

767
00:46:29,215 --> 00:46:32,655
Speaker 7:  platforms, which is taking your speech and your network with you should a

768
00:46:32,815 --> 00:46:35,735
Speaker 7:  platform as large as Meta have to allow interoperability. That's something

769
00:46:35,735 --> 00:46:38,735
Speaker 7:  I would love the government to, to look at. But instead they're like,

770
00:46:39,925 --> 00:46:41,125
Speaker 7:  you're competing with me. We,

771
00:46:41,925 --> 00:46:45,525
Speaker 6:  It, It is very strange because I'm, I'm so torn between like my

772
00:46:45,525 --> 00:46:49,005
Speaker 6:  principles and how I feel about technology and the internet and

773
00:46:49,475 --> 00:46:53,285
Speaker 6:  like, I, I would like using WhatsApp more if it weren't

774
00:46:53,285 --> 00:46:55,685
Speaker 6:  owned by Meta. Like that's just, I it's just how I feel a

775
00:46:55,685 --> 00:46:57,045
Speaker 7:  Lot of people feel that way. Yeah. Yeah.

776
00:46:57,245 --> 00:47:01,085
Speaker 6:  I, and yet every single thing I have seen

777
00:47:01,105 --> 00:47:05,085
Speaker 6:  and read about this trial makes me agree with Meta.

778
00:47:05,445 --> 00:47:08,845
Speaker 6:  Yeah. And, and there's just so many moments, like, so much of this

779
00:47:08,845 --> 00:47:12,525
Speaker 6:  discussion seems to have been basically the

780
00:47:12,605 --> 00:47:16,565
Speaker 6:  FTC saying to Zuckerberg and the other witnesses, like, you bought

781
00:47:16,565 --> 00:47:20,165
Speaker 6:  these companies because they were threats and, and they're sort of like,

782
00:47:20,165 --> 00:47:23,725
Speaker 6:  well sure. Like we, we thought that they might be, but also they are only

783
00:47:23,745 --> 00:47:27,605
Speaker 6:  as successful as they are because they are part of this company. And I, I

784
00:47:27,605 --> 00:47:30,205
Speaker 6:  like, again, I hate how compelling I find that argument.

785
00:47:30,265 --> 00:47:32,525
Speaker 7:  The evidence is, it's irrefutable. It

786
00:47:32,525 --> 00:47:35,725
Speaker 6:  Is. And and I think the, the WhatsApp piece of It is, is my absolute favorite

787
00:47:35,725 --> 00:47:39,445
Speaker 6:  because there, there was a bunch of evidence presented that basically

788
00:47:39,505 --> 00:47:42,765
Speaker 6:  the, the WhatsApp guys were just happy. They were just like, they, they remind

789
00:47:42,765 --> 00:47:45,325
Speaker 6:  me of like, when Microsoft tried to buy Nintendo and Nintendo was like, what

790
00:47:45,325 --> 00:47:48,445
Speaker 6:  do we want with your money? Like, leave us alone. We're having a great time

791
00:47:48,475 --> 00:47:52,165
Speaker 6:  over here. But the, the basically, like, you, you heard this more than I

792
00:47:52,165 --> 00:47:55,965
Speaker 6:  did Alex, but my, my impression was basically like Zuckerberg goes to talk

793
00:47:55,965 --> 00:47:59,525
Speaker 6:  to the WhatsApp co-founders and he's like, he's like, don't you wanna have

794
00:47:59,595 --> 00:48:02,165
Speaker 6:  lots of features and sell ads and take over the world and you're gonna be

795
00:48:02,165 --> 00:48:04,005
Speaker 6:  huge? And they were just like, not really. No.

796
00:48:04,245 --> 00:48:07,925
Speaker 7:  No. They said they wanted to be Craigslist and Zuckerberg.

797
00:48:07,995 --> 00:48:08,285
Speaker 6:  Like

798
00:48:08,285 --> 00:48:09,565
Speaker 7:  Hell yeah. And Zuckerberg was like, one

799
00:48:09,565 --> 00:48:10,565
Speaker 6:  Of us should wanna be Craigslist.

800
00:48:10,825 --> 00:48:14,405
Speaker 7:  So, and then the judge is like, how does Craigslist work? And then Zuck is

801
00:48:14,405 --> 00:48:18,165
Speaker 7:  like, well Boberg feels like a Craigslist guy. I have to say if I had to

802
00:48:18,165 --> 00:48:18,365
Speaker 7:  pick

803
00:48:19,305 --> 00:48:21,005
Speaker 6:  One platform for Judge Boberg,

804
00:48:21,005 --> 00:48:24,245
Speaker 7:  It would be Craigslist. Yeah. And, and Mark was like, or next door and Mark

805
00:48:24,245 --> 00:48:28,165
Speaker 7:  was like, I, I didn't want them to be Craigslist. Like I saw this being a

806
00:48:28,165 --> 00:48:32,085
Speaker 7:  billion plus user platform. And he literally called Y kmb the CO of

807
00:48:32,245 --> 00:48:35,965
Speaker 7:  WhatsApp unambitious after he met with him the first time. And

808
00:48:35,995 --> 00:48:39,525
Speaker 7:  that really cuts at the FTCs argument because intent alone

809
00:48:40,115 --> 00:48:43,845
Speaker 7:  does not prove you did something to become a monopoly. You act as,

810
00:48:43,905 --> 00:48:47,805
Speaker 7:  as far as I understand it, the government has to show that Meta degraded

811
00:48:47,905 --> 00:48:51,695
Speaker 7:  the marketplace by, you know, buying competition. That

812
00:48:51,695 --> 00:48:55,655
Speaker 7:  basically these apps, these services got worse. Prices went up. They

813
00:48:55,655 --> 00:48:57,895
Speaker 7:  can't argue that 'cause it's free. Right. Although they're trying to make

814
00:48:57,895 --> 00:49:01,135
Speaker 7:  some ad load argument that's not really even sticking as they're saying it

815
00:49:01,415 --> 00:49:01,815
Speaker 7:  in court.

816
00:49:03,475 --> 00:49:07,295
Speaker 7:  And then Zuckerberg can just say no, like we, and they're showing the board

817
00:49:07,295 --> 00:49:11,215
Speaker 7:  decks where like they projected to get to X user milestone. They way surpassed

818
00:49:11,215 --> 00:49:14,855
Speaker 7:  it way faster. Nearly 3 billion people use

819
00:49:15,055 --> 00:49:17,535
Speaker 7:  WhatsApp now, which is the first time I've heard of WhatsApp user stat in

820
00:49:17,665 --> 00:49:20,255
Speaker 7:  years, something Zuckerberg said on the stand,

821
00:49:21,565 --> 00:49:24,295
Speaker 7:  Instagram, he was like, Kevin's sister and I, we thought we could get to

822
00:49:24,295 --> 00:49:27,015
Speaker 7:  a hundred million users and if we did that, that would be a success. And

823
00:49:27,015 --> 00:49:30,455
Speaker 7:  it got to a billion within a few years. And so

824
00:49:31,405 --> 00:49:35,015
Speaker 7:  it's hard to argue that Instagram and WhatsApp became

825
00:49:35,955 --> 00:49:39,755
Speaker 7:  meaningfully worse. Now I know everyone is listening and going, I come on,

826
00:49:39,755 --> 00:49:43,035
Speaker 7:  what are you saying? Like, I hate Instagram. I love it, but I hate it. Right?

827
00:49:43,215 --> 00:49:46,435
Speaker 7:  And that's the tension of the case is that people do feel strongly that

828
00:49:47,005 --> 00:49:50,715
Speaker 7:  these apps could be better if, if Meta and its incentives weren't, weren't

829
00:49:50,715 --> 00:49:54,675
Speaker 7:  behind them. But if you look at the marketplace, it's like there was a

830
00:49:54,675 --> 00:49:58,635
Speaker 7:  lot of times spent on path. Right. Which, like, I had not thought about

831
00:49:58,635 --> 00:49:59,515
Speaker 7:  Path in so long.

832
00:49:59,915 --> 00:50:03,275
Speaker 6:  I was just gonna mention Path. Path caught so many strays in this trial.

833
00:50:03,375 --> 00:50:03,755
Speaker 6:  It was so

834
00:50:04,055 --> 00:50:07,715
Speaker 7:  Brutal. My, and it was because Zuckerberg also looked at buying Path

835
00:50:08,175 --> 00:50:12,075
Speaker 7:  and Path is an example of a startup that he didn't buy and it

836
00:50:12,345 --> 00:50:16,275
Speaker 7:  died and it's been lost to the, you know, to to

837
00:50:16,275 --> 00:50:17,435
Speaker 7:  tech history. And he

838
00:50:17,435 --> 00:50:20,355
Speaker 6:  Talked about it in exactly the same way, which is I think why Meta kept bringing

839
00:50:20,355 --> 00:50:23,675
Speaker 6:  this up, that it was like it was the same. Like this is growing. People really

840
00:50:23,675 --> 00:50:26,635
Speaker 6:  love it. Maybe it's a threat. Like he talked about it in the same terms he

841
00:50:26,635 --> 00:50:29,125
Speaker 6:  talked about Instagram and it's like, look at the one that they bought and

842
00:50:29,125 --> 00:50:32,685
Speaker 6:  look at the one that they didn't. And It is, I I'm not saying those two things

843
00:50:32,685 --> 00:50:35,925
Speaker 6:  are like predictive, right? Like correlation causation. But

844
00:50:38,255 --> 00:50:40,195
Speaker 6:  one is Instagram and one is not.

845
00:50:40,195 --> 00:50:43,835
Speaker 5:  Yeah. Well, okay, so I will, I'm I'm gonna try to use Zuckerberg's own argument

846
00:50:43,835 --> 00:50:47,595
Speaker 5:  against him. Okay. Because It is true that Zucks strategy

847
00:50:47,725 --> 00:50:51,595
Speaker 5:  memos and even It is like dashed off emails where he like emails a random

848
00:50:51,955 --> 00:50:55,115
Speaker 5:  engineer and It is like I had this idea and the engineer's like

849
00:50:55,805 --> 00:50:59,775
Speaker 5:  help. You know, like the ideas are always really good 'cause he's smart

850
00:50:59,835 --> 00:51:03,535
Speaker 5:  and he is ruthless and he, there's an email, it's one of the emails

851
00:51:03,975 --> 00:51:07,815
Speaker 5:  you scooped back in the day, Alex, where he's like, my insight is that

852
00:51:07,815 --> 00:51:11,455
Speaker 5:  every generation comes up with a new sharing mechanic and I need to buy the

853
00:51:11,455 --> 00:51:15,135
Speaker 5:  sharing mechanic. Yeah. So we had friends and family updates on Facebook,

854
00:51:15,685 --> 00:51:19,175
Speaker 5:  Instagram is photo sharing. And then he clearly saw that messaging was the

855
00:51:19,175 --> 00:51:21,735
Speaker 5:  next one with WhatsApp, right? Yeah. And this tracks everything Facebook

856
00:51:21,795 --> 00:51:25,495
Speaker 5:  and Instagram say about themselves. Yeah. All the action is in the dms.

857
00:51:25,805 --> 00:51:29,655
Speaker 5:  They say this all the time. So you just see Mark was like, okay, I had

858
00:51:29,655 --> 00:51:33,215
Speaker 5:  this mechanic. I see the next one is gonna be photo sharing. I'm gonna buy

859
00:51:33,215 --> 00:51:36,415
Speaker 5:  that mechanic. What's the hottest thing there? Okay, the next one is obviously

860
00:51:36,525 --> 00:51:38,935
Speaker 5:  private messaging. I'm gonna buy that mechanic. What's the hottest thing

861
00:51:38,975 --> 00:51:42,735
Speaker 5:  I can buy there? And he just did it. And I could not

862
00:51:42,805 --> 00:51:46,775
Speaker 5:  tell you what that thing is as it relates to path check, checking

863
00:51:46,805 --> 00:51:50,015
Speaker 5:  into play. Like what? What, I don't even remember what it was, but it wasn't

864
00:51:50,015 --> 00:51:53,575
Speaker 5:  something where I'm like, oh, there's some core mechanic here that will

865
00:51:53,575 --> 00:51:56,535
Speaker 5:  undercut the entire promise of Facebook. I think

866
00:51:56,535 --> 00:51:59,935
Speaker 7:  It was their idea that the graph would be artificially limited. 'cause path

867
00:51:59,935 --> 00:52:03,175
Speaker 7:  was like you could only add so many people. They based it on that. There

868
00:52:03,175 --> 00:52:03,695
Speaker 7:  was like a theory,

869
00:52:03,695 --> 00:52:06,215
Speaker 5:  But that's not a sharing dynamic. Right, right. That was past theory. Yeah.

870
00:52:06,215 --> 00:52:10,175
Speaker 5:  Yeah. And even by Zuckerberg's own like framework, it would never be a

871
00:52:10,175 --> 00:52:10,655
Speaker 5:  thing. The

872
00:52:10,895 --> 00:52:13,255
Speaker 6:  Location based check-in thing was was real.

873
00:52:13,525 --> 00:52:14,735
Speaker 5:  That was Foursquare. I

874
00:52:14,735 --> 00:52:17,175
Speaker 6:  Know. But it was like it was all sitting right there. Right. This like sort

875
00:52:17,175 --> 00:52:20,975
Speaker 6:  of real life geographic thing was like, was almost

876
00:52:20,975 --> 00:52:21,215
Speaker 6:  that.

877
00:52:22,045 --> 00:52:25,335
Speaker 5:  Sure. I like bring back Path David, let's do,

878
00:52:25,335 --> 00:52:26,575
Speaker 6:  You could check in on Facebook Fe

879
00:52:26,895 --> 00:52:30,295
Speaker 5:  Federated Path. It's the, it's the future. You can have six friends and all

880
00:52:30,295 --> 00:52:33,615
Speaker 5:  of them are like, why am I here? But the next turn,

881
00:52:34,075 --> 00:52:37,895
Speaker 5:  the one that they almost missed was, what if we show you videos

882
00:52:37,965 --> 00:52:41,845
Speaker 5:  from people? You dunno. Truly. That was the next one. That was TikTok.

883
00:52:41,845 --> 00:52:45,645
Speaker 5:  Was TikTok. And they immediately, they could not buy TikTok and And they

884
00:52:45,645 --> 00:52:48,765
Speaker 5:  even said there was all these like Chinese issues. Yeah. Chinese ownership

885
00:52:48,765 --> 00:52:49,725
Speaker 5:  issues with why we couldn't buy music.

886
00:52:49,975 --> 00:52:53,205
Speaker 7:  Again, he looked at it before anyone else. He met the founder before it was

887
00:52:53,205 --> 00:52:56,205
Speaker 7:  even in the US 'cause he knew this was coming and it was like I couldn't

888
00:52:56,365 --> 00:52:57,045
Speaker 7:  do it 'cause of the China

889
00:52:57,045 --> 00:53:01,005
Speaker 5:  Stuff. And they had to hard pivot Instagram and they had to compete.

890
00:53:01,235 --> 00:53:04,685
Speaker 5:  Yeah. Whatever you think of Instagram reels, It is a better competitor to

891
00:53:04,685 --> 00:53:08,485
Speaker 5:  TikTok than YouTube shorts, right? Yep. Because they absolutely had to compete

892
00:53:08,485 --> 00:53:10,205
Speaker 5:  and they are worthless and they're very good at, and they'll just do it.

893
00:53:10,505 --> 00:53:13,285
Speaker 5:  And that's the market distortion that the government hasn't been able to

894
00:53:13,285 --> 00:53:17,005
Speaker 5:  articulate. Like if Facebook had actually had to compete with an

895
00:53:17,005 --> 00:53:20,885
Speaker 5:  Instagram that actually had this new dynamic that Mark Zuckerberg had identified,

896
00:53:21,105 --> 00:53:23,605
Speaker 5:  things would be different. Both of those companies would be competing with

897
00:53:23,605 --> 00:53:27,205
Speaker 5:  each other. Yeah. But that's, it's, it's still

898
00:53:27,205 --> 00:53:30,565
Speaker 5:  illusory to David's point. You, you will never know. And Matt's argument

899
00:53:30,565 --> 00:53:32,885
Speaker 5:  on the other side is pretty good. Which is, well I don't know. It's Instagram,

900
00:53:32,885 --> 00:53:33,365
Speaker 5:  here It is.

901
00:53:34,365 --> 00:53:37,765
Speaker 7:  I am not an expert on the edge cases of antitrust law enforcement and maybe

902
00:53:37,765 --> 00:53:41,725
Speaker 7:  the FTC will finally get something through throughout this trial. That makes

903
00:53:41,725 --> 00:53:45,165
Speaker 7:  sense. I have looked at an absurd amount of internal

904
00:53:45,685 --> 00:53:49,365
Speaker 7:  Facebook documents over the years and their data

905
00:53:49,725 --> 00:53:53,365
Speaker 7:  analysis, how they view the market and not stuff that like it's been PR

906
00:53:53,725 --> 00:53:56,365
Speaker 7:  sanctioned, like stuff leaked to me. I feel like I actually have a under

907
00:53:56,365 --> 00:53:59,485
Speaker 7:  the hood real assessment of how they view the world. They

908
00:54:00,255 --> 00:54:04,005
Speaker 7:  think maniacally about time spent, about,

909
00:54:04,155 --> 00:54:08,045
Speaker 7:  they talk like they're the un it's like population density. It's

910
00:54:08,045 --> 00:54:11,845
Speaker 7:  like we are at X density in X country. They're thinking so much

911
00:54:11,845 --> 00:54:15,805
Speaker 7:  broader than the ftc. They're thinking like, how can I suck time

912
00:54:15,805 --> 00:54:19,645
Speaker 7:  away from Netflix, et cetera. Right? It's like the Reed Hastings quote. It

913
00:54:19,645 --> 00:54:22,885
Speaker 7:  is like, I'm competing with sleep who was on the board of Facebook for like

914
00:54:22,885 --> 00:54:26,725
Speaker 7:  15 years. That's how these companies operate because that's

915
00:54:26,725 --> 00:54:30,685
Speaker 7:  the business model. And I don't think the FTC understands how the business

916
00:54:30,685 --> 00:54:34,445
Speaker 7:  model informs the strategy, which is that if you're an advertising business

917
00:54:34,445 --> 00:54:38,365
Speaker 7:  model, really all that matters is eyeballs and getting as much

918
00:54:38,365 --> 00:54:42,285
Speaker 7:  of those eyeballs for as long as possible. And the only real monopoly

919
00:54:42,285 --> 00:54:45,965
Speaker 7:  Meta has is its network, is its network effects. And the thing Zuck is

920
00:54:45,965 --> 00:54:49,645
Speaker 7:  constantly trying to fight is a new thing coming in and eating into those

921
00:54:49,645 --> 00:54:53,005
Speaker 7:  network effects, whether it was Google Plus back in the day, which got an

922
00:54:53,005 --> 00:54:56,605
Speaker 7:  insane amount of airtime in this trial was very fun. I really felt like I

923
00:54:56,605 --> 00:55:00,525
Speaker 7:  was getting like a, like a Stanford business cl like seminar,

924
00:55:00,835 --> 00:55:04,765
Speaker 7:  like Silicon Valley tech history class. It was really fun. Google

925
00:55:04,835 --> 00:55:08,725
Speaker 7:  Plus path, like OpenAI, which we'll talk about in a little bit,

926
00:55:09,995 --> 00:55:13,365
Speaker 7:  snap these things that come in and like potentially siphon people away from

927
00:55:13,365 --> 00:55:16,445
Speaker 7:  the network, which leads to a thing called network collapse, which they did

928
00:55:16,725 --> 00:55:20,525
Speaker 7:  talk about in the courtroom that he just, like you said, he

929
00:55:20,805 --> 00:55:23,805
Speaker 7:  recognized these formats and goes, I can graph this onto my bigger network,

930
00:55:24,235 --> 00:55:27,845
Speaker 7:  I'll scale it faster. And that will make sure that the startup that invented

931
00:55:27,845 --> 00:55:31,685
Speaker 7:  that form, whether it's stories or whatever, can't reach a billion

932
00:55:31,685 --> 00:55:34,445
Speaker 7:  users. He kept saying over and over, he is like, once you get to a billion

933
00:55:34,605 --> 00:55:38,485
Speaker 7:  users, like the world is your oyster. Like he's like, he's like, I really

934
00:55:38,485 --> 00:55:41,205
Speaker 7:  like, there's very few companies that do that. Very few do it on their own.

935
00:55:41,395 --> 00:55:44,245
Speaker 7:  He's like, he actually made the case that none have done it on their own.

936
00:55:44,245 --> 00:55:48,205
Speaker 7:  That they all have big parent companies. YouTube, TikTok with Bite

937
00:55:48,205 --> 00:55:50,845
Speaker 7:  Dance Snap is close to a billion. Yeah. I

938
00:55:50,845 --> 00:55:54,165
Speaker 5:  Feel like, is this more Evan Spiegel shade? Like he, he, he can't get to

939
00:55:54,165 --> 00:55:54,725
Speaker 5:  the magic number.

940
00:55:54,865 --> 00:55:58,125
Speaker 7:  It was around the SNAP acquisition questions Yeah. Is when he said this.

941
00:55:59,505 --> 00:56:03,365
Speaker 7:  And that's, he knows that's his competitive moat and that's, it's,

942
00:56:03,675 --> 00:56:06,845
Speaker 7:  it's strong and it's durable and there are monopoly questions there, but

943
00:56:06,845 --> 00:56:09,605
Speaker 7:  it's not like tying, it's not like what Google does with its products where

944
00:56:09,605 --> 00:56:13,565
Speaker 7:  it, it's, it's just like he recognizes if he can get to something and strap

945
00:56:13,565 --> 00:56:17,365
Speaker 7:  it onto his scale, he'll kill it. And he is done that very well

946
00:56:17,475 --> 00:56:18,605
Speaker 7:  over the last 20 years.

947
00:56:18,975 --> 00:56:22,485
Speaker 5:  We'll see what happens with this one. I, and again, I don't want to overdo

948
00:56:22,485 --> 00:56:26,445
Speaker 5:  it on the, on the like legal inside baseball piece of

949
00:56:26,445 --> 00:56:30,365
Speaker 5:  it, but you got like a dozed up FTC that fired everybody,

950
00:56:31,225 --> 00:56:35,125
Speaker 5:  run by a guy who has to be a fire breather on Fox News to please

951
00:56:35,185 --> 00:56:39,125
Speaker 5:  his boss who is absolutely shown that he will come

952
00:56:39,215 --> 00:56:42,765
Speaker 5:  right up to the edge of the law and asked the Supreme Court to overturn a

953
00:56:42,765 --> 00:56:46,045
Speaker 5:  hundred year old precedent and fire people that he's not supposed to fire.

954
00:56:46,395 --> 00:56:50,305
Speaker 5:  Like that's not a recipe for great lawyering. Right.

955
00:56:50,365 --> 00:56:54,345
Speaker 5:  And like I think the DOJ under Biden can't turn specifically like

956
00:56:54,345 --> 00:56:57,825
Speaker 5:  having talked to him about how he ran what was effectively a law firm.

957
00:56:58,465 --> 00:57:02,385
Speaker 5:  I was like, oh, they're doing good lawyering. I think they had a, they had

958
00:57:02,385 --> 00:57:05,705
Speaker 5:  better cases to deal with because Google does have all these deals.

959
00:57:06,785 --> 00:57:10,185
Speaker 5:  I am very curious. The DOJ has the Apple case, which has the same

960
00:57:10,225 --> 00:57:14,145
Speaker 5:  dynamics as Meta here in big ways, right? It's just Apple. They're just

961
00:57:14,145 --> 00:57:16,545
Speaker 5:  like, well we have the iPhone, we can just do whatever we want. iMessage,

962
00:57:16,545 --> 00:57:20,475
Speaker 5:  here It is, blah, it's done. We'll see. Right. A lot

963
00:57:20,475 --> 00:57:23,595
Speaker 5:  of this is once you have, once you own a platform, how dirty can you be and

964
00:57:23,615 --> 00:57:27,005
Speaker 5:  is that illegal? Right? And some of the stuff with, with Apple is like,

965
00:57:27,665 --> 00:57:30,805
Speaker 5:  we all know it App developers, like they, they call me and yell at me to

966
00:57:30,805 --> 00:57:33,005
Speaker 5:  start in-app subscriptions because that's where they make the money from.

967
00:57:33,465 --> 00:57:36,875
Speaker 5:  Is that, I don't know. But that was started under one

968
00:57:36,875 --> 00:57:40,715
Speaker 5:  administration and now it's come to this one and

969
00:57:41,055 --> 00:57:44,315
Speaker 5:  Pam Bondi is gonna pursue Apple. Like

970
00:57:44,585 --> 00:57:47,315
Speaker 5:  there's just an element of that which is like, is it the government's case?

971
00:57:47,315 --> 00:57:50,475
Speaker 5:  Is it the law that's bad? Is it that META'S Legal or Apple's legal or is

972
00:57:50,475 --> 00:57:54,115
Speaker 5:  it just a bunch of Doge kids? Dunno what they're doing. There's and they're,

973
00:57:54,115 --> 00:57:55,875
Speaker 5:  and they're up against Meta's lawyers. Right? Yeah.

974
00:57:55,975 --> 00:57:59,555
Speaker 7:  And I, well I think there's also an element, you know, leaving DC and talking

975
00:57:59,555 --> 00:58:01,955
Speaker 7:  to a lot of the Met execs, you know, 'cause they're all there and you know,

976
00:58:01,955 --> 00:58:05,235
Speaker 7:  it was off the record, but just the vibe I got is like, I think there's a

977
00:58:05,355 --> 00:58:08,715
Speaker 7:  consensus that Trump is going to be harder on all these companies than they

978
00:58:08,715 --> 00:58:11,635
Speaker 7:  thought. And that Yeah, if they, they thought if they could just kiss up

979
00:58:12,025 --> 00:58:15,955
Speaker 7:  that things would be easy. And I think Trump is a

980
00:58:15,955 --> 00:58:19,195
Speaker 7:  little smarter than they maybe gave him credit for in terms of leverage.

981
00:58:19,495 --> 00:58:22,795
Speaker 7:  And I, I, I think Meta would've very much liked to settle this case. Not

982
00:58:22,795 --> 00:58:26,075
Speaker 7:  necessarily because they were worried about losing it, but because it's a,

983
00:58:26,075 --> 00:58:29,675
Speaker 7:  it's a massive pain and it's a, it's a, you know, bad headlines. It's

984
00:58:29,675 --> 00:58:32,555
Speaker 7:  Zuckerberg's time, a ton of money, et cetera.

985
00:58:33,575 --> 00:58:37,155
Speaker 7:  The discovery process, which is very embarrassing. But

986
00:58:37,625 --> 00:58:40,915
Speaker 7:  yeah, I, I would hope, I would think that, and you know, the journal had

987
00:58:40,915 --> 00:58:44,595
Speaker 7:  a great story about this, that Hal Zuckerberg pushed to, to, you know, settle

988
00:58:44,625 --> 00:58:48,435
Speaker 7:  this. I think he probably thought that he would,

989
00:58:48,435 --> 00:58:51,915
Speaker 7:  might be able to, because of the, the January stuff that we talked about,

990
00:58:51,935 --> 00:58:55,795
Speaker 7:  all the mago changes that they made. And Apple's gonna go to DOJ and

991
00:58:55,795 --> 00:58:59,315
Speaker 7:  like I, I think all these CEOs are in for a kind of a leopard face moment

992
00:58:59,415 --> 00:59:00,475
Speaker 7:  in the next year or so.

993
00:59:00,985 --> 00:59:04,955
Speaker 6:  That photo that everybody has of all the CEOs standing on

994
00:59:04,955 --> 00:59:08,875
Speaker 6:  the day is behind Trump at the inauguration, is going to end up being iconic

995
00:59:08,875 --> 00:59:12,515
Speaker 6:  for reasons that none of those CEOs like. Exactly. Is my ongoing thesis

996
00:59:13,035 --> 00:59:15,595
Speaker 5:  Actually, can I respond to that in a, like, just a slightly different I agree.

997
00:59:15,595 --> 00:59:18,755
Speaker 5:  That photo will be very embarrassing. Yeah. For all of them because the leopards

998
00:59:18,755 --> 00:59:21,075
Speaker 5:  are reading all their faces. It's happening. Trump wants these wins, then

999
00:59:21,150 --> 00:59:24,765
Speaker 5:  he wants to settle, like he wants to win the trial so that he can negotiate

1000
00:59:24,765 --> 00:59:27,835
Speaker 5:  the settlement that ends the appeals. Right? That's, that's what you do.

1001
00:59:27,835 --> 00:59:31,635
Speaker 5:  The tariffs on China are 5000000000% and then we're gonna make a deal Trump,

1002
00:59:32,255 --> 00:59:35,915
Speaker 5:  the thing that kills me at that is the expectation they had

1003
00:59:36,605 --> 00:59:40,435
Speaker 5:  going into that photo was corruption, right? Tim

1004
00:59:40,435 --> 00:59:43,795
Speaker 5:  Cook is gonna personally donate a million dollars to Trump's library and

1005
00:59:43,795 --> 00:59:47,365
Speaker 5:  that'll take the DOJ case away from Apple naked

1006
00:59:47,415 --> 00:59:51,245
Speaker 5:  corruption. That is a nakedly corrupt thought. There's, there's nothing about,

1007
00:59:51,385 --> 00:59:55,365
Speaker 5:  and that's fine in the sense that like a lot of people believe the

1008
00:59:55,365 --> 00:59:59,335
Speaker 5:  government is corrupt and so like, Trump being even more corrupt

1009
00:59:59,445 --> 01:00:03,265
Speaker 5:  does not offend them. But it's

1010
01:00:03,265 --> 01:00:06,665
Speaker 5:  not fine in the sense that like, even when we were covering

1011
01:00:07,125 --> 01:00:10,945
Speaker 5:  the Google case today, people on Blue Sky were replying to me being like,

1012
01:00:10,945 --> 01:00:11,745
Speaker 5:  they'll just buy him off.

1013
01:00:12,965 --> 01:00:13,185
Speaker 3:  Yep.

1014
01:00:13,275 --> 01:00:17,235
Speaker 5:  What? Like that, that means that the system is collapsed. Like you

1015
01:00:17,235 --> 01:00:21,115
Speaker 5:  don't believe in it anymore and maybe you didn't before, but

1016
01:00:21,115 --> 01:00:24,915
Speaker 5:  like the level to Which we have accepted that

1017
01:00:24,915 --> 01:00:28,555
Speaker 5:  just naked corruption is how this works is a little more dangerous

1018
01:00:28,665 --> 01:00:32,355
Speaker 5:  than I think people are are giving it credit for. Like, if you believe

1019
01:00:32,385 --> 01:00:35,675
Speaker 5:  that Google can be like, oh, screw it, write 'em a check and it'll go away.

1020
01:00:36,135 --> 01:00:39,555
Speaker 5:  And that is, maybe you don't think that's right, but you think that is possible.

1021
01:00:39,975 --> 01:00:43,755
Speaker 5:  You've are it, it's gone. You have to not believe that's possible. You have

1022
01:00:43,755 --> 01:00:45,955
Speaker 5:  to actually hold everybody to account and say, actually that's corruption.

1023
01:00:46,415 --> 01:00:49,475
Speaker 5:  So I'm not saying call your senator and tell 'em to break up Google. Just

1024
01:00:49,475 --> 01:00:50,195
Speaker 5:  an idea that you could do.

1025
01:00:51,815 --> 01:00:55,675
Speaker 5:  I'm saying, I'm saying you can't, if you give into nihilism

1026
01:00:55,675 --> 01:00:58,475
Speaker 5:  that the corruption is already won, you've already, you've just given in

1027
01:00:59,125 --> 01:01:02,335
Speaker 5:  like, you should not feel helpless. You should feel outraged that the

1028
01:01:02,445 --> 01:01:06,095
Speaker 5:  expectation of that photograph was corruption. And there's t that there's

1029
01:01:06,095 --> 01:01:09,855
Speaker 5:  a little glimmer of hope that it ha it hasn't been just overt corruption

1030
01:01:09,855 --> 01:01:12,855
Speaker 5:  from the jump. Like they at least have to go to trial.

1031
01:01:13,735 --> 01:01:15,775
Speaker 5:  I dunno what's gonna happen after that. But they at least have had to go

1032
01:01:15,775 --> 01:01:16,415
Speaker 5:  to trial. I

1033
01:01:16,415 --> 01:01:19,735
Speaker 7:  Think Trump is more savvy about power and leverage than the CEOs thought

1034
01:01:19,995 --> 01:01:21,615
Speaker 7:  and knows that. Yeah. The moment he just starts

1035
01:01:21,615 --> 01:01:24,175
Speaker 5:  Taking checks or most of his checks tapers as we will come to.

1036
01:01:24,485 --> 01:01:27,775
Speaker 7:  Yeah. Yeah. And the moment you just start taking any check to kill anything,

1037
01:01:27,955 --> 01:01:30,615
Speaker 7:  you've lost power. And I think Trump cares about power.

1038
01:01:31,285 --> 01:01:34,815
Speaker 5:  Yeah. All right, we gotta take a break. We're gonna come back. We're gonna

1039
01:01:34,815 --> 01:01:38,335
Speaker 5:  talk about OpenAI, which is also making some moves to scare Mark Zuckerberg.

1040
01:01:38,335 --> 01:01:38,895
Speaker 5:  We'll be right back.

1041
01:05:10,635 --> 01:05:14,195
Speaker 5:  understand what's happening here. But yeah,

1042
01:05:14,535 --> 01:05:16,355
Speaker 5:  OpenAI has been for the last several weeks,

1043
01:05:17,165 --> 01:05:20,885
Speaker 7:  Showing off this internal prototype that is a kind of x like

1044
01:05:21,145 --> 01:05:24,965
Speaker 7:  social feed with a bunch of AI stuff in it. Apparently they're calling the

1045
01:05:24,965 --> 01:05:28,765
Speaker 7:  post yts, which for early Blue Sky users was the,

1046
01:05:29,225 --> 01:05:32,725
Speaker 7:  the name for posting on Blue Sky affectionately before Jake Grabber killed

1047
01:05:32,725 --> 01:05:33,445
Speaker 7:  that. Well, no, they were

1048
01:05:33,565 --> 01:05:34,605
Speaker 6:  Skeets on Blue Sky.

1049
01:05:35,065 --> 01:05:37,205
Speaker 7:  Oh wait, there were Skeet, which is worse. Not Eets

1050
01:05:37,205 --> 01:05:39,565
Speaker 6:  Somehow slightly worse on Blue Sky. No,

1051
01:05:39,565 --> 01:05:42,885
Speaker 5:  It's not slightly worse. It's horrible. It's a, it's a joke that is fully

1052
01:05:43,065 --> 01:05:46,525
Speaker 5:  out of control. Oh my God. And people still call them skeets, even though

1053
01:05:46,525 --> 01:05:48,285
Speaker 5:  I, I believe Blue Sky I prefer you didn't No.

1054
01:05:48,345 --> 01:05:50,925
Speaker 6:  Liz Lipato calls them skeets. No one else calls them Skeets. Don't

1055
01:05:50,995 --> 01:05:53,565
Speaker 5:  More people than than you want. Call them skeet. Does

1056
01:05:53,725 --> 01:05:55,685
Speaker 7:  Yeee Yeet come from something else though

1057
01:05:55,915 --> 01:05:58,925
Speaker 5:  That Ye's. Like a gamer term. It means like throw a thing into the ocean.

1058
01:05:58,925 --> 01:05:59,165
Speaker 5:  Yeah,

1059
01:05:59,165 --> 01:06:02,885
Speaker 7:  Yeah, yeah. Okay. Yeah, so they're Ying and oh,

1060
01:06:06,985 --> 01:06:08,925
Speaker 6:  The Yeee myself off this podcast. That's

1061
01:06:08,925 --> 01:06:10,565
Speaker 5:  Right. See, that's, you understand what,

1062
01:06:11,665 --> 01:06:15,405
Speaker 7:  No, so they're, Sam Alman has been going around to conferences and

1063
01:06:15,805 --> 01:06:19,245
Speaker 7:  in private dinners, et cetera, and talking about how he wants to compete

1064
01:06:19,245 --> 01:06:23,125
Speaker 7:  with Elon and X and they have a prototype and we skipped

1065
01:06:23,125 --> 01:06:26,885
Speaker 7:  some of the details. It's very early. It's like, it's early, but o the way

1066
01:06:26,945 --> 01:06:30,085
Speaker 7:  OpenAI works is like something that's very early, could actually ship within

1067
01:06:30,195 --> 01:06:34,165
Speaker 7:  like a few weeks. So especially after I think

1068
01:06:34,165 --> 01:06:38,045
Speaker 7:  the reaction to this and all the headlines, and I think the story got

1069
01:06:38,045 --> 01:06:41,565
Speaker 7:  a lot more attention than maybe we even expected. So maybe that pushes them

1070
01:06:41,665 --> 01:06:44,805
Speaker 7:  to, to ship faster. I saw Kevin Wheel, their

1071
01:06:45,325 --> 01:06:47,365
Speaker 7:  CPO, who was the former head of product at Instagram,

1072
01:06:48,875 --> 01:06:52,085
Speaker 7:  gave an interview to Bloomberg shortly after the story saying like, we need

1073
01:06:52,085 --> 01:06:56,045
Speaker 7:  to find a way to let people share stuff that they do with Chad

1074
01:06:56,165 --> 01:07:00,085
Speaker 7:  GPT more easily. So they're already starting to hint at it. This puts

1075
01:07:00,085 --> 01:07:03,685
Speaker 7:  them on like a direct, you know, collision course with Elon obviously, but

1076
01:07:03,685 --> 01:07:07,085
Speaker 7:  also Zuckerberg who is adding a feed like

1077
01:07:07,625 --> 01:07:11,525
Speaker 7:  AI social network to its assistance. Later this year, they're

1078
01:07:11,645 --> 01:07:14,725
Speaker 7:  actually gonna turn the Meta RayBan app, the companion app into the Meta

1079
01:07:14,905 --> 01:07:18,765
Speaker 7:  AI app. So you'll still have to have it to pair with the glasses and

1080
01:07:18,765 --> 01:07:21,925
Speaker 7:  they're gonna ship new glasses later this year, but they're gonna have a

1081
01:07:21,925 --> 01:07:25,645
Speaker 7:  feed as well in there. So this is like a Grok and X merged

1082
01:07:25,935 --> 01:07:29,885
Speaker 7:  right through the same company. If you're on X, you'll see Grok, you

1083
01:07:29,885 --> 01:07:33,365
Speaker 7:  know, suggesting things in the responses. It's everywhere in the app. And

1084
01:07:33,365 --> 01:07:36,965
Speaker 7:  now the product teams are, are merged. So this trend is happening across

1085
01:07:36,965 --> 01:07:40,165
Speaker 7:  the industry. So it kind of makes sense for OpenAI to go here, you know,

1086
01:07:40,195 --> 01:07:43,645
Speaker 7:  chat, BT has been a, a, you know, a single player experience

1087
01:07:44,145 --> 01:07:48,125
Speaker 7:  and I think Open Eye recognizes that to, you

1088
01:07:48,125 --> 01:07:51,285
Speaker 7:  know, they're probably not thinking about this it this way, but really to

1089
01:07:51,315 --> 01:07:55,245
Speaker 7:  justify this in, in, you know, incredible valuation they have and all

1090
01:07:55,245 --> 01:07:59,005
Speaker 7:  this money that they've raised. They, they need to make money beyond

1091
01:07:59,005 --> 01:08:01,685
Speaker 7:  just selling chat GT subscriptions, though, I don't think they're gonna do

1092
01:08:02,005 --> 01:08:05,965
Speaker 7:  advertising anytime soon. I think this would be a natural, this is why I

1093
01:08:05,965 --> 01:08:07,245
Speaker 7:  said we may still talk about Ad tech.

1094
01:08:07,275 --> 01:08:09,405
Speaker 5:  Wait, what's the money if they don't do advertising, they start a social

1095
01:08:09,405 --> 01:08:10,965
Speaker 5:  network and there's an advertising. What's the money?

1096
01:08:11,345 --> 01:08:14,725
Speaker 7:  What's the money? Yeah, just running ads in the feed.

1097
01:08:15,265 --> 01:08:16,005
Speaker 7:  So It is, It is

1098
01:08:16,245 --> 01:08:19,445
Speaker 6:  Advertising, but it's not advertising in chat GPT, it's advertising in

1099
01:08:19,825 --> 01:08:21,445
Speaker 6:  social GPT or whatever

1100
01:08:21,545 --> 01:08:25,525
Speaker 7:  In the feed. That will probably it, they may do a standalone app, the prototype

1101
01:08:25,525 --> 01:08:29,285
Speaker 7:  is standalone, but they may just merge it with chat. GPT their

1102
01:08:29,405 --> 01:08:33,165
Speaker 7:  CFO. Sarah Friar was the CO of Nextdoor, which sold ads in a feed. Like they

1103
01:08:33,165 --> 01:08:37,125
Speaker 7:  have a lot, I mean, they could do this, it would make sense. And it

1104
01:08:37,145 --> 01:08:40,885
Speaker 7:  begins to explain to me why Zuckerberg has been so

1105
01:08:40,885 --> 01:08:44,565
Speaker 7:  focused on them beyond just the model competition, I think. And he was, it

1106
01:08:44,565 --> 01:08:47,085
Speaker 7:  was kind of interesting like publishing this story when I was in the courtroom,

1107
01:08:47,085 --> 01:08:50,765
Speaker 7:  like the same day I am like watching him on the stand saying like, look,

1108
01:08:50,765 --> 01:08:54,245
Speaker 7:  once you get to a billion users, you know,

1109
01:08:54,935 --> 01:08:58,675
Speaker 7:  really, like, it's, it's very hard to compete and you can

1110
01:08:58,815 --> 01:09:02,275
Speaker 7:  fan out and spread out, I think was his words and do a lot of different things.

1111
01:09:02,935 --> 01:09:06,355
Speaker 7:  And I think he probably saw this coming. So OpenAI is,

1112
01:09:07,495 --> 01:09:10,675
Speaker 7:  is approaching a billion users, they'll probably hit it this year

1113
01:09:11,695 --> 01:09:15,515
Speaker 7:  and they're just in this huge expansion product mode, right?

1114
01:09:15,535 --> 01:09:17,995
Speaker 7:  So they're going in a bunch of different directions. But I think the social

1115
01:09:18,045 --> 01:09:21,395
Speaker 7:  piece really makes the idea of

1116
01:09:21,765 --> 01:09:25,675
Speaker 7:  chatt PT being more than just a Google killer potentially.

1117
01:09:25,675 --> 01:09:29,435
Speaker 7:  Now they also want to be a Meta killer. So this is like the kind of

1118
01:09:29,435 --> 01:09:31,755
Speaker 7:  ever expanding ambition of Sam Altman. I think

1119
01:09:32,105 --> 01:09:35,875
Speaker 6:  This runs into one of the big trends

1120
01:09:35,875 --> 01:09:39,675
Speaker 6:  right now that I find like completely befuddling, which is that everyone

1121
01:09:39,675 --> 01:09:43,555
Speaker 6:  is now convinced that lots of people really want endless

1122
01:09:43,565 --> 01:09:46,075
Speaker 6:  feeds of AI generated content. And

1123
01:09:47,595 --> 01:09:51,425
Speaker 6:  maybe they do, maybe, maybe I'm the one who's wrong here, but like,

1124
01:09:52,125 --> 01:09:55,585
Speaker 6:  you know, listening to Mark Zuckerberg sit on stage and say people really

1125
01:09:55,585 --> 01:09:59,145
Speaker 6:  love ads. People love ads so much that we've actually considered at one point

1126
01:09:59,285 --> 01:10:03,065
Speaker 6:  having a feed of just ads because people like the ads as much as they like

1127
01:10:03,065 --> 01:10:06,905
Speaker 6:  the content, which to me reads not as we have great ads, but

1128
01:10:06,905 --> 01:10:09,865
Speaker 6:  we have shit content is like that's, you should take that as an insult, not

1129
01:10:09,905 --> 01:10:13,305
Speaker 6:  a compliment, but anyway. And then like everybody's building these creative

1130
01:10:13,305 --> 01:10:16,745
Speaker 6:  tools so that It is easier and easier to make stuff with AI and share it

1131
01:10:16,745 --> 01:10:20,625
Speaker 6:  on your feeds. And we're, we're like running headlong into all of

1132
01:10:20,625 --> 01:10:24,425
Speaker 6:  my social feeds are going to just be absolutely overrun by

1133
01:10:24,925 --> 01:10:28,905
Speaker 6:  AI content. They already are. And it seems to me what's happening is

1134
01:10:29,245 --> 01:10:33,025
Speaker 6:  OpenAI looked at like the, the Studio Ghibli thing, right? That like took

1135
01:10:33,025 --> 01:10:35,945
Speaker 6:  over the internet for two days and everybody was sharing the stuff they made

1136
01:10:35,945 --> 01:10:39,185
Speaker 6:  in chat GPT somewhere else. Yep. And they look at that and they're like,

1137
01:10:39,185 --> 01:10:42,785
Speaker 6:  okay, no, we need to own this whole cycle. And to me I'm like, no,

1138
01:10:43,375 --> 01:10:47,145
Speaker 6:  it's just AI all the way down and this is a disaster. And so I'm like,

1139
01:10:47,205 --> 01:10:50,905
Speaker 6:  I'm, I'm so, I don't know, I'm just lost between these two different things

1140
01:10:50,905 --> 01:10:53,945
Speaker 6:  that both seem to be happening and it doesn't not seem like a thing anyone

1141
01:10:53,945 --> 01:10:54,385
Speaker 6:  should want.

1142
01:10:54,865 --> 01:10:57,385
Speaker 7:  I mean, Eli, what you said on Blue Sky's, right? Everyone wants their own

1143
01:10:57,585 --> 01:11:00,945
Speaker 7:  distribution. I don't think they've want Yeah. These images

1144
01:11:01,525 --> 01:11:05,305
Speaker 7:  and the value and attention around them being just monetized

1145
01:11:05,365 --> 01:11:09,025
Speaker 7:  by Elon Musk who is actively suing them and trying to

1146
01:11:09,055 --> 01:11:12,665
Speaker 7:  literally keep them from existing. Dude, why won't Sam

1147
01:11:12,825 --> 01:11:16,635
Speaker 5:  Altman quit X and join Blue Sky? Like you

1148
01:11:16,635 --> 01:11:20,435
Speaker 5:  wanna compete with Elon, you've got this big problem. He's still on his platform

1149
01:11:20,565 --> 01:11:24,475
Speaker 5:  every day. Yeah. Like just do it. Stand up your own mast on server. I don't

1150
01:11:24,475 --> 01:11:25,795
Speaker 5:  do something other than that. Right.

1151
01:11:25,795 --> 01:11:28,395
Speaker 7:  The open eye people are constantly Yeah. Complaining about Elon. I'm like,

1152
01:11:28,395 --> 01:11:31,635
Speaker 7:  you're just giving him training data. Like your entire company is posting

1153
01:11:31,945 --> 01:11:35,595
Speaker 7:  nonstop on X all day long. And as a result the AI

1154
01:11:35,915 --> 01:11:39,515
Speaker 7:  industry is very active on X. Like X has lost a lot of

1155
01:11:39,755 --> 01:11:43,195
Speaker 7:  audience. But I would say the AI industry remains one of its core

1156
01:11:43,595 --> 01:11:47,555
Speaker 7:  audiences. Yeah. And I do think OpenAI would have a pretty

1157
01:11:47,555 --> 01:11:51,395
Speaker 7:  compelling pitch to take that audience with them on a,

1158
01:11:51,395 --> 01:11:54,315
Speaker 7:  on a different surface and it could end up being like

1159
01:11:55,465 --> 01:11:58,955
Speaker 7:  even more split, right? Where you just have like people who like Elon's version

1160
01:11:58,955 --> 01:12:02,755
Speaker 7:  of AI on X and, and the audience is fracture

1161
01:12:02,755 --> 01:12:05,755
Speaker 7:  even more. I think we're just gonna continue to see this constant fracturing.

1162
01:12:06,225 --> 01:12:06,515
Speaker 7:  Yeah.

1163
01:12:06,515 --> 01:12:09,395
Speaker 5:  Yeah. It's just like, it's, it's funny to me, like you can stand up your

1164
01:12:09,395 --> 01:12:11,955
Speaker 5:  own social network. You can, you can do all this stuff or you could just

1165
01:12:12,025 --> 01:12:14,835
Speaker 5:  stop using the one owned by the guy who hates you, who's your competitor,

1166
01:12:14,975 --> 01:12:15,315
Speaker 5:  but you

1167
01:12:15,315 --> 01:12:16,595
Speaker 7:  Still gotta eat. Where are you gonna eat

1168
01:12:18,065 --> 01:12:21,635
Speaker 5:  Threads? Like anything like find some obscure

1169
01:12:22,155 --> 01:12:25,235
Speaker 5:  European Mastodon server and be like, I live here now and like a bunch of

1170
01:12:25,235 --> 01:12:28,275
Speaker 5:  people will come with you 'cause you're Sam Altman, here's where the news

1171
01:12:28,295 --> 01:12:32,275
Speaker 5:  is gonna be. Yeah. Right. Like, here's where I'm gonna lowercase sad boy

1172
01:12:32,275 --> 01:12:35,755
Speaker 5:  tweet about no one liking. Like, you can do it anywhere you want,

1173
01:12:36,535 --> 01:12:40,275
Speaker 5:  but like he chooses to do it on X for some reason. And I'm assuming that

1174
01:12:40,275 --> 01:12:43,355
Speaker 5:  reason is the absolutely bizarre relationship between those two men.

1175
01:12:44,315 --> 01:12:46,795
Speaker 7:  I think it's also network effects. It's what we're talking about with Meta.

1176
01:12:46,945 --> 01:12:50,235
Speaker 7:  It's just the AI industry is there. It's where companies still announce news

1177
01:12:50,265 --> 01:12:53,515
Speaker 7:  tech, tech companies especially. And

1178
01:12:54,395 --> 01:12:58,075
Speaker 7:  I, I think OpenAI sees an opening because they're the hottest tech company

1179
01:12:58,075 --> 01:13:00,195
Speaker 7:  in the world right now to take that audience.

1180
01:13:00,655 --> 01:13:03,395
Speaker 6:  And I think the idea that if you're Sam Altman people will follow you to

1181
01:13:03,395 --> 01:13:07,315
Speaker 6:  your obscure ma on server. I'm not sure that's true. And I'm, and I'm, I

1182
01:13:07,315 --> 01:13:10,955
Speaker 6:  know for sure that if you're Sam Altman, you're not sure you wanna find out

1183
01:13:11,375 --> 01:13:15,355
Speaker 5:  If you have the confidence to just like roll up to, to roll up to the richest

1184
01:13:15,355 --> 01:13:16,955
Speaker 5:  people in the world and be like, here's what I need, a trillion dollars.

1185
01:13:17,025 --> 01:13:19,595
Speaker 5:  Like you should find out if people will follow you to a masteron server.

1186
01:13:20,265 --> 01:13:20,555
Speaker 6:  Like,

1187
01:13:21,745 --> 01:13:25,715
Speaker 5:  Like there's one person who has this, the sheer audacity to be

1188
01:13:25,715 --> 01:13:28,835
Speaker 5:  like, I need a billion, I need a trillion dollars to buy every GPU in the

1189
01:13:28,835 --> 01:13:28,995
Speaker 5:  world.

1190
01:13:29,275 --> 01:13:33,155
Speaker 6:  I mean, Elon Musk spent $44 billion to make himself cool on Twitter.

1191
01:13:33,225 --> 01:13:36,075
Speaker 6:  Like you, it's, it's, it's a harder thing to do than you think

1192
01:13:36,435 --> 01:13:39,235
Speaker 7:  Stargate is just to fund the biggest mast on server in the world.

1193
01:13:40,505 --> 01:13:43,395
Speaker 5:  There's this quote in your piece, Alex, it's by somebody who runs a different

1194
01:13:43,415 --> 01:13:46,875
Speaker 5:  AI company. Yeah. They're anonymous. The grok integration with X has made

1195
01:13:47,035 --> 01:13:50,115
Speaker 5:  everyone jealous, especially how people create viral tweets by getting to

1196
01:13:50,115 --> 01:13:50,715
Speaker 5:  say something stupid. Neil,

1197
01:13:50,815 --> 01:13:52,995
Speaker 6:  The next thing I said was about to be this quote. Very good. This is the

1198
01:13:53,195 --> 01:13:54,315
Speaker 6:  funniest I've ever read.

1199
01:13:54,345 --> 01:13:57,755
Speaker 5:  Very, it's, it's an incredible quote and it has just made me think about

1200
01:13:58,735 --> 01:14:02,155
Speaker 5:  AI art and how people react to it and the feeds being full of art and like

1201
01:14:02,175 --> 01:14:06,115
Speaker 5:  why people are into it. And the, and we've written a lot

1202
01:14:06,115 --> 01:14:09,595
Speaker 5:  about this, like Addie and I have like spent a lot of time being like, ai,

1203
01:14:09,745 --> 01:14:12,885
Speaker 5:  it's like, why are we, it's very much like someone telling you about their

1204
01:14:12,885 --> 01:14:16,725
Speaker 5:  dream. Like that's how I always feel. Like, has someone ever

1205
01:14:16,725 --> 01:14:19,165
Speaker 5:  excitedly told you about a dream they had and you're like, cool. And it's

1206
01:14:19,165 --> 01:14:22,125
Speaker 5:  like the most important thing that's ever happened to that person and just

1207
01:14:22,125 --> 01:14:25,405
Speaker 5:  the disparity and experience is just too vast to be overcome.

1208
01:14:26,115 --> 01:14:30,045
Speaker 5:  Like you were you riding a dolphin? Great. Like, that's like how I feel

1209
01:14:30,045 --> 01:14:33,885
Speaker 5:  every time CAIR. It's like very good. And I think the

1210
01:14:33,885 --> 01:14:37,845
Speaker 5:  Studio Ghibli stuff hit because of the incredible juxtaposition of

1211
01:14:37,845 --> 01:14:41,325
Speaker 5:  the art style and the creator hating it. And then you're making Guantanamo

1212
01:14:41,325 --> 01:14:44,045
Speaker 5:  Bay memes with it, right? Like there's something in there that was wrong,

1213
01:14:44,475 --> 01:14:48,005
Speaker 5:  like on a fundamental level, the thing itself

1214
01:14:48,555 --> 01:14:52,445
Speaker 5:  portrayed the great conflict of our time. And then you turn

1215
01:14:52,545 --> 01:14:55,765
Speaker 5:  to the next one and you're like, oh, you made an action figure of yourself.

1216
01:14:56,385 --> 01:14:59,885
Speaker 5:  Is that, oh my God, is that your MacBook? Like, who gives a shit? Like,

1217
01:15:00,235 --> 01:15:04,045
Speaker 5:  like who cares? And I think the AI industry is really misconstrued

1218
01:15:04,045 --> 01:15:07,965
Speaker 5:  what the interest was. It's not people talking about their dreams,

1219
01:15:08,715 --> 01:15:12,485
Speaker 5:  it's people stealing artistic expression And that driving

1220
01:15:12,685 --> 01:15:16,645
Speaker 5:  a wave of conflict. And then people being able to participate on

1221
01:15:16,645 --> 01:15:20,445
Speaker 5:  either side of that conflict in ways that like drive the conflict

1222
01:15:20,445 --> 01:15:23,725
Speaker 5:  forward or, or amplify it. Like no one was outraged when people

1223
01:15:25,035 --> 01:15:27,725
Speaker 5:  made their weird action vickers. Like no one felt bad about it.

1224
01:15:27,745 --> 01:15:29,045
Speaker 6:  No, it's just boring. It

1225
01:15:29,045 --> 01:15:29,885
Speaker 5:  Was just like, here's some stuff.

1226
01:15:29,955 --> 01:15:33,565
Speaker 6:  There's even diminishing returns on the outrage, right? Like you can't run

1227
01:15:33,625 --> 01:15:36,965
Speaker 6:  the studio Ghibli playbook over and over and over again. And I think,

1228
01:15:37,355 --> 01:15:40,845
Speaker 6:  like, I'll be honest that the, the novelty factor of

1229
01:15:41,605 --> 01:15:44,885
Speaker 6:  I asked Chad GBT to do something and look at this wacky thing it came back

1230
01:15:44,885 --> 01:15:48,765
Speaker 6:  with has lasted a lot longer than I expected. It's still very much

1231
01:15:48,765 --> 01:15:51,685
Speaker 6:  there. This is the thing that a lot of these companies are trading on, is

1232
01:15:51,685 --> 01:15:55,205
Speaker 6:  like, people think grok is silly and they they like that.

1233
01:15:55,705 --> 01:15:57,845
Speaker 6:  And maybe that'll last forever.

1234
01:15:58,185 --> 01:16:01,685
Speaker 5:  No, but the, even even the grok one, the conflict of the grok is really obvious,

1235
01:16:01,685 --> 01:16:05,365
Speaker 5:  right? Grok is often like, yeah, yeah, Elon's pretty racist

1236
01:16:05,465 --> 01:16:08,765
Speaker 5:  and that's hilarious, right? Like it's

1237
01:16:08,815 --> 01:16:09,485
Speaker 5:  subversive,

1238
01:16:09,485 --> 01:16:13,045
Speaker 6:  But it's, but it's not like I too can type Elon as racist

1239
01:16:13,235 --> 01:16:15,125
Speaker 6:  into a text box and then screenshot it. But you're

1240
01:16:15,125 --> 01:16:18,045
Speaker 5:  Not a robot controlled by Elon. Like there's nothing subversive about us

1241
01:16:18,045 --> 01:16:19,445
Speaker 5:  doing, we just do it all the time. Right?

1242
01:16:19,445 --> 01:16:22,485
Speaker 6:  But, but is that, is that gonna be funny forever? Like, this is my point,

1243
01:16:22,605 --> 01:16:26,565
Speaker 6:  I just, I don't know how many versions of that thing we're gonna

1244
01:16:26,565 --> 01:16:29,125
Speaker 6:  get before this just stops being interesting.

1245
01:16:29,565 --> 01:16:33,325
Speaker 7:  I mean, open AI's user base doubled after it launched that

1246
01:16:33,355 --> 01:16:36,925
Speaker 7:  chat, the upgraded image generation. So you can, right, because

1247
01:16:37,195 --> 01:16:37,485
Speaker 7:  it's

1248
01:16:37,485 --> 01:16:37,605
Speaker 5:  A new

1249
01:16:37,605 --> 01:16:40,605
Speaker 6:  Capability. Can we say that differently? A lot of people went to a website

1250
01:16:40,605 --> 01:16:44,515
Speaker 6:  after that happened. That's what happened. A lot of people went to a

1251
01:16:44,515 --> 01:16:48,505
Speaker 6:  website. It's not the same, it's just not the same thing. Like

1252
01:16:49,395 --> 01:16:52,945
Speaker 6:  there are a lot of people and the numbers are crazy. I I absolutely agree

1253
01:16:52,945 --> 01:16:55,705
Speaker 6:  with that. But like a lot of people went to a website.

1254
01:16:56,665 --> 01:17:00,475
Speaker 7:  Yeah, yeah. I just, I just, I I too have a problem with

1255
01:17:00,475 --> 01:17:04,395
Speaker 7:  like the Studio Ghibli thing in particular. Like the fact

1256
01:17:04,395 --> 01:17:08,315
Speaker 7:  that they picked the style of the guy who called, what did he call ai? He

1257
01:17:08,315 --> 01:17:11,445
Speaker 7:  said it was like a, a the, the Studio Ghibli founder. Didn't he say something

1258
01:17:11,445 --> 01:17:12,285
Speaker 7:  about how it's like a Yeah,

1259
01:17:12,285 --> 01:17:13,005
Speaker 5:  It's like a crime against

1260
01:17:13,205 --> 01:17:15,925
Speaker 7:  Humanity. Crime against humanity. The fact that that was the style that went

1261
01:17:15,925 --> 01:17:19,285
Speaker 7:  viral feels, feels wrong. Yeah. But

1262
01:17:20,125 --> 01:17:23,965
Speaker 7:  I don't think we can discount the interests people have at scale with this

1263
01:17:23,965 --> 01:17:27,925
Speaker 7:  stuff and open, I sees it in their numbers. Sure.

1264
01:17:27,925 --> 01:17:31,885
Speaker 7:  Maybe it's like fleeting or maybe it's a, a

1265
01:17:31,885 --> 01:17:35,325
Speaker 7:  gimmick that can only be replicated so many times, like you're saying. But

1266
01:17:35,365 --> 01:17:38,405
Speaker 7:  I think, look, I think we're professional riders and we,

1267
01:17:38,705 --> 01:17:40,805
Speaker 5:  I'm sorry, insult to life itself.

1268
01:17:40,805 --> 01:17:44,685
Speaker 7:  Just insult to life itself. Yeah. We're, we're professional riders we like,

1269
01:17:45,065 --> 01:17:48,525
Speaker 7:  or it's our jobs, like, say say things on the internet. I think most people

1270
01:17:48,525 --> 01:17:51,885
Speaker 7:  look at x or threads or blue sky or whatever and they don't really know what

1271
01:17:51,885 --> 01:17:55,845
Speaker 7:  to say. And I think the, the tech product view

1272
01:17:55,845 --> 01:17:59,765
Speaker 7:  of this, just talking to the people inside these labs is that like

1273
01:18:00,145 --> 01:18:04,125
Speaker 7:  we see a, a demand for people who wanna engage and don't

1274
01:18:04,125 --> 01:18:07,525
Speaker 7:  necessarily know how to or are scared to, and AI will help them. AI will

1275
01:18:07,875 --> 01:18:11,485
Speaker 7:  give them ways to express themselves that they could not before. And it's

1276
01:18:11,485 --> 01:18:15,285
Speaker 7:  reflected in the metrics of how people are gravitating towards these products.

1277
01:18:15,665 --> 01:18:19,405
Speaker 7:  So yeah, like the, I think the culture class is gonna continue to have,

1278
01:18:21,185 --> 01:18:25,085
Speaker 7:  you know, a lot of like hand ringing and like rightful criticism of

1279
01:18:25,085 --> 01:18:28,965
Speaker 7:  how these companies approach things like ip. But I also think we can't deny

1280
01:18:28,965 --> 01:18:32,885
Speaker 7:  that this is a trend that is here to stay. I, I, I at least think so

1281
01:18:33,205 --> 01:18:36,005
Speaker 6:  I do buy that. But I think, I think that's a, that's a actually a really

1282
01:18:36,005 --> 01:18:39,885
Speaker 6:  great definition of AI as a tool in a, in a way that

1283
01:18:39,885 --> 01:18:43,805
Speaker 6:  I really like. Frank AI is an enabling tool for lots of things, I think is

1284
01:18:43,925 --> 01:18:47,645
Speaker 6:  actually really exciting. Yeah. But what I see so much of the

1285
01:18:47,865 --> 01:18:50,925
Speaker 6:  bet here being is that AI is going to keep being

1286
01:18:51,795 --> 01:18:55,285
Speaker 6:  sort of the main character. Hmm. And it, and, and again, it has been for

1287
01:18:55,285 --> 01:18:59,085
Speaker 6:  much longer than I expected, so maybe I'm just wrong and maybe this thing

1288
01:18:59,085 --> 01:19:02,605
Speaker 6:  is so funny and silly and weird and unexpected that people will keep wanting

1289
01:19:02,605 --> 01:19:03,525
Speaker 6:  to interact with it forever.

1290
01:19:05,105 --> 01:19:07,605
Speaker 6:  But it just, that just does not feel right to me. I don't know,

1291
01:19:07,805 --> 01:19:10,365
Speaker 7:  I don't think the open eye social network's gonna be just like an endless

1292
01:19:10,795 --> 01:19:14,365
Speaker 7:  feed of only people's like Ghibli photos. I think like

1293
01:19:14,555 --> 01:19:18,405
Speaker 7:  it's a jumping point to build a AI native social network

1294
01:19:18,835 --> 01:19:22,765
Speaker 7:  that uses AI throughout the entire posting and editing and, and

1295
01:19:22,765 --> 01:19:25,765
Speaker 7:  publishing and recommendation process that like every other

1296
01:19:26,075 --> 01:19:29,965
Speaker 7:  established company is now trying to retrofit. And OpenAI has this insane,

1297
01:19:29,965 --> 01:19:33,485
Speaker 7:  highly engaged user base that they, I think they think they can fan out and

1298
01:19:33,485 --> 01:19:36,725
Speaker 7:  take this opportunity. Especially with what Google's going through, like

1299
01:19:36,725 --> 01:19:40,085
Speaker 7:  we were talking about and the fact that these other companies seem to just

1300
01:19:40,145 --> 01:19:44,085
Speaker 7:  not get product in this way. So yeah, I I think,

1301
01:19:44,165 --> 01:19:47,205
Speaker 7:  I think it's gonna be a disaster, but it's also the future which is like

1302
01:19:47,635 --> 01:19:48,325
Speaker 7:  kind of AI

1303
01:19:48,725 --> 01:19:50,445
Speaker 5:  Nutshell, The Verge everybody Yeah.

1304
01:19:53,995 --> 01:19:57,645
Speaker 5:  There's other stuff going on in AI world. Open eye debuted

1305
01:19:57,925 --> 01:20:01,895
Speaker 5:  GP 4.1 and then Sam was like, I promise I'm gonna

1306
01:20:01,895 --> 01:20:05,875
Speaker 5:  clear up these names. God, they're so bad. What is going on here? Like

1307
01:20:05,875 --> 01:20:07,290
Speaker 5:  it's, it's better, right? It's the newest

1308
01:20:07,290 --> 01:20:09,965
Speaker 6:  Better one. I personally so vindicated by this because I've been complaining

1309
01:20:09,965 --> 01:20:13,205
Speaker 6:  about the names on this show and elsewhere for forever, that when you go,

1310
01:20:13,205 --> 01:20:16,765
Speaker 6:  it's like a dropdown of nonsensical numbers where

1311
01:20:16,915 --> 01:20:19,685
Speaker 6:  they don't even go up in order in the way that you think that they should.

1312
01:20:21,025 --> 01:20:23,965
Speaker 6:  And so to have Sam be like, yeah, we know the numbers are ridiculous, please

1313
01:20:23,965 --> 01:20:27,445
Speaker 6:  make fun of so we're gonna fix it. Made me, made me feel a lot better.

1314
01:20:27,805 --> 01:20:31,605
Speaker 7:  Something else. OpenAI and Google share besides their bitter AI rivalry is

1315
01:20:31,645 --> 01:20:35,405
Speaker 7:  a horrible naming convention for their models. But

1316
01:20:35,635 --> 01:20:39,205
Speaker 6:  Alex, am I crazy? Is OpenAI on like a pretty wild product

1317
01:20:39,505 --> 01:20:42,245
Speaker 6:  run here? Like it's it's really the, there was deepsea. Yeah. And then they

1318
01:20:42,245 --> 01:20:45,405
Speaker 6:  were like, oh, we're gonna launch some stuff and like, boy have they, it

1319
01:20:45,405 --> 01:20:49,165
Speaker 7:  Seems unprecedented to a degree where it's like hard to

1320
01:20:49,195 --> 01:20:52,805
Speaker 7:  even keep up as someone covering it. My understanding is this model

1321
01:20:52,805 --> 01:20:56,685
Speaker 7:  architecture is their first, and I, I still feel like I'm trying to

1322
01:20:56,685 --> 01:21:00,205
Speaker 7:  understand really what this means practically, but like agentic model that

1323
01:21:00,205 --> 01:21:04,165
Speaker 7:  has now, it's the first one that does the deep thinking stuff,

1324
01:21:04,305 --> 01:21:08,045
Speaker 7:  but also can hook into all of the chat GPT products. So it can pull in web

1325
01:21:08,045 --> 01:21:11,045
Speaker 7:  results, do multimodal, it can like

1326
01:21:12,165 --> 01:21:15,685
Speaker 7:  apparently like do really interesting weird things with images and like edit

1327
01:21:15,685 --> 01:21:18,765
Speaker 7:  them and turn them around and like people are dropping an image like have

1328
01:21:18,765 --> 01:21:22,645
Speaker 7:  it reverse engineer where it was taken. So like the YouTube, like Google

1329
01:21:22,645 --> 01:21:25,765
Speaker 7:  Earth guy, like viral stuff, but like with ai.

1330
01:21:26,985 --> 01:21:30,685
Speaker 7:  So it's just a, it's a smarter model that now hooks

1331
01:21:30,915 --> 01:21:34,685
Speaker 7:  into all of the product. Whereas the models have so far been fairly sequestered

1332
01:21:34,685 --> 01:21:38,565
Speaker 7:  to certain aspects of chat GPT and what it can do. That's

1333
01:21:38,565 --> 01:21:42,405
Speaker 7:  my understanding of it. But they're, they're on such a tear, it's really

1334
01:21:42,405 --> 01:21:44,765
Speaker 7:  hard to keep track. I mean it's

1335
01:21:44,885 --> 01:21:47,365
Speaker 5:  Interesting 'cause the tear seems to be more related to

1336
01:21:48,585 --> 01:21:50,805
Speaker 5:  making better products out of all the products.

1337
01:21:50,995 --> 01:21:51,285
Speaker 7:  Yeah.

1338
01:21:51,705 --> 01:21:55,165
Speaker 5:  Or like attaching capabilities between products to each other to

1339
01:21:56,215 --> 01:22:00,075
Speaker 5:  get to the next step as opposed to here's the next new

1340
01:22:00,075 --> 01:22:03,435
Speaker 5:  model which is smarter than the last model by Yeah. However many percentage.

1341
01:22:03,755 --> 01:22:06,995
Speaker 5:  I do wonder if that's because Kevin Miles there, he's the product guy and

1342
01:22:06,995 --> 01:22:10,515
Speaker 5:  he is like, make the products good, but there's also a part where it feels

1343
01:22:10,545 --> 01:22:14,435
Speaker 5:  like the frontier model is not gonna get so much better. Yeah.

1344
01:22:14,585 --> 01:22:17,195
Speaker 5:  That it drives usage. You actually have to like make products.

1345
01:22:17,505 --> 01:22:20,675
Speaker 7:  Yeah. I've been writing about this for a while. The, the competitive nature

1346
01:22:20,735 --> 01:22:23,955
Speaker 7:  now is at the product layer, not the model layer. The models are commodifying.

1347
01:22:24,095 --> 01:22:28,035
Speaker 7:  Yes. Like they still feel different like when you use a new one. But I think

1348
01:22:28,065 --> 01:22:30,835
Speaker 7:  chat GBT, they're trying to make it like an operating system for your life.

1349
01:22:31,035 --> 01:22:32,955
Speaker 7:  I think they want to be Google Meta,

1350
01:22:34,695 --> 01:22:38,075
Speaker 7:  you know, product all productivity software. It's this,

1351
01:22:38,545 --> 01:22:42,155
Speaker 7:  it's, it's one of the grandest visions I've ever seen in like consumer tech

1352
01:22:42,175 --> 01:22:46,155
Speaker 7:  in terms of like, we are gonna use AI to try to do everything and,

1353
01:22:46,575 --> 01:22:49,715
Speaker 7:  and then he is working with Johnny Ive on hardware, right? That like you,

1354
01:22:49,935 --> 01:22:51,635
Speaker 7:  you tie that into your own hardware over time. What

1355
01:22:51,635 --> 01:22:52,555
Speaker 5:  If humane but good.

1356
01:22:53,545 --> 01:22:54,675
Speaker 7:  What if human made the good?

1357
01:22:55,195 --> 01:22:58,395
Speaker 6:  I mean, and to be clear, this is the story you have to tell in order to raise

1358
01:22:58,415 --> 01:23:00,275
Speaker 6:  the amount of money that they have raised. It

1359
01:23:00,275 --> 01:23:03,515
Speaker 7:  Is, but, but, but you look at what they're doing to chat GBT And that is

1360
01:23:03,515 --> 01:23:07,485
Speaker 7:  clearly the goal is like to Oh yeah. Encompass more of your everyday life.

1361
01:23:07,795 --> 01:23:10,365
Speaker 6:  Yeah. I mean there was the, was it this week that they announced the thing

1362
01:23:10,365 --> 01:23:12,925
Speaker 6:  where it'll remember all your past conversations, which is think Yeah. The

1363
01:23:12,925 --> 01:23:15,525
Speaker 6:  memory stuff. I feel like that didn't get talked about enough that that's

1364
01:23:15,525 --> 01:23:19,285
Speaker 6:  like all of a sudden if you, if you can have this thing be sort of accumulating

1365
01:23:19,285 --> 01:23:23,165
Speaker 6:  over time as you use it, the, the possibilities of stuff it can start

1366
01:23:23,165 --> 01:23:24,685
Speaker 6:  to do for you. It is really powerful.

1367
01:23:24,835 --> 01:23:28,565
Speaker 7:  It's lockin too. 'cause it knows more about you and it's way easier to, it's

1368
01:23:28,565 --> 01:23:32,445
Speaker 7:  way harder to wanna switch to another product because Chachi pet knows everything

1369
01:23:32,445 --> 01:23:32,765
Speaker 7:  about you.

1370
01:23:32,835 --> 01:23:33,325
Speaker 6:  Totally.

1371
01:23:33,845 --> 01:23:36,725
Speaker 5:  I realize I'm saying this is a guy who's on a been on a podcast for 15 years,

1372
01:23:36,725 --> 01:23:40,005
Speaker 5:  like has made a lot of YouTube videos and I just don't wanna be perceived

1373
01:23:40,005 --> 01:23:43,685
Speaker 5:  in this way. Like I, I don't want the computer to know me.

1374
01:23:45,425 --> 01:23:45,765
Speaker 7:  It already

1375
01:23:45,765 --> 01:23:46,965
Speaker 5:  Does. No, thank you. It's

1376
01:23:46,965 --> 01:23:49,805
Speaker 7:  Already showing you ads for like random car stuff. Like,

1377
01:23:50,025 --> 01:23:53,885
Speaker 5:  Oh man already knows you, my computer so believes that I'm gonna buy a Volvo

1378
01:23:54,105 --> 01:23:58,085
Speaker 5:  ex 90, like whatever, whatever's going on in here, it knows one

1379
01:23:58,085 --> 01:24:01,725
Speaker 5:  thing and it's gonna sell me a goddamn Volvo EX 19.

1380
01:24:01,845 --> 01:24:03,085
Speaker 6:  I feel like your computer's wrong about that.

1381
01:24:03,475 --> 01:24:07,325
Speaker 5:  It's so wrong about, about that. It's not correct. Also a Range Rover,

1382
01:24:07,385 --> 01:24:10,725
Speaker 5:  it really believes that what I'm gonna do is probably a Range Rover sport

1383
01:24:10,725 --> 01:24:11,005
Speaker 5:  And that

1384
01:24:11,005 --> 01:24:11,645
Speaker 6:  That feels closer.

1385
01:24:12,515 --> 01:24:16,005
Speaker 5:  It's not, I I I've looked at the reliability records of that vehicle. I

1386
01:24:16,005 --> 01:24:19,485
Speaker 7:  Just wanna like, I real thing, do you guys use the voice mode on Chachi pt?

1387
01:24:19,865 --> 01:24:22,445
Speaker 5:  All the timely, I was actually just looking at my history to be like, what

1388
01:24:22,445 --> 01:24:25,565
Speaker 5:  would this thing think about me? And it will think that I'm a 6-year-old

1389
01:24:25,565 --> 01:24:29,405
Speaker 5:  girl who occasionally asks for pickled red onion recipes. And that's,

1390
01:24:30,985 --> 01:24:32,925
Speaker 5:  that's like, those are the two things that happen

1391
01:24:33,475 --> 01:24:34,525
Speaker 7:  When I was in DC Yeah, we

1392
01:24:34,525 --> 01:24:36,405
Speaker 5:  Use it all the time. Like Max and I use it all the time.

1393
01:24:36,475 --> 01:24:39,485
Speaker 7:  Yeah. When I was in DC I was like, before I was the first day of court, I

1394
01:24:39,485 --> 01:24:42,645
Speaker 7:  was like laying in bed and I was like, I'm going to court tomorrow this court.

1395
01:24:42,645 --> 01:24:45,765
Speaker 7:  Like I'm not exactly sure how it's gonna work. Like what do I need to know

1396
01:24:45,765 --> 01:24:49,605
Speaker 7:  about going in? Like what can I not bring? And like it was, it was

1397
01:24:49,605 --> 01:24:53,405
Speaker 7:  amazing. Like it was like this is, I I can't believe it just, it works.

1398
01:24:53,945 --> 01:24:54,285
Speaker 7:  Was it

1399
01:24:54,285 --> 01:24:54,685
Speaker 5:  Correct?

1400
01:24:55,305 --> 01:24:59,285
Speaker 7:  Yes, it was correct. Yeah. And that, that's like I, I don't

1401
01:24:59,285 --> 01:25:01,885
Speaker 7:  know if they're doing better grounding with like real data that they're stealing

1402
01:25:01,905 --> 01:25:05,405
Speaker 7:  or what, but it's, I'm, excuse me, buying

1403
01:25:05,515 --> 01:25:06,125
Speaker 7:  licensing

1404
01:25:06,745 --> 01:25:07,885
Speaker 5:  Now I have to disclose it,

1405
01:25:09,605 --> 01:25:12,285
Speaker 5:  licensing deal with our company somewhere on the back end. It's, it's there.

1406
01:25:12,605 --> 01:25:14,765
Speaker 5:  I yeah, it it has nothing to do with us.

1407
01:25:14,915 --> 01:25:18,565
Speaker 7:  Yeah. But no, I I think like the combo of like the, the, the desktop product

1408
01:25:18,625 --> 01:25:22,205
Speaker 7:  really starting to encompass like all the productivity, the voice being very

1409
01:25:22,205 --> 01:25:25,205
Speaker 7:  good and then them doing hardware with Johnny I think is like this

1410
01:25:26,265 --> 01:25:28,125
Speaker 7:  insane play for everything.

1411
01:25:28,425 --> 01:25:31,405
Speaker 6:  The vision is really big. And I, and I think you're right that It is the,

1412
01:25:31,425 --> 01:25:35,325
Speaker 6:  the shift has really happened away from like, we, I think

1413
01:25:35,325 --> 01:25:37,885
Speaker 6:  pretty quickly we're gonna start to have conversations internally at The

1414
01:25:37,965 --> 01:25:41,645
Speaker 6:  Verge about whether we cover new models because it's, it's rapidly

1415
01:25:41,645 --> 01:25:44,085
Speaker 6:  getting to the point that it doesn't matter that much. It's like, it's like

1416
01:25:44,285 --> 01:25:47,845
Speaker 6:  covering new versions of AWS software. Like it's just, it's just not

1417
01:25:47,845 --> 01:25:51,565
Speaker 6:  meaningful to most people in these specific ways. I don't

1418
01:25:51,845 --> 01:25:52,485
Speaker 6:  think we're there yet.

1419
01:25:52,705 --> 01:25:55,325
Speaker 7:  We could just do a story stream where it's like new model came out.

1420
01:25:55,765 --> 01:25:59,005
Speaker 6:  Like yeah, like new model came out, it's 4% better.

1421
01:25:59,195 --> 01:26:01,925
Speaker 5:  Well, I mean you, you gotta cover the new models because they're all cheating

1422
01:26:01,925 --> 01:26:04,285
Speaker 5:  on the benchmarks and that's actually the story. Well yeah,

1423
01:26:04,285 --> 01:26:08,085
Speaker 6:  Agreed, agreed on that front. But yeah, we are, we are very much

1424
01:26:08,625 --> 01:26:12,285
Speaker 6:  moving toward like what can you build to have people

1425
01:26:12,705 --> 01:26:15,765
Speaker 6:  do with these things? And that's gonna be the only thing that matters.

1426
01:26:16,045 --> 01:26:19,765
Speaker 5:  I continue to believe, I mean the whole industry has been chasing what is

1427
01:26:19,765 --> 01:26:23,165
Speaker 5:  the new input paradigm that overtakes

1428
01:26:23,215 --> 01:26:26,965
Speaker 5:  multitouch forever. Like even Apple has been chasing, we,

1429
01:26:27,065 --> 01:26:29,525
Speaker 5:  I'm constantly joking about Apple, introducing the Apple watch to the digital

1430
01:26:29,575 --> 01:26:33,085
Speaker 5:  Crown. 'cause they, in their head, they have like a system,

1431
01:26:33,315 --> 01:26:37,175
Speaker 5:  like an equation that makes good products and they just learned it from

1432
01:26:37,335 --> 01:26:39,895
Speaker 5:  watching old Steve Jobs keynotes. Like they reversed engineer to Steve Jobs

1433
01:26:39,895 --> 01:26:43,775
Speaker 5:  keynote and he is like, well he did a click wheel, he did U2

1434
01:26:43,775 --> 01:26:47,535
Speaker 5:  was there and he said it was small. And then they got to the Apple

1435
01:26:47,535 --> 01:26:51,295
Speaker 5:  watch and they're like, okay, it's got a wheel. U2 is here and it's small.

1436
01:26:51,295 --> 01:26:51,535
Speaker 5:  Like,

1437
01:26:52,205 --> 01:26:52,495
Speaker 6:  It's

1438
01:26:52,495 --> 01:26:54,695
Speaker 5:  Like that's just how their brains work. You know,

1439
01:26:56,615 --> 01:26:59,855
Speaker 5:  everyone has been trying to move on to say, okay, this is the new input,

1440
01:26:59,855 --> 01:27:03,815
Speaker 5:  this is the new user interface paradigm that's gonna drive the next form

1441
01:27:03,815 --> 01:27:07,415
Speaker 5:  factor that's gonna drive the next wave of apps, whatever It is. And It is

1442
01:27:07,415 --> 01:27:11,375
Speaker 5:  true that with AI in particular, what you have is natural

1443
01:27:11,695 --> 01:27:13,455
Speaker 5:  language voice. So you can just talk to the computer, it'll talk back to

1444
01:27:13,455 --> 01:27:17,415
Speaker 5:  you. It's a very compelling and then we still

1445
01:27:17,415 --> 01:27:20,495
Speaker 5:  dunno how any of that's gonna make money. And then at the same time, right,

1446
01:27:20,495 --> 01:27:24,255
Speaker 5:  there's the big cursor deal, which seems like a really big deal. Yeah. And

1447
01:27:24,255 --> 01:27:27,495
Speaker 5:  then OpenAI is going to potentially buy this company called Windsurf for

1448
01:27:27,495 --> 01:27:31,415
Speaker 5:  $3 billion. Yeah. There's this whole enterprise set of applications that

1449
01:27:31,415 --> 01:27:35,135
Speaker 5:  has kind of nothing to do with, is this a new input paradigm? It's much more,

1450
01:27:35,835 --> 01:27:38,855
Speaker 5:  oh, we're gonna make everybody vastly more productive in this specific way.

1451
01:27:38,855 --> 01:27:40,215
Speaker 6:  Yeah. And that's where all the money is.

1452
01:27:40,315 --> 01:27:42,455
Speaker 5:  And that's, that does feel like where all the money is. Yeah.

1453
01:27:42,485 --> 01:27:42,775
Speaker 7:  Yeah.

1454
01:27:44,035 --> 01:27:47,495
Speaker 5:  But I, the part where Johnny Ive is like, I can take the new input paradigm

1455
01:27:47,495 --> 01:27:51,175
Speaker 5:  and make the next great product. It, it's, even if it's Johnny,

1456
01:27:51,275 --> 01:27:54,695
Speaker 5:  ive, even if it's Sam Altman, even if they have direct access to the next

1457
01:27:54,695 --> 01:27:57,975
Speaker 5:  model from open, like it's still uncertain because it,

1458
01:27:58,685 --> 01:28:02,025
Speaker 5:  it hasn't been proven that that's what you wanna do all the time.

1459
01:28:02,525 --> 01:28:05,345
Speaker 6:  I'm actually very excited about this next moment because I, I wrote a feature

1460
01:28:05,445 --> 01:28:09,065
Speaker 6:  for Wired like 10 years ago now. Basically

1461
01:28:09,065 --> 01:28:11,025
Speaker 6:  proclaiming the beginning of the voice era.

1462
01:28:11,645 --> 01:28:12,105
Speaker 5:  You were a

1463
01:28:12,105 --> 01:28:12,585
Speaker 7:  Little early.

1464
01:28:13,065 --> 01:28:17,025
Speaker 6:  I was, I was rough. Right. And I was wrong. Right. Like it was, it it happened.

1465
01:28:17,025 --> 01:28:20,025
Speaker 6:  Yeah. Everybody started doing voice, but in much more limited ways than I

1466
01:28:20,025 --> 01:28:23,985
Speaker 6:  think I was expecting. Yeah. But we're now at the point where the tech works.

1467
01:28:24,295 --> 01:28:27,505
Speaker 6:  Like, it's, it's not perfect, but it works. The, the basic

1468
01:28:28,285 --> 01:28:31,985
Speaker 6:  can I speak and be spoken to with a computer in a useful way?

1469
01:28:32,125 --> 01:28:35,105
Speaker 6:  It works. And now the open question is,

1470
01:28:36,445 --> 01:28:39,905
Speaker 6:  so what, what do we do with that? And that no one has good answers to that

1471
01:28:39,925 --> 01:28:42,625
Speaker 6:  yet. Right. Like it's, it's fun and interesting. Yeah. But we're sitting

1472
01:28:42,645 --> 01:28:44,865
Speaker 6:  on more and if there's gonna be more, it's coming.

1473
01:28:45,145 --> 01:28:48,265
Speaker 7:  I think we're gonna be talking about the Johnny thing with Sam Altman in

1474
01:28:48,265 --> 01:28:52,025
Speaker 7:  the coming year to two years. I really do. I think Johnny's

1475
01:28:52,025 --> 01:28:55,945
Speaker 7:  biggest funder for his new company is Lre Pal Jobs. Like it's, and he's

1476
01:28:55,945 --> 01:28:59,825
Speaker 7:  hired all of the original Apple team design team. If you're

1477
01:28:59,825 --> 01:29:03,725
Speaker 7:  gonna bet on anyone coming in as like a wild horse and, and doing

1478
01:29:03,725 --> 01:29:05,685
Speaker 7:  something interesting, I would be paying attention to that.

1479
01:29:06,075 --> 01:29:09,805
Speaker 5:  Yeah. And meanwhile Apple is going under whatever series shuffles it's

1480
01:29:09,805 --> 01:29:13,125
Speaker 5:  undergoing. Right? Like who knows, who knows that they can, they can pull

1481
01:29:13,125 --> 01:29:16,525
Speaker 5:  it off. But you know, apple, we started by talking about opening, starting

1482
01:29:16,525 --> 01:29:19,805
Speaker 5:  a social network. Apple still has the most important distribution of all.

1483
01:29:19,875 --> 01:29:23,005
Speaker 5:  Yeah. Right. It's just like in your pocket, like Oprah at the Apple TV launch

1484
01:29:23,005 --> 01:29:24,405
Speaker 5:  being like a billion pockets, you know, like

1485
01:29:26,025 --> 01:29:28,925
Speaker 5:  if they can get it together, like maybe they'll get there. But it's interesting

1486
01:29:28,925 --> 01:29:32,885
Speaker 5:  that they're wavering and Google is wavering and then Sam Altman's

1487
01:29:32,885 --> 01:29:36,245
Speaker 5:  like, I need a trillion dollars. Yeah. And I just dunno how that plays out.

1488
01:29:36,345 --> 01:29:38,845
Speaker 5:  All right. We gotta take a break. We're gonna come back with a lightning

1489
01:29:38,845 --> 01:29:39,765
Speaker 5:  round. We'll be right back.

1490
01:33:07,145 --> 01:33:11,085
Speaker 5:  So Brenda loves to threaten or even file what he

1491
01:33:11,085 --> 01:33:14,965
Speaker 5:  calls news distortion cases or the FCC, which licenses the nation's

1492
01:33:14,965 --> 01:33:18,885
Speaker 5:  airwaves to broadcasters can say to various news

1493
01:33:18,885 --> 01:33:21,485
Speaker 5:  organizations, the broadcast news organizations,

1494
01:33:21,965 --> 01:33:25,885
Speaker 5:  N-B-C-C-B-S, Fox, Hey, you're distorting news. You're taking the

1495
01:33:25,965 --> 01:33:28,565
Speaker 5:  spectrum, we're giving you and doing something misleading with the news on

1496
01:33:28,565 --> 01:33:32,485
Speaker 5:  it. They're not supposed to do this in most cases. Right? The First

1497
01:33:32,485 --> 01:33:36,285
Speaker 5:  Amendment protects those broadcasters and you can air what you want to air

1498
01:33:36,545 --> 01:33:39,845
Speaker 5:  as long as you're not being willfully misleading in particular ways.

1499
01:33:40,425 --> 01:33:44,245
Speaker 5:  And It is true that Fox owns a bunch of broadcast stations. Sinclair

1500
01:33:44,245 --> 01:33:47,765
Speaker 5:  Broadcasting very conservative, owns a bunch of broadcast stations. And yes,

1501
01:33:48,285 --> 01:33:51,805
Speaker 5:  NBC and CBS and a BC also own a bunch of podcast stations.

1502
01:33:52,505 --> 01:33:56,445
Speaker 5:  So you can see already Americans have choices. But this

1503
01:33:56,445 --> 01:34:00,365
Speaker 5:  week the Trump administration is under tremendous amounts of criticism

1504
01:34:00,745 --> 01:34:04,485
Speaker 5:  and controversy because it mistakenly deported a man to

1505
01:34:04,485 --> 01:34:08,205
Speaker 5:  El Salvador, Kmar Abrego Garcia. It did this with

1506
01:34:08,205 --> 01:34:11,885
Speaker 5:  basically no evidence. It has admitted to the court that it had

1507
01:34:11,985 --> 01:34:15,325
Speaker 5:  no real evidence And that this was a mistake. I call it administrative error.

1508
01:34:15,705 --> 01:34:19,445
Speaker 5:  And instead of bringing a man back, which the Supreme Court ordered,

1509
01:34:19,585 --> 01:34:23,405
Speaker 5:  it had to facilitate. It is doubled down now on calling him a

1510
01:34:23,685 --> 01:34:27,085
Speaker 5:  terrorist and a gang member. The evidence, by the way, this may be a gang

1511
01:34:27,085 --> 01:34:30,765
Speaker 5:  member, is that he was wearing a Chicago Bulls hat and a t-shirt

1512
01:34:31,285 --> 01:34:35,085
Speaker 5:  with dollar bills on it, or a sweatshirt with dollar bills on it, where the

1513
01:34:35,085 --> 01:34:38,645
Speaker 5:  presidents on the bills had their eyes covered, ears covered and, and mouth

1514
01:34:38,645 --> 01:34:42,405
Speaker 5:  covered. And somehow that indicated that they, they were in a gang. I don't

1515
01:34:42,405 --> 01:34:46,235
Speaker 5:  know, man. That's the evidence the government has proffered this week for

1516
01:34:46,515 --> 01:34:49,075
Speaker 5:  evidence that he's being in a gang. It's not great.

1517
01:34:49,345 --> 01:34:51,595
Speaker 6:  It's nothing is what It is. It's nothing.

1518
01:34:51,865 --> 01:34:55,635
Speaker 5:  It's it's nothing. I mean, this is a, he was in the country legally, but

1519
01:34:55,635 --> 01:34:59,445
Speaker 5:  he had a, a, a court order saying he couldn't be deported because he,

1520
01:34:59,625 --> 01:35:03,485
Speaker 5:  his, he was in danger if he went to El Salvador from other gangs there. So

1521
01:35:03,585 --> 01:35:06,965
Speaker 5:  the court, the Trump administration has mistakenly deported him. They've

1522
01:35:06,965 --> 01:35:10,085
Speaker 5:  gone up to the Supreme Court, which has ruled that has to facilitate his

1523
01:35:10,085 --> 01:35:13,685
Speaker 5:  return. They've gone to the court again, the court is very angry with him,

1524
01:35:13,715 --> 01:35:16,685
Speaker 5:  with the Trump administration. Now, I don't know how this is gonna play out,

1525
01:35:17,025 --> 01:35:20,965
Speaker 5:  but news organizations around the country have been covering it and

1526
01:35:21,245 --> 01:35:24,765
Speaker 5:  covering in particular fact that there's no evidence that this man was actually

1527
01:35:24,765 --> 01:35:28,725
Speaker 5:  an MSN 13. Like, not like none at all outside

1528
01:35:28,725 --> 01:35:32,365
Speaker 5:  of a hat and one confidential informant that nobody has ever. No, you, you

1529
01:35:32,365 --> 01:35:36,005
Speaker 5:  were good at, none at all. That was, you were, you were set there. That's

1530
01:35:36,005 --> 01:35:39,965
Speaker 5:  not at all. Yeah. So Brendan this week has decided to threaten

1531
01:35:39,965 --> 01:35:43,885
Speaker 5:  Comcast disclosure. Comcast is an investor in Vox Media, but truly

1532
01:35:43,885 --> 01:35:47,565
Speaker 5:  they dislike me. He decided to threaten Comcast this week.

1533
01:35:47,865 --> 01:35:51,765
Speaker 5:  He said Comcast outlets have spent days misleading the American public, implying

1534
01:35:51,765 --> 01:35:55,485
Speaker 5:  that a Braigo Garcia was merely a law abiding citizen, just a regular Maryland

1535
01:35:55,625 --> 01:35:59,565
Speaker 5:  man. When the truth comes out, what is the truth, Brendan? They ignore

1536
01:35:59,565 --> 01:36:03,445
Speaker 5:  it. Comcast knows that federal law requires its licensed operations to

1537
01:36:03,455 --> 01:36:06,725
Speaker 5:  serve the public interest. News distortion doesn't cut it.

1538
01:36:07,065 --> 01:36:09,965
Speaker 5:  Abrego Garcia came to America legally from El Salvador, was validated as

1539
01:36:09,965 --> 01:36:13,645
Speaker 5:  a member of the violent MS 13 gang, a transnational

1540
01:36:13,925 --> 01:36:17,765
Speaker 5:  criminal organization and denied bond by immigration court for failure

1541
01:36:17,785 --> 01:36:20,845
Speaker 5:  to show he cannot pose a danger to others. Why does Comcast ignore these

1542
01:36:20,845 --> 01:36:24,605
Speaker 5:  facts? Because they're not facts, Brendan. They're just not facts.

1543
01:36:25,065 --> 01:36:29,005
Speaker 5:  And actually the job of news organizations we run, one is to

1544
01:36:29,685 --> 01:36:33,605
Speaker 5:  question the government, is to take the political figures of our

1545
01:36:33,605 --> 01:36:37,445
Speaker 5:  government, to take the Attorney general, to take JD Vance

1546
01:36:37,465 --> 01:36:41,365
Speaker 5:  and say, is that true? Is it true what you're saying? We've

1547
01:36:41,365 --> 01:36:45,245
Speaker 5:  given you the power to jail people. The state has a monopoly

1548
01:36:45,245 --> 01:36:49,205
Speaker 5:  on violence in this country. You have that power. Are you using it well?

1549
01:36:49,745 --> 01:36:53,485
Speaker 5:  Are you using it with justification? Are you using it in the name of justice?

1550
01:36:55,285 --> 01:36:58,215
Speaker 5:  They're not like, whatever you think about this case, whatever you think

1551
01:36:58,215 --> 01:37:01,815
Speaker 5:  about deportations in this case, they have not given this mandu process.

1552
01:37:01,845 --> 01:37:05,215
Speaker 5:  They shipped him off to El Salvador and the only evidence they have

1553
01:37:05,815 --> 01:37:08,655
Speaker 5:  actually profited is It is wearing a bulls hat.

1554
01:37:11,445 --> 01:37:15,375
Speaker 5:  Like, great. That is a controversy. You can cover it the way they're covering

1555
01:37:15,375 --> 01:37:17,815
Speaker 5:  it on a Fox. You can cover it the way they're covering it on newsmax. You

1556
01:37:17,815 --> 01:37:21,695
Speaker 5:  can cover it the way they're covering it on MSN bbc. But the government doesn't

1557
01:37:21,695 --> 01:37:25,225
Speaker 5:  get to go threaten the news organizations covering it. Brendan

1558
01:37:25,455 --> 01:37:29,185
Speaker 5:  Carr doesn't get to show up and say News Distortion doesn't cut it.

1559
01:37:29,485 --> 01:37:33,305
Speaker 5:  And the only reason he's saying It is because NBC owns some broadcast licenses

1560
01:37:33,305 --> 01:37:36,945
Speaker 5:  and he has the authority to say it. He can't say it to us, we're on the internet.

1561
01:37:37,365 --> 01:37:41,105
Speaker 5:  He can't say it to M-S-N-B-C or Fox, which are cable stations

1562
01:37:41,175 --> 01:37:44,625
Speaker 5:  that he doesn't have control over. This is just naked political

1563
01:37:44,625 --> 01:37:48,545
Speaker 5:  posturing because some of these stations run over the

1564
01:37:48,545 --> 01:37:51,945
Speaker 5:  broadcast airwaves. And even in his mentions, I'll point out, even in his

1565
01:37:51,945 --> 01:37:55,445
Speaker 5:  mentions, people are calling him an idiot. Like, this is just wrong.

1566
01:37:56,075 --> 01:37:58,845
Speaker 5:  It's wrong for the person who runs the nation's communications infrastructure

1567
01:37:59,345 --> 01:38:02,085
Speaker 5:  to say that not supporting the administration's lies

1568
01:38:03,445 --> 01:38:07,305
Speaker 5:  is news distortion. Actually, what he'll be saying is, I support

1569
01:38:07,605 --> 01:38:11,385
Speaker 5:  our vibrant broadcast networks, which reach most Americans. Pushing hard

1570
01:38:11,725 --> 01:38:15,665
Speaker 5:  on the truth whether or not you agree with mass deportations,

1571
01:38:15,665 --> 01:38:19,625
Speaker 5:  whether or not you agree with the Trump administration coming down

1572
01:38:19,625 --> 01:38:22,345
Speaker 5:  really hard on everybody who was illegally in this country. Fine,

1573
01:38:23,405 --> 01:38:27,225
Speaker 5:  you can think what you want, but in this case the lie is obvious.

1574
01:38:27,605 --> 01:38:30,785
Speaker 5:  In this case, the evidence has not been produced and It is not news distortion

1575
01:38:31,405 --> 01:38:35,185
Speaker 5:  to say the government has not produced this evidence. I just,

1576
01:38:35,385 --> 01:38:39,345
Speaker 5:  I, he's such a flunky. It drives me bananas. It

1577
01:38:39,345 --> 01:38:41,745
Speaker 5:  is nice that people are starting to call him out on it. I will say that,

1578
01:38:42,805 --> 01:38:46,745
Speaker 5:  but It is just obvious that just like Andrew Ferguson, there are things he

1579
01:38:46,745 --> 01:38:50,465
Speaker 5:  has to say and there are are lines he has to accept

1580
01:38:50,495 --> 01:38:54,345
Speaker 5:  from the rest of the administration in order to preserve his job. And Brendan

1581
01:38:54,345 --> 01:38:58,105
Speaker 5:  does it with such glee that you have to just accept that he

1582
01:38:58,105 --> 01:38:58,505
Speaker 5:  wants to,

1583
01:38:59,105 --> 01:39:02,545
Speaker 6:  I think that gives him too much of an out to say these are things that he

1584
01:39:02,545 --> 01:39:05,905
Speaker 6:  has to say. I think all evidence about Brendan Carr suggests that he is so,

1585
01:39:05,905 --> 01:39:09,865
Speaker 6:  so, so happy to be saying and doing all the stuff that he is saying and

1586
01:39:09,865 --> 01:39:13,825
Speaker 6:  doing. He's like, Mr. I'm out here having the time of my life. Guy like

1587
01:39:14,015 --> 01:39:15,585
Speaker 5:  Wearing the head of Donald Trump on the

1588
01:39:15,585 --> 01:39:19,105
Speaker 6:  Game. Yeah, no, none of this is making him sad on his insides.

1589
01:39:19,285 --> 01:39:22,945
Speaker 5:  So then here's the loop closing, which I think is even more dangerous as

1590
01:39:22,945 --> 01:39:26,065
Speaker 5:  he does. President Trump was watching television late at night. The thing

1591
01:39:26,065 --> 01:39:26,305
Speaker 5:  he does.

1592
01:39:27,415 --> 01:39:29,025
Speaker 6:  Yeah. Presidents, they're just like us.

1593
01:39:29,445 --> 01:39:32,865
Speaker 5:  He watches 60 minutes a lot. Donald Trump, it appears. So this week he's

1594
01:39:32,985 --> 01:39:36,665
Speaker 5:  watching 60 minutes and he gets real mad and he posts this long rant on truth

1595
01:39:36,665 --> 01:39:40,585
Speaker 5:  social about how they're talking to Kamala Harris. Again, they

1596
01:39:40,585 --> 01:39:43,705
Speaker 5:  mentioned the word Trump and they're not nice to me. And at the end of this

1597
01:39:43,735 --> 01:39:47,385
Speaker 5:  long rant he says they should lose their license. Hopefully the

1598
01:39:47,425 --> 01:39:51,225
Speaker 5:  FCC is headed by a s highly respected chairman. Brendan Carr will impose

1599
01:39:51,325 --> 01:39:55,265
Speaker 5:  the maximum fines and punishment for their unlawful and illegal behavior.

1600
01:39:55,545 --> 01:39:59,185
Speaker 5:  CBS is out of control and they should pay a big price for this. When you

1601
01:39:59,185 --> 01:40:03,145
Speaker 5:  become the flunky, the president of the United States can say,

1602
01:40:03,305 --> 01:40:07,265
Speaker 5:  I want to punish the speech of this company and my guy's gonna do

1603
01:40:07,265 --> 01:40:10,735
Speaker 5:  it for me. That is just a violation of the First Amendment

1604
01:40:11,135 --> 01:40:14,495
Speaker 5:  straightforwardly. No matter how you think about the legal mechanics of who

1605
01:40:14,495 --> 01:40:18,175
Speaker 5:  owns the broadcast licenses, the president watching tv, getting mad at the

1606
01:40:18,335 --> 01:40:22,015
Speaker 5:  coverage and then directing his flunky to punish the company is not how it's

1607
01:40:22,175 --> 01:40:25,535
Speaker 5:  supposed to work. Like at all. They work for us.

1608
01:40:26,455 --> 01:40:30,345
Speaker 5:  Like when I watch these press conferences, the thing that I want some reporter

1609
01:40:30,445 --> 01:40:34,145
Speaker 5:  to say sometime is, do you realize that you work for me?

1610
01:40:34,865 --> 01:40:38,115
Speaker 5:  Because they've all forgotten it. Brendan has forgotten it. He works for

1611
01:40:38,115 --> 01:40:41,795
Speaker 5:  us. And I think it's probably times someone reminded him of that.

1612
01:40:42,255 --> 01:40:45,995
Speaker 5:  And Brendan, I would happy to do that. If you just want to come onto Coder

1613
01:40:45,995 --> 01:40:48,675
Speaker 5:  or The Vergecast as always, the door's open. I don't think you can do it.

1614
01:40:48,755 --> 01:40:51,435
Speaker 5:  'cause I don't think you can take the heat. I know people are starting to

1615
01:40:51,435 --> 01:40:54,565
Speaker 5:  tweet these segments at you. It's pretty good. So if you think you can do

1616
01:40:54,565 --> 01:40:58,045
Speaker 5:  it, if you think of the intellectual rigor to show up in the show and justify

1617
01:40:58,045 --> 01:41:01,325
Speaker 5:  your actions, you're welcome. That's been Brennan Carr is dummy America's

1618
01:41:01,365 --> 01:41:02,205
Speaker 5:  favorite podcast. Within a podcast

1619
01:41:03,825 --> 01:41:05,365
Speaker 6:  Jingle tk.

1620
01:41:05,915 --> 01:41:09,165
Speaker 5:  It's funny, like I'm just becoming like an angry talk radio show host, you

1621
01:41:09,165 --> 01:41:11,445
Speaker 5:  know, but that's, you gotta fight firefighter. It's

1622
01:41:11,445 --> 01:41:13,765
Speaker 6:  Okay. I like to think we just need to get it outta your system once a week.

1623
01:41:13,765 --> 01:41:15,605
Speaker 6:  It makes you like a happier person afterwards.

1624
01:41:15,635 --> 01:41:19,425
Speaker 5:  Yeah. The the number, it's like what you want most

1625
01:41:19,445 --> 01:41:22,705
Speaker 5:  of all is just feedback from the audience. You know, like anybody who makes

1626
01:41:22,705 --> 01:41:26,065
Speaker 5:  something that's like as desperate, you know, like, read my novel and now

1627
01:41:26,065 --> 01:41:28,985
Speaker 5:  we get a lot of the feedback, but the feedback only enrages me. 'cause it's

1628
01:41:28,985 --> 01:41:30,625
Speaker 5:  just stuff Brendan has done that other people

1629
01:41:30,625 --> 01:41:30,945
Speaker 6:  Notice.

1630
01:41:32,225 --> 01:41:32,345
Speaker 5:  I,

1631
01:41:32,885 --> 01:41:36,385
Speaker 7:  The the feeling of like, you work for me. I had in the Meta trial earlier

1632
01:41:36,455 --> 01:41:40,425
Speaker 7:  this week when like Ferguson was like looking down at all of us, like who

1633
01:41:40,425 --> 01:41:43,825
Speaker 7:  were there with the press and like would not make eye contact with us. And

1634
01:41:43,825 --> 01:41:47,545
Speaker 7:  then his like comms lead who used to I think work for the Washington examiner

1635
01:41:48,885 --> 01:41:52,865
Speaker 7:  was also like, just pretending we didn't exist when we were standing

1636
01:41:52,865 --> 01:41:55,065
Speaker 7:  right in front of him and trying to like, ask basic

1637
01:41:55,065 --> 01:41:57,385
Speaker 5:  Things. It's like really bad for the comms people, right? It's like, you

1638
01:41:57,385 --> 01:42:00,025
Speaker 5:  know, like that's why you're here. But like, I mean that like the highest

1639
01:42:00,075 --> 01:42:03,765
Speaker 5:  level. Yeah. Donald Trump works for you whether you love him or you hate

1640
01:42:03,765 --> 01:42:07,475
Speaker 5:  him. That that's the whole point. He works for us.

1641
01:42:07,695 --> 01:42:10,965
Speaker 5:  We, we get to fire him at the end, right? Like

1642
01:42:12,115 --> 01:42:15,595
Speaker 5:  I, this whole administration has completely forgotten this like, very important

1643
01:42:15,595 --> 01:42:19,355
Speaker 5:  piece of the puzzle. But that said,

1644
01:42:19,355 --> 01:42:22,075
Speaker 5:  Brendan isn't smart enough to make it through the whole four years. So we'll

1645
01:42:22,075 --> 01:42:24,795
Speaker 5:  see what happens. All right. Pallet cleanser, David.

1646
01:42:25,475 --> 01:42:29,155
Speaker 6:  Okay, we're gonna skip right over tariffs because that that doesn't count.

1647
01:42:29,395 --> 01:42:29,755
Speaker 5:  That's a

1648
01:42:30,355 --> 01:42:32,755
Speaker 6:  And also nothing has changed. Tariffs happen. They don't

1649
01:42:32,755 --> 01:42:35,435
Speaker 5:  Happen. Well the numbers, the numbers have changed, but it doesn't matter.

1650
01:42:35,435 --> 01:42:35,675
Speaker 5:  Yeah,

1651
01:42:35,675 --> 01:42:38,835
Speaker 6:  But who cares? They'll change again by the time this podcast goes up. Like

1652
01:42:38,835 --> 01:42:40,715
Speaker 6:  the, the numbers have changed. There you go. That's the news.

1653
01:42:42,725 --> 01:42:46,265
Speaker 6:  We figured out the G seven X story. Eli Alison Johnson went

1654
01:42:46,565 --> 01:42:49,225
Speaker 6:  and answered our question about, there's

1655
01:42:49,225 --> 01:42:53,105
Speaker 5:  Like two answers to this question and one of them is so

1656
01:42:53,105 --> 01:42:57,055
Speaker 5:  confusing and the other one is like also confusing in

1657
01:42:57,055 --> 01:42:57,655
Speaker 5:  a very different way.

1658
01:42:57,915 --> 01:43:01,095
Speaker 6:  So, okay, so I, I want, I want you to explain this story because actually

1659
01:43:01,095 --> 01:43:05,055
Speaker 6:  this story originates with you. Fun fact. I, I did the, the final

1660
01:43:05,055 --> 01:43:08,695
Speaker 6:  edit on this story and I made Alison take out the line where she says, I'm

1661
01:43:08,695 --> 01:43:10,495
Speaker 6:  writing this story because Neil, I made me do it.

1662
01:43:12,195 --> 01:43:15,415
Speaker 5:  We definitely put up a Liz story today that it contains like a very similar

1663
01:43:15,445 --> 01:43:18,655
Speaker 5:  line. It's great. That's, that's what being an energy chief is about. It

1664
01:43:18,655 --> 01:43:21,335
Speaker 5:  is true. However, that other people on our staff also saw the story.

1665
01:43:22,565 --> 01:43:25,415
Speaker 5:  Okay, so the Canon G seven X three

1666
01:43:26,465 --> 01:43:30,265
Speaker 5:  a camera from 2018 has gone totally virally, cannot get this camera anywhere.

1667
01:43:30,725 --> 01:43:34,145
Speaker 5:  If you can get it, it's even like a used one is selling for like

1668
01:43:34,145 --> 01:43:38,105
Speaker 5:  $300 over MSRP. This is not normal. Like

1669
01:43:38,105 --> 01:43:41,545
Speaker 5:  there's lots of pocket cameras with one inch sensors that do a good job of

1670
01:43:41,775 --> 01:43:45,585
Speaker 5:  just taking photos, but it's gone viral on TikTok and so it's sold out

1671
01:43:45,585 --> 01:43:49,225
Speaker 5:  everywhere and there are tiktoks now about how to get one,

1672
01:43:49,455 --> 01:43:53,205
Speaker 5:  like when in the middle of the night to wake up and like power refresh the

1673
01:43:53,205 --> 01:43:57,045
Speaker 5:  target website. So I see all this, Allison and the crew and I

1674
01:43:57,045 --> 01:44:00,725
Speaker 5:  talk about it and we had the first idea, which is we should buy one and see

1675
01:44:00,725 --> 01:44:03,405
Speaker 5:  if this camera's any good. And then Allison is like, it's been three weeks

1676
01:44:03,405 --> 01:44:07,285
Speaker 5:  and I can't buy one. Like I've been trying to buy one. Yeah. Like

1677
01:44:07,955 --> 01:44:11,325
Speaker 5:  many people have been like setting up weird bots for her

1678
01:44:11,985 --> 01:44:15,645
Speaker 5:  to buy like Antonio de Beno. And our team was like, I'm really good at buying

1679
01:44:15,645 --> 01:44:18,605
Speaker 5:  stuff. Like I'll help you so we we could not get one

1680
01:44:19,495 --> 01:44:22,325
Speaker 5:  crazy if you have one, let us know if you like it. But then she talked to

1681
01:44:22,325 --> 01:44:26,005
Speaker 5:  all the creators who are using it and it turns out one, it's just

1682
01:44:26,265 --> 01:44:30,235
Speaker 5:  an answer. Which is fascinating, right? There's still enough choice

1683
01:44:30,255 --> 01:44:34,075
Speaker 5:  in that market that just an answer is

1684
01:44:34,575 --> 01:44:38,475
Speaker 5:  useful. Right? So it, yes, you could just buy an RX 100. Yes.

1685
01:44:38,475 --> 01:44:42,235
Speaker 5:  There's like various Fuji cameras that like do the job, but this is just

1686
01:44:42,235 --> 01:44:43,075
Speaker 5:  the answer. Yeah.

1687
01:44:43,075 --> 01:44:45,315
Speaker 6:  Like it takes, it takes pretty good video, it takes pretty good pictures.

1688
01:44:46,655 --> 01:44:50,265
Speaker 6:  It's a reasonable size that you can carry around with you like and

1689
01:44:50,265 --> 01:44:51,545
Speaker 5:  It looks cool, which is important.

1690
01:44:51,655 --> 01:44:52,505
Speaker 6:  Sold. Yeah. And

1691
01:44:52,505 --> 01:44:56,385
Speaker 5:  Then so that part is like confusing in, in the sense that like, who

1692
01:44:56,385 --> 01:44:59,855
Speaker 5:  knows how things become the answer. Do you know what I mean? Like, and it's

1693
01:44:59,855 --> 01:45:03,655
Speaker 5:  not a cannon that stepped up production, it's just here's this thing

1694
01:45:03,895 --> 01:45:06,655
Speaker 5:  everyone wants and cannon's like it's a five old camera, buy her new camera

1695
01:45:06,655 --> 01:45:09,975
Speaker 5:  instead. Like very much canon's like, would you like to buy the new camera?

1696
01:45:10,115 --> 01:45:11,335
Speaker 5:  And people are like no old camera.

1697
01:45:11,555 --> 01:45:15,415
Speaker 6:  One of the things Allison found is that there, there is like a newer camera

1698
01:45:15,635 --> 01:45:19,415
Speaker 6:  in that line, I think it's called the Power Shot V one that like

1699
01:45:19,565 --> 01:45:23,255
Speaker 6:  just relatively recently came out. You can buy it so easily. It's just right

1700
01:45:23,255 --> 01:45:26,095
Speaker 6:  there. Yeah. Wants that one. You can just have it, but no one wants it. They

1701
01:45:26,095 --> 01:45:27,175
Speaker 6:  want the five-year-old one.

1702
01:45:27,445 --> 01:45:30,175
Speaker 5:  Yeah. Because it's just the answer. So that's confusing in the sense that

1703
01:45:30,175 --> 01:45:33,935
Speaker 5:  like, why do things become popular? You know, it's like some art

1704
01:45:33,955 --> 01:45:37,535
Speaker 5:  and science confusing. The more confusing thing is the reason people like

1705
01:45:37,535 --> 01:45:41,495
Speaker 5:  It is because apparently it shoots great flash photos. So all the tips for

1706
01:45:41,495 --> 01:45:45,175
Speaker 5:  using it are like open the flash even in like broad daylight, just like fire

1707
01:45:45,175 --> 01:45:45,895
Speaker 5:  that flash out.

1708
01:45:46,445 --> 01:45:48,895
Speaker 6:  It's, it's 1999 again Nili. It's

1709
01:45:48,895 --> 01:45:51,535
Speaker 5:  Great. We're doing it. I kind of love it. I haven't, I I've started popping

1710
01:45:51,535 --> 01:45:55,525
Speaker 5:  the flash on my RX 100 to be like baby rave, you

1711
01:45:55,525 --> 01:45:59,325
Speaker 5:  know, like it's like a good time. Wait till these kids figure out how to

1712
01:45:59,325 --> 01:46:02,725
Speaker 5:  shoot with slow shutter. So you get the nice background and the flash.

1713
01:46:03,945 --> 01:46:07,635
Speaker 5:  It's so funny. Yeah. Flash was just like you, it was, it was embarrassing

1714
01:46:07,775 --> 01:46:09,035
Speaker 5:  to need flash for so

1715
01:46:09,035 --> 01:46:10,115
Speaker 6:  Long. Oh yeah. And,

1716
01:46:10,175 --> 01:46:12,355
Speaker 5:  But it was cool before that And that now it's the trend And that it's cool

1717
01:46:12,355 --> 01:46:15,835
Speaker 5:  that, and this one camera, like literally the, the

1718
01:46:15,835 --> 01:46:19,355
Speaker 5:  conversation, the discourse is you need to buy this camera because

1719
01:46:19,695 --> 01:46:20,515
Speaker 5:  of its flash.

1720
01:46:21,175 --> 01:46:24,675
Speaker 6:  And that means all these kids are like looking at their parents' photos from

1721
01:46:24,675 --> 01:46:28,155
Speaker 6:  college being like, oh that's so vintage. And those are the pictures they

1722
01:46:28,155 --> 01:46:30,915
Speaker 6:  want to take. And I'm realizing those are the pictures that I have from college

1723
01:46:30,945 --> 01:46:33,555
Speaker 6:  because I'm 100,000 years old.

1724
01:46:34,255 --> 01:46:37,875
Speaker 5:  So when we were like early two thousands

1725
01:46:37,925 --> 01:46:41,795
Speaker 5:  moved out to Chicago, we were in the bar every night and my friends and I

1726
01:46:42,055 --> 01:46:45,995
Speaker 5:  had those like Cannon Power shot elfs and they only worked

1727
01:46:45,995 --> 01:46:48,595
Speaker 5:  with flash in the bar. Oh yeah. Like they unusable they did not have low

1728
01:46:48,595 --> 01:46:51,605
Speaker 5:  light capabilities. Yeah. And those flashes are really harsh and really direct

1729
01:46:51,605 --> 01:46:55,525
Speaker 5:  and really cold. And we would always hold our Miller Light bottles in front

1730
01:46:55,525 --> 01:46:59,165
Speaker 5:  of the flash and shoot through those. 'cause they would both diffuse the

1731
01:46:59,165 --> 01:47:02,205
Speaker 5:  flash and then t tint them like Miller Lights brown, you know, that's pretty

1732
01:47:02,205 --> 01:47:05,445
Speaker 5:  good. And then people would, we were like, oh my God, what if we use a Heineken

1733
01:47:05,445 --> 01:47:08,245
Speaker 5:  bottle? Like what? And they're like, we're like, we should sell filters for

1734
01:47:08,245 --> 01:47:10,965
Speaker 5:  flat. And this idea died like the iPhone came out the next day and we're

1735
01:47:10,965 --> 01:47:14,845
Speaker 5:  like, well that's over. But that's how we solved the problem back in the

1736
01:47:14,845 --> 01:47:17,565
Speaker 5:  day. We just held the beer bottles in front of the camera flashes. I have

1737
01:47:17,565 --> 01:47:21,485
Speaker 5:  a lot of very weird photos taken that way from about like 2004

1738
01:47:21,505 --> 01:47:22,365
Speaker 5:  to 2007.

1739
01:47:23,085 --> 01:47:23,685
Speaker 6:  I love this for you.

1740
01:47:24,145 --> 01:47:27,805
Speaker 5:  It was great. Anyway, the the, the mystery is solved and the mystery is,

1741
01:47:28,035 --> 01:47:31,125
Speaker 5:  it's just the one, like, it just became the one. It's just the thing that's

1742
01:47:31,125 --> 01:47:34,765
Speaker 5:  popular and the thing specifically popular about It is the flesh,

1743
01:47:34,935 --> 01:47:35,285
Speaker 5:  right?

1744
01:47:35,595 --> 01:47:39,485
Speaker 6:  Yeah. It is like the, the virality has fully taken hold on that

1745
01:47:39,485 --> 01:47:42,605
Speaker 6:  thing. And it's like, it can happen with anything. It can happen with a weird

1746
01:47:42,605 --> 01:47:46,245
Speaker 6:  Fleetwood Mac song with a guy drinking cranberry juice and it can happen

1747
01:47:46,245 --> 01:47:50,165
Speaker 6:  with 5-year-old cameras like no one knows. And it,

1748
01:47:50,185 --> 01:47:51,885
Speaker 6:  it can literally happen to anything at any time.

1749
01:47:52,065 --> 01:47:55,995
Speaker 5:  Do not turn on the flash on your smartphone. No, it's not as good.

1750
01:47:57,525 --> 01:47:58,885
Speaker 5:  I just, I need to tell you this. Do

1751
01:47:58,885 --> 01:48:01,045
Speaker 6:  You think we can make the phrase, it's not as good eating the flash happen

1752
01:48:01,395 --> 01:48:04,565
Speaker 6:  when you pop up the flash, you're heating the flash? No. Do you think we

1753
01:48:04,565 --> 01:48:07,485
Speaker 5:  Can do that? Unless you ripped the flash off the camera and like threw it

1754
01:48:07,485 --> 01:48:10,885
Speaker 5:  into another room. Like no, that's not, that's not what that word means,

1755
01:48:10,945 --> 01:48:13,085
Speaker 6:  Bro. I'm gonna get a picture. Just let me y the flash real quick. I feel

1756
01:48:13,085 --> 01:48:14,005
Speaker 6:  like we can make this happen. Is

1757
01:48:14,045 --> 01:48:16,365
Speaker 5:  Yeee gonna be gonna make this happen? Is ye gonna be in the title of this

1758
01:48:16,365 --> 01:48:18,805
Speaker 5:  episode? Can't do this. We, we can't do this. We, it's going to be, I'm,

1759
01:48:18,945 --> 01:48:22,005
Speaker 5:  we can't keep saying Y is already old science. It's like 5-year-old saying

1760
01:48:22,005 --> 01:48:24,965
Speaker 5:  already and now we're just talking about like a bunch of old dudes like eat

1761
01:48:24,965 --> 01:48:28,525
Speaker 5:  this is what I'm saying. How about Yee the monopoly?

1762
01:48:28,585 --> 01:48:31,685
Speaker 5:  That's the new title of the verse Cats. Alright, we'll accept ye the monopoly.

1763
01:48:31,685 --> 01:48:32,925
Speaker 5:  Do you have one more pallet cleanser David?

1764
01:48:33,915 --> 01:48:37,645
Speaker 6:  Yeah. Should we talk just for a second about Phil Spencer saying Microsoft

1765
01:48:37,645 --> 01:48:41,525
Speaker 6:  really wants to support the switch to Yeah. Which a bunch of gamers

1766
01:48:41,915 --> 01:48:45,805
Speaker 6:  that I know and talked to found a mix of very exciting and sort of

1767
01:48:45,825 --> 01:48:49,805
Speaker 6:  odd. Like basically what he said is, you know, Microsoft's whole

1768
01:48:49,805 --> 01:48:53,605
Speaker 6:  plan is they wanna have Xbox stuff everywhere including on the Switch

1769
01:48:53,605 --> 01:48:55,565
Speaker 6:  too, right? And they've like, they've, they're launching these games for

1770
01:48:55,565 --> 01:48:59,525
Speaker 6:  the, the PS five. I think Indiana Jones comes out like today

1771
01:48:59,585 --> 01:49:03,205
Speaker 6:  as you're hearing this on the PS five, which would be very exciting for some

1772
01:49:03,205 --> 01:49:07,005
Speaker 6:  people. But he said, he was like, we want to have our franchises, our

1773
01:49:07,005 --> 01:49:10,965
Speaker 6:  games on the switch to also seems

1774
01:49:10,965 --> 01:49:14,525
Speaker 6:  like great news, lots of gamers are like sick. This is that one of the reasons

1775
01:49:14,525 --> 01:49:17,645
Speaker 6:  people don't get things like the switch to is 'cause it can't play some of

1776
01:49:17,725 --> 01:49:21,445
Speaker 6:  those games. So the idea that it might, it's very exciting but then there

1777
01:49:21,445 --> 01:49:25,325
Speaker 6:  was an interesting backlash to it of people being like, Microsoft is

1778
01:49:25,325 --> 01:49:29,285
Speaker 6:  just going, you know, squeeze Nintendo and ruin this beautiful console for

1779
01:49:29,285 --> 01:49:33,005
Speaker 6:  capitalism. And I just think it's kind of funny like the, the way

1780
01:49:33,005 --> 01:49:36,885
Speaker 6:  everybody talks about all of the gaming industry that isn't Nintendo

1781
01:49:37,185 --> 01:49:40,805
Speaker 6:  is increasingly sort of ruthless and brutal and

1782
01:49:41,185 --> 01:49:44,445
Speaker 6:  not beautiful and artistic. And then Nintendo is this just like beautiful

1783
01:49:44,445 --> 01:49:48,365
Speaker 6:  flower child over here. Yeah. That we cannot allow to be ruined by

1784
01:49:48,365 --> 01:49:49,125
Speaker 6:  these other companies.

1785
01:49:49,855 --> 01:49:52,705
Speaker 5:  Well I mean Nintendo is the only company that can look at something like

1786
01:49:53,105 --> 01:49:54,825
Speaker 5:  Zelda and be like, yeah, it's done.

1787
01:49:56,395 --> 01:49:58,905
Speaker 5:  We're done. The story's over, we have no more story here. We're gonna start

1788
01:49:58,905 --> 01:50:02,745
Speaker 5:  a new story over here. Like very few companies can look at

1789
01:50:03,205 --> 01:50:06,745
Speaker 5:  Breath of the Wild and be like, yep, this version of this has come to its

1790
01:50:06,745 --> 01:50:09,825
Speaker 5:  conclusion. Most companies are like, have you heard of DLC? There's more

1791
01:50:09,825 --> 01:50:13,705
Speaker 5:  of it. Right? And then I think for Microsoft in particular,

1792
01:50:13,705 --> 01:50:17,455
Speaker 5:  they're, they lost this console generation, I dunno what they're gonna do

1793
01:50:17,455 --> 01:50:18,175
Speaker 5:  with the next one.

1794
01:50:19,815 --> 01:50:22,705
Speaker 5:  They bought all these studios, we're gonna monetize the games of the advertising.

1795
01:50:23,055 --> 01:50:26,665
Speaker 5:  Yeah. So we're gonna put the games everywhere so we can get multiplayer.

1796
01:50:26,665 --> 01:50:29,185
Speaker 5:  It's kinda like network effects. So if you want a big multiplayer games full

1797
01:50:29,185 --> 01:50:32,225
Speaker 5:  of advertising Yeah. You just need a lot of players. Yeah. So of course you're

1798
01:50:32,225 --> 01:50:35,145
Speaker 5:  gonna be on the switch. And I think that's the thing gamers in particular

1799
01:50:35,145 --> 01:50:38,545
Speaker 5:  are responding to is like every game is becoming some like open world

1800
01:50:38,945 --> 01:50:42,915
Speaker 5:  advertising paradise full of things to buy. Yep. And

1801
01:50:43,075 --> 01:50:46,985
Speaker 5:  Nintendo games are like, would you like to have fun? Yeah. And

1802
01:50:46,985 --> 01:50:49,665
Speaker 5:  that's the end of that. Like Yes, yes.

1803
01:50:49,705 --> 01:50:53,265
Speaker 6:  I would, I I will play tennis with Bowser for five hours. Yes, thank

1804
01:50:53,265 --> 01:50:56,105
Speaker 5:  You. I think that's why people, we've been playing a lot of Astro Bot

1805
01:50:56,855 --> 01:50:57,145
Speaker 6:  Nice.

1806
01:50:57,615 --> 01:51:01,585
Speaker 5:  Like that game's great. I don't feel like someone's gonna a ask us for

1807
01:51:01,585 --> 01:51:05,545
Speaker 5:  money while we're playing. Like there's very few of

1808
01:51:05,545 --> 01:51:08,265
Speaker 5:  those games left and when they come out people love them. But I think, I

1809
01:51:08,265 --> 01:51:11,825
Speaker 5:  think Microsoft has to put advertising on the Nintendo Switch. I think that's

1810
01:51:11,825 --> 01:51:12,425
Speaker 5:  what people reacted

1811
01:51:12,425 --> 01:51:15,665
Speaker 6:  To. Yeah. The other funny switch thing that happened this week was Switch.

1812
01:51:15,665 --> 01:51:18,745
Speaker 6:  Nintendo had another event just to show off more of the new Mario Kart game,

1813
01:51:18,745 --> 01:51:22,665
Speaker 6:  which looks sick. Like I'm so excited about that game. And

1814
01:51:22,965 --> 01:51:26,225
Speaker 6:  the whole chat in the whole thing was just about the price.

1815
01:51:27,025 --> 01:51:30,825
Speaker 6:  A bunch of people were like a like, tell us what the actual

1816
01:51:30,825 --> 01:51:34,225
Speaker 6:  price is. Why won't you let us buy this? Lower the price. How dare you? And

1817
01:51:34,225 --> 01:51:37,985
Speaker 6:  then a bunch of people being like, ah, games are expensive and it just,

1818
01:51:38,405 --> 01:51:41,505
Speaker 6:  all anyone cares about at this point is like, what is this thing actually

1819
01:51:41,505 --> 01:51:45,025
Speaker 6:  gonna cost and when are you gonna let me buy it? And anytime Nintendo does

1820
01:51:45,185 --> 01:51:48,465
Speaker 6:  anything else, that's the only question left. And that is also the question

1821
01:51:48,545 --> 01:51:51,945
Speaker 6:  I have because the pre-order date has come and gone. They have not even announced

1822
01:51:51,945 --> 01:51:55,895
Speaker 6:  when it's going to happen. I would like to throw my money at a switch to

1823
01:51:55,895 --> 01:51:56,095
Speaker 6:  please,

1824
01:51:56,325 --> 01:51:59,415
Speaker 7:  It's gonna end up costing like $1,500 to buy this much too.

1825
01:52:00,395 --> 01:52:01,015
Speaker 5:  So honestly,

1826
01:52:01,365 --> 01:52:04,455
Speaker 6:  Like you can either wait a year and get it at normal price or buy it now

1827
01:52:04,455 --> 01:52:06,855
Speaker 6:  for a thousand dollars. Like it, it could happen.

1828
01:52:07,845 --> 01:52:11,565
Speaker 5:  I mean there's all the, you know, high-minded like Trump really

1829
01:52:11,565 --> 01:52:14,325
Speaker 5:  began with Gamergate and to have it come full circle to you can't buy an

1830
01:52:14,325 --> 01:52:18,165
Speaker 5:  Nintendo is very funny. I'm just gonna, I'm, I just needed to say it on

1831
01:52:18,165 --> 01:52:22,085
Speaker 5:  our show one time. I, I think Nintendo will, will figure out a

1832
01:52:22,085 --> 01:52:24,725
Speaker 5:  way to get this thing on sale. I I, I actually really,

1833
01:52:26,105 --> 01:52:30,025
Speaker 5:  I talked to the CEO of a very large company that makes a

1834
01:52:30,025 --> 01:52:32,905
Speaker 5:  lot of stuff this week and he was like, I don't think anyone understands

1835
01:52:32,905 --> 01:52:36,705
Speaker 5:  we're all gonna solve it with smuggling. He was like dead serious.

1836
01:52:37,295 --> 01:52:40,945
Speaker 7:  Just like Tim Cook, like flying planes like out of like Vietnam.

1837
01:52:40,975 --> 01:52:44,385
Speaker 5:  Yeah. Like we're gonna, all the parts will, we'll like all the parts will

1838
01:52:44,385 --> 01:52:48,325
Speaker 5:  go to Mexico for final assembly And that final assembly is like

1839
01:52:48,405 --> 01:52:51,725
Speaker 5:  a sticker that says made in Mexico and then that will come in through that

1840
01:52:51,725 --> 01:52:55,365
Speaker 5:  tariff regime, like the amount of that that is going to start happening.

1841
01:52:55,665 --> 01:52:59,565
Speaker 5:  The thing specifically that was described to me is you have

1842
01:52:59,565 --> 01:53:02,365
Speaker 5:  all these export controls in these various countries that like you have to

1843
01:53:02,365 --> 01:53:05,605
Speaker 5:  check the list and he is like, yeah we just set up 15

1844
01:53:06,135 --> 01:53:09,325
Speaker 5:  shell companies so that it completely obscures where things are going.

1845
01:53:09,945 --> 01:53:13,125
Speaker 5:  All those people get to make money but that money is less than the tariffs.

1846
01:53:13,585 --> 01:53:16,165
Speaker 5:  And I was like, is it smuggling? And he was like, yeah, it's smuggling. Like

1847
01:53:16,385 --> 01:53:18,485
Speaker 5:  it was just very direct. So

1848
01:53:18,505 --> 01:53:21,285
Speaker 16:  Do we pay tariffs or do we pay bribes? Like it Yeah, he

1849
01:53:21,285 --> 01:53:24,445
Speaker 5:  Was like, he was very straightforward. It was like, yeah, we're justing smuggling.

1850
01:53:25,305 --> 01:53:28,725
Speaker 5:  So I'm excited for Nintendo to figure out smuggling. Basically it's the next

1851
01:53:28,725 --> 01:53:32,645
Speaker 5:  great switch. Two game Smuggle A switch, two Yeet the switch

1852
01:53:32,705 --> 01:53:35,965
Speaker 5:  two. I would play that game. We're done. That's it. That's the B test. Everybody

1853
01:53:36,635 --> 01:53:36,925
Speaker 3:  Rock

1854
01:53:36,925 --> 01:53:37,245
Speaker 5:  And roll.

1855
01:53:43,025 --> 01:53:46,245
Speaker 3:  And that's it for The Vergecast this week. And hey, we'd love to hear from

1856
01:53:46,245 --> 01:53:49,845
Speaker 3:  you. Give us a call at eight six six VERGE one one.

1857
01:53:50,025 --> 01:53:53,525
Speaker 3:  The Vergecast is a production of The Verge and the Vox Media podcast network.

1858
01:53:53,825 --> 01:53:57,645
Speaker 3:  Our show is produced by Will Por, Eric Gomez and Brandon Keefer. And

1859
01:53:57,645 --> 01:53:59,125
Speaker 3:  that's it. We'll see you next week.

