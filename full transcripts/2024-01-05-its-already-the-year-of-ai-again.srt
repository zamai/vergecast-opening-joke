1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 104a71c6-1815-482a-9b4d-ae00be00bf5e
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/285115196806288049/-7351152687757378521/s93290-US-5407s-1704469650.mp3
Description: The Verge's Nilay Patel, David Pierce, and Alex Cranz kick off the new year with a preview of what we're excited to see at CES 2024 next week, but not before a brief discussion on copyright, the open web, and the first movements of a battle between The New York Times and OpenAI.

2
00:00:45,945 --> 00:00:49,895
Speaker 3:  Hello and welcome to Our Chest, the flagship podcast of Quantum Technology.

3
00:00:50,555 --> 00:00:50,775
Speaker 4:  Ooh,

4
00:00:51,155 --> 00:00:55,135
Speaker 3:  You ready? It's, we're like leading up into the CES hype. We gotta

5
00:00:55,135 --> 00:00:58,655
Speaker 3:  start making up buzzwords left and right, the AI

6
00:00:58,655 --> 00:01:02,615
Speaker 3:  powered podcast of Quantum Dots. Now with more ai,

7
00:01:03,195 --> 00:01:04,535
Speaker 3:  please stop us. Best Buy.

8
00:01:06,475 --> 00:01:09,735
Speaker 3:  I'm your friend, NELI. I'm, it's been a, it's been a a minute. We, the last

9
00:01:09,735 --> 00:01:12,775
Speaker 3:  time we spoke to you was last year. Welcome back. It's good. See you again.

10
00:01:12,845 --> 00:01:13,775
Speaker 3:  Alex Transit is here.

11
00:01:14,255 --> 00:01:17,775
Speaker 4:  I am here in my mom's house. That's why I have a creepy

12
00:01:17,775 --> 00:01:18,295
Speaker 4:  background.

13
00:01:19,795 --> 00:01:22,055
Speaker 3:  You do have a real mom's house vibe? Yes. Yes.

14
00:01:22,805 --> 00:01:26,655
Speaker 4:  Flowers. Graduation photo of someone guitar

15
00:01:26,685 --> 00:01:28,895
Speaker 4:  from my brother's like guitar years. You

16
00:01:28,895 --> 00:01:30,575
Speaker 3:  Got the little posable figurine guy.

17
00:01:30,665 --> 00:01:32,535
Speaker 4:  Dunno what that's about, but I got it.

18
00:01:33,515 --> 00:01:34,895
Speaker 3:  The dress making, I believe

19
00:01:35,995 --> 00:01:36,895
Speaker 4:  That's how they do it.

20
00:01:37,145 --> 00:01:38,215
Speaker 3:  David. Pierce is here.

21
00:01:38,365 --> 00:01:42,295
Speaker 5:  What is the age at which you get to have like a chair that is your

22
00:01:42,295 --> 00:01:46,255
Speaker 5:  chair? I'd like to be that person. Like Alex. You're in a

23
00:01:46,255 --> 00:01:48,935
Speaker 5:  chair that like be like is a person's chair. Yeah. This is, you know what

24
00:01:48,935 --> 00:01:51,575
Speaker 5:  I mean? Yeah. I think's like that's not your chair. That's someone's chair.

25
00:01:51,675 --> 00:01:53,135
Speaker 5:  And I would like a chair. That is mine.

26
00:01:53,635 --> 00:01:57,535
Speaker 3:  You're in your own home. At any moment you can acquire a chair.

27
00:01:58,255 --> 00:02:01,375
Speaker 5:  I know, but it's like, it just feels wrong. Like if I went and tried to buy

28
00:02:01,375 --> 00:02:04,495
Speaker 5:  a Lazboy right now, they'd be like, get outta here. You're not ready. You

29
00:02:04,495 --> 00:02:05,255
Speaker 5:  haven't earned this yet.

30
00:02:05,955 --> 00:02:08,935
Speaker 4:  That's what you know when your wife is like, it's okay. Get the Lazboy. You'd

31
00:02:08,935 --> 00:02:10,295
Speaker 4:  be like, I hit it. I'm at that age.

32
00:02:11,495 --> 00:02:14,335
Speaker 3:  If that happened, I'd be like, this relationship is like she's, there's someone

33
00:02:14,335 --> 00:02:18,295
Speaker 3:  else. That's how I would know if she was like, I've given up on you. You

34
00:02:18,295 --> 00:02:22,135
Speaker 3:  may have a lazy boy. I, I would know some other information

35
00:02:22,325 --> 00:02:25,695
Speaker 3:  that I, I wouldn't once to know. Anyway, there's a lot of news. It's been

36
00:02:25,815 --> 00:02:29,415
Speaker 3:  a, it's a very slow period of sort of iterative

37
00:02:29,475 --> 00:02:32,015
Speaker 3:  things, but some things happened before the break that we should talk about.

38
00:02:32,195 --> 00:02:36,135
Speaker 3:  And then we are headed into CES and the trickle of CES

39
00:02:36,135 --> 00:02:39,935
Speaker 3:  News is, you can see that we're gonna have a

40
00:02:39,935 --> 00:02:43,575
Speaker 3:  pretty noisy CES in Vegas. There might not be a lot of

41
00:02:44,515 --> 00:02:48,065
Speaker 3:  stuff, but there's gonna be a lot of news, if that makes any sense.

42
00:02:48,825 --> 00:02:49,115
Speaker 4:  Yeah.

43
00:02:49,785 --> 00:02:53,755
Speaker 3:  Like the trends are converging on CES for just

44
00:02:53,815 --> 00:02:56,675
Speaker 3:  for example, I I think we're gonna hear a lot about Windows laptops with

45
00:02:56,675 --> 00:03:00,085
Speaker 3:  various AI features in them. Yeah. Based on the fact that Microsoft just

46
00:03:00,085 --> 00:03:03,045
Speaker 3:  announced an AI button on Windows keyboards is coming.

47
00:03:03,755 --> 00:03:06,655
Speaker 4:  Oh it's, it's here. We we're gonna talk about that when I talk about the

48
00:03:06,655 --> 00:03:08,055
Speaker 4:  Dell XPS laptops co button.

49
00:03:08,055 --> 00:03:11,855
Speaker 5:  Yeah. It's gonna be a very CES e CES. I think like I think

50
00:03:11,855 --> 00:03:15,815
Speaker 5:  we've, we've spent the last don don't know decade watching it become

51
00:03:15,845 --> 00:03:19,735
Speaker 5:  kind of less and less CES e in the sense

52
00:03:19,735 --> 00:03:23,655
Speaker 5:  that it either was teeny tiny upgrades to mostly

53
00:03:23,795 --> 00:03:27,735
Speaker 5:  mature products or like weird wacky

54
00:03:28,455 --> 00:03:31,975
Speaker 5:  nonsense from Europe that no one was ever gonna buy, but seemed potentially

55
00:03:32,295 --> 00:03:35,015
Speaker 5:  interesting. And now we're back in a place where there's like

56
00:03:36,155 --> 00:03:39,935
Speaker 5:  new kinds of gadgets, new ideas about gadgets, new stuff. And

57
00:03:39,935 --> 00:03:43,735
Speaker 5:  there's like somewhere in there is stuff people are actually gonna

58
00:03:43,755 --> 00:03:46,655
Speaker 5:  buy. Yeah. And it feels like CES has not been about things that people might

59
00:03:46,855 --> 00:03:49,655
Speaker 5:  actually buy in a while. And I'm kind of excited about it

60
00:03:49,955 --> 00:03:52,975
Speaker 3:  All, right. I'm gonna make myself sound like an ancient wizard. Is it like,

61
00:03:53,005 --> 00:03:54,575
Speaker 3:  like a man with a chair basically?

62
00:03:54,955 --> 00:03:55,175
Speaker 5:  Yes.

63
00:03:55,895 --> 00:03:59,535
Speaker 3:  I started writing about gadgets before, before the iPhone existed.

64
00:04:00,325 --> 00:04:02,135
Speaker 5:  Like 1958.

65
00:04:02,285 --> 00:04:02,575
Speaker 3:  Yeah.

66
00:04:03,085 --> 00:04:05,095
Speaker 4:  Just went to Neli Ageing. Yeah.

67
00:04:06,375 --> 00:04:10,175
Speaker 3:  I started writing about those big mechanical typewriters, you know. No, but

68
00:04:10,275 --> 00:04:14,215
Speaker 3:  you know, sort of like 2006, 2007 there were smartphones but we parked them

69
00:04:14,315 --> 00:04:18,175
Speaker 3:  on End Gadget Mobile because our gadget audience on End

70
00:04:18,175 --> 00:04:21,055
Speaker 3:  Gadget was like, what are these weird European smartphones? Get them out

71
00:04:21,055 --> 00:04:21,255
Speaker 3:  of our face.

72
00:04:21,255 --> 00:04:22,455
Speaker 5:  They were like, netbooks are nothing

73
00:04:22,925 --> 00:04:26,015
Speaker 3:  This, that's where we were. Yeah. And so CES every year was

74
00:04:26,445 --> 00:04:30,135
Speaker 3:  basically how gadget stores would get

75
00:04:30,135 --> 00:04:33,975
Speaker 3:  stocked like this. This is where the buyers from Best Buy would like

76
00:04:34,355 --> 00:04:37,895
Speaker 3:  go and like figure out what would be in their store for the next year. And

77
00:04:37,965 --> 00:04:41,455
Speaker 3:  they were just full of gadgets like AV

78
00:04:41,815 --> 00:04:45,735
Speaker 3:  receivers and weird TV I, lots and lots of weird TV

79
00:04:45,785 --> 00:04:48,895
Speaker 3:  ideas. An infinite amount of weird TV ideas.

80
00:04:50,595 --> 00:04:54,455
Speaker 3:  And then all that stuff converged into phones. And even TVs became

81
00:04:54,455 --> 00:04:57,335
Speaker 3:  basically Android tablets that you hang on the wall. Like if you think about

82
00:04:57,335 --> 00:05:00,415
Speaker 3:  a modern television, they've got an arm processor, they're running some

83
00:05:01,175 --> 00:05:04,975
Speaker 3:  Linux variant very often. Android sometimes ties in like

84
00:05:05,285 --> 00:05:08,175
Speaker 3:  they're just big tablets. You hang on the wall. So all the stuff converged

85
00:05:08,175 --> 00:05:11,935
Speaker 3:  into computers and CS got boring because almost

86
00:05:11,935 --> 00:05:15,655
Speaker 3:  every product involved you having to believe that Panasonic

87
00:05:15,755 --> 00:05:16,935
Speaker 3:  was good at making software.

88
00:05:18,965 --> 00:05:20,975
Speaker 3:  Yeah. It's like don, don't dunno about that.

89
00:05:21,595 --> 00:05:23,095
Speaker 4:  So what a Panasonic believe that

90
00:05:23,965 --> 00:05:26,895
Speaker 3:  Many of these companies fully believed it or they, or like remember there

91
00:05:26,895 --> 00:05:29,615
Speaker 3:  was a year that like Sam, the big announcement CSS was that Samsung bought

92
00:05:29,615 --> 00:05:33,175
Speaker 3:  smart things and they're gonna like take over home automation. And it's like,

93
00:05:33,475 --> 00:05:37,455
Speaker 3:  oh, we all really believe, oops. Like I don Dunno if you've

94
00:05:37,455 --> 00:05:38,415
Speaker 3:  used smart things lately.

95
00:05:40,495 --> 00:05:44,295
Speaker 3:  I have it on my frame tv. It's a weird, weird product all the way around.

96
00:05:44,595 --> 00:05:48,575
Speaker 3:  Anyway, the point of this is we're just back at a place where there's

97
00:05:48,575 --> 00:05:52,455
Speaker 3:  a little bit of what you might call it de convergence happening. And

98
00:05:52,455 --> 00:05:54,735
Speaker 3:  I say this every year about css 'cause they're always catch. But you can

99
00:05:54,735 --> 00:05:58,725
Speaker 3:  just see that there's interest in things outside of the phone. And AI

100
00:05:58,745 --> 00:06:02,165
Speaker 3:  is like the thing that is not totally

101
00:06:02,525 --> 00:06:06,375
Speaker 3:  dependent on Apple letting it exist. So it's just like happening in more

102
00:06:06,375 --> 00:06:08,215
Speaker 3:  and more places. And I think that's just like fundamentally interesting.

103
00:06:09,355 --> 00:06:12,695
Speaker 3:  but it, and but for the most part CSS is like where sales

104
00:06:12,955 --> 00:06:16,845
Speaker 3:  people go to do sales stuff. Yeah. And where tech

105
00:06:16,845 --> 00:06:19,925
Speaker 3:  reporters go to be like, what's happening here? Yeah. And it's like maybe

106
00:06:19,925 --> 00:06:23,805
Speaker 3:  this year after several pandemic years and with the emergence of ai,

107
00:06:24,615 --> 00:06:27,805
Speaker 3:  maybe this year the balance will shift a little bit back towards interesting

108
00:06:27,805 --> 00:06:29,925
Speaker 3:  things. We, we, we will have to see. It's

109
00:06:29,925 --> 00:06:33,725
Speaker 5:  At least weird stuff from companies with

110
00:06:34,605 --> 00:06:38,485
Speaker 5:  resources to make that weird stuff and sell it to you. Right. I feel

111
00:06:38,485 --> 00:06:41,125
Speaker 5:  like Samsung for so long has just

112
00:06:42,275 --> 00:06:45,405
Speaker 5:  made slightly better versions of all of its stuff and then been like, look

113
00:06:45,405 --> 00:06:49,245
Speaker 5:  at this refrigerator. Yeah. That's where our innovation lies. And

114
00:06:50,025 --> 00:06:54,005
Speaker 5:  now we're coming back to, and I think this is a trend of this whole year

115
00:06:54,865 --> 00:06:57,365
Speaker 5:  and it, I mean it goes to your point about the co-pilot button on Windows

116
00:06:57,685 --> 00:07:01,525
Speaker 5:  computers. Like we are coming back to these incredibly mature devices

117
00:07:01,955 --> 00:07:05,725
Speaker 5:  that I think are gonna start to change faster and in bigger ways than they

118
00:07:05,725 --> 00:07:09,125
Speaker 5:  have in a while, largely because of ai. But everybody is kind of like

119
00:07:09,745 --> 00:07:13,645
Speaker 5:  ground up re-imagining all of their devices, including the ones

120
00:07:13,645 --> 00:07:17,045
Speaker 5:  that haven't been touched in a while for this next phase. It's gonna get

121
00:07:17,045 --> 00:07:20,525
Speaker 5:  weird and a lot of it's gonna get much worse. But just from a pure, like

122
00:07:20,605 --> 00:07:22,965
Speaker 5:  I like covering gadgets perspective. It's gonna be so fun.

123
00:07:23,435 --> 00:07:26,965
Speaker 3:  Yeah. I'm, I'm, I haven't gone in years. I'm excited to go and

124
00:07:27,275 --> 00:07:30,605
Speaker 3:  have a conversation about something other than whether a huge

125
00:07:30,615 --> 00:07:33,965
Speaker 3:  dependency on the smartphone will kill whatever product I'm looking at.

126
00:07:34,035 --> 00:07:34,525
Speaker 5:  Totally.

127
00:07:34,555 --> 00:07:37,605
Speaker 3:  Yeah. Which is basically what we've been doing for years. Yeah. Before we

128
00:07:37,605 --> 00:07:40,565
Speaker 3:  get into that, which we will get into, we should talk about the big news

129
00:07:40,715 --> 00:07:44,565
Speaker 3:  that happened while we were on break that is deeply related to whether

130
00:07:44,585 --> 00:07:47,685
Speaker 3:  the AI industry can continue the way it is currently going.

131
00:07:48,825 --> 00:07:51,805
Speaker 3:  The New York Times has sued OpenAI for copyright

132
00:07:53,305 --> 00:07:56,605
Speaker 3:  infringement. They are far from the first to

133
00:07:56,905 --> 00:08:00,085
Speaker 3:  Sue OpenAI for copyright infringement. Sarah Silverman, other famous authors

134
00:08:00,085 --> 00:08:03,845
Speaker 3:  have sued OpenAI. George R. Martin in a different case has sued

135
00:08:03,845 --> 00:08:07,405
Speaker 3:  OpenAI. But in classic times fashion, now that

136
00:08:08,025 --> 00:08:11,685
Speaker 3:  they have sued OpenAI, they're covering it as though this is

137
00:08:13,585 --> 00:08:15,285
Speaker 3:  the watershed moment as though this is the one that's stopping our brain.

138
00:08:15,285 --> 00:08:19,205
Speaker 3:  They're like the, a pivotal moment for AI has arrived now that we have

139
00:08:19,355 --> 00:08:23,155
Speaker 3:  sued, have sued OpenAI. You can, you can

140
00:08:23,155 --> 00:08:25,355
Speaker 3:  believe about that. What you will. I think it's, it's

141
00:08:25,495 --> 00:08:29,155
Speaker 5:  In reality. Aren't all of these cases destined to kind of merge together

142
00:08:29,425 --> 00:08:32,555
Speaker 5:  into one the people versus AI kind of case?

143
00:08:33,065 --> 00:08:36,835
Speaker 3:  Yeah. So they, I think it's the Sarah Silverman case filed in the same

144
00:08:36,835 --> 00:08:39,875
Speaker 3:  court. They've assigned the Times case to the same judge because they've

145
00:08:39,875 --> 00:08:43,675
Speaker 3:  been deemed related. A lot of the fundamental legal questions are

146
00:08:43,675 --> 00:08:47,515
Speaker 3:  just the same here. So I, you should go read the Times' complaint.

147
00:08:47,515 --> 00:08:51,475
Speaker 3:  It is well written. Very often we point this out, but a lot of

148
00:08:51,475 --> 00:08:53,955
Speaker 3:  these filings are written for the public to read.

149
00:08:55,265 --> 00:08:59,045
Speaker 3:  And their relationship to the actual questions that are determined in the

150
00:08:59,045 --> 00:09:03,005
Speaker 3:  court are potentially quite fuzzy. Like this,

151
00:09:03,075 --> 00:09:06,565
Speaker 3:  this thing is a, is a, a piece of marketing. Yeah. And like that's what a

152
00:09:06,565 --> 00:09:10,245
Speaker 3:  good complaint is supposed to be. But that means also it is very readable.

153
00:09:10,245 --> 00:09:14,165
Speaker 3:  It is not like a technical document or a technical legal argument. It's just

154
00:09:14,285 --> 00:09:18,245
Speaker 3:  a list of problems. For example, you can just ask cha a

155
00:09:18,245 --> 00:09:22,165
Speaker 3:  BT to tell you to recite a Times article at you

156
00:09:22,685 --> 00:09:26,525
Speaker 3:  and it will just do it. Which implies a number of things.

157
00:09:27,215 --> 00:09:31,205
Speaker 3:  First. That OpenAI has a database of New York Times

158
00:09:31,205 --> 00:09:34,925
Speaker 3:  articles that it is made, which you need permission to

159
00:09:35,075 --> 00:09:39,045
Speaker 3:  make. Like that. That's just a very straightforward, did you have permission

160
00:09:39,045 --> 00:09:41,045
Speaker 3:  to make all of these copies of Times articles?

161
00:09:41,155 --> 00:09:44,765
Speaker 5:  Okay. But wait, can we, can we pause on that immediately? Yeah. Because that

162
00:09:44,765 --> 00:09:48,525
Speaker 5:  is like the, the thing you have beaten into my head over the many years that

163
00:09:48,525 --> 00:09:52,085
Speaker 5:  I've known you Eli, is copyright laws about copies. Right. Like fundamentally

164
00:09:52,085 --> 00:09:52,845
Speaker 5:  it is about things that

165
00:09:52,945 --> 00:09:55,045
Speaker 3:  One believes me get copy. But you do. I do. I'm very happy that you,

166
00:09:55,235 --> 00:09:57,925
Speaker 5:  I've learned this. I've known you a long time and I have finally learned

167
00:09:57,925 --> 00:10:01,485
Speaker 5:  this and a lot of the talking that I've seen about

168
00:10:01,875 --> 00:10:05,765
Speaker 5:  this case, which like fundamentally the Times makes a lot of allegations

169
00:10:05,765 --> 00:10:07,685
Speaker 5:  and we should talk about them. 'cause I think they're really interesting

170
00:10:07,685 --> 00:10:11,325
Speaker 5:  in ways that some of the other cases have not been as

171
00:10:11,445 --> 00:10:14,325
Speaker 5:  straightforward about that thing you're describing where like you can tell

172
00:10:14,875 --> 00:10:18,605
Speaker 5:  that chat GPT knows New York Times articles because it will tell you about

173
00:10:18,945 --> 00:10:22,805
Speaker 5:  them. But I think what I have not figured out and what

174
00:10:22,805 --> 00:10:24,845
Speaker 5:  everybody has been sort of talking in circles about in this

175
00:10:26,505 --> 00:10:30,405
Speaker 5:  is, is this actually a copyright thing at all? Like

176
00:10:30,405 --> 00:10:34,285
Speaker 5:  is it against the law for OpenAI and Chat GPT

177
00:10:34,285 --> 00:10:38,165
Speaker 5:  to know the contents of a New York Times article? I've read a

178
00:10:38,165 --> 00:10:41,725
Speaker 5:  New York Times article. If I tell you about a New York Times article, is

179
00:10:41,725 --> 00:10:45,365
Speaker 5:  that copyright infringement? Is that even remotely the same thing? Like,

180
00:10:45,615 --> 00:10:49,365
Speaker 5:  just like first principles? Yeah. Can you just make sense of this for me?

181
00:10:49,365 --> 00:10:52,565
Speaker 5:  'cause I feel like I've read every direction of this and I have no idea where

182
00:10:52,405 --> 00:10:52,565
Speaker 5:  to land.

183
00:10:52,835 --> 00:10:56,365
Speaker 3:  Okay. So the most important first principle is that no one knows how fair

184
00:10:56,365 --> 00:10:59,885
Speaker 3:  use cases will get decided. Perfect. Ever. Like first

185
00:10:59,915 --> 00:11:01,165
Speaker 5:  Principle is blurred lines.

186
00:11:01,505 --> 00:11:05,245
Speaker 3:  Anyone making that argument to you is definitely

187
00:11:05,365 --> 00:11:08,725
Speaker 3:  doing it for money. Sure. You know what I mean? Like they're all coin flips.

188
00:11:08,725 --> 00:11:12,325
Speaker 3:  David mentioned blurred lines. I will just say this again. I'm at the point

189
00:11:12,325 --> 00:11:16,165
Speaker 3:  where I'm a soundboard about fair use cases and blurred lines. Like

190
00:11:16,205 --> 00:11:19,525
Speaker 3:  I, I gave this argument on CNBC and the anchors looked at me like they didn't

191
00:11:19,525 --> 00:11:22,245
Speaker 3:  know what blurred line was. And I was like, Emily Rakowski. And they're like,

192
00:11:22,245 --> 00:11:22,485
Speaker 3:  oh yeah.

193
00:11:26,945 --> 00:11:30,925
Speaker 3:  So Blurred lines, the Robin Thick song with Pharrell Williams, Marvin Gay's

194
00:11:30,925 --> 00:11:34,365
Speaker 3:  Estate is like, Hey, that sounds like a Marvin Gaye song. And they sued Marvin

195
00:11:34,365 --> 00:11:37,925
Speaker 3:  Gaye's estate preemptively Oh, the way around to get a court. No. That way

196
00:11:37,925 --> 00:11:41,765
Speaker 3:  they pre preemptively sued Marvin Gaye to get a court to say, no,

197
00:11:41,875 --> 00:11:45,245
Speaker 3:  this isn't copyright infringement. Because they hadn't used a note. They

198
00:11:45,325 --> 00:11:48,365
Speaker 3:  hadn't used a chord, they just used like a vibe.

199
00:11:49,515 --> 00:11:52,715
Speaker 3:  I did a, a decoder episode with Charlie Harding about this that we can link

200
00:11:52,715 --> 00:11:55,925
Speaker 3:  to. It's just a vibe. Like he's a musicologist. He's like, this is just a

201
00:11:55,925 --> 00:11:59,565
Speaker 3:  vibe. And they lost the jury was like,

202
00:11:59,745 --> 00:12:03,245
Speaker 3:  no, like you Robin Thick are kind of like an

203
00:12:03,245 --> 00:12:07,205
Speaker 3:  unsympathetic defending, like this song's kinda weird.

204
00:12:07,205 --> 00:12:09,885
Speaker 3:  There's like whatever. For whatever reason they lost, they paid the money

205
00:12:10,575 --> 00:12:14,525
Speaker 3:  years later just recently, Marvin Gaye's Estate Emboldened by

206
00:12:14,525 --> 00:12:18,325
Speaker 3:  this Sues Ed Sheeran 'cause Shape of You

207
00:12:18,705 --> 00:12:22,645
Speaker 3:  has the chords of a Marvin Gaye song in it that so much so that

208
00:12:22,645 --> 00:12:26,605
Speaker 3:  he like plays them all together in concert. Like he like transitions from

209
00:12:26,605 --> 00:12:30,125
Speaker 3:  one song. And Ed Sheeran vastly more

210
00:12:30,125 --> 00:12:31,285
Speaker 3:  sympathetic defendant,

211
00:12:33,085 --> 00:12:36,905
Speaker 3:  old floppy hair is like Anna, you need colds. You know, like,

212
00:12:37,405 --> 00:12:37,905
Speaker 3:  and he wins

213
00:12:40,015 --> 00:12:43,825
Speaker 3:  just objectively, he has used more of the Marvin Gay song or

214
00:12:43,825 --> 00:12:47,025
Speaker 3:  what you might consider as the Marvin and he wins. That is a total coin flip

215
00:12:47,615 --> 00:12:51,345
Speaker 3:  just dead ahead coin flip. You do not know, and you

216
00:12:51,345 --> 00:12:54,985
Speaker 3:  shouldn't have that permissioning based on whether you think Robin thick

217
00:12:55,045 --> 00:12:58,905
Speaker 3:  is more or less sympathetic than Ed. She like that's a bad place

218
00:12:59,485 --> 00:13:00,465
Speaker 3:  Yes. To live. So

219
00:13:00,645 --> 00:13:04,025
Speaker 5:  The only approach here, like total nihilism, nobody knows anything. Nothing

220
00:13:04,025 --> 00:13:04,825
Speaker 5:  matters that,

221
00:13:04,825 --> 00:13:07,585
Speaker 3:  That's what I'm saying right now. Like I, people have asked me, what do you

222
00:13:07,585 --> 00:13:10,505
Speaker 3:  think will happen? Like what do you think should happen? And I just keep

223
00:13:10,505 --> 00:13:14,305
Speaker 3:  reminding everyone that fair use law is literal coin

224
00:13:14,315 --> 00:13:18,185
Speaker 3:  flips every time they are legally supposed to be coin

225
00:13:18,185 --> 00:13:21,945
Speaker 3:  flips. They're all supposed to be evaluated on case by case basis. So that

226
00:13:21,965 --> 00:13:24,705
Speaker 3:  one thing is not supposed to be precedent for the next thing. So even if

227
00:13:24,705 --> 00:13:27,425
Speaker 3:  you think, okay, Robin Thick won or lost,

228
00:13:28,735 --> 00:13:32,505
Speaker 3:  that doesn't give Ed Sheeran a rule to follow, which is how he ended up back

229
00:13:32,505 --> 00:13:36,445
Speaker 3:  in court and then he won. And now no one has a rule like you

230
00:13:36,445 --> 00:13:40,085
Speaker 3:  just move on to the next song and try again. Right. So this is a really weird

231
00:13:40,495 --> 00:13:43,645
Speaker 3:  murky area of the law. So that's like just the first, when you talk about

232
00:13:43,645 --> 00:13:47,605
Speaker 3:  first principles, the only, like the thing that I will just put in everyone's

233
00:13:47,605 --> 00:13:50,325
Speaker 3:  brain is that no one knows what's gonna happen. The first

234
00:13:50,325 --> 00:13:51,445
Speaker 5:  Principle is that there are no

235
00:13:51,445 --> 00:13:55,205
Speaker 3:  Principles. It's in fair use law. There is just chaos. Like

236
00:13:55,305 --> 00:13:58,765
Speaker 3:  it is, it is supposed to be chaos because times

237
00:13:58,945 --> 00:14:02,365
Speaker 3:  change. Our attitudes about remixing and copying change,

238
00:14:03,485 --> 00:14:07,445
Speaker 3:  the specifics of each use and reuse are totally different.

239
00:14:07,785 --> 00:14:11,735
Speaker 3:  And the law is sort of designed to make you fight it out like

240
00:14:11,735 --> 00:14:15,135
Speaker 3:  that. It's very much where, where they want it to be. I mean, artistically

241
00:14:15,135 --> 00:14:18,095
Speaker 3:  that sounds right. Whether that's what it should be is like a different question.

242
00:14:18,095 --> 00:14:21,935
Speaker 3:  Especially at internet scale. Like again, this law is written

243
00:14:21,935 --> 00:14:25,295
Speaker 3:  in 1976. Many things have happened

244
00:14:26,045 --> 00:14:29,375
Speaker 3:  between smartphones for example, just recently

245
00:14:30,155 --> 00:14:34,135
Speaker 3:  the internet not contemplated. So like there's, there's

246
00:14:34,135 --> 00:14:37,535
Speaker 3:  just something that's disconnected there. But more specifically to your point

247
00:14:37,625 --> 00:14:40,615
Speaker 3:  David, now that I've answered your question with everything is chaos.

248
00:14:42,995 --> 00:14:45,655
Speaker 3:  The first thing you look at is like, did you make a copy? Even if you wanna

249
00:14:45,655 --> 00:14:49,335
Speaker 3:  make a fair use argument, A fair use argument is what they call an

250
00:14:49,335 --> 00:14:52,995
Speaker 3:  affirmative defense. So it is, but you're like, you

251
00:14:53,215 --> 00:14:56,875
Speaker 3:  did copyright infringement and you're like, yes I did do it,

252
00:14:58,175 --> 00:15:01,875
Speaker 3:  but let me tell you it's fine and here's why it's fine.

253
00:15:02,695 --> 00:15:06,475
Speaker 3:  And you have to, you have to accept that you've made some

254
00:15:06,475 --> 00:15:10,195
Speaker 3:  copies without permission. Right. That you didn't have a license to copy

255
00:15:10,295 --> 00:15:13,035
Speaker 3:  the entire database of New York Times article or scrape the entire website.

256
00:15:13,035 --> 00:15:16,435
Speaker 3:  You didn't get permission, you don't have a license, but your use of it in

257
00:15:16,435 --> 00:15:19,235
Speaker 3:  the end was fair for X, Y, Z reasons. And there's all these reasons you can

258
00:15:19,235 --> 00:15:19,995
Speaker 3:  go into, to

259
00:15:19,995 --> 00:15:23,915
Speaker 5:  Even make a fair use case. I have to forfeit my copyright infringement

260
00:15:23,915 --> 00:15:27,635
Speaker 5:  case because what I then have to say is, yes, I took it, but I'm

261
00:15:27,835 --> 00:15:31,395
Speaker 5:  doing something transformative or you know,

262
00:15:31,535 --> 00:15:35,035
Speaker 5:  useful or whatever with it such that it's okay. But I have to, I have to

263
00:15:35,055 --> 00:15:38,955
Speaker 5:  say at the beginning, yes I did make a copy in order to be able to do that.

264
00:15:39,025 --> 00:15:42,515
Speaker 3:  Yeah. You just have to, you have, you just have to give that up. Okay. And

265
00:15:42,515 --> 00:15:46,235
Speaker 3:  that is complicated in a lot of cases for a lot of reasons. It is less complicated

266
00:15:46,235 --> 00:15:48,755
Speaker 3:  in the case of computers because

267
00:15:50,315 --> 00:15:54,035
Speaker 3:  anything a computer does is a copy. Like merely taking a text

268
00:15:54,065 --> 00:15:57,915
Speaker 3:  file out of memory and putting it on a display involves making

269
00:15:57,915 --> 00:15:59,235
Speaker 3:  several copies along the way.

270
00:15:59,385 --> 00:16:02,235
Speaker 5:  Yeah. There's a copy of the New York Times article that I'm reading right

271
00:16:02,425 --> 00:16:04,475
Speaker 5:  now, somewhere in a cache on my computer

272
00:16:04,935 --> 00:16:08,795
Speaker 3:  And it hundreds of different cash points across the internet. Yeah. And

273
00:16:08,795 --> 00:16:12,315
Speaker 3:  to enable to load fast. And all of those I will remind everyone over and

274
00:16:12,315 --> 00:16:15,755
Speaker 3:  over again, all of those were litigated. The thing I'm saying about loading

275
00:16:15,785 --> 00:16:19,395
Speaker 3:  bits from memory, from one place on the computer to another straight up that

276
00:16:19,395 --> 00:16:22,995
Speaker 3:  was litigated. You can go read MAI versus peak systems a case that may

277
00:16:23,315 --> 00:16:26,475
Speaker 3:  be like spitting mad in law school because it's so stupid.

278
00:16:27,205 --> 00:16:31,155
Speaker 3:  Where one company sued another company that was installing its software without

279
00:16:31,155 --> 00:16:34,915
Speaker 3:  permission and said the co the illegal copy here is when

280
00:16:34,915 --> 00:16:38,195
Speaker 3:  your people copy our bits from a disc to memory

281
00:16:39,195 --> 00:16:42,575
Speaker 3:  to load it onto a computer. And they, they won like they, that was copyright.

282
00:16:42,735 --> 00:16:46,095
Speaker 3:  The court was like, yep, that's a copy. And the law was rewritten to protect

283
00:16:46,095 --> 00:16:49,575
Speaker 3:  what are called ephemeral copies that let like the internet work

284
00:16:50,055 --> 00:16:53,215
Speaker 3:  because it is obviously a bad policy outcome to say copying things from disc

285
00:16:53,215 --> 00:16:56,895
Speaker 3:  to memory is actionable copyright infringement. That's just using a computer.

286
00:16:57,275 --> 00:17:01,055
Speaker 3:  So here we have this like total unknown. Can you take, make a

287
00:17:01,255 --> 00:17:05,055
Speaker 3:  database of the internet and then do stuff with it such

288
00:17:05,055 --> 00:17:08,905
Speaker 3:  that you can spit back out the internet. don

289
00:17:08,905 --> 00:17:12,885
Speaker 3:  don't know. I I think probably there should be

290
00:17:12,885 --> 00:17:16,765
Speaker 3:  some payments in the mix there, right? That, that, that seems

291
00:17:16,765 --> 00:17:20,445
Speaker 3:  like the thing that should happen here, right? Is like, yeah,

292
00:17:20,715 --> 00:17:24,645
Speaker 3:  like OpenAI has a gigantic valuation. They need

293
00:17:24,645 --> 00:17:28,405
Speaker 3:  this data to train their systems. If you need the data to make your valuation

294
00:17:28,415 --> 00:17:32,325
Speaker 3:  exist, you probably have to trade some of your valuation back to the

295
00:17:32,325 --> 00:17:34,965
Speaker 3:  people that made the data in the first place. Like Right. That's just abstract.

296
00:17:34,965 --> 00:17:38,615
Speaker 3:  That's not me carrying much journalism or whatever. That's just like, if

297
00:17:38,615 --> 00:17:42,455
Speaker 3:  that is the raw material of your business, you should probably pay for the

298
00:17:42,455 --> 00:17:43,695
Speaker 3:  raw material of your business. Well

299
00:17:43,695 --> 00:17:45,255
Speaker 4:  And they, they've made deals too, right?

300
00:17:45,805 --> 00:17:49,135
Speaker 3:  Yeah. They made a big deal with Axel Springer, which publishes Business Insider.

301
00:17:49,245 --> 00:17:52,645
Speaker 3:  I think that's, it's not a very lucrative deal. It it's quoted at like

302
00:17:52,645 --> 00:17:56,005
Speaker 3:  $10 million over a number of years. Oof. Which

303
00:17:56,615 --> 00:18:00,365
Speaker 3:  is right. Yeah. Yeah. $10 million is divid 10 divided by

304
00:18:00,475 --> 00:18:04,045
Speaker 3:  any number over one, over a number of years is like you're making a couple

305
00:18:04,205 --> 00:18:07,765
Speaker 3:  million dollars a year. Right? Yeah. Like that's what that sounds like. So

306
00:18:07,765 --> 00:18:11,685
Speaker 3:  like the deals are not very lucrative, but I think all, a lot of

307
00:18:11,745 --> 00:18:15,645
Speaker 3:  companies rather get paid than spend 10 years in court. And I think the

308
00:18:15,645 --> 00:18:18,725
Speaker 3:  time is like, no, we're gonna spend 10 years in court. I think Sarah Silverman

309
00:18:18,725 --> 00:18:22,525
Speaker 3:  is like, we'll spend 10, she'll spend 10 years in court. George, RR Martin,

310
00:18:22,875 --> 00:18:26,285
Speaker 3:  that dude, he's gotta finish the book. Like he's happy to litigate this through

311
00:18:25,965 --> 00:18:26,285
Speaker 3:  before

312
00:18:26,765 --> 00:18:28,605
Speaker 5:  He's not gonna do it. Doesn't have to now. Yeah.

313
00:18:29,425 --> 00:18:33,285
Speaker 3:  So like, I, I just think like this case is a big deal and the Times is gonna

314
00:18:33,285 --> 00:18:34,845
Speaker 3:  fight it pretty vociferously.

315
00:18:36,565 --> 00:18:40,185
Speaker 3:  But the argument here from all the companies, from Google, from OpenAI, from

316
00:18:40,185 --> 00:18:44,145
Speaker 3:  whoever, is this is fair use. We're gonna make the copies, we're gonna

317
00:18:44,145 --> 00:18:47,925
Speaker 3:  do stuff to the copies and that is fine because

318
00:18:49,135 --> 00:18:52,045
Speaker 3:  we're, you know, we're, we're creating a new product based on those copies,

319
00:18:52,095 --> 00:18:55,485
Speaker 3:  which is basically what sample or like sampling and music is

320
00:18:56,205 --> 00:18:59,445
Speaker 3:  supposed to do. even that, that is all licensed now. Like you get to a place

321
00:18:59,445 --> 00:19:03,245
Speaker 3:  where you make the argument about everything being a remix long enough and

322
00:19:03,245 --> 00:19:06,565
Speaker 3:  then you run out of original work to remix 'cause you've destroyed the market

323
00:19:06,745 --> 00:19:10,005
Speaker 3:  for it and then you start paying for it. So like the music industry

324
00:19:11,145 --> 00:19:14,925
Speaker 3:  by and large has sorted this out, right? There's just a lot of payments

325
00:19:14,975 --> 00:19:18,765
Speaker 3:  going on for publishing, for interpolation, for rewriting, for sample

326
00:19:18,765 --> 00:19:22,605
Speaker 3:  clearance in a way that in the eighties when all this happened,

327
00:19:22,635 --> 00:19:25,685
Speaker 3:  like, you know, the Beastie Boys never cleared a single sample.

328
00:19:26,555 --> 00:19:29,405
Speaker 3:  Like they just didn't do it. And they, there's so many in that record that

329
00:19:29,405 --> 00:19:33,125
Speaker 3:  that, you know, the argument is you can't now no major label

330
00:19:33,125 --> 00:19:37,045
Speaker 3:  runs that way anymore. Like they've built a market for remixing work

331
00:19:37,545 --> 00:19:40,765
Speaker 3:  and you have to expect that OpenAI and the others will have to create a market

332
00:19:40,825 --> 00:19:43,085
Speaker 3:  for remixing the data that they're ingesting.

333
00:19:43,155 --> 00:19:46,765
Speaker 5:  Well, and I do think a, a huge amount of that market you're talking about

334
00:19:46,775 --> 00:19:50,685
Speaker 5:  comes from nobody wanting to go to court. And I think in

335
00:19:50,685 --> 00:19:53,605
Speaker 5:  this case, what you have, like you said, is a couple of parties that are

336
00:19:53,605 --> 00:19:57,285
Speaker 5:  really, really psyched about going to court and, and actually

337
00:19:57,285 --> 00:20:00,805
Speaker 5:  hashing this out no matter how it goes. It's gonna be really interesting.

338
00:20:00,805 --> 00:20:04,685
Speaker 5:  But I think this is one of those things that strikes me as two

339
00:20:05,005 --> 00:20:08,565
Speaker 5:  separate issues. And I feel like we've talked about this a bunch with these

340
00:20:08,885 --> 00:20:12,485
Speaker 5:  companies recently. There is the kind of what feels right as a person in

341
00:20:12,485 --> 00:20:15,765
Speaker 5:  the world case, and then there's the like is this,

342
00:20:17,155 --> 00:20:21,125
Speaker 5:  does this match to what we understand to be our laws in the country? Right?

343
00:20:21,125 --> 00:20:23,925
Speaker 5:  Because the thing you're describing about the times and paying for the raw

344
00:20:24,125 --> 00:20:28,005
Speaker 5:  materials of your stuff, there are debates about this, right? All the AI

345
00:20:28,285 --> 00:20:31,365
Speaker 5:  companies say these things won't exist if we have to pay the billions of

346
00:20:31,365 --> 00:20:35,285
Speaker 5:  dollars of money required to get the data to make them. Which I find deeply

347
00:20:35,285 --> 00:20:38,045
Speaker 5:  hilarious because that just means you acknowledge that it's worth money and

348
00:20:38,045 --> 00:20:41,805
Speaker 5:  you're just stealing it for free. But leaving that aside, the idea

349
00:20:41,835 --> 00:20:45,805
Speaker 5:  that the Times and whoever else has stuff that's going

350
00:20:45,805 --> 00:20:49,605
Speaker 5:  into the training data for chat GPT and all these other things that

351
00:20:49,605 --> 00:20:52,685
Speaker 5:  those parties should be compensated seems obvious. Right? Like I, I don't

352
00:20:52,685 --> 00:20:56,525
Speaker 5:  think you can make a super compelling case that says OpenAI and

353
00:20:56,525 --> 00:21:00,085
Speaker 5:  Google and everybody else should just have free access to the entire internet

354
00:21:00,085 --> 00:21:03,805
Speaker 5:  forever to do with whatever they want, including compete with

355
00:21:03,905 --> 00:21:05,445
Speaker 5:  all of those publications.

356
00:21:07,075 --> 00:21:10,125
Speaker 3:  Yeah. Yeah. I mean, take your hypothetical from earlier

357
00:21:11,025 --> 00:21:14,965
Speaker 3:  and just remove AI from the equation and just sort of

358
00:21:15,025 --> 00:21:18,685
Speaker 3:  run them as they were normal products. You David Pierce have

359
00:21:18,685 --> 00:21:22,525
Speaker 3:  memorized the entire New York Times and for, and you've not compensated them

360
00:21:22,525 --> 00:21:26,325
Speaker 3:  for it. Right. And for a small fee, you'll just tell anyone what's in the

361
00:21:26,325 --> 00:21:30,265
Speaker 3:  times today. Right. That's copyright infringement direct,

362
00:21:30,665 --> 00:21:33,185
Speaker 3:  like directly there. There's no getting around it. Right.

363
00:21:33,375 --> 00:21:34,265
Speaker 5:  It's also impressive.

364
00:21:34,945 --> 00:21:37,865
Speaker 3:  It's it, but, and, and the reason that we don't like sit around

365
00:21:38,905 --> 00:21:42,425
Speaker 3:  worrying about it is because you can't do that. Right? Right. Like, human

366
00:21:42,505 --> 00:21:46,285
Speaker 3:  memory is so fallible. President Barack

367
00:21:46,285 --> 00:21:49,365
Speaker 3:  Obama under decoder said the, the genius thing about the human memory is

368
00:21:49,365 --> 00:21:52,725
Speaker 3:  that it changes everything all the time. This is like, this was his argument

369
00:21:52,725 --> 00:21:55,405
Speaker 3:  when he was talking about copyright law and ai. He's like, your memories

370
00:21:55,405 --> 00:21:59,005
Speaker 3:  change things Andis don't, and So I think, and his argument was like, human

371
00:21:59,005 --> 00:22:02,845
Speaker 3:  creativity will be forever unsurpassed. Which, you know,

372
00:22:04,105 --> 00:22:04,525
Speaker 5:  Thanks.

373
00:22:04,525 --> 00:22:06,685
Speaker 3:  He's a, he's, he's famously a very hopeful man.

374
00:22:07,705 --> 00:22:10,925
Speaker 5:  But like Mike Masnick at Tech Dart wrote a smart piece about this after the,

375
00:22:10,925 --> 00:22:13,285
Speaker 5:  the lawsuit came out. And one of the things that he said was that if the

376
00:22:13,285 --> 00:22:17,205
Speaker 5:  Times wins, it opens up the times to a lot of issues because the

377
00:22:17,205 --> 00:22:21,085
Speaker 5:  Times is famous for basically taking and building

378
00:22:21,185 --> 00:22:25,125
Speaker 5:  on work done by other reporters elsewhere without giving them credit. And

379
00:22:25,225 --> 00:22:27,925
Speaker 5:  people at, you know, smaller blogs and sites have been yelling at the times

380
00:22:27,925 --> 00:22:31,685
Speaker 5:  about this for forever. And anyone who aggregates anything on the

381
00:22:31,805 --> 00:22:35,685
Speaker 5:  internet could suddenly be open to these same things because just by

382
00:22:35,685 --> 00:22:39,005
Speaker 5:  taking something and knowing it and doing something with it, you open yourself

383
00:22:39,005 --> 00:22:42,485
Speaker 5:  up to copyright infringement. And that's like, that strikes me as like a,

384
00:22:42,605 --> 00:22:45,885
Speaker 5:  a ways down that road. But I think is is not a totally impossible outcome.

385
00:22:46,025 --> 00:22:49,885
Speaker 5:  But again, all of this is like, I think there, there is a case to

386
00:22:49,885 --> 00:22:53,685
Speaker 5:  be made pretty simply that it just feels right that

387
00:22:53,925 --> 00:22:57,365
Speaker 5:  everyone who is helping make this thing for these enormously profitable companies

388
00:22:57,865 --> 00:22:59,765
Speaker 5:  should be compensated in some way. Right.

389
00:22:59,875 --> 00:23:03,685
Speaker 3:  Well, so two things. One, open eyes isn't profitable

390
00:23:03,685 --> 00:23:07,645
Speaker 3:  yet just burning money, but they are collecting a ton of investment dollars.

391
00:23:07,645 --> 00:23:11,325
Speaker 3:  Sure. So like that's interesting. Yeah. But the product itself is not yet

392
00:23:11,325 --> 00:23:11,645
Speaker 3:  profitable.

393
00:23:12,085 --> 00:23:12,845
Speaker 5:  Microsoft is pretty profitable.

394
00:23:13,325 --> 00:23:17,285
Speaker 3:  M Microsoft is pretty profitable Google. Right. But like these products right

395
00:23:17,285 --> 00:23:20,165
Speaker 3:  now represent sort of rising costs and not falling costs.

396
00:23:20,165 --> 00:23:20,925
Speaker 5:  That's fair. Yeah.

397
00:23:21,175 --> 00:23:24,965
Speaker 3:  Right. Like every hit on a one, whatever tensor unit or

398
00:23:25,125 --> 00:23:28,925
Speaker 3:  GPU that they're using to run these things, it costs more money than an average

399
00:23:28,925 --> 00:23:32,085
Speaker 3:  Google search or whatever. Yeah. So there, there's some like interesting

400
00:23:32,405 --> 00:23:35,925
Speaker 3:  economics that it, they're not quite as profitable as everyone wants them

401
00:23:35,945 --> 00:23:38,525
Speaker 3:  to be. Sure. But everyone can see the future in which they're extraordinarily.

402
00:23:38,625 --> 00:23:42,125
Speaker 5:  But also does that matter, like in, in copyright infringement, does, does

403
00:23:42,155 --> 00:23:44,165
Speaker 5:  your company valuation make a difference?

404
00:23:44,705 --> 00:23:47,605
Speaker 3:  No, I, but I think that's the moral case. It doesn't make a difference. Copyright

405
00:23:47,605 --> 00:23:50,885
Speaker 3:  infringement. Copyright infringement. This notion that there's some sort

406
00:23:50,885 --> 00:23:54,205
Speaker 3:  of big taking happening economically, I think

407
00:23:54,605 --> 00:23:58,205
Speaker 3:  provides ammunition to the moral argument that you're making, which is like,

408
00:23:58,205 --> 00:24:01,925
Speaker 3:  you should, you should get compensated for this use. You just,

409
00:24:02,235 --> 00:24:05,085
Speaker 3:  there's gotta be money at the other end of the line. Right. And like that

410
00:24:05,105 --> 00:24:08,445
Speaker 3:  is sort of as yet unproven. I think everyone believes that there will be

411
00:24:08,445 --> 00:24:10,725
Speaker 3:  a lot of money at the end of the line. I believe there will be a lot of money

412
00:24:10,725 --> 00:24:14,325
Speaker 3:  at the end of the line and you should sort out the economics early. That

413
00:24:14,325 --> 00:24:17,005
Speaker 3:  all makes sense. But the money isn't actually at the end. We're not actually

414
00:24:17,005 --> 00:24:18,645
Speaker 3:  at the end of the line. So that's just one, one thing I like.

415
00:24:18,645 --> 00:24:20,845
Speaker 5:  But I I will say just one other thought to that and then you should keep

416
00:24:20,845 --> 00:24:23,005
Speaker 5:  going. Yeah. Is that like

417
00:24:24,355 --> 00:24:27,125
Speaker 5:  there's a weird thing in this where kind of everybody loses, right? Because

418
00:24:27,125 --> 00:24:29,925
Speaker 5:  if OpenAI is, is taking the New York

419
00:24:30,675 --> 00:24:34,365
Speaker 5:  Times information to make a thing that loses tons of money, but

420
00:24:34,545 --> 00:24:37,725
Speaker 5:  in so doing is taking readership away from the New York Times because it

421
00:24:37,725 --> 00:24:40,765
Speaker 5:  can answer some of the questions people might have otherwise gone to the

422
00:24:40,865 --> 00:24:44,805
Speaker 5:  New York Times for and even tell you about New York Times articles, the

423
00:24:44,865 --> 00:24:47,965
Speaker 5:  New York Times also loses. So you're, you're stealing my money in order to

424
00:24:47,965 --> 00:24:51,205
Speaker 5:  not have any money. Right. Which is kind of a wild current version of affairs.

425
00:24:51,885 --> 00:24:55,485
Speaker 3:  I agree. And th and there's a weird zero sum notion

426
00:24:56,345 --> 00:25:00,205
Speaker 3:  to the value of information embedded in there. Sure. That is hard to

427
00:25:00,225 --> 00:25:03,965
Speaker 3:  unpack. Like it costs the New York Times a lot of

428
00:25:04,425 --> 00:25:08,245
Speaker 3:  money to generate the reporting. It costs us a lot of money to generate the

429
00:25:08,705 --> 00:25:10,645
Speaker 3:  reporting and then everyone sort of believes that it should be

430
00:25:12,525 --> 00:25:16,365
Speaker 3:  free. I don don't know, like yeah, I know how much it costs to employ

431
00:25:16,365 --> 00:25:16,565
Speaker 3:  our

432
00:25:18,465 --> 00:25:21,765
Speaker 3:  staff. We we should make more money than it costs to run our business.

433
00:25:22,435 --> 00:25:25,485
Speaker 3:  That that argument plays in every part of the

434
00:25:26,545 --> 00:25:28,405
Speaker 3:  world except journalism on the

435
00:25:30,395 --> 00:25:33,805
Speaker 3:  internet. Like that's very weird. And like you can see, you know, the reaction

436
00:25:33,805 --> 00:25:37,245
Speaker 3:  to that across the sort of media landscape is more paywalls are going up.

437
00:25:37,245 --> 00:25:40,805
Speaker 3:  Like people are trying to value the information at what they think the market

438
00:25:40,805 --> 00:25:44,325
Speaker 3:  should value it at. And that is working and not working in different ways.

439
00:25:45,605 --> 00:25:48,425
Speaker 3:  The other thing I wanna say is I love Mike Masek. I think he's very smart.

440
00:25:48,505 --> 00:25:51,145
Speaker 3:  I protect her at all the time. People should protect her. This is the place

441
00:25:51,145 --> 00:25:53,985
Speaker 3:  where I I I tend to disagree with Mike and I am a

442
00:25:54,895 --> 00:25:58,505
Speaker 3:  copyright minimalist. I would say. Like I worry about the

443
00:25:58,505 --> 00:26:00,905
Speaker 3:  expansion of copyright law all the time. That's how I started my career as

444
00:26:00,905 --> 00:26:04,665
Speaker 3:  a lawyer. That's like what I've written about a long time. But I, I think

445
00:26:04,665 --> 00:26:08,345
Speaker 3:  sometimes Mike just devalues everything to zero too quickly and

446
00:26:08,625 --> 00:26:11,105
Speaker 3:  embedded in the argument that he makes in that piece. Which again, you should

447
00:26:11,105 --> 00:26:12,905
Speaker 3:  go read, I love tech, you should read tech art all the time.

448
00:26:14,525 --> 00:26:18,465
Speaker 3:  Is the notion that the time work is not valuable. That

449
00:26:18,565 --> 00:26:22,385
Speaker 3:  the times insisting that its work has value unto itself

450
00:26:23,015 --> 00:26:26,865
Speaker 3:  somehow is hypocritical. Because then everyone else can

451
00:26:26,865 --> 00:26:30,105
Speaker 3:  insist that their work also has value, which will destroy the New York Times.

452
00:26:30,105 --> 00:26:33,705
Speaker 3:  There's, there's something in there that I, I think on the internet we're

453
00:26:33,725 --> 00:26:37,705
Speaker 3:  getting to a place where more and more people are insisting that their

454
00:26:37,855 --> 00:26:41,385
Speaker 3:  digital work has value unto itself. Not just

455
00:26:42,225 --> 00:26:46,135
Speaker 3:  as a, a rapper around some advertising or like

456
00:26:46,135 --> 00:26:49,015
Speaker 3:  a rapper around some like influencer merch hustle or like

457
00:26:50,155 --> 00:26:54,135
Speaker 3:  whatever. And that's like, that's just new. The joke I keep making with Addie

458
00:26:54,135 --> 00:26:57,855
Speaker 3:  Robertson, our policy editor, is that we came up in a time when

459
00:26:58,095 --> 00:27:01,995
Speaker 3:  the dominant like vibe on the internet was everything is a remix.

460
00:27:02,895 --> 00:27:05,915
Speaker 3:  And now every the vibe on the internet is, fuck you pay me. Yeah,

461
00:27:06,655 --> 00:27:10,035
Speaker 3:  that's good. Right? I like that. Yeah. Like that's a big shift. It's a big

462
00:27:10,035 --> 00:27:13,795
Speaker 3:  culture shift. Like it's hard for me to wrap my head around it 'cause I am

463
00:27:13,795 --> 00:27:17,635
Speaker 3:  very much of the, everything is a remix school, but you just, you

464
00:27:17,655 --> 00:27:21,155
Speaker 3:  you, it there has to be like, some money has to flow

465
00:27:21,735 --> 00:27:25,715
Speaker 3:  to original creators and it, it isn't happening at scale on

466
00:27:25,715 --> 00:27:29,315
Speaker 3:  any of the social platforms. Like every influencer

467
00:27:29,495 --> 00:27:33,115
Speaker 3:  is pivoting into selling you goods. Like whether it's water

468
00:27:33,115 --> 00:27:36,955
Speaker 3:  bottles or shoes or Mr. Mobile just launched a, a

469
00:27:37,195 --> 00:27:40,915
Speaker 3:  keyboard case. The iPhone today. Like it's fine. Like that's what the,

470
00:27:41,055 --> 00:27:43,555
Speaker 3:  all their businesses are going there because there isn't enough value in

471
00:27:43,555 --> 00:27:46,435
Speaker 3:  the content itself on the platforms. I mean that's why they're boxing. Like

472
00:27:46,435 --> 00:27:50,035
Speaker 3:  literally there are fighting every YouTubers are becoming professional boxers

473
00:27:50,035 --> 00:27:53,235
Speaker 3:  because that's how you, you can now buy a bottle of prime that is just Logan

474
00:27:53,235 --> 00:27:54,435
Speaker 3:  Paul's blood. Ugh.

475
00:27:56,255 --> 00:28:00,075
Speaker 3:  That's not true. Okay. I I will be remiss if I

476
00:28:00,075 --> 00:28:03,835
Speaker 3:  don't do this. It will take a little longer, but it's the actual legal

477
00:28:03,985 --> 00:28:07,835
Speaker 3:  nerd thing that we should do to talk about fair use. And there's one

478
00:28:07,835 --> 00:28:11,555
Speaker 3:  point in here that I, I want to make before we, we break and talk about css.

479
00:28:12,015 --> 00:28:15,715
Speaker 3:  So the fair use analysis, which I have pointed out is always chaos,

480
00:28:15,975 --> 00:28:19,835
Speaker 3:  always a coin flip. But there is a legal analysis, like you can go

481
00:28:19,835 --> 00:28:23,515
Speaker 3:  read the statute. There are four factors to consider an nefarious analysis.

482
00:28:23,975 --> 00:28:27,955
Speaker 3:  So just think about OpenAI in a times in this way. So the four

483
00:28:27,955 --> 00:28:30,755
Speaker 3:  factors the judge is supposed to consider the purpose and character of your

484
00:28:30,815 --> 00:28:34,675
Speaker 3:  use. What are you using it for? The nature of the copyrighted

485
00:28:34,675 --> 00:28:38,475
Speaker 3:  work, the amount and substantiality of the proportion

486
00:28:38,475 --> 00:28:42,355
Speaker 3:  taken, how much of the work you're using and the effect

487
00:28:42,415 --> 00:28:46,395
Speaker 3:  of the use upon the potential market for the original work. So

488
00:28:46,395 --> 00:28:49,755
Speaker 3:  if I take your thing and I make something based on it and then I destroy

489
00:28:49,815 --> 00:28:53,515
Speaker 3:  the market for your thing, I've lost, it's not fair. Right. That's an

490
00:28:53,515 --> 00:28:56,565
Speaker 3:  unfair use of the work. So this is, I think

491
00:28:57,355 --> 00:29:00,685
Speaker 3:  this is why it's always a coin flip because in every single case these four

492
00:29:00,685 --> 00:29:04,325
Speaker 3:  factors are weighted differently. Sometimes judges wake up and they have

493
00:29:04,325 --> 00:29:08,005
Speaker 3:  different ideas about what the market for art looks like in Amer. Like this

494
00:29:08,005 --> 00:29:10,765
Speaker 3:  is why it's a coin flip because these factors are different every time and

495
00:29:10,765 --> 00:29:14,525
Speaker 3:  different people evaluate them. But the one I would point to

496
00:29:14,525 --> 00:29:18,125
Speaker 3:  here for the times that they, I would guess that they lean on the most

497
00:29:18,785 --> 00:29:21,965
Speaker 3:  is the fourth factor. Yep. The effect of the use upon the market for the

498
00:29:22,165 --> 00:29:26,125
Speaker 3:  original work. Because it is sort of undeniable that the purpose of open

499
00:29:26,235 --> 00:29:29,405
Speaker 3:  AI's use is to do the things the times does.

500
00:29:30,055 --> 00:29:33,365
Speaker 3:  Right. You ask it questions, it delivers you answers that potentially were

501
00:29:33,365 --> 00:29:36,845
Speaker 3:  first generated by the New York Times. The nature of the work is it's

502
00:29:38,745 --> 00:29:40,965
Speaker 3:  attack the amount and substantiality of proportion take. Well it's all of

503
00:29:41,995 --> 00:29:45,965
Speaker 3:  it. Yeah. There's, that's it's all of it. So what's what's

504
00:29:45,965 --> 00:29:49,685
Speaker 3:  the one with the wiggle room in it? Yeah. It's the effect of the

505
00:29:50,105 --> 00:29:53,925
Speaker 3:  use on the potential market. And if the times can prove that

506
00:29:54,065 --> 00:29:57,965
Speaker 3:  OpenAI is replacing the market for the New York Times by

507
00:29:57,965 --> 00:30:00,405
Speaker 3:  copying the New York Times. If I had to make one prediction, I would say

508
00:30:00,795 --> 00:30:04,405
Speaker 3:  it's this fourth factor, the market factor that is the most heavily

509
00:30:04,405 --> 00:30:06,765
Speaker 3:  weighted and the one that gets discussed the most. Well,

510
00:30:06,765 --> 00:30:09,645
Speaker 5:  And there's, there's a bunch of that in the complaint even, right? Like the,

511
00:30:09,645 --> 00:30:13,405
Speaker 5:  the time talks a bunch about trademark dilution and the idea that

512
00:30:13,945 --> 00:30:17,125
Speaker 5:  the, the chat GPT hallucinating

513
00:30:17,825 --> 00:30:20,805
Speaker 5:  New York Times articles and attributing

514
00:30:21,025 --> 00:30:24,645
Speaker 5:  product recommendations to the Wirecutter that didn't come from Wirecutter.

515
00:30:24,675 --> 00:30:28,645
Speaker 5:  That that kind of thing is actually bad for the New York Times as a

516
00:30:28,645 --> 00:30:32,605
Speaker 5:  competitor in the market of good and valuable information. And again, like

517
00:30:32,605 --> 00:30:36,165
Speaker 5:  you said, this thing where you can just basically have it read you paragraph

518
00:30:36,845 --> 00:30:40,445
Speaker 5:  by paragraph a New York Times article, like it's, it's already

519
00:30:40,675 --> 00:30:43,685
Speaker 5:  seeming to push past this idea that it's illegal to have a database full

520
00:30:44,005 --> 00:30:47,325
Speaker 5:  of our things. I think it would like to make that case, but it seems to have

521
00:30:47,325 --> 00:30:50,965
Speaker 5:  quickly jumped past that too. By doing this, you're making the times look

522
00:30:50,965 --> 00:30:54,725
Speaker 5:  worse and trying to steal our business. And I think at least of the cases

523
00:30:54,925 --> 00:30:58,835
Speaker 5:  that I've seen, that is the step beyond a lot of the

524
00:30:58,835 --> 00:31:02,275
Speaker 5:  other stuff that I've seen. Not just, it's illegal for chat GBT to have trained

525
00:31:02,275 --> 00:31:05,875
Speaker 5:  on this data, but it is actually turning it back around in ways that harm

526
00:31:05,895 --> 00:31:09,435
Speaker 5:  us. So I, I think you're right. And I think the Times is, is gonna push that

527
00:31:09,435 --> 00:31:12,635
Speaker 5:  pretty hard. I mean an amazing amount of this complaint is just

528
00:31:13,225 --> 00:31:17,115
Speaker 5:  like examples of conversations with chat GPT about New York Times

529
00:31:17,315 --> 00:31:21,195
Speaker 5:  articles, which again, to your point about these things being marketing is,

530
00:31:21,255 --> 00:31:22,835
Speaker 5:  is not accidental.

531
00:31:22,835 --> 00:31:26,635
Speaker 3:  Yeah. This thing is made to make the argument for us

532
00:31:26,695 --> 00:31:30,275
Speaker 3:  to read to you on this podcast for news anchors to read. You know, like

533
00:31:30,495 --> 00:31:33,955
Speaker 3:  that's what complaints are for. Eventually they're gonna have to make more

534
00:31:33,955 --> 00:31:37,275
Speaker 3:  pleadings and actually have a trial. And the thing that is crazy about all

535
00:31:37,275 --> 00:31:41,125
Speaker 3:  this is if the time settles with OpenAI,

536
00:31:41,745 --> 00:31:44,965
Speaker 3:  it doesn't mean anything for the next case to come along because the, the,

537
00:31:44,965 --> 00:31:48,565
Speaker 3:  there's no fair use precedent here. So I, I think some of these cases

538
00:31:48,675 --> 00:31:51,805
Speaker 3:  will like run to ground. But what you don't have

539
00:31:52,745 --> 00:31:56,685
Speaker 3:  is a music industry that is invested in its own

540
00:31:57,125 --> 00:32:01,045
Speaker 3:  survival as the music industry to develop a whole bunch of deal structures

541
00:32:01,045 --> 00:32:04,525
Speaker 3:  around sampling and interpolation, which they have done. Like it has taken

542
00:32:04,525 --> 00:32:08,285
Speaker 3:  them several decades to do. But there's a whole business model

543
00:32:08,425 --> 00:32:12,325
Speaker 3:  for like publishing rights and sampling in the music industry because it's

544
00:32:12,325 --> 00:32:15,045
Speaker 3:  a closed ecosystem. You're like, I'm gonna take some music and make some

545
00:32:15,045 --> 00:32:18,605
Speaker 3:  more music based off of it. I'll give you this example. Major record labels

546
00:32:18,995 --> 00:32:22,365
Speaker 3:  have songwriter workshops where they get a bunch of songwriters, they take

547
00:32:22,365 --> 00:32:25,485
Speaker 3:  their own catalog of old hits and say write new songs based on these hits

548
00:32:25,915 --> 00:32:29,645
Speaker 3:  because they know that's the safest way to, to sample their own work

549
00:32:30,025 --> 00:32:33,285
Speaker 3:  and they can trade on some nostalgia. That is a totally wild a like if you

550
00:32:33,285 --> 00:32:36,845
Speaker 3:  said this would be happening in the eighties at the dawn of hip hop, like

551
00:32:36,845 --> 00:32:40,725
Speaker 3:  people think you were crazy, but they've built an, they've

552
00:32:40,725 --> 00:32:44,685
Speaker 3:  built a legal and financial ecosystem around this

553
00:32:44,875 --> 00:32:48,565
Speaker 3:  copyright problem of sampling that is actually now generated. Here's how

554
00:32:48,565 --> 00:32:52,405
Speaker 3:  songs are written. There's none of that on the internet. Like there's, there's

555
00:32:52,405 --> 00:32:56,045
Speaker 3:  no closed ecosystem of news providers and tech platforms and YouTube

556
00:32:56,325 --> 00:32:58,405
Speaker 3:  creators. It's all gonna get together in a room and be like, how are we gonna

557
00:32:58,405 --> 00:32:59,845
Speaker 3:  do this? There's just chaos.

558
00:33:00,065 --> 00:33:03,685
Speaker 5:  So hypothetically if say the CEO of

559
00:33:03,785 --> 00:33:07,405
Speaker 5:  Amazon were to buy one of America's

560
00:33:07,475 --> 00:33:09,285
Speaker 5:  largest national newspapers,

561
00:33:10,975 --> 00:33:14,885
Speaker 5:  would that, would that you know, close the ecosystem a little bit and maybe

562
00:33:14,885 --> 00:33:17,845
Speaker 5:  another one like bought Time magazine,

563
00:33:19,635 --> 00:33:23,405
Speaker 5:  like hypothetically if these tech companies started to buy these media

564
00:33:23,555 --> 00:33:26,765
Speaker 5:  organizations like May maybe, maybe we'd start to see something like that.

565
00:33:27,225 --> 00:33:31,125
Speaker 3:  So that would be hilarious if like all the

566
00:33:31,125 --> 00:33:34,805
Speaker 3:  entire Salesforce UI was based on the Taylor Swift article and the time

567
00:33:35,005 --> 00:33:38,765
Speaker 3:  magazine. It was just like, she's great I don Dunno what you're asking about.

568
00:33:39,245 --> 00:33:42,965
Speaker 3:  I can't increase your sales, but she's amazing. That's actually what

569
00:33:42,965 --> 00:33:46,405
Speaker 3:  Salesforce is. AI should be, just talk to your clients about Taylor Swift

570
00:33:47,345 --> 00:33:49,725
Speaker 3:  number of times. Taylor Swift was mentioned on this call,

571
00:33:51,185 --> 00:33:55,005
Speaker 3:  but the Amazon examples better. So Jeff Bezos owns the Washington

572
00:33:56,025 --> 00:33:59,365
Speaker 3:  Post and he obviously has a huge controlling stake in Amazon. If you get

573
00:33:59,365 --> 00:34:02,685
Speaker 3:  to the place where the purpose of the Washington Post is not to make money

574
00:34:02,685 --> 00:34:06,605
Speaker 3:  as the Washington Post, but it's to serve as a cost center for

575
00:34:06,605 --> 00:34:10,485
Speaker 3:  training Amazon's ai. That's a weird reason to do journalism. Yes.

576
00:34:11,885 --> 00:34:15,305
Speaker 3:  And like you can, you can like skip to that ending pretty fast in a lot of

577
00:34:15,305 --> 00:34:15,625
Speaker 3:  these cases

578
00:34:17,215 --> 00:34:20,785
Speaker 3:  like faster than you think. The purpose of X,

579
00:34:21,565 --> 00:34:24,825
Speaker 3:  you can argue is to serve as training data for grok.

580
00:34:25,695 --> 00:34:26,265
Speaker 4:  Sure. Now

581
00:34:26,765 --> 00:34:30,625
Speaker 3:  That's the argument Elon Musk is making. Like, is that

582
00:34:30,855 --> 00:34:34,705
Speaker 3:  what we want? Is that, is that the right incentive to, to make

583
00:34:34,705 --> 00:34:38,595
Speaker 3:  content so that we can mush it all together and spit it out as

584
00:34:38,615 --> 00:34:41,395
Speaker 3:  AI somewhere else? Like I don't I don know the answer to that question. That

585
00:34:41,395 --> 00:34:45,315
Speaker 3:  does not a appeal to me. I don Dunno if it appeals to you,

586
00:34:45,315 --> 00:34:49,035
Speaker 3:  but that's, you can quickly get to the end result where even if the AI companies

587
00:34:49,035 --> 00:34:52,835
Speaker 3:  are paying millions of dollars in fees to journalism companies or media

588
00:34:53,035 --> 00:34:56,595
Speaker 3:  companies or YouTube creators or whatever because there's more margin on

589
00:34:56,595 --> 00:35:00,585
Speaker 3:  the other end of owning the AI tool. Well then

590
00:35:00,625 --> 00:35:02,985
Speaker 3:  a bunch of YouTube creators are basically working for the AI tool.

591
00:35:03,755 --> 00:35:03,975
Speaker 4:  But

592
00:35:03,975 --> 00:35:04,895
Speaker 3:  That that's, we that's weird.

593
00:35:05,125 --> 00:35:09,055
Speaker 4:  That supposes that the AI tool will like actually make that kind

594
00:35:09,055 --> 00:35:09,335
Speaker 4:  of money.

595
00:35:10,025 --> 00:35:12,935
Speaker 3:  Right. Which is what I said, like I don't Yeah, we're not at that place yet

596
00:35:13,215 --> 00:35:17,095
Speaker 3:  actually. So you you it's, I I find it tempting to skip to the end of like,

597
00:35:17,095 --> 00:35:19,815
Speaker 3:  what does YouTube look like in the world where Barred can summarize a YouTube

598
00:35:19,815 --> 00:35:23,775
Speaker 3:  video and it's like none of that is good right now. Like, it's

599
00:35:23,775 --> 00:35:27,015
Speaker 3:  like, I mean just that's a problem. Google wishes it had no, but

600
00:35:27,195 --> 00:35:30,975
Speaker 4:  To some extent it's already doing that. Right? Because so many YouTube videos

601
00:35:31,035 --> 00:35:34,855
Speaker 4:  are now made to the algorithm, right? Yeah. Like they're already many made

602
00:35:34,855 --> 00:35:34,935
Speaker 4:  to

603
00:35:34,935 --> 00:35:37,325
Speaker 3:  Many TikTok videos are made to an AI algorithm. Yeah.

604
00:35:37,325 --> 00:35:40,525
Speaker 4:  So it's just like, okay, that, that homogenization that we see on YouTube

605
00:35:40,955 --> 00:35:42,565
Speaker 4:  just gets like accelerated.

606
00:35:43,605 --> 00:35:47,445
Speaker 3:  I cannot wait for the New York Times to adopt the Mr. Beast style. Yes.

607
00:35:47,445 --> 00:35:50,645
Speaker 3:  For all journalism. Oh my god. This is how we're, I was wondering how we're

608
00:35:50,645 --> 00:35:54,485
Speaker 3:  gonna cover the election and it's just straight rips of Mr. Beast

609
00:35:54,535 --> 00:35:55,645
Speaker 3:  videos about tech policy. Oh

610
00:35:55,665 --> 00:35:59,405
Speaker 5:  Man. Every, every picture on the homepage of the New York Times is just

611
00:35:59,605 --> 00:36:01,325
Speaker 5:  the reporter with their mouth open making a face.

612
00:36:02,105 --> 00:36:03,845
Speaker 4:  No, it's closed now, right? It's closed now.

613
00:36:04,025 --> 00:36:06,525
Speaker 5:  Oh you're right. It's, yeah, it's, your mouth is closed and there's something

614
00:36:06,595 --> 00:36:08,325
Speaker 5:  gold and a bunch of money behind you

615
00:36:09,025 --> 00:36:10,845
Speaker 3:  And it's just New York Times

616
00:36:13,965 --> 00:36:16,445
Speaker 3:  reporter. Look, it would, it would certainly be interesting. That's all I'm

617
00:36:16,825 --> 00:36:20,205
Speaker 3:  saying. All right? We gotta take a break. I'm, I talked about copyright law

618
00:36:20,205 --> 00:36:23,845
Speaker 3:  for two. This is my my fault. We're gonna watch the chart in Apple podcast

619
00:36:23,845 --> 00:36:24,725
Speaker 3:  be like you know I did it

620
00:36:26,945 --> 00:36:28,445
Speaker 3:  again. All right. We're gonna take a break, we're gonna come back, we're

621
00:36:28,445 --> 00:36:29,605
Speaker 3:  gonna talk about some css. We'll grab back

622
00:37:20,595 --> 00:37:23,565
Speaker 7:  Investments offered through Robinhood Financial LLC

623
00:37:24,075 --> 00:37:25,125
Speaker 7:  investing is risky.

624
00:38:40,065 --> 00:38:43,915
Speaker 3:  Okay, we're back. That's all the copyright law talk. Will there be a little

625
00:38:43,915 --> 00:38:44,275
Speaker 3:  more copyright

626
00:38:44,275 --> 00:38:46,115
Speaker 5:  Law? I was gonna say you've made that promise before.

627
00:38:47,245 --> 00:38:48,395
Speaker 4:  Don't don't believe them guys.

628
00:38:49,105 --> 00:38:52,875
Speaker 3:  It's my favorite. It's the only law that works on the internet telling you

629
00:38:52,875 --> 00:38:56,765
Speaker 3:  this is true. It's also the law that might break Google in the end,

630
00:38:56,765 --> 00:39:00,115
Speaker 3:  which is fascinating to think about. Okay, that's enough. That's enough.

631
00:39:01,755 --> 00:39:04,395
Speaker 3:  We should talk about cs. CS is coming in a week. We're going, we're gonna

632
00:39:04,395 --> 00:39:08,235
Speaker 3:  be there. Yes. I would say there's, there's a bunch of stuff

633
00:39:08,235 --> 00:39:11,035
Speaker 3:  here that has been announced pre css.

634
00:39:12,115 --> 00:39:15,035
Speaker 3:  I always wonder if they announced the best stuff early to get the early wave

635
00:39:15,035 --> 00:39:18,195
Speaker 3:  of hype or this is just the, hey

636
00:39:19,055 --> 00:39:20,835
Speaker 3:  pay attention to us. The real stuff is coming.

637
00:39:21,315 --> 00:39:24,955
Speaker 4:  I think it's like both I think, I think it depends on the company. Some

638
00:39:25,155 --> 00:39:27,955
Speaker 4:  companies are like I wanna get my cool stuff out early. But most companies

639
00:39:27,955 --> 00:39:31,875
Speaker 4:  are like, I wanna get some fun stuff out, tease

640
00:39:31,955 --> 00:39:33,835
Speaker 4:  you and then do the really cool stuff later.

641
00:39:34,105 --> 00:39:37,995
Speaker 3:  Yeah and nothing will have a price or a ship date. Yeah, all of it will

642
00:39:38,495 --> 00:39:41,355
Speaker 3:  be like the weirdest render you've ever seen and then you can come see it

643
00:39:41,355 --> 00:39:41,955
Speaker 3:  in person or a

644
00:39:41,955 --> 00:39:43,155
Speaker 4:  Booth or it'll be a sticker

645
00:39:43,615 --> 00:39:47,435
Speaker 5:  Or it is the thing you are most likely to buy but is kind of the

646
00:39:47,435 --> 00:39:51,195
Speaker 5:  least interesting, right? Like the, if you're gonna release a spec

647
00:39:51,195 --> 00:39:55,155
Speaker 5:  update to your already existing laptop, do it before CES because

648
00:39:55,155 --> 00:39:58,795
Speaker 5:  by the time we get there nobody caress. 'cause everybody is like drowning

649
00:39:58,935 --> 00:40:02,155
Speaker 5:  in weird flying iPhone cases. But

650
00:40:02,855 --> 00:40:05,955
Speaker 5:  if you have something that is like here is an actual product that actual

651
00:40:05,955 --> 00:40:09,915
Speaker 5:  people will probably buy, this is when some of this stuff comes out. That's

652
00:40:09,915 --> 00:40:13,195
Speaker 5:  why we're seeing a lot of like monitor upgrades and

653
00:40:13,815 --> 00:40:17,635
Speaker 5:  you know, spec bumps to laptops and things like that. And then I think you

654
00:40:17,635 --> 00:40:20,595
Speaker 5:  get to CES and that's when they're like, have you seen these speakers? They're

655
00:40:20,595 --> 00:40:23,995
Speaker 5:  62 feet tall and they cost $5 million

656
00:40:25,335 --> 00:40:28,835
Speaker 3:  CES and they're just me standing in front of me like exactly. This is why

657
00:40:28,875 --> 00:40:32,795
Speaker 3:  I do what I do. I'm home again All.

658
00:40:32,795 --> 00:40:34,755
Speaker 3:  right. So I'm just gonna read a few of them that I think are incredible.

659
00:40:35,915 --> 00:40:39,715
Speaker 3:  LG released what like a speaker system. I don know how what, how to

660
00:40:39,835 --> 00:40:43,115
Speaker 3:  describe this thing. It's a speaker with vacuum tubes in it and it transparent

661
00:40:43,355 --> 00:40:46,955
Speaker 3:  ed display on the front of it that displays the name of the song in like

662
00:40:46,955 --> 00:40:50,635
Speaker 3:  old time font. Yeah. I want this thing so badly. It's sick.

663
00:40:50,825 --> 00:40:54,755
Speaker 3:  It's so stupid. It is so dumb. but it ISS

664
00:40:54,755 --> 00:40:55,515
Speaker 3:  so cool. It

665
00:40:55,515 --> 00:40:59,275
Speaker 4:  Just is like a Kickstarter that somehow LG made

666
00:40:59,275 --> 00:40:59,515
Speaker 4:  real

667
00:41:00,295 --> 00:41:01,795
Speaker 3:  That's exactly right. Yeah.

668
00:41:01,795 --> 00:41:05,315
Speaker 4:  Like a 2014 Kickstarter and they're like no we're just gonna sell this thing

669
00:41:05,315 --> 00:41:06,275
Speaker 4:  and put LG sample

670
00:41:06,295 --> 00:41:10,195
Speaker 3:  On it. It's so cool. Like ridiculously cool. Big

671
00:41:10,195 --> 00:41:13,955
Speaker 3:  vacuum tubes. Little vacuum tubes. Old

672
00:41:14,045 --> 00:41:18,035
Speaker 3:  timey fonts. I'm not even sure if it's recasting the name

673
00:41:18,035 --> 00:41:21,995
Speaker 3:  of the song into the old timey font or if they just found

674
00:41:22,715 --> 00:41:26,235
Speaker 3:  a song whose album cover is in an old timey font. Do you know what I mean?

675
00:41:26,235 --> 00:41:29,795
Speaker 3:  Like don don't know what's going on here. Exactly. I just know that this

676
00:41:29,795 --> 00:41:32,755
Speaker 3:  picture of this, it's a black and white picture of a guy leaning back in

677
00:41:32,755 --> 00:41:36,685
Speaker 3:  a chair but then the speaker system is in color but then it's

678
00:41:36,845 --> 00:41:39,725
Speaker 3:  actually not in color. It's just the orange of the vacuum tubes is the color.

679
00:41:39,835 --> 00:41:40,685
Speaker 4:  It's GI ceia.

680
00:41:41,475 --> 00:41:45,325
Speaker 3:  It's per it's perfect. It's so good. It's a very CSS product. I'm very

681
00:41:45,325 --> 00:41:49,245
Speaker 3:  excited about it. I'm gonna go look at it a lot. Then there's been a bunch

682
00:41:49,245 --> 00:41:52,485
Speaker 3:  of display news that I'll just read quickly 'cause it's a bunch of gaming

683
00:41:52,485 --> 00:41:55,845
Speaker 3:  monitors. Samsung now has more ole gaming monitors.

684
00:41:56,285 --> 00:41:58,805
Speaker 3:  Some of them have up to 360 hertz refresh rates,

685
00:42:00,075 --> 00:42:03,705
Speaker 3:  which I believe is many times faster than human perception. But good for

686
00:42:03,705 --> 00:42:07,345
Speaker 3:  Samsung. Hell yeah. And then LG has topped Samsung with a

687
00:42:07,345 --> 00:42:11,105
Speaker 3:  27 inch OLED that has a 480 hertz refresher

688
00:42:11,365 --> 00:42:11,945
Speaker 5:  In your face.

689
00:42:11,945 --> 00:42:15,345
Speaker 3:  Samsung. So we are, we are just doing like watt war

690
00:42:15,345 --> 00:42:16,985
Speaker 3:  horsepower war specs. Is

691
00:42:16,985 --> 00:42:20,065
Speaker 5:  This the new thing? This actually kind of makes sense that if, if we're definitely

692
00:42:20,245 --> 00:42:24,065
Speaker 5:  in a phase where the best way to sell a really fancy monitor

693
00:42:24,205 --> 00:42:28,185
Speaker 5:  is to sell really great gameplay to gamers.

694
00:42:28,185 --> 00:42:32,025
Speaker 5:  Yeah. Like that's who buys your fancy monitors. And I think we're

695
00:42:32,025 --> 00:42:34,945
Speaker 5:  just in a place now where we're just gonna be on like a crazy

696
00:42:35,715 --> 00:42:39,705
Speaker 5:  hertz refresh rate arm race and eventually Samsung

697
00:42:40,005 --> 00:42:42,505
Speaker 5:  is gonna be like we did it everybody 10 80.

698
00:42:43,945 --> 00:42:47,425
Speaker 4:  I think it'll be more like everybody will start to realize they don't actually

699
00:42:47,535 --> 00:42:51,225
Speaker 4:  need that and most of their games will never take advantage of it

700
00:42:51,925 --> 00:42:53,625
Speaker 4:  and it's probably not worth their money. Yeah.

701
00:42:53,625 --> 00:42:56,465
Speaker 5:  But that's like three years from now. Oh yeah. After a bunch of people buy

702
00:42:56,505 --> 00:42:59,825
Speaker 5:  monitors out after the 10 80 hurts would ever notice. Right. Exactly.

703
00:43:00,495 --> 00:43:03,025
Speaker 4:  It's after and then we'll be like, oh remember that phase Weird.

704
00:43:03,615 --> 00:43:07,185
Speaker 3:  Well, So I, just to be specific, the LG display is

705
00:43:07,185 --> 00:43:10,625
Speaker 3:  480 hertz at 10 80 p which is, I think

706
00:43:10,765 --> 00:43:14,745
Speaker 3:  that's why a bunch of monitors hit 1440 for a minute. That was the

707
00:43:14,745 --> 00:43:18,425
Speaker 3:  sweet spot of resolution and and refresh rate and So I think what this

708
00:43:18,625 --> 00:43:22,385
Speaker 3:  actually signals is you're gonna get faster refresh rates at the resolutions

709
00:43:22,385 --> 00:43:25,425
Speaker 3:  you actually wanna run at. And then, and then you have to make some sort

710
00:43:25,425 --> 00:43:28,625
Speaker 3:  of decisions about what you prioritize. But yeah, it, this is just a spec

711
00:43:28,645 --> 00:43:32,505
Speaker 3:  war and I'm here for it. Absolutely. I, I want to be very clear that

712
00:43:32,505 --> 00:43:36,345
Speaker 3:  anytime LG and Samsung decide to engage in a display spec

713
00:43:36,405 --> 00:43:39,865
Speaker 3:  war, you just call me. I'll be there a hundred percent. We're we're gonna

714
00:43:39,865 --> 00:43:43,145
Speaker 3:  cover every ounce of that spec war. 'cause display spec wars are what this

715
00:43:43,465 --> 00:43:44,025
Speaker 3:  business is made of.

716
00:43:44,425 --> 00:43:48,185
Speaker 5:  I also still really like this trend where everybody is putting smart TV

717
00:43:48,235 --> 00:43:49,865
Speaker 5:  stuff into computer monitors.

718
00:43:49,935 --> 00:43:50,465
Speaker 4:  It's the best.

719
00:43:50,855 --> 00:43:54,505
Speaker 5:  It's so good. Like, like just to have a thing that's like I have a

720
00:43:54,505 --> 00:43:58,425
Speaker 5:  32 inch screen and I can, it is my television and my

721
00:43:58,425 --> 00:44:01,265
Speaker 5:  gaming monitor and my computer monitor and it does all those things pretty,

722
00:44:01,295 --> 00:44:02,825
Speaker 5:  it's like I love it. It's

723
00:44:02,825 --> 00:44:05,745
Speaker 4:  Great. Can you imagine being a college student and having that like I'm just

724
00:44:05,745 --> 00:44:09,425
Speaker 4:  like, why I want that. I know I'm gonna go back to college just So I can

725
00:44:09,425 --> 00:44:12,185
Speaker 4:  have this monitor experience but then I'm gonna be in the dorm one night

726
00:44:12,185 --> 00:44:12,785
Speaker 4:  and be like, wait,

727
00:44:13,825 --> 00:44:14,225
Speaker 5:  I like having

728
00:44:14,385 --> 00:44:17,745
Speaker 3:  A house. I just want to be clear. Both of you are are very senior. Editorial

729
00:44:17,745 --> 00:44:21,185
Speaker 3:  staffers.com David's like, I can't wait till I can own a chair

730
00:44:21,585 --> 00:44:24,865
Speaker 3:  And Alex is like, I'm gonna go back to college to get a monitor.

731
00:44:29,135 --> 00:44:31,645
Speaker 3:  It's good. We all need dreams and hopes and aspirations.

732
00:44:31,645 --> 00:44:35,245
Speaker 4:  Yeah. Our dreams just going backwards or forwards rapidly in time.

733
00:44:35,785 --> 00:44:38,325
Speaker 3:  I'm gonna get a chair guys. It's gonna be my chair.

734
00:44:39,315 --> 00:44:40,325
Speaker 4:  He's gonna have his name on the

735
00:44:40,325 --> 00:44:43,445
Speaker 5:  Back. You have to earn comfort me. Like Yeah, don't forget that.

736
00:44:43,745 --> 00:44:46,165
Speaker 3:  All. right. The last little display one I want to call out and then we should

737
00:44:46,165 --> 00:44:49,805
Speaker 3:  do this is lightning round. Is this LG projector that looks like an old

738
00:44:50,355 --> 00:44:54,285
Speaker 3:  bell and Howell film projector. Like it this, it's

739
00:44:54,285 --> 00:44:58,005
Speaker 3:  a handle but it looks like a crank on the side. It's called the cine beam

740
00:44:58,075 --> 00:45:02,045
Speaker 3:  cube. Cube is spelled with a q extraordinarily important to

741
00:45:02,045 --> 00:45:05,685
Speaker 3:  note that it's spelled with a Q. It weighs 3.2

742
00:45:05,905 --> 00:45:09,685
Speaker 3:  pounds. It's just a little bit shorter

743
00:45:09,995 --> 00:45:13,965
Speaker 3:  than an iPhone. So it's itty bitty and it can do 120 inch image

744
00:45:13,965 --> 00:45:14,605
Speaker 3:  at 4K.

745
00:45:16,575 --> 00:45:20,145
Speaker 3:  It's pretty dimm. It's it's 500. It's not, it's not great

746
00:45:20,685 --> 00:45:22,305
Speaker 3:  but it is so pretty. It's

747
00:45:22,305 --> 00:45:22,665
Speaker 5:  Beautiful.

748
00:45:23,645 --> 00:45:25,105
Speaker 3:  It also, it runs web oss of

749
00:45:25,105 --> 00:45:27,985
Speaker 5:  Course. So, I. I really think back to like what we were talking about, about

750
00:45:28,005 --> 00:45:31,865
Speaker 5:  the kind of disintermediating phones as a thing. I think this is

751
00:45:31,865 --> 00:45:35,665
Speaker 5:  one way it's gonna happen. I think we're gonna get this really

752
00:45:35,815 --> 00:45:39,625
Speaker 5:  cool run of like furniture

753
00:45:39,935 --> 00:45:43,665
Speaker 5:  gadgets that I'm really excited about. Like we, we spent a long time with

754
00:45:43,665 --> 00:45:47,545
Speaker 5:  all the smart speakers and all this stuff being like, what if we made

755
00:45:47,545 --> 00:45:51,505
Speaker 5:  everything in your house more gadgety and it looked more like the

756
00:45:51,505 --> 00:45:55,425
Speaker 5:  future. Yeah. And everybody said that sucks. And then like with

757
00:45:55,765 --> 00:45:58,785
Speaker 5:  TVs and like the, the Samsung frame, which I know you haven't have many feelings

758
00:45:58,785 --> 00:46:01,625
Speaker 5:  about. We've, we've kind of gone back to like, what if these things actually

759
00:46:01,625 --> 00:46:05,265
Speaker 5:  looked, you know, nice and looked designed

760
00:46:05,565 --> 00:46:09,465
Speaker 5:  and looked like they belonged in your house and weren't just sort of dropped

761
00:46:09,485 --> 00:46:13,145
Speaker 5:  out of a Best Buy. And I think you're starting to see it from some of these

762
00:46:13,145 --> 00:46:16,225
Speaker 5:  bigger companies too. These things are all kind of like

763
00:46:16,695 --> 00:46:20,145
Speaker 5:  special edition larks right now. But you really get the sense that these

764
00:46:20,425 --> 00:46:24,265
Speaker 5:  companies are testing the waters to see like if we made a thing that doesn't

765
00:46:24,935 --> 00:46:28,345
Speaker 5:  look like a big fat white piece of plastic,

766
00:46:29,195 --> 00:46:32,505
Speaker 5:  would people buy that? And like I know for me the answer is yes and I really

767
00:46:32,505 --> 00:46:35,945
Speaker 5:  hope it is for other people too. 'cause I think design like this is what

768
00:46:35,985 --> 00:46:38,585
Speaker 5:  a projector should look like. Yeah. I'm so

769
00:46:38,815 --> 00:46:42,345
Speaker 3:  Cool as hell. Yeah. What what's funny though about all of that

770
00:46:42,645 --> 00:46:46,505
Speaker 3:  is, you know, old projectors look this way. Partially beautiful, but

771
00:46:46,615 --> 00:46:49,905
Speaker 3:  partially 'cause form followed function. Like they were very utilitarian

772
00:46:49,905 --> 00:46:53,145
Speaker 3:  products. This is just a projector. Like

773
00:46:53,815 --> 00:46:57,545
Speaker 3:  this is just an arm chip in some, I'm guessing some like very

774
00:46:57,865 --> 00:47:00,745
Speaker 3:  standard off the shelf projector parts that they have. They have lying around

775
00:47:01,365 --> 00:47:04,785
Speaker 3:  and they've made it beautiful. They've made it look like the old form,

776
00:47:05,335 --> 00:47:09,105
Speaker 3:  like the old function. And we haven't, we

777
00:47:09,105 --> 00:47:11,105
Speaker 3:  haven't quite figured out like, oh you could just make it really, really

778
00:47:11,105 --> 00:47:14,545
Speaker 3:  small. Like, oh we should make it bigger and like beautiful And like that

779
00:47:14,545 --> 00:47:17,505
Speaker 3:  is interesting to me. The Frame TV is like a deeply fascinating product to

780
00:47:17,505 --> 00:47:21,145
Speaker 3:  me. Why I as, as somebody who now owns A Frame TV in a frame,

781
00:47:21,215 --> 00:47:24,425
Speaker 3:  I'll rant about this product all day and all night. First of all, have you

782
00:47:24,425 --> 00:47:26,945
Speaker 3:  used Smart Things? What what?

783
00:47:27,705 --> 00:47:29,925
Speaker 4:  I used it like four years ago. Horrible.

784
00:47:30,505 --> 00:47:34,045
Speaker 3:  So the Frame TV is fascinating 'cause Samsung will just tell you this is

785
00:47:34,045 --> 00:47:37,685
Speaker 3:  a TV that's designed to be off and people buy it because they, they

786
00:47:37,755 --> 00:47:41,685
Speaker 3:  they realize that their TV is off more than on. Yeah. And so it should be

787
00:47:41,685 --> 00:47:45,365
Speaker 3:  beautiful when it's off, which is just wildly interesting. Second, if you

788
00:47:45,525 --> 00:47:48,325
Speaker 3:  actually put a frame on it, you destroy the functionality of a Frame tv.

789
00:47:48,645 --> 00:47:51,685
Speaker 3:  This is a true thing that I will talk about at length. 'cause it blocks all

790
00:47:51,685 --> 00:47:52,405
Speaker 3:  the sensors in the front.

791
00:47:52,835 --> 00:47:56,245
Speaker 5:  Neli has assigned like a half dozen stories investigating the Frame tv, what

792
00:47:56,245 --> 00:47:57,285
Speaker 5:  went wrong with his frame tv.

793
00:47:57,965 --> 00:48:01,885
Speaker 3:  I think a tech product that is a bad TV that kind of

794
00:48:01,885 --> 00:48:03,925
Speaker 3:  doesn't work when you do what you're supposed to do with it and is still

795
00:48:03,925 --> 00:48:07,805
Speaker 3:  the bestselling tech product and category is a fat, like is

796
00:48:07,805 --> 00:48:11,525
Speaker 3:  a cultural object. Yeah. We should just think about that more. Totally agree.

797
00:48:11,795 --> 00:48:15,205
Speaker 4:  It's kind of like what happened was for a long time when they were making

798
00:48:15,215 --> 00:48:18,925
Speaker 4:  technology for like going in the homes, they wanted it to make it look cool

799
00:48:18,945 --> 00:48:22,515
Speaker 4:  and like, or they wanted to make it look like it was meant for anyone

800
00:48:22,815 --> 00:48:25,475
Speaker 4:  and not be scary. That's why they had all the wood paneling and stuff like

801
00:48:25,475 --> 00:48:28,595
Speaker 4:  that. Yeah. And then one day they were like, oh, we can just go like balls

802
00:48:28,595 --> 00:48:31,875
Speaker 4:  to the wall, do whatever we want, like do our spec wars,

803
00:48:32,415 --> 00:48:35,395
Speaker 4:  get to 10 80 hertz. We can do all of that and have fun with it and not worry

804
00:48:35,395 --> 00:48:37,995
Speaker 4:  about the design factor. And now they're starting to realize like they're

805
00:48:38,035 --> 00:48:41,435
Speaker 4:  starting to hit a lot of those limits on like, on a lot of the technology.

806
00:48:41,455 --> 00:48:44,355
Speaker 4:  And so they're like, okay, what do we have left? Oh, we can actually make

807
00:48:44,355 --> 00:48:45,315
Speaker 4:  it not look like garbage.

808
00:48:45,865 --> 00:48:48,395
Speaker 5:  Yeah. Well there's such a, there's such an interesting

809
00:48:49,065 --> 00:48:52,675
Speaker 5:  philosophical shift underneath what you just described too, right? Because

810
00:48:52,675 --> 00:48:56,315
Speaker 5:  we, we went through this whole long phase where technology was exciting because

811
00:48:56,315 --> 00:48:59,235
Speaker 5:  it was technology, right? And you kind of wanted the things in your life

812
00:48:59,235 --> 00:49:03,115
Speaker 5:  to scream technology. Yeah. And I feel like we are headed into

813
00:49:03,115 --> 00:49:07,075
Speaker 5:  something very different from that that is going to be like, technology

814
00:49:07,175 --> 00:49:10,715
Speaker 5:  is not supposed to be everywhere and

815
00:49:10,775 --> 00:49:14,475
Speaker 5:  scream its name in my face all the time. It's supposed to like blend

816
00:49:14,625 --> 00:49:18,555
Speaker 5:  into my life and surroundings. And I think like if that's this next generation

817
00:49:18,575 --> 00:49:22,515
Speaker 5:  and the design is sort of the leader of that, it's gonna change a lot

818
00:49:22,515 --> 00:49:24,875
Speaker 5:  of things in really interesting ways. But I think you're right. I think that

819
00:49:24,935 --> 00:49:28,835
Speaker 5:  is at least where a lot of people are pushing us right

820
00:49:28,835 --> 00:49:31,835
Speaker 5:  now is out of this thing where it's like everything I have looks more and

821
00:49:31,835 --> 00:49:34,715
Speaker 5:  more like a gadget and my house just becomes one big gadget to like, I have

822
00:49:34,715 --> 00:49:37,875
Speaker 5:  more gadgets but they don't show themselves the same way. Yeah. Well

823
00:49:37,875 --> 00:49:41,035
Speaker 4:  We're seeing it too in like how, how people are moving that into different

824
00:49:41,035 --> 00:49:44,915
Speaker 4:  spaces in their house, right? Like, like the, the office is not in the

825
00:49:44,915 --> 00:49:47,915
Speaker 4:  kitchen, it's not in the dining room. Generally speaking, it's often a room.

826
00:49:48,135 --> 00:49:51,915
Speaker 4:  The home theater is another one, like most people's home theaters probably

827
00:49:51,925 --> 00:49:55,355
Speaker 4:  isn't the same room where they do other just like hanging out stuff. It's

828
00:49:55,475 --> 00:49:59,235
Speaker 4:  probably cool and dark and I wanna own every, like all $10,000 worth of

829
00:49:59,235 --> 00:49:59,515
Speaker 4:  equipment.

830
00:49:59,515 --> 00:50:01,195
Speaker 5:  Do you have one of those in your dorm room also?

831
00:50:01,835 --> 00:50:03,635
Speaker 4:  I will, I will when I go back to school.

832
00:50:03,865 --> 00:50:06,355
Speaker 3:  Okay, cool. No, the, the theater thing is really interesting and I'm sure

833
00:50:06,355 --> 00:50:09,875
Speaker 3:  we'll see this at CSS a bunch. This is why Soundbars exist as a

834
00:50:10,195 --> 00:50:13,955
Speaker 3:  category. Yeah. 'cause people didn't wanna put five speakers in their house.

835
00:50:14,455 --> 00:50:17,675
Speaker 3:  Now if you're me, you wanna put 12 speakers in there. So that's a very different

836
00:50:17,955 --> 00:50:21,355
Speaker 3:  approach. But most people are like, no, what about one inconspicuous black

837
00:50:21,355 --> 00:50:25,315
Speaker 3:  bar under the tv? That sounds good. Leave everything else out. And that more

838
00:50:25,315 --> 00:50:28,365
Speaker 3:  or less one. The thing you're talking about David, is what we used to call

839
00:50:28,365 --> 00:50:32,325
Speaker 3:  like the ambient computer. Like several years ago, this was the theme that

840
00:50:32,345 --> 00:50:34,765
Speaker 3:  the computers would disappear on the walls and we would just like talk to

841
00:50:34,765 --> 00:50:38,445
Speaker 3:  Alexa. And that really didn't play out. And

842
00:50:38,645 --> 00:50:42,245
Speaker 3:  I think the twist here that is interesting, and again, this is just one 500

843
00:50:42,335 --> 00:50:46,325
Speaker 3:  lumen projector, but the twist here that is interesting is that things are

844
00:50:46,525 --> 00:50:50,205
Speaker 3:  designed to be seen. Yeah. Right? They're, they're designed to be beautiful

845
00:50:50,205 --> 00:50:53,645
Speaker 3:  objects. And because you can take the smartphone

846
00:50:53,785 --> 00:50:57,685
Speaker 3:  supply chain and say, okay, now your computer monitor also has its

847
00:50:57,685 --> 00:51:01,125
Speaker 3:  own operating system and its own arm processor. And also

848
00:51:01,785 --> 00:51:05,405
Speaker 3:  by the way, it's like easier to, to get a bunch of streaming services on

849
00:51:05,405 --> 00:51:09,045
Speaker 3:  this weird custom computer than on your desktop computer. Yep. So we'll just

850
00:51:09,045 --> 00:51:12,845
Speaker 3:  like run it over here or we can make a little projector or whatever

851
00:51:12,865 --> 00:51:16,165
Speaker 3:  we, we want to do. Using all these commodity smartphone pieces,

852
00:51:16,665 --> 00:51:19,965
Speaker 3:  you're seeing more technology, more complete computers put into different

853
00:51:19,965 --> 00:51:23,805
Speaker 3:  things as like single purpose things that actually

854
00:51:23,805 --> 00:51:27,685
Speaker 3:  work well. And that lets you get to the design element of it. Whereas before,

855
00:51:27,845 --> 00:51:31,325
Speaker 3:  I think the idea of putting a computer in anything

856
00:51:32,285 --> 00:51:36,125
Speaker 3:  required, like an awful lot of computer. Yes. Yeah. And that

857
00:51:36,125 --> 00:51:38,645
Speaker 3:  made everything ugly. And that now all that stuff is just teeny tiny and

858
00:51:38,645 --> 00:51:40,965
Speaker 3:  small and cheap because we've had smartphones for so long.

859
00:51:41,555 --> 00:51:44,045
Speaker 5:  Yeah. I think that's right. And I think we're gonna see a ton of that at

860
00:51:44,065 --> 00:51:45,685
Speaker 5:  CES, including some of the stuff we've seen already

861
00:51:45,865 --> 00:51:49,565
Speaker 3:  All. right. So let's wrap up this little CES previous segment by doing a

862
00:51:49,625 --> 00:51:53,195
Speaker 3:  CES lightning round. Then the third segment will just be a regular, none

863
00:51:53,195 --> 00:51:56,235
Speaker 3:  of these are never quick. I don't know why we pretend it's lightning. Please

864
00:51:56,235 --> 00:51:58,955
Speaker 3:  buy the lightning round. Someone show up.

865
00:52:00,055 --> 00:52:03,915
Speaker 3:  You can have it. We'll rename it for you. It's fine. This is the one thing

866
00:52:03,915 --> 00:52:07,475
Speaker 3:  where I will abandon my journalistic ethics and just sell, sell, sell

867
00:52:07,775 --> 00:52:08,795
Speaker 4:  The Samsung frame land.

868
00:52:08,795 --> 00:52:12,475
Speaker 3:  You tell me. Yeah. The whatever kind of refrigerator you want me to hawk.

869
00:52:13,375 --> 00:52:16,555
Speaker 3:  You got it. What's that weird brand that just makes the retro fridges? You

870
00:52:16,555 --> 00:52:17,315
Speaker 3:  want the lightning round?

871
00:52:18,095 --> 00:52:18,315
Speaker 4:  Seg

872
00:52:19,445 --> 00:52:22,605
Speaker 3:  Smeg, lightning rounds ground Chilled by Smeg.

873
00:52:24,705 --> 00:52:28,645
Speaker 3:  You got it. Oh boy. Anything, just show up. His name is Andrew Ze.

874
00:52:28,645 --> 00:52:32,525
Speaker 3:  He's our, he's our, he's our director of like network integrations or whatever.

875
00:52:32,545 --> 00:52:36,125
Speaker 3:  Its, you just talk to him. He'll, he'll write him a check. He got you. He'll

876
00:52:36,125 --> 00:52:38,325
Speaker 3:  say whatever you want. All, right? Alex, what's your CS line?

877
00:52:39,825 --> 00:52:43,325
Speaker 4:  So this one is, they announced it before CES. They're gonna show 'em off

878
00:52:43,545 --> 00:52:47,445
Speaker 4:  at CES, but Dell has redone the whole XPS

879
00:52:47,445 --> 00:52:51,405
Speaker 4:  lineup. The XPS 13 plus has gone away. but it is

880
00:52:51,405 --> 00:52:51,765
Speaker 4:  also, which is also

881
00:52:52,045 --> 00:52:52,485
Speaker 5:  'cause it's sucked,

882
00:52:52,825 --> 00:52:56,765
Speaker 4:  But it is also technically the, the new XPS 13.

883
00:52:56,985 --> 00:53:00,815
Speaker 4:  It, it's using a lot of the same stuff. But then they've,

884
00:53:00,815 --> 00:53:04,775
Speaker 4:  they've gotten rid of the 15 inch and the 17 inch. Those will both

885
00:53:04,775 --> 00:53:07,815
Speaker 4:  still be around, you'll still be able to buy the old version for a while,

886
00:53:07,815 --> 00:53:11,175
Speaker 4:  but they're not gonna be doing big upgrades to it. And instead you're getting

887
00:53:11,255 --> 00:53:15,095
Speaker 4:  a 14 and a 16 inch. And the 14 inch I'm

888
00:53:15,255 --> 00:53:18,935
Speaker 4:  really excited about because it's only like a pound more than the 13

889
00:53:18,965 --> 00:53:22,735
Speaker 4:  inch, which I don't carry my computer everywhere, so that's not bad for me.

890
00:53:23,235 --> 00:53:27,045
Speaker 4:  It gets you like a much larger battery. I think it goes up to 69.5 watts

891
00:53:27,045 --> 00:53:30,965
Speaker 4:  per hour versus the previous one, which was 55 watts

892
00:53:30,965 --> 00:53:34,845
Speaker 4:  per hour. And it gets you discrete graphics and that's just really

893
00:53:35,045 --> 00:53:38,685
Speaker 4:  exciting. And also there's a little tiny copilot button, but they like

894
00:53:38,925 --> 00:53:41,995
Speaker 4:  hadn't figured out the rounding. Yeah.

895
00:53:41,995 --> 00:53:44,155
Speaker 3:  This is one of the funniest pictures we have ever run

896
00:53:44,705 --> 00:53:45,835
Speaker 4:  With the just little sticker.

897
00:53:46,135 --> 00:53:47,235
Speaker 3:  The sticker on the carpi.

898
00:53:47,305 --> 00:53:49,955
Speaker 4:  Yeah. They hadn't figured out. They, they like, they didn't get the, they

899
00:53:49,955 --> 00:53:53,235
Speaker 4:  they, they didn't get it until the last minute. And so they're like, okay

900
00:53:53,585 --> 00:53:55,275
Speaker 4:  sticker. We already made these laptops.

901
00:53:56,845 --> 00:53:57,995
Speaker 4:  Boops. Thanks. Thanks Microsoft.

902
00:53:58,875 --> 00:54:01,195
Speaker 3:  The sticker's a little fuzzy. It, everything about this picture is perfect.

903
00:54:01,395 --> 00:54:03,955
Speaker 4:  I love it. Thank you Amelia for taking beautiful photos. Yeah,

904
00:54:03,955 --> 00:54:07,835
Speaker 5:  It's just, it's just, what is this the, is this the menu button that they

905
00:54:07,835 --> 00:54:10,515
Speaker 5:  just literally put a little sticker over with the

906
00:54:10,515 --> 00:54:14,075
Speaker 4:  Co-pilot and now I'll go co-pilot, which just, it really, I know everybody's

907
00:54:14,075 --> 00:54:17,235
Speaker 4:  very excited about the co-pilot button, but for me Maybe, it was because

908
00:54:17,275 --> 00:54:20,955
Speaker 4:  I first experienced it with the Dell XPS, I had big like

909
00:54:21,145 --> 00:54:21,955
Speaker 4:  Cortana vibes.

910
00:54:22,915 --> 00:54:26,525
Speaker 3:  Yeah, yeah. I mean look, this is the dream for Microsoft, right? Yeah. It's

911
00:54:26,525 --> 00:54:29,765
Speaker 3:  like there's a button, an assistant shows up, you ask at some things

912
00:54:30,275 --> 00:54:33,325
Speaker 3:  that lies to your face and tries to bang you and move on with your day.

913
00:54:33,995 --> 00:54:36,685
Speaker 3:  That was the original Pitch for Clippy. Clippy

914
00:54:36,705 --> 00:54:37,805
Speaker 5:  Clippy tries to bang you.

915
00:54:38,355 --> 00:54:40,925
Speaker 4:  Yeah. don don't want that Could be get away. Yeah.

916
00:54:40,925 --> 00:54:42,085
Speaker 5:  That's somehow worse.

917
00:54:43,055 --> 00:54:43,685
Speaker 4:  Those eyes,

918
00:54:45,385 --> 00:54:48,045
Speaker 3:  The fact that I keep insisting that Bing is trying to bang you, they haven't

919
00:54:48,045 --> 00:54:50,765
Speaker 3:  said a word to me about it, is like very funny

920
00:54:50,825 --> 00:54:52,805
Speaker 5:  To me. Yeah. The silence is deafening Microsoft,

921
00:54:53,795 --> 00:54:54,285
Speaker 3:  They're

922
00:54:54,285 --> 00:54:54,525
Speaker 4:  Gonna get

923
00:54:54,525 --> 00:54:58,285
Speaker 3:  You for click. Not one email, not one text, not one LinkedIn

924
00:54:58,365 --> 00:55:01,725
Speaker 3:  message from some aggrieved Bing product manager. They're just like, yeah,

925
00:55:01,725 --> 00:55:03,685
Speaker 3:  definitely tried to bang a bunch of people did.

926
00:55:03,705 --> 00:55:03,925
Speaker 5:  Did

927
00:55:04,395 --> 00:55:04,965
Speaker 4:  Sure did.

928
00:55:05,825 --> 00:55:06,685
Speaker 3:  All right. David, what do you

929
00:55:06,685 --> 00:55:10,605
Speaker 5:  Got? Mine is, and I have, I literally have to load the page so

930
00:55:10,605 --> 00:55:13,445
Speaker 5:  that I can tell you the name because the name just breaks my heart every

931
00:55:13,445 --> 00:55:17,285
Speaker 5:  time I say it out loud. The Samsung 2024

932
00:55:17,355 --> 00:55:21,245
Speaker 5:  bespoke four-door Flex Refrigerator with AI Family Hub Plus. Yes.

933
00:55:21,265 --> 00:55:25,085
Speaker 5:  Yes. Which is the Samsung iest thing to ever Samsung.

934
00:55:25,945 --> 00:55:29,925
Speaker 5:  It is Samsung's new smart fridge. I love, love,

935
00:55:30,115 --> 00:55:33,805
Speaker 5:  love that Samsung is all in on smart fridges. Like this company

936
00:55:33,955 --> 00:55:37,885
Speaker 5:  will not abandon the idea that your fridge

937
00:55:38,145 --> 00:55:41,445
Speaker 5:  should be the biggest and most important screen in your house.

938
00:55:41,945 --> 00:55:44,525
Speaker 5:  And I think that rules, and I hope it never changes.

939
00:55:46,985 --> 00:55:50,125
Speaker 5:  So, and like, and, and I actually think like, I have two thoughts about this.

940
00:55:50,225 --> 00:55:54,215
Speaker 5:  One is that we're going to see just, just

941
00:55:54,855 --> 00:55:58,655
Speaker 5:  infinite gadgets at CES that are just gadget plus chat. GPT

942
00:55:58,805 --> 00:56:02,615
Speaker 5:  like name a thing plus chat, GPT. And they'll be like, is this anything?

943
00:56:02,955 --> 00:56:06,175
Speaker 5:  And I'll just be wandering through the Venetian being like, that's nothing.

944
00:56:06,475 --> 00:56:10,375
Speaker 5:  That's nothing. That's nothing. You can't just put chat GPT in it. That's

945
00:56:10,375 --> 00:56:14,215
Speaker 5:  still, it's still nothing. But then the other thing is going to be

946
00:56:14,815 --> 00:56:18,455
Speaker 5:  companies that are further ahead of the game trying to figure out

947
00:56:18,645 --> 00:56:22,295
Speaker 5:  what cool stuff you can actually do with some of these

948
00:56:22,985 --> 00:56:26,325
Speaker 5:  AI tools. And Samsung has been doing this for a while. It's had some

949
00:56:26,785 --> 00:56:30,405
Speaker 5:  fun slash bizarre ideas about what you can do with a camera

950
00:56:30,545 --> 00:56:33,565
Speaker 5:  inside of your fridge. And this one in particular,

951
00:56:34,385 --> 00:56:38,365
Speaker 5:  it uses a camera inside of your fridge to not just figure out what you

952
00:56:38,365 --> 00:56:42,285
Speaker 5:  have, but to help you identify recipes that you can cook

953
00:56:42,515 --> 00:56:46,365
Speaker 5:  with what you have in the fridge. Which for me is like the dream, right?

954
00:56:46,365 --> 00:56:49,485
Speaker 5:  It's like you wanna open it up and be like, okay, I have, I have broccoli

955
00:56:49,505 --> 00:56:53,325
Speaker 5:  and pasta and a half a thing of Worcestershire sauce. Like what can I make

956
00:56:53,325 --> 00:56:56,725
Speaker 5:  for dinner? And it'll just tell you that's like, that is, if you

957
00:56:56,725 --> 00:57:00,165
Speaker 3:  Can't figure out what to do with broccoli and pasta and Worcester around

958
00:57:00,285 --> 00:57:03,405
Speaker 3:  here, you mix the broccoli with the pasta and you set the wors syrup aside,

959
00:57:04,335 --> 00:57:04,685
Speaker 3:  throw

960
00:57:04,685 --> 00:57:06,085
Speaker 5:  The worre sauce, you

961
00:57:06,085 --> 00:57:09,725
Speaker 3:  Drizzle it on. You're like, not today. Weird sauce.

962
00:57:12,905 --> 00:57:13,125
Speaker 3:  No,

963
00:57:13,125 --> 00:57:14,405
Speaker 5:  That's, I mean you

964
00:57:14,405 --> 00:57:18,005
Speaker 3:  Should, I can, I can. I just, I like, I I support your dream. I can I just

965
00:57:18,005 --> 00:57:21,725
Speaker 3:  point out the most hilarious limitation of the dream as expressed

966
00:57:22,345 --> 00:57:26,045
Speaker 3:  in this refrigerator. Sure. The AI camera can only recognize

967
00:57:26,045 --> 00:57:29,965
Speaker 3:  33 different systems. Yeah. So if, if you were just like

968
00:57:30,085 --> 00:57:33,845
Speaker 3:  a little bit out of Samsung strike zone of 33 foods it

969
00:57:33,845 --> 00:57:36,365
Speaker 3:  knows about, it's like don don't know man, you're on your own.

970
00:57:36,995 --> 00:57:40,965
Speaker 5:  Just one small clarification. It can, it can identify up to 33

971
00:57:40,965 --> 00:57:41,405
Speaker 5:  food, I

972
00:57:41,405 --> 00:57:41,525
Speaker 3:  Guess

973
00:57:43,945 --> 00:57:45,325
Speaker 3:  33 is the dream.

974
00:57:46,195 --> 00:57:48,005
Speaker 5:  Does it have to be like specific brands?

975
00:57:50,595 --> 00:57:54,445
Speaker 3:  Yeah. That unclear. I will say the touchscreen has a, a TikTok

976
00:57:54,545 --> 00:57:57,605
Speaker 3:  app and a YouTube app. Oh, that's what I mean. And standing in front of your

977
00:57:57,605 --> 00:57:59,085
Speaker 3:  fridge scrolling TikTok videos

978
00:58:00,725 --> 00:58:04,685
Speaker 3:  actually kind of amazing. Like honestly kind of an like, I'm

979
00:58:04,685 --> 00:58:06,605
Speaker 3:  gonna go try to have that experience. I mean,

980
00:58:07,185 --> 00:58:09,605
Speaker 5:  How have you, have you never done the thing where there's something in the

981
00:58:09,605 --> 00:58:12,405
Speaker 5:  microwave for 60 seconds and you're like, oh, I'm just gonna look at four

982
00:58:12,475 --> 00:58:14,645
Speaker 5:  tiktoks while I do this. You could do that on your fridge. Yeah.

983
00:58:14,645 --> 00:58:18,005
Speaker 3:  The screen's huge. And the way that I'm gonna choose to express that desire

984
00:58:18,345 --> 00:58:21,765
Speaker 3:  is not by pulling out my $1,500 state-of-the-art phone.

985
00:58:23,235 --> 00:58:25,565
Speaker 3:  It's by using the computer in my fridge.

986
00:58:26,275 --> 00:58:27,525
Speaker 5:  Yeah. I don't see what the problem is.

987
00:58:28,545 --> 00:58:32,405
Speaker 3:  By the way. Deciding who in the family gets to determine the TikTok algorithm

988
00:58:32,625 --> 00:58:36,485
Speaker 3:  or even the TikTok account loaded onto the refrigerator.

989
00:58:37,265 --> 00:58:40,165
Speaker 5:  Who the fridge. I think you gotta give the fridge its own algorithm. Yeah.

990
00:58:40,185 --> 00:58:41,405
Speaker 5:  If the fridge gets its own account, I think

991
00:58:41,405 --> 00:58:42,365
Speaker 3:  Fridge gets its own. Yeah.

992
00:58:45,085 --> 00:58:48,785
Speaker 3:  That's like the truly one of the most dangerous and destabilizing pieces

993
00:58:48,845 --> 00:58:52,745
Speaker 3:  of technology you can introduce them to. Any family is

994
00:58:53,055 --> 00:58:56,865
Speaker 3:  full-size TikTok on the fridge and you're like, whose account

995
00:58:57,125 --> 00:59:00,305
Speaker 3:  is gonna sign into this TikTok? I don't know about that.

996
00:59:00,935 --> 00:59:02,025
Speaker 5:  It's a lot of trust. I

997
00:59:02,205 --> 00:59:06,185
Speaker 3:  Our, we have an LG by the way. LG has a, a smart platform called Think,

998
00:59:06,355 --> 00:59:10,225
Speaker 3:  think Q that looks exactly like smart things. I know everyone

999
00:59:10,345 --> 00:59:14,305
Speaker 3:  always wants to dunk on Xiaomi and Huawei for exactly copying iOS.

1000
00:59:14,485 --> 00:59:17,985
Speaker 3:  The fact that LG and Samsung have exactly copied their bad smart home

1001
00:59:17,985 --> 00:59:21,925
Speaker 3:  experiences. Very funny. Very funny. So we now

1002
00:59:21,925 --> 00:59:24,725
Speaker 3:  have a thank you microwave and a thank you fridge.

1003
00:59:25,745 --> 00:59:29,565
Speaker 3:  The microwave will send you a notification when it is done, which is

1004
00:59:29,785 --> 00:59:33,275
Speaker 3:  the least useful notification in the world. Because

1005
00:59:34,255 --> 00:59:37,915
Speaker 3:  how long, like getting a notification on your phone for something that you've

1006
00:59:37,915 --> 00:59:39,755
Speaker 3:  set for a minute, it's like not useful.

1007
00:59:39,835 --> 00:59:42,315
Speaker 4:  People used to roast turkeys in 'em. Maybe, maybe you're

1008
00:59:42,315 --> 00:59:42,395
Speaker 3:  Roast

1009
00:59:42,595 --> 00:59:44,835
Speaker 5:  A, a Turkey, turn your microwave and just sprint out the front door.

1010
00:59:45,425 --> 00:59:46,555
Speaker 3:  Yeah, I'm out. I'm gone.

1011
00:59:49,455 --> 00:59:53,395
Speaker 3:  You ours is over our stove. So you can also tell whatever voice

1012
00:59:53,395 --> 00:59:57,235
Speaker 3:  assistant to turn on the light and the fan. And my wife was like, but

1013
00:59:57,235 --> 00:59:58,235
Speaker 3:  the button is right there.

1014
01:00:00,115 --> 01:00:03,795
Speaker 3:  And then our refrigerator will not send me notifications for when it thinks

1015
01:00:03,795 --> 01:00:07,525
Speaker 3:  our ice is too old. And it's like, throw away your ice. And I've,

1016
01:00:07,555 --> 01:00:10,125
Speaker 3:  I've never even considered this before. And I don dunno why I have any of

1017
01:00:10,125 --> 01:00:13,445
Speaker 3:  these notifications turned on or why I've even connected any of these devices

1018
01:00:13,665 --> 01:00:15,205
Speaker 3:  to the internet. To the begin. Wait, I've,

1019
01:00:15,305 --> 01:00:17,125
Speaker 5:  Are you supposed to throw away your ice?

1020
01:00:17,355 --> 01:00:19,125
Speaker 4:  Yeah. I was like quietly Googling

1021
01:00:19,765 --> 01:00:23,125
Speaker 3:  Straight up. I got a notification. It's like, it's been seven days.

1022
01:00:23,745 --> 01:00:25,965
Speaker 3:  Please discard your ice so we can make you fresh ice

1023
01:00:26,255 --> 01:00:29,965
Speaker 5:  Seven days. And if you had said a year, I would've been like, oh, I've never,

1024
01:00:30,035 --> 01:00:31,125
Speaker 5:  I've still never done that. Like,

1025
01:00:31,345 --> 01:00:35,165
Speaker 3:  So our old fridge didn't have an ice maker. So. I, you know, I, we

1026
01:00:35,165 --> 01:00:38,525
Speaker 3:  bought the most ice maker. It can make four kinds of ice. My good man.

1027
01:00:39,545 --> 01:00:42,885
Speaker 3:  And I was like, what a luxury. And then it turns out we don't use ice.

1028
01:00:44,065 --> 01:00:47,645
Speaker 3:  So now I just have like a fridge full of ice and the fridge is like, get

1029
01:00:47,645 --> 01:00:50,525
Speaker 3:  this ice outta me. And that is the relationship I have with technology. Now

1030
01:00:50,525 --> 01:00:54,165
Speaker 5:  Listen, if you aren't listening to this and you know, if you're supposed

1031
01:00:54,205 --> 01:00:57,725
Speaker 5:  to replace your ice every seven days, please email us Vergecast at The Verge

1032
01:00:57,745 --> 01:01:01,445
Speaker 5:  dot com. If you're an expert on ice replacement situations in

1033
01:01:01,445 --> 01:01:03,605
Speaker 5:  fridges. I need to know this please.

1034
01:01:04,325 --> 01:01:06,005
Speaker 3:  I think LG is in the pocket of big one.

1035
01:01:06,005 --> 01:01:07,645
Speaker 5:  That's what I, that's where I'm at right now.

1036
01:01:08,315 --> 01:01:11,205
Speaker 3:  Yeah. And it's also someone who's been installing a lot of new smart lights

1037
01:01:11,445 --> 01:01:14,485
Speaker 3:  switches. I think Lutron is in the pocket of big wire nut. Oh yeah. Because

1038
01:01:14,505 --> 01:01:17,445
Speaker 3:  God bless the Lutron switch. But that's a lot of wire nuts.

1039
01:01:18,385 --> 01:01:21,245
Speaker 3:  You're just packing 'em in that box and screwing it tight.

1040
01:01:24,865 --> 01:01:25,885
Speaker 4:  What's your lightning round?

1041
01:01:26,425 --> 01:01:29,965
Speaker 3:  So mine is the TV stuff. We're getting some glimmers of the TV stuff.

1042
01:01:31,635 --> 01:01:35,325
Speaker 3:  There's two trends that I think are really interesting in TVs this year.

1043
01:01:36,105 --> 01:01:39,275
Speaker 3:  One, they're bringing AI to settings.

1044
01:01:39,935 --> 01:01:43,775
Speaker 3:  So actually if you go back years now, AI has

1045
01:01:43,775 --> 01:01:46,855
Speaker 3:  been at CS for years because every TV company is like, look at our AI pic

1046
01:01:46,855 --> 01:01:50,255
Speaker 3:  picture processing and upscaling. Like they've been talking about it forever

1047
01:01:50,275 --> 01:01:53,175
Speaker 3:  and ever and ever. And everyone's like, haha, AI in this year it's gonna

1048
01:01:53,175 --> 01:01:56,975
Speaker 3:  be outta control because now the AI can can lie to you.

1049
01:01:57,315 --> 01:02:00,335
Speaker 3:  But they've been doing AI and upscaling for years and years and years to

1050
01:02:00,335 --> 01:02:04,255
Speaker 3:  get, you know, to upscale your horrible seven 20 P Fox NFL broadcast

1051
01:02:04,255 --> 01:02:08,215
Speaker 3:  to 4K. They've applied a lot of AI to that at the panel level. So they're

1052
01:02:08,215 --> 01:02:11,055
Speaker 3:  gonna do more and more of that this year. The thing that they're all doing

1053
01:02:11,915 --> 01:02:14,735
Speaker 3:  is they're applying it to settings. So they're gonna say, okay, we are gonna

1054
01:02:15,055 --> 01:02:18,565
Speaker 3:  recognize your content and adjust to the settings of the tv.

1055
01:02:19,145 --> 01:02:22,205
Speaker 3:  So you won't have to switch between game mode and cinema mode or whatever.

1056
01:02:22,735 --> 01:02:25,965
Speaker 3:  We'll recognize, okay, you're playing a video game, we're gonna switch you

1057
01:02:25,965 --> 01:02:29,725
Speaker 3:  to the highest refresh rate. Lowest latency of the whole thing. Okay.

1058
01:02:29,725 --> 01:02:33,405
Speaker 3:  You're watching a movie that's Tom Cruise's face. We're gonna put you in

1059
01:02:33,425 --> 01:02:36,725
Speaker 3:  Tom Cruise mode. We, which is fascinating. They should have done this.

1060
01:02:36,955 --> 01:02:38,205
Speaker 5:  Yeah, that's a good idea. Wait,

1061
01:02:38,465 --> 01:02:41,845
Speaker 4:  But why does that require ai? Couldn't that just require

1062
01:02:41,955 --> 01:02:44,165
Speaker 4:  acknowledging that you've changed inputs

1063
01:02:45,185 --> 01:02:48,005
Speaker 3:  You, well you can already do input level settings, but if you have Yeah,

1064
01:02:48,005 --> 01:02:51,865
Speaker 3:  if your input level setting is like an Xbox, knowing

1065
01:02:51,935 --> 01:02:55,025
Speaker 3:  what kind of content is coming outta the Xbox, actually. Okay. Really hard,

1066
01:02:55,195 --> 01:02:58,825
Speaker 3:  right? Like the Xbox either needs to communicate with the tv, which

1067
01:02:59,115 --> 01:03:01,025
Speaker 3:  given the state of HMI seems unlikely. Yeah.

1068
01:03:01,025 --> 01:03:04,825
Speaker 5:  What was the name of that thing? That the, the box that had all the inputs

1069
01:03:04,825 --> 01:03:08,545
Speaker 5:  that pr, the cavo, that was the, one of the things it tried to do

1070
01:03:08,685 --> 01:03:12,425
Speaker 5:  was figure out what you're watching and actually like to

1071
01:03:12,525 --> 01:03:15,825
Speaker 5:  the experience based on literally the content on the screen.

1072
01:03:16,855 --> 01:03:20,225
Speaker 3:  Yeah. The cavo is different 'cause it was a universal remote. So its whole

1073
01:03:20,275 --> 01:03:23,985
Speaker 3:  Pitch was like, you tell us what you want and we'll know what you have

1074
01:03:24,405 --> 01:03:27,865
Speaker 3:  and we'll deliver that. Like we'll click around the Apple TV interface for

1075
01:03:27,865 --> 01:03:31,305
Speaker 3:  you's. Right. And because it was machine learning, it wouldn't be brittle.

1076
01:03:31,455 --> 01:03:35,385
Speaker 3:  Like if you wanna do a most universal or most, if you wanna do

1077
01:03:35,385 --> 01:03:38,825
Speaker 3:  a macro, you're like, okay, press power, wait four seconds, click right.

1078
01:03:38,825 --> 01:03:41,985
Speaker 3:  Three times wait. You know, like, and that is all inherently brittle and

1079
01:03:41,985 --> 01:03:45,025
Speaker 3:  broken. The Cavo is like, we will look at the screen and we'll make sure

1080
01:03:45,025 --> 01:03:48,225
Speaker 3:  we're gonna click on the Hulu app. We'll click on the Hulu app, we'll see

1081
01:03:48,225 --> 01:03:52,035
Speaker 3:  what's on the screen. We'll find the thing you want. It did not work.

1082
01:03:52,035 --> 01:03:55,195
Speaker 3:  That company pivoted to selling video conferencing solutions for nursing

1083
01:03:55,195 --> 01:03:58,995
Speaker 3:  homes. This is a true story, but the idea that you can recognize

1084
01:03:58,995 --> 01:04:01,955
Speaker 3:  it's on the screen and take action on it. Kind of an old idea.

1085
01:04:02,835 --> 01:04:05,555
Speaker 3:  Advertising on Connected TVs has worked this way for a very long time.

1086
01:04:06,695 --> 01:04:10,435
Speaker 3:  Really weird stuff. But automatic a CR automatic content recognition

1087
01:04:10,535 --> 01:04:13,955
Speaker 3:  has been built into most panels for a long time. So the TV manufacturers

1088
01:04:13,955 --> 01:04:16,235
Speaker 3:  know what you're watching, they can sell ads against it, which isn't great.

1089
01:04:16,415 --> 01:04:19,475
Speaker 3:  And now they're gonna finally start doing a useful thing with that technology,

1090
01:04:20,075 --> 01:04:23,235
Speaker 3:  which is saying, okay, it's a movie. We're gonna put you in the best mode

1091
01:04:23,235 --> 01:04:26,995
Speaker 3:  for this movie. Roku is gonna announce new Roku Pro

1092
01:04:26,995 --> 01:04:30,595
Speaker 3:  mini LED TVs, they've got smart picture modes.

1093
01:04:31,085 --> 01:04:34,435
Speaker 3:  Their Pitch is 90% of people never change the settings on the tv. This will

1094
01:04:34,435 --> 01:04:37,875
Speaker 3:  help a lot of people. They're also Roku's gonna do mini L led d TVs. They're

1095
01:04:37,875 --> 01:04:41,235
Speaker 3:  gonna make higher end TVs that I think is really interesting. Mini LED is

1096
01:04:41,235 --> 01:04:44,755
Speaker 3:  gonna be everywhere at CS SU. Yeah. And then Sony is not gonna announce new

1097
01:04:44,975 --> 01:04:48,475
Speaker 3:  TVs. Sony is off the TV cycle at css, which is

1098
01:04:48,995 --> 01:04:52,755
Speaker 3:  fascinating. The Sony 8 95 quantum oled, that was

1099
01:04:52,755 --> 01:04:56,635
Speaker 3:  the flagship TV of last year, just hit in October. Oh geez. So Sony

1100
01:04:56,635 --> 01:04:59,955
Speaker 3:  is just way off this cycle. They're just doing whatever they want, but they

1101
01:05:00,125 --> 01:05:03,035
Speaker 3:  previewed. We've got a bunch of mini LED tech coming this year that's better

1102
01:05:03,035 --> 01:05:06,635
Speaker 3:  than before. So like they're still making CSS announcements, which

1103
01:05:06,875 --> 01:05:10,795
Speaker 3:  is fascinating. And then LG announced its next generation

1104
01:05:11,085 --> 01:05:14,835
Speaker 3:  of OLEDs kind of minor bumps from last year. But the, the big news is

1105
01:05:14,975 --> 01:05:18,405
Speaker 3:  MLA, its multiple lens array technology is gonna hit the 83 inch size and

1106
01:05:18,485 --> 01:05:22,325
Speaker 3:  the G three. And then they've got smaller versions of its

1107
01:05:22,325 --> 01:05:26,165
Speaker 3:  ones that are wireless, which means you plug all your stuff into a

1108
01:05:26,225 --> 01:05:28,365
Speaker 3:  box on the other side of your room, but you still have to plug your TV into

1109
01:05:28,365 --> 01:05:31,965
Speaker 3:  the wall. Which don don't know man. But so like sort of

1110
01:05:31,965 --> 01:05:35,725
Speaker 3:  iterative on the OLED side. And then I think huge strides in the mini

1111
01:05:35,845 --> 01:05:39,325
Speaker 3:  LED side, which is gonna be really interesting because many

1112
01:05:39,555 --> 01:05:43,125
Speaker 3:  LEDs are cheaper. They're just LCD screens with really, really advanced backlights.

1113
01:05:43,385 --> 01:05:46,845
Speaker 3:  But the backlights are getting simultaneously more advanced and more interesting

1114
01:05:47,145 --> 01:05:51,085
Speaker 3:  and cheaper. Right. So they're, they're gonna crash right into oed. So I

1115
01:05:51,085 --> 01:05:55,045
Speaker 3:  just bought an A 95. My thesis is that the TVs going on my

1116
01:05:55,045 --> 01:05:58,645
Speaker 3:  wall for like a decade. Spending money on a TV is actually a pretty good

1117
01:05:58,645 --> 01:06:02,525
Speaker 3:  investment. And I came this close to buying an

1118
01:06:02,565 --> 01:06:06,525
Speaker 3:  X 95. Like, so shout out to Val Electronics in Scarsdale.

1119
01:06:06,565 --> 01:06:10,365
Speaker 3:  I went, they had two calibrated Sony TVs like Cal not in retail mode, like

1120
01:06:10,805 --> 01:06:14,725
Speaker 3:  calibrated a 95 next to an X 95. A 95 is

1121
01:06:14,725 --> 01:06:18,525
Speaker 3:  the Oad X 95 is the mini LED. And I was like this

1122
01:06:18,525 --> 01:06:19,285
Speaker 3:  close to my next

1123
01:06:19,285 --> 01:06:20,725
Speaker 4:  95. What was, what were they playing on it?

1124
01:06:21,395 --> 01:06:24,605
Speaker 3:  They were playing some, you know, dark stereo

1125
01:06:24,605 --> 01:06:26,045
Speaker 5:  Story. I literally, I

1126
01:06:26,045 --> 01:06:27,485
Speaker 3:  Feel like, like look at this lizard. I want

1127
01:06:27,485 --> 01:06:31,125
Speaker 5:  Know a how many hours you spent standing between the two of them

1128
01:06:31,865 --> 01:06:35,285
Speaker 5:  and, and quit and like bouncing how close you got to one and then you'd walk

1129
01:06:35,285 --> 01:06:37,765
Speaker 5:  over the other like, did you bring a, did you bring a loop? Did you bring

1130
01:06:37,765 --> 01:06:41,565
Speaker 5:  a microscope? Like did you, did you bring your trusty Nikon

1131
01:06:41,575 --> 01:06:45,565
Speaker 5:  macro lens to take pictures of the pixels? Like they just closed and left

1132
01:06:45,565 --> 01:06:47,965
Speaker 5:  you in there overnight. They were like, we'll see you tomorrow, let us know.

1133
01:06:47,965 --> 01:06:51,245
Speaker 3:  Yeah. but it was like me alone in a dark store with like various

1134
01:06:51,425 --> 01:06:54,565
Speaker 3:  $30,000, like BW speakers,

1135
01:06:55,025 --> 01:06:58,805
Speaker 3:  hugely expensive. I was just like in heaven. And then this

1136
01:06:58,805 --> 01:07:01,685
Speaker 3:  store, they're the ones who run this thing on YouTube called the King of

1137
01:07:01,685 --> 01:07:04,685
Speaker 3:  tv. Shootouts been new here for like 20 years. And so like they calibrate

1138
01:07:04,685 --> 01:07:07,965
Speaker 3:  everything. It's like beautiful. Ugh, So I. Like, but I came this close my,

1139
01:07:07,965 --> 01:07:11,525
Speaker 3:  the next, it's the mini a d Tech is so close. It's like,

1140
01:07:11,675 --> 01:07:15,325
Speaker 3:  it's right there. And I think at CSS we're gonna see the next

1141
01:07:15,325 --> 01:07:17,925
Speaker 3:  evolution of it across a number of manufacturers. And then Sony's gonna show

1142
01:07:17,925 --> 01:07:21,205
Speaker 3:  us some more stuff this year. And the point I always make is if you pay attention

1143
01:07:21,265 --> 01:07:24,965
Speaker 3:  to displays, like one, it's fun. 'cause it's just a, it's a

1144
01:07:25,035 --> 01:07:28,765
Speaker 3:  stakeless spec war, right? Like, it's not like will

1145
01:07:28,765 --> 01:07:31,845
Speaker 3:  TikTok ruin democracy? You know, it's like will this display look sick or

1146
01:07:31,845 --> 01:07:35,485
Speaker 3:  not? Is like all you need to know. But if you keep

1147
01:07:35,975 --> 01:07:39,205
Speaker 3:  track of it, you can kind of tell what kind of devices we're gonna get a

1148
01:07:39,205 --> 01:07:42,765
Speaker 3:  few years down the line. Yeah. Right. Because the, the display is usually

1149
01:07:42,785 --> 01:07:45,885
Speaker 3:  the thing that limits the foreign factor of any device you're talking about.

1150
01:07:46,425 --> 01:07:49,845
Speaker 3:  And so TVs are where you kind of get the, the state of the artie, state of

1151
01:07:49,845 --> 01:07:53,045
Speaker 3:  the art and that stuff just trickles down to everything else. And I I, the

1152
01:07:53,045 --> 01:07:56,365
Speaker 3:  mini LED moment is like, we're right here.

1153
01:07:57,015 --> 01:08:00,405
Speaker 3:  We're spending the extra money in an OLED for a lot of people isn't gonna

1154
01:08:00,405 --> 01:08:02,285
Speaker 3:  be worth it. Ugh. Which I think is fascinating. That's

1155
01:08:02,285 --> 01:08:05,605
Speaker 4:  Gonna suck. I like to be smug about my oled.

1156
01:08:06,285 --> 01:08:09,645
Speaker 3:  I love, look, I just, I bought, I didn't buy the X 95, I bought the 8 95.

1157
01:08:09,645 --> 01:08:12,525
Speaker 3:  'cause I wanna, I wanna be smug. Yeah. I wanna look at that thing and just

1158
01:08:12,645 --> 01:08:14,165
Speaker 3:  feel a wave of smugness every time I look

1159
01:08:14,165 --> 01:08:16,300
Speaker 4:  At it. Like I need to know what, know what I'm gonna be smug about in four

1160
01:08:16,300 --> 01:08:16,780
Speaker 4:  to five years.

1161
01:08:17,145 --> 01:08:20,365
Speaker 3:  Here's what I'm smug about. I now have access to the world's most useless

1162
01:08:20,365 --> 01:08:21,885
Speaker 3:  streaming service. Bravia core.

1163
01:08:24,065 --> 01:08:26,365
Speaker 4:  You get the really good reds on Spider-Man though,

1164
01:08:26,505 --> 01:08:29,005
Speaker 3:  You get the really good reds, it's, it streams in pure stream. It streams

1165
01:08:29,005 --> 01:08:32,885
Speaker 3:  80 megabits per second on Bravia core. But you can stream four movies

1166
01:08:33,065 --> 01:08:34,445
Speaker 3:  and three of them are Spider-Man.

1167
01:08:38,705 --> 01:08:39,245
Speaker 3:  And as soon

1168
01:08:39,245 --> 01:08:42,365
Speaker 5:  As you turn it on Comcast calls and says, are you running a Bitcoin mine

1169
01:08:42,385 --> 01:08:42,925
Speaker 5:  out of your house?

1170
01:08:43,475 --> 01:08:47,365
Speaker 3:  Exactly. But one of the movies on Broadway Corps that had access

1171
01:08:47,365 --> 01:08:51,325
Speaker 3:  to, 'cause they changed the library all the time, was a remaster in IMAX

1172
01:08:51,345 --> 01:08:54,885
Speaker 3:  of the original Ghostbusters. And I was like, I'm in heaven.

1173
01:08:55,475 --> 01:08:58,685
Speaker 3:  Like this is a kind of, it was kind of like a bad 4K upscale. Like

1174
01:08:58,705 --> 01:09:01,325
Speaker 4:  You like see the pores, but they're weird looking. Yeah.

1175
01:09:01,325 --> 01:09:03,485
Speaker 3:  You know, there's like too much contrast. You were Alex what was the one

1176
01:09:03,485 --> 01:09:05,445
Speaker 3:  you were pointing out the other day? You, you quick posted about there was

1177
01:09:05,445 --> 01:09:07,045
Speaker 3:  something that just got upscaled and it looks really bad. Well, they're

1178
01:09:07,045 --> 01:09:10,045
Speaker 4:  Doing it a bunch with everything like YouTube. On YouTube right now, if you

1179
01:09:10,045 --> 01:09:13,685
Speaker 4:  go and look up an old trailer, almost all of them have been upscaled. Yeah.

1180
01:09:13,745 --> 01:09:16,645
Speaker 4:  And you're just like, oh, that's weird.

1181
01:09:17,125 --> 01:09:20,125
Speaker 3:  I sat and re-watched all of Ghostbusters in this bad upscale, I mean, it

1182
01:09:20,125 --> 01:09:23,845
Speaker 3:  looked in, it looked insane in some ways. Like just like two

1183
01:09:24,085 --> 01:09:26,165
Speaker 3:  contrasty. Like that's the thing I always catch with these bad upscales.

1184
01:09:26,165 --> 01:09:29,885
Speaker 3:  Like it's like two contrasty and some things like blown out in weird ways.

1185
01:09:30,025 --> 01:09:33,045
Speaker 3:  But then I was like, I'm reading the titles of the name tags

1186
01:09:33,995 --> 01:09:34,965
Speaker 4:  Because you can, this

1187
01:09:34,965 --> 01:09:38,325
Speaker 3:  Is a movie I watched a hundred times on VHS on a 13 inch screen. And I'm

1188
01:09:38,325 --> 01:09:41,565
Speaker 3:  like, look at, look at all those words that are on the screen.

1189
01:09:41,825 --> 01:09:43,685
Speaker 4:  How is Slimer beautiful?

1190
01:09:43,965 --> 01:09:47,925
Speaker 3:  I mean, you look no, like, parts of it are blurry. Like, 'cause you know,

1191
01:09:47,925 --> 01:09:51,885
Speaker 3:  the old lenses weren't perfectly sharp across Yeah. The whole frame.

1192
01:09:52,705 --> 01:09:55,605
Speaker 3:  And they were sh and like, you know, they sh a lot of that movie is shot

1193
01:09:55,605 --> 01:09:59,045
Speaker 3:  at night. So there's like a lot of film grain that's g getting re upscale.

1194
01:09:59,045 --> 01:10:02,805
Speaker 3:  Like none of this looked good. I do not think you should buy a Sony TV for

1195
01:10:02,805 --> 01:10:06,605
Speaker 3:  this experience. But in terms of things I am smug about

1196
01:10:06,605 --> 01:10:10,565
Speaker 3:  having had this experience because I own this TV very high on the list.

1197
01:10:11,595 --> 01:10:15,085
Speaker 3:  Like I need a shirt that's just like Bravia Stan. And everyone's like, what

1198
01:10:15,085 --> 01:10:18,885
Speaker 3:  are you watching? And I'm like, nothing Air Force one. I gotta

1199
01:10:18,885 --> 01:10:19,085
Speaker 3:  go

1200
01:10:20,905 --> 01:10:23,325
Speaker 4:  Got rid of your Netflix account years ago. Yeah.

1201
01:10:23,425 --> 01:10:26,445
Speaker 3:  I'm watching four movies on Bravia court. Meanwhile,

1202
01:10:26,485 --> 01:10:30,165
Speaker 5:  I was just making plans to watch Oppenheimer on my iPad on the way to Vegas

1203
01:10:30,235 --> 01:10:30,685
Speaker 5:  next week.

1204
01:10:31,795 --> 01:10:35,405
Speaker 4:  Christopher Nolan is gonna be behind you on the plane.

1205
01:10:35,625 --> 01:10:36,045
Speaker 4:  Like, be careful

1206
01:10:37,865 --> 01:10:40,005
Speaker 3:  All. right. We gotta take a break. As you can tell, I'm very excited to go

1207
01:10:40,005 --> 01:10:43,285
Speaker 3:  look at TVs at css. We're gonna take a break. We're gonna come back with

1208
01:10:43,405 --> 01:10:45,165
Speaker 3:  a non CSS lighting round. We'll be right back.

1209
01:10:52,485 --> 01:10:56,355
Speaker 3:  We're back the lightning round, not sponsored by Smeg. It's

1210
01:10:56,355 --> 01:10:56,755
Speaker 3:  un chill.

1211
01:11:00,445 --> 01:11:01,355
Speaker 4:  We're lightning.

1212
01:11:02,505 --> 01:11:05,715
Speaker 3:  This poor company is like a great business selling retro fridges in the back

1213
01:11:05,715 --> 01:11:07,915
Speaker 3:  of office max. And they're like, boss,

1214
01:11:08,395 --> 01:11:11,555
Speaker 5:  Whatever man. We said Smeg like 10 times already on this podcast. They're

1215
01:11:11,555 --> 01:11:11,915
Speaker 5:  doing fine.

1216
01:11:11,915 --> 01:11:13,245
Speaker 4:  Weird name, weird name. Yeah. Yeah.

1217
01:11:13,345 --> 01:11:17,325
Speaker 3:  Our Google results are blowing up today. Someone's got

1218
01:11:17,325 --> 01:11:21,175
Speaker 3:  the Google or you know, it's like, what is going, they

1219
01:11:21,175 --> 01:11:24,015
Speaker 3:  they're, they're adorable. They're, they look like the fifties only using

1220
01:11:24,015 --> 01:11:26,815
Speaker 3:  modern pay us the money. And I'll finish the sentence smg,

1221
01:11:27,475 --> 01:11:28,855
Speaker 5:  The modern what? smg

1222
01:11:33,955 --> 01:11:36,575
Speaker 3:  By the way, in case you're wondering this is not how you generate sales.

1223
01:11:38,375 --> 01:11:41,895
Speaker 3:  I don't know how I think that should be very clear to everyone. That's not

1224
01:11:41,895 --> 01:11:45,455
Speaker 3:  my side of the business at all. But I'm very clear that this isn't how you

1225
01:11:45,455 --> 01:11:48,815
Speaker 3:  do it by threatening the maker of a retro refrigerator.

1226
01:11:49,755 --> 01:11:53,695
Speaker 3:  But if you know the good people at Smeg, if you know Alan Smeg, you know,

1227
01:11:53,805 --> 01:11:55,295
Speaker 3:  call him up. All, right?

1228
01:11:56,895 --> 01:11:58,175
Speaker 3:  I don't know if his name is Alan.

1229
01:11:58,845 --> 01:12:00,895
Speaker 4:  It's probably not Last name's. Probably not. Smeg.

1230
01:12:04,215 --> 01:12:07,295
Speaker 3:  Lightning round part two, non css. David, what got, so

1231
01:12:07,295 --> 01:12:11,055
Speaker 5:  There was this patent that came out this week. We think we're

1232
01:12:11,055 --> 01:12:14,935
Speaker 5:  about three weeks-ish away from Division

1233
01:12:15,035 --> 01:12:18,295
Speaker 5:  Pro launch from Apple. That's the, the word on the street I think is like

1234
01:12:18,295 --> 01:12:22,215
Speaker 5:  January 25th, 26th seems to be

1235
01:12:22,215 --> 01:12:25,415
Speaker 5:  what that means. Who knows. but it, it appears to be imminent that this thing

1236
01:12:25,415 --> 01:12:28,975
Speaker 5:  is coming. And one of the things that came out this

1237
01:12:29,235 --> 01:12:32,495
Speaker 5:  week was that Apple was granted a patent

1238
01:12:33,465 --> 01:12:37,295
Speaker 5:  for stuff to put on the outside of the

1239
01:12:37,315 --> 01:12:41,295
Speaker 5:  display. So if you remember, one of the things that the Vision Pro will do

1240
01:12:41,295 --> 01:12:44,895
Speaker 5:  is essentially give you googly eyes on the front of your Vision

1241
01:12:45,395 --> 01:12:49,175
Speaker 5:  Pro so that you can sort of look through them and it's like creepy

1242
01:12:49,175 --> 01:12:52,815
Speaker 5:  and weird and I hate it, but it's

1243
01:12:52,925 --> 01:12:56,095
Speaker 5:  technologically kind of cool. But what it turns out happened is that Apple,

1244
01:12:56,095 --> 01:12:59,855
Speaker 5:  including Jony Ive, who's named as an inventor on this patent, had a bunch

1245
01:12:59,915 --> 01:13:03,775
Speaker 5:  of ideas about what it might do with an external screen

1246
01:13:03,795 --> 01:13:06,895
Speaker 5:  on your face. And I think they're awesome.

1247
01:13:08,765 --> 01:13:12,615
Speaker 5:  There's, one of the ideas is just that you could have the words

1248
01:13:12,755 --> 01:13:15,455
Speaker 5:  do not disturb written on the outside of your face.

1249
01:13:16,155 --> 01:13:16,575
Speaker 3:  One of them

1250
01:13:16,665 --> 01:13:18,855
Speaker 5:  Could just project the weather on the outside screen.

1251
01:13:19,775 --> 01:13:23,255
Speaker 3:  I love the, the weather one is incredible. So

1252
01:13:23,255 --> 01:13:24,495
Speaker 5:  Useful, incredible, incredible. It could show

1253
01:13:24,495 --> 01:13:28,415
Speaker 3:  Your, all of the rest of these are sort of like, I see the weather one is

1254
01:13:28,415 --> 01:13:28,855
Speaker 3:  spectacular,

1255
01:13:28,855 --> 01:13:31,455
Speaker 5:  Incredible. It's spectacular. I agree. It could show your eyes in a bunch

1256
01:13:31,455 --> 01:13:35,415
Speaker 5:  of different shapes, including like zoom icons in

1257
01:13:35,415 --> 01:13:38,135
Speaker 5:  front of each of your eyes for when you're on a video call, it could show

1258
01:13:38,335 --> 01:13:41,655
Speaker 5:  a, a play button. Like if you're playing YouTube, it could show a

1259
01:13:41,765 --> 01:13:45,575
Speaker 5:  screensaver. Like it's, there's so many ideas

1260
01:13:45,765 --> 01:13:49,215
Speaker 5:  here, and this all reminds me of like early Apple Watch when they were just

1261
01:13:49,215 --> 01:13:53,135
Speaker 5:  like, here's a bunch of wacky features. You can send

1262
01:13:53,135 --> 01:13:56,495
Speaker 5:  your heartbeat to somebody or draw on your wrist to draw on somebody else's

1263
01:13:56,495 --> 01:14:00,455
Speaker 5:  wrist. And this feels so in line with that to me, where they're just

1264
01:14:00,455 --> 01:14:03,815
Speaker 5:  like, what can we do with a screen on your face? And Jony Ive is just like

1265
01:14:04,555 --> 01:14:04,975
Speaker 5:  hearts.

1266
01:14:07,975 --> 01:14:11,925
Speaker 4:  I I I'm missing the, the heartbeat thing though on the Apple watch.

1267
01:14:11,925 --> 01:14:12,845
Speaker 4:  That was, was it,

1268
01:14:14,465 --> 01:14:15,205
Speaker 4:  it was like creepy.

1269
01:14:15,225 --> 01:14:16,245
Speaker 3:  Did did you ever do it?

1270
01:14:16,685 --> 01:14:19,965
Speaker 4:  I mean, just to be like creepy to people. It's, it's from, that's how I do

1271
01:14:20,025 --> 01:14:24,005
Speaker 4:  the walkie-talkie now too, is just to be creepy. Never to like actually

1272
01:14:24,245 --> 01:14:25,165
Speaker 4:  communicate with another human being.

1273
01:14:25,945 --> 01:14:27,885
Speaker 3:  Oh see, I I, my wife and I are constantly

1274
01:14:27,975 --> 01:14:29,205
Speaker 4:  Using the walkie-talkie. Yeah,

1275
01:14:29,595 --> 01:14:32,885
Speaker 3:  It's, it's, it's really quite good. And actually now our house does not,

1276
01:14:32,955 --> 01:14:36,645
Speaker 3:  it's not necessary, but we still do it. So I will walkie talkie her and she'll

1277
01:14:36,645 --> 01:14:37,405
Speaker 3:  just yell up the stairs.

1278
01:14:38,945 --> 01:14:39,525
Speaker 5:  That's great

1279
01:14:39,695 --> 01:14:40,725
Speaker 3:  Technology, everybody.

1280
01:14:40,745 --> 01:14:44,125
Speaker 5:  But I think the, the thing I like about this is one thing Apple has always

1281
01:14:44,125 --> 01:14:47,925
Speaker 5:  been really good at is taking things that are otherwise kind

1282
01:14:48,085 --> 01:14:51,525
Speaker 5:  of problems and making them sort of iconic. Like all the way back to the,

1283
01:14:51,825 --> 01:14:55,805
Speaker 5:  the white headphones on the silhouette in the iPod commercials. Like it

1284
01:14:55,805 --> 01:14:59,725
Speaker 5:  took the cable of your headphones and turned it into a thing. Right? And

1285
01:14:59,725 --> 01:15:02,085
Speaker 5:  it, like, it did the same thing with AirPods, which are objectively ugly,

1286
01:15:02,105 --> 01:15:05,525
Speaker 5:  but it made them like culturally cool. And I think

1287
01:15:05,675 --> 01:15:08,525
Speaker 5:  Apple's gonna try to do the same thing with the Vision Pro

1288
01:15:09,705 --> 01:15:13,085
Speaker 5:  in some way. It's going to try to make it like, no, this is not a stupid

1289
01:15:13,085 --> 01:15:16,045
Speaker 5:  thing you wear on your face because it gives you stuff like this is a cool

1290
01:15:16,045 --> 01:15:19,965
Speaker 5:  thing for your face, which is a hard sell to make.

1291
01:15:19,965 --> 01:15:23,925
Speaker 5:  But I think Apple's gonna try. But yet as, as Jay

1292
01:15:23,925 --> 01:15:27,565
Speaker 5:  pointed out in this story that he wrote, we still have not seen,

1293
01:15:28,305 --> 01:15:31,925
Speaker 5:  as far as I know anyway, an Apple executive Tim Cook or otherwise

1294
01:15:32,315 --> 01:15:35,165
Speaker 5:  with a Vision Pro on their face. And

1295
01:15:36,265 --> 01:15:39,925
Speaker 5:  it is, it is very rare that one of these things comes out and is not

1296
01:15:39,925 --> 01:15:43,725
Speaker 5:  instantly made a meme. And so for Apple

1297
01:15:43,825 --> 01:15:47,645
Speaker 5:  to both simultaneously pursue this idea of like, how do we do more and

1298
01:15:47,645 --> 01:15:50,805
Speaker 5:  more and more and more and more with a screen on your face and

1299
01:15:51,935 --> 01:15:54,645
Speaker 5:  let's maybe hide the fact that it's a screen on your face for as long as

1300
01:15:54,645 --> 01:15:55,325
Speaker 5:  we possibly can.

1301
01:15:56,935 --> 01:15:59,375
Speaker 5:  I just, we're like a few weeks away from figuring out which one of those

1302
01:15:59,375 --> 01:16:02,775
Speaker 5:  is gonna win in the real world. And I think it's fascinating. I'm

1303
01:16:02,975 --> 01:16:05,295
Speaker 4:  Excited for Tim Cook's digital Eyes.

1304
01:16:06,395 --> 01:16:09,215
Speaker 5:  Tim Cook just like giving interviews and he gets bored and the weather pops

1305
01:16:09,215 --> 01:16:12,375
Speaker 5:  up is just gonna be incredible. Like I cannot wait

1306
01:16:14,915 --> 01:16:16,255
Speaker 4:  The little play side, you

1307
01:16:16,255 --> 01:16:18,895
Speaker 3:  Can go read the post and look at the pictures. The actual claims of this

1308
01:16:18,895 --> 01:16:22,175
Speaker 3:  patent are very small.

1309
01:16:23,885 --> 01:16:27,055
Speaker 3:  Like the actual thing that is being patented, a wearable electronic device

1310
01:16:28,045 --> 01:16:31,655
Speaker 3:  with a camera in it that's captures images of your, the wearer's face

1311
01:16:32,235 --> 01:16:34,975
Speaker 3:  and then a display in the housing that displays images of the wearer's face

1312
01:16:35,275 --> 01:16:38,815
Speaker 3:  the images based on the captured images. And then it

1313
01:16:39,215 --> 01:16:42,255
Speaker 3:  a sensor that detects the position of the observer

1314
01:16:43,235 --> 01:16:45,855
Speaker 3:  so they can point the images. Right. That's the whole thing. That's the whole

1315
01:16:45,855 --> 01:16:49,745
Speaker 3:  patent. Oh and the usual thing that they, they stick, they stick

1316
01:16:49,745 --> 01:16:53,465
Speaker 3:  this in all computer patents now they're like a computing system that does

1317
01:16:53,465 --> 01:16:56,705
Speaker 3:  it. And it's like, yeah, we, we understand the patent office doesn't understand

1318
01:16:56,945 --> 01:16:57,145
Speaker 3:  computers.

1319
01:16:57,385 --> 01:17:00,425
Speaker 5:  There's not a small person inside doing it for you. Yeah,

1320
01:17:00,425 --> 01:17:04,305
Speaker 3:  Exactly. That's, that's, it's always fascinating to

1321
01:17:04,305 --> 01:17:06,865
Speaker 3:  read what actual apple's actually claiming in these. 'cause they, they'll

1322
01:17:06,865 --> 01:17:10,045
Speaker 3:  put a lot of pictures in these and as everyone knows, you gotta read the

1323
01:17:10,045 --> 01:17:12,645
Speaker 3:  actual claims and the claims are here are just like we put a camera in it

1324
01:17:13,865 --> 01:17:17,285
Speaker 3:  and it display on the outside. That's the whole claim of this patent. And

1325
01:17:17,285 --> 01:17:19,925
Speaker 3:  then Jony, I've got to do some pictures. I will say if you walk around in

1326
01:17:19,925 --> 01:17:23,365
Speaker 3:  an Apple Vision Pro just displaying to people the weather in Cupertino, California,

1327
01:17:24,425 --> 01:17:25,795
Speaker 3:  it's very good. Like the

1328
01:17:25,795 --> 01:17:28,795
Speaker 4:  Idea, they don't even change the weather. It's always gonna be Cupertino.

1329
01:17:28,995 --> 01:17:32,635
Speaker 5:  I think if you wear one of these, you should be obligated to be showing your

1330
01:17:32,695 --> 01:17:34,995
Speaker 5:  TikTok feed on the outside of it at all times.

1331
01:17:36,415 --> 01:17:36,835
Speaker 10:  That's

1332
01:17:37,205 --> 01:17:37,555
Speaker 4:  Shame.

1333
01:17:39,095 --> 01:17:42,355
Speaker 3:  CS is next week. Apple has said Vision Pro is coming early 2024.

1334
01:17:42,995 --> 01:17:46,035
Speaker 3:  A lot of rumbles out in the world. I would bet there's some sort of Vision

1335
01:17:46,095 --> 01:17:48,205
Speaker 3:  Pro announcement that interferes.

1336
01:17:48,205 --> 01:17:50,565
Speaker 5:  Apple loves up staging. CES loves it.

1337
01:17:51,195 --> 01:17:55,115
Speaker 3:  Yeah. Yeah, I bet you're right. So, I. That, that's just my bet. I

1338
01:17:55,115 --> 01:17:59,075
Speaker 3:  don't, I don't have any insight into on that. I just based on history.

1339
01:17:59,555 --> 01:18:01,915
Speaker 3:  Remember one year at css Apple was like, we have an event. And I was like,

1340
01:18:01,935 --> 01:18:03,955
Speaker 3:  the iPhone's now in Verizon. Yeah.

1341
01:18:06,305 --> 01:18:06,595
Speaker 10:  Cool.

1342
01:18:06,665 --> 01:18:08,035
Speaker 3:  Yeah, it's the same one.

1343
01:18:10,045 --> 01:18:11,105
Speaker 3:  All, right? Cranz what you got?

1344
01:18:11,375 --> 01:18:14,905
Speaker 4:  Okay, so it is with like great sadness. I say that

1345
01:18:15,205 --> 01:18:18,705
Speaker 4:  Amazon is moving to advertising starting in

1346
01:18:18,895 --> 01:18:22,705
Speaker 4:  January 29th. That means you're gonna have to watch ads if you

1347
01:18:22,705 --> 01:18:23,905
Speaker 4:  have Amazon Prime. Unless

1348
01:18:23,965 --> 01:18:24,385
Speaker 3:  That's

1349
01:18:24,385 --> 01:18:28,065
Speaker 4:  Crazy. You wanna pay extra. But it's also like, it was always

1350
01:18:28,065 --> 01:18:31,665
Speaker 4:  inevitable. It was always gonna happen. They were, nobody was shy about putting

1351
01:18:31,725 --> 01:18:35,105
Speaker 4:  ads on these things when they, when they started with the maybe Netflix.

1352
01:18:35,445 --> 01:18:38,105
Speaker 4:  But everybody else was always like, yeah, ads is is somewhere in a forecast

1353
01:18:38,105 --> 01:18:41,895
Speaker 4:  for us. So now it's just like, okay. And for

1354
01:18:41,955 --> 01:18:45,255
Speaker 4:  Amazon, a company who we don't actually know how many people watch their

1355
01:18:45,255 --> 01:18:48,655
Speaker 4:  shows, we just know they have all of the subscribers because everybody has

1356
01:18:48,655 --> 01:18:52,055
Speaker 4:  Amazon Prime. This makes a lot of sense. 'cause now they can make,

1357
01:18:52,205 --> 01:18:56,195
Speaker 5:  Well I think we can confidently say it's not very many based

1358
01:18:56,195 --> 01:18:58,315
Speaker 5:  on the success of their big shows that they have.

1359
01:18:59,125 --> 01:19:00,475
Speaker 4:  Which ones? Yeah,

1360
01:19:02,255 --> 01:19:03,955
Speaker 3:  Wom Reacher. Hey there's the Boys. The Boys is

1361
01:19:03,955 --> 01:19:05,075
Speaker 4:  Good. It's richer and Boys. Yeah,

1362
01:19:05,505 --> 01:19:06,555
Speaker 5:  It's a show. Yeah.

1363
01:19:06,825 --> 01:19:10,595
Speaker 4:  Everybody's dad watches reachers. Like you two are gonna be

1364
01:19:10,795 --> 01:19:12,315
Speaker 4:  watching it soon. You don't know it, isn't

1365
01:19:12,315 --> 01:19:13,595
Speaker 3:  It just singular reacher? It's

1366
01:19:13,745 --> 01:19:15,395
Speaker 4:  It's reacher. Yeah, you're right. It's just reacher.

1367
01:19:15,985 --> 01:19:18,075
Speaker 3:  It's like the James Cameron sequels Reachers.

1368
01:19:22,065 --> 01:19:23,395
Speaker 4:  It's coming for you guys. Just

1369
01:19:23,555 --> 01:19:27,435
Speaker 5:  A lot of tall, quiet men running around small towns in America.

1370
01:19:27,855 --> 01:19:30,675
Speaker 3:  The only thing I know about Reacher is I saw a t who's the main actor. I

1371
01:19:30,675 --> 01:19:33,595
Speaker 3:  don't even know, I just saw a TikTok with him where he was saying that the

1372
01:19:33,595 --> 01:19:37,555
Speaker 3:  amount of muscle that he has to carry on his body to portray reacher is actually

1373
01:19:37,555 --> 01:19:41,035
Speaker 3:  causing a physical toll on his body. Wow. Oh no. He's like, imagine walking

1374
01:19:41,035 --> 01:19:44,595
Speaker 3:  up a flight of stairs, but you're holding two 40 pound dumbbells. That's

1375
01:19:44,595 --> 01:19:45,035
Speaker 3:  my life, Lord.

1376
01:19:47,495 --> 01:19:48,795
Speaker 4:  That's a lot. That's too much muscle.

1377
01:19:49,545 --> 01:19:52,955
Speaker 3:  Yeah. He was like, yeah, but it's worth it because I'm, I'm reacher. Soon

1378
01:19:52,955 --> 01:19:54,915
Speaker 3:  as starting the sequel reachers direct way change games,

1379
01:19:56,895 --> 01:19:59,435
Speaker 3:  it is inevitable that all these streaming services are doing ads. Like everyone

1380
01:19:59,635 --> 01:20:03,475
Speaker 3:  watching Netflix turn on ads and make more money. Amazon is

1381
01:20:03,715 --> 01:20:07,485
Speaker 3:  actually a secretly huge player in the ads business. Yeah. Like a huge player

1382
01:20:07,485 --> 01:20:10,605
Speaker 3:  in the ads business. It's, it's Meta, Google and Amazon. And

1383
01:20:11,305 --> 01:20:15,095
Speaker 3:  of course they're gonna do connected TV ads, but it's kind of

1384
01:20:15,095 --> 01:20:18,815
Speaker 3:  gross. Like the whole point of prime is like not that, right?

1385
01:20:19,365 --> 01:20:22,135
Speaker 3:  Like you pay Amazon the money up front to get all the good service on the

1386
01:20:22,135 --> 01:20:25,695
Speaker 3:  backend. Yeah. And now it's like, now it's just cable. You just,

1387
01:20:26,315 --> 01:20:27,855
Speaker 3:  I'm paying for cable then shipping,

1388
01:20:28,335 --> 01:20:31,695
Speaker 4:  I think for them it's like, okay, you get free shipping, you get whatever

1389
01:20:31,695 --> 01:20:35,655
Speaker 4:  other stuff comes with Prime and now you also get free cable and if you

1390
01:20:35,655 --> 01:20:39,255
Speaker 4:  wanna get rid of the, the ads on your cable, you can give us even more money

1391
01:20:39,255 --> 01:20:41,805
Speaker 4:  every month. And four people are gonna do that.

1392
01:20:43,035 --> 01:20:47,005
Speaker 3:  Yeah. No one write us a note if you're gonna pay

1393
01:20:47,025 --> 01:20:50,885
Speaker 3:  for the ad free tier of Amazon Prime video. I wanna meet you.

1394
01:20:51,045 --> 01:20:52,125
Speaker 3:  I feel like I could meet you individual.

1395
01:20:52,125 --> 01:20:52,645
Speaker 5:  Yeah. Oh yeah.

1396
01:20:53,315 --> 01:20:56,645
Speaker 3:  Like that, that's a scalable proposition is I wanna meet all of

1397
01:20:56,645 --> 01:21:00,085
Speaker 5:  You don. You could fit all of those people in like a single Dave and Busters.

1398
01:21:00,155 --> 01:21:01,005
Speaker 5:  Like no question

1399
01:21:03,295 --> 01:21:07,245
Speaker 3:  We're gonna have a party sponsored by, you

1400
01:21:07,245 --> 01:21:07,805
Speaker 3:  know who you are

1401
01:21:11,425 --> 01:21:15,245
Speaker 3:  All. right? I have two. 'cause I, I added one 'cause it's so

1402
01:21:15,245 --> 01:21:18,125
Speaker 3:  funny. But my first one is

1403
01:21:19,505 --> 01:21:22,705
Speaker 3:  Alma Drafthouse runs Sony Digital Cinema projectors.

1404
01:21:23,285 --> 01:21:27,225
Speaker 3:  And they had some sort of certificate timeout over the break

1405
01:21:27,725 --> 01:21:29,145
Speaker 3:  and they just stopped showing movies.

1406
01:21:30,135 --> 01:21:30,865
Speaker 5:  It's so brutal.

1407
01:21:32,495 --> 01:21:35,825
Speaker 4:  It's, and that's like, they're the, they're supposed to be the good company.

1408
01:21:35,825 --> 01:21:39,425
Speaker 4:  They're supposed to be like the good movie theater that like actually

1409
01:21:39,475 --> 01:21:43,305
Speaker 4:  cares about how they screen things. So for them to like drop the ball this

1410
01:21:43,325 --> 01:21:44,305
Speaker 4:  bad is Yeah.

1411
01:21:44,305 --> 01:21:47,665
Speaker 3:  So it's, it's unclear what happened. We've read a bunch of forum posts from

1412
01:21:47,665 --> 01:21:51,425
Speaker 3:  like theater employees and like projectionists, one amazing thing about the

1413
01:21:51,585 --> 01:21:54,265
Speaker 3:  internet is you're like, man, I, I wonder if there's a community online that's

1414
01:21:54,265 --> 01:21:56,785
Speaker 3:  deep in the weeds of this and you're like, oh, it's the projectionist forums.

1415
01:21:57,895 --> 01:22:01,705
Speaker 3:  Yeah, obviously. So there's, there's people like explaining what

1416
01:22:01,865 --> 01:22:04,465
Speaker 3:  happened, you know, they're like man the company. But, but it feels like,

1417
01:22:04,465 --> 01:22:07,105
Speaker 3:  David, I know you read a bunch of this stuff too and we're gonna write a

1418
01:22:07,105 --> 01:22:09,985
Speaker 3:  story on it. 'cause it's, it is very, it's like perfectly ver Strike House.

1419
01:22:09,985 --> 01:22:13,185
Speaker 3:  There's a lot of DRM involved in digital

1420
01:22:13,475 --> 01:22:17,105
Speaker 3:  projection. Like you send a movie to a movie theater, there's a bunch

1421
01:22:17,305 --> 01:22:20,465
Speaker 3:  of DRM steps in being able to play back that digital file. Yes.

1422
01:22:21,735 --> 01:22:25,475
Speaker 3:  And somewhere between the projector and the file,

1423
01:22:25,955 --> 01:22:29,715
Speaker 3:  there was a certificate timeout and no one, like, no one caught saw it

1424
01:22:29,715 --> 01:22:33,315
Speaker 5:  Coming. Yeah. That, that's about as far as I've gotten down the rabbit hole.

1425
01:22:33,395 --> 01:22:37,095
Speaker 5:  I think that's right. And Sony kind of

1426
01:22:37,095 --> 01:22:40,735
Speaker 5:  increasingly has no interest in this business. And these things are

1427
01:22:40,735 --> 01:22:43,695
Speaker 5:  notoriously brittle anyway. Like remember we did that story a few months

1428
01:22:43,695 --> 01:22:47,655
Speaker 5:  ago about the IMAX theaters that still crucially rely on a

1429
01:22:47,655 --> 01:22:51,375
Speaker 5:  Palm pilot and are now emulating a palm pilot on an iPad. And we're like

1430
01:22:51,595 --> 01:22:55,455
Speaker 5:  the, the true nature of the tape and strings that hold these things

1431
01:22:55,735 --> 01:22:59,335
Speaker 5:  together is just unbelievable. Even if you're at Alamo

1432
01:22:59,335 --> 01:23:03,055
Speaker 5:  Drafthouse and care deeply about how this stuff works, these folks

1433
01:23:03,205 --> 01:23:03,495
Speaker 5:  just

1434
01:23:05,445 --> 01:23:09,115
Speaker 5:  don't upgrade the equipment unless they have to. And meanwhile, the

1435
01:23:09,545 --> 01:23:13,395
Speaker 5:  equipment on which these movies are made is increasingly high tech. And

1436
01:23:13,415 --> 01:23:17,035
Speaker 5:  the way that they're being shipped around is increasingly digital and

1437
01:23:17,035 --> 01:23:20,835
Speaker 5:  increasingly high tech. And to your point, these companies are taking more

1438
01:23:20,855 --> 01:23:24,835
Speaker 5:  and more care to lock this stuff down. Especially with

1439
01:23:25,735 --> 01:23:28,875
Speaker 5:  big important movies like the, these things are more carefully controlled

1440
01:23:28,875 --> 01:23:31,795
Speaker 5:  than ever. They're not just shipping giant reels around the country nearly

1441
01:23:31,855 --> 01:23:35,795
Speaker 5:  the way that they used to. It. It, a lot of this is happening online.

1442
01:23:36,305 --> 01:23:39,635
Speaker 5:  It's mostly happening digitally now. Like it, there are just so many more

1443
01:23:39,635 --> 01:23:43,115
Speaker 5:  places for it to break in these old weird systems than there used to be.

1444
01:23:43,815 --> 01:23:47,595
Speaker 5:  And if you're Alamo, there's just like nothing you can do. You just

1445
01:23:47,775 --> 01:23:49,595
Speaker 5:  update the firmware and hope for the best.

1446
01:23:50,115 --> 01:23:52,675
Speaker 4:  I think, I think the, the suggestion from a lot of those projectionists though

1447
01:23:52,675 --> 01:23:56,555
Speaker 4:  is that like Alamo probably did mess up here. Yeah. And there's been like

1448
01:23:56,555 --> 01:23:59,955
Speaker 4:  a lot of talk about like in the theater community about Alamo and it's kind

1449
01:23:59,955 --> 01:24:03,515
Speaker 4:  of decline. And so this is kind of like an indication of that decline.

1450
01:24:03,785 --> 01:24:06,595
Speaker 4:  They've, they've been rough since like 2017. So

1451
01:24:06,595 --> 01:24:10,035
Speaker 5:  Yeah. But like there's, there's no such thing as like a full stack movie

1452
01:24:10,035 --> 01:24:13,915
Speaker 5:  theater. Right? Like a MC is not out here making its own projectors so

1453
01:24:13,915 --> 01:24:16,915
Speaker 5:  that it can show you the movie better. Like everybody is still reliant on

1454
01:24:16,915 --> 01:24:20,875
Speaker 5:  this crazy chain that is not really designed to

1455
01:24:20,875 --> 01:24:22,995
Speaker 5:  make the process seamless and good.

1456
01:24:24,125 --> 01:24:26,775
Speaker 4:  Yeah. It's supposed to be as complex as possible. 'cause they don't want

1457
01:24:26,775 --> 01:24:29,895
Speaker 4:  like a young projectionist to be like, Ooh, let me just upload this

1458
01:24:30,755 --> 01:24:34,655
Speaker 4:  to BitTorrent. Gonna have a good time. Beautiful film.

1459
01:24:35,405 --> 01:24:37,335
Speaker 3:  Yeah. Can I tell a story for my youth?

1460
01:24:37,595 --> 01:24:37,815
Speaker 4:  Yes.

1461
01:24:38,445 --> 01:24:41,775
Speaker 3:  When I was in high school, my friend Allison's dad was the manager of the

1462
01:24:41,775 --> 01:24:45,655
Speaker 3:  local movie theater and somehow this emboldened us to believe as

1463
01:24:45,655 --> 01:24:49,415
Speaker 3:  we were walking out of a movie that we could pick up the reels of Austin

1464
01:24:49,415 --> 01:24:53,095
Speaker 3:  Powers two, the film reels of Austin Powers two and sprint them to

1465
01:24:55,085 --> 01:24:57,655
Speaker 3:  our park. They were very heavy. We

1466
01:24:58,955 --> 01:25:02,215
Speaker 3:  got nowhere before. We were just stopped by a group of theater employees

1467
01:25:02,215 --> 01:25:04,775
Speaker 3:  going, what are you doing? And we're, we don't know.

1468
01:25:07,805 --> 01:25:11,295
Speaker 5:  What was your plan? Like, like wind this all the way back for me. What was

1469
01:25:11,295 --> 01:25:12,535
Speaker 5:  the idea outcome to this story?

1470
01:25:13,515 --> 01:25:13,735
Speaker 3:  We

1471
01:25:14,995 --> 01:25:15,775
Speaker 4:  Did You have a projector

1472
01:25:15,935 --> 01:25:19,655
Speaker 3:  Still stuff. I don't know. High school. Racine, Wisconsin. We saw the reels

1473
01:25:19,655 --> 01:25:23,455
Speaker 3:  to Austin Paris too. We're like, now we'll have them. I was like

1474
01:25:23,455 --> 01:25:27,415
Speaker 3:  16 years old. It's, but it's burned into my brain how heavy

1475
01:25:27,485 --> 01:25:31,455
Speaker 3:  they were like, you know that oh this is a mistake.

1476
01:25:31,685 --> 01:25:31,975
Speaker 3:  Yeah.

1477
01:25:32,215 --> 01:25:33,815
Speaker 5:  But then you're too far in. Yeah. Is

1478
01:25:33,815 --> 01:25:36,055
Speaker 4:  There like a who as soon as you picked them up

1479
01:25:36,055 --> 01:25:39,575
Speaker 3:  Yeah. The second you pick 'em up Yeah. You're, it's already over. Even if

1480
01:25:39,715 --> 01:25:43,585
Speaker 3:  by simply trying to pick them up, you've, you've realized you've made

1481
01:25:43,625 --> 01:25:44,465
Speaker 3:  a horrible mistake.

1482
01:25:47,725 --> 01:25:51,705
Speaker 4:  Fun fact, the opening sequence for that movie is you

1483
01:25:51,705 --> 01:25:55,095
Speaker 4:  couldn't play it on, on Twitch now because they, they just Oh,

1484
01:25:55,095 --> 01:25:56,055
Speaker 3:  Just of the nudity rules. Yeah.

1485
01:25:56,175 --> 01:25:59,495
Speaker 4:  'cause of the implied nudity rule. And that's the whole first like second

1486
01:25:59,495 --> 01:26:00,175
Speaker 4:  chunk of the movie.

1487
01:26:01,455 --> 01:26:02,775
Speaker 3:  I, you know, it's probably for the best.

1488
01:26:04,775 --> 01:26:05,765
Speaker 4:  Where were you watching it now?

1489
01:26:05,765 --> 01:26:08,885
Speaker 3:  There's, there's a time and a place for the opening sequence of Austin Powers

1490
01:26:08,905 --> 01:26:11,605
Speaker 3:  two. And don don't know if it's Twitch, I, to be honest with

1491
01:26:13,035 --> 01:26:16,525
Speaker 3:  you. It's, it's on Bra Corps in 80 megabits per second. Crystal

1492
01:26:16,525 --> 01:26:17,645
Speaker 3:  clear Purestream. See

1493
01:26:17,645 --> 01:26:18,885
Speaker 4:  Every strand of Chest hair

1494
01:26:19,605 --> 01:26:23,245
Speaker 3:  Speaking of stealing things, the Kia boys are back. Yeah.

1495
01:26:24,065 --> 01:26:27,205
Speaker 3:  And Kia has a new plan to stop them. So if you're aware of the Kia Boys,

1496
01:26:27,545 --> 01:26:31,285
Speaker 3:  you can, it's apparently very easy to steal many, many Kia and Hyundai

1497
01:26:31,285 --> 01:26:35,125
Speaker 3:  cars. So Kia is acknowledged this problem. They're getting sued by various

1498
01:26:35,125 --> 01:26:38,565
Speaker 3:  states who say Kia is negligent because they've made their cars too easy

1499
01:26:38,565 --> 01:26:42,165
Speaker 3:  to steal. Very funny outcome. A deeply funny

1500
01:26:42,165 --> 01:26:46,125
Speaker 3:  outcome. Kia is doing like software updates, Hyundai's doing software

1501
01:26:46,125 --> 01:26:50,085
Speaker 3:  updates. They're shipping out like, like steering wheel locks

1502
01:26:50,085 --> 01:26:53,885
Speaker 3:  like the club to people. It's all very funny. Now there're, in addition

1503
01:26:53,885 --> 01:26:57,725
Speaker 3:  to this, there's a press release. They're shipping out devices

1504
01:26:57,945 --> 01:27:01,285
Speaker 3:  to protect the ignition column. Incredible,

1505
01:27:01,575 --> 01:27:05,445
Speaker 3:  incredible line in this press release. This is a bullet under the headline

1506
01:27:05,785 --> 01:27:09,645
Speaker 3:  in bold device reinforces ignition cylinder body to

1507
01:27:09,645 --> 01:27:12,485
Speaker 3:  guard against theft methods popularized on social media.

1508
01:27:13,065 --> 01:27:13,285
Speaker 5:  Wow.

1509
01:27:14,195 --> 01:27:15,005
Speaker 3:  It's very good.

1510
01:27:15,555 --> 01:27:17,885
Speaker 5:  It's one of those things that you write and you're like, what has the world

1511
01:27:17,885 --> 01:27:19,965
Speaker 5:  become like, what are we doing here?

1512
01:27:20,635 --> 01:27:21,125
Speaker 3:  Exactly.

1513
01:27:23,075 --> 01:27:26,005
Speaker 3:  Very good. And then in order to make it clear

1514
01:27:27,185 --> 01:27:30,365
Speaker 3:  to the Kia Boys that you've installed this device that are giving everybody

1515
01:27:30,405 --> 01:27:34,355
Speaker 3:  a sticker. So now your, your car can have a sticker that says

1516
01:27:34,355 --> 01:27:38,315
Speaker 3:  Stay away Kia Boys, boys. We have a device that reinforces

1517
01:27:38,475 --> 01:27:39,715
Speaker 3:  ignition cylinder body and stuff.

1518
01:27:39,915 --> 01:27:43,235
Speaker 5:  No chance whatsoever that that'll backfire. None.

1519
01:27:44,105 --> 01:27:46,835
Speaker 5:  That sticker will solve all of your problems. For

1520
01:27:46,865 --> 01:27:50,475
Speaker 3:  Sure. Another bullet in this press release, second wave of local

1521
01:27:50,875 --> 01:27:54,755
Speaker 3:  software upgrade clinics also planned in coordination with local Kia dealers

1522
01:27:54,755 --> 01:27:56,155
Speaker 3:  in key cities across the us

1523
01:27:58,555 --> 01:28:02,415
Speaker 3:  Yep. Software upgrade clinics at the Kia dealer. If you have a Kia on it,

1524
01:28:02,415 --> 01:28:04,295
Speaker 3:  go get your car fixed. 'cause the Kia boys are on the loose

1525
01:28:04,605 --> 01:28:05,695
Speaker 4:  Only park it in the garage.

1526
01:28:06,445 --> 01:28:09,615
Speaker 3:  Yeah, that's, there are Kias in my family and I have family members who are

1527
01:28:09,615 --> 01:28:11,135
Speaker 3:  like, I gotta get this thing in the garage. I'm like,

1528
01:28:11,205 --> 01:28:14,295
Speaker 5:  Nila, do you think if you were a teen right now you'd be a Kia boy? I feel

1529
01:28:14,295 --> 01:28:17,935
Speaker 5:  like there's like, like the same neli that is stealing Austin Power's. Two

1530
01:28:18,095 --> 01:28:22,055
Speaker 5:  reels is definitely out here. Being a Kia boy right

1531
01:28:22,055 --> 01:28:22,175
Speaker 5:  now,

1532
01:28:22,605 --> 01:28:23,895
Speaker 4:  Just be like, nah, take a car.

1533
01:28:24,375 --> 01:28:27,055
Speaker 3:  I think it is very good that I was not a teenager in the age of social media.

1534
01:28:28,075 --> 01:28:30,055
Speaker 3:  That's what I got for you. I think I would've,

1535
01:28:31,855 --> 01:28:34,335
Speaker 3:  I would've, I would've turned out differently. Fair. Probably in jail.

1536
01:28:36,925 --> 01:28:40,495
Speaker 3:  That seems like the most likely outcome of teenage Eli plus the internet.

1537
01:28:41,555 --> 01:28:45,255
Speaker 3:  All. right? That's it. We're way over as always. There was an extended

1538
01:28:45,255 --> 01:28:47,895
Speaker 3:  copyright loss segment for which I apologize. Nothing.

1539
01:28:49,245 --> 01:28:53,135
Speaker 3:  Zero apologies for that. And also zero apologies to the local

1540
01:28:53,135 --> 01:28:56,575
Speaker 3:  refrigerator factory, which would sponsor the lightning round immediately.

1541
01:28:57,375 --> 01:29:01,245
Speaker 3:  I like how they're turned into a local refrigerator factory. Yeah, just around

1542
01:29:01,245 --> 01:29:01,525
Speaker 3:  the corner.

1543
01:29:03,265 --> 01:29:07,165
Speaker 3:  I'm coming over there. We're gonna CSS next week. We'll have a

1544
01:29:07,285 --> 01:29:11,125
Speaker 3:  ton of coverage. I we have two Vergecast, right? Yep. At css. So

1545
01:29:11,125 --> 01:29:14,485
Speaker 3:  two Verge casts from CSS historically are craziest Vergecast of the year

1546
01:29:14,485 --> 01:29:18,365
Speaker 3:  because we're all sleep deprived. Just tons of coverage on the

1547
01:29:18,365 --> 01:29:21,845
Speaker 3:  site. CSS is where the year really kicks off. So I'm excited to go look at

1548
01:29:21,845 --> 01:29:25,245
Speaker 3:  some gadgets, see a bunch of people, do a bunch of reporting and obviously

1549
01:29:25,245 --> 01:29:28,245
Speaker 3:  talk to all of you on the Red Chest. So we'll see you next week at cs. That's

1550
01:29:28,245 --> 01:29:29,645
Speaker 3:  the Rich Chest rock roll.

1551
01:29:34,945 --> 01:29:38,485
Speaker 9:  And that's a wrap for Vergecast this week. Hey, we'd love to hear from you.

1552
01:29:38,555 --> 01:29:42,525
Speaker 9:  Give us a call at eight six six Verge one. One The

1553
01:29:42,525 --> 01:29:46,005
Speaker 9:  Vergecast is a production of The Verge and Vox Media Podcast Network. The

1554
01:29:46,205 --> 01:29:50,085
Speaker 9:  show is produced by Andrew Marino and Liam James. This episode was mixed

1555
01:29:50,105 --> 01:29:53,165
Speaker 9:  and edited by Xander Adams. And that's it. We'll see you next week. We'll.

