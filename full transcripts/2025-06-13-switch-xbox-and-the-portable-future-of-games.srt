1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 85c21e52-5241-4713-85ef-1eda16888438
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-6085400793422067167/-5441834408049713462/s93290-US-6898s-1749813459.mp3
Description: There's a lot of news this week, so today's episode turned into a whole bunch of lightning rounds. Nilay, David, and The Verge's Jake Kastrenakes talk through all the vibes and news at WWDC, and why F1 seemed to outshine everything else. We also talk about the Switch 2 launch, and the news this week that Microsoft and Asus are building Xbox handhelds in both clever and confusing ways. After that, we run through for a bunch of AI news, including the ongoing decline of Google traffic to the web, the new Dia browser, and Sam Altman's ideas about how much water ChatGPT uses. Finally, it's time for another edition of Brendan Carr is a Dummy, followed by the news of Warner Bros. Discovery breaking up, some very fast flash drives, and a new Meta messaging app.


2
00:00:02,175 --> 00:00:06,125
Speaker 3:  Hello and welcome to Our Chest, the flagship podcast of America's bestselling

3
00:00:06,125 --> 00:00:06,805
Speaker 3:  video game console.

4
00:00:08,775 --> 00:00:11,905
Speaker 3:  See, it's topical. It's not snarky.

5
00:00:12,265 --> 00:00:13,505
Speaker 1:  I know. That was, that was it.

6
00:00:13,845 --> 00:00:16,165
Speaker 3:  It wasn't mean. I can do it.

7
00:00:16,725 --> 00:00:18,765
Speaker 2:  I feel like you were really trying to prove it. See,

8
00:00:19,585 --> 00:00:20,205
Speaker 3:  See everybody

9
00:00:20,875 --> 00:00:21,765
Speaker 2:  That wasn't the most

10
00:00:30,215 --> 00:00:32,955
Speaker 3:  That's, that's where we are. It's one or the other. There it is. It's either

11
00:00:32,965 --> 00:00:34,315
Speaker 3:  Mario Cart or

12
00:01:03,725 --> 00:01:07,685
Speaker 3:  there was a moral panic about this game Smash Super. It was like smash TV

13
00:01:07,745 --> 00:01:10,605
Speaker 3:  or something, I don't know. And it was like you were, you were doing a riot

14
00:01:10,625 --> 00:01:14,005
Speaker 3:  in a shopping mall. Perfect. Okay.

15
00:01:14,005 --> 00:01:15,885
Speaker 1:  That is a really great premise for a video game.

16
00:01:15,985 --> 00:01:18,245
Speaker 2:  Is this eight bit like, what are we talking here?

17
00:01:18,275 --> 00:01:21,525
Speaker 3:  Yeah, it was like eight bit. Oh, I found it. It's a smash TV is a 1990

18
00:01:21,945 --> 00:01:25,925
Speaker 3:  arcade game and then it came out as Super

19
00:01:25,925 --> 00:01:29,765
Speaker 3:  Smash TV on the S Nest and the Genesis. Mm. And it was

20
00:01:29,825 --> 00:01:32,445
Speaker 3:  the, the theme of the game was borrowed from Robocop.

21
00:01:33,305 --> 00:01:33,685
Speaker 2:  Oh wow.

22
00:01:34,705 --> 00:01:37,605
Speaker 3:  And then in the, in the game, you're playing on the most violent game show

23
00:01:37,605 --> 00:01:41,445
Speaker 3:  of all time in the not too distant future of 1999. And the goal is

24
00:01:41,445 --> 00:01:45,365
Speaker 3:  to survive while earning cash and prizes, including

25
00:01:45,595 --> 00:01:46,325
Speaker 3:  VCRs and Toasters.

26
00:01:46,785 --> 00:01:50,685
Speaker 2:  How has this not been made into a movie? I don, this is like a perfect

27
00:01:50,685 --> 00:01:52,205
Speaker 2:  premise for 2025. You

28
00:01:52,205 --> 00:01:55,325
Speaker 1:  Just described Squid Game, you know that, right? They did Squid Game,

29
00:01:55,665 --> 00:01:59,485
Speaker 3:  But there was like a straight Oh. And if you, if you, you cannot

30
00:01:59,485 --> 00:02:02,725
Speaker 3:  collect enough keys. You go to a bonus level called the Pleasure Dome where

31
00:02:02,725 --> 00:02:05,645
Speaker 3:  you can collect hundreds of blue bikini glad women,

32
00:02:06,985 --> 00:02:10,925
Speaker 3:  you know, there was a full, there was just a full moral

33
00:02:10,925 --> 00:02:14,805
Speaker 3:  panic about this game. I, for obvious reasons. And now it's just Squid game.

34
00:02:15,445 --> 00:02:19,015
Speaker 1:  Yeah, that's like, that's like a pretty medium black mirror

35
00:02:19,125 --> 00:02:22,695
Speaker 1:  episode premise. What you just, what you just said. That's really good.

36
00:02:23,835 --> 00:02:27,175
Speaker 3:  Anyway, Welcome to The Vergecast, the flagship podcast of the pleasure to,

37
00:02:28,685 --> 00:02:31,615
Speaker 3:  it's been unusually morning on The Vergecast these past few weeks. Mostly

38
00:02:31,615 --> 00:02:34,975
Speaker 3:  David Pierce's fault, I have to say. So I'm just trying to, I'm trying to

39
00:02:34,975 --> 00:02:37,495
Speaker 3:  keep, keep our theme alive. Anyway, I have your friend David Pierce is here.

40
00:02:37,785 --> 00:02:38,135
Speaker 2:  Hello.

41
00:02:38,915 --> 00:02:39,975
Speaker 3:  Jay Castran is here.

42
00:02:40,075 --> 00:02:40,815
Speaker 2:  Hey, good to be here.

43
00:02:41,535 --> 00:02:44,535
Speaker 3:  A lot has gone on this week. Obviously. I just came back from wwe C My brain

44
00:02:44,535 --> 00:02:48,415
Speaker 3:  is basically mush After that experience. The switch two came

45
00:02:48,415 --> 00:02:51,295
Speaker 3:  out. We should talk about that. We got lightning round after lightning round.

46
00:02:51,605 --> 00:02:55,015
Speaker 3:  Brendan, Brendan, there's a, we gotta talk about six G because of Brendan.

47
00:02:56,045 --> 00:02:58,655
Speaker 3:  It's just getting dumber and dumber over there every day. You guys,

48
00:03:00,055 --> 00:03:03,645
Speaker 3:  media companies continue to merge and Unmerge just unprecedented rates.

49
00:03:04,235 --> 00:03:07,805
Speaker 3:  Just a lot going on. And then I missed most of it 'cause I was

50
00:03:08,065 --> 00:03:11,905
Speaker 3:  at Apple Park where talking about

51
00:03:11,905 --> 00:03:15,505
Speaker 3:  the F1 movie just took precedent over like everything

52
00:03:15,885 --> 00:03:19,425
Speaker 1:  You say that, but like, it really seemed like that, like the main thing

53
00:03:20,345 --> 00:03:24,235
Speaker 1:  from afar that it seemed like Apple cared about this week was F1.

54
00:03:24,815 --> 00:03:28,585
Speaker 1:  Yeah, it was, it was the intro to the keynote. It was

55
00:03:28,805 --> 00:03:32,145
Speaker 1:  all over the place at Apple Park. They, I, they did a screening for press.

56
00:03:32,205 --> 00:03:32,625
Speaker 1:  It was like

57
00:03:32,855 --> 00:03:36,745
Speaker 3:  With an F1 car in the middle of the Steve Jobs theater, like the, the top

58
00:03:36,745 --> 00:03:37,025
Speaker 3:  part.

59
00:03:37,365 --> 00:03:37,785
Speaker 1:  Oh, wild.

60
00:03:38,015 --> 00:03:41,745
Speaker 3:  It's a big empty area and many different things have been

61
00:03:41,745 --> 00:03:44,945
Speaker 3:  staged in this big empty area. But this was an F1 car. It was what I was

62
00:03:44,945 --> 00:03:48,385
Speaker 3:  told Alison was there. I was not there. I was podcasting with John Gruber

63
00:03:48,485 --> 00:03:48,705
Speaker 3:  and

64
00:03:48,705 --> 00:03:52,625
Speaker 1:  Then like Tim Cook, who, who was sort of mysteriously absent from a lot of

65
00:03:52,795 --> 00:03:56,625
Speaker 1:  stuff. This week was in a big, I think it was a variety profile

66
00:03:56,625 --> 00:04:00,465
Speaker 1:  that was largely about like F1. It's just, this is like Apple's

67
00:04:00,465 --> 00:04:03,985
Speaker 1:  flagship product is now like a Brad Pitt movie. Yeah. Which is just a weird

68
00:04:03,985 --> 00:04:04,745
Speaker 1:  state of affairs.

69
00:04:05,205 --> 00:04:08,705
Speaker 2:  The thing that's great about F1 at a developer conference is that nobody

70
00:04:08,715 --> 00:04:12,705
Speaker 2:  there is even remotely qualified to, to assess whether it

71
00:04:12,705 --> 00:04:15,985
Speaker 2:  is the right thing to do or a good thing like that is not like,

72
00:04:15,985 --> 00:04:16,505
Speaker 1:  They're just like,

73
00:04:16,505 --> 00:04:19,305
Speaker 2:  Hey, here's this thing. It's for a totally different audience. It's probably

74
00:04:19,305 --> 00:04:19,505
Speaker 2:  good.

75
00:04:19,535 --> 00:04:23,385
Speaker 3:  Well that's very much reflected in the, like the TBOS segment of wwc where

76
00:04:23,385 --> 00:04:26,945
Speaker 3:  they announced like the pictures are bigger and there's more content and

77
00:04:26,945 --> 00:04:30,825
Speaker 3:  those are the features of TBO S. Like no new ideas. I will say like

78
00:04:30,855 --> 00:04:34,705
Speaker 3:  it's, WC has two tracks. There's a big consumer track, which is the part

79
00:04:34,705 --> 00:04:37,785
Speaker 3:  that we cover, and then there's an actual developer track where they get

80
00:04:37,785 --> 00:04:41,745
Speaker 3:  into the nitty gritty of how you can use different AI models

81
00:04:41,925 --> 00:04:45,745
Speaker 3:  And I x code to make swift, like that's all there. It's just

82
00:04:45,745 --> 00:04:49,065
Speaker 3:  tucked away. They had a bunch of like sub stackers there, like fashion and

83
00:04:49,065 --> 00:04:52,645
Speaker 3:  culture sub stackers who did a meet and greet with Tim.

84
00:04:53,435 --> 00:04:57,285
Speaker 3:  Sure. Right. But what's really interesting is Tim did nothing about

85
00:04:57,355 --> 00:05:01,165
Speaker 3:  Apple's products. The only big press that Tim did was

86
00:05:01,165 --> 00:05:04,445
Speaker 3:  that profile and variety with Lewis Hamilton where they talked about F1.

87
00:05:04,705 --> 00:05:07,245
Speaker 3:  And I encourage everyone to read it because

88
00:05:08,415 --> 00:05:11,965
Speaker 3:  Louis Hamilton convinced the author of that profile that he was impressed

89
00:05:12,705 --> 00:05:15,645
Speaker 3:  at at the, the skyline of San Jose.

90
00:05:17,595 --> 00:05:21,205
Speaker 3:  Like, I don't, there's, I can't, that's how, that's where, that's where that

91
00:05:21,205 --> 00:05:24,765
Speaker 3:  profile begins is like they're on the roof of Apple Park together and

92
00:05:25,425 --> 00:05:29,365
Speaker 3:  the, he's like, is that San Jose? And Tim Cook is like, it is. And

93
00:05:29,365 --> 00:05:32,405
Speaker 3:  then they like stand there and admire the beauty. And I'm like, San Jose

94
00:05:32,405 --> 00:05:34,565
Speaker 3:  is is very pretty. It's very pretty. No,

95
00:05:34,565 --> 00:05:38,085
Speaker 1:  In California, I lived in San Jose. I am, I'm qualified to

96
00:05:38,325 --> 00:05:42,205
Speaker 1:  opine on the skylight of San Jose. The skyline of San Jose does not

97
00:05:42,205 --> 00:05:45,765
Speaker 1:  exist. That's like interesting. It's weird. There's like four

98
00:05:46,045 --> 00:05:48,365
Speaker 1:  buildings. That's not a skyline. That's four

99
00:05:48,605 --> 00:05:51,885
Speaker 3:  Buildings. But if you read the profile, it's like even Lewis Park was taken

100
00:05:51,905 --> 00:05:54,645
Speaker 3:  in by Apple Park And I, you know, apple Park is very pretty, but it's been

101
00:05:54,645 --> 00:05:58,425
Speaker 3:  around for a while now. And it, it it's been,

102
00:05:58,425 --> 00:06:01,305
Speaker 3:  it's just a familiar thing. Like lots of people have been there for lots

103
00:06:01,305 --> 00:06:04,935
Speaker 3:  of reasons. Louis Hamilton is a knight who like

104
00:06:05,845 --> 00:06:09,335
Speaker 3:  routinely drives the most expensive cars in the world around Monaco.

105
00:06:09,885 --> 00:06:13,695
Speaker 3:  Like I just get the feeling like maybe, maybe this room with no furniture

106
00:06:13,695 --> 00:06:15,215
Speaker 3:  in it was not that impressive too.

107
00:06:15,795 --> 00:06:19,655
Speaker 1:  So Matt, when Matt Bella from Puck was on this show a month or

108
00:06:19,655 --> 00:06:22,695
Speaker 1:  so ago, he basically was like, I I, my question for him was essentially like,

109
00:06:22,795 --> 00:06:26,415
Speaker 1:  why are all these big tech companies so invested

110
00:06:26,595 --> 00:06:30,255
Speaker 1:  in being part of the streaming wars when it seems to mostly be all downside?

111
00:06:30,595 --> 00:06:34,575
Speaker 1:  And, and basically what he said is like, don't underestimate how much

112
00:06:34,715 --> 00:06:38,055
Speaker 1:  really wealthy people want really famous friends. And I just look at that

113
00:06:38,055 --> 00:06:41,295
Speaker 1:  picture of Tim Cook and Lewis Hamilton and I'm like, oh, I get it. Like that's,

114
00:06:41,525 --> 00:06:42,335
Speaker 1:  this is why you do

115
00:06:42,335 --> 00:06:45,855
Speaker 3:  It. There's a, there's an entire side of it. Not like it's fine variety.

116
00:06:45,925 --> 00:06:49,015
Speaker 3:  They're the trade publication of Hollywood. Sure. They do glossy features

117
00:06:49,015 --> 00:06:51,455
Speaker 3:  on new movies all the time. It's like that's, that's their function. And

118
00:06:51,455 --> 00:06:55,215
Speaker 3:  I'm glad they did it because I get to read it. But you just read it as a

119
00:06:55,215 --> 00:06:59,055
Speaker 3:  tech reporter and it, they're like, apple invented cameras for this

120
00:06:59,055 --> 00:07:01,455
Speaker 3:  movie and it's like, did they, what are the cameras like? And there's no

121
00:07:01,455 --> 00:07:05,415
Speaker 3:  further there. No follow-up is given. It's like, I guess, I

122
00:07:05,415 --> 00:07:06,135
Speaker 3:  guess they did. There

123
00:07:06,135 --> 00:07:08,655
Speaker 1:  Was a really big GQ story about the movie that actually had some of that

124
00:07:08,675 --> 00:07:11,975
Speaker 1:  detail on how they made the thing. It was pretty cool. But they're like,

125
00:07:12,695 --> 00:07:15,855
Speaker 1:  I mean this is as universally

126
00:07:16,575 --> 00:07:20,455
Speaker 1:  promoted a movie as I can remember in a long time. Like Apple

127
00:07:20,715 --> 00:07:24,375
Speaker 1:  is partly, you know, it's Brad Pitt and it's the guy who made Top Gun Maverick.

128
00:07:24,375 --> 00:07:27,775
Speaker 1:  And so it's like a big name production, but also it's very clear that Apple

129
00:07:27,795 --> 00:07:31,615
Speaker 1:  is putting like absolutely everything it has behind this movie being a

130
00:07:31,615 --> 00:07:33,495
Speaker 1:  huge hit. Which is just fascinating.

131
00:07:33,735 --> 00:07:37,575
Speaker 3:  I surprised a lot of Apple people with my extensive knowledge of the movie

132
00:07:37,575 --> 00:07:40,855
Speaker 3:  Days of Thunder and my many questions about whether they had just made Days

133
00:07:40,855 --> 00:07:44,415
Speaker 3:  of Thunder again and whether there was as much cocaine on the set of F1 as

134
00:07:44,415 --> 00:07:48,295
Speaker 3:  there was on Days of Thunder. And like literally at one point

135
00:07:48,295 --> 00:07:51,615
Speaker 3:  someone from Apple looked at me and said, you know a lot about Days of Thunder.

136
00:07:53,355 --> 00:07:56,455
Speaker 3:  So I'm, I'm dying to know that's, that's my only angle on this movie. Like,

137
00:07:56,515 --> 00:08:00,295
Speaker 3:  did they make Days of Thunder again? But Tim only did press

138
00:08:01,065 --> 00:08:05,015
Speaker 3:  about the movie. He only did photo ops with, I I

139
00:08:05,015 --> 00:08:08,335
Speaker 3:  you would call them culture reporters. Like, and that's great. That's what

140
00:08:08,335 --> 00:08:12,215
Speaker 3:  he did. That's what they got. No product conversation. The

141
00:08:12,215 --> 00:08:15,855
Speaker 3:  person who talked about products the most was Craig Federighi. And

142
00:08:15,855 --> 00:08:19,015
Speaker 3:  mostly what he did in those conversations with Lance ov, with Joanna Stern

143
00:08:19,015 --> 00:08:22,895
Speaker 3:  with a few others, he apologized for AI not being

144
00:08:22,895 --> 00:08:26,835
Speaker 3:  ready. And that's, it's, Tim is not on the

145
00:08:26,835 --> 00:08:30,635
Speaker 3:  hook for that in any way, shape or form. And I, you can, that's

146
00:08:30,635 --> 00:08:34,435
Speaker 3:  kind of the wwc right over here we're gonna have this conversation about

147
00:08:35,145 --> 00:08:38,075
Speaker 3:  Siri and why it didn't happen and what's gonna happen next. And over here

148
00:08:38,075 --> 00:08:41,955
Speaker 3:  we're gonna celebrate F1 and that's the CEO and it's this guy who's accountable

149
00:08:41,955 --> 00:08:45,035
Speaker 3:  for the mistake and this guy who's hanging out with the race car driver.

150
00:08:45,495 --> 00:08:49,225
Speaker 3:  And that feels a little upside down to me. I don't like did you guys

151
00:08:49,425 --> 00:08:51,705
Speaker 3:  perceive that from the outside? It was very much the sense on the ground

152
00:08:51,705 --> 00:08:54,865
Speaker 3:  there remotely. I feel like it was not, I mean the F1 stuff

153
00:08:54,865 --> 00:08:57,685
Speaker 2:  Was certainly not as prevalent remotely.

154
00:08:59,165 --> 00:09:02,325
Speaker 2:  I think the AI thing like was very loud, right? Because I think, you know,

155
00:09:02,325 --> 00:09:05,805
Speaker 2:  coming into it from the past like year of Apple, right?

156
00:09:05,975 --> 00:09:09,965
Speaker 2:  Their last WDC, what they, they went all in on ai. And

157
00:09:09,965 --> 00:09:13,845
Speaker 2:  it's funny, I've, I feel like I've seen some folks say like,

158
00:09:14,025 --> 00:09:17,125
Speaker 2:  why, you know, why is Apple being held up? Why do they have to do ai? Why,

159
00:09:17,225 --> 00:09:20,485
Speaker 2:  why does it matter if they get this AI done in time? It's like what? Apple

160
00:09:20,885 --> 00:09:24,685
Speaker 2:  promised it. Apple went like, yeah, really big last year

161
00:09:24,945 --> 00:09:28,765
Speaker 2:  saying that AI was part of their identity. They redefined AI as an

162
00:09:28,765 --> 00:09:32,675
Speaker 2:  acronym with their name in it. They ran ads promoting

163
00:09:32,675 --> 00:09:35,875
Speaker 2:  these features. Fast forward a year and AI

164
00:09:36,495 --> 00:09:39,675
Speaker 2:  is really just this like very shallow thing throughout the conference

165
00:09:40,775 --> 00:09:43,955
Speaker 2:  now, you know, in fairness it did have a lot to show with, with

166
00:09:45,215 --> 00:09:48,915
Speaker 2:  Liquid Glass in every single possible location. But

167
00:09:50,025 --> 00:09:53,755
Speaker 2:  yeah, that, that felt like the big one and the fact that they did not

168
00:09:53,755 --> 00:09:57,635
Speaker 2:  talk about it and then only kind of like threaded it into these interviews

169
00:09:57,645 --> 00:10:01,595
Speaker 2:  after the fact where they kind of just like e even then,

170
00:10:01,695 --> 00:10:05,675
Speaker 2:  you know, you said Craig apologized, but I, I feel like he gave kind of the

171
00:10:05,675 --> 00:10:09,115
Speaker 2:  same exact explanation to everybody where he was like, well it was kind of

172
00:10:09,115 --> 00:10:12,235
Speaker 2:  ready but not ready enough. Yeah. And we're like,

173
00:10:12,935 --> 00:10:16,755
Speaker 2:  but like what, what does that mean? Like every other company has

174
00:10:16,755 --> 00:10:20,155
Speaker 2:  done this. You guys have more money than I don't know

175
00:10:20,375 --> 00:10:23,355
Speaker 2:  anyone on earth. How can you not get

176
00:10:23,865 --> 00:10:24,795
Speaker 2:  something working?

177
00:10:25,145 --> 00:10:27,475
Speaker 3:  Wait, I want, actually, I wanna be fair. No one else has pulled this off.

178
00:10:27,475 --> 00:10:30,075
Speaker 3:  We'll come to this 'cause we're gonna talk about Alexa plus later on in the

179
00:10:30,075 --> 00:10:33,755
Speaker 3:  show, no one else has done this. Like zero companies have pulled off the

180
00:10:33,755 --> 00:10:36,955
Speaker 3:  thing that everyone wants to pull off and Apple has this problem where they

181
00:10:36,955 --> 00:10:39,555
Speaker 3:  can't say agent 'cause that's the word everyone else is using. But the idea

182
00:10:39,555 --> 00:10:42,435
Speaker 3:  that you have some like agent that like uses the apps for you is like a is

183
00:10:42,435 --> 00:10:44,915
Speaker 3:  a thing. Everybody wants to do it and Google has come sort of the closest.

184
00:10:45,055 --> 00:10:45,475
Speaker 3:  That's

185
00:10:45,475 --> 00:10:47,155
Speaker 2:  Fair. But they're not even halfway there. Yeah,

186
00:10:47,155 --> 00:10:49,595
Speaker 3:  They're not even like they're, but they're, and there are excuses. We won't

187
00:10:49,635 --> 00:10:52,475
Speaker 3:  ship the bad one and everyone else is bad, which is very Apple. Yeah. But

188
00:10:52,635 --> 00:10:55,275
Speaker 3:  everyone else is like shipping the bad one. Like you can just buy a pixel

189
00:10:55,275 --> 00:10:59,035
Speaker 3:  phone and like talk to it for six hours, you know, like it's fine.

190
00:10:59,295 --> 00:11:03,075
Speaker 1:  The like true legacy of chat GPT is going to be that every, it made

191
00:11:03,075 --> 00:11:05,835
Speaker 1:  everybody comfortable with shipping the bad one, right? Yeah. Because it's

192
00:11:05,835 --> 00:11:09,715
Speaker 1:  like, if you remember before chat GPT Google, which was like working on

193
00:11:09,715 --> 00:11:12,075
Speaker 1:  all of this stuff internally, it was like, well this stuff sucks, why would

194
00:11:12,075 --> 00:11:15,475
Speaker 1:  we ship it to people? And then chat GPT, they were just like, eh, we don't

195
00:11:15,475 --> 00:11:18,435
Speaker 1:  know if this is anything. It's a research preview. Here you go. And it like

196
00:11:18,495 --> 00:11:20,955
Speaker 1:  set the world on fire and now all of a sudden everybody had to ship all of

197
00:11:20,955 --> 00:11:24,755
Speaker 1:  their bad stuff just to prove they had a bad thing to ship. And, and Apple

198
00:11:24,895 --> 00:11:28,715
Speaker 1:  let itself get caught up in that, which is yeah, very

199
00:11:28,985 --> 00:11:30,155
Speaker 1:  unapply in that sense.

200
00:11:30,375 --> 00:11:34,285
Speaker 3:  You know, if Apple had made a chat, Bott can, you know, in, in

201
00:11:34,345 --> 00:11:36,485
Speaker 3:  all these interviews that they did, they said they were never gonna make

202
00:11:36,485 --> 00:11:38,805
Speaker 3:  a chat bot and they were just trying to pin a chat bott on 'em. And that's

203
00:11:38,805 --> 00:11:41,365
Speaker 3:  not what they're trying to make and fine. But if they just made one, can

204
00:11:41,365 --> 00:11:45,165
Speaker 3:  you imagine just how absolutely anodyne it would be

205
00:11:45,265 --> 00:11:49,045
Speaker 3:  to comply with being Apple? Like they have like some brand problems

206
00:11:49,045 --> 00:11:52,965
Speaker 3:  here where, you know, like I'm assuming there's not one lick of sex

207
00:11:53,045 --> 00:11:56,455
Speaker 3:  in the F1 movie, right? Like the Apple just like, it doesn't exist for them

208
00:11:56,735 --> 00:12:00,695
Speaker 3:  like in any other content. Like it is the most androgynous company that has

209
00:12:00,695 --> 00:12:04,055
Speaker 3:  ever existed in the history of the world. Like it's just liquid glass,

210
00:12:04,935 --> 00:12:07,995
Speaker 3:  you know what I mean? Like it's just smooth. That's it. That's Apple. And

211
00:12:07,995 --> 00:12:11,795
Speaker 3:  so like that chat bots thrive on having personality and like open eyes always

212
00:12:11,795 --> 00:12:14,555
Speaker 3:  talking like, oh this was too nice, it's too obsequious, we're gonna dial

213
00:12:14,555 --> 00:12:18,355
Speaker 3:  it. Backrock is just out there, right? Elon's like it's me and someone's

214
00:12:18,355 --> 00:12:21,995
Speaker 3:  like, this is horrifying. Like there's an element of danger to the chatbot

215
00:12:22,115 --> 00:12:25,435
Speaker 3:  'cause it is just talking to you that can you imagine if a chatbot talk like

216
00:12:25,435 --> 00:12:29,355
Speaker 3:  an Apple executive in an interview? Like there's a problem here that you

217
00:12:29,355 --> 00:12:33,075
Speaker 3:  know. And so look, my point Jake is yes, they

218
00:12:33,075 --> 00:12:36,315
Speaker 3:  haven't done it nearly as, they haven't shipped anything as bad as anyone

219
00:12:36,315 --> 00:12:39,675
Speaker 3:  else, but everyone else is still kind of bad and doesn't work. And I think

220
00:12:39,675 --> 00:12:43,155
Speaker 3:  they should say like the apple of old Steve Jobs of old have been like, look

221
00:12:43,155 --> 00:12:43,635
Speaker 3:  at this garbage.

222
00:12:44,095 --> 00:12:44,315
Speaker 1:  Yep.

223
00:12:44,665 --> 00:12:48,195
Speaker 3:  Like look at this. Like, we're not doing this. And he, he, he just like won't

224
00:12:48,195 --> 00:12:51,875
Speaker 3:  bring they can't bring themselves to do it for whatever reason. And that

225
00:12:51,875 --> 00:12:54,835
Speaker 3:  they're, I think they're just, they're kind of trapped in a, a puzzle of

226
00:12:54,835 --> 00:12:55,315
Speaker 3:  their own making.

227
00:12:55,545 --> 00:12:58,875
Speaker 2:  Yeah. I I think that's like a, a fair enough argument. And I think again,

228
00:12:58,875 --> 00:13:01,755
Speaker 2:  if they had done nothing last year, we'd be like, we, you know, we, we could,

229
00:13:01,775 --> 00:13:04,595
Speaker 2:  we could impugn all of this onto them, right? Like they're waiting to ship

230
00:13:04,595 --> 00:13:07,915
Speaker 2:  the right thing, but like instead they're stuck in a situation where

231
00:13:08,345 --> 00:13:12,315
Speaker 2:  Siri has existed for a decade and it is the bad version

232
00:13:12,415 --> 00:13:16,275
Speaker 2:  of the chatbot. Yeah. They promised a better version and now

233
00:13:16,305 --> 00:13:20,285
Speaker 2:  it's like, you know, if if they just ship, honestly, like again, if they

234
00:13:20,285 --> 00:13:23,845
Speaker 2:  just ship chat GBT, we'd be like, it has some problems. It has but it's better

235
00:13:23,845 --> 00:13:25,045
Speaker 2:  than Siri currently is.

236
00:13:25,395 --> 00:13:28,605
Speaker 3:  Yeah. I don't need to belabor this. Joanna did the best of these interviews.

237
00:13:28,625 --> 00:13:29,605
Speaker 3:  She pushed them really hard.

238
00:13:31,145 --> 00:13:35,085
Speaker 3:  She like really hard good on her for doing that. And then I

239
00:13:35,085 --> 00:13:38,605
Speaker 3:  was on a podcast with her. We were the guests who replaced Craig

240
00:13:38,605 --> 00:13:41,285
Speaker 3:  Federici and Greg s Schack or whoever, whatever. I think the last year was

241
00:13:41,285 --> 00:13:44,445
Speaker 3:  Mike Rockwell. John Gruber always has a talk show with Apple executives.

242
00:13:44,445 --> 00:13:48,125
Speaker 3:  He asked for a decade and they declined his invitation this year. And Joanna

243
00:13:48,125 --> 00:13:51,805
Speaker 3:  And I were the dancing monkey fill-ins and we had a great time, but we just

244
00:13:51,965 --> 00:13:54,125
Speaker 3:  honestly had a great time. Especially 'cause Joanna had just interviewed

245
00:13:54,125 --> 00:13:57,885
Speaker 3:  them. So if you want more unpacking of all of that, you can listen to the

246
00:13:57,885 --> 00:14:00,405
Speaker 3:  talk show. It was fun to do. Thanks for John. Thanks to John for having us

247
00:14:00,405 --> 00:14:03,845
Speaker 3:  on the, the only thing I just wanted to unpack was like, this was a weird

248
00:14:03,865 --> 00:14:07,275
Speaker 3:  one and like a lot of ways it was, it was just a weird one.

249
00:14:07,775 --> 00:14:11,675
Speaker 3:  And usually Apple is very confident like this. They're doing what

250
00:14:11,675 --> 00:14:14,995
Speaker 3:  they're doing. And this year for the, the split between

251
00:14:15,935 --> 00:14:19,835
Speaker 3:  the confidence of Hollywood style marketing of a race car movie and the

252
00:14:19,835 --> 00:14:21,715
Speaker 3:  sort of like back foot,

253
00:14:23,275 --> 00:14:26,055
Speaker 3:  the rest of the industry is pursuing AI in one way and, and we don't think

254
00:14:26,055 --> 00:14:29,895
Speaker 3:  it's good enough and we will, we will try to explain but

255
00:14:29,895 --> 00:14:33,135
Speaker 3:  never not really explain like it was on the ground kind of drawing.

256
00:14:33,515 --> 00:14:37,455
Speaker 1:  It was weird to watch because it was, it was, I mean Apple doesn't do anything

257
00:14:37,455 --> 00:14:41,375
Speaker 1:  like this. Not deliberately, but this felt particularly deliberate

258
00:14:41,395 --> 00:14:44,255
Speaker 1:  in the sense that like, you go and read and watch some of the stuff that

259
00:14:44,745 --> 00:14:48,735
Speaker 1:  Craig Feder in particular was saying. I mean, and, and he had a, he

260
00:14:48,735 --> 00:14:52,445
Speaker 1:  had the speech just nailed right? And, and they, he was unusually

261
00:14:52,445 --> 00:14:54,685
Speaker 1:  accessible in a bunch of different ways. They were, they talked to a bunch

262
00:14:54,685 --> 00:14:58,405
Speaker 1:  of different people and just said the same thing over and over

263
00:14:58,505 --> 00:15:02,045
Speaker 1:  and over again. And that's not to say it's not true, it's just like clearly

264
00:15:02,315 --> 00:15:06,085
Speaker 1:  this was the, the message that they had and they were like, not only do we

265
00:15:06,085 --> 00:15:08,485
Speaker 1:  have to communicate all this stuff that we think is cool and exciting and

266
00:15:08,985 --> 00:15:12,765
Speaker 1:  why liquid glass is great, we also have to explain

267
00:15:12,895 --> 00:15:16,125
Speaker 1:  where Siri is. And it is, it's very clear the company knows that.

268
00:15:16,705 --> 00:15:20,125
Speaker 1:  And ordinarily, like we always make fun of Apple for pretending that

269
00:15:20,885 --> 00:15:24,765
Speaker 1:  anything it doesn't want to exist just doesn't exist. And you, you can feel

270
00:15:25,595 --> 00:15:29,285
Speaker 1:  that Apple is like, it, it knows, it has to acknowledge this stuff

271
00:15:29,785 --> 00:15:33,685
Speaker 1:  in a way that is awkward for Apple to try and do. And even

272
00:15:33,685 --> 00:15:36,765
Speaker 1:  at the very beginning of the keynote on Monday for Craig to be like, yeah,

273
00:15:36,765 --> 00:15:39,125
Speaker 1:  we're we're shipping this stuff. We're we're still working on it. It's not

274
00:15:39,125 --> 00:15:42,325
Speaker 1:  quite ready, it's coming later this year. Very unapply. And you, you can

275
00:15:42,325 --> 00:15:45,565
Speaker 1:  tell this company is just like very much on its back foot with a lot of this

276
00:15:45,565 --> 00:15:46,085
Speaker 1:  stuff right now.

277
00:15:46,635 --> 00:15:50,445
Speaker 3:  Yeah. And a lot of, by the way that the, the speech, it was

278
00:15:50,555 --> 00:15:54,045
Speaker 3:  them saying John Gruber was wrong,

279
00:15:54,595 --> 00:15:58,005
Speaker 3:  like directly, like there's a bad narrative out there about this and what

280
00:15:58,005 --> 00:16:01,605
Speaker 3:  they mean, what they have meant this entire time is we hate John's blog post.

281
00:16:01,945 --> 00:16:05,325
Speaker 3:  We are mad at him. And for it's like fine, like

282
00:16:06,195 --> 00:16:10,125
Speaker 3:  John Gruber is maybe the most influential Apple blogger of all time.

283
00:16:10,385 --> 00:16:13,525
Speaker 3:  He remains so he has been like Steve Jobs used to like send his blog post

284
00:16:13,545 --> 00:16:17,325
Speaker 3:  to people to be like, here's yes, this is what I think too. Great.

285
00:16:17,635 --> 00:16:20,525
Speaker 3:  He's he has achieved that goal, but it's just pretty wild. The disparity

286
00:16:20,525 --> 00:16:24,485
Speaker 3:  between a trillion dollar company and literally one guy, they're not mad

287
00:16:24,485 --> 00:16:27,485
Speaker 3:  at like the New York Times. They're mad at one guy.

288
00:16:27,555 --> 00:16:29,685
Speaker 1:  Well they're also mad at the New York Times. Like

289
00:16:29,685 --> 00:16:33,045
Speaker 3:  In a way that you're like always like, yeah, supposed to, like everyone in

290
00:16:33,075 --> 00:16:36,685
Speaker 3:  America is perpetually angry at the New York Times. They feed on your hate

291
00:16:36,745 --> 00:16:40,245
Speaker 3:  and they drive subscriptions to their games because of it. Like

292
00:16:40,505 --> 00:16:43,325
Speaker 3:  that's their job. They're the New York Times. They're, they're owned by a

293
00:16:43,325 --> 00:16:45,685
Speaker 3:  billionaire family and they have 10 million lawyers and have apples and apple

294
00:16:45,685 --> 00:16:49,285
Speaker 3:  and that's fine. This is one guy, like

295
00:16:49,285 --> 00:16:52,445
Speaker 3:  literally one guy, like he at one point he was like, I'm one guy,

296
00:16:53,845 --> 00:16:57,455
Speaker 3:  like the Virgin newsroom dwarfs John Gruber by a DX,

297
00:16:58,665 --> 00:16:59,855
Speaker 3:  right? Like it's

298
00:17:00,125 --> 00:17:00,415
Speaker 1:  Yeah.

299
00:17:00,765 --> 00:17:04,415
Speaker 3:  He's one guy. And that dynamic was one of the like

300
00:17:04,505 --> 00:17:07,575
Speaker 3:  truly the weirdest parts of this where what they meant was we're mad at that

301
00:17:07,575 --> 00:17:08,135
Speaker 3:  one blog post.

302
00:17:08,555 --> 00:17:12,335
Speaker 1:  If I'm intuiting the dynamic here correctly. It seems like what,

303
00:17:12,445 --> 00:17:16,335
Speaker 1:  what Gruber said in that post, what earlier this

304
00:17:16,335 --> 00:17:20,135
Speaker 1:  spring was basically that what Apple showed was

305
00:17:20,445 --> 00:17:24,295
Speaker 1:  more or less a lie. Like it was, it was a concept video disguised as

306
00:17:24,375 --> 00:17:28,295
Speaker 1:  a product demonstration. And Apple is

307
00:17:28,295 --> 00:17:32,095
Speaker 1:  saying no, it was just a really bad product

308
00:17:32,455 --> 00:17:34,095
Speaker 1:  that we were demonstrating. And it's like,

309
00:17:34,575 --> 00:17:35,655
Speaker 3:  I, I guess

310
00:17:35,655 --> 00:17:39,415
Speaker 1:  That's an argument, but I'm not sure that's as compelling as you think that

311
00:17:39,415 --> 00:17:39,775
Speaker 1:  it is.

312
00:17:40,225 --> 00:17:44,015
Speaker 3:  Right. What they said to everyone was that was real code. Right. And it just

313
00:17:44,015 --> 00:17:46,455
Speaker 3:  didn't mean our quality standards. Right. Okay.

314
00:17:46,715 --> 00:17:49,965
Speaker 1:  We made a bad thing, but we made a thing

315
00:17:50,585 --> 00:17:54,525
Speaker 1:  is a is a really interesting version of a defense against the, the spirit

316
00:17:54,525 --> 00:17:57,605
Speaker 1:  of Gruber's argument, which is that Siri sucks and Apple should feel bad

317
00:17:57,605 --> 00:17:57,965
Speaker 1:  about it.

318
00:17:58,095 --> 00:18:01,085
Speaker 3:  Right? And then somewhere in Apple's culture, the decision that they could

319
00:18:01,085 --> 00:18:05,045
Speaker 3:  get away with it was made. Right? Right. And then if you're gambling

320
00:18:05,045 --> 00:18:08,325
Speaker 3:  like that, especially in a prerecorded video, when the bill comes due, someone

321
00:18:08,325 --> 00:18:12,165
Speaker 3:  has to pay it. And that's really his argument. Like he, I don't think he

322
00:18:12,165 --> 00:18:14,965
Speaker 3:  ever says they lied. And he says, I think the title is something is Rotten

323
00:18:14,965 --> 00:18:17,605
Speaker 3:  in the state of Cupertino. Like what he means is something in the culture

324
00:18:17,745 --> 00:18:21,725
Speaker 3:  has gone awry to the place where you're, because you have these prerecorded

325
00:18:21,725 --> 00:18:24,645
Speaker 3:  videos, you can get away with a little bit more. Like, do you know what else

326
00:18:25,145 --> 00:18:29,045
Speaker 3:  was real code that was definitely not up to Apple's quality

327
00:18:29,325 --> 00:18:32,805
Speaker 3:  standards. The iPhone that Steve Jobs demoed at the first iPhone event. Right.

328
00:18:33,475 --> 00:18:37,245
Speaker 3:  Like that, that was a demo on Rails. Like famously there was a

329
00:18:37,245 --> 00:18:40,925
Speaker 3:  magic path through the demo that would prevent that iPhone from crashing

330
00:18:40,925 --> 00:18:43,845
Speaker 3:  and any deviation from it would've crashed the phone. Yep. And the whole

331
00:18:43,845 --> 00:18:47,485
Speaker 3:  iPhone team was like doing shots through that demo

332
00:18:47,805 --> 00:18:50,765
Speaker 3:  as Steve Shots got through it. 'cause they were like so worked up and nervous

333
00:18:51,145 --> 00:18:53,365
Speaker 3:  and they were all completely hammer drunk at the end of it. It's like, great

334
00:18:53,365 --> 00:18:57,325
Speaker 3:  stories, you can go find it out, out on the internet, but he took the risk

335
00:18:58,575 --> 00:19:02,155
Speaker 3:  and the risk is what would've absolved them of a delay.

336
00:19:02,645 --> 00:19:05,735
Speaker 3:  Right. He's like, I actually used this thing, I actually showed it to you.

337
00:19:05,735 --> 00:19:07,695
Speaker 3:  It's not quite up to our standards. We're gonna keep working on it. People

338
00:19:07,695 --> 00:19:10,255
Speaker 3:  are like, well we believe you. The prerecorded demo

339
00:19:11,215 --> 00:19:15,085
Speaker 3:  eliminates the risk. It can be even worse. There can be no magic path.

340
00:19:15,445 --> 00:19:16,365
Speaker 3:  'cause it's a prerecorded demo,

341
00:19:16,375 --> 00:19:19,405
Speaker 1:  Right? Like how many tries did it take you to get this to work once the way

342
00:19:19,405 --> 00:19:23,045
Speaker 1:  that you needed it to in order to shoot it? It's very different from what

343
00:19:23,045 --> 00:19:26,765
Speaker 1:  it used to be, which is like Craig Federighi walks up to a laptop on

344
00:19:26,765 --> 00:19:29,965
Speaker 1:  stage and uses it in front of you. Yeah. Like it, it's just a completely

345
00:19:29,965 --> 00:19:30,605
Speaker 1:  different dynamic.

346
00:19:30,995 --> 00:19:34,885
Speaker 3:  Yeah. So I like, again, it was just that vibe was weird

347
00:19:34,905 --> 00:19:38,805
Speaker 3:  and that's what I, I was just immersed in it for like several days and in

348
00:19:38,805 --> 00:19:42,165
Speaker 3:  the meantime, like the switch to is coming out and Microsoft is announcing

349
00:19:42,165 --> 00:19:45,565
Speaker 3:  an entirely new like, handheld strategy for Xbox. And I'm like looking at

350
00:19:45,565 --> 00:19:49,205
Speaker 3:  our list, I'm like, all this other stuff happened and that stuff is basically

351
00:19:49,205 --> 00:19:52,925
Speaker 3:  like, I, I don't even know how to describe it. It was like an alternate

352
00:19:52,955 --> 00:19:56,765
Speaker 3:  reality where like there's the highest of highs like Lewis

353
00:19:56,965 --> 00:20:00,845
Speaker 3:  Hamilton in a race car and the weirdest of lows. Yeah. So

354
00:20:01,195 --> 00:20:04,755
Speaker 3:  let's talk about the other stuff again, if you want to hear me dive way more

355
00:20:04,755 --> 00:20:08,155
Speaker 3:  into the weirdness of Apple Talk show, I I assume we'll be out. You can also

356
00:20:08,155 --> 00:20:11,995
Speaker 3:  watch it in a Vision Pro. It was a full event, a packed theater. It was really

357
00:20:11,995 --> 00:20:12,955
Speaker 3:  fun to meet everybody who was there.

358
00:20:13,065 --> 00:20:16,555
Speaker 1:  Spatial neli is, I don't think a thing I'm ready for. I tell you it was

359
00:20:16,555 --> 00:20:20,515
Speaker 3:  True. It was really weird. Lots of cameras on stage and then a 360 camera

360
00:20:20,515 --> 00:20:24,155
Speaker 3:  in the middle. It was fun. Anyhow, you can go listen to the talk show or

361
00:20:24,155 --> 00:20:27,355
Speaker 3:  watch it I guess. But the Switch two came out and it's like very, like we

362
00:20:27,355 --> 00:20:30,035
Speaker 3:  have a lot of them on our team. People have been playing them, people are

363
00:20:30,035 --> 00:20:33,435
Speaker 3:  buying them at incredible rates, but then there's like the inevitable problems

364
00:20:33,435 --> 00:20:34,475
Speaker 3:  of scale. David, what's going on?

365
00:20:34,705 --> 00:20:38,555
Speaker 1:  Yeah. So the, the vibes around the switch two

366
00:20:38,555 --> 00:20:41,795
Speaker 1:  launch have been strange in the sense that like

367
00:20:42,455 --> 00:20:46,235
Speaker 1:  the, there were, I mean, going all the way back to like the day they

368
00:20:46,235 --> 00:20:49,845
Speaker 1:  announced, it was also the day that Trump announced tariffs with like the

369
00:20:49,865 --> 00:20:53,325
Speaker 1:  big, you know, sign on the lawn of the White House. And so

370
00:20:53,335 --> 00:20:56,245
Speaker 1:  everything was thrown into chaos and nobody knew what it was gonna cost or

371
00:20:56,365 --> 00:21:00,005
Speaker 1:  whatever it was gonna ship. But the thing ends up shipping people had an

372
00:21:00,005 --> 00:21:03,885
Speaker 1:  unusually easy time buying it, I think, which A lot of people took to

373
00:21:03,915 --> 00:21:07,125
Speaker 1:  mean maybe demand was not as high as we expected.

374
00:21:07,945 --> 00:21:10,165
Speaker 1:  We talked a little bit about this last week, but like I was able to just

375
00:21:10,165 --> 00:21:13,845
Speaker 1:  walk into Target on launch day and buy one. I heard from

376
00:21:13,915 --> 00:21:17,805
Speaker 1:  lots of people who also did Chris Grant on

377
00:21:17,825 --> 00:21:21,125
Speaker 1:  our in at from Fox Media was very excited. He saw my post about how easy

378
00:21:21,125 --> 00:21:24,005
Speaker 1:  it was to get one and he went and got one and was very thankful. So like,

379
00:21:24,315 --> 00:21:26,965
Speaker 1:  everybody's like, okay, maybe this thing isn't the hit that we thought it

380
00:21:26,965 --> 00:21:30,885
Speaker 1:  was. It's just a better switch. And then Nintendo puts out

381
00:21:30,885 --> 00:21:34,725
Speaker 1:  data earlier this week that said it sold 3.5 million of them over

382
00:21:34,905 --> 00:21:38,845
Speaker 1:  the basically the long launch weekend, which would make it the fastest selling

383
00:21:38,845 --> 00:21:42,565
Speaker 1:  game console of all time, which is a huge

384
00:21:42,565 --> 00:21:46,525
Speaker 1:  number full of context. Right. And actually, actually what

385
00:21:46,525 --> 00:21:49,805
Speaker 1:  it suggests is that what Nintendo did

386
00:21:50,385 --> 00:21:54,285
Speaker 1:  was manage its supply chain for a launch better than

387
00:21:54,285 --> 00:21:58,005
Speaker 1:  any console in the history of video games. Right. Which is like, not a

388
00:21:58,055 --> 00:22:01,965
Speaker 1:  small thing, but it it, it appears that both tons of people

389
00:22:01,965 --> 00:22:05,885
Speaker 1:  wanted this thing and Nintendo had enough of them, which is like a

390
00:22:05,945 --> 00:22:09,845
Speaker 1:  pretty remarkable accomplishment in the current world that we live in.

391
00:22:10,525 --> 00:22:13,845
Speaker 1:  Reviews are still coming out. No one got one ahead of time, which was an

392
00:22:14,045 --> 00:22:17,765
Speaker 1:  interesting and and odd thing that doesn't often happen with things like

393
00:22:17,765 --> 00:22:21,725
Speaker 1:  this. But so reviews are still coming out. I

394
00:22:21,725 --> 00:22:24,285
Speaker 1:  think there's a pretty good chance that by the time you're hearing this episode,

395
00:22:24,285 --> 00:22:26,965
Speaker 1:  Andrew Webster's review will be live. He's also gonna be on the show next

396
00:22:26,965 --> 00:22:27,765
Speaker 1:  Tuesday talking about it.

397
00:22:29,345 --> 00:22:32,845
Speaker 1:  But like all of them say sort of the same thing, which is like yeah, it's

398
00:22:32,845 --> 00:22:33,565
Speaker 1:  a really great switch.

399
00:22:34,195 --> 00:22:37,525
Speaker 3:  Yeah. My sense of reading all the reviews And I read a bunch on, on the plane

400
00:22:37,545 --> 00:22:41,445
Speaker 3:  on the way home yesterday was, And I could not bring

401
00:22:41,445 --> 00:22:45,245
Speaker 3:  myself to buy an OLED switch. Like I have the original switch and like after

402
00:22:45,245 --> 00:22:48,605
Speaker 3:  a while you're like, man, this screen is small and bad. I should get an OLED

403
00:22:48,605 --> 00:22:51,165
Speaker 3:  screen. And then you like look at it, you're like, this is, this is just

404
00:22:51,165 --> 00:22:54,485
Speaker 3:  a switch with an oled. I can't spend this money. I have children. Like,

405
00:22:55,635 --> 00:22:59,625
Speaker 3:  like no, and then this is enough. This is

406
00:22:59,625 --> 00:23:02,865
Speaker 3:  enough to make you buy a new switch. But it's then it's a new switch.

407
00:23:03,155 --> 00:23:06,905
Speaker 1:  Right? And, and there's, there's this weird dynamic of it is both,

408
00:23:07,505 --> 00:23:11,465
Speaker 1:  I think a, a nearly perfect upgrade to

409
00:23:11,465 --> 00:23:14,185
Speaker 1:  the switch in the sense that it, like, it made all the things that you didn't

410
00:23:14,185 --> 00:23:17,585
Speaker 1:  like better and it made all of the things that you already liked

411
00:23:18,005 --> 00:23:21,865
Speaker 1:  better than that. But there is like, there are no new ideas here

412
00:23:22,045 --> 00:23:24,705
Speaker 1:  in a way that I think Nintendo's bar for

413
00:23:25,575 --> 00:23:29,505
Speaker 1:  launching things that are like weird and wild and wonderful is so high

414
00:23:29,855 --> 00:23:33,545
Speaker 1:  that you're like, my mind has not been blown by something. I never even

415
00:23:33,865 --> 00:23:37,825
Speaker 1:  imagined a game console could do Four outta 10. And you're

416
00:23:37,825 --> 00:23:38,585
Speaker 1:  like, wait, hold on.

417
00:23:38,975 --> 00:23:40,385
Speaker 3:  Like, what, what are we

418
00:23:40,505 --> 00:23:43,665
Speaker 1:  Supposed? So it's just, it's been a very strange phenomenon. And I will say

419
00:23:43,685 --> 00:23:46,565
Speaker 1:  the biggest concern I've heard so far

420
00:23:48,105 --> 00:23:51,445
Speaker 1:  has been about battery life. People have done a bunch of tests and, and there's

421
00:23:51,445 --> 00:23:55,285
Speaker 1:  some indication that like the switch to battery life is as much as like

422
00:23:55,715 --> 00:23:59,085
Speaker 1:  half of the switch oles battery life, which is bad

423
00:23:59,685 --> 00:24:03,165
Speaker 1:  like, like two hours of battery life bad, which is bad.

424
00:24:04,145 --> 00:24:07,405
Speaker 1:  And it's bad enough that Nintendo is now saying it might be a bug, which

425
00:24:07,405 --> 00:24:11,325
Speaker 1:  is like dangerously close to a, you're holding it wrong Yeah. Explanation

426
00:24:11,325 --> 00:24:15,125
Speaker 1:  for this kind of stuff. And so that's, that's a little sketchy and

427
00:24:15,335 --> 00:24:19,265
Speaker 1:  weird. But in general, outside of not being as exciting

428
00:24:19,285 --> 00:24:23,145
Speaker 1:  as some people wanted, this is all going exceptionally well for

429
00:24:23,145 --> 00:24:23,625
Speaker 1:  Nintendo.

430
00:24:24,185 --> 00:24:27,625
Speaker 2:  I got one Monday I've been playing Zelda. It's delightful. It really, it's,

431
00:24:27,625 --> 00:24:30,385
Speaker 2:  it is a switch and everything is a little bit better. It is what it should

432
00:24:30,385 --> 00:24:34,265
Speaker 2:  be for, for this year. I, the thing that I think is a little bit underwhelming

433
00:24:34,265 --> 00:24:37,825
Speaker 2:  about it right now is not necessarily the hardware. I think one of the things

434
00:24:37,825 --> 00:24:41,545
Speaker 2:  that's so wonderful about the original switch is by

435
00:24:41,545 --> 00:24:44,545
Speaker 2:  virtue of being a little bit behind all the other consoles,

436
00:24:45,605 --> 00:24:49,225
Speaker 2:  it just has this incredible library of old games from other consoles Yeah.

437
00:24:49,225 --> 00:24:52,665
Speaker 2:  That it can now play because it's capable enough. And so now

438
00:24:52,665 --> 00:24:56,545
Speaker 2:  theoretically the switch too is unlocking the ability to play a whole

439
00:24:56,575 --> 00:25:00,225
Speaker 2:  wave of games that the original switch wasn't capable of.

440
00:25:01,115 --> 00:25:04,135
Speaker 3:  Can you get Smash TV on the switch too? That's what I'm asking right now.

441
00:25:04,145 --> 00:25:04,495
Speaker 3:  Maybe

442
00:25:05,605 --> 00:25:08,455
Speaker 2:  That, that, that age rating might not be supported by

443
00:25:08,455 --> 00:25:08,935
Speaker 1:  Nintendo.

444
00:25:09,315 --> 00:25:12,735
Speaker 2:  But the problem is on day one, that stuff is not there.

445
00:25:13,065 --> 00:25:16,295
Speaker 2:  Right. You can play cyberpunk. That is crazy. You can play

446
00:25:16,915 --> 00:25:18,735
Speaker 2:  in upgraded No Man Sky. That's

447
00:25:18,735 --> 00:25:19,975
Speaker 1:  Cool. Fortnite sick,

448
00:25:20,145 --> 00:25:23,855
Speaker 2:  Right? Fortnite Okay, great. But like, you know, I'm playing through

449
00:25:24,055 --> 00:25:27,815
Speaker 2:  Zelda and it's like I'm playing the final five

450
00:25:27,965 --> 00:25:31,695
Speaker 2:  side quests that I did not finish earlier. Like it, it's, you know,

451
00:25:32,315 --> 00:25:35,975
Speaker 2:  So I, I'm very excited. I think this is going to be

452
00:25:36,375 --> 00:25:40,175
Speaker 2:  a, a fantastic handheld eventually, but what I'm looking forward to

453
00:25:40,235 --> 00:25:44,135
Speaker 2:  is okay, eventually Red Dead Redemption two, which

454
00:25:44,215 --> 00:25:47,215
Speaker 2:  I have never been able to play because I only have a switch is gonna come

455
00:25:47,215 --> 00:25:50,815
Speaker 2:  to the Switch too. Yeah. And it will look very good that day is not today.

456
00:25:50,815 --> 00:25:51,495
Speaker 2:  That's also like

457
00:25:51,535 --> 00:25:55,455
Speaker 1:  A perfect switch to game. 'cause it's, so much of it is just like, ride a

458
00:25:55,455 --> 00:25:59,295
Speaker 1:  horse for 45 minutes and like this, you can just sit on the couch and ride

459
00:25:59,295 --> 00:26:01,575
Speaker 1:  a horse for 45 minutes. Like that's the dream. Which

460
00:26:01,595 --> 00:26:03,295
Speaker 2:  By the way is also the appeal of Zelda.

461
00:26:03,325 --> 00:26:06,535
Speaker 1:  Yeah, it's true. Like, it's great. Would you like to walk through a forest

462
00:26:06,755 --> 00:26:07,535
Speaker 1:  all night? Like Sure.

463
00:26:07,595 --> 00:26:08,695
Speaker 2:  You're the only games I play

464
00:26:09,095 --> 00:26:12,455
Speaker 3:  Zelda's one of the few games that involves that level of grinding

465
00:26:12,805 --> 00:26:16,695
Speaker 3:  that I can tolerate because it doesn't feel like a job. And like so many

466
00:26:16,695 --> 00:26:20,655
Speaker 3:  of these games I'm like, I have a job. Like I'm, I already do so much grinding.

467
00:26:20,655 --> 00:26:21,535
Speaker 3:  Have you seen my email?

468
00:26:21,815 --> 00:26:25,255
Speaker 1:  There's a lot of that in, in Red Dead, frankly. That's what I'm saying. Do

469
00:26:25,255 --> 00:26:28,655
Speaker 1:  you wanna go milk the cows this morning? And it's like, no, I, it's 2025.

470
00:26:28,735 --> 00:26:29,815
Speaker 1:  I don't have to do that anymore.

471
00:26:30,035 --> 00:26:33,935
Speaker 3:  But Zelda is very much, it's very different. It's like you, you, you have

472
00:26:33,935 --> 00:26:37,655
Speaker 3:  to cook and it's like, this is delightful actually, I don't know why, because

473
00:26:37,655 --> 00:26:39,615
Speaker 3:  you cook the magic. I won't do this for myself. Right.

474
00:26:42,325 --> 00:26:45,965
Speaker 3:  I'm excited for it. I'm, I'm, I'm, I'm goading myself into buying one

475
00:26:46,425 --> 00:26:49,325
Speaker 3:  at some point. Like, I, I just need one more game. I think it's not Breath

476
00:26:49,325 --> 00:26:52,245
Speaker 3:  of the Wild for me. I've played Breath the Wild a lot. Breath of the Wild

477
00:26:52,245 --> 00:26:55,405
Speaker 3:  again, but better when I've already done luck rendering. We'll see. But it's

478
00:26:55,405 --> 00:26:58,085
Speaker 2:  Coming. Here's the thing, I I think give it a year and that library will

479
00:26:58,085 --> 00:27:01,885
Speaker 2:  be there. And right now it's like if you want Mario Kart, great and if

480
00:27:01,885 --> 00:27:03,325
Speaker 2:  not, eh, you, you

481
00:27:03,325 --> 00:27:06,045
Speaker 1:  Can, I also think if you're a Nintendo, you, you are absolutely fine with

482
00:27:06,045 --> 00:27:08,725
Speaker 1:  this outcome. Right? Like, I was actually thinking about this earlier that

483
00:27:09,075 --> 00:27:12,885
Speaker 1:  most companies spend a lot of time caring about and perfectly

484
00:27:12,885 --> 00:27:16,805
Speaker 1:  trying to time their launch weekend and sort of bring everything in one place

485
00:27:16,805 --> 00:27:20,525
Speaker 1:  and make it a huge event. Nintendo ships like one console

486
00:27:20,655 --> 00:27:24,045
Speaker 1:  every eight years And I think is not super concerned

487
00:27:24,715 --> 00:27:28,125
Speaker 1:  with what happens in the first four days. That said, it sold three and a

488
00:27:28,125 --> 00:27:31,525
Speaker 1:  half million of them in the first few days. So like, it's, it's a real have

489
00:27:31,525 --> 00:27:34,605
Speaker 1:  your cake and eat it too situation. But I think if all of this goes well,

490
00:27:34,605 --> 00:27:37,805
Speaker 1:  this will be a notably better console like on

491
00:27:38,335 --> 00:27:41,965
Speaker 1:  Labor Day Weekend than it was at launch day. Oh,

492
00:27:41,965 --> 00:27:44,805
Speaker 3:  I think it's the holidays that matter the most, right? Like they've sold

493
00:27:44,845 --> 00:27:47,925
Speaker 3:  a lot of them, but they will have the inventory, they will understand their

494
00:27:47,985 --> 00:27:51,845
Speaker 3:  supply chain fluctuations and maybe they'll understand a tariff and they

495
00:27:51,845 --> 00:27:54,525
Speaker 3:  will have a better library of games through a market. Totally. Holidays good

496
00:27:54,525 --> 00:27:54,765
Speaker 3:  for them.

497
00:27:56,825 --> 00:28:00,625
Speaker 3:  Somewhat related. Microsoft announced a vastly more confused strategy about

498
00:28:00,625 --> 00:28:01,625
Speaker 3:  handheld game this week. Oh my god,

499
00:28:03,305 --> 00:28:06,545
Speaker 1:  I cannot tell you how much I've read about this. Trying to figure out if

500
00:28:06,545 --> 00:28:07,905
Speaker 1:  any of it makes any sense. They

501
00:28:07,905 --> 00:28:10,385
Speaker 3:  Announced new Xboxes that you can hold in your hand that don't play Xbox

502
00:28:10,385 --> 00:28:12,665
Speaker 3:  games just to be a hundred percent clear on what happened.

503
00:28:14,215 --> 00:28:17,005
Speaker 1:  Right? Yeah. That's no, that's, that's right. That's, yes. It's

504
00:28:17,005 --> 00:28:18,885
Speaker 3:  Weird. It's a, it's just a weird thing that they did.

505
00:28:18,885 --> 00:28:21,725
Speaker 2:  Yeah. And they're like not being super clear about this either, right. Like

506
00:28:21,725 --> 00:28:24,165
Speaker 2:  if you were just to watch this video, you're like, sick. It's an Xbox that

507
00:28:24,165 --> 00:28:28,085
Speaker 2:  plays Xbox games and it's like Xbox asterisk. Like what,

508
00:28:28,085 --> 00:28:29,685
Speaker 2:  what is an Xbox game? Yeah. That's not

509
00:28:29,685 --> 00:28:33,525
Speaker 1:  Clear. So the launch here is is we've, we're in the middle of this like

510
00:28:34,425 --> 00:28:38,405
Speaker 1:  run of game launches and game events. Summer Game Fest,

511
00:28:38,405 --> 00:28:41,605
Speaker 1:  which used to be E three, it was last week. They've just done a, we we've

512
00:28:41,605 --> 00:28:44,325
Speaker 1:  heard about a million new games, all of which are gonna ship at some point

513
00:28:44,325 --> 00:28:48,245
Speaker 1:  in the next century over the last like eight days. And at one

514
00:28:48,245 --> 00:28:48,525
Speaker 1:  of these

515
00:28:50,165 --> 00:28:54,125
Speaker 1:  Microsoft and a Seuss announced two new

516
00:28:54,125 --> 00:28:57,965
Speaker 1:  devices that are just like wrong ally handhelds,

517
00:28:58,145 --> 00:29:02,085
Speaker 1:  except they run this like brand new Xbox focused

518
00:29:02,085 --> 00:29:05,645
Speaker 1:  version of Windows, which is an insane sentence that I look forward to talking

519
00:29:05,645 --> 00:29:09,325
Speaker 1:  about. Yep. But did it in this very like, casual way where it was like, it

520
00:29:09,325 --> 00:29:13,205
Speaker 1:  was mostly a gears of war demo. And then they were just

521
00:29:13,205 --> 00:29:16,565
Speaker 1:  like, here's this new handheld that is actually the future of our entire

522
00:29:16,565 --> 00:29:17,685
Speaker 1:  portable gaming strategy.

523
00:29:17,915 --> 00:29:21,885
Speaker 2:  They would not allow anybody to take photos of it operating currently, by

524
00:29:21,885 --> 00:29:22,045
Speaker 2:  the way.

525
00:29:22,045 --> 00:29:22,885
Speaker 3:  Oh, that's, that's perfect.

526
00:29:23,115 --> 00:29:26,845
Speaker 1:  Yeah. It's really, it's very weird. And it's also called the a

527
00:29:27,015 --> 00:29:30,805
Speaker 1:  Seuss r Xbox Ally and the a Seus Rog Xbox

528
00:29:31,125 --> 00:29:34,845
Speaker 1:  Ally X, which is bad and everyone should feel

529
00:29:34,905 --> 00:29:38,045
Speaker 1:  bad who came up with a name that is that many words long.

530
00:29:38,825 --> 00:29:42,645
Speaker 1:  But it's all just very weird. And I think the, the strategy as I understand

531
00:29:42,645 --> 00:29:46,555
Speaker 1:  it, and, and again that is, that is a leap that I'm about to take

532
00:29:46,555 --> 00:29:50,315
Speaker 1:  here because I don't understand it, is that instead of

533
00:29:50,855 --> 00:29:54,585
Speaker 1:  trying to basically make Xbox

534
00:29:54,945 --> 00:29:58,785
Speaker 1:  specific things, what what Microsoft is trying to do is

535
00:29:59,345 --> 00:30:03,305
Speaker 1:  shove the Xbox software and windows ever closer together

536
00:30:03,565 --> 00:30:07,025
Speaker 1:  so that what you get on a handheld in particular is not

537
00:30:07,935 --> 00:30:11,665
Speaker 1:  Xbox software, like, which would be sort of windows underneath, but it's

538
00:30:11,665 --> 00:30:15,265
Speaker 1:  like all Xbox on the top. But it is actually essentially Windows

539
00:30:17,175 --> 00:30:20,785
Speaker 1:  optimized for Xbox with like, it's, it's like Android, but with a custom

540
00:30:20,785 --> 00:30:23,945
Speaker 1:  launcher is like essentially what Microsoft is trying to do with Windows

541
00:30:24,005 --> 00:30:24,585
Speaker 1:  and Xbox.

542
00:30:24,885 --> 00:30:27,305
Speaker 3:  That's the classic winning strategy of a custom

543
00:30:27,305 --> 00:30:31,265
Speaker 1:  Launcher. Yeah. Right. So you, you turn this thing on and Tom Warren has

544
00:30:31,265 --> 00:30:33,185
Speaker 1:  covered this a bunch for us. I'll put some links in the show notes, but the

545
00:30:33,185 --> 00:30:36,945
Speaker 1:  way he describes it, it, it loads some of windows but not

546
00:30:36,965 --> 00:30:40,865
Speaker 1:  all of Windows and then loads this Xbox launcher on top. So the

547
00:30:40,865 --> 00:30:44,545
Speaker 1:  idea is Windows should use less memory and thus run faster, which is a good

548
00:30:44,545 --> 00:30:48,105
Speaker 1:  thing. 'cause it just absolutely crushes most of these handhelds. And then

549
00:30:48,445 --> 00:30:51,905
Speaker 1:  the layer on top is, is what looks like an Xbox launcher

550
00:30:52,095 --> 00:30:55,265
Speaker 1:  that'll launch not just your Xbox games, but all of the other games that

551
00:30:55,325 --> 00:30:58,385
Speaker 1:  run on PCs. So like steam store stuff and things like that.

552
00:30:59,135 --> 00:31:03,065
Speaker 1:  Notably, like you said, not Xbox games. You can stream Xbox

553
00:31:03,065 --> 00:31:06,985
Speaker 1:  games. Oh good. You can't, they are PC games that you are playing

554
00:31:07,045 --> 00:31:10,465
Speaker 1:  on your Xbox handheld. And so it's like, there there is this like

555
00:31:10,905 --> 00:31:14,705
Speaker 1:  mush of all of Microsoft's many things into

556
00:31:14,905 --> 00:31:17,745
Speaker 1:  a handheld software that kind of, sort of looks like an Xbox.

557
00:31:18,105 --> 00:31:21,425
Speaker 2:  I I think you can see the trajectory, right? Like they lost to the PS four,

558
00:31:21,425 --> 00:31:25,145
Speaker 2:  they lost to the PS five and now they're like, okay, wait a second.

559
00:31:25,245 --> 00:31:29,185
Speaker 2:  We, we run Windows, we run possibly the biggest gaming platform that

560
00:31:29,185 --> 00:31:30,105
Speaker 2:  exists and

561
00:31:30,105 --> 00:31:32,545
Speaker 3:  Windows to the consumer most relevant as a gaming platform.

562
00:31:32,845 --> 00:31:36,745
Speaker 2:  Yes. Right. And So I think when you look ahead, what is the next Xbox?

563
00:31:37,045 --> 00:31:40,905
Speaker 2:  If there is a singular next Xbox, it's like perhaps it is

564
00:31:40,905 --> 00:31:44,425
Speaker 2:  this Windows thing, right? They're doing a pretty hard, a pretty aggressive

565
00:31:44,425 --> 00:31:47,705
Speaker 2:  pivot. And I think in some ways they're looking at it as maybe they don't

566
00:31:47,905 --> 00:31:51,865
Speaker 2:  actually have a lot to lose given the state of the Xbox in the console

567
00:31:51,895 --> 00:31:52,625
Speaker 2:  race. This

568
00:31:52,625 --> 00:31:56,545
Speaker 1:  Is just such an old school Microsoft strategy to me though. And I don't mean

569
00:31:56,545 --> 00:32:00,305
Speaker 1:  that as a compliment. Like in the Steve Balmer days, the thing was

570
00:32:01,125 --> 00:32:04,305
Speaker 1:  all Windows everything, right? Like we are, we are going to put Windows on

571
00:32:04,305 --> 00:32:07,585
Speaker 1:  everything and that is how we are going to win. We are the Windows company,

572
00:32:07,805 --> 00:32:10,745
Speaker 1:  so we're gonna put Windows on phones and we're gonna put Windows on your

573
00:32:10,745 --> 00:32:14,705
Speaker 1:  desktop and we're gonna put Windows everywhere you can think of. And Satya

574
00:32:14,705 --> 00:32:18,625
Speaker 1:  Nadella came in and said, actually that's the wrong like, level of abstraction

575
00:32:18,645 --> 00:32:22,465
Speaker 1:  at which to put our focus what we are as a cloud company. And they were like,

576
00:32:22,685 --> 00:32:26,105
Speaker 1:  the bet is not on Windows, the bet is on the internet. And like we are going

577
00:32:26,105 --> 00:32:29,945
Speaker 1:  to power data centers and that's going to be very successful. And they've

578
00:32:29,945 --> 00:32:33,745
Speaker 1:  been doing that with the Xbox, right? Like Game Pass is the big bet for the

579
00:32:33,775 --> 00:32:37,705
Speaker 1:  Xbox, right? That like, instead of having a, a console that I plug a disc

580
00:32:37,775 --> 00:32:41,605
Speaker 1:  into and play games on it, anything with a screen becomes an Xbox, right?

581
00:32:41,605 --> 00:32:43,925
Speaker 1:  Like that's the whole marketing strategy. That's what they're trying to do.

582
00:32:44,585 --> 00:32:48,485
Speaker 1:  And now they're just like, rather than build

583
00:32:48,555 --> 00:32:51,485
Speaker 1:  good software, they're just trying to shove Windows back into it. And I'm

584
00:32:51,485 --> 00:32:54,525
Speaker 1:  like, no, you, you missed, you missed the point of all of this, which is

585
00:32:54,525 --> 00:32:57,445
Speaker 1:  that it doesn't all have to be Windows because it shouldn't all be Windows.

586
00:32:58,075 --> 00:33:01,805
Speaker 3:  Well there's weirdness there. I mean, I I do

587
00:33:01,815 --> 00:33:05,205
Speaker 3:  enjoy it. Like bomber's version of Windows everywhere

588
00:33:06,205 --> 00:33:10,145
Speaker 3:  manifested in like Microsoft trying to conquer the living room with

589
00:33:10,145 --> 00:33:13,985
Speaker 3:  Windows, right? And, and for years they would announce a new

590
00:33:13,985 --> 00:33:17,905
Speaker 3:  attempt to put a Windows PC in your living room, culminating in the

591
00:33:18,055 --> 00:33:21,545
Speaker 3:  Xbox One, which ran a cut down weird version of Windows

592
00:33:21,775 --> 00:33:25,345
Speaker 3:  with an Xbox launcher on top of it. And then like this whole plan did

593
00:33:25,645 --> 00:33:29,545
Speaker 3:  IR blaster control your satellite box or something that did not

594
00:33:29,545 --> 00:33:33,375
Speaker 3:  work. It just didn't work. And then they, you know, they moved

595
00:33:33,395 --> 00:33:36,135
Speaker 3:  on and they, they're like, the Xbox is the Xbox again, we're totally focused

596
00:33:36,135 --> 00:33:39,815
Speaker 3:  on gaming, it's this custom thing. But in the meantime, the

597
00:33:40,735 --> 00:33:41,835
Speaker 3:  the handheld market

598
00:33:43,365 --> 00:33:47,185
Speaker 3:  was the, became basically the switch and a bunch of steam deck clones

599
00:33:47,185 --> 00:33:50,565
Speaker 3:  and the steam deck, right? And if you're gonna go compete with that, you're

600
00:33:50,565 --> 00:33:54,405
Speaker 3:  like, oh, this is taking market share from us in any way. Then

601
00:33:54,525 --> 00:33:57,765
Speaker 3:  you're stuck with, they don't want Xbox games, they want PC games here.

602
00:33:58,655 --> 00:34:02,225
Speaker 3:  Like what gamers are saying is we wanna take our PC games on the go and you

603
00:34:02,225 --> 00:34:06,025
Speaker 3:  can't be like, here's some console games on the go because I

604
00:34:06,025 --> 00:34:08,905
Speaker 3:  don't think they can compete with the gamers who want PC games. And that

605
00:34:08,905 --> 00:34:12,515
Speaker 3:  might be the strategy error. Do you know what I mean? Like that might actually

606
00:34:12,515 --> 00:34:13,195
Speaker 3:  be the mistake.

607
00:34:13,655 --> 00:34:17,195
Speaker 1:  So you have to go backwards from where is our big library of games

608
00:34:17,505 --> 00:34:21,195
Speaker 1:  into a handheld Yeah. Because that's just what Microsoft has to do.

609
00:34:21,195 --> 00:34:21,675
Speaker 1:  Because

610
00:34:21,675 --> 00:34:24,875
Speaker 3:  If you're like, the future of the Xbox is more accessible PC gaming,

611
00:34:25,455 --> 00:34:29,315
Speaker 3:  you are cruising your way towards putting Windows underneath the TV again.

612
00:34:29,835 --> 00:34:33,115
Speaker 3:  Yeah. Like you're, they're headed there. Tom basically wrote this story for

613
00:34:33,115 --> 00:34:36,315
Speaker 3:  us. Microsoft just teased this next gen Xbox console and nobody noticed.

614
00:34:37,125 --> 00:34:40,795
Speaker 3:  Right. And his point is, if you look at these handhelds that are

615
00:34:40,825 --> 00:34:44,745
Speaker 3:  basically ways to run PC games in cut

616
00:34:44,745 --> 00:34:48,505
Speaker 3:  down power restricted environments that acknowledge the existence of

617
00:34:48,505 --> 00:34:51,425
Speaker 3:  Steam, but still have Windows, you can run your Windows games.

618
00:34:52,415 --> 00:34:55,275
Speaker 3:  Oh, that's gonna be the next, it's obviously this is how the next Xbox will

619
00:34:55,275 --> 00:34:57,995
Speaker 3:  work. Yeah. Somewhere in there it was like, what happens to the Xbox library?

620
00:34:59,345 --> 00:35:03,245
Speaker 3:  'cause that is pretty important to a lot of people. And I I I, that's

621
00:35:03,245 --> 00:35:06,525
Speaker 3:  the answer that I think Microsoft hasn't even gestured at. And then the additional

622
00:35:06,525 --> 00:35:09,925
Speaker 3:  weirdness is they didn't make this handheld, someone else made this handhold.

623
00:35:10,275 --> 00:35:13,845
Speaker 1:  Well, and there was some news recently that Microsoft actually killed a project

624
00:35:14,945 --> 00:35:18,845
Speaker 1:  or, or paused a project to build something like this. So it

625
00:35:18,845 --> 00:35:22,645
Speaker 1:  is, it is like in, it seems to be running further and further towards

626
00:35:22,985 --> 00:35:26,645
Speaker 1:  we want to be a software provider and a games provider, not the

627
00:35:26,925 --> 00:35:27,845
Speaker 1:  hardware system. Right.

628
00:35:27,845 --> 00:35:31,445
Speaker 3:  They wanna be Steam. Yeah. Being Steam is a better business than being Windows

629
00:35:31,705 --> 00:35:34,045
Speaker 3:  in in the gaming industry right now, which is really weird.

630
00:35:34,195 --> 00:35:35,365
Speaker 1:  That is, yeah, that's true.

631
00:35:36,115 --> 00:35:39,355
Speaker 3:  And so you'd rather be Steam where you're like collecting your credits and

632
00:35:39,355 --> 00:35:42,955
Speaker 3:  like taking percentages of the transactions as opposed to

633
00:35:43,195 --> 00:35:47,075
Speaker 3:  Microsoft, which collects a license when you buy your PC and like

634
00:35:47,295 --> 00:35:51,185
Speaker 3:  you only do that once, like most of the time they don't even

635
00:35:51,185 --> 00:35:54,825
Speaker 3:  get a cut of your GPU, right? Like the things you might upgrade on pc, Microsoft

636
00:35:54,825 --> 00:35:57,865
Speaker 3:  doesn't get a piece of, and they certainly a piece of the transactions that

637
00:35:57,865 --> 00:36:00,745
Speaker 3:  are kind the platform, they wanna be Steam. So they're shipping a thing that

638
00:36:00,745 --> 00:36:04,225
Speaker 3:  looks way, way more like Steam by the way that that launcher, they haven't

639
00:36:04,225 --> 00:36:06,705
Speaker 3:  given a name, it's just they keep calling it the single screen experience

640
00:36:06,725 --> 00:36:10,625
Speaker 3:  or the full screen experience, which is just like, guys give it a name. Knowing

641
00:36:10,905 --> 00:36:11,985
Speaker 1:  Microsoft, that's just what it'll be.

642
00:36:12,425 --> 00:36:16,305
Speaker 3:  Yeah, it's a weird one. I it's, it's interesting to see the gaming

643
00:36:16,305 --> 00:36:19,225
Speaker 3:  market just like shake up, like all, you know, game studios are coming and

644
00:36:19,225 --> 00:36:23,185
Speaker 3:  going like it's a topsy-turvy time in games and then there's Nintendo

645
00:36:23,185 --> 00:36:25,305
Speaker 3:  that's like Mario Kart 3.5 million sold.

646
00:36:25,415 --> 00:36:28,865
Speaker 1:  Yeah. I do think though that we are running

647
00:36:29,025 --> 00:36:32,865
Speaker 1:  headlong into the, like the handheld is the future

648
00:36:32,885 --> 00:36:36,785
Speaker 1:  of gaming era here. There's like, there's been a bunch of

649
00:36:36,785 --> 00:36:39,585
Speaker 1:  news about a PlayStation six portable

650
00:36:40,605 --> 00:36:44,185
Speaker 1:  that's starting to, you know, all of that is like super early rumors about

651
00:36:44,185 --> 00:36:46,865
Speaker 1:  a thing that's gonna launch in like two or three years, but is like, that's

652
00:36:46,865 --> 00:36:49,825
Speaker 1:  the, that's the scuttlebutt that's out there as like these flagship devices

653
00:36:50,475 --> 00:36:54,225
Speaker 1:  might start to look more like the Switch than the PS five. Like

654
00:36:54,225 --> 00:36:54,505
Speaker 1:  quickly.

655
00:36:54,855 --> 00:36:58,785
Speaker 3:  This is just my theory that the Samsung Frame TV Harold's the, the

656
00:36:58,785 --> 00:37:02,625
Speaker 3:  Death of Hollywood people don't want TVs, man. Yeah. They don't want

657
00:37:02,785 --> 00:37:05,505
Speaker 3:  'em, they want handhelds, they want, they everybody wants to be playing their

658
00:37:05,505 --> 00:37:09,105
Speaker 3:  own weird PS five handhold on the couch next to someone else playing a weird

659
00:37:09,785 --> 00:37:12,705
Speaker 3:  se rock ally next to someone playing a switch.

660
00:37:12,855 --> 00:37:16,025
Speaker 1:  Yeah. Jake, what's your switch playing setup? Are you a, are you a handheld

661
00:37:16,025 --> 00:37:17,185
Speaker 1:  guy or are you docked on the tv?

662
00:37:17,505 --> 00:37:21,185
Speaker 2:  I I, yeah. No, it's, it's almost exclusively tv. Okay. But like, and yet

663
00:37:21,225 --> 00:37:24,385
Speaker 2:  I don't think I would buy it if it was not also a handheld console. Like

664
00:37:24,535 --> 00:37:25,465
Speaker 2:  knowing I can,

665
00:37:27,055 --> 00:37:30,425
Speaker 2:  yeah. I don't know. It's, it's wonderful to be able to take it on the go.

666
00:37:30,425 --> 00:37:30,625
Speaker 2:  But

667
00:37:30,745 --> 00:37:31,985
Speaker 1:  Have you brought it on the Subway yet?

668
00:37:33,045 --> 00:37:34,225
Speaker 2:  I'm not crazy. No. Subway

669
00:37:34,225 --> 00:37:37,545
Speaker 1:  Switch was one of the most like transformative gaming experiences I've ever,

670
00:37:37,825 --> 00:37:38,985
Speaker 1:  like sincerely. It

671
00:37:38,985 --> 00:37:40,585
Speaker 2:  Is. I do see so many people using them on the subway.

672
00:37:40,895 --> 00:37:44,035
Speaker 3:  Does the new Switch have better support for Bluetooth headphones? Someone

673
00:37:44,055 --> 00:37:45,155
Speaker 3:  say yes. It, yes.

674
00:37:45,785 --> 00:37:48,115
Speaker 1:  Okay. Better is such a low bar.

675
00:37:48,855 --> 00:37:49,875
Speaker 3:  You see what I'm saying? It

676
00:37:49,875 --> 00:37:51,555
Speaker 1:  Is better. It's not good, but

677
00:37:51,555 --> 00:37:54,675
Speaker 3:  It's better. But I'm saying subway switch was also a transformative experience

678
00:37:54,675 --> 00:37:57,035
Speaker 3:  for everyone else on the subway. Yeah. So

679
00:37:57,075 --> 00:37:58,195
Speaker 2:  Speakers are better on it.

680
00:37:58,195 --> 00:38:01,315
Speaker 1:  Well now it has two USBC ports so you can, you can plug in your headphones

681
00:38:01,355 --> 00:38:04,275
Speaker 1:  a little more easily, which is something. But yeah, I think, I think it's,

682
00:38:04,385 --> 00:38:08,155
Speaker 1:  it's, it's gonna be a very handheld e next like

683
00:38:08,395 --> 00:38:11,755
Speaker 1:  18 months. And I think there's a decent chance that if Microsoft can't figure

684
00:38:11,755 --> 00:38:15,355
Speaker 1:  out how to push all this stuff together in a way that makes sense, it's going

685
00:38:15,355 --> 00:38:17,275
Speaker 1:  to have had the right idea and still lose

686
00:38:18,275 --> 00:38:18,595
Speaker 3:  Microsoft.

687
00:38:23,465 --> 00:38:27,075
Speaker 3:  Yeah, fair enough. A couple other little bits in our

688
00:38:27,135 --> 00:38:30,345
Speaker 3:  gadget lightning round, by the way, this would've been a gadget lightning

689
00:38:30,345 --> 00:38:31,345
Speaker 3:  round in case you hadn't noticed.

690
00:38:31,585 --> 00:38:32,345
Speaker 1:  Yes. We're going so fast.

691
00:38:32,705 --> 00:38:35,285
Speaker 3:  Nothing. Phone three coming to the US is actually happening.

692
00:38:36,025 --> 00:38:39,715
Speaker 1:  Very exciting. So nothing is launching its next phone

693
00:38:39,895 --> 00:38:43,155
Speaker 1:  and its first over ear headphones, which I'm actually very intrigued by

694
00:38:43,775 --> 00:38:47,595
Speaker 1:  on July 1st. So like in three weeks. And

695
00:38:47,785 --> 00:38:50,715
Speaker 1:  over the course of the run of this company, they've gotten sort of increasingly

696
00:38:51,315 --> 00:38:55,115
Speaker 1:  USE the, the last, the, the

697
00:38:55,115 --> 00:38:59,035
Speaker 1:  phone two I think worked on a couple of carriers in the US and like worked

698
00:38:59,105 --> 00:39:02,755
Speaker 1:  fine on others but wasn't sort of officially supported.

699
00:39:03,975 --> 00:39:07,195
Speaker 1:  But now, so the, the news about the phone three is it's gonna be on sale

700
00:39:07,575 --> 00:39:11,435
Speaker 1:  on Amazon in the us which I actually think is a pretty big deal. And in Nothing

701
00:39:11,725 --> 00:39:14,835
Speaker 1:  store it'll support at and t and T-Mobile

702
00:39:16,455 --> 00:39:20,315
Speaker 1:  and is going to be like an actual like honest to god US phone,

703
00:39:20,645 --> 00:39:24,505
Speaker 1:  which I think is pretty cool. Nothing has surprised

704
00:39:24,505 --> 00:39:27,625
Speaker 1:  me over the years in that it continues to make like pretty interesting, pretty

705
00:39:27,675 --> 00:39:30,505
Speaker 1:  compelling phones. The company

706
00:39:31,485 --> 00:39:34,185
Speaker 1:  was always like, we're doing phones so that we can do the next thing. And

707
00:39:34,185 --> 00:39:36,865
Speaker 1:  part of me is like, is the next thing just over your headphones? Like, I

708
00:39:36,865 --> 00:39:40,665
Speaker 1:  don't know. But it is, it is maybe the most

709
00:39:40,915 --> 00:39:44,665
Speaker 1:  compelling non gigantic smartphone maker

710
00:39:44,815 --> 00:39:48,625
Speaker 1:  left. And So I find myself continuing to root for

711
00:39:48,625 --> 00:39:51,505
Speaker 3:  It. There's this book out now called Apple in China. It's by Patrick McGee.

712
00:39:51,505 --> 00:39:55,185
Speaker 3:  He was the Financial Times correspondent on Apple

713
00:39:55,285 --> 00:39:58,745
Speaker 3:  for years. He was, you gotta read this book. This book is incredible. It

714
00:39:58,745 --> 00:40:01,825
Speaker 3:  has all kinds of like bits and bobs in about Apple in China and including

715
00:40:01,895 --> 00:40:05,185
Speaker 3:  like how they figured out how to manufacture their first iMac and how badly

716
00:40:05,185 --> 00:40:08,945
Speaker 3:  that went. And Fox on swooping in with a pirated reverse

717
00:40:09,185 --> 00:40:11,465
Speaker 3:  engineered iMac to prove that they could do it at scale. It's very good.

718
00:40:12,265 --> 00:40:15,065
Speaker 3:  Anyway, the point I'm, I'm bringing this up in the context of nothing because

719
00:40:15,305 --> 00:40:19,225
Speaker 3:  a lot of that book is about Apple basically creating the Chinese phone ecosystem

720
00:40:20,065 --> 00:40:23,405
Speaker 3:  by training all these engineers at all these factories and how to do the

721
00:40:23,405 --> 00:40:26,965
Speaker 3:  things. Oh, interesting. And then the Chinese government and Chinese companies

722
00:40:26,965 --> 00:40:30,805
Speaker 3:  realizing they could just take those engineers away and swap in new engineers

723
00:40:30,805 --> 00:40:34,485
Speaker 3:  and Apple would've to train those too. And that became sort of like the basis

724
00:40:34,625 --> 00:40:38,445
Speaker 3:  of the piece between Apple and the Chinese government. Super

725
00:40:38,765 --> 00:40:42,205
Speaker 3:  fascinating stuff. And what's really interesting about that is

726
00:40:43,205 --> 00:40:47,045
Speaker 3:  there's a part where Huawei gets in trouble with US government and to

727
00:40:47,045 --> 00:40:50,205
Speaker 3:  save itself it spins out honor it's like budget phone division, right? Which

728
00:40:50,205 --> 00:40:53,765
Speaker 3:  is the competitor to apo, which was where nothing came from.

729
00:40:54,065 --> 00:40:58,045
Speaker 3:  And this is all, this ecosystem is created because Apple trained all

730
00:40:58,045 --> 00:41:01,445
Speaker 3:  these engineers. And then like there has been all these battles, And I'm

731
00:41:01,445 --> 00:41:05,365
Speaker 3:  only bringing this up because nothing has gotten to a place where it is

732
00:41:05,365 --> 00:41:08,805
Speaker 3:  an interesting competitor to Apple. But it came out of that ecosystem

733
00:41:09,555 --> 00:41:13,445
Speaker 3:  like in very real ways. And I I if

734
00:41:13,445 --> 00:41:16,925
Speaker 3:  you're interested in these phones and like what they can do and whether they're

735
00:41:16,925 --> 00:41:20,085
Speaker 3:  better than Apple, if if you have, if you're that sort of person and many,

736
00:41:20,085 --> 00:41:23,645
Speaker 3:  many, many, many Vergecast people are, you should read this book just to

737
00:41:23,645 --> 00:41:26,645
Speaker 3:  get a sense of the foundation of where these companies came from and why

738
00:41:26,645 --> 00:41:27,765
Speaker 3:  they're able to kind of like

739
00:41:29,345 --> 00:41:32,995
Speaker 3:  collect a bunch of interesting ideas from the, the Chinese iPhone

740
00:41:33,065 --> 00:41:36,485
Speaker 3:  supply chain and design ecosystem and seemingly

741
00:41:36,595 --> 00:41:39,725
Speaker 3:  outpace apple, Which is just totally fascinating

742
00:41:39,725 --> 00:41:42,885
Speaker 1:  To me. Yeah, that's really interesting. Dom Preston on our team has just

743
00:41:42,885 --> 00:41:46,725
Speaker 1:  like, every week seems to just like drop a story about

744
00:41:46,875 --> 00:41:50,765
Speaker 1:  some wild China brand phone that we'll never see in

745
00:41:50,765 --> 00:41:54,165
Speaker 1:  the US and every single time it's like, look at this weird thing they did

746
00:41:54,165 --> 00:41:57,845
Speaker 1:  with the camera. And we are just like, everybody is just starting to push

747
00:41:57,915 --> 00:42:01,085
Speaker 1:  past into weird new ideas about what smartphones can be.

748
00:42:01,315 --> 00:42:04,005
Speaker 3:  Yeah. And it's, and it's because of this incredible base of manufacturing

749
00:42:04,015 --> 00:42:06,765
Speaker 3:  there, which by the way is like the reason for tariffs and blah blah blah,

750
00:42:06,765 --> 00:42:10,525
Speaker 3:  blah. Like it's all there. I I I can't recommend this book enough. And it's

751
00:42:10,525 --> 00:42:13,805
Speaker 3:  so funny, after you read the book, you look at things like The Nothing Phone

752
00:42:13,805 --> 00:42:16,365
Speaker 3:  Free and you're like, oh, I have a totally different perspective on these

753
00:42:16,365 --> 00:42:20,285
Speaker 3:  devices. Hmm. They, they came from like a different ecosystem

754
00:42:20,395 --> 00:42:24,285
Speaker 3:  than the one that we are used to. But that ecosystem was seeded by the

755
00:42:24,285 --> 00:42:28,005
Speaker 3:  success of the iPhone swap stuff. Speaking of totally weird products to

756
00:42:28,205 --> 00:42:31,805
Speaker 3:  make no sense. HP has revealed a $25,000 piece of hardware

757
00:42:32,105 --> 00:42:36,005
Speaker 3:  to do Google Beam, which is Google's like 3D TV video conferencing

758
00:42:36,005 --> 00:42:39,965
Speaker 3:  system. This is a victory. 'cause the first Google beams are

759
00:42:39,965 --> 00:42:43,085
Speaker 3:  like totally custom and cost like a million dollars. And we're only prototypes

760
00:42:43,605 --> 00:42:47,325
Speaker 3:  25,000. I mean, this is a corporate video conferencing product. And to be

761
00:42:47,325 --> 00:42:51,085
Speaker 2:  Clear, you need at least two of these. Correct. This is not, you can't

762
00:42:51,085 --> 00:42:53,045
Speaker 2:  just spend 20 5K

763
00:42:53,145 --> 00:42:55,605
Speaker 3:  Or you have a friend right. At another company. Oh

764
00:42:55,605 --> 00:42:55,925
Speaker 2:  Yeah, yeah,

765
00:42:55,925 --> 00:42:59,735
Speaker 1:  Yeah. True. If But if you just have the one, you're

766
00:42:59,735 --> 00:43:02,695
Speaker 1:  basically just gonna be like the best looking person on your Google meet

767
00:43:02,755 --> 00:43:03,255
Speaker 1:  and that's it.

768
00:43:05,285 --> 00:43:07,655
Speaker 1:  Yeah. If you have two. So this, this is the thing that used to be Project

769
00:43:07,695 --> 00:43:11,615
Speaker 1:  starline, the, the like fancy conferencing thing that has been

770
00:43:11,615 --> 00:43:15,335
Speaker 1:  inside of Google for like a decade. They've been running on this for forever

771
00:43:15,555 --> 00:43:19,535
Speaker 1:  and it's super fascinating and they, they rebranded

772
00:43:19,535 --> 00:43:22,495
Speaker 1:  it to Beam. It was just this year, right? It was like a month ago. Yeah.

773
00:43:22,715 --> 00:43:26,255
Speaker 1:  And now our, our actual actually they're

774
00:43:26,615 --> 00:43:30,335
Speaker 1:  shipping is strong, but products with names exist. This thing is called the

775
00:43:30,515 --> 00:43:34,335
Speaker 1:  HP Dimension. Perfect. And it has, the spec list is just truly

776
00:43:34,335 --> 00:43:38,255
Speaker 1:  fantastic. It has a 65 inch light field display with six high

777
00:43:38,255 --> 00:43:42,215
Speaker 1:  speed cameras inside the bezel. And the idea is

778
00:43:42,215 --> 00:43:45,695
Speaker 1:  that it, it is able to basically map you

779
00:43:46,275 --> 00:43:49,895
Speaker 1:  and your space to turn you into like a three-dimensional thing that sits

780
00:43:49,895 --> 00:43:53,775
Speaker 1:  on the other side of the screen from the person

781
00:43:53,775 --> 00:43:56,815
Speaker 1:  that you're talking to. And I've done a demo of this in the past and it is

782
00:43:56,815 --> 00:44:00,775
Speaker 1:  the, the effect is amazing. Like it is really sincerely the

783
00:44:00,775 --> 00:44:04,615
Speaker 1:  best version of this thing I have ever tried in my life. Yeah. But

784
00:44:04,615 --> 00:44:08,255
Speaker 1:  it's again, like Jake said, this is $50,000 worth of

785
00:44:08,255 --> 00:44:11,535
Speaker 1:  equipment. And I look at this and I'm like, who, who is this actually

786
00:44:12,315 --> 00:44:12,535
Speaker 1:  for

787
00:44:13,135 --> 00:44:13,695
Speaker 3:  Sergei Brin?

788
00:44:13,825 --> 00:44:17,335
Speaker 1:  Maybe, maybe this is like, this is just gonna be every

789
00:44:17,535 --> 00:44:20,175
Speaker 1:  CEO is gonna have this and this is just gonna be how they talk to each other.

790
00:44:21,605 --> 00:44:24,015
Speaker 3:  Well, so the, the one piece of weirdness here,

791
00:44:25,545 --> 00:44:29,285
Speaker 3:  it's a single user product, but you can't have this in a conference room

792
00:44:29,285 --> 00:44:31,685
Speaker 3:  with like six people talking about a conference. Oh, true. Right. So there

793
00:44:31,685 --> 00:44:34,405
Speaker 3:  are a lot of enterprise video conferencing products that cost this much.

794
00:44:34,805 --> 00:44:38,645
Speaker 3:  By the way, the $25,000 doesn't come with a license to run Google Beam.

795
00:44:39,125 --> 00:44:42,755
Speaker 3:  That's a separate, that's just like a separate monthly charge or something.

796
00:44:42,785 --> 00:44:45,955
Speaker 3:  It's very, it's very good. All that's perfect. Love it. But usually you buy

797
00:44:45,955 --> 00:44:48,515
Speaker 3:  that for a conference room and so you get the value out of all that money

798
00:44:48,535 --> 00:44:52,475
Speaker 3:  in a conference room. This is for one person talking to one person in

799
00:44:52,475 --> 00:44:55,795
Speaker 3:  his life, like a manner as possible, which I think is perfect. Yeah.

800
00:44:56,295 --> 00:44:59,275
Speaker 2:  The effect is really convincing. Like, I, I use it like a year and a half

801
00:44:59,295 --> 00:45:02,315
Speaker 2:  ago or something and it, it looks great and it feels great and you know,

802
00:45:02,415 --> 00:45:05,395
Speaker 2:  to the extent that video calls are kind of uncomfortable, I think this does

803
00:45:05,395 --> 00:45:09,355
Speaker 2:  away with a lot of that. But it still feels like one

804
00:45:09,355 --> 00:45:13,335
Speaker 2:  of those things where the, the end goal of this has to

805
00:45:13,335 --> 00:45:17,295
Speaker 2:  be to shrink this way down and make it like, I don't know,

806
00:45:17,295 --> 00:45:21,255
Speaker 2:  $250 because the, this is just not a thing that

807
00:45:21,255 --> 00:45:25,095
Speaker 2:  can scale. Like th there's not going to be a a world in which

808
00:45:26,055 --> 00:45:29,695
Speaker 2:  companies outfit every single conference room with these in part because

809
00:45:29,705 --> 00:45:33,375
Speaker 2:  again, you need a dedicated room for a single

810
00:45:33,375 --> 00:45:35,175
Speaker 2:  person Right. To have a video call.

811
00:45:35,395 --> 00:45:39,135
Speaker 1:  But the problem is, And I I suspect this is what Google continues to run

812
00:45:39,135 --> 00:45:43,015
Speaker 1:  into, is as soon as you make it smaller, you kill the effect. Yeah.

813
00:45:43,155 --> 00:45:47,135
Speaker 1:  The thing only tracks if you look like you and you

814
00:45:47,135 --> 00:45:50,175
Speaker 1:  don't look like you on a 10 inch screen, even if it's the most amazing,

815
00:45:50,725 --> 00:45:52,895
Speaker 1:  perfectly rendered version of you. Oh, come

816
00:45:52,895 --> 00:45:55,095
Speaker 3:  On, I want to talk to Tiny 3D David really badly.

817
00:45:56,855 --> 00:45:59,505
Speaker 1:  Just me. But you can put me in your pocket is like, yeah, that's what we're

818
00:45:59,505 --> 00:46:00,025
Speaker 1:  going for. It's

819
00:46:00,025 --> 00:46:02,385
Speaker 3:  Like, Hey buddy, have you tried this notion update?

820
00:46:03,855 --> 00:46:07,385
Speaker 1:  Like I was just about to say the, the Facebook portal stuff is like,

821
00:46:07,685 --> 00:46:10,585
Speaker 1:  that's a version of the hardware I have always imagined for this that like,

822
00:46:10,585 --> 00:46:14,025
Speaker 1:  that's what you try to get to. It's a thing I can put on top of my television

823
00:46:14,045 --> 00:46:17,985
Speaker 1:  or it's a thing I can just have as like my secondary screen that I use for

824
00:46:17,985 --> 00:46:21,705
Speaker 1:  calls. But again, that's really hard because

825
00:46:21,765 --> 00:46:25,665
Speaker 1:  you need the person to be lifesize in order for them to appear lifesize.

826
00:46:26,325 --> 00:46:29,825
Speaker 1:  And So I think I just, I I totally agree with you Jake, but I also don't,

827
00:46:29,865 --> 00:46:33,545
Speaker 1:  I don't know how you get to that point. Like maybe this thing just

828
00:46:33,545 --> 00:46:36,625
Speaker 1:  doesn't scale in any meaningful way and maybe Google it just is gonna have

829
00:46:36,625 --> 00:46:37,225
Speaker 1:  to be fine with it.

830
00:46:37,925 --> 00:46:40,985
Speaker 3:  I'm actually, it's the display as always. It's the display that fascinates

831
00:46:40,985 --> 00:46:44,025
Speaker 3:  me the most. So they keep calling a light, light field display, which is,

832
00:46:44,285 --> 00:46:48,185
Speaker 3:  you know, we, I haven't seen a beam device up close. Like they

833
00:46:48,185 --> 00:46:51,985
Speaker 3:  had them at io but I wasn't allowed to go and like walk up to them. The

834
00:46:51,985 --> 00:46:55,545
Speaker 3:  early versions of starline, it was very much just a wave guide on in the

835
00:46:55,545 --> 00:46:59,225
Speaker 3:  front of a tv. Like it was more complicated than that. But that's what it

836
00:46:59,345 --> 00:47:03,025
Speaker 3:  was, you know, and I'm sure this is more complicated than that, but that's

837
00:47:03,025 --> 00:47:06,385
Speaker 3:  still what it is. And those things, glasses

838
00:47:06,775 --> 00:47:10,665
Speaker 3:  free 3D in that way tends to be optimized for a single viewer

839
00:47:10,665 --> 00:47:14,265
Speaker 3:  in a specific spot. And there are some new interesting glasses free

840
00:47:14,555 --> 00:47:17,745
Speaker 3:  3D technologies that are sort of out there there, there have been some like

841
00:47:18,025 --> 00:47:20,905
Speaker 3:  overheated articles lately that are like three Ds back baby. And it's like,

842
00:47:21,825 --> 00:47:25,505
Speaker 3:  I don't know about that, but Sure. And that's the, that's your multi-user

843
00:47:25,505 --> 00:47:29,065
Speaker 3:  problem really. Can the display show 3D to multiple people in multiple

844
00:47:29,295 --> 00:47:33,285
Speaker 3:  spots around the room. I truly do not know the answer to that for Beam.

845
00:47:33,675 --> 00:47:36,445
Speaker 3:  I've known the answer for everything else for a long time that has required

846
00:47:36,445 --> 00:47:40,365
Speaker 3:  glasses, right? And then your product is said, what are you gonna do? Like,

847
00:47:40,665 --> 00:47:44,005
Speaker 3:  that's, that's the end of that. So we'll see. I'm excited about it. Like

848
00:47:44,245 --> 00:47:47,965
Speaker 3:  I do love a new display. I, I, I love a new display technology And I

849
00:47:47,965 --> 00:47:51,805
Speaker 3:  certainly think it's time for some more interesting video conferencing ideas

850
00:47:51,805 --> 00:47:55,725
Speaker 3:  that are not Zoom. Making an AI avatar view to pretend to pay

851
00:47:55,725 --> 00:47:59,605
Speaker 3:  attention to meetings like that is an innovation unto itself. But

852
00:47:59,725 --> 00:48:00,605
Speaker 3:  I don't think it's the right one.

853
00:48:01,145 --> 00:48:05,085
Speaker 1:  So, no, my, my ongoing assumption, And I think the, the plan all along

854
00:48:05,105 --> 00:48:08,885
Speaker 1:  has been that be like a neat, really high end

855
00:48:08,895 --> 00:48:12,525
Speaker 1:  thing and most of the best features will eventually sort of trickle down

856
00:48:12,525 --> 00:48:16,445
Speaker 1:  into Google Meet in less impressive ways that this gets to be

857
00:48:16,445 --> 00:48:20,365
Speaker 1:  the, the like tip of the technological spear. And I, I assume it's like

858
00:48:20,405 --> 00:48:23,685
Speaker 1:  a victory inside of Google that they got HP to actually make and ship one

859
00:48:23,685 --> 00:48:27,045
Speaker 1:  of these things because now they get to like, keep making it. Oh, I

860
00:48:27,045 --> 00:48:30,405
Speaker 3:  Mean, HP just got the best toy for, its like enterprise demos of all time.

861
00:48:30,405 --> 00:48:33,725
Speaker 1:  Totally. Yeah. This be, this is the thing you trot out in every meeting you

862
00:48:33,725 --> 00:48:37,045
Speaker 1:  ever have with potential customers from now. Like, I get why all of this

863
00:48:37,045 --> 00:48:40,765
Speaker 1:  exists. I just, I have a hard time imagining it, like showing up in a

864
00:48:40,765 --> 00:48:43,125
Speaker 1:  WeWork near you anytime soon. Look,

865
00:48:43,245 --> 00:48:46,325
Speaker 3:  3D displays are back and you're gonna get a 3D laptop and we're all gonna

866
00:48:46,325 --> 00:48:49,405
Speaker 3:  talk to tiny versions of each other on Google Beam. It's gonna be amazing.

867
00:48:50,405 --> 00:48:53,965
Speaker 3:  Alright, that's the first lightning round. We gotta take a break. We have

868
00:48:53,965 --> 00:48:57,045
Speaker 3:  a second lightning round and then I'm told there's even a third.

869
00:48:58,345 --> 00:49:02,005
Speaker 3:  Can you imagine? It's wild here on The Verge chest. We'll be right back.

870
00:49:06,305 --> 00:49:10,125
Speaker 3:  All right, we're back. I'm told this is AI lightning round. It's not

871
00:49:10,125 --> 00:49:13,945
Speaker 3:  sponsored by an AI company. It's for flavor. So

872
00:49:14,095 --> 00:49:17,925
Speaker 3:  Unsponsored, now that we have had sponsors, again, I feel like I need to

873
00:49:18,125 --> 00:49:21,445
Speaker 3:  rework this entire pitch. Basically what I'm trying to say is, you can't

874
00:49:21,445 --> 00:49:22,405
Speaker 3:  buy us for any price.

875
00:49:23,015 --> 00:49:24,405
Speaker 1:  We're flavorful no matter what.

876
00:49:24,965 --> 00:49:28,365
Speaker 3:  I did ask Apple to send me home in an Aston Martin with CarPlay Ultra,

877
00:49:28,745 --> 00:49:31,405
Speaker 3:  and the vibe was like, will you break the rules for that? And I was like,

878
00:49:31,425 --> 00:49:35,365
Speaker 3:  no, but I like saying it. And that was like literally the,

879
00:49:35,385 --> 00:49:36,285
Speaker 3:  of the conversation.

880
00:49:39,385 --> 00:49:43,125
Speaker 3:  So, well, that's where we're at is like, I'll, I will make jokes

881
00:49:43,125 --> 00:49:47,085
Speaker 3:  about breaking our, our very strict ethics policies for an Aston Martin

882
00:49:47,105 --> 00:49:50,755
Speaker 3:  and above. But even then, probably not, but like, that's where you gotta

883
00:49:50,755 --> 00:49:51,435
Speaker 3:  be. Yeah,

884
00:49:51,555 --> 00:49:54,795
Speaker 1:  I think that's right. Yeah. You, everybody has, everybody has limits, you

885
00:49:54,795 --> 00:49:57,355
Speaker 1:  know what I mean? Like, if you can't, if you can't be bought for any price,

886
00:49:57,515 --> 00:49:58,675
Speaker 1:  I don't trust you. You know what I mean?

887
00:49:58,905 --> 00:50:01,915
Speaker 3:  Yeah. I just, I don't know what it is. It's, it's more than an Aston Martin.

888
00:50:01,925 --> 00:50:03,995
Speaker 3:  Right. That's what I got for you. It's, it's,

889
00:50:03,995 --> 00:50:05,515
Speaker 1:  Yeah. Let's explore from there. It's

890
00:50:07,025 --> 00:50:08,475
Speaker 1:  next year you And I are gonna go to the

891
00:50:41,555 --> 00:50:44,445
Speaker 3:  technically ongoing, but they're gonna go back up in price. So

892
00:51:49,265 --> 00:51:53,185
Speaker 1:  a lot of time talking to people about like the death of linear television

893
00:51:53,205 --> 00:51:56,865
Speaker 1:  and cable and that whole bundle, which everybody thought would,

894
00:51:56,875 --> 00:51:59,785
Speaker 1:  would take a long time. And there would be a bunch of money on the way down.

895
00:51:59,785 --> 00:52:03,345
Speaker 1:  And it's like, okay, we're gonna, we're gonna build this new era of entertainment

896
00:52:04,555 --> 00:52:08,345
Speaker 1:  while we sort of coast on the slowly dying, but still

897
00:52:08,345 --> 00:52:12,185
Speaker 1:  very profitable previous way that it existed. And that actually

898
00:52:12,185 --> 00:52:15,465
Speaker 1:  what happened is all of that just died immediately. And now everybody is

899
00:52:15,465 --> 00:52:18,265
Speaker 1:  scrambling in, businesses are falling apart. And that is exactly the same

900
00:52:18,265 --> 00:52:21,785
Speaker 1:  thing that's happening on the web. Like I think it, it has been sort of

901
00:52:23,025 --> 00:52:26,825
Speaker 1:  intellectually true for a couple of years that most people knew they

902
00:52:26,825 --> 00:52:29,785
Speaker 1:  couldn't rely on Google search forever. I think everybody always knew it

903
00:52:29,785 --> 00:52:33,265
Speaker 1:  was fraught to rely on Google search, but it worked for a long time. And

904
00:52:33,555 --> 00:52:36,145
Speaker 1:  there was just this sense of like, okay, this is not going to be

905
00:52:37,605 --> 00:52:40,825
Speaker 1:  the thing for us forever. Right? Like people have known that since Google

906
00:52:40,825 --> 00:52:44,705
Speaker 1:  started doing like the answer boxes on search results. And there was

907
00:52:44,705 --> 00:52:48,145
Speaker 1:  this sense of like, okay, over time Google is going to be less and less interested

908
00:52:48,145 --> 00:52:51,905
Speaker 1:  in sending clicks to our website and more and more interested in just keeping

909
00:52:51,905 --> 00:52:54,825
Speaker 1:  you inside of Google products. Everybody kind of knew that. Well,

910
00:52:54,825 --> 00:52:58,185
Speaker 3:  They kind of knew it, but the incentive to not believe it

911
00:52:58,605 --> 00:53:02,465
Speaker 3:  was so overpowering that they didn't know it,

912
00:53:02,475 --> 00:53:02,825
Speaker 3:  right.

913
00:53:02,825 --> 00:53:03,465
Speaker 1:  Because to do you know what

914
00:53:03,465 --> 00:53:03,625
Speaker 3:  I mean?

915
00:53:03,625 --> 00:53:07,345
Speaker 1:  Because to to lean into that and to work with that

916
00:53:07,465 --> 00:53:11,425
Speaker 1:  requires essentially completely upending the business

917
00:53:11,425 --> 00:53:15,225
Speaker 1:  of being online. Like a, a thing I think I

918
00:53:15,245 --> 00:53:19,225
Speaker 1:  didn't realize until recently is like almost every

919
00:53:19,815 --> 00:53:23,745
Speaker 1:  publisher in particular online, has only ever existed in

920
00:53:23,745 --> 00:53:27,285
Speaker 1:  the Google world. It's not like everybody did the, the like Facebook style

921
00:53:27,285 --> 00:53:31,245
Speaker 1:  pivot to video. And then that all fell apart and the, a lot

922
00:53:31,245 --> 00:53:33,565
Speaker 1:  of stuff went away, but also a lot of people sort of knew what to go back

923
00:53:33,565 --> 00:53:37,485
Speaker 1:  to. Most of these places have not ever done

924
00:53:37,485 --> 00:53:41,325
Speaker 1:  this. And by this I mean like online publishing, media journalism,

925
00:53:41,525 --> 00:53:44,965
Speaker 1:  whatever you wanna call it out in a world where Google is not

926
00:53:45,505 --> 00:53:49,325
Speaker 1:  the main source of people and traffic on the internet. So

927
00:53:49,345 --> 00:53:53,325
Speaker 1:  it, it comes to this existential crisis of like, if I don't believe

928
00:53:53,325 --> 00:53:57,205
Speaker 1:  in Google anymore, what do I do? And I think, again,

929
00:53:57,205 --> 00:54:00,845
Speaker 1:  because Google was so huge and so successful and because the, the

930
00:54:01,135 --> 00:54:04,965
Speaker 1:  abyss of whatever else we have to do was so huge and unknowable,

931
00:54:05,695 --> 00:54:09,555
Speaker 1:  people just didn't really try. But then what has happened is this,

932
00:54:09,585 --> 00:54:13,435
Speaker 1:  this like slow gradual decline everybody was betting on that would give us

933
00:54:13,435 --> 00:54:16,315
Speaker 1:  like a generation of technology to figure out what's coming next is just

934
00:54:16,315 --> 00:54:19,675
Speaker 1:  happening. Like it is happening like minute to minute and day to day in front

935
00:54:19,675 --> 00:54:22,675
Speaker 1:  of our eyes. The Wall Street Journal had a big story this week

936
00:54:23,485 --> 00:54:26,315
Speaker 1:  going through a bunch of different, like Huffington Post and, and the Wall

937
00:54:26,315 --> 00:54:29,595
Speaker 1:  Street Journal and the Washington Post, And I think Business Insider was

938
00:54:29,595 --> 00:54:33,355
Speaker 1:  the other one showing these just like dramatically down sloping

939
00:54:33,775 --> 00:54:37,715
Speaker 1:  charts Yeah. Of traffic from Google. And Business Insider has done layoffs

940
00:54:37,715 --> 00:54:40,435
Speaker 1:  and they have quotes from a bunch of the folks at the other publications

941
00:54:40,435 --> 00:54:44,155
Speaker 1:  being like, we, we now can see the obvious trend

942
00:54:44,155 --> 00:54:48,115
Speaker 1:  line toward Google Zero, which has caused you Neli to

943
00:54:48,115 --> 00:54:50,355
Speaker 1:  just take victory lap after victory lap.

944
00:54:50,545 --> 00:54:53,555
Speaker 3:  They won't say Google Zero. If you hear someone say, our Google traffic is

945
00:54:53,555 --> 00:54:56,795
Speaker 3:  gonna zero, I need you to jump out of a bush and say, that is called Google

946
00:54:56,825 --> 00:54:58,835
Speaker 3:  Zero, a term coined by Neil Patel in

947
00:54:58,835 --> 00:55:00,515
Speaker 1:  2022. You owe six. Yeah.

948
00:55:01,135 --> 00:55:04,875
Speaker 3:  In addition to your crashing revenues, you now owe a royalty fee for acknowledging

949
00:55:04,875 --> 00:55:06,635
Speaker 3:  your crashing rev revenue.

950
00:55:07,025 --> 00:55:10,835
Speaker 1:  Yeah. But so it, we are like, we, we have gone from this being a, a theoretical

951
00:55:10,905 --> 00:55:14,875
Speaker 1:  eventuality to like, it is, it is happening in front of us right now.

952
00:55:14,985 --> 00:55:15,275
Speaker 1:  Yeah.

953
00:55:15,305 --> 00:55:18,475
Speaker 2:  It's interesting. Like Google, there are Google changes all the time, right?

954
00:55:18,475 --> 00:55:21,115
Speaker 2:  This, there, this is a thing that's happened for years where there have been

955
00:55:21,115 --> 00:55:24,635
Speaker 2:  winners and losers as Google makes changes to its algorithm.

956
00:55:25,175 --> 00:55:28,435
Speaker 2:  And I think what is particularly unique about this one is that there are

957
00:55:28,435 --> 00:55:32,155
Speaker 2:  no winners, right? It's not like there is some subset of

958
00:55:32,155 --> 00:55:36,035
Speaker 2:  publishers, or I don't even know, like companies online that have figured

959
00:55:36,095 --> 00:55:38,395
Speaker 2:  out a way to crack this, at least that I have heard of.

960
00:55:38,505 --> 00:55:41,875
Speaker 3:  Wait, there's a, there's a weird set of winners. It's not a great set of

961
00:55:41,875 --> 00:55:45,755
Speaker 3:  winners. Reddit is a winner in all of this, right?

962
00:55:45,905 --> 00:55:49,395
Speaker 3:  Like Google has made it gone out and made a deal with Reddit, and they know

963
00:55:49,395 --> 00:55:53,075
Speaker 3:  that Reddit is a rich source of actual human content that it can synthesize

964
00:55:53,295 --> 00:55:57,075
Speaker 3:  to get the answers to questions. YouTube oddly a winner in this.

965
00:55:57,075 --> 00:55:59,715
Speaker 3:  Google owns YouTube, but it's a winner. I was gonna say, but like, you know

966
00:55:59,715 --> 00:56:03,275
Speaker 3:  what I mean? Like, there are media platforms where people are, that are winners

967
00:56:03,295 --> 00:56:07,195
Speaker 3:  in this. They're just not publishers that pay people money to

968
00:56:07,195 --> 00:56:10,935
Speaker 3:  make news, right? And so, you know, and Google will just, And I should disclose

969
00:56:10,935 --> 00:56:13,855
Speaker 3:  like open AI has a deal like that with Fox Media and a bunch of other publishers.

970
00:56:14,125 --> 00:56:17,375
Speaker 3:  None of that is sending us the traffic that would counteract Google.

971
00:56:18,235 --> 00:56:21,135
Speaker 3:  By the way, to be clear, our Google traffic is in decline. So is everyone

972
00:56:21,135 --> 00:56:24,885
Speaker 3:  else's. We have just been paranoid freaks for so long that we're,

973
00:56:25,015 --> 00:56:28,045
Speaker 3:  we've been talking about it forever on this show, but also in our business,

974
00:56:28,425 --> 00:56:31,885
Speaker 3:  that's our redesign. And so we've just been hedged against it.

975
00:56:32,225 --> 00:56:35,725
Speaker 3:  And when I run out and talk to other publishers about it, or other executives

976
00:56:35,725 --> 00:56:39,565
Speaker 3:  on decoder or wherever else, this is what I mean by the incentives to not

977
00:56:39,565 --> 00:56:43,085
Speaker 3:  believe it. I've had media executives look me in the eye and say things like,

978
00:56:43,085 --> 00:56:46,805
Speaker 3:  you think people are gonna stop searching? And they cannot separate the concept

979
00:56:46,945 --> 00:56:50,325
Speaker 3:  of search from Google as a company upon which they have a business dependency,

980
00:56:50,455 --> 00:56:53,645
Speaker 3:  right? And so people are searching, they might be searching more than ever.

981
00:56:53,905 --> 00:56:57,165
Speaker 3:  Google will tell you they're searching more than ever. They're just not getting

982
00:56:57,455 --> 00:57:01,365
Speaker 3:  links to publishers as answers. They might be getting links to Reddit, like

983
00:57:01,365 --> 00:57:04,405
Speaker 3:  Google's like, we're sending more traffic to the web than ever. And the question

984
00:57:04,405 --> 00:57:08,325
Speaker 3:  that I have to which there is no answer, is where is that

985
00:57:08,325 --> 00:57:12,145
Speaker 3:  traffic going? Who are these winners? It can't all just be Reddit,

986
00:57:12,145 --> 00:57:15,985
Speaker 3:  right? It has to be other stuff. And it's just unclear what that other

987
00:57:15,985 --> 00:57:19,665
Speaker 3:  stuff is. Like where has the traffic gone? So I

988
00:57:19,805 --> 00:57:23,425
Speaker 3:  Jay, I mean, And I don't, none of those AI deals are paying anyone nearly

989
00:57:23,425 --> 00:57:27,345
Speaker 3:  enough money to counteract the loss of revenue as you can obviously tell.

990
00:57:28,245 --> 00:57:32,195
Speaker 3:  But it's, I just, I don't want to it, they're not keeping

991
00:57:32,195 --> 00:57:35,475
Speaker 3:  everything for themself. It's just unclear who the true winners will be.

992
00:57:35,825 --> 00:57:37,035
Speaker 3:  Nick Thompson at The Atlantic,

993
00:57:38,855 --> 00:57:42,555
Speaker 3:  he keeps talking about optimizing the content to

994
00:57:42,655 --> 00:57:46,555
Speaker 3:  be tr like show up in the ai search results as the next generation of

995
00:57:46,715 --> 00:57:50,625
Speaker 3:  SEO. That is a Galaxy Brain idea. But I'm starting

996
00:57:50,625 --> 00:57:54,375
Speaker 3:  to see pop up everywhere, right? To be like, we wanna make sure we

997
00:57:54,375 --> 00:57:57,815
Speaker 3:  become part of the AI generated answer wacky,

998
00:57:58,965 --> 00:58:02,385
Speaker 3:  but that, like the SEO community is already talking about that as well. But

999
00:58:02,545 --> 00:58:06,265
Speaker 1:  E even in inherent in that is the bet that

1000
00:58:06,525 --> 00:58:09,585
Speaker 1:  if we are the one that surfaces in the answer, actually what people will

1001
00:58:09,605 --> 00:58:12,465
Speaker 1:  do after reading the answer is click the links. And

1002
00:58:13,865 --> 00:58:17,685
Speaker 1:  at least in my behavior and what I observe in other people, that is sure

1003
00:58:17,705 --> 00:58:21,445
Speaker 1:  not the case. And that is sure, not the product goal is to send you

1004
00:58:21,505 --> 00:58:23,845
Speaker 1:  out of chat GPT or Gemini or whatever.

1005
00:58:24,245 --> 00:58:27,405
Speaker 3:  I mean, Sundar will say that is the, the goal of AI overview and that people

1006
00:58:27,405 --> 00:58:30,685
Speaker 3:  search more AI overview and that means they inevitably click more. There

1007
00:58:30,685 --> 00:58:32,565
Speaker 3:  is no public data backing that up, right?

1008
00:58:32,635 --> 00:58:36,525
Speaker 1:  What they say also is that the people who go are more

1009
00:58:36,525 --> 00:58:40,045
Speaker 1:  engaged because basically they've, like, by the time they get to your

1010
00:58:40,475 --> 00:58:43,485
Speaker 1:  website, they're already halfway down the rabbit hole. And that it's actually

1011
00:58:43,485 --> 00:58:47,325
Speaker 1:  like the, the people who are coming are the people who

1012
00:58:47,325 --> 00:58:50,965
Speaker 1:  are serious, right? And it's like, well, okay, yes. But the whole business

1013
00:58:50,965 --> 00:58:54,925
Speaker 1:  of Google forever was fundamentally predicated on the people who

1014
00:58:54,925 --> 00:58:58,245
Speaker 1:  were not serious and there being lots and lots and lots of them, right? And

1015
00:58:58,245 --> 00:59:01,205
Speaker 1:  it was like, it's, I mean, it's what it was. And it's for, for so many people,

1016
00:59:01,395 --> 00:59:04,845
Speaker 1:  it's the, the huge bet of internet publishing for so long

1017
00:59:05,225 --> 00:59:09,125
Speaker 1:  was that you can, with enough volume, pennies turns into

1018
00:59:09,125 --> 00:59:13,045
Speaker 1:  dollars, right? Yeah. Like that's, that's the bet. And, and there was so

1019
00:59:13,045 --> 00:59:15,725
Speaker 1:  much of it that it was like, we don't have to be good. We just have to be

1020
00:59:16,565 --> 00:59:20,245
Speaker 1:  voluminous. And as long as we can get enough people coming to our crap by

1021
00:59:20,445 --> 00:59:24,285
Speaker 1:  accident, we will make a lot of money on it. And that is the thing, to Jake's

1022
00:59:24,285 --> 00:59:27,125
Speaker 1:  point, that is just dead. There's just, it's not, they're not pointing it

1023
00:59:27,285 --> 00:59:30,405
Speaker 1:  anywhere else. They're not changing the way that they think about it. It's

1024
00:59:30,405 --> 00:59:34,155
Speaker 1:  just dying. And so it's like if you're good at product reviews,

1025
00:59:34,745 --> 00:59:38,155
Speaker 1:  it's dying. If you're bad at product reviews, it's dying. And there Google

1026
00:59:38,215 --> 00:59:42,075
Speaker 1:  is, I think spent a long time trying to pretend that

1027
00:59:42,075 --> 00:59:45,835
Speaker 1:  it was optimizing for quality and just trying to get rid of the sort of bad

1028
00:59:45,935 --> 00:59:48,835
Speaker 1:  scammy stuff that is basically just like copying and pasting Amazon reviews

1029
00:59:49,935 --> 00:59:53,915
Speaker 1:  and pushing it toward other stuff. And increasingly it's like, no, what they've

1030
00:59:53,915 --> 00:59:57,755
Speaker 1:  done is just knife the entire, like product review and buying

1031
00:59:58,035 --> 01:00:01,705
Speaker 1:  guide world from Google. And they're fine with that.

1032
01:00:02,225 --> 01:00:05,025
Speaker 3:  I, I mean there's so much scams there that it might be fine. Like,

1033
01:00:06,705 --> 01:00:10,185
Speaker 3:  I don't know, there's something happening there with the old web

1034
01:00:10,615 --> 01:00:12,225
Speaker 3:  that people didn't like anyway,

1035
01:00:12,835 --> 01:00:13,185
Speaker 1:  Right?

1036
01:00:13,375 --> 01:00:16,145
Speaker 2:  Wait, did people not like the old web or

1037
01:00:17,405 --> 01:00:20,945
Speaker 2:  is it that because of Google's incentives, the old web got completely

1038
01:00:21,015 --> 01:00:23,665
Speaker 2:  corrupted and now Google is solving its own problem?

1039
01:00:23,885 --> 01:00:25,185
Speaker 3:  Oh, it's completely that. Yeah, it's that one.

1040
01:00:25,665 --> 01:00:28,545
Speaker 1:  But I think, but I don't think those are different things, right? Like the,

1041
01:00:28,545 --> 01:00:31,425
Speaker 1:  the outcome is the same. And I think like recipe sites are the perfect example

1042
01:00:31,425 --> 01:00:34,465
Speaker 1:  of this, right? Like the, the running joke of the internet is that recipe

1043
01:00:34,475 --> 01:00:38,145
Speaker 1:  sites are awful because you go to a recipe blog, you click on the thing to

1044
01:00:38,145 --> 01:00:42,065
Speaker 1:  get the recipe, and what you get is like six popup video ads

1045
01:00:42,325 --> 01:00:46,225
Speaker 1:  and 2000 words about the person's Thursday before they get to the actual

1046
01:00:46,555 --> 01:00:49,985
Speaker 1:  thing. And it's a bunch of H twos telling you like different kinds of substitutions.

1047
01:00:50,045 --> 01:00:54,025
Speaker 1:  And it's just an immeasurable amount of barely useful information. The

1048
01:00:54,025 --> 01:00:57,665
Speaker 1:  thing is, every single pixel on every single one of those sites exists because

1049
01:00:57,665 --> 01:01:01,225
Speaker 1:  of a of SEO. Like they are, they are ruthlessly optimized

1050
01:01:01,485 --> 01:01:04,665
Speaker 1:  to get to the top of Google search results because there is a lot of money

1051
01:01:04,685 --> 01:01:07,665
Speaker 1:  in being the first thing people click on when they search for chocolate chip

1052
01:01:07,665 --> 01:01:11,485
Speaker 1:  cookies that is going to die. Because

1053
01:01:11,505 --> 01:01:14,965
Speaker 1:  now when you search chocolate chip cookie recipe, it just gives you a recipe.

1054
01:01:15,625 --> 01:01:18,165
Speaker 1:  It doesn't give you links, it doesn't give you anything else. It just gives

1055
01:01:18,165 --> 01:01:20,765
Speaker 1:  you a recipe. And so all of these sites are gonna have to figure out, okay,

1056
01:01:20,785 --> 01:01:24,645
Speaker 1:  not only do I, am I able to undo all of this SEO

1057
01:01:24,645 --> 01:01:27,605
Speaker 1:  stuff, I have to figure out an entire new strategy for getting people to

1058
01:01:27,605 --> 01:01:30,845
Speaker 1:  come to my website. And I think, and we've talked about this on the show,

1059
01:01:31,085 --> 01:01:34,565
Speaker 1:  right? Like long term, there are things about that that are really great.

1060
01:01:34,795 --> 01:01:38,605
Speaker 1:  Like the, the, the amount of time publishers have spent

1061
01:01:38,605 --> 01:01:41,645
Speaker 1:  thinking about Google versus the amount of time they've spent thinking about

1062
01:01:41,645 --> 01:01:45,605
Speaker 1:  their audience vastly skewed in the wrong direction over the last two decades.

1063
01:01:46,045 --> 01:01:49,445
Speaker 1:  Not true of everybody, but true, more true than it should be.

1064
01:01:50,545 --> 01:01:54,285
Speaker 1:  So like that, that incentive is going to go back in the right direction of

1065
01:01:54,285 --> 01:01:57,005
Speaker 1:  like, the only thing we have left is to take care of our audience because

1066
01:01:57,005 --> 01:02:00,875
Speaker 1:  Google won't just gin one up for us every day. The

1067
01:02:00,875 --> 01:02:04,595
Speaker 1:  problem is, in the interim, many, many, many, many

1068
01:02:04,835 --> 01:02:07,155
Speaker 1:  businesses will die and many, many, many people will. And

1069
01:02:07,155 --> 01:02:10,875
Speaker 3:  They already, like we even covering literally the words Google Zero

1070
01:02:11,335 --> 01:02:14,715
Speaker 3:  for at least three years. Yeah. And we have done, we have headlines of Google

1071
01:02:14,715 --> 01:02:18,635
Speaker 3:  Zero and the Mia wrote an incredible feature about the

1072
01:02:18,635 --> 01:02:22,005
Speaker 3:  incentives and how they shape webpages that we can link and like, you know,

1073
01:02:22,005 --> 01:02:24,925
Speaker 3:  the webpage animates into place. Like we've done endless coverage of this.

1074
01:02:24,925 --> 01:02:28,685
Speaker 3:  Yeah. Here's the front of the recipe war that I'm very curious

1075
01:02:28,695 --> 01:02:32,675
Speaker 3:  about. 'cause this dynamic of, I hate that the recipe content is

1076
01:02:32,675 --> 01:02:35,235
Speaker 3:  buried for me. I'm just gonna make a tool that scrapes recipes and then everyone's

1077
01:02:35,235 --> 01:02:38,955
Speaker 3:  gonna yell at like, well known in the SEO era. Yep.

1078
01:02:39,455 --> 01:02:42,355
Speaker 3:  The recipe bloggers get to yell at those people for taking their labor, blah,

1079
01:02:42,355 --> 01:02:45,915
Speaker 3:  blah blah. Never. Okay. There are now infinite tools to

1080
01:02:46,535 --> 01:02:49,875
Speaker 3:  scrape and store the recipes from like TikTok chefs,

1081
01:02:51,575 --> 01:02:55,195
Speaker 3:  but the TikTok videos are inherently monetized by the platform themselves.

1082
01:02:55,935 --> 01:02:59,635
Speaker 3:  Yes. And the games they play to win the TikTok algorithm wars

1083
01:02:59,865 --> 01:03:03,515
Speaker 3:  have nothing to do with the recipes. Right? Like in, in kind of the same

1084
01:03:03,515 --> 01:03:07,115
Speaker 3:  way. But they're getting the video views. And so all these new

1085
01:03:07,145 --> 01:03:10,925
Speaker 3:  recipes store all these new like recipe cataloging and

1086
01:03:10,925 --> 01:03:14,845
Speaker 3:  storage tools that promise to like save the recipes from Instagram

1087
01:03:14,845 --> 01:03:17,965
Speaker 3:  and TikTok that you love most and well like index then and dah dah dah, don't

1088
01:03:18,085 --> 01:03:21,945
Speaker 3:  actually take economic value from the creators. 'cause you, they sort of

1089
01:03:22,535 --> 01:03:24,065
Speaker 3:  implied that you have watched the video,

1090
01:03:24,515 --> 01:03:26,905
Speaker 1:  Right? 'cause the video is the thing, they don't care about the recipe

1091
01:03:27,005 --> 01:03:30,345
Speaker 3:  The same way the video is inherently itself monetized inside a distribution

1092
01:03:30,345 --> 01:03:33,665
Speaker 3:  algorithm does not change the content in like that specific way.

1093
01:03:34,805 --> 01:03:38,745
Speaker 3:  I'm dying to know, like, I'm very much dying to know if the

1094
01:03:38,745 --> 01:03:42,145
Speaker 3:  same kind of dynamic plays out where everyone gets mad at the recipe app

1095
01:03:42,145 --> 01:03:46,025
Speaker 3:  people, I suspect it will not because the economics are so different.

1096
01:03:46,845 --> 01:03:50,225
Speaker 3:  And I that, that to me is like a, a view into what's happening across the

1097
01:03:50,225 --> 01:03:53,775
Speaker 3:  web where I'm desperate to get any

1098
01:03:53,965 --> 01:03:57,895
Speaker 3:  eyeball onto this webpage. So desperate that when you land here, I

1099
01:03:57,895 --> 01:04:01,855
Speaker 3:  will attack you, I will mug you, I will put pop-up ads and

1100
01:04:02,095 --> 01:04:05,215
Speaker 3:  subscription boxes and blah, blah, blah, blah, blah. All of your face. Because

1101
01:04:05,275 --> 01:04:08,815
Speaker 3:  the chances of getting a visitor are so infinitesimally small. I have to

1102
01:04:08,815 --> 01:04:12,535
Speaker 3:  make as much money from every single visitor as I can. Yep. Whereas a

1103
01:04:12,535 --> 01:04:15,135
Speaker 3:  TikTok video just makes money in the algorithm and then you make another

1104
01:04:15,135 --> 01:04:17,695
Speaker 3:  one and you like, it makes money in the algorithm and you have distribution

1105
01:04:18,005 --> 01:04:21,185
Speaker 3:  that doesn't put as much pressure on monetization. And

1106
01:04:22,165 --> 01:04:26,105
Speaker 3:  that's, that's just a big story that the web's distribution made everybody

1107
01:04:26,105 --> 01:04:29,255
Speaker 3:  so desperate for so long, but nobody could see their way through it. Nobody

1108
01:04:29,315 --> 01:04:33,255
Speaker 3:  in the web. Maybe we do, people don't like our redesign, but like we

1109
01:04:33,255 --> 01:04:36,895
Speaker 3:  try very hard to compete on user experience and webpages. We don't have pop-up

1110
01:04:36,895 --> 01:04:40,885
Speaker 3:  ads and weird banners and all this stuff, but the sites that

1111
01:04:40,885 --> 01:04:43,245
Speaker 3:  do are doing it. 'cause that's the only way they can make money. 'cause there's

1112
01:04:43,245 --> 01:04:46,845
Speaker 3:  no other referral source to get onto their pages. Right. I don't know what

1113
01:04:46,845 --> 01:04:50,725
Speaker 3:  happens next. I I think the web turns into like an application

1114
01:04:51,085 --> 01:04:54,775
Speaker 3:  platform. Like at a big, big level. I think the future of the web is not

1115
01:04:54,775 --> 01:04:58,175
Speaker 3:  as a media platform. I think it is as an application platform.

1116
01:04:58,875 --> 01:05:02,295
Speaker 3:  And like thinking of the web as an application platform changes how we think

1117
01:05:02,295 --> 01:05:04,975
Speaker 3:  about web browsers. I think it's changing how Google's thinking of Chrome

1118
01:05:05,395 --> 01:05:09,175
Speaker 3:  and David, you just covered Dia, the new browser from the browser

1119
01:05:09,175 --> 01:05:12,975
Speaker 3:  company that replaces arc and that's sort of predicated on this idea

1120
01:05:12,975 --> 01:05:15,495
Speaker 3:  that like something else is happening on the web.

1121
01:05:15,725 --> 01:05:18,685
Speaker 1:  Yeah. It's, its whole thesis is essentially that

1122
01:05:19,345 --> 01:05:23,005
Speaker 1:  you're gonna spend most of your time a on the web

1123
01:05:23,425 --> 01:05:27,165
Speaker 1:  and b inside of apps on the web. And, and it's whole

1124
01:05:27,165 --> 01:05:30,965
Speaker 1:  idea is like, okay, well you want a chat bot that can see that

1125
01:05:30,965 --> 01:05:34,525
Speaker 1:  stuff, right? And it's like, wouldn't it be cool if there was a a, an

1126
01:05:34,825 --> 01:05:38,805
Speaker 1:  AI assistant that knew everything that I was doing in Slack and knew

1127
01:05:38,805 --> 01:05:41,325
Speaker 1:  everything that I was doing in my email and could see all my Figma files

1128
01:05:41,545 --> 01:05:44,285
Speaker 1:  and it's like, oh, there's only one layer that can do that and it's the browser.

1129
01:05:44,905 --> 01:05:48,325
Speaker 1:  But to your point that that thing is not like all the demos I saw and all

1130
01:05:48,325 --> 01:05:50,245
Speaker 1:  the stuff I heard from the folks at the browser company, like they're not

1131
01:05:51,515 --> 01:05:55,285
Speaker 1:  intrigued by the idea of like summarizing news articles for you. Right? They're

1132
01:05:55,285 --> 01:05:59,125
Speaker 1:  like, you're in, you're, you're doing job interviews. This is like an

1133
01:05:59,125 --> 01:06:01,525
Speaker 1:  example I got from a few people. You're doing job interviews and you have,

1134
01:06:01,745 --> 01:06:04,805
Speaker 1:  you have a Slack thread in which you're talking about all the potential candidates

1135
01:06:05,025 --> 01:06:09,005
Speaker 1:  and you have their, their resume in a Google doc and you have

1136
01:06:09,175 --> 01:06:12,925
Speaker 1:  their scorecards from their interviews and you ask the bot to summarize it

1137
01:06:12,945 --> 01:06:15,485
Speaker 1:  and it is able to pull from those things because all of those things are

1138
01:06:15,485 --> 01:06:17,885
Speaker 1:  web apps that just are exist in a tab.

1139
01:06:19,305 --> 01:06:22,765
Speaker 1:  All of it is, it's an app platform. Right. And this is like, it's, it's not

1140
01:06:22,765 --> 01:06:26,365
Speaker 1:  that different from like what Apple imagines someday future good

1141
01:06:26,475 --> 01:06:28,205
Speaker 1:  Siri to be on the iPhone. It's

1142
01:06:28,205 --> 01:06:32,105
Speaker 3:  Not different from what anyone imagines about anything like Right. We

1143
01:06:32,105 --> 01:06:35,305
Speaker 3:  are gonna, we're gonna lace together all of your apps and they can all talk

1144
01:06:35,305 --> 01:06:37,785
Speaker 3:  to each other and you'll have a natural language interface to a bunch of

1145
01:06:37,785 --> 01:06:41,465
Speaker 3:  capabilities that broadly the industry is

1146
01:06:41,465 --> 01:06:42,745
Speaker 3:  coalesced on this being the future.

1147
01:06:43,175 --> 01:06:46,865
Speaker 1:  Yeah. And the, the bet is just at which layer should that thing exist in

1148
01:06:46,865 --> 01:06:50,665
Speaker 1:  order to have the most power. Right. And Apple's bet is

1149
01:06:50,665 --> 01:06:54,225
Speaker 1:  it's a, the operating system and Diaz's bet is it's in the browser.

1150
01:06:54,575 --> 01:06:58,425
Speaker 2:  Well the browser is like, right, we, we saw this already when OpenAI tried

1151
01:06:58,425 --> 01:07:02,025
Speaker 2:  to launch operator. Right. It it is just running in a browser.

1152
01:07:02,245 --> 01:07:05,185
Speaker 2:  It is an agent that is poking around a browser trying to get things done

1153
01:07:05,185 --> 01:07:08,745
Speaker 2:  for you, but it is not your browser. And so we can't get anything done for

1154
01:07:08,745 --> 01:07:12,145
Speaker 2:  you. Right. And So I think like fundamentally, it's pretty clear that Dia

1155
01:07:12,285 --> 01:07:15,345
Speaker 2:  is probably the right approach even at an operating system level.

1156
01:07:16,325 --> 01:07:19,185
Speaker 2:  It doesn't necessarily have the permission for all that stuff in your browser.

1157
01:07:19,275 --> 01:07:23,185
Speaker 2:  Right. The problem is, I don't think any bot can reliably

1158
01:07:23,185 --> 01:07:24,385
Speaker 2:  do any of that stuff yet.

1159
01:07:24,725 --> 01:07:27,825
Speaker 1:  So I will say one thing I thought was really interesting is in talking to

1160
01:07:27,825 --> 01:07:30,545
Speaker 1:  the folks at the browser company about this, they went way down the road

1161
01:07:30,645 --> 01:07:34,185
Speaker 1:  of like pure agentic ai. Like how do we

1162
01:07:35,385 --> 01:07:38,545
Speaker 1:  actively do stuff for you on these websites that we have access to? Because

1163
01:07:38,565 --> 01:07:41,465
Speaker 1:  one of the things that you get as the browser is cookies. And if you have

1164
01:07:41,465 --> 01:07:45,185
Speaker 1:  cookies, you essentially have a logged in state to every

1165
01:07:45,245 --> 01:07:49,185
Speaker 1:  app that I'm logged into, which is just a vast amount of power to have

1166
01:07:49,295 --> 01:07:52,985
Speaker 1:  over what's going on on the web. And so they were like, well sure

1167
01:07:53,085 --> 01:07:56,985
Speaker 1:  we, we have what we need to go in and control your Spotify

1168
01:07:57,165 --> 01:08:00,545
Speaker 1:  for you or book stuff for you on Airbnb. And what they discovered is that

1169
01:08:00,665 --> 01:08:04,505
Speaker 1:  a, the tech for that doesn't really work and it certainly

1170
01:08:04,505 --> 01:08:08,025
Speaker 1:  doesn't work reliably enough to do it on your behalf. And also it feels bad.

1171
01:08:08,765 --> 01:08:12,625
Speaker 1:  The idea of just basically sitting passively while your browser uses itself

1172
01:08:13,425 --> 01:08:17,045
Speaker 1:  actually was not an enjoyable experience for people. And I felt very

1173
01:08:17,045 --> 01:08:19,965
Speaker 1:  vindicated hearing them say that, that they were like, we ran this down and

1174
01:08:19,965 --> 01:08:23,325
Speaker 1:  it doesn't work and people don't want it. And I'm like, oh, I agree. I come,

1175
01:08:23,325 --> 01:08:25,845
Speaker 1:  they're like, and they're like, maybe that's where we'll get, and some of

1176
01:08:25,845 --> 01:08:28,445
Speaker 1:  this will be possible and you'll be able to say the assistant, like, you

1177
01:08:28,445 --> 01:08:30,805
Speaker 1:  know, go do this and this and this and this app for me and that'll be great.

1178
01:08:30,865 --> 01:08:34,765
Speaker 1:  But the idea that that works right now, they were like, we,

1179
01:08:34,765 --> 01:08:37,445
Speaker 1:  we ran it down as far as we could and it just doesn't work. And I was like,

1180
01:08:37,445 --> 01:08:39,325
Speaker 1:  oh good. That's, that's also my exact

1181
01:08:39,325 --> 01:08:39,845
Speaker 3:  Experience.

1182
01:08:42,205 --> 01:08:45,885
Speaker 3:  I I'm gonna come off Nic, an AI booster and I'm not in, I'm not,

1183
01:08:46,065 --> 01:08:49,845
Speaker 3:  I'm just, I think there are major flaws with the AI industry. There's a fatal

1184
01:08:49,845 --> 01:08:53,365
Speaker 3:  copyright flaw, which we will talk about in one second. And then there's

1185
01:08:53,365 --> 01:08:57,325
Speaker 3:  like, can LLMs actually do this and scale flaw, which might just like

1186
01:08:57,325 --> 01:09:01,165
Speaker 3:  upend this whole thing. Like the rate of improvement of LLMs is the core

1187
01:09:01,165 --> 01:09:04,445
Speaker 3:  technology for the AI industry maybe,

1188
01:09:04,895 --> 01:09:08,325
Speaker 3:  right? Like, and there's actually a paper out of Apple this week in which

1189
01:09:08,325 --> 01:09:11,965
Speaker 3:  the answer is a hard no. Yeah. Like we've hit a wall and that's the end of

1190
01:09:11,965 --> 01:09:15,565
Speaker 3:  it. Who knows? I don't know. I'm gonna come off like a booster. I'm just

1191
01:09:15,565 --> 01:09:19,205
Speaker 3:  saying I'm aware of these like core flaws and climate. We're gonna talk about

1192
01:09:19,205 --> 01:09:22,945
Speaker 3:  climate a second too. There's all this stuff. The thing that has

1193
01:09:22,945 --> 01:09:26,225
Speaker 3:  changed my mind recently is I'm watching people

1194
01:09:27,645 --> 01:09:31,545
Speaker 3:  not do a bunch of prompts to get answers. Not make a

1195
01:09:31,545 --> 01:09:35,225
Speaker 3:  bunch of, you know, VO three videos, although people are making lots of VO

1196
01:09:35,225 --> 01:09:38,625
Speaker 3:  three videos. I'm watching people create application logic

1197
01:09:39,285 --> 01:09:42,745
Speaker 3:  in automation platforms out of AI agent capabilities.

1198
01:09:43,965 --> 01:09:47,275
Speaker 3:  Right. In a way that is like the stuff they're doing is not

1199
01:09:47,545 --> 01:09:51,475
Speaker 3:  important. It's, some of it is just like straight up content piracy.

1200
01:09:51,745 --> 01:09:55,515
Speaker 3:  Like take all the most viral videos on TikTok, make

1201
01:09:55,515 --> 01:09:59,155
Speaker 3:  faceless YouTube shorts about them and then republish them as YouTube

1202
01:09:59,155 --> 01:10:02,275
Speaker 3:  shorts And I will collect money for free and all this is happening instead

1203
01:10:02,275 --> 01:10:05,835
Speaker 3:  of an AI based automation platform called N Aden. Okay, great. Like

1204
01:10:06,085 --> 01:10:10,035
Speaker 3:  we're, here's the, here's the slot machine at scale. Right? But what

1205
01:10:10,065 --> 01:10:14,035
Speaker 3:  that is, is application logic. They're building new apps in a new

1206
01:10:14,095 --> 01:10:17,755
Speaker 3:  way using new tools. They're using new emergent

1207
01:10:17,915 --> 01:10:20,795
Speaker 3:  standards like MCP to go query a bunch of databases and write to a bunch

1208
01:10:20,795 --> 01:10:24,475
Speaker 3:  of spreadsheets and then create content and publish it to other places. And

1209
01:10:24,475 --> 01:10:28,075
Speaker 3:  they're moving stuff around there. A bunch of call center logic is being

1210
01:10:28,075 --> 01:10:31,355
Speaker 3:  automated on these platforms. Right. Someone talks to you and it goes and

1211
01:10:31,355 --> 01:10:35,315
Speaker 3:  gets an answer and spits it back to you. That stuff reminds

1212
01:10:35,375 --> 01:10:39,235
Speaker 3:  me a lot of the, the like original Web

1213
01:10:39,235 --> 01:10:42,955
Speaker 3:  2.0 where the idea was all of these

1214
01:10:43,235 --> 01:10:47,155
Speaker 3:  services have APIs and you can like make new things out of APIs by

1215
01:10:47,315 --> 01:10:51,165
Speaker 3:  mashing them up the entire website. Mashable was

1216
01:10:51,795 --> 01:10:55,525
Speaker 3:  like founded because people were making so many interesting things

1217
01:10:55,585 --> 01:10:58,805
Speaker 3:  by remixing APIs. There were, remember there's a service called Yahoo Pipes.

1218
01:10:58,995 --> 01:11:02,645
Speaker 3:  Yeah. Yahoo Pipes ruled like we ran a lot of end gadget

1219
01:11:02,905 --> 01:11:06,405
Speaker 3:  on weird Yahoo Pipes. Automations. Sorry, what was Yahoo

1220
01:11:06,695 --> 01:11:10,445
Speaker 3:  Pipes? Yahoo Pipes is this like dragon drop service builder

1221
01:11:11,275 --> 01:11:14,885
Speaker 3:  that was basically like, you can take an API it was like if this than that,

1222
01:11:14,885 --> 01:11:16,245
Speaker 3:  but for like web. Oh my god.

1223
01:11:16,245 --> 01:11:17,805
Speaker 1:  Yeah. It was it was awesome. It was great.

1224
01:11:17,805 --> 01:11:21,165
Speaker 3:  Yeah. The rules and all of that was the original promise of Web 2.0. We're

1225
01:11:21,165 --> 01:11:25,085
Speaker 3:  gonna build all these services and then you can at some level of API abstraction,

1226
01:11:25,545 --> 01:11:29,085
Speaker 3:  you can build new services by mashing them up. And literally, this is where

1227
01:11:29,285 --> 01:11:32,285
Speaker 3:  Mashable as a website came from, then it went away.

1228
01:11:33,825 --> 01:11:36,725
Speaker 3:  All that went away. Like Facebook, like closed down the internet basically.

1229
01:11:36,915 --> 01:11:39,605
Speaker 3:  They said we are gonna do all these services in a proprietary way and we

1230
01:11:39,605 --> 01:11:43,495
Speaker 3:  won't talk to anyone else. And that was the end of that. I'm only

1231
01:11:43,495 --> 01:11:47,215
Speaker 3:  making the comparison 'cause I see what people are doing with MCP

1232
01:11:47,215 --> 01:11:50,975
Speaker 3:  with these automation platforms with a bunch of age agentic, no

1233
01:11:51,005 --> 01:11:54,975
Speaker 3:  code tools. And I'm like, oh, I see this parallel. Right? I

1234
01:11:54,975 --> 01:11:58,495
Speaker 3:  see a bunch of people making applications in a new way using new standards,

1235
01:11:59,355 --> 01:12:03,335
Speaker 3:  having some like straightforwardly depressing ideas

1236
01:12:03,465 --> 01:12:07,255
Speaker 3:  about what the application should do. Sure. But like there's an energy there

1237
01:12:07,255 --> 01:12:11,085
Speaker 3:  that is unlike the energy of I don know crypto, right?

1238
01:12:11,085 --> 01:12:14,845
Speaker 3:  Where the only goal was ever to make number go up or take a cut of transactions,

1239
01:12:14,845 --> 01:12:18,485
Speaker 3:  which is just the least inspiring economic model of all time.

1240
01:12:19,105 --> 01:12:23,005
Speaker 3:  It was this like that was all financialized. This is very much like the

1241
01:12:23,005 --> 01:12:26,925
Speaker 3:  kids are making toys and they're having a good time doing it and

1242
01:12:26,925 --> 01:12:29,845
Speaker 3:  they're posting tiktoks about the toys they're making and the other ideas

1243
01:12:29,875 --> 01:12:33,685
Speaker 3:  that that is inspiring them to have. And there's,

1244
01:12:34,165 --> 01:12:38,045
Speaker 3:  I just know that there's usually something there, there are all these

1245
01:12:38,045 --> 01:12:41,405
Speaker 3:  other flaws. The, there's a fatal copyright flaw. There's a really, really,

1246
01:12:41,405 --> 01:12:44,645
Speaker 3:  really important climate flaw that everyone should talk about more. There

1247
01:12:44,745 --> 01:12:48,695
Speaker 3:  is just an LOM technology flaw that who

1248
01:12:48,695 --> 01:12:52,295
Speaker 3:  knows. But in the meantime there's this like little thing, like

1249
01:12:52,445 --> 01:12:56,335
Speaker 3:  there's this little green shoot of activity that it feels like,

1250
01:12:56,875 --> 01:12:59,735
Speaker 3:  oh, we're about to re-architect how applications work.

1251
01:13:00,305 --> 01:13:00,655
Speaker 1:  Right?

1252
01:13:01,055 --> 01:13:04,455
Speaker 3:  M-C-P-M-C-P is like fundamentally a conversation about what is an API, how

1253
01:13:04,455 --> 01:13:08,015
Speaker 3:  should APIs work? And that stuff is like, you know, fundamentally

1254
01:13:08,295 --> 01:13:08,495
Speaker 3:  interesting.

1255
01:13:09,145 --> 01:13:13,115
Speaker 1:  Yeah. I think I, I've come to see AI as like two separate things that

1256
01:13:13,115 --> 01:13:16,795
Speaker 1:  really need separate words. And the one is, is like

1257
01:13:17,175 --> 01:13:21,115
Speaker 1:  AI as essentially tool building systems. And

1258
01:13:21,115 --> 01:13:24,755
Speaker 1:  I think the, the thing I hear over and over from people is that like

1259
01:13:25,455 --> 01:13:29,155
Speaker 1:  it, the, the coding use of generative

1260
01:13:29,255 --> 01:13:33,235
Speaker 1:  AI has like already found product market fit. Like however much code

1261
01:13:33,295 --> 01:13:37,075
Speaker 1:  you think you use is being written by ai. The the

1262
01:13:37,075 --> 01:13:40,995
Speaker 1:  actual answer is much higher. Like much, much higher. And

1263
01:13:41,385 --> 01:13:45,275
Speaker 1:  it's, it's everywhere and it works and it is powerful and it is in use in

1264
01:13:45,455 --> 01:13:49,155
Speaker 1:  vastly mainstream ways. Like the, the idea of vibe

1265
01:13:49,155 --> 01:13:52,875
Speaker 1:  coding like is here and it works. And I, I generally

1266
01:13:52,875 --> 01:13:56,795
Speaker 1:  agree, I think it's very cool. I think like one level of

1267
01:13:57,245 --> 01:14:00,595
Speaker 1:  above that is the question of like, is any of this worth it?

1268
01:14:01,395 --> 01:14:03,755
Speaker 1:  Which I think is like a good and valuable question, but it is a separate

1269
01:14:04,035 --> 01:14:07,395
Speaker 1:  question. Right? Like it, that piece of it works. I don't think there's any

1270
01:14:07,595 --> 01:14:11,445
Speaker 1:  question about that. And I think there's a really interesting road down

1271
01:14:11,445 --> 01:14:15,365
Speaker 1:  that that is also the same question about like, is AI going

1272
01:14:15,365 --> 01:14:19,005
Speaker 1:  to get us closer to curing cancer? Like Yes. And that that stuff is real

1273
01:14:19,025 --> 01:14:22,805
Speaker 1:  and it's working and it's meaningful. Again, is it worth, it is a fair

1274
01:14:22,965 --> 01:14:26,805
Speaker 1:  question, but like that stuff is real. The flip side, And I think this is

1275
01:14:26,805 --> 01:14:30,205
Speaker 1:  the thing that gets us tripped up because we conflate these two things is

1276
01:14:30,345 --> 01:14:34,325
Speaker 1:  should my computer be my friend? Seriously? And this, this is

1277
01:14:34,325 --> 01:14:38,045
Speaker 1:  the thing that I have come to is like the, the, the question of

1278
01:14:38,045 --> 01:14:41,645
Speaker 1:  like, do we think as humans it is good

1279
01:14:42,035 --> 01:14:45,485
Speaker 1:  that people are building relationships with ai? Chatbots

1280
01:14:45,945 --> 01:14:49,845
Speaker 1:  is a completely separate And I think equally important question in

1281
01:14:49,845 --> 01:14:53,485
Speaker 1:  all of this, and it has nothing to do with the other thing. Like cursor is

1282
01:14:53,505 --> 01:14:57,335
Speaker 1:  not your friend cursor is just this like unbelievably powerful

1283
01:14:57,595 --> 01:15:01,215
Speaker 1:  AI tool for building things. It's not, it's not trying to bang you.

1284
01:15:01,445 --> 01:15:04,775
Speaker 1:  It's not trying to like give you advice about how to live your life. But

1285
01:15:04,775 --> 01:15:08,535
Speaker 1:  then there is other stuff that is very explicitly doing that, like the

1286
01:15:08,535 --> 01:15:10,975
Speaker 1:  replicas and the characters of the world. And then there's all this stuff

1287
01:15:10,975 --> 01:15:14,855
Speaker 1:  in the middle that's like, chat GPT is is nice to you

1288
01:15:14,855 --> 01:15:17,975
Speaker 1:  because you'll use it more if it's nice to you. Like that's just real.

1289
01:15:18,755 --> 01:15:21,495
Speaker 1:  But then they tipped that over where it was like it got weirdly nice to you

1290
01:15:21,495 --> 01:15:23,535
Speaker 1:  and then people didn't want to use it anymore and they had to roll that back.

1291
01:15:23,875 --> 01:15:27,655
Speaker 1:  And this is like, all this stuff is being tuned so that you'll

1292
01:15:27,675 --> 01:15:30,895
Speaker 1:  use it and it's like, it's an engagement machine in the way that like social

1293
01:15:30,895 --> 01:15:34,775
Speaker 1:  media is an engagement machine. And I think that's the thing that

1294
01:15:34,835 --> 01:15:38,495
Speaker 1:  I'm trying to sort of separate and reckon with separately because like,

1295
01:15:38,875 --> 01:15:42,055
Speaker 1:  as a, as an infrastructure for product making,

1296
01:15:43,395 --> 01:15:47,375
Speaker 1:  AI is like very powerful and everywhere And I think

1297
01:15:47,375 --> 01:15:50,775
Speaker 1:  is is essentially inevitable at this point. But this question of like, should

1298
01:15:50,775 --> 01:15:53,895
Speaker 1:  I hang out with my computer? I think we should spend a lot more time

1299
01:15:54,705 --> 01:15:56,105
Speaker 1:  thinking about and talking about.

1300
01:15:56,505 --> 01:15:59,225
Speaker 3:  I would separate that. I I I agree with that separation. I, I, I think I

1301
01:15:59,225 --> 01:16:03,065
Speaker 3:  would do it differently. Okay. There's, and it, it's just

1302
01:16:03,065 --> 01:16:06,585
Speaker 3:  really about the hype of, of the industry. There's,

1303
01:16:07,065 --> 01:16:10,185
Speaker 3:  I can see the old web going away because Google has decided to answer the

1304
01:16:10,305 --> 01:16:13,825
Speaker 3:  questions itself and some of those answers are wrong because the AI isn't

1305
01:16:13,985 --> 01:16:15,545
Speaker 3:  actually smart and can't be trusted. Well,

1306
01:16:15,545 --> 01:16:16,145
Speaker 1:  Right. There's that.

1307
01:16:16,565 --> 01:16:20,145
Speaker 3:  And then right next to that is, you know, Sundar saying

1308
01:16:20,365 --> 01:16:23,345
Speaker 3:  to me on decoder, we're gonna start to do

1309
01:16:24,205 --> 01:16:27,905
Speaker 3:  web app deployment on the search result page, like zero shot

1310
01:16:28,095 --> 01:16:31,665
Speaker 3:  vibe coded custom web apps when you search for something. And that is a very

1311
01:16:31,945 --> 01:16:34,665
Speaker 3:  powerful new idea about search. I don dunno what those web apps are gonna

1312
01:16:34,665 --> 01:16:38,585
Speaker 3:  be. All of their ideas are like, we made a chart of baseball statistics and

1313
01:16:38,585 --> 01:16:42,235
Speaker 3:  it's like, well do we have to, we're literally boiling the oceans for is

1314
01:16:42,235 --> 01:16:46,115
Speaker 3:  it worth it to your point? Right? Then there's the right next to that. If

1315
01:16:46,115 --> 01:16:48,515
Speaker 3:  you believe in any, all that's gonna happen and Google's making it happen.

1316
01:16:49,145 --> 01:16:52,715
Speaker 3:  There's that we are going to reconceptualize the web itself

1317
01:16:53,375 --> 01:16:57,195
Speaker 3:  as a new kind of application environment where

1318
01:16:57,855 --> 01:17:01,675
Speaker 3:  agents are able to go and talk to what are effectively

1319
01:17:01,915 --> 01:17:05,795
Speaker 3:  databases and services and kind of like construct new capabilities for

1320
01:17:05,795 --> 01:17:09,605
Speaker 3:  you. That's a big, big, big, big, big idea.

1321
01:17:10,035 --> 01:17:13,605
Speaker 3:  Like maybe the biggest idea in the history of application development

1322
01:17:13,915 --> 01:17:16,885
Speaker 3:  that we're gonna take the web from a series of user interfaces that you can

1323
01:17:16,885 --> 01:17:20,845
Speaker 3:  click around on, which is already a remarkably big idea. Yeah. That changed

1324
01:17:20,865 --> 01:17:24,805
Speaker 3:  the entire nature of computers. And we're gonna say we're abstracting the

1325
01:17:24,805 --> 01:17:28,605
Speaker 3:  user interface away to an a bot or an agent or whatever. And the services

1326
01:17:28,605 --> 01:17:32,485
Speaker 3:  themselves are just like coin operated databases.

1327
01:17:33,065 --> 01:17:35,565
Speaker 3:  And you show up and you say Uber, do you have cars? And Uber says, I do have

1328
01:17:35,565 --> 01:17:38,405
Speaker 3:  cars. That'll be $3 from me to tell you what cars you have. And then you

1329
01:17:38,405 --> 01:17:41,125
Speaker 3:  pay the fee and it tells you your car and off you go, okay.

1330
01:17:42,085 --> 01:17:44,715
Speaker 3:  Right. Like and then you gotta pay Uber. It's transaction fees on top of

1331
01:17:44,715 --> 01:17:44,795
Speaker 3:  that.

1332
01:17:46,625 --> 01:17:50,525
Speaker 3:  That's a big idea about how you would build new kinds of capabilities in

1333
01:17:50,525 --> 01:17:50,765
Speaker 3:  the world.

1334
01:17:51,425 --> 01:17:54,165
Speaker 2:  Do do we think that's gonna happen though? Do we think that Uber is going

1335
01:17:54,165 --> 01:17:56,245
Speaker 2:  to open up that API for Google?

1336
01:17:56,685 --> 01:18:00,485
Speaker 3:  I mean basically, I mean what, what Dara has said to me is we're gonna try

1337
01:18:00,485 --> 01:18:03,445
Speaker 3:  it at first 'cause it'll be cool and if it's really cool and everyone likes

1338
01:18:03,445 --> 01:18:05,565
Speaker 3:  it, we're gonna charge a lot of money for it. Okay.

1339
01:18:05,565 --> 01:18:08,845
Speaker 2:  Yeah, because this is my question, right? Like if they open a specific API

1340
01:18:08,845 --> 01:18:12,645
Speaker 2:  for Google, then like probably Google's going to wanna cut of that

1341
01:18:12,825 --> 01:18:13,365
Speaker 2:  too, right?

1342
01:18:13,365 --> 01:18:16,765
Speaker 3:  Well so it's not a specific API for Google. It's more like they'll open up

1343
01:18:16,765 --> 01:18:20,725
Speaker 3:  an MCP server and your agent can show up and maybe your agent is run

1344
01:18:20,725 --> 01:18:22,845
Speaker 3:  by Google or maybe you're running it luckily who knows how any of this will

1345
01:18:22,845 --> 01:18:26,805
Speaker 3:  work. It'll show up and be able to like, instead of having to issue known

1346
01:18:26,965 --> 01:18:30,845
Speaker 3:  API commands, it can in a more natural languagey way,

1347
01:18:31,305 --> 01:18:34,645
Speaker 3:  say I've got a person who needs a car. Do you, do you have cars?

1348
01:18:35,535 --> 01:18:39,205
Speaker 3:  Right? And you won't need this like big database of API commands.

1349
01:18:39,575 --> 01:18:43,405
Speaker 3:  It'll just be like, yeah, I do. They're very expensive. Yeah. Right. Do you

1350
01:18:43,405 --> 01:18:45,885
Speaker 3:  have money? And then like a third service will be like, I'm here to process

1351
01:18:45,885 --> 01:18:49,405
Speaker 3:  your transaction. That will also cost money and maybe all that makes everything

1352
01:18:49,405 --> 01:18:52,905
Speaker 3:  too expensive and untenable. Right? But you just have these like

1353
01:18:54,885 --> 01:18:57,665
Speaker 3:  vastly more resilient APIs. Like that's how I've been thinking about

1354
01:18:57,725 --> 01:19:01,665
Speaker 2:  It. It's just So I feel like what you're describing is the AI version of,

1355
01:19:01,845 --> 01:19:05,745
Speaker 2:  of the app store versus the web. Yep. Where it's like, that

1356
01:19:05,745 --> 01:19:08,865
Speaker 2:  would be great. It would be really nice if everything worked nicely.

1357
01:19:09,965 --> 01:19:13,825
Speaker 2:  And all I see is a way for Google to take a big cut of money on every

1358
01:19:13,825 --> 01:19:14,865
Speaker 2:  single thing it's doing. I

1359
01:19:14,865 --> 01:19:18,345
Speaker 3:  Think that might be what Google sees too, right? I mean there's a reason

1360
01:19:18,345 --> 01:19:21,865
Speaker 3:  they're all cha Microsoft chasing, Google's chasing it. And the, the fight,

1361
01:19:22,045 --> 01:19:25,385
Speaker 3:  the reason I was like, yep. When you said the app store, the fight is that

1362
01:19:25,385 --> 01:19:29,345
Speaker 3:  the whole industry is chasing this on the web. That's where

1363
01:19:29,345 --> 01:19:33,105
Speaker 3:  the industry is going. Mm. The web MCP big web

1364
01:19:33,465 --> 01:19:37,385
Speaker 3:  services. How do we, can we buy Chrome from Google if the, if

1365
01:19:37,385 --> 01:19:41,105
Speaker 3:  the government makes Google sell Chrome, can we light up a new browser

1366
01:19:41,105 --> 01:19:44,625
Speaker 3:  called Dia instead of Arc? Our old browser, the browser company's a startup.

1367
01:19:44,895 --> 01:19:48,385
Speaker 3:  There's no reason for them to burn down their existing browser other people

1368
01:19:48,515 --> 01:19:52,425
Speaker 3:  don't use. Yeah. Right. They had to start over 'cause that's the future

1369
01:19:52,425 --> 01:19:55,585
Speaker 3:  they see. And you gotta re-architect the whole idea if you're like all of

1370
01:19:55,585 --> 01:19:59,435
Speaker 3:  this new application, logical exist on a web in new ways, and maybe

1371
01:19:59,435 --> 01:20:02,695
Speaker 3:  we're not clicking around yet, right? Maybe we're just summarizing here.

1372
01:20:02,695 --> 01:20:06,175
Speaker 3:  But owning the, owning the browser, owning the literal application layer

1373
01:20:06,315 --> 01:20:10,195
Speaker 3:  is important. And then there's Apple, which thinks

1374
01:20:10,255 --> 01:20:13,155
Speaker 3:  all of this is gonna happen inside apps locally on your phone.

1375
01:20:15,555 --> 01:20:18,695
Speaker 3:  Boy is that risky. Boy is that existentially risky for Apple?

1376
01:20:19,095 --> 01:20:22,055
Speaker 1:  I mean, gosh, it's like, it's so weird that everybody believes the thing

1377
01:20:22,055 --> 01:20:25,175
Speaker 1:  that they are heavily financially incentivized to believe is gonna be the

1378
01:20:25,175 --> 01:20:25,935
Speaker 1:  one that comes True.

1379
01:20:27,035 --> 01:20:30,445
Speaker 3:  Yeah. But I mean the iPhone already exists as a vessel for other people's

1380
01:20:30,565 --> 01:20:33,805
Speaker 3:  services, right? Like chat GBT is nothing,

1381
01:20:34,275 --> 01:20:37,645
Speaker 3:  nothing really happens on the iPhone when you open the chat GBT app, right?

1382
01:20:37,905 --> 01:20:41,805
Speaker 3:  So like there's just some thing where like if you think the user

1383
01:20:41,805 --> 01:20:45,325
Speaker 3:  interface is moving because of ai, it's not because people are in

1384
01:20:45,645 --> 01:20:49,325
Speaker 3:  love with their computers. Like that's the, that's the distinction that I'm

1385
01:20:49,325 --> 01:20:52,245
Speaker 3:  making is there's a part of AI that is very much about

1386
01:20:53,725 --> 01:20:57,075
Speaker 3:  where the applications go, what the platform shift looks like, what even

1387
01:20:57,135 --> 01:21:01,075
Speaker 3:  is an application or an API in this new world. And then there's

1388
01:21:01,135 --> 01:21:04,955
Speaker 3:  Sam Altman being like, I've developed artificial general intelligence and

1389
01:21:05,175 --> 01:21:08,835
Speaker 3:  you will, you will marry your computer, right? And I need a trillion dollars.

1390
01:21:08,895 --> 01:21:12,775
Speaker 3:  And it's like, well that's just hype, right? Like what you

1391
01:21:12,775 --> 01:21:15,695
Speaker 3:  need is a bunch of money to take down Apple's application model.

1392
01:21:16,965 --> 01:21:19,265
Speaker 3:  Or maybe Sam Altman really believes he's gonna fall in love with his computer.

1393
01:21:19,305 --> 01:21:21,305
Speaker 3:  I don't, I don't know the answer to that question. Like, I

1394
01:21:21,305 --> 01:21:24,025
Speaker 1:  Mean, ironically if you're Sam Altman, there's way more money in being the

1395
01:21:24,105 --> 01:21:26,865
Speaker 1:  one who takes down Apple's application model than in making people fall in

1396
01:21:26,865 --> 01:21:27,625
Speaker 1:  love with their computers.

1397
01:21:27,725 --> 01:21:29,745
Speaker 3:  But I think that's where they're going and that's why I think that's what,

1398
01:21:29,745 --> 01:21:32,665
Speaker 3:  why they're doing this, Johnny I deal. Right? The next platform has to

1399
01:21:33,185 --> 01:21:36,945
Speaker 3:  overtake the iPhone application model. Yeah. The distinction to me,

1400
01:21:36,975 --> 01:21:40,925
Speaker 3:  like I think that will Kevin Russ eventually leave his family for

1401
01:21:40,925 --> 01:21:44,845
Speaker 3:  chat GPT again, I, my my, my sincere thanks to

1402
01:21:44,845 --> 01:21:46,605
Speaker 3:  Kevin for allowing me to continue to make this joke.

1403
01:21:48,855 --> 01:21:52,715
Speaker 3:  But I, it just feels like a sideshow and like

1404
01:21:52,745 --> 01:21:56,555
Speaker 3:  it's a sideshow that justifies the hype, but

1405
01:21:56,555 --> 01:21:59,475
Speaker 3:  it's not, I don't think it's actually the thing I agree, you know, it's funny

1406
01:21:59,535 --> 01:22:03,415
Speaker 3:  is like in all of this chum Amazon announced

1407
01:22:03,495 --> 01:22:07,255
Speaker 3:  that a million people now have Alexa Plus and I have only ever met one person

1408
01:22:07,315 --> 01:22:08,095
Speaker 3:  who has Alexa. Plus

1409
01:22:08,155 --> 01:22:09,735
Speaker 1:  You met some, I have met zero people.

1410
01:22:10,065 --> 01:22:12,855
Speaker 3:  There was one person at the talk show. I, I basically asked this question

1411
01:22:12,875 --> 01:22:16,015
Speaker 3:  of the room at the talk show. I was like, does any of you, any of these 700

1412
01:22:16,015 --> 01:22:18,655
Speaker 3:  or however many people were there? Does anybody have Alexa plus a million

1413
01:22:18,655 --> 01:22:22,575
Speaker 3:  people do? And one guy, I was like, yes. And then we asked, is it any good?

1414
01:22:22,575 --> 01:22:26,175
Speaker 3:  And there was like silence and everyone watched it was like very funny. And

1415
01:22:26,175 --> 01:22:30,135
Speaker 3:  then he came up to me afterwards, his name is Don McCaskill. He's the CEO

1416
01:22:30,135 --> 01:22:31,455
Speaker 3:  of Flicker. He's the guy

1417
01:22:32,995 --> 01:22:36,735
Speaker 3:  who has Alexa Plus that feels right. And we talked to, and Andre And I talked

1418
01:22:36,735 --> 01:22:39,215
Speaker 3:  to him for a minute. It was very nice for, for him to be there, for him to

1419
01:22:39,605 --> 01:22:43,055
Speaker 3:  talk to us about it. And he is like, it's fine. It's sort of fine. And at

1420
01:22:43,055 --> 01:22:45,175
Speaker 3:  WIC works it's, it's better than they think it is, but it's not very good.

1421
01:22:45,195 --> 01:22:48,495
Speaker 3:  It was like, it was basically a takeaway. We should just have him on to talk

1422
01:22:48,495 --> 01:22:51,015
Speaker 3:  about Flickr and then his also his experiences with Alexa plus,

1423
01:22:51,365 --> 01:22:53,495
Speaker 1:  Yeah, a hundred percent love this idea. But

1424
01:22:53,495 --> 01:22:56,535
Speaker 3:  That's like where we're at. It's like a Amazon shipped it, they promised

1425
01:22:56,535 --> 01:23:00,415
Speaker 3:  they were gonna do it and it's like me and Google has promised

1426
01:23:00,415 --> 01:23:02,895
Speaker 3:  it and like they might be the closest and with, you know, some of the stuff

1427
01:23:02,895 --> 01:23:06,605
Speaker 3:  Gemini can do on a Samsung phone is like, you can just talk to, you can just

1428
01:23:06,605 --> 01:23:10,205
Speaker 3:  talk to it and you can be like, turn off my Bluetooth and like it'll kind

1429
01:23:10,205 --> 01:23:14,045
Speaker 3:  of do it. That's, that's the state of the art, you know, like it's

1430
01:23:14,545 --> 01:23:18,105
Speaker 3:  all this stuff is gonna change but none of it works yet. And so you can give

1431
01:23:18,105 --> 01:23:20,665
Speaker 3:  shit to Apple but like none of it works yet. And

1432
01:23:20,665 --> 01:23:24,615
Speaker 1:  Until it like really, really, really works, it's a

1433
01:23:24,615 --> 01:23:28,535
Speaker 1:  bad product. Like this is not the kind of thing that can be successful

1434
01:23:28,535 --> 01:23:31,695
Speaker 1:  at like a, you know, 70% success rate.

1435
01:23:32,245 --> 01:23:34,495
Speaker 1:  This thing you're supposed to talk to and interact with all the time, if

1436
01:23:34,495 --> 01:23:38,415
Speaker 1:  it like, is kind of good. It's actually really bad and it's, it's

1437
01:23:38,415 --> 01:23:42,255
Speaker 1:  gonna be in kind of good for a pretty long time I think. Yeah.

1438
01:23:42,675 --> 01:23:46,455
Speaker 3:  The last thing we should talk about here, Sam Altman put out a long blog,

1439
01:23:46,525 --> 01:23:50,495
Speaker 3:  blog post as he is want to do. Yeah. I always wonder

1440
01:23:50,495 --> 01:23:52,095
Speaker 3:  if he has chat g did he write the blog posts?

1441
01:23:52,395 --> 01:23:55,295
Speaker 1:  He said he didn't, but he said in his tweet that this was probably the last

1442
01:23:55,325 --> 01:23:57,815
Speaker 1:  blog post he would write without chat GPT.

1443
01:23:58,085 --> 01:23:58,895
Speaker 3:  Alright, Sam.

1444
01:23:59,275 --> 01:24:02,815
Speaker 1:  And I just like, there's so many executives now who are like,

1445
01:24:03,455 --> 01:24:06,615
Speaker 1:  I didn't even have to do anything. I just used AI to do this. And it's like,

1446
01:24:06,615 --> 01:24:10,495
Speaker 1:  are you trying to fire yourself? Like, like what a cool way to

1447
01:24:10,495 --> 01:24:12,055
Speaker 1:  tell on yourself for being bad at your job.

1448
01:24:12,485 --> 01:24:16,455
Speaker 3:  There's a very funny, like from the late nineties early two

1449
01:24:16,615 --> 01:24:20,575
Speaker 3:  thousands image, it's like a meme, it's

1450
01:24:20,575 --> 01:24:23,535
Speaker 3:  like a proto meme. I don't know how to describe it. Will Joel, our senior

1451
01:24:23,735 --> 01:24:26,575
Speaker 3:  creative director And I send it to each other all the time and it has a title

1452
01:24:26,595 --> 01:24:30,375
Speaker 3:  that's like lifecycle advertising, career evolution,

1453
01:24:30,875 --> 01:24:34,695
Speaker 3:  and it's told through application icons. So it's like you start as a junior

1454
01:24:35,165 --> 01:24:39,095
Speaker 3:  account designer and you've, and the icons like the Photoshop icon

1455
01:24:39,095 --> 01:24:41,695
Speaker 3:  and then it's like Photoshop illustrator and then it's flash, which is very

1456
01:24:41,695 --> 01:24:44,935
Speaker 3:  funny. This is how old this meme is. And then at some point they add Excel

1457
01:24:44,995 --> 01:24:48,175
Speaker 3:  to the stack and then some point the entire stack goes away. And it's the

1458
01:24:48,495 --> 01:24:51,695
Speaker 3:  Microsoft entourage icon again, how old this is. That was an email client

1459
01:24:51,695 --> 01:24:55,295
Speaker 3:  that Microsoft had. And the very last one is Chief creative Officer and it's

1460
01:24:55,295 --> 01:24:59,215
Speaker 3:  just a bottle of champagne. That's really good. I will dig this up. We'll

1461
01:24:59,215 --> 01:25:02,655
Speaker 3:  find a way to share this. It is, it makes me laugh every time and literally

1462
01:25:02,655 --> 01:25:05,815
Speaker 3:  will And I send it back and forth to each other all the time. 'cause we both

1463
01:25:05,815 --> 01:25:09,295
Speaker 3:  live in a meeting zone now, like constantly. That's what I think of every

1464
01:25:09,295 --> 01:25:11,735
Speaker 3:  time an executive says Chachi Peter wrote this for me. Like, oh, you're just

1465
01:25:11,735 --> 01:25:14,535
Speaker 3:  the bottle. Yep. Your job is just the bottle.

1466
01:25:15,755 --> 01:25:18,815
Speaker 3:  The fact that you can fire off text is sort of irrelevant to your actual

1467
01:25:18,815 --> 01:25:22,015
Speaker 3:  job. That's amazing. Anyhow, the blog post is titled The Gentle Singularity.

1468
01:25:22,235 --> 01:25:26,175
Speaker 3:  It is very long, very convoluted and Sam Altman Ways and basically the

1469
01:25:26,175 --> 01:25:28,655
Speaker 3:  thesis is a GI is already here. Like, I don't know how else to explain his

1470
01:25:28,655 --> 01:25:32,095
Speaker 3:  thesis. He's like, it's already happening. Just sit back, enjoy the ride

1471
01:25:32,095 --> 01:25:32,855
Speaker 3:  and gimme a trillion dollars.

1472
01:25:37,155 --> 01:25:41,015
Speaker 3:  And in it, he, he makes this claim that the average chat GBT

1473
01:25:41,015 --> 01:25:44,855
Speaker 3:  query uses roughly one fifteenth of a teaspoon of water. And I think that

1474
01:25:44,855 --> 01:25:48,615
Speaker 3:  means the climate concerns are finally getting to Sam Almond, right? We're

1475
01:25:48,655 --> 01:25:51,135
Speaker 3:  lighting up new coal and gas plants, we're building data centers faster than

1476
01:25:51,135 --> 01:25:55,055
Speaker 3:  we were building data centers than ever. Justine Calm on our team who

1477
01:25:55,055 --> 01:25:58,615
Speaker 3:  covers climate for us. She And I are having this conversation and

1478
01:25:58,785 --> 01:26:02,215
Speaker 3:  she's like, the thing is data center use was basically flat and then AI showed

1479
01:26:02,215 --> 01:26:03,580
Speaker 3:  up and now it's skyrocketing.

1480
01:26:03,885 --> 01:26:04,005
Speaker 2:  Hmm.

1481
01:26:04,525 --> 01:26:08,475
Speaker 3:  Right. So we, we, it's not that like com using computers is bad.

1482
01:26:08,825 --> 01:26:12,635
Speaker 3:  It's that this new thing is like inefficient and we're, we're just, the

1483
01:26:12,695 --> 01:26:15,075
Speaker 3:  demand for data centers has skyrocketed because of it.

1484
01:26:17,185 --> 01:26:20,835
Speaker 3:  What do you think, like I look at this stat, I'll read the full quote. This

1485
01:26:20,835 --> 01:26:24,675
Speaker 3:  is from Sam Altman people. Lemme actually let me read the full

1486
01:26:24,705 --> 01:26:28,395
Speaker 3:  stat from Altman's blog post And I wanna get your reactions to it. Quote,

1487
01:26:28,415 --> 01:26:32,115
Speaker 3:  people are often curious about how much energy a chat bet query uses. The

1488
01:26:32,115 --> 01:26:35,835
Speaker 3:  average query uses about 0.34 watt hours about what an oven would use in

1489
01:26:35,835 --> 01:26:38,955
Speaker 3:  little over a second or a high efficiency light bulb would use in a couple

1490
01:26:38,955 --> 01:26:42,835
Speaker 3:  minutes. And then he says the cost will converge too near the cost

1491
01:26:42,835 --> 01:26:46,035
Speaker 3:  of the electricity itself. And he says this thing up on 15th of a teaspoon

1492
01:26:46,035 --> 01:26:48,685
Speaker 3:  of water. Those aren't great stats. What do you think?

1493
01:26:49,205 --> 01:26:53,025
Speaker 2:  I don't know exactly how much water. I don't know any

1494
01:26:53,025 --> 01:26:55,465
Speaker 2:  piece of electronics like it should use. I don't know. I don't know what

1495
01:26:55,465 --> 01:26:59,105
Speaker 2:  a good amount of a teaspoon is. So, so it's a, it's it's like,

1496
01:26:59,535 --> 01:27:02,745
Speaker 2:  this makes it sound really tiny, but I don't actually know what this means.

1497
01:27:04,215 --> 01:27:08,025
Speaker 2:  It's interesting. I I I kind of wanna separate this, or at least in my mind

1498
01:27:08,025 --> 01:27:11,305
Speaker 2:  to separate this as two different things. I think a lot of the like, oh,

1499
01:27:11,565 --> 01:27:14,505
Speaker 2:  AI is terrible. It's boiling the oceans. That feels like a way of actually

1500
01:27:14,505 --> 01:27:18,265
Speaker 2:  just dismissing AI rather than genuine

1501
01:27:18,295 --> 01:27:22,025
Speaker 2:  concern about climate to me, in a lot of ways, that being said,

1502
01:27:22,685 --> 01:27:25,465
Speaker 2:  as we're talking about data center use is

1503
01:27:26,465 --> 01:27:29,345
Speaker 2:  dramatically increasing. Electricity use is dramatically increasing and these

1504
01:27:29,585 --> 01:27:32,985
Speaker 2:  companies that made these climate goals are now having a much more difficult

1505
01:27:32,985 --> 01:27:35,945
Speaker 2:  time reaching them. I think that has compounded by

1506
01:27:37,085 --> 01:27:41,065
Speaker 2:  the current electricity plans of the administration that

1507
01:27:41,065 --> 01:27:44,785
Speaker 2:  is in office, which is not making it easier to get clean energy

1508
01:27:44,785 --> 01:27:46,225
Speaker 2:  online. So

1509
01:27:48,065 --> 01:27:51,735
Speaker 2:  I don't know. IIII think it is very

1510
01:27:52,055 --> 01:27:54,615
Speaker 2:  interesting that this has

1511
01:27:55,715 --> 01:27:59,495
Speaker 2:  boiled up enough to reach Sam Altman that he feels that he has to defend

1512
01:27:59,495 --> 01:28:03,335
Speaker 2:  against it. This doesn't really feel like a meaningful defense in any way

1513
01:28:03,335 --> 01:28:03,655
Speaker 2:  to me,

1514
01:28:06,365 --> 01:28:10,225
Speaker 2:  but you know, when you're measuring it by teaspoons of water, that's like

1515
01:28:10,225 --> 01:28:14,185
Speaker 2:  not, you're clearly trying to downplay it. You're tr yeah. You, you are

1516
01:28:14,185 --> 01:28:17,385
Speaker 2:  not actually trying to solve it. You're trying to say, look, it's, it's so

1517
01:28:17,385 --> 01:28:20,945
Speaker 2:  small you can't actually tell what it is. I I don't wanna

1518
01:28:21,295 --> 01:28:25,065
Speaker 2:  like, it, it kind of like disturbs me to know like that any

1519
01:28:25,065 --> 01:28:29,025
Speaker 2:  amount of water is disappearing when I'm using technology. I mean, I assume

1520
01:28:29,025 --> 01:28:32,385
Speaker 2:  we're all drinking a little bit of water listening to this podcast, but like

1521
01:28:32,385 --> 01:28:36,225
Speaker 2:  I, I don't know what the right number is. And I think it's very,

1522
01:28:36,405 --> 01:28:40,105
Speaker 2:  it, it is funny to think of it as individual chat GPT queries

1523
01:28:40,485 --> 01:28:40,905
Speaker 2:  versus

1524
01:28:43,115 --> 01:28:44,375
Speaker 2:  the data centers themselves.

1525
01:28:44,795 --> 01:28:48,735
Speaker 3:  I'm obliged on behalf of our most pedantic listeners to say the water doesn't

1526
01:28:48,735 --> 01:28:52,415
Speaker 3:  disappear, it's just diverted into a different part of the water cycle. But

1527
01:28:52,415 --> 01:28:56,095
Speaker 3:  that's not people drinking it or being used in farmlands, right? Like that's

1528
01:28:56,095 --> 01:28:59,095
Speaker 3:  the problem. Like you're using the water elsewhere.

1529
01:29:00,225 --> 01:29:04,105
Speaker 3:  That's the problem, right? Like the water is being diverted to this use as

1530
01:29:04,105 --> 01:29:07,985
Speaker 3:  opposed to whatever higher value use you might believe exists. That's

1531
01:29:07,995 --> 01:29:11,505
Speaker 3:  weird. Like we should just acknowledge that that's a weird outcome of this.

1532
01:29:11,725 --> 01:29:15,365
Speaker 3:  The other thing that really gets me, and David, I think you've spent more

1533
01:29:15,365 --> 01:29:19,325
Speaker 3:  time like using AI tools than I have in this way. Like no one

1534
01:29:19,325 --> 01:29:21,445
Speaker 3:  does, but one chat GPT query.

1535
01:29:22,355 --> 01:29:26,165
Speaker 1:  Well, right, I mean I think it's, it's just a stupid way to

1536
01:29:26,605 --> 01:29:30,125
Speaker 1:  quantify this stuff, right? And I think we, we've talked a lot about how

1537
01:29:30,125 --> 01:29:34,005
Speaker 1:  much this stuff costs. Like we know OpenAI loses money

1538
01:29:34,005 --> 01:29:37,845
Speaker 1:  every time you do the query. Like that's just true. It continue. They,

1539
01:29:37,845 --> 01:29:40,645
Speaker 1:  they're just burning money happily as they grow.

1540
01:29:42,385 --> 01:29:46,285
Speaker 1:  But yeah, the, the, these things are designed for like long conversations

1541
01:29:46,305 --> 01:29:49,605
Speaker 1:  and some of the numbers that we've seen are like, there are some estimates

1542
01:29:49,605 --> 01:29:52,165
Speaker 1:  out there that Chad GBT gets more than a billion queries a day.

1543
01:29:54,125 --> 01:29:57,685
Speaker 1:  A billion fifteenths of a teaspoon is still an awful lot of water.

1544
01:29:58,385 --> 01:30:01,165
Speaker 1:  And So I think again, it's, it's this question of

1545
01:30:02,395 --> 01:30:05,445
Speaker 1:  it's the is it worth it question, right? Like all this stuff is trade-offs

1546
01:30:05,445 --> 01:30:08,605
Speaker 1:  and it's like to the data center point that there have been all these

1547
01:30:09,185 --> 01:30:12,925
Speaker 1:  issues recently where these massive data centers are being built in these

1548
01:30:12,925 --> 01:30:16,765
Speaker 1:  communities that just don't want massive data centers because it, it changes

1549
01:30:17,465 --> 01:30:20,325
Speaker 1:  the look of your community, it changes the electrical grid of your community.

1550
01:30:20,325 --> 01:30:24,285
Speaker 1:  Like all of these things are happening downstream of

1551
01:30:25,035 --> 01:30:28,205
Speaker 1:  this belief that AI is going to change the way that we do everything and

1552
01:30:28,205 --> 01:30:32,165
Speaker 1:  we have to build enough infrastructure to support it. And so sure

1553
01:30:32,905 --> 01:30:36,485
Speaker 1:  the cost will come down towards the cost of electricity, but still what that

1554
01:30:36,485 --> 01:30:40,405
Speaker 1:  means is a vast amount of the electricity of my town is going to

1555
01:30:40,405 --> 01:30:43,645
Speaker 1:  be diverted to doing AI queries. Like I don't,

1556
01:30:44,505 --> 01:30:48,405
Speaker 1:  we, we should decide how we feel about that, right? One way or another. And

1557
01:30:48,715 --> 01:30:52,205
Speaker 1:  even if it's not a a, a huge amount

1558
01:30:52,455 --> 01:30:56,325
Speaker 1:  right now, have you seen the growth that OpenAI is projecting?

1559
01:30:56,395 --> 01:31:00,325
Speaker 1:  Like this is not going to flatline at this

1560
01:31:00,325 --> 01:31:03,885
Speaker 1:  number of queries per day. If Sam Altman is right, we are all going to do

1561
01:31:03,925 --> 01:31:07,725
Speaker 1:  a 15th of a teaspoon of water, thousands of times a day for

1562
01:31:07,725 --> 01:31:10,805
Speaker 1:  billions of people around the world. And like that changes things. How

1563
01:31:10,805 --> 01:31:14,005
Speaker 3:  Much water do you think it took to fall in love with Kevin Reese? Gallons

1564
01:31:14,705 --> 01:31:15,125
Speaker 1:  Easily

1565
01:31:15,125 --> 01:31:16,365
Speaker 3:  Gallons, hundreds of gallons

1566
01:31:16,435 --> 01:31:19,245
Speaker 1:  Like Olympic sized pools worth at that point,

1567
01:31:19,775 --> 01:31:23,685
Speaker 3:  Kevin, I will give you two Olympic pools in exchange for your

1568
01:31:23,685 --> 01:31:24,205
Speaker 3:  wife and child.

1569
01:31:26,055 --> 01:31:29,885
Speaker 3:  Again, my, my continued things to, I've asked, I want everyone to know, I've

1570
01:31:30,085 --> 01:31:33,285
Speaker 3:  asked him if I can keep making this joke and he looked very tired and said

1571
01:31:33,285 --> 01:31:35,965
Speaker 3:  yes, that's it. And So I just need to make that clear.

1572
01:31:37,355 --> 01:31:40,445
Speaker 1:  Resignation and permission, I guess are the same thing in, in this case,

1573
01:31:40,915 --> 01:31:43,085
Speaker 3:  He's the one who chose to put it on the front page of the New York Times.

1574
01:31:43,115 --> 01:31:44,005
Speaker 3:  That wasn't my decision.

1575
01:31:44,355 --> 01:31:47,365
Speaker 1:  Yeah. I would also, we should move on for this, but I would also just point

1576
01:31:47,365 --> 01:31:50,925
Speaker 1:  out that the, the this, there is absolutely nothing that Sam

1577
01:31:51,125 --> 01:31:55,005
Speaker 1:  Altman offers in this post to substantiate that particular claim.

1578
01:31:55,265 --> 01:31:58,725
Speaker 1:  And in fact, it is vastly smaller than what lots of other

1579
01:31:59,005 --> 01:32:02,925
Speaker 1:  researchers have said. Like, like orders of magnitude smaller.

1580
01:32:03,185 --> 01:32:06,565
Speaker 1:  And so either Sam knows something that we don't and he should tell us how

1581
01:32:06,565 --> 01:32:07,925
Speaker 1:  he got to that number or

1582
01:32:09,685 --> 01:32:10,995
Speaker 1:  maybe that's chat GPT.

1583
01:32:11,225 --> 01:32:12,075
Speaker 3:  It's also worth

1584
01:32:12,075 --> 01:32:15,155
Speaker 1:  Noting chat. GPT also estimates much higher if you just ask Chad GPT I'm

1585
01:32:15,155 --> 01:32:17,115
Speaker 1:  Water it uses it's estimates are much higher than Sam.

1586
01:32:17,225 --> 01:32:21,115
Speaker 3:  It's just li it's just thinking about Kevin. We should ask Microsoft

1587
01:32:21,315 --> 01:32:25,275
Speaker 3:  'cause it runs on Azure. So Yeah. One last, well,

1588
01:32:25,385 --> 01:32:28,675
Speaker 3:  very quickly before we move on. Climate one Fatal Flaw. The other fatal flaw

1589
01:32:28,675 --> 01:32:32,035
Speaker 3:  they keep talking about is copyright law. And Disney and Universal sued Midjourney

1590
01:32:32,035 --> 01:32:35,595
Speaker 3:  this week for copyright infringement because you can just generate

1591
01:32:36,585 --> 01:32:40,095
Speaker 3:  their characters. You can just generate Marvel characters and, and, and DC

1592
01:32:40,095 --> 01:32:41,175
Speaker 3:  characters. You can just do it

1593
01:32:41,275 --> 01:32:43,615
Speaker 1:  Not just, and you don't even have to do the thing where you like ask around

1594
01:32:43,615 --> 01:32:46,415
Speaker 1:  it. You can just be like, show me Simpsons and it'll just do that.

1595
01:32:46,645 --> 01:32:50,015
Speaker 2:  Yeah. Yeah. I'm confused how this took so long. Like this is it like, it's

1596
01:32:50,015 --> 01:32:53,975
Speaker 2:  just, there it is right there. Like the lawsuit is just filled with

1597
01:32:54,315 --> 01:32:56,735
Speaker 2:  AI images of Shrek. Like, it's s like

1598
01:32:56,735 --> 01:32:59,095
Speaker 3:  Insane. That's I meant insane. It wasn't DC characters, it was Shrek that

1599
01:32:59,095 --> 01:33:02,535
Speaker 3:  was on my mind. This is a big problem. It by the way, that's the same that

1600
01:33:02,535 --> 01:33:05,175
Speaker 3:  as the New York Times lawsuit. The lawsuit, their complaint is filled with

1601
01:33:05,195 --> 01:33:08,895
Speaker 3:  the thing just generating times articles Yep. Or information from times articles.

1602
01:33:09,635 --> 01:33:11,255
Speaker 3:  The analysis that I've read is,

1603
01:33:13,425 --> 01:33:16,685
Speaker 3:  you know, open Eyes kind of losing that lawsuit against the Times meta,

1604
01:33:17,305 --> 01:33:21,085
Speaker 3:  you know, they torrented a bunch of books and there's emails in their discovery

1605
01:33:21,185 --> 01:33:23,885
Speaker 3:  in their case where their researcher was like, should we torrent a bunch

1606
01:33:23,885 --> 01:33:26,165
Speaker 3:  of books? And I'm like, what else are we gonna do? I'm like, that's bad.

1607
01:33:26,505 --> 01:33:30,245
Speaker 3:  And so you see the most aggressive rights holders, Disney,

1608
01:33:30,385 --> 01:33:34,365
Speaker 3:  the most aggressive copyright litigant in history being like, oh we

1609
01:33:34,365 --> 01:33:38,005
Speaker 3:  can, we, we got it. We're gonna crush these guys there. There's some weird

1610
01:33:38,245 --> 01:33:41,965
Speaker 3:  outcomes when Disney wins. Its copyright paddles. Like that is a real,

1611
01:33:42,025 --> 01:33:44,605
Speaker 3:  be careful what you wish for situation with Disney in particular,

1612
01:33:45,945 --> 01:33:49,005
Speaker 3:  but this is a fatal flaw for this industry to the point where Nick Clegg,

1613
01:33:49,105 --> 01:33:52,965
Speaker 3:  who used to run meta like policy stuff, la

1614
01:33:53,045 --> 01:33:56,565
Speaker 3:  I think last week was like, if we make artists, if we pay artists or ask

1615
01:33:56,565 --> 01:34:00,045
Speaker 3:  for their permission, the AI industry will fail. And then Disney's like,

1616
01:34:00,045 --> 01:34:03,705
Speaker 3:  here we are so fatal flaw for this industry. I like,

1617
01:34:04,185 --> 01:34:07,905
Speaker 3:  I I see this like thing happening with applications on the web and blah blah,

1618
01:34:07,905 --> 01:34:11,545
Speaker 3:  blah. I wanna be clear, there are some fatal flaws that are gonna have to

1619
01:34:11,545 --> 01:34:13,665
Speaker 3:  be overcome that I don't think money alone can overcome.

1620
01:34:14,255 --> 01:34:17,345
Speaker 1:  This is what I mean by the, is it worth it? Question. Right? Like we, the,

1621
01:34:17,445 --> 01:34:21,185
Speaker 1:  we are starting to understand the list of what it costs

1622
01:34:21,375 --> 01:34:24,745
Speaker 1:  literally and figuratively to do the AI thing

1623
01:34:25,635 --> 01:34:29,375
Speaker 1:  all of these tech companies are trying to do. And to them,

1624
01:34:29,475 --> 01:34:32,935
Speaker 1:  the the answer is yes, it's worth it, right? Like, is is it worth the destruction

1625
01:34:32,995 --> 01:34:36,775
Speaker 1:  of the, the art business in the world? Yes. Clearly

1626
01:34:36,835 --> 01:34:40,455
Speaker 1:  the answer is yes. Is it worth like a flattening of how we think about

1627
01:34:41,075 --> 01:34:43,975
Speaker 1:  all of the stuff that we make as a society? Clearly, yes. Is it worth all

1628
01:34:43,975 --> 01:34:47,175
Speaker 1:  the climate stuff? Is it the answer is just yes. All the way across the board.

1629
01:34:47,925 --> 01:34:51,895
Speaker 1:  They think it's worth it. And like a lot of other people are

1630
01:34:52,055 --> 01:34:55,695
Speaker 1:  standing up and being like, no, the fact that you can't do this without stealing

1631
01:34:55,905 --> 01:34:59,605
Speaker 1:  every artistic work this has ever been created means you shouldn't

1632
01:34:59,705 --> 01:35:03,525
Speaker 1:  do this. Like, we just, it's just how like the, we should

1633
01:35:03,525 --> 01:35:07,085
Speaker 1:  have the other side of that conversation too. I also wanna say just

1634
01:35:07,895 --> 01:35:11,605
Speaker 1:  kudos to Disney again for like having its lawyers

1635
01:35:11,695 --> 01:35:15,645
Speaker 1:  write bars. Like this is, we're in a, we're on such a good run

1636
01:35:16,185 --> 01:35:19,365
Speaker 1:  of just sick ass burns in legal filings.

1637
01:35:20,605 --> 01:35:24,565
Speaker 1:  I just, this, it's right at the beginning of this filing. It just says, midjourney

1638
01:35:24,565 --> 01:35:28,245
Speaker 1:  is the quintessential copyright free writer and a bottomless pit of plagiarism.

1639
01:35:28,625 --> 01:35:31,445
Speaker 1:  You know, somebody wrote bottomless pit of plagiarism and then just like

1640
01:35:31,515 --> 01:35:34,525
Speaker 1:  fist bumped a bunch of dudes in suits around a table.

1641
01:35:34,905 --> 01:35:38,005
Speaker 3:  That's how lawyers do their writing. They, they just are like,

1642
01:35:38,735 --> 01:35:39,565
Speaker 3:  Steve, read this

1643
01:35:42,905 --> 01:35:46,765
Speaker 3:  Co Steve, the complaints are being written to be read by the public.

1644
01:35:46,765 --> 01:35:50,565
Speaker 3:  Yeah. This is a new thing. Jonathan Ter, the DOJ attorney who filed

1645
01:35:50,565 --> 01:35:54,405
Speaker 3:  the against Apple and one and all the Google cases, basically, he was like,

1646
01:35:54,405 --> 01:35:57,605
Speaker 3:  yeah, the first 10 pages are for the public to read. This is how we write

1647
01:35:57,605 --> 01:36:00,485
Speaker 3:  them now. Totally. So it's a good one. We will link it. We can read it, but

1648
01:36:01,055 --> 01:36:04,365
Speaker 3:  fatal false. All right, we gotta take a break. We're gonna come back with

1649
01:36:04,365 --> 01:36:08,165
Speaker 3:  the lightning round. May or not be sponsored. Who knows? I don't know.

1650
01:36:08,305 --> 01:36:10,765
Speaker 3:  That's the whole point, is that, I don't know. We'll be right back.

1651
01:36:15,145 --> 01:36:19,105
Speaker 3:  All right. We're back. Lightning round unsponsored for flavor Again,

1652
01:36:19,745 --> 01:36:23,665
Speaker 3:  I just made that up because I needed to say something after we had sponsors,

1653
01:36:23,965 --> 01:36:27,825
Speaker 3:  but what I really mean is that no one can pay us to do anything, which

1654
01:36:28,075 --> 01:36:31,915
Speaker 3:  I apparently, I've been so loud about lately that people think that

1655
01:36:31,915 --> 01:36:35,835
Speaker 3:  like, I, I won't look like I, I can't even be in the presence

1656
01:36:35,835 --> 01:36:38,675
Speaker 3:  of advertising, which is a very hard way to live as an American. Congratulations.

1657
01:36:38,675 --> 01:36:41,075
Speaker 3:  Yeah. The people are like, oh, the ads are, you go, you have to leave the

1658
01:36:41,075 --> 01:36:44,425
Speaker 3:  room. I'm like, I'm fine. But that's where I see,

1659
01:36:44,525 --> 01:36:47,385
Speaker 1:  I'm starting to think you're easily bought. There's a real, like, you know,

1660
01:36:47,525 --> 01:36:50,625
Speaker 1:  me thinks that off protest too much thing going on here where I'm like, maybe

1661
01:36:50,695 --> 01:36:53,065
Speaker 1:  Neli iss on the take and he's just yelling loudly about it. I

1662
01:36:53,065 --> 01:36:55,985
Speaker 3:  Don't know. Have you heard of the new Pegasus GS nine yacht? David,

1663
01:36:57,415 --> 01:36:59,345
Speaker 3:  it's delightful. If you have the means,

1664
01:37:01,645 --> 01:37:02,385
Speaker 3:  all right, it's time.

1665
01:37:02,885 --> 01:37:05,945
Speaker 1:  Oh my God, I've, I've gone all the way around from excitement about this

1666
01:37:05,945 --> 01:37:08,465
Speaker 1:  to, I can't believe we have to keep doing this. We're gonna keep doing it.

1667
01:37:08,655 --> 01:37:12,585
Speaker 1:  It's time for America's favorite podcast within a podcast 2026

1668
01:37:12,635 --> 01:37:16,425
Speaker 1:  Webby award-winning podcast within a podcast. Brenda Carr is a dummy

1669
01:37:16,615 --> 01:37:19,145
Speaker 1:  neli. How does this keep happening? What happened this week? It

1670
01:37:19,145 --> 01:37:22,465
Speaker 3:  Does keep happening. I will say it's getting dumb on a meta level, right?

1671
01:37:22,465 --> 01:37:25,985
Speaker 3:  Where like, it's, it's just so dumb that

1672
01:37:26,415 --> 01:37:28,625
Speaker 3:  like the ecosystem is getting dumb.

1673
01:37:30,485 --> 01:37:33,665
Speaker 3:  So this week on Brendan Cars a dummy, we don't have a lot of Brendan stuff

1674
01:37:33,735 --> 01:37:35,185
Speaker 3:  himself, which is

1675
01:37:35,465 --> 01:37:38,585
Speaker 1:  Fascinating. Oh, I see. We're talking like Brendan dumb ripple effects,

1676
01:37:38,895 --> 01:37:42,385
Speaker 3:  Like extremely stupid ripple effects of Brendan's behavior

1677
01:37:43,045 --> 01:37:46,785
Speaker 3:  are causing other people to have to be like just

1678
01:37:47,505 --> 01:37:48,345
Speaker 3:  monumentally stupid.

1679
01:37:48,575 --> 01:37:48,865
Speaker 1:  Okay.

1680
01:37:49,725 --> 01:37:51,145
Speaker 3:  In order to keep up with him,

1681
01:37:51,645 --> 01:37:54,345
Speaker 1:  The new name of this segment is Brendan Carr made us All Dummies.

1682
01:37:54,905 --> 01:37:58,885
Speaker 3:  That's where we're going. Or they have to react to him in ways that are like,

1683
01:37:58,995 --> 01:38:02,845
Speaker 3:  like just plainly no normal human being should react to, right? No,

1684
01:38:02,905 --> 01:38:06,165
Speaker 3:  no one should have to behave this way. So I have three this week. The first

1685
01:38:06,425 --> 01:38:10,385
Speaker 3:  is by far my favorite, like by far one

1686
01:38:10,385 --> 01:38:14,145
Speaker 3:  of the best emails we have ever gotten here at The Verge, right up there

1687
01:38:14,215 --> 01:38:18,025
Speaker 3:  with the conspiracy theories I used to get about Steve

1688
01:38:18,025 --> 01:38:21,185
Speaker 3:  Jobs stealing technology, and then they would all end with, he then died.

1689
01:38:21,765 --> 01:38:24,265
Speaker 3:  If you're an old school VERGE House listener, you know, but like I used to

1690
01:38:24,265 --> 01:38:27,945
Speaker 3:  like do dramatic readings of this, of, he then died on like the End GAT podcast

1691
01:38:28,155 --> 01:38:31,465
Speaker 3:  right up there with the Foxconn emails where the guy would end them all with

1692
01:38:31,465 --> 01:38:34,585
Speaker 3:  Leave Us alone when I, we'd ride up at the Fox on Factory not being there.

1693
01:38:34,585 --> 01:38:38,505
Speaker 3:  Yeah, right up here only instead of being a weird anonymous poet,

1694
01:38:39,175 --> 01:38:43,105
Speaker 3:  this is TI Network's communications people. So if

1695
01:38:43,105 --> 01:38:46,625
Speaker 3:  you were call Brendan in the first Trump administration,

1696
01:38:47,935 --> 01:38:51,785
Speaker 3:  Ajit Pie and the Trump administration broadly inked a

1697
01:38:51,785 --> 01:38:55,225
Speaker 3:  deal in which T-Mobile was allowed to buy Sprint, which reduced the number

1698
01:38:55,225 --> 01:38:59,025
Speaker 3:  of National Wireless competitors from three to four. And to solve this

1699
01:38:59,055 --> 01:39:02,465
Speaker 3:  very obvious problem where reducing competition raises prices, they gave

1700
01:39:02,505 --> 01:39:05,985
Speaker 3:  a bunch of spectrum to Dish Network, which had no network, which made promises

1701
01:39:06,095 --> 01:39:09,665
Speaker 3:  that it would stand up a nationwide wireless network, become the fourth carrier,

1702
01:39:10,125 --> 01:39:13,945
Speaker 3:  and send shockwaves through the market. And look around,

1703
01:39:14,315 --> 01:39:18,105
Speaker 3:  right? The, this mark that it does not exist. The, it's been years, right?

1704
01:39:18,105 --> 01:39:21,025
Speaker 3:  That was the first Trump administration. It's been years. No one is using

1705
01:39:21,025 --> 01:39:24,705
Speaker 3:  this network. They, they had a, a stat that they, like 1.3 million people

1706
01:39:24,705 --> 01:39:27,825
Speaker 3:  have access to this network. There are 300 plus million people in America.

1707
01:39:28,685 --> 01:39:31,385
Speaker 3:  No one, no one is on this network. They do operate, yeah, boost Mobile, which

1708
01:39:31,385 --> 01:39:34,265
Speaker 3:  is a prepaid network. That's a big network. A lot of people use it, but the

1709
01:39:34,425 --> 01:39:37,465
Speaker 3:  majority of people who are Boost customers are actually sort of like using

1710
01:39:37,525 --> 01:39:40,745
Speaker 3:  at t and T-Mobile's networks. They're just like roaming onto it. This is

1711
01:39:40,745 --> 01:39:44,505
Speaker 3:  a big problem. Anyhow, SpaceX decided they would take it upon

1712
01:39:44,505 --> 01:39:48,305
Speaker 3:  itself to study whether or not Dish Network existed,

1713
01:39:48,975 --> 01:39:52,265
Speaker 3:  that they noticed it, didn't they? And they just asked for the spectrum.

1714
01:39:52,525 --> 01:39:56,345
Speaker 3:  And Brendan responded in his corrupt, sort of lackadaisical fashion by saying,

1715
01:39:56,345 --> 01:39:58,945
Speaker 3:  I have an opening investigation. I'm gonna give this spectrum to SpaceX.

1716
01:39:59,575 --> 01:40:02,745
Speaker 3:  Dish Network has responded to this. They have

1717
01:40:03,465 --> 01:40:06,705
Speaker 3:  threatened to declare bankruptcy to preserve their spectrum through the bankruptcy

1718
01:40:06,705 --> 01:40:10,385
Speaker 3:  proceeding. 'cause that's their big asset. This would prevent, right? They're,

1719
01:40:10,385 --> 01:40:12,825
Speaker 3:  they're, they're playing a smarter political game than Brendan, who again

1720
01:40:12,825 --> 01:40:16,225
Speaker 3:  is an idiot. Anyhow, we got this email because we've even covering this,

1721
01:40:16,305 --> 01:40:19,585
Speaker 3:  I keep pointing out that Brendan created this problem through his own corruption

1722
01:40:20,445 --> 01:40:23,385
Speaker 3:  out of a solution that the previous Trump administration, his former Boss

1723
01:40:23,865 --> 01:40:27,785
Speaker 3:  Pi created for him. He's an idiot. This is how it goes. Here's the

1724
01:40:27,785 --> 01:40:31,425
Speaker 3:  email that we got from EchoStar, which ends Dish Network and Boost Mobile.

1725
01:40:32,085 --> 01:40:35,625
Speaker 3:  Hi folks. Given the vers continuing coverage of Echo Star's interaction with

1726
01:40:35,625 --> 01:40:38,465
Speaker 3:  the FCC and Chairman Carr, I wanted to share the blow with you as we lay

1727
01:40:38,465 --> 01:40:42,105
Speaker 3:  out in our filings with the FCC, our network in fact exists.

1728
01:40:43,285 --> 01:40:45,265
Speaker 3:  My T-shirt, it says my network exists

1729
01:40:48,575 --> 01:40:52,225
Speaker 3:  like just a top 10. It's tough. It's just like, it's, it's incredible. And

1730
01:40:52,225 --> 01:40:55,885
Speaker 3:  it goes on to say we offer a high quality 5G service to 80% of the US population

1731
01:40:55,905 --> 01:40:59,365
Speaker 3:  on our own network, which I, and that network has won coverage and

1732
01:40:59,365 --> 01:41:02,805
Speaker 3:  reliability recognition across the country. That's for Boost. We've come

1733
01:41:02,805 --> 01:41:05,245
Speaker 3:  a long way in four years when other carriers have had decades to build a

1734
01:41:05,245 --> 01:41:09,215
Speaker 3:  network. The two questions I have is why are people still being issued at

1735
01:41:09,455 --> 01:41:11,855
Speaker 3:  t and T-Mobile SIM cards? And I sign up for Boost, which is a real thing

1736
01:41:11,855 --> 01:41:15,455
Speaker 3:  you can see people talking about and where is it? Where's the

1737
01:41:15,815 --> 01:41:19,175
Speaker 3:  advertising? Where's the customer acquisition? Where is this network

1738
01:41:21,445 --> 01:41:24,735
Speaker 3:  that you are totally exists? Yeah, send me a phone.

1739
01:41:25,605 --> 01:41:29,255
Speaker 3:  Send me a phone that runs on Project Gen five sis that runs

1740
01:41:29,295 --> 01:41:33,225
Speaker 3:  natively on your network and doesn't run to at and t in

1741
01:41:33,225 --> 01:41:36,785
Speaker 3:  New York. I live in New York City. If you're gonna stand up a network for

1742
01:41:36,785 --> 01:41:40,705
Speaker 3:  80% of the population, presumably I can get

1743
01:41:40,705 --> 01:41:41,985
Speaker 3:  service in New York City, right?

1744
01:41:43,965 --> 01:41:46,855
Speaker 3:  Just, I'm just saying our network can fax this. So that's one my easily.

1745
01:41:46,915 --> 01:41:50,735
Speaker 3:  And this is what I mean, he's just made everyone else have to have to be

1746
01:41:50,735 --> 01:41:54,655
Speaker 3:  stupid. Send me the phone. We're wide open to it. I sent 'em an email

1747
01:41:54,655 --> 01:41:57,415
Speaker 3:  back, said I had a lot of questions, but I was traveling and they, they were

1748
01:41:57,415 --> 01:42:01,295
Speaker 3:  just like, safe travels. No scheduling. So a follow up.

1749
01:42:01,295 --> 01:42:04,575
Speaker 3:  Alright, second one. We've talked about the other commissioner on the FCC

1750
01:42:04,575 --> 01:42:08,095
Speaker 3:  right now, Anna Gomez a lot. All of the other commissioners are gone. They

1751
01:42:08,095 --> 01:42:11,975
Speaker 3:  all quit. The other democrat, Jeffrey Starks quit. The other Republican Nathan

1752
01:42:11,975 --> 01:42:15,895
Speaker 3:  Simington quit. No one knows who's gonna get nominated to replace him. Trump

1753
01:42:15,895 --> 01:42:19,735
Speaker 3:  has nominated no Democrats to anything. FCC is supposed to have a quorum

1754
01:42:19,735 --> 01:42:23,175
Speaker 3:  of three, but they're actually five three from the incumbent party, two from

1755
01:42:23,175 --> 01:42:26,695
Speaker 3:  the opposing party. They right now they got Anna Gomez.

1756
01:42:26,885 --> 01:42:30,525
Speaker 3:  Yeah, Brendan. So we actually interviewed and

1757
01:42:30,585 --> 01:42:34,285
Speaker 3:  Anna's on tour just talking about what a, a monster Brendan is. Like,

1758
01:42:34,285 --> 01:42:36,205
Speaker 3:  literally, she's like on a first night tour. We talked about this a lot.

1759
01:42:36,545 --> 01:42:40,445
Speaker 3:  She did an interview with Lauren Finer at one of the stops on, on on this

1760
01:42:40,445 --> 01:42:43,045
Speaker 3:  tour. Lauren talked to her And I just wanna say, this is just like one of

1761
01:42:43,045 --> 01:42:46,825
Speaker 3:  the funniest Brendan, far a dummy quotes we have.

1762
01:42:47,875 --> 01:42:51,335
Speaker 3:  She just said to Lauren Finer, actually, I have a good working relationship

1763
01:42:51,335 --> 01:42:55,135
Speaker 3:  with Carr. It is what it is. He knows that I need to speak out and we have

1764
01:42:55,135 --> 01:42:57,455
Speaker 3:  a relationship where I can tell him my concerns. And Lauren said, do you

1765
01:42:57,455 --> 01:42:59,415
Speaker 3:  know why Trump hasn't fired you? And she just said, no,

1766
01:43:01,515 --> 01:43:04,215
Speaker 3:  no. Can you imagine Brendan's like, here's this person

1767
01:43:05,345 --> 01:43:09,335
Speaker 3:  who's just touring the country saying that I

1768
01:43:09,365 --> 01:43:12,935
Speaker 3:  suck and that I'm a threat to American free speech. And

1769
01:43:13,485 --> 01:43:17,095
Speaker 3:  yeah. Yeah. I, I accept her concerns also. I have no idea why my boss hasn't

1770
01:43:17,095 --> 01:43:20,775
Speaker 3:  fired her, but if she goes, the FCC is functionally

1771
01:43:20,775 --> 01:43:21,575
Speaker 3:  useless. I

1772
01:43:21,575 --> 01:43:24,495
Speaker 1:  Love the idea of having like a weekly one-on-one with your boss where you're

1773
01:43:24,495 --> 01:43:27,695
Speaker 1:  like, here are all the new reasons. I believe you're a danger to democracy.

1774
01:43:28,395 --> 01:43:31,775
Speaker 1:  And they're just like, Hmm, this is your meeting. You, you, you tell me what

1775
01:43:31,775 --> 01:43:32,375
Speaker 1:  you wanna talk about.

1776
01:43:32,765 --> 01:43:34,015
Speaker 3:  What are the blockers? Do you think this

1777
01:43:34,015 --> 01:43:34,735
Speaker 1:  Is your time? Yeah,

1778
01:43:34,735 --> 01:43:38,055
Speaker 3:  Exactly. It's very good. It's very good. So that's the second one. You should

1779
01:43:38,055 --> 01:43:40,695
Speaker 3:  read that piece by Lauren. It's very good. It's a good interview. I've been

1780
01:43:40,695 --> 01:43:43,615
Speaker 3:  trying to get Anna to come on one or more of our shows. We'll keep working

1781
01:43:43,615 --> 01:43:47,495
Speaker 3:  on it. Okay, then last one Brendan tweeted, he, this is a Brendan one,

1782
01:43:47,515 --> 01:43:51,055
Speaker 3:  but it downstream of Brendan's the dc As you know, Brendan loves giving a

1783
01:43:51,245 --> 01:43:54,245
Speaker 3:  spectrum. So Brenda Tree this week, president Trump locked in another great

1784
01:43:54,245 --> 01:43:57,965
Speaker 3:  win for this country. Freeing up spectrum is key to America's economic prosperity,

1785
01:43:58,165 --> 01:44:01,845
Speaker 3:  national security, blah, blah, blah, blah. And really this is about a Trump

1786
01:44:01,845 --> 01:44:05,125
Speaker 3:  post where he says, Trump is congratulating Ted Cruz and Roger Wicker and

1787
01:44:05,125 --> 01:44:08,565
Speaker 3:  Tom Cotton for their quote, amazing deal on spectrum. And he says, this is

1788
01:44:08,565 --> 01:44:12,245
Speaker 3:  serious power for American leadership on six G

1789
01:44:12,245 --> 01:44:12,565
Speaker 3:  David.

1790
01:44:13,305 --> 01:44:13,765
Speaker 1:  Oh God,

1791
01:44:14,515 --> 01:44:17,165
Speaker 2:  It's time. We've made it.

1792
01:44:17,745 --> 01:44:21,485
Speaker 3:  So as part of the big beautiful Bill, there's some compromise where Ted

1793
01:44:21,515 --> 01:44:24,765
Speaker 3:  Cruz has been mad at the Pentagon for hoarding spectrum for years and years

1794
01:44:24,765 --> 01:44:26,485
Speaker 3:  and years. Everything about this

1795
01:44:26,865 --> 01:44:27,485
Speaker 1:  So new.

1796
01:44:27,995 --> 01:44:31,485
Speaker 3:  It's true. This is, I'm I'm not wrong about this. So it's part of this bill,

1797
01:44:31,485 --> 01:44:35,045
Speaker 3:  the big beautiful bill, which is not passed. Ted Cruz has agreed that the

1798
01:44:35,045 --> 01:44:38,685
Speaker 3:  defense department can keep part of the three gigahertz band and then like

1799
01:44:38,705 --> 01:44:42,245
Speaker 3:  the in the middle from 7.4 to 8.4 gigahertz band. And the rest

1800
01:44:42,505 --> 01:44:45,245
Speaker 3:  can go into what's called the spectrum pipeline. It auctioned for new five

1801
01:44:45,265 --> 01:44:49,145
Speaker 3:  and six G services. This bill has not passed. It may not

1802
01:44:49,145 --> 01:44:49,345
Speaker 3:  pass.

1803
01:44:50,965 --> 01:44:53,985
Speaker 3:  Six G doesn't exist just to be a hundred percent clear. Correct? Correct.

1804
01:44:53,985 --> 01:44:57,625
Speaker 3:  Yeah. FI 5G came to nothing. And in other parts of the governance, it, it

1805
01:44:57,625 --> 01:45:01,305
Speaker 3:  seems relatively clear that at any moment RFK will will tell you that 5G

1806
01:45:01,305 --> 01:45:02,505
Speaker 3:  less you see through time or something.

1807
01:45:02,925 --> 01:45:06,505
Speaker 1:  Oh yeah. Bill Gates did 5G to you when COVID happened. I think

1808
01:45:06,655 --> 01:45:07,705
Speaker 1:  that is what that was.

1809
01:45:08,325 --> 01:45:12,065
Speaker 3:  So anyway, so Brandon is congratulating Trump on congratulating Ted Cruz

1810
01:45:12,565 --> 01:45:16,345
Speaker 3:  on a spectrum plan that is nowhere near reality. But this will

1811
01:45:16,505 --> 01:45:20,185
Speaker 3:  preserve American leadership in six G. We're doing great. Everybody,

1812
01:45:20,505 --> 01:45:23,745
Speaker 1:  Everyone should be so embarrassed who had to be involved in that in any way.

1813
01:45:24,215 --> 01:45:27,905
Speaker 3:  It's, and and that to some extent, that's just normal politicking, right?

1814
01:45:27,935 --> 01:45:31,825
Speaker 3:  Like we're all congratulating ourselves, but it's like Brendan

1815
01:45:32,045 --> 01:45:35,545
Speaker 3:  man, like read the room. Like everyone thinks 5G sucked. Yeah.

1816
01:45:37,285 --> 01:45:39,945
Speaker 3:  All right. We need a pallet cleanser. This pallet cleanser is ridiculous.

1817
01:45:40,085 --> 01:45:41,705
Speaker 3:  Why is this here is zip pound cleanser.

1818
01:45:41,725 --> 01:45:45,465
Speaker 1:  I'm so excited about this because the, what, what brings The Vergecast

1819
01:45:45,575 --> 01:45:48,665
Speaker 1:  more joy than making fun of David Zla and his stupid decisions.

1820
01:45:49,335 --> 01:45:52,385
Speaker 2:  This this we're making fun of Brendan. This is the definition of business

1821
01:45:52,385 --> 01:45:54,025
Speaker 2:  success. What is happening here?

1822
01:45:55,655 --> 01:45:58,065
Speaker 1:  Jake, do you wanna, do you wanna explain what happened here? Walk us through

1823
01:45:58,065 --> 01:45:58,305
Speaker 1:  it. Well,

1824
01:45:58,845 --> 01:46:02,745
Speaker 2:  Warner Bros discovery, which correct me if I have

1825
01:46:02,745 --> 01:46:06,705
Speaker 2:  this wrong, was created by the merger of Warner Media.

1826
01:46:06,845 --> 01:46:10,505
Speaker 2:  And discovery is now and again, that was very

1827
01:46:10,745 --> 01:46:13,745
Speaker 2:  recently, what, two, three years ago. Like so recently they have now announced

1828
01:46:13,745 --> 01:46:16,425
Speaker 2:  plans to split themselves in half into two companies.

1829
01:46:18,165 --> 01:46:21,225
Speaker 2:  And I'm trying to figure out exactly what this, this is, this looks like,

1830
01:46:21,325 --> 01:46:25,305
Speaker 2:  but again, tell me if I have this wrong. It looks roughly like one

1831
01:46:25,305 --> 01:46:28,745
Speaker 2:  half is gonna be studios. Let's call this roughly

1832
01:46:28,925 --> 01:46:32,745
Speaker 2:  Warner Bros. And another is gonna have a bunch of television

1833
01:46:32,745 --> 01:46:36,665
Speaker 2:  networks, which I don't know, seems a little discovery ish to me.

1834
01:46:36,935 --> 01:46:37,425
Speaker 2:  They're

1835
01:46:37,815 --> 01:46:38,785
Speaker 1:  Name these companies

1836
01:46:39,455 --> 01:46:43,385
Speaker 2:  Warn are they not just splitting themselves back up into roughly the original

1837
01:46:43,705 --> 01:46:45,865
Speaker 2:  companies, but now one has a boatload of debt?

1838
01:46:46,735 --> 01:46:50,605
Speaker 3:  Yeah. That's that's the move, that's what you do. This is, this is

1839
01:46:50,605 --> 01:46:53,245
Speaker 3:  what Comcast is doing with NT Outrageous.

1840
01:46:53,315 --> 01:46:54,165
Speaker 2:  This is insane.

1841
01:46:54,675 --> 01:46:57,845
Speaker 1:  It's really, honestly, it's, it's pretty incredible. And meanwhile,

1842
01:46:58,555 --> 01:47:02,445
Speaker 1:  basically what has happened is nothing and David Zaslav got

1843
01:47:02,445 --> 01:47:05,205
Speaker 1:  a hundred million dollars. Hmm. Like that, that's essentially what we've

1844
01:47:05,205 --> 01:47:08,885
Speaker 1:  accomplished in the last couple of years with these two companies is,

1845
01:47:09,065 --> 01:47:12,445
Speaker 1:  is we are right back where we started except David Soff made a hundred million

1846
01:47:12,445 --> 01:47:12,765
Speaker 1:  dollars

1847
01:47:13,225 --> 01:47:15,765
Speaker 2:  And we got to rebrand HBO Max like

1848
01:47:15,765 --> 01:47:16,205
Speaker 1:  Five times.

1849
01:47:17,245 --> 01:47:20,885
Speaker 3:  So here's the Zoff memo to the company announcing the separation.

1850
01:47:21,255 --> 01:47:23,765
Speaker 3:  While the work, since the merger has been challenging at times,

1851
01:47:26,025 --> 01:47:26,405
Speaker 3:  the work

1852
01:47:26,525 --> 01:47:30,005
Speaker 5:  Being rebranding one service over and over again,

1853
01:47:30,235 --> 01:47:31,365
Speaker 5:  they've done else

1854
01:47:31,435 --> 01:47:32,725
Speaker 1:  Done a very bad job ever

1855
01:47:32,725 --> 01:47:35,725
Speaker 3:  Since. No, there's been a lot of investor presentations that where David

1856
01:47:36,025 --> 01:47:39,125
Speaker 3:  Zla was like, the pink stuff is what chicks like this is real by the way.

1857
01:47:39,125 --> 01:47:43,085
Speaker 3:  Oh yeah. We, we, that deck exists. We've talked about it anyway. While the

1858
01:47:43,085 --> 01:47:45,845
Speaker 3:  works inside merger has been challenging at times ultimately have succeeded

1859
01:47:45,845 --> 01:47:49,125
Speaker 3:  in strengthening each element of our business by bringing together the Discovery

1860
01:47:49,185 --> 01:47:52,805
Speaker 3:  and Turner Networks. We've created a leader in live and unscripted television

1861
01:47:52,955 --> 01:47:56,725
Speaker 3:  with a truly global footprint operating industry leading margins. We've transformed

1862
01:47:56,745 --> 01:47:59,405
Speaker 3:  our direct to consumer offering as HBO Max is one of the few world's, few

1863
01:47:59,405 --> 01:48:02,845
Speaker 3:  global and meaningfully profitable streaming services. And then by fusing

1864
01:48:03,045 --> 01:48:06,845
Speaker 3:  creative brilliance with operational excellence, we've made strong progress

1865
01:48:07,275 --> 01:48:10,885
Speaker 3:  returning our film and television studios to industry leadership. I don't

1866
01:48:10,885 --> 01:48:12,245
Speaker 3:  believe that one at all actually.

1867
01:48:13,685 --> 01:48:15,645
Speaker 1:  I don't really think any of those are true.

1868
01:48:16,105 --> 01:48:20,005
Speaker 3:  It, I So Jake TI think the answer is they combined all the

1869
01:48:20,005 --> 01:48:23,605
Speaker 3:  stuff, they remixed it into dying cable

1870
01:48:23,605 --> 01:48:27,525
Speaker 3:  company with debt and new look streaming company. So it's

1871
01:48:27,525 --> 01:48:31,285
Speaker 3:  not quite Warner Bros in Discovery. It's like the worst parts of

1872
01:48:31,285 --> 01:48:35,095
Speaker 3:  both go over here and then maybe the future is over here.

1873
01:48:35,245 --> 01:48:35,535
Speaker 3:  Yeah,

1874
01:48:35,575 --> 01:48:39,455
Speaker 1:  I mean ironically what, what the streaming company

1875
01:48:39,645 --> 01:48:43,175
Speaker 1:  gets is also all of the content. So it's like

1876
01:48:43,475 --> 01:48:46,735
Speaker 1:  all of the things that have a chance are gonna be over here and all of the

1877
01:48:46,735 --> 01:48:50,135
Speaker 1:  things that our cable networks are gonna go over, I mean it's

1878
01:48:50,565 --> 01:48:54,455
Speaker 1:  it's bleak what's going in that second company. And that thing is basically

1879
01:48:54,455 --> 01:48:58,055
Speaker 1:  just being set up to fairly rapidly die on top of

1880
01:48:58,335 --> 01:49:02,215
Speaker 1:  a giant pile of debt while the other one just gets to go and try

1881
01:49:02,215 --> 01:49:05,935
Speaker 1:  to turn HBO max into Netflix. Like

1882
01:49:06,315 --> 01:49:08,815
Speaker 1:  that's what, that's what this is. They're trying to streamline the thing

1883
01:49:08,815 --> 01:49:12,695
Speaker 1:  so the one company can try to go be Netflix and so far

1884
01:49:13,175 --> 01:49:15,855
Speaker 1:  everyone who has tried to be Netflix, which is many, many, many companies

1885
01:49:16,595 --> 01:49:20,015
Speaker 1:  had failed fairly spectacularly at trying to be Netflix. Except Netflix,

1886
01:49:20,305 --> 01:49:21,495
Speaker 1:  which is doing a very good job.

1887
01:49:21,805 --> 01:49:25,495
Speaker 3:  Yeah. And Netflix is the pure play. Everyone else has tried to do it by

1888
01:49:25,495 --> 01:49:29,175
Speaker 3:  bootstrapping the, the excess margin of the dying cable business into the

1889
01:49:29,175 --> 01:49:32,655
Speaker 3:  content to make Netflix. And that's where they've all failed. And now as

1890
01:49:32,655 --> 01:49:35,455
Speaker 3:  David has pointed out, the cable business are dying all getting rid of them.

1891
01:49:35,455 --> 01:49:39,415
Speaker 3:  So Comcast disclosure, NBC Universal part of Comcast

1892
01:49:40,455 --> 01:49:43,215
Speaker 3:  investor in our parent company, Vox Media, but they don't like us for reasons

1893
01:49:43,215 --> 01:49:47,175
Speaker 3:  that will be instantly made clear. As I continue speaking, Comcast is spinning

1894
01:49:47,245 --> 01:49:51,005
Speaker 3:  off all of its dying cable companies into a new company called Versent

1895
01:49:51,185 --> 01:49:54,885
Speaker 3:  so they can die or get reborn in any way and they're gonna hold on to

1896
01:49:54,885 --> 01:49:56,605
Speaker 3:  Peacock and all the streaming stuff in the Olympics.

1897
01:49:58,115 --> 01:49:59,525
Speaker 3:  This is I think the same move.

1898
01:49:59,875 --> 01:50:01,845
Speaker 1:  Yeah, I think this is, this is exactly the same.

1899
01:50:02,235 --> 01:50:05,365
Speaker 3:  It's it's the same move I I have heard because

1900
01:50:06,165 --> 01:50:10,135
Speaker 3:  CNBC is part of the new version thing. There's some excitement,

1901
01:50:10,995 --> 01:50:14,765
Speaker 3:  lots of trepidation, some excitement that they'll be free

1902
01:50:14,785 --> 01:50:18,045
Speaker 3:  of the machine and they can try new things in a way that being part of the

1903
01:50:18,045 --> 01:50:19,885
Speaker 3:  machine would not let them in the past.

1904
01:50:21,405 --> 01:50:25,245
Speaker 3:  I don't know if anybody at Discovery Turner feels is gonna

1905
01:50:25,245 --> 01:50:26,045
Speaker 3:  feel that way.

1906
01:50:26,945 --> 01:50:29,805
Speaker 1:  No, it's just a really interesting moment. I mean the other, the other streaming

1907
01:50:29,805 --> 01:50:33,245
Speaker 1:  thing that happened this week was Disney finally finished the deal to buy

1908
01:50:33,245 --> 01:50:37,165
Speaker 1:  the rest of Hulu and there is now some noise

1909
01:50:37,235 --> 01:50:40,565
Speaker 1:  that the end of Hulu is kind of n right? Like

1910
01:50:41,025 --> 01:50:44,925
Speaker 1:  all of this stuff is just gonna be roped into Disney plus ESPN

1911
01:50:44,925 --> 01:50:48,525
Speaker 1:  is doing its flagship thing that's gonna start to be piped further and further

1912
01:50:48,525 --> 01:50:52,365
Speaker 1:  into Disney Plus. Like the, we're sort of back in a

1913
01:50:52,365 --> 01:50:55,125
Speaker 1:  bundling phase of some of this stuff in a really interesting way that like

1914
01:50:55,765 --> 01:50:59,525
Speaker 1:  HBO Max is trying to be Netflix and Disney is trying to be

1915
01:50:59,525 --> 01:51:03,205
Speaker 1:  Netflix and everybody is, is pulling everything they

1916
01:51:03,405 --> 01:51:07,085
Speaker 1:  possibly can into these like mega streaming services, offloading

1917
01:51:07,085 --> 01:51:10,565
Speaker 1:  everything that isn't those things. Because like you said, they thought there

1918
01:51:10,565 --> 01:51:13,525
Speaker 1:  was gonna be money in those for a long time and there is, there is no longer

1919
01:51:13,525 --> 01:51:17,125
Speaker 1:  money in those and just the only path forward

1920
01:51:17,505 --> 01:51:20,845
Speaker 1:  is to try and be Netflix and boy does that look like suicide right now

1921
01:51:21,385 --> 01:51:22,525
Speaker 1:  for all of these companies.

1922
01:51:22,795 --> 01:51:26,045
Speaker 3:  This pallet cleanser sucks. I'm I'm doing a another one. Can

1923
01:51:26,045 --> 01:51:26,805
Speaker 1:  I give you a better one?

1924
01:51:27,435 --> 01:51:28,645
Speaker 3:  Okay. You do one and I'll do one.

1925
01:51:28,785 --> 01:51:31,085
Speaker 1:  All right. You No, you do yours 'cause we gotta go. What's

1926
01:51:31,085 --> 01:51:32,805
Speaker 3:  Yours? I I kind of wanna see if we had the same one.

1927
01:51:34,055 --> 01:51:34,435
Speaker 1:  You go.

1928
01:51:35,075 --> 01:51:38,735
Speaker 3:  All right, mine is that PNY just announced the dual link V three flash

1929
01:51:38,745 --> 01:51:42,455
Speaker 3:  drive, which has both USBA and USPC connectors

1930
01:51:42,675 --> 01:51:46,535
Speaker 3:  but supports USB 3.2 gen two that enables read speeds of up to

1931
01:51:46,735 --> 01:51:50,375
Speaker 3:  a thousand megabits per second and right speeds of up to 800 megabits per

1932
01:51:50,375 --> 01:51:53,615
Speaker 3:  second. It's 32 99 for 2 56 6 at

1933
01:51:53,615 --> 01:51:57,495
Speaker 3:  32 99 for 2 56. But it's is the fastest flash drive that

1934
01:51:57,495 --> 01:51:58,495
Speaker 3:  exists. So you can

1935
01:51:58,495 --> 01:52:00,295
Speaker 1:  Fill your flash drive in two seconds.

1936
01:52:00,955 --> 01:52:04,815
Speaker 3:  I'm just, that's a pallet cleanser, baby sick flash

1937
01:52:04,815 --> 01:52:07,975
Speaker 3:  drive. That's a pallet cleanser. What was yours?

1938
01:52:08,555 --> 01:52:09,895
Speaker 1:  Do people still use flash drives?

1939
01:52:10,405 --> 01:52:13,615
Speaker 2:  Have you ever tried to print something outta the office? Hmm.

1940
01:52:14,365 --> 01:52:15,055
Speaker 2:  Okay, now

1941
01:52:15,115 --> 01:52:15,575
Speaker 1:  That's fair.

1942
01:52:16,015 --> 01:52:19,215
Speaker 2:  USBC into my laptop USBA into the printer.

1943
01:52:19,795 --> 01:52:22,495
Speaker 2:  Hey, boom. Done. I'm expensing this.

1944
01:52:22,715 --> 01:52:26,495
Speaker 3:  Oh yeah. How do you think I get these images onto the frame tv? Ancient flash

1945
01:52:26,495 --> 01:52:26,695
Speaker 3:  drives,

1946
01:52:26,875 --> 01:52:29,015
Speaker 1:  Man, that story sucks for both of you. Yeah, I

1947
01:52:29,245 --> 01:52:30,655
Speaker 3:  What was yours? I

1948
01:52:30,655 --> 01:52:33,855
Speaker 1:  Just wanted to talk about Thread's dms for like two seconds. Alright, because

1949
01:52:33,855 --> 01:52:34,095
Speaker 1:  I think

1950
01:52:36,015 --> 01:52:39,695
Speaker 1:  I Threads, which I have spent a lot of time talking about, it's very slow

1951
01:52:39,695 --> 01:52:42,295
Speaker 1:  product development. They announced this week that they're starting to roll

1952
01:52:42,295 --> 01:52:45,965
Speaker 1:  out a DM inbox that is actually separate from Instagram. Yeah,

1953
01:52:46,225 --> 01:52:50,045
Speaker 1:  that's good. A lot of people not excited about that who are like, oh cool,

1954
01:52:50,065 --> 01:52:53,205
Speaker 1:  you know what Meta Needs is another messaging app. And I that's fair

1955
01:52:53,945 --> 01:52:57,325
Speaker 1:  and Meta now has thousands of messaging apps that none of which talk to each

1956
01:52:57,325 --> 01:53:00,845
Speaker 1:  other. But I also think a Threads DM thing is a good idea

1957
01:53:01,625 --> 01:53:04,645
Speaker 1:  and that like, it's, it's threads is gonna end up being one of those accounts

1958
01:53:04,645 --> 01:53:08,565
Speaker 1:  that like everybody has but nobody really pays attention to.

1959
01:53:08,625 --> 01:53:12,245
Speaker 1:  And I think like as Twitter continues to fall apart, one thing I miss is

1960
01:53:12,265 --> 01:53:16,045
Speaker 1:  the like relatively accessible messaging system to reach almost

1961
01:53:16,045 --> 01:53:19,205
Speaker 1:  anybody. And Threads I think is gonna turn into that.

1962
01:53:19,765 --> 01:53:20,465
Speaker 1:  That's my theory.

1963
01:53:21,645 --> 01:53:21,885
Speaker 3:  Interesting

1964
01:53:22,075 --> 01:53:25,885
Speaker 1:  That it's, it's just gonna be an inbox that everybody kind of has and you

1965
01:53:25,885 --> 01:53:29,845
Speaker 1:  check sometimes and it's fine. And like maybe that's only useful to

1966
01:53:29,845 --> 01:53:33,805
Speaker 1:  me as a reporter who like constantly wants to ask people about their stupid

1967
01:53:34,145 --> 01:53:37,885
Speaker 1:  iOS home screens, but I think that's like, it's a good

1968
01:53:37,915 --> 01:53:40,045
Speaker 1:  idea for threads to have dms, I think.

1969
01:53:40,175 --> 01:53:41,085
Speaker 3:  Isn't that LinkedIn?

1970
01:53:41,555 --> 01:53:44,045
Speaker 1:  Yeah, but I don't want it to be, it's, it's like it, yeah. I see what saying

1971
01:53:44,045 --> 01:53:47,485
Speaker 1:  it has been threatening to be LinkedIn in a way that really bums me out because

1972
01:53:47,485 --> 01:53:50,845
Speaker 1:  every time I have to use LinkedIn, it makes me sad and

1973
01:53:51,825 --> 01:53:54,925
Speaker 1:  it like, it used to be Twitter, the like how do I reach out to a stranger?

1974
01:53:54,925 --> 01:53:58,845
Speaker 1:  Twitter was the closest thing we had to that. And I think Threads is

1975
01:53:58,845 --> 01:54:02,085
Speaker 1:  smart to try and take that mantle And I think is going to do it fairly quickly.

1976
01:54:02,515 --> 01:54:02,805
Speaker 1:  Yeah.

1977
01:54:04,145 --> 01:54:07,565
Speaker 3:  All right. It was a fine pal cleanser. I think the the cool USB drive is

1978
01:54:07,565 --> 01:54:10,645
Speaker 3:  better. You let us know, you can email us something, you can call someone

1979
01:54:11,475 --> 01:54:14,725
Speaker 1:  Also if you have a really weird esoteric use for a flash drive that you wanna

1980
01:54:14,725 --> 01:54:17,205
Speaker 1:  tell us about. I very much wanna hear about it. Dead

1981
01:54:17,205 --> 01:54:18,685
Speaker 3:  Serious. What's the number, what's the

1982
01:54:18,685 --> 01:54:19,045
Speaker 6:  Number again?

1983
01:54:19,425 --> 01:54:23,165
Speaker 1:  You can call 8 6 6 version one one. You can email us Vergecast at The Verge

1984
01:54:23,185 --> 01:54:27,005
Speaker 1:  dot com, all kinds of stuff. We, we're gonna do a lot of hotline stuff this

1985
01:54:27,005 --> 01:54:29,205
Speaker 1:  summer, so keep keep questions coming. Yeah.

1986
01:54:29,625 --> 01:54:31,525
Speaker 3:  All right. That's it. That's The Vergecast Rock roll.

1987
01:54:36,785 --> 01:54:40,085
Speaker 6:  And that's it for The Vergecast this week. And hey, we'd love to hear from

1988
01:54:40,085 --> 01:54:43,725
Speaker 6:  you. Give us a call at eight six six VERGE one one.

1989
01:54:43,905 --> 01:54:47,365
Speaker 6:  The Vergecast is a production of The Verge and the Vox Media Podcast network.

1990
01:54:47,705 --> 01:54:51,685
Speaker 6:  Our show is produced by Will Por, Eric Gomez and Brandon Keefer. And that's

1991
01:54:51,685 --> 01:54:52,725
Speaker 6:  it. We'll see you next week.

