1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 529644a5-45d3-46b4-850e-4746c9ba2bf6
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-2344718276481201612/-2971917372811609962/s93290-US-6563s-1730456682.mp3
Description: Nilay and David discuss a big week in AI news, including the new web search features in ChatGPT and the reporting that Meta is working on something very similar. They also briefly talk about this quarter's tech earnings, and what they say about the ways AI is really being used. Then, Wall Street Journal columnist Joanna Stern joins the show to talk about Apple Intelligence, Apple's week of Mac launches, and why Siri still can't open her garage. Finally, in the lightning round, the hosts talk about Netflix's gentle push into social features, Tony Fadell's AI thoughts, and our endorsement of Kamala Harris.

2
00:00:45,375 --> 00:00:47,845
Speaker 3:  Hello and welcome to Vergecast Flagship podcast,

3
00:00:48,915 --> 00:00:52,845
Speaker 3:  searching using artificial intelligence. Welcome to the future.

4
00:00:54,465 --> 00:00:56,045
Speaker 3:  Hi, I'm your friend Neil. I, David Pierce is here.

5
00:00:56,175 --> 00:00:56,525
Speaker 4:  Hello.

6
00:00:57,305 --> 00:01:01,165
Speaker 3:  Joanna Stern is gonna join the show in a little bit. There's a lot of

7
00:01:01,165 --> 00:01:04,485
Speaker 3:  news this week. Search, GPT is here. That's open AI's

8
00:01:04,975 --> 00:01:07,965
Speaker 3:  competitor to Google that's built right into chat. GT, we gotta talk about

9
00:01:07,965 --> 00:01:11,685
Speaker 3:  that. Meta is apparently announcing AI powered search. iOS

10
00:01:11,925 --> 00:01:15,085
Speaker 3:  18.1 with Apple Intelligence arrived

11
00:01:15,835 --> 00:01:17,865
Speaker 3:  with something.

12
00:01:18,725 --> 00:01:21,385
Speaker 4:  It did arrive. We can say that with certainty with

13
00:01:21,385 --> 00:01:24,945
Speaker 3:  A puff of smoke. And then there's just like earnings to talk about. We got

14
00:01:24,945 --> 00:01:27,545
Speaker 3:  a lightning round. I'm very excited about some of the lightning round items.

15
00:01:27,575 --> 00:01:30,185
Speaker 3:  Yeah. Oh, and we should mention Apple also announced a whole bunch of New

16
00:01:30,185 --> 00:01:34,115
Speaker 3:  Macs. Yeah. So we're gonna save a bunch of the Apple conversation for

17
00:01:34,275 --> 00:01:37,595
Speaker 3:  when Joanna joins us. We should start with the news search

18
00:01:37,835 --> 00:01:41,475
Speaker 3:  GPT launching, or I guess search in chat. GPT is how they're framing it.

19
00:01:42,515 --> 00:01:46,325
Speaker 3:  It's funny how much we talked about Google and Google search changing

20
00:01:46,345 --> 00:01:50,285
Speaker 3:  and the web and whether AI would kill Google and, and here it

21
00:01:50,285 --> 00:01:51,565
Speaker 3:  is and it's kinda like, huh?

22
00:01:52,795 --> 00:01:55,765
Speaker 4:  Yeah, I I'm, I'm actually really glad that was your reaction because that

23
00:01:55,765 --> 00:01:58,365
Speaker 4:  was mine too. It's like If, you just imagined

24
00:01:59,595 --> 00:02:03,325
Speaker 4:  what a, I don't know, three quarters baked search product

25
00:02:03,325 --> 00:02:07,125
Speaker 4:  would look like from OpenAI. You would've gotten it almost a hundred

26
00:02:07,125 --> 00:02:10,965
Speaker 4:  percent. Exactly right. And I think two things about this are

27
00:02:10,965 --> 00:02:14,765
Speaker 4:  really interesting to me. One is that a, this is the

28
00:02:14,765 --> 00:02:18,605
Speaker 4:  thing that OpenAI has been signing publisher deals for disclosure,

29
00:02:18,785 --> 00:02:22,765
Speaker 4:  Vox Media, the VIRs parent company signed one of those deals. That's

30
00:02:22,765 --> 00:02:26,525
Speaker 4:  all I know about it. It exists, but they've signed lots of these deals in

31
00:02:26,525 --> 00:02:30,045
Speaker 4:  recent months. They've had this web crawler doing stuff for a long time now

32
00:02:30,165 --> 00:02:32,885
Speaker 4:  that web crawler has been really controversial, like it's all been building

33
00:02:33,225 --> 00:02:37,165
Speaker 4:  to this and in open AI's sort of typical

34
00:02:37,165 --> 00:02:40,245
Speaker 4:  fashion. They don't make a giant deal out of their biggest launches, but

35
00:02:40,245 --> 00:02:43,685
Speaker 4:  like this is a big one for OpenAI. It, it is the thing that gives

36
00:02:44,195 --> 00:02:47,565
Speaker 4:  Chad GBT real time information, which is I would say the single biggest

37
00:02:48,315 --> 00:02:52,205
Speaker 4:  hole it has had so far. I also think it's fascinating that they just

38
00:02:52,205 --> 00:02:55,685
Speaker 4:  built it into chat GPT, like when it first was a thing, it was gonna be,

39
00:02:55,685 --> 00:02:59,525
Speaker 4:  you know, search GPT. And I think OpenAI has struggled to figure

40
00:02:59,665 --> 00:03:03,645
Speaker 4:  out how exactly to package and productize all of this stuff

41
00:03:04,225 --> 00:03:08,125
Speaker 4:  and just shoving it in all inside of the chat bot has turned

42
00:03:08,125 --> 00:03:11,565
Speaker 4:  out to be the answer. Yeah, and I think this thing looks fine. I think

43
00:03:11,785 --> 00:03:15,285
Speaker 4:  OpenAI is making some wild, obviously incorrect claims about it,

44
00:03:16,185 --> 00:03:20,165
Speaker 4:  but the idea of what it is seems pretty straightforward and

45
00:03:20,185 --> 00:03:20,605
Speaker 4:  useful.

46
00:03:21,145 --> 00:03:24,645
Speaker 3:  The shove it all in the chatbot is super interesting, right? Because Google

47
00:03:24,785 --> 00:03:28,725
Speaker 3:  and opening Eye are coming at the same problem from radically

48
00:03:28,725 --> 00:03:32,685
Speaker 3:  different directions. They have kind of the same idea and

49
00:03:32,685 --> 00:03:36,635
Speaker 3:  they're arriving at very different rifts on the

50
00:03:36,635 --> 00:03:40,155
Speaker 3:  same core user interface. Yeah. So Google's right, Google wants to be an

51
00:03:40,155 --> 00:03:42,915
Speaker 3:  answer engine. They've, they've talked about Google search that way for such

52
00:03:42,915 --> 00:03:46,755
Speaker 3:  a long time. So you ask Google a question and 10 blue links and

53
00:03:46,755 --> 00:03:50,715
Speaker 3:  then answer cards and knowledge panels, and now you get AI overview, which

54
00:03:50,715 --> 00:03:53,755
Speaker 3:  are still kind of a mess. But the idea that you, you just ask a question

55
00:03:53,755 --> 00:03:57,555
Speaker 3:  in Google and it delivers you an answer has been the core thesis

56
00:03:57,615 --> 00:03:59,275
Speaker 3:  of Google search for quite some time.

57
00:04:00,875 --> 00:04:04,815
Speaker 3:  And they've, they're getting there, but it's still very structured, right?

58
00:04:04,815 --> 00:04:08,535
Speaker 3:  You are not supposed to chat with Google search, right? But it's still like,

59
00:04:08,635 --> 00:04:11,535
Speaker 3:  ask a freeform question in this text box and Google search will figure it

60
00:04:11,535 --> 00:04:15,375
Speaker 3:  out and deliver you some answer. OpenAI started not with the web,

61
00:04:15,475 --> 00:04:19,065
Speaker 3:  but with just like freeform chat, right? Just like talk to this

62
00:04:19,155 --> 00:04:21,775
Speaker 3:  robot, it might try to bang you. Let's find

63
00:04:21,775 --> 00:04:24,295
Speaker 4:  Out where did this information come from? Who knows,

64
00:04:24,615 --> 00:04:28,535
Speaker 3:  Right? Like here's just some weird stuff and they're adding all of this

65
00:04:28,815 --> 00:04:32,335
Speaker 3:  structured information to it with search now, right? By crawling the web.

66
00:04:32,475 --> 00:04:36,295
Speaker 3:  And so they, it it's, they're just coming at it from two, like two

67
00:04:36,295 --> 00:04:40,135
Speaker 3:  radically different positions and they're, they're closer to

68
00:04:40,135 --> 00:04:41,935
Speaker 3:  each other than I think they want to admit.

69
00:04:42,615 --> 00:04:45,495
Speaker 4:  I, I think that's right. And I think it's because in a lot of ways

70
00:04:46,265 --> 00:04:50,055
Speaker 4:  there just aren't that many answers to this. I will say one of the things

71
00:04:50,325 --> 00:04:54,255
Speaker 4:  that strikes me just looking at even some of these early screenshots

72
00:04:54,255 --> 00:04:58,215
Speaker 4:  of what OpenAI is doing, OpenAI actually appears

73
00:04:58,215 --> 00:05:01,695
Speaker 4:  to be a better citizen of the web than Google

74
00:05:02,355 --> 00:05:06,215
Speaker 4:  in the way that they're implementing the AI search stuff. So like, it, it,

75
00:05:06,215 --> 00:05:09,695
Speaker 4:  we'll, we'll put the link in the show notes to Kylie Robinson's story. She

76
00:05:09,695 --> 00:05:13,135
Speaker 4:  saw it, got a demo of it, talked to the folks who were making it. But let

77
00:05:13,135 --> 00:05:15,975
Speaker 4:  me, let me just describe like this one screenshot in the middle of her story.

78
00:05:16,075 --> 00:05:19,895
Speaker 4:  So on the left side, which is the, the sort of OpenAI chat g

79
00:05:19,895 --> 00:05:23,575
Speaker 4:  PD chat window, this person has typed what are some great ways to fix up

80
00:05:23,615 --> 00:05:27,535
Speaker 4:  a backyard? and it goes out and looks at the web and then comes back.

81
00:05:27,595 --> 00:05:28,135
Speaker 4:  And by

82
00:05:28,135 --> 00:05:29,615
Speaker 3:  The way, totally normal query.

83
00:05:30,205 --> 00:05:31,895
Speaker 4:  Yeah. It's not,

84
00:05:32,435 --> 00:05:35,095
Speaker 3:  That's how everyone talks about fixing up the backyard.

85
00:05:35,695 --> 00:05:36,495
Speaker 4:  Backyard. What do

86
00:05:37,375 --> 00:05:37,695
Speaker 3:  Question mark?

87
00:05:38,645 --> 00:05:39,135
Speaker 4:  Alright,

88
00:05:40,685 --> 00:05:44,655
Speaker 3:  When I think about sitting down on my computer for search, that's exactly

89
00:05:44,755 --> 00:05:45,735
Speaker 3:  how I would phrase it. Yeah,

90
00:05:45,735 --> 00:05:49,135
Speaker 4:  Go ahead then. But so the, the first thing it delivers is a, a thing that

91
00:05:49,135 --> 00:05:52,815
Speaker 4:  appears to be an article from the spruce.com called 54 Backyard

92
00:05:52,815 --> 00:05:56,655
Speaker 4:  Ideas to Upgrade Your Outdoor Space, which a is very funny because that headline

93
00:05:56,655 --> 00:06:00,125
Speaker 4:  is so clearly written for Google. Yeah. That it is

94
00:06:00,415 --> 00:06:04,405
Speaker 4:  borderline nonsense. Yeah. 54 Backyard Ideas doesn't

95
00:06:04,405 --> 00:06:07,125
Speaker 4:  mean anything. But anyway, so

96
00:06:07,235 --> 00:06:10,605
Speaker 3:  It's So I. Just wanna say within the first two lines of this demo,

97
00:06:11,095 --> 00:06:13,405
Speaker 3:  we've just left the English language. Oh yeah,

98
00:06:13,455 --> 00:06:17,405
Speaker 4:  We're gone. This is, yeah, but it has,

99
00:06:17,505 --> 00:06:21,285
Speaker 4:  it, it says the spruce.com on right underneath it, it has the

100
00:06:21,285 --> 00:06:24,805
Speaker 4:  Spruces logo right next to it, the little favicon and then

101
00:06:25,115 --> 00:06:28,965
Speaker 4:  four images underneath it that I assume are pulled from that article. And

102
00:06:28,965 --> 00:06:32,765
Speaker 4:  then basically a, a sort of multi-step summary of some of the stuff

103
00:06:32,905 --> 00:06:36,805
Speaker 4:  in that article. Then off to the right, it has a whole sidebar

104
00:06:36,805 --> 00:06:40,725
Speaker 4:  that says citations. And then here it has five links to a

105
00:06:40,725 --> 00:06:44,685
Speaker 4:  bunch of different websites showing similar stuff.

106
00:06:44,685 --> 00:06:48,085
Speaker 4:  Right. 50 stunning backyard ideas that fit every kind of space. Your DIY

107
00:06:48,085 --> 00:06:51,765
Speaker 4:  guy do a backyard makeover on a budget, like all of this is just Google

108
00:06:51,875 --> 00:06:55,845
Speaker 4:  Ease. It's so funny and it's just being surfaced in these new ways. But

109
00:06:55,845 --> 00:06:59,765
Speaker 4:  like in in, in the guise of being

110
00:06:59,765 --> 00:07:03,605
Speaker 4:  like a publisher who cares about having your stuff surfaced and not

111
00:07:03,605 --> 00:07:07,325
Speaker 4:  just like stolen and repackaged looking like a chat bot,

112
00:07:07,595 --> 00:07:11,445
Speaker 4:  this is actually pretty good. This is just one screenshot and I, I am

113
00:07:11,445 --> 00:07:14,285
Speaker 4:  confident that OpenAI is going to pick the things that make it look good

114
00:07:14,305 --> 00:07:18,005
Speaker 4:  in its marketing, but like, it's not a particularly attractive

115
00:07:18,115 --> 00:07:21,885
Speaker 4:  user interface, but it's pretty honest about the web.

116
00:07:22,435 --> 00:07:25,805
Speaker 3:  Yeah. Again, we dunno anything about our deal. We had Nick Thompson, who

117
00:07:25,805 --> 00:07:29,365
Speaker 3:  is CEO of the Atlantic, the former editor of Wired on

118
00:07:29,435 --> 00:07:32,165
Speaker 3:  Decoder, and he talked about what he wanted out of the Atlantics deal with

119
00:07:32,165 --> 00:07:35,845
Speaker 3:  OpenAI. And a lot of what he talked about was, I want, I want

120
00:07:35,845 --> 00:07:37,965
Speaker 3:  influence over what these results look like.

121
00:07:38,375 --> 00:07:38,725
Speaker 4:  Right?

122
00:07:39,055 --> 00:07:42,805
Speaker 3:  Right. So the, the publisher deals, a lot of, a lot of it is they,

123
00:07:43,615 --> 00:07:46,545
Speaker 3:  they all gave up too much to Google. It was too much for a free for all.

124
00:07:46,545 --> 00:07:49,865
Speaker 3:  They were mad about it. Now they have a licensing deal, they have a contract,

125
00:07:49,865 --> 00:07:53,385
Speaker 3:  presumably they have points of contact and they, there's some back and forth

126
00:07:53,385 --> 00:07:56,945
Speaker 3:  here about what, how to make this best for everyone. And So I think you can

127
00:07:56,945 --> 00:08:00,385
Speaker 3:  see that here. I'll also, just to keep harping on this one example

128
00:08:00,795 --> 00:08:04,785
Speaker 3:  point out that for all this ai, for all these millions

129
00:08:04,785 --> 00:08:08,705
Speaker 3:  of GPUs running nuclear hot, boiling the

130
00:08:08,705 --> 00:08:12,465
Speaker 3:  ocean, the answers the most cutting edge

131
00:08:12,645 --> 00:08:16,505
Speaker 3:  AI in the entire world came up with for what are some great ways to

132
00:08:16,505 --> 00:08:20,305
Speaker 3:  fix up a backyard are create a seating area, incorporate

133
00:08:20,305 --> 00:08:24,285
Speaker 3:  outdoor lighting and add a fire pit. That's what we got.

134
00:08:24,515 --> 00:08:28,405
Speaker 3:  Boom. That's, it's in incredible. So

135
00:08:28,405 --> 00:08:30,365
Speaker 3:  it's chairs, lights, and fireplace.

136
00:08:31,465 --> 00:08:32,565
Speaker 4:  We, we did it everybody.

137
00:08:33,665 --> 00:08:36,885
Speaker 3:  And maybe look, maybe the person doing this demo has never been in a backyard

138
00:08:36,885 --> 00:08:40,765
Speaker 3:  before. I come back to that all the time. That's really where the huh

139
00:08:41,115 --> 00:08:44,735
Speaker 3:  came from for me. Is that, yeah, I mean

140
00:08:45,465 --> 00:08:48,455
Speaker 3:  maybe If, you ask Google this question a few years ago and you got one of

141
00:08:48,455 --> 00:08:52,335
Speaker 3:  these extremely over SEOed articles that are loaded

142
00:08:52,335 --> 00:08:55,685
Speaker 3:  up with affiliate links and not really written for people, and that's a worse

143
00:08:55,735 --> 00:08:59,565
Speaker 3:  experience. And so maybe just presenting these

144
00:08:59,635 --> 00:09:03,525
Speaker 3:  extremely basic ideas in a nicer experience is all the innovation we need.

145
00:09:04,345 --> 00:09:07,325
Speaker 3:  But then you're like, so all we did was we just cleaned up a little bit,

146
00:09:07,745 --> 00:09:11,085
Speaker 3:  we just took out some of the, the hum boxes. Like there's not a belly fat

147
00:09:11,105 --> 00:09:14,925
Speaker 3:  ad in here, right. That took all of the GPUs in the world.

148
00:09:14,985 --> 00:09:18,965
Speaker 3:  Sam Altman is literally traveling the world asking kings

149
00:09:18,965 --> 00:09:22,805
Speaker 3:  and queens for billions of dollars to build chip fabs. So the robot can say

150
00:09:22,805 --> 00:09:24,965
Speaker 3:  incorporate outdoor lighting. That's what we're doing. Okay.

151
00:09:25,525 --> 00:09:29,285
Speaker 4:  A I think the answer is closer to just straightforwardly Yes. Than

152
00:09:29,585 --> 00:09:33,005
Speaker 4:  anyone would like to admit, which we're gonna get to in a minute when we

153
00:09:33,005 --> 00:09:36,965
Speaker 4:  talk about earnings. But the, the fact that this thing is just

154
00:09:37,085 --> 00:09:40,325
Speaker 4:  a slightly cleaner interface on top of roughly the same information

155
00:09:41,025 --> 00:09:44,725
Speaker 4:  is kind of what everyone is landing on, right? Like whether you're

156
00:09:45,015 --> 00:09:48,565
Speaker 4:  perplexity or what Bing has been trying to do, or now

157
00:09:48,825 --> 00:09:52,365
Speaker 4:  OpenAI like even even Google's thing is like, yeah,

158
00:09:52,625 --> 00:09:56,285
Speaker 4:  we agree that the search page is kind of a mess. Let's,

159
00:09:56,415 --> 00:10:00,365
Speaker 4:  let's do something better. And the question then of how do you

160
00:10:00,525 --> 00:10:03,635
Speaker 4:  monetize any of that, who knows?

161
00:10:04,495 --> 00:10:07,875
Speaker 4:  The OpenAI wouldn't really tell Kylie, they're only rolling it out now for

162
00:10:08,065 --> 00:10:11,475
Speaker 4:  paid chat GBT users. So that's one pretty straight path.

163
00:10:12,135 --> 00:10:15,995
Speaker 4:  But eventually this will be available to free people.

164
00:10:16,215 --> 00:10:19,155
Speaker 4:  And how that makes money free, free, especially because this is very expensive.

165
00:10:19,305 --> 00:10:23,195
Speaker 4:  Yeah. It's not easy to run these kind of

166
00:10:23,315 --> 00:10:26,955
Speaker 4:  searches in real time in like, it's expensive to run inference on an

167
00:10:27,235 --> 00:10:30,635
Speaker 4:  existing model. It's a whole nother thing to go get real time information

168
00:10:30,635 --> 00:10:34,075
Speaker 4:  from the internet. Like that's a much harder problem to solve computationally.

169
00:10:35,075 --> 00:10:38,275
Speaker 4:  I, yeah, we will see if this becomes a thing that actually works at any scale

170
00:10:38,295 --> 00:10:42,185
Speaker 4:  for any of these companies, but like it is

171
00:10:42,245 --> 00:10:46,145
Speaker 4:  so, so straightforwardly just a slightly better interface

172
00:10:46,245 --> 00:10:48,985
Speaker 4:  on top of things. And you even listen to these companies talk about it and

173
00:10:48,985 --> 00:10:52,705
Speaker 4:  it's like, oh, clicking is so arduous. You have to find

174
00:10:52,705 --> 00:10:56,265
Speaker 4:  information for yourself. And there are certain things in which sure,

175
00:10:56,575 --> 00:11:00,505
Speaker 4:  like sometimes there is a piece of information buried at the bottom

176
00:11:00,525 --> 00:11:03,985
Speaker 4:  of a support document. And what I would like my search results to do

177
00:11:04,525 --> 00:11:07,465
Speaker 4:  is just pull that piece of information out and give it to me. Right? Like

178
00:11:07,505 --> 00:11:11,385
Speaker 4:  I, I need to know how to hard reset a gadget. I just

179
00:11:11,385 --> 00:11:13,905
Speaker 4:  wanna know the answer. I don't, I don't wanna, and, and often you do have

180
00:11:13,905 --> 00:11:17,705
Speaker 4:  to look on 10 websites to find how to hard reset your gadget. This one,

181
00:11:18,295 --> 00:11:20,905
Speaker 4:  what are some great ways to fix up a backyard? This is like

182
00:11:22,015 --> 00:11:25,945
Speaker 4:  very slightly better than what you would get just by clicking any

183
00:11:25,945 --> 00:11:27,025
Speaker 4:  of these webpages on Google.

184
00:11:27,495 --> 00:11:31,065
Speaker 3:  Yeah. And I will say, you know, we're we're Cherrypicking the one example,

185
00:11:31,245 --> 00:11:35,225
Speaker 3:  but it's the example they gave us, right? Right. Like there are other things

186
00:11:35,565 --> 00:11:38,945
Speaker 3:  and we have to use it and we have to, it's interesting to try to review search

187
00:11:38,945 --> 00:11:42,265
Speaker 3:  engines. We, we've like had this concept for a long, we should review Google

188
00:11:42,405 --> 00:11:46,265
Speaker 3:  and then it doesn't mean anything like try to give Google a

189
00:11:46,265 --> 00:11:50,185
Speaker 3:  score out of 10, it's seven. Like that's the answer. Yeah.

190
00:11:50,455 --> 00:11:54,205
Speaker 3:  Like, so, and we have to find some ways, ways to evaluate these tools

191
00:11:54,345 --> 00:11:57,885
Speaker 3:  to actually like address the breadth of how people use them.

192
00:11:58,705 --> 00:12:02,485
Speaker 3:  But right now it is very much, we just got rid of the ads. Like this

193
00:12:02,485 --> 00:12:06,365
Speaker 3:  market had a monopoly player, the monopoly player basically, and ified

194
00:12:06,365 --> 00:12:10,045
Speaker 3:  the whole thing, the entire economics to make the content are people will

195
00:12:10,045 --> 00:12:13,805
Speaker 3:  click on one webpage on your entire site maybe once a year

196
00:12:13,805 --> 00:12:17,285
Speaker 3:  because they search for backyard ideas. So that webpage has to make all of

197
00:12:17,285 --> 00:12:21,155
Speaker 3:  the money all at once. That's weird. So that's how

198
00:12:21,155 --> 00:12:23,555
Speaker 3:  we've loaded up all the pages of the ads and chum boxes and dah da da da

199
00:12:23,775 --> 00:12:27,475
Speaker 3:  and like, maybe this breaks it, this isn't gonna send a lot of traffic to

200
00:12:27,475 --> 00:12:31,085
Speaker 3:  the spruce or whatever sources are in here. We don't know.

201
00:12:31,385 --> 00:12:33,805
Speaker 3:  So it might, there's just a long road to come.

202
00:12:34,115 --> 00:12:36,885
Speaker 4:  Yeah. Well, and I think your your point about the, the tension they're feeling

203
00:12:36,885 --> 00:12:40,605
Speaker 4:  with these publisher deals, I think probably says more about this design

204
00:12:40,795 --> 00:12:44,565
Speaker 4:  than you, than OpenAI would like it to. Because

205
00:12:45,155 --> 00:12:48,845
Speaker 4:  like, this is what's happening with Meta too, right? There was news this

206
00:12:48,845 --> 00:12:52,805
Speaker 4:  week that Meta is working on a search engine

207
00:12:52,805 --> 00:12:56,405
Speaker 4:  of its own partly just to reduce reliance on Google and

208
00:12:56,515 --> 00:12:59,765
Speaker 4:  Bing, because I think everybody would like to reduce reliance on Google and

209
00:12:59,765 --> 00:13:03,525
Speaker 4:  Bing, but also because as meta AI gets more useful, they announced it has

210
00:13:03,525 --> 00:13:06,325
Speaker 4:  500 million monthly active users. Like it's big, it's working, people are

211
00:13:06,325 --> 00:13:09,965
Speaker 4:  using it. Having good realtime

212
00:13:10,245 --> 00:13:13,245
Speaker 4:  internet information just allows you to do lots of new things. Right. And

213
00:13:13,685 --> 00:13:17,485
Speaker 4:  I have to assume, if I'm OpenAI, the best case scenario

214
00:13:17,635 --> 00:13:21,325
Speaker 4:  here would be something that doesn't feel anything like search at all and

215
00:13:21,325 --> 00:13:24,925
Speaker 4:  is not a list of links, but just has this giant

216
00:13:25,145 --> 00:13:29,045
Speaker 4:  new capability of real-time information, which just opens

217
00:13:29,045 --> 00:13:32,965
Speaker 4:  up a huge set of things you can suddenly do with chat GPT that you

218
00:13:32,965 --> 00:13:36,565
Speaker 4:  couldn't before because its information ended. Like Yeah, it, it literally,

219
00:13:36,565 --> 00:13:39,645
Speaker 4:  it would tell you I only have information up to, I think it was like mid

220
00:13:39,645 --> 00:13:41,205
Speaker 4:  2023 the last time I checked.

221
00:13:42,915 --> 00:13:46,525
Speaker 4:  Once you get rid of that cap and I can just start to ask questions about

222
00:13:46,525 --> 00:13:50,485
Speaker 4:  like the world as it is happening, chat GBT becomes much more powerful. It

223
00:13:50,485 --> 00:13:53,485
Speaker 4:  also runs you into lawsuits from every publisher on planet earth, which is

224
00:13:53,485 --> 00:13:57,325
Speaker 4:  what has happened. And so you can, you can see how like

225
00:13:58,025 --> 00:14:01,325
Speaker 4:  OpenAI kind of lawyered its way into this design where it's like, okay, we're

226
00:14:01,325 --> 00:14:05,005
Speaker 4:  gonna do some AI stuff, but also there's gonna be a bunch of big ass links

227
00:14:05,005 --> 00:14:08,365
Speaker 4:  on the right side. Like, is everybody happy now? I don't know if they will

228
00:14:08,365 --> 00:14:08,525
Speaker 4:  be.

229
00:14:08,945 --> 00:14:12,285
Speaker 3:  We, we, we paid you money, will you shut up? Right. Like and that's the back

230
00:14:12,285 --> 00:14:15,405
Speaker 3:  and forth here. And I think, you know, Kylie asked the questions in the,

231
00:14:15,405 --> 00:14:17,805
Speaker 3:  in the briefing and you can see it in the, in the story that we'll link,

232
00:14:19,105 --> 00:14:22,845
Speaker 3:  but they're like, we're working with our publisher partners and now the game

233
00:14:22,845 --> 00:14:26,085
Speaker 3:  is instead of doing SEO to get to the top of the rankings,

234
00:14:26,915 --> 00:14:30,765
Speaker 3:  it's do deals with OpenAI Right. To get in the list and get the money and

235
00:14:30,995 --> 00:14:34,125
Speaker 3:  hopefully have influence over what these things look like. And that's just

236
00:14:34,125 --> 00:14:37,325
Speaker 3:  gonna be a whole different world when you look at meta and meta doing search.

237
00:14:38,085 --> 00:14:41,965
Speaker 3:  I think one, this is just evidence that ai, regardless of whether it's

238
00:14:41,965 --> 00:14:45,765
Speaker 3:  good or bad or whether it works or doesn't, has created the feeling

239
00:14:46,235 --> 00:14:47,965
Speaker 3:  that search is now a competitive market.

240
00:14:48,385 --> 00:14:48,605
Speaker 4:  Yes.

241
00:14:49,305 --> 00:14:53,165
Speaker 3:  If the Google antitrust case, you know, goes the way that

242
00:14:53,165 --> 00:14:57,125
Speaker 3:  we think it will go on appeal and Google remains unable to just pay its

243
00:14:57,125 --> 00:15:00,965
Speaker 3:  way into default payments, well that means a lot of

244
00:15:00,965 --> 00:15:04,725
Speaker 3:  people could get placement in iOS to be the default search

245
00:15:04,725 --> 00:15:08,405
Speaker 3:  engine. Those browser ballots that

246
00:15:08,475 --> 00:15:12,365
Speaker 3:  have not worked in Europe for a decade, but like might get

247
00:15:12,565 --> 00:15:16,325
Speaker 3:  imposed on Android in this country as well. Maybe you wanna put

248
00:15:16,825 --> 00:15:20,645
Speaker 3:  the meta logo there and say meta powered AI search or OpenAI chat

249
00:15:20,725 --> 00:15:24,485
Speaker 3:  GBT powered search to say there are other options for you for search engines

250
00:15:24,485 --> 00:15:28,165
Speaker 3:  beyond Google. And so the market is opening some

251
00:15:28,165 --> 00:15:32,125
Speaker 3:  combination of just like regulatory effort and the existence of AI as

252
00:15:32,125 --> 00:15:35,605
Speaker 3:  a whole, plus Google search as a product

253
00:15:36,065 --> 00:15:38,805
Speaker 3:  having plateaued into whatever it was last year.

254
00:15:39,985 --> 00:15:41,925
Speaker 3:  All of this is just conditions for web search to change.

255
00:15:42,275 --> 00:15:42,565
Speaker 4:  Yeah.

256
00:15:43,025 --> 00:15:46,565
Speaker 3:  The question that I have very like

257
00:15:47,275 --> 00:15:51,245
Speaker 3:  existentially is does any of this create incentives for people

258
00:15:51,265 --> 00:15:54,995
Speaker 3:  to put information on the web? Because right now all the incentives

259
00:15:55,135 --> 00:15:58,835
Speaker 3:  are for you as a creator or a publisher or whoever to put new

260
00:15:58,835 --> 00:16:02,195
Speaker 3:  information on TikTok Yeah. Or Instagram reels or

261
00:16:02,625 --> 00:16:06,595
Speaker 3:  YouTube where you might actually make some money. Like the A to B of

262
00:16:06,755 --> 00:16:10,315
Speaker 3:  I made some information on the web and made some money is as fuzzy as it

263
00:16:10,315 --> 00:16:10,875
Speaker 3:  has ever been.

264
00:16:11,265 --> 00:16:14,835
Speaker 4:  Yeah. I I've spent a lot of time talking to and

265
00:16:14,835 --> 00:16:18,675
Speaker 4:  reading kind of OG bloggers recently we

266
00:16:18,675 --> 00:16:21,475
Speaker 4:  just did The Vergecast about the origin of the Word podcast. And a lot of

267
00:16:21,475 --> 00:16:25,395
Speaker 4:  the folks involved with that were also like really early bloggers, So

268
00:16:25,395 --> 00:16:29,035
Speaker 4:  I ended up sort of back in this sphere. And the the

269
00:16:29,075 --> 00:16:32,555
Speaker 4:  overwhelming thing I keep hearing from these early bloggers is like

270
00:16:33,575 --> 00:16:37,115
Speaker 4:  the, we we blog because we want to, it's not about the money, it's about,

271
00:16:37,265 --> 00:16:40,835
Speaker 4:  it's about having something to say and it's like that's well and good that

272
00:16:41,215 --> 00:16:45,155
Speaker 4:  the, the like number of people for whom that applies is this big.

273
00:16:45,855 --> 00:16:49,835
Speaker 4:  And and it is like a, in a lot of ways it's like a bunch of dudes who sold

274
00:16:49,835 --> 00:16:53,675
Speaker 4:  startups in the nineties and needed something to do all day. Yeah. Like not

275
00:16:53,675 --> 00:16:57,435
Speaker 4:  to be an asshole about it, but like that's what it was. And, and, and you're

276
00:16:57,435 --> 00:17:00,955
Speaker 4:  right. And the idea that I'm going to be able to do this

277
00:17:01,705 --> 00:17:05,555
Speaker 4:  open web something blog, find other

278
00:17:05,555 --> 00:17:08,995
Speaker 4:  ways to make content, the i there is not

279
00:17:09,895 --> 00:17:13,235
Speaker 4:  any more a a sort of obvious or even like

280
00:17:13,955 --> 00:17:17,915
Speaker 4:  straight line to I can make a business out of this because

281
00:17:18,535 --> 00:17:21,795
Speaker 4:  all of the interface is just getting subsumed. And even

282
00:17:22,495 --> 00:17:26,115
Speaker 4:  if you're, if you're competing to be a link in Chatt t you don't have the

283
00:17:26,115 --> 00:17:29,115
Speaker 4:  lawyers to make the deal with OpenAI. So you may not show up in there. Yep.

284
00:17:29,115 --> 00:17:32,995
Speaker 4:  So suddenly the, the list of even available sources to you

285
00:17:33,125 --> 00:17:36,555
Speaker 4:  might be much smaller than it once was because you just don't have the engine

286
00:17:36,555 --> 00:17:40,475
Speaker 4:  with which to play the game. And OpenAI might decide that

287
00:17:40,475 --> 00:17:44,355
Speaker 4:  it's easier to just shut everybody else out than to fight the fight

288
00:17:44,545 --> 00:17:46,355
Speaker 4:  website by website all around the internet.

289
00:17:46,655 --> 00:17:49,885
Speaker 3:  And I, the weird danger of this is

290
00:17:51,175 --> 00:17:55,145
Speaker 3:  that we'll go back to a media ecosystem that looks like the

291
00:17:55,145 --> 00:17:59,025
Speaker 3:  one we had before the internet, which is I think

292
00:17:59,055 --> 00:18:02,905
Speaker 3:  hard for a lot of people to understand or see. But

293
00:18:02,905 --> 00:18:06,385
Speaker 3:  what I'm describing is you'll have a lot of people who write paid newsletters

294
00:18:06,765 --> 00:18:10,465
Speaker 3:  or have small audiences that pay money behind

295
00:18:10,465 --> 00:18:14,385
Speaker 3:  paywalls or even medium sized audiences behind paywalls because

296
00:18:14,645 --> 00:18:17,905
Speaker 3:  that's the best way to make the money. and we can see that all over the place.

297
00:18:18,145 --> 00:18:21,465
Speaker 3:  Creators are just making money directly. They're Casey Newton a great friend

298
00:18:21,465 --> 00:18:24,435
Speaker 3:  of The Verge platform is doing great, but he,

299
00:18:25,215 --> 00:18:28,795
Speaker 3:  that's the size of the audience, right? And like there's a lot of newsletters

300
00:18:28,795 --> 00:18:31,235
Speaker 3:  that have hit escape velocity like Platformer has and they're, they're doing

301
00:18:31,235 --> 00:18:35,115
Speaker 3:  really, really well, but that they're just paywall. They're just that

302
00:18:35,135 --> 00:18:38,275
Speaker 3:  and that's how big they're gonna be or and there are some that are even smaller.

303
00:18:39,175 --> 00:18:42,155
Speaker 3:  And then you have the mass outlets that are free,

304
00:18:43,145 --> 00:18:47,035
Speaker 3:  that are gate kept by weird deals. Yeah.

305
00:18:47,135 --> 00:18:50,995
Speaker 3:  And that is cable news or like whatever other big free distribution

306
00:18:51,325 --> 00:18:54,595
Speaker 3:  where everyone has made the deals to support that. And so most people will

307
00:18:54,595 --> 00:18:57,715
Speaker 3:  experience the things that can be subsidized in that way. And then a lot

308
00:18:57,715 --> 00:19:00,915
Speaker 3:  of people are gonna have small magazines or small blogs that are pay walled.

309
00:19:01,375 --> 00:19:05,315
Speaker 3:  And that, that weird thing that the internet did, which is let everyone

310
00:19:05,315 --> 00:19:09,115
Speaker 3:  just sort of compete freely against each other is kind of just like

311
00:19:09,115 --> 00:19:12,675
Speaker 3:  getting crushed by all of this. What amounts to just a bunch of

312
00:19:12,675 --> 00:19:16,595
Speaker 3:  interface changes, right? Like it's a cleaner search inter

313
00:19:16,595 --> 00:19:20,155
Speaker 3:  interface and then behind that is like a total reordering of

314
00:19:20,655 --> 00:19:23,195
Speaker 3:  the internet into paywalls and not,

315
00:19:23,435 --> 00:19:27,155
Speaker 4:  I think the question implicit in that is how different

316
00:19:27,495 --> 00:19:28,515
Speaker 4:  is, at

317
00:19:28,515 --> 00:19:30,955
Speaker 3:  Least for writing, I wanna be clear that's for writing. Yeah. On the video

318
00:19:30,985 --> 00:19:33,155
Speaker 3:  side it's just very different on the podcasting side it's very different.

319
00:19:33,185 --> 00:19:33,475
Speaker 3:  Well,

320
00:19:33,475 --> 00:19:37,315
Speaker 4:  But even, even on that side, I think the question, the question I was

321
00:19:37,315 --> 00:19:40,795
Speaker 4:  about to ask is like how different is kind of the

322
00:19:40,805 --> 00:19:44,195
Speaker 4:  unknowable TikTok algorithm versus like the

323
00:19:44,195 --> 00:19:47,915
Speaker 4:  unknowable guy in the corner office who decided what was fit to print,

324
00:19:47,915 --> 00:19:51,715
Speaker 4:  right? Like it is, it is rules, it's just a

325
00:19:51,835 --> 00:19:54,635
Speaker 4:  question of which rules and how transparent are they and do they make sense

326
00:19:54,635 --> 00:19:58,395
Speaker 4:  to you? Yeah. And the idea of there being this ecosystem that was

327
00:19:59,095 --> 00:20:02,475
Speaker 4:  too big for any one player to control

328
00:20:03,095 --> 00:20:06,955
Speaker 4:  that's gone, right? Like that, that's long gone. And I think it's been gone

329
00:20:07,615 --> 00:20:11,075
Speaker 4:  longer than a lot of people realized. It's just that now

330
00:20:11,725 --> 00:20:15,475
Speaker 4:  we're getting new interfaces to see some of this stuff and it's, it's making

331
00:20:15,475 --> 00:20:19,195
Speaker 4:  it really obvious how hard it is to make it If. you

332
00:20:19,195 --> 00:20:22,755
Speaker 4:  don't have either the sort of unknowable

333
00:20:23,115 --> 00:20:26,995
Speaker 4:  blessing of an unknowable algorithm or some big thing

334
00:20:26,995 --> 00:20:28,595
Speaker 4:  to fight on your behalf in some way or another.

335
00:20:28,905 --> 00:20:32,355
Speaker 3:  Well, I'll give you an example and So I think about it all the time. So

336
00:20:32,635 --> 00:20:36,515
Speaker 3:  Becca Fache was just on the waveform podcast with Marquez and David, we

337
00:20:36,515 --> 00:20:38,835
Speaker 3:  wish Becca all the best with her YouTube channel. I hope she does really

338
00:20:38,835 --> 00:20:40,995
Speaker 3:  great. It's a good pod. Yeah, it's a good podcast. You should go listen to

339
00:20:40,995 --> 00:20:44,955
Speaker 3:  it. And they had a, just a brief conversation about

340
00:20:44,995 --> 00:20:48,525
Speaker 3:  a thing that I've heard so many tech YouTubers talk about all the time, which

341
00:20:48,525 --> 00:20:51,445
Speaker 3:  is the audiences on tech YouTube are overwhelmingly male

342
00:20:52,465 --> 00:20:56,405
Speaker 3:  and even getting to 10% female audience breaking

343
00:20:56,505 --> 00:21:00,445
Speaker 3:  two digits on tech YouTube is like hard. Like people talk about it.

344
00:21:01,045 --> 00:21:03,685
Speaker 3:  I think Mark has said, I've never, I've only seen one and it might be another

345
00:21:03,685 --> 00:21:06,885
Speaker 3:  one like that's true for our channel as well. It's impossible.

346
00:21:07,435 --> 00:21:11,245
Speaker 3:  That is not reality, right? That is an algorithmic truth

347
00:21:11,305 --> 00:21:15,245
Speaker 3:  of YouTube. The YouTube algorithm has decided that

348
00:21:15,245 --> 00:21:18,925
Speaker 3:  women are not interested in tech videos and so it doesn't show them to them.

349
00:21:19,465 --> 00:21:22,685
Speaker 3:  And so all of these channels have these horrible skews

350
00:21:23,505 --> 00:21:26,605
Speaker 3:  and you can't, you have to fight it. I don't know how to fight it. I know

351
00:21:26,605 --> 00:21:30,525
Speaker 3:  that this is an algorithmic truth because we run a giant website where

352
00:21:30,625 --> 00:21:34,285
Speaker 3:  our gender breakdown on our website of people who come to our website directly

353
00:21:34,655 --> 00:21:38,285
Speaker 3:  looks nothing like that. Right? It is way closer to 50 50

354
00:21:38,285 --> 00:21:41,965
Speaker 3:  because that is fucking true. Like, like everybody

355
00:21:42,205 --> 00:21:46,085
Speaker 3:  likes technology like stat from our sales team all the time

356
00:21:46,085 --> 00:21:49,605
Speaker 3:  is like women make like 80% of technology purchasing decisions in the average

357
00:21:49,605 --> 00:21:53,165
Speaker 3:  household. That's just a real thing that we think about all the time and

358
00:21:53,165 --> 00:21:57,085
Speaker 3:  we are able to address it. And yes, we are buffeted by algorithms,

359
00:21:57,085 --> 00:21:59,925
Speaker 3:  we're buffeted by search for buffet by all stuff. But the algorithm truth

360
00:21:59,925 --> 00:22:03,845
Speaker 3:  of YouTube is that that's your whole audience and you

361
00:22:03,845 --> 00:22:06,685
Speaker 3:  will, you will have to fight it. And I hope that all of them fight it. I'm

362
00:22:06,685 --> 00:22:09,685
Speaker 3:  glad that they're all talking about it. It's good that they're transparent

363
00:22:09,685 --> 00:22:13,525
Speaker 3:  about it. Hopefully there'll be some change. But that is the,

364
00:22:13,825 --> 00:22:17,765
Speaker 3:  that's the mass media now is like algorithmic media. And so I'm, I'm just

365
00:22:17,765 --> 00:22:21,325
Speaker 3:  hopeful that as the AI search and all these other kind of distribution algorithms

366
00:22:21,325 --> 00:22:25,205
Speaker 3:  hit the mix, there's some resorting in

367
00:22:25,205 --> 00:22:28,765
Speaker 3:  a way that makes more sense. Yeah. Right. Like there, there's some resorting

368
00:22:28,765 --> 00:22:32,685
Speaker 3:  in a way that allows small players to not have to chase scale. Which was

369
00:22:32,685 --> 00:22:36,515
Speaker 3:  the big, that was the big miss of like the Facebook video era is like

370
00:22:36,655 --> 00:22:40,275
Speaker 3:  the small recipe site was like, now we make Facebook videos too, right?

371
00:22:40,275 --> 00:22:43,275
Speaker 3:  Something horrible was happening there. It was the big miss of the search

372
00:22:43,295 --> 00:22:47,235
Speaker 3:  era where everything got blanded down into this weird semi robotic English

373
00:22:47,235 --> 00:22:51,115
Speaker 3:  that makes no sense to anyone. And if the next turn is the AI can just read

374
00:22:51,115 --> 00:22:54,315
Speaker 3:  everything as it's written and make it sensible and still distribute it well

375
00:22:54,825 --> 00:22:58,475
Speaker 3:  that will allow things to be more different. But the danger is you're gonna

376
00:22:58,475 --> 00:23:02,025
Speaker 3:  end up with small to medium sized paywall media

377
00:23:02,765 --> 00:23:06,465
Speaker 3:  and then mass algorithmic media and the middle of that will be,

378
00:23:07,245 --> 00:23:10,085
Speaker 3:  I dunno what the fuck the middle of that will be. It'll be weird. Like that's

379
00:23:10,085 --> 00:23:10,165
Speaker 3:  what

380
00:23:10,165 --> 00:23:12,885
Speaker 4:  I got. and it will feel like all you're doing is feeding some

381
00:23:14,145 --> 00:23:18,125
Speaker 4:  AI system more training data. Yeah. Can I give you a better

382
00:23:18,275 --> 00:23:21,765
Speaker 4:  case scenario in news this week that makes me very excited about AI search?

383
00:23:23,225 --> 00:23:27,205
Speaker 4:  So Google just launched a new thing in Google Maps

384
00:23:27,205 --> 00:23:31,085
Speaker 4:  that it calls Ask Maps. And I think this rules, and it's basically, it's

385
00:23:31,085 --> 00:23:34,245
Speaker 4:  just Gemini search, but pointed only at

386
00:23:34,665 --> 00:23:38,525
Speaker 4:  Google Maps data. And so you can, you can start to do things like

387
00:23:39,145 --> 00:23:42,965
Speaker 4:  ask it. The example they give is things to do with friends

388
00:23:42,985 --> 00:23:45,925
Speaker 4:  at night, which again, not, not English,

389
00:23:46,545 --> 00:23:49,885
Speaker 3:  The by the way, the range of answers to that question Yeah.

390
00:23:49,935 --> 00:23:52,405
Speaker 3:  Acceptable to unacceptable is wild.

391
00:23:52,875 --> 00:23:56,725
Speaker 4:  Okay. But like think about your own Google Maps usage, or at least the, the

392
00:23:56,725 --> 00:23:59,085
Speaker 4:  one I encounter all the time is I'm like, okay, we we wanna go out to dinner,

393
00:23:59,085 --> 00:24:02,965
Speaker 4:  right? I wanna like find a place that I've been before,

394
00:24:02,965 --> 00:24:06,125
Speaker 4:  which is in theory information Google has or like what's the best pizza place

395
00:24:06,125 --> 00:24:06,845
Speaker 4:  around here for? But does

396
00:24:06,845 --> 00:24:09,965
Speaker 3:  Google know about me? Is it using the, like my previous Google search history,

397
00:24:09,965 --> 00:24:13,885
Speaker 3:  like if I'm out here, like, it's Halloween, so I'm out here searching

398
00:24:13,885 --> 00:24:17,805
Speaker 3:  for like masks black clothing and I'm like, what to do at night? And it's

399
00:24:17,805 --> 00:24:18,645
Speaker 3:  like Rob Bank

400
00:24:20,945 --> 00:24:21,645
Speaker 3:  things to do

401
00:24:21,765 --> 00:24:23,645
Speaker 4:  With friends at night who rob several banks.

402
00:24:25,325 --> 00:24:28,965
Speaker 4:  I, I don't know. I doubt it. Okay. That's, that's everybody's long-term plan.

403
00:24:28,985 --> 00:24:32,285
Speaker 4:  But what I think is happening here is that Google is actually just doing

404
00:24:32,285 --> 00:24:36,205
Speaker 4:  this with the existing maps data, which is basically like

405
00:24:36,205 --> 00:24:40,125
Speaker 4:  all the place data, it has all the navigation data it has and crucially

406
00:24:40,225 --> 00:24:43,725
Speaker 4:  all of the like reviews and stuff that are in there. So the thing that I

407
00:24:43,725 --> 00:24:47,605
Speaker 4:  encounter all the time is looking for a place to eat dinner.

408
00:24:47,665 --> 00:24:51,165
Speaker 4:  And then I, I find myself combing through reviews looking for one of two

409
00:24:51,165 --> 00:24:54,925
Speaker 4:  things. Either there is good outdoor seating or it it is

410
00:24:54,925 --> 00:24:58,525
Speaker 4:  meaningfully kid friendly in some way. And just the

411
00:24:58,845 --> 00:25:02,485
Speaker 4:  ability to like ask that question at the top of the search

412
00:25:03,315 --> 00:25:07,125
Speaker 4:  becomes incredibly useful. And this I feel zero

413
00:25:08,045 --> 00:25:12,005
Speaker 4:  qualms about because no one is on Google Maps for the purpose of being

414
00:25:12,005 --> 00:25:14,805
Speaker 4:  on Google Maps, right? Like Google Maps is a means to an end every single

415
00:25:14,805 --> 00:25:18,685
Speaker 4:  time. And all of these places that put their information on Google Maps do

416
00:25:18,685 --> 00:25:22,525
Speaker 4:  it so that I will go to a place and, and there the goal is to get

417
00:25:22,525 --> 00:25:26,085
Speaker 4:  me to the place I want to be more quickly. And I think there are lots of

418
00:25:26,365 --> 00:25:29,605
Speaker 4:  interesting complicated like bias problems to figure out with all of this

419
00:25:29,705 --> 00:25:31,885
Speaker 4:  AI stuff. Yeah. But the idea of just being able to be like,

420
00:25:33,475 --> 00:25:37,405
Speaker 4:  what kid friendly place can I go to this weekend that isn't

421
00:25:37,405 --> 00:25:39,605
Speaker 4:  likely to be super busy on a Saturday night? Like

422
00:25:39,955 --> 00:25:41,365
Speaker 3:  Haven't you just described Yelp?

423
00:25:41,675 --> 00:25:45,565
Speaker 4:  I've described what Yelp would like to be and has pitched itself as for forever.

424
00:25:46,065 --> 00:25:49,845
Speaker 4:  But what I just described on Yelp involves opening a filters menu and

425
00:25:49,845 --> 00:25:53,685
Speaker 4:  selecting 31 things and combin through a hundred listings and like Right.

426
00:25:53,685 --> 00:25:54,085
Speaker 4:  But is

427
00:25:54,085 --> 00:25:57,885
Speaker 3:  The whole point of the LLM is like, it will understand natural

428
00:25:58,245 --> 00:26:01,725
Speaker 3:  language and it will be able to communicate in a more naturalistic language.

429
00:26:01,725 --> 00:26:05,645
Speaker 3:  Yeah. I mean we, I we get comments on our site and I

430
00:26:06,315 --> 00:26:10,135
Speaker 3:  almost a 10 outta 10 can tell when they've been written by an LLM like, oh

431
00:26:10,135 --> 00:26:13,055
Speaker 3:  yeah, there's a stilted form that is just the way it goes.

432
00:26:14,595 --> 00:26:18,135
Speaker 3:  But the idea that the compute, the input and output of the computer is much

433
00:26:18,135 --> 00:26:21,375
Speaker 3:  more natural language. That's the thing everyone's freaking out about. Right?

434
00:26:21,375 --> 00:26:25,365
Speaker 3:  That's the platform shift. That's your click wheel. It's not

435
00:26:25,365 --> 00:26:28,405
Speaker 3:  your digital crown, I'm sorry, but Right. That's your multi-touch. Yeah.

436
00:26:28,405 --> 00:26:32,365
Speaker 3:  Like that's the thing people are freaking out about. And so you get to,

437
00:26:33,605 --> 00:26:36,655
Speaker 3:  okay, I can just talk to Google Maps and Google Maps and just talk back to

438
00:26:36,655 --> 00:26:40,295
Speaker 3:  me all, you're still just looking at a database of information inside of

439
00:26:40,295 --> 00:26:43,645
Speaker 3:  Google, right? Yeah. And it's still, you're, you're clicking the filters,

440
00:26:43,645 --> 00:26:44,845
Speaker 3:  but just with natural language.

441
00:26:45,135 --> 00:26:48,365
Speaker 4:  Right? But that's, that's the thing, right? Like that that changes

442
00:26:48,985 --> 00:26:52,885
Speaker 4:  the whole interface. Like they, they have a, a gif in this story that Emma Roth

443
00:26:52,885 --> 00:26:56,325
Speaker 4:  wrote that it, it opens up a, a

444
00:26:56,675 --> 00:27:00,005
Speaker 4:  bars page on Google Maps and then you, you type in

445
00:27:00,375 --> 00:27:03,765
Speaker 4:  under a thing that says Ask maps about this place. You say, do they have

446
00:27:03,765 --> 00:27:07,205
Speaker 4:  a full bar? and it it, what it appears to be doing is it go, it looks at

447
00:27:07,205 --> 00:27:11,125
Speaker 4:  the menu to see that it serves beer, wine, cocktails and liquor and

448
00:27:11,125 --> 00:27:14,245
Speaker 4:  then looks at the reviews to see what people like and just puts that into

449
00:27:14,245 --> 00:27:16,285
Speaker 4:  three sentences and hands it back and says, yes, it is a full bar.

450
00:27:17,875 --> 00:27:21,645
Speaker 4:  Some people say, what are the cocktails are delicious. Like

451
00:27:21,985 --> 00:27:25,405
Speaker 4:  that's excellent. That is an extremely good user interface

452
00:27:25,835 --> 00:27:29,605
Speaker 4:  that takes something that would've taken a bunch of filtering and

453
00:27:29,605 --> 00:27:33,405
Speaker 4:  collating and searching through reviews and just answers

454
00:27:33,465 --> 00:27:36,325
Speaker 4:  the question. And that is like, that's always been there inside of Google

455
00:27:36,435 --> 00:27:40,045
Speaker 4:  Maps and they've just never quite put it all the way together before. Yeah.

456
00:27:40,045 --> 00:27:41,885
Speaker 4:  And if they have this time, I think that's awesome.

457
00:27:42,115 --> 00:27:45,485
Speaker 3:  It's funny 'cause I, I think Amazon is launching that same feature for ask

458
00:27:45,765 --> 00:27:48,245
Speaker 3:  questions about this product and we will search reviews and stuff. Yes. And

459
00:27:48,245 --> 00:27:52,125
Speaker 3:  my experience with that is, yeah, you can do it and it'll work and

460
00:27:52,125 --> 00:27:55,685
Speaker 3:  everything is so depressingly averaged out. Yeah. Like the AI

461
00:27:55,685 --> 00:27:59,525
Speaker 3:  generated summary of the average set of Amazon reviews is like, some

462
00:27:59,525 --> 00:28:03,325
Speaker 3:  people liked it, some people said it set their house on fire. Right. What

463
00:28:03,325 --> 00:28:04,325
Speaker 3:  am I supposed to do with

464
00:28:04,795 --> 00:28:08,645
Speaker 4:  Yeah, well, and and again it like, it it's AI all the way down,

465
00:28:08,645 --> 00:28:11,165
Speaker 4:  right? Yeah. Because you get more and more people who are using AI to write

466
00:28:11,165 --> 00:28:15,045
Speaker 4:  these reviews. The, the AI is like naming the products for

467
00:28:15,095 --> 00:28:18,885
Speaker 4:  god's sake. Like the, the promotional images are being made by Gen ai. So

468
00:28:18,885 --> 00:28:22,725
Speaker 4:  it's like there is a mess that gets created in all of this if it doesn't

469
00:28:22,745 --> 00:28:26,725
Speaker 4:  go well. But I think the idea of it, and same on Amazon. Nobody cares

470
00:28:26,735 --> 00:28:29,805
Speaker 4:  about the content of their Amazon page. They want me to buy their thing.

471
00:28:30,065 --> 00:28:33,885
Speaker 4:  And So I think the, the extent to which AI search can get down to

472
00:28:34,045 --> 00:28:36,845
Speaker 4:  that more quickly. That's the stuff I think is really exciting.

473
00:28:37,235 --> 00:28:41,045
Speaker 3:  Yeah. Well it's very obvious that the race is on like Yeah. We have spent

474
00:28:41,145 --> 00:28:44,485
Speaker 3:  so much time talking on Google and pissing off so many SEO people by the

475
00:28:44,485 --> 00:28:48,295
Speaker 3:  way. The SEO people have all come around. They know. They know. and

476
00:28:48,355 --> 00:28:51,335
Speaker 3:  it, it is very funny. They were all real mad and now they're like, oh shit.

477
00:28:51,335 --> 00:28:55,095
Speaker 3:  You were right about the comment. A Google this week by the way,

478
00:28:55,635 --> 00:28:58,935
Speaker 3:  in a workshop basically said, we don't know if search traffic is gonna back

479
00:28:58,935 --> 00:28:59,855
Speaker 3:  to small websites. Yeah.

480
00:29:00,245 --> 00:29:01,905
Speaker 4:  And that you should prepare for it not to.

481
00:29:02,455 --> 00:29:05,745
Speaker 3:  Yeah. Brutal. Everyone's just saying it. Everyone yelled at me

482
00:29:06,335 --> 00:29:08,955
Speaker 3:  now everyone's just like, here it is. Yeah. So we're gonna track this very

483
00:29:08,955 --> 00:29:12,755
Speaker 3:  closely. David, you've been making the point that the, the money behind this

484
00:29:13,695 --> 00:29:16,915
Speaker 3:  is just all over the place and no one really knows how it's gonna go. And

485
00:29:17,365 --> 00:29:20,555
Speaker 3:  there was a lot of earnings this week. Yeah. Google had earnings, Microsoft

486
00:29:20,555 --> 00:29:24,355
Speaker 3:  head earnings. Reddit is profitable first, first time ever. Snap. Not

487
00:29:24,455 --> 00:29:28,075
Speaker 3:  so much snaps wrap. What do you, what do you, what do you see in here?

488
00:29:28,335 --> 00:29:32,195
Speaker 4:  So, okay, I, I took a bunch of notes on the earnings reports this week and

489
00:29:32,595 --> 00:29:35,275
Speaker 4:  I think as everyone knows, we kind of hate talking about earnings on this

490
00:29:35,275 --> 00:29:39,155
Speaker 4:  show. Yeah. And also in general because who cares? Companies make

491
00:29:39,155 --> 00:29:42,905
Speaker 4:  money, it's fine. But going through the earnings reports and

492
00:29:42,905 --> 00:29:46,785
Speaker 4:  listening to the calls and stuff, just a bunch of the same things

493
00:29:47,215 --> 00:29:50,065
Speaker 4:  kept jumping out to me and So I just wanna, I wanna just throw a couple of

494
00:29:50,065 --> 00:29:53,945
Speaker 4:  the things I have noticed at you and I'm, I'm curious how it makes you

495
00:29:53,945 --> 00:29:57,745
Speaker 4:  feel. The thing number one that just

496
00:29:58,115 --> 00:30:01,945
Speaker 4:  jumps out to me over and over and over again is that the thing that AI is

497
00:30:01,945 --> 00:30:05,745
Speaker 4:  being used for is to make everybody's very good ad businesses

498
00:30:06,575 --> 00:30:10,505
Speaker 4:  even better. That actually it might be true right

499
00:30:10,505 --> 00:30:14,425
Speaker 4:  now that the single thing AI does best, and I mean best in the

500
00:30:14,425 --> 00:30:18,145
Speaker 4:  terms of like most money making is connect

501
00:30:19,045 --> 00:30:23,025
Speaker 4:  an ad to a person, right? Which is like fundamentally a

502
00:30:23,025 --> 00:30:26,145
Speaker 4:  big data problem. And, and ad targeting has been a question on the internet

503
00:30:26,145 --> 00:30:29,985
Speaker 4:  for forever. And that Google talked about this, about how

504
00:30:29,985 --> 00:30:33,345
Speaker 4:  YouTube advertising has gotten better. Meta talked about it, about how its

505
00:30:33,345 --> 00:30:35,585
Speaker 4:  own advertising has gotten better, their revenue is going up as a result.

506
00:30:36,005 --> 00:30:39,865
Speaker 4:  But the fact that AI is being fundamentally monetized

507
00:30:40,365 --> 00:30:44,305
Speaker 4:  as an ad targeting thing is just so fascinating to me. And

508
00:30:44,305 --> 00:30:48,185
Speaker 4:  I think, I think we're we're due for a long run of that that Yeah. What it

509
00:30:48,185 --> 00:30:51,185
Speaker 4:  is is there is a mountain of data about me, there's an advertiser who is

510
00:30:51,185 --> 00:30:54,825
Speaker 4:  looking for me and AI can find me faster than any

511
00:30:55,265 --> 00:30:56,505
Speaker 4:  database software we've had before.

512
00:30:57,085 --> 00:31:00,425
Speaker 3:  Oh you you, that's just scratching the surface. That's just step one.

513
00:31:01,025 --> 00:31:04,705
Speaker 3:  'cause step two is what ad are you gonna see? Right?

514
00:31:05,095 --> 00:31:05,585
Speaker 4:  Totally.

515
00:31:05,805 --> 00:31:09,625
Speaker 3:  And every one of these companies is explicitly talking

516
00:31:09,625 --> 00:31:13,465
Speaker 3:  about, well we'll just have the AI generate a custom ad

517
00:31:13,665 --> 00:31:17,625
Speaker 3:  for you. Yep. Millions and millions and millions of iterations

518
00:31:17,925 --> 00:31:21,565
Speaker 3:  of the same creative generated for, for people

519
00:31:21,965 --> 00:31:25,485
Speaker 3:  specific taglines or specific needs. We know you were searching for

520
00:31:25,655 --> 00:31:29,585
Speaker 3:  capes and, and black boots. Have you thought about grappling

521
00:31:29,585 --> 00:31:33,545
Speaker 3:  hooks? Like, like exactly that thing. Yeah.

522
00:31:34,735 --> 00:31:38,185
Speaker 3:  It's gonna be weird. And there's a reason that they're all chasing video

523
00:31:38,185 --> 00:31:41,905
Speaker 3:  generation. 'cause the thing they absolutely wanna do is make video ads

524
00:31:41,975 --> 00:31:45,425
Speaker 3:  with influencers in them. Yes. And they're already, they're, they're

525
00:31:45,495 --> 00:31:48,585
Speaker 3:  priming. And I don't mean to sound this in a conspiracy way. I mean this

526
00:31:48,585 --> 00:31:52,105
Speaker 3:  is the reporting and this is what is happening. They're priming

527
00:31:52,565 --> 00:31:55,665
Speaker 3:  the creators and their audiences to interact with ais

528
00:31:56,695 --> 00:32:00,305
Speaker 3:  Meta. Meta has a thing where if you're an Instagram influencer, you can have

529
00:32:00,305 --> 00:32:03,465
Speaker 3:  people talk to your AI trained on your Instagram data, which by the way includes

530
00:32:03,465 --> 00:32:07,145
Speaker 3:  your threads posts. Which is wild. So our friend Katie

531
00:32:07,495 --> 00:32:11,345
Speaker 3:  Pols at Business Insider, she's been engagement baiting

532
00:32:11,405 --> 00:32:15,345
Speaker 3:  on threads just as a bit, yeah. Forever. And then she lit up her Instagram

533
00:32:15,525 --> 00:32:19,465
Speaker 3:  bot and it trained on her threads. So her Instagram

534
00:32:19,525 --> 00:32:22,785
Speaker 3:  bot is just an engagement bait bot. It's like perfect, that's perfect.

535
00:32:23,585 --> 00:32:27,465
Speaker 3:  YouTube has this thing, right? They say out loud to creators, don't,

536
00:32:27,515 --> 00:32:31,185
Speaker 3:  don't worry about all this like fan audience engagement. We want you to make

537
00:32:31,185 --> 00:32:35,105
Speaker 3:  videos, make great content. We'll let the bot chat with your, with your viewers.

538
00:32:36,555 --> 00:32:40,245
Speaker 3:  The turn to you can make the branded content with

539
00:32:40,385 --> 00:32:44,365
Speaker 3:  an AI video of yourself is, it's not, that's not

540
00:32:44,365 --> 00:32:47,765
Speaker 3:  a conspiracy theory. That is the plan. No. And I, I think that's from one

541
00:32:47,765 --> 00:32:51,045
Speaker 3:  perspective that is fascinating. Will The Verge have something to write about

542
00:32:51,145 --> 00:32:54,085
Speaker 3:  for the next 10 years? Yeah. Yes. I think we're gonna

543
00:32:54,085 --> 00:32:54,405
Speaker 4:  Be okay.

544
00:32:54,515 --> 00:32:58,205
Speaker 3:  Yeah. Go get it. Like I'm, there's, there'll be a lot to unpack with all

545
00:32:58,205 --> 00:33:02,005
Speaker 3:  that, but you just see where it's going and it is all, all of this effort

546
00:33:02,005 --> 00:33:03,405
Speaker 3:  right now is pointed at advertising.

547
00:33:03,405 --> 00:33:06,885
Speaker 4:  Yeah. Lemme just do one more thing really quickly on the earnings thing because

548
00:33:07,685 --> 00:33:10,725
Speaker 4:  I don't wanna talk about earnings because I hate earnings. But I found this

549
00:33:11,325 --> 00:33:14,805
Speaker 4:  fascinating quote from Jen Wong, the CFO of Reddit talking about exactly

550
00:33:14,825 --> 00:33:18,805
Speaker 4:  the thing you're describing. Lemme just read you this quote. She says, so

551
00:33:18,825 --> 00:33:22,325
Speaker 4:  we launched a couple of quarters ago a headline generator using gen AI where

552
00:33:22,325 --> 00:33:25,725
Speaker 4:  you can just put in the URL from your website and it actually gives you reddity

553
00:33:25,965 --> 00:33:29,245
Speaker 4:  headlines that actually drive improved ad performance. And having reddity

554
00:33:29,245 --> 00:33:32,165
Speaker 4:  type headlines in your ads really does make a difference in the ad resonance.

555
00:33:32,345 --> 00:33:35,725
Speaker 4:  So that's just an example of I think what's possible in terms of ad creative.

556
00:33:35,915 --> 00:33:39,645
Speaker 4:  Yeah. And that is actually such a simple version of the thing that it's just

557
00:33:39,645 --> 00:33:43,525
Speaker 4:  like here, here's a Reddit bot that you can just plug a headline

558
00:33:43,525 --> 00:33:47,205
Speaker 4:  into and it will teach you how to Reddit. And like I just think about all

559
00:33:47,205 --> 00:33:50,645
Speaker 4:  the brands who did all that like awful cringey stuff on Twitter for all those

560
00:33:50,645 --> 00:33:54,605
Speaker 4:  years. This is about to get so horrible and so AI

561
00:33:54,605 --> 00:33:56,565
Speaker 4:  driven in so many ugly ways. By

562
00:33:56,565 --> 00:34:00,485
Speaker 3:  The way Mark Zuckerberg said more AI generated content is coming to Facebook

563
00:34:00,505 --> 00:34:02,685
Speaker 3:  and Instagram and maybe even threads.

564
00:34:02,835 --> 00:34:05,125
Speaker 4:  Yeah. And they're, they're fine with this. This is a feature on not a bug

565
00:34:05,125 --> 00:34:08,765
Speaker 4:  like it to, it's so, it's so is and everybody is fine with this.

566
00:34:08,945 --> 00:34:11,845
Speaker 4:  So that's one thing is the ads. And then just the two other things I just

567
00:34:11,845 --> 00:34:15,685
Speaker 4:  wanna say out loud because I, I feel like I'm losing my mind talking about

568
00:34:15,785 --> 00:34:19,725
Speaker 4:  AI with people. One is that I think we all

569
00:34:19,735 --> 00:34:23,325
Speaker 4:  still massively underrate how expensive the infrastructure for all of this

570
00:34:23,325 --> 00:34:26,685
Speaker 4:  is. Almost every one of these companies has like gone out of its way and

571
00:34:26,685 --> 00:34:30,325
Speaker 4:  its earning reports to talk about the increased

572
00:34:30,515 --> 00:34:33,885
Speaker 4:  cost just of physical infrastructure of supporting

573
00:34:34,665 --> 00:34:37,805
Speaker 4:  ai. And so like Sam Altman was out there being like, I need

574
00:34:37,805 --> 00:34:41,765
Speaker 4:  $7 trillion to build data centers to make all this AI stuff possible.

575
00:34:41,795 --> 00:34:45,605
Speaker 4:  Like the money is going to be crazy. Yeah. And the numbers are only going

576
00:34:45,605 --> 00:34:49,445
Speaker 4:  up. And I think like anyone who wants to say we're in an AI bubble, like

577
00:34:49,445 --> 00:34:52,925
Speaker 4:  those are the costs that are going to pop the bubble. So that's thing number

578
00:34:52,925 --> 00:34:55,925
Speaker 4:  two. And then thing number three, and this is just the, the most important

579
00:34:55,925 --> 00:34:59,765
Speaker 4:  point and the thing I want everyone to remember about AI is that anything

580
00:34:59,765 --> 00:35:03,605
Speaker 4:  other than like back of house AI that is doing like

581
00:35:03,605 --> 00:35:06,725
Speaker 4:  data analytics and helping customer service and all that stuff,

582
00:35:07,685 --> 00:35:11,485
Speaker 4:  anything other than that is a total money pit that there is very little evidence

583
00:35:11,685 --> 00:35:15,125
Speaker 4:  is actually working for anyone in the world. Like go read these earnings

584
00:35:15,125 --> 00:35:19,045
Speaker 4:  reports. They all start with the CEO being like, here are some cool magical

585
00:35:19,045 --> 00:35:22,365
Speaker 4:  things that we think we're inventing. And then the CFO comes on and is like,

586
00:35:22,385 --> 00:35:26,245
Speaker 4:  all of that has cost us $16 billion this year. Here's how we've made our

587
00:35:26,245 --> 00:35:30,165
Speaker 4:  money. Like over and over and over. That's what it is. All

588
00:35:30,165 --> 00:35:34,005
Speaker 4:  of this other stuff is being built in service of like being

589
00:35:34,035 --> 00:35:37,965
Speaker 4:  cool and exciting and getting in front of users. All of the actual utility

590
00:35:38,145 --> 00:35:42,005
Speaker 4:  and more importantly all of the actual money. Here is the

591
00:35:42,005 --> 00:35:45,965
Speaker 4:  boring B2B crap that nobody wants to talk about. Yeah. That is the AI story.

592
00:35:46,225 --> 00:35:49,765
Speaker 3:  If, you want to hear more about how AI is flipping over the

593
00:35:50,005 --> 00:35:53,285
Speaker 3:  advertising industry and creators in general. You should go listen to the

594
00:35:53,285 --> 00:35:56,605
Speaker 3:  decoder episode with Amy Landey, who is the CEO of Digitas.

595
00:35:56,825 --> 00:35:58,165
Speaker 4:  Oh yeah, that was a good one. and

596
00:35:58,165 --> 00:36:00,765
Speaker 3:  We, we did that in front of an audience and there was a lot of like ooh moments

597
00:36:00,785 --> 00:36:03,805
Speaker 3:  and that was fun. And I asked her, what is the difference between a creator

598
00:36:03,805 --> 00:36:07,525
Speaker 3:  and an influencer that got nowhere? Great icebreaker by the way, if you're

599
00:36:07,525 --> 00:36:10,965
Speaker 3:  ever an ad world. 'cause no one knows. No one really knows. But inside of

600
00:36:10,965 --> 00:36:14,125
Speaker 3:  that, we talked about this boring B2B stuff and what they're using a for

601
00:36:14,225 --> 00:36:17,925
Speaker 3:  and it yeah, there's a big, there's the, we're gonna have a GI

602
00:36:18,715 --> 00:36:22,685
Speaker 3:  like flashy noise and then there's the, like we're doing better ad

603
00:36:22,685 --> 00:36:23,965
Speaker 3:  targeting reality. Right.

604
00:36:24,265 --> 00:36:27,285
Speaker 4:  And to be clear, the the ad targeting reality is fine. Right? Like all of

605
00:36:27,285 --> 00:36:30,645
Speaker 4:  that is well and good and, and those things are going to be very meaningful

606
00:36:30,645 --> 00:36:33,365
Speaker 4:  to a lot of people in their jobs that are gonna make a lot of companies like

607
00:36:33,365 --> 00:36:36,845
Speaker 4:  that's all great. Let's just talk about what it is, right? Yeah. Like

608
00:36:37,585 --> 00:36:41,405
Speaker 4:  OpenAI makes most of its money from that stuff. Not by bid

609
00:36:41,685 --> 00:36:42,685
Speaker 4:  building. Digital God

610
00:36:43,025 --> 00:36:46,765
Speaker 3:  By the way open. They haven't actually made more money than they spend yet.

611
00:36:46,765 --> 00:36:50,405
Speaker 3:  So it's, they got a waste to go close. Not, not anywhere close.

612
00:36:52,225 --> 00:36:56,045
Speaker 3:  And by the way, what they will disrupt is Google search, which

613
00:36:56,065 --> 00:36:58,765
Speaker 3:  is one of the richest businesses in the history of the world. Yeah. Like

614
00:36:58,915 --> 00:37:02,845
Speaker 3:  pure margin businesses that has ever existed. It's a lot.

615
00:37:02,845 --> 00:37:03,805
Speaker 3:  It's like I said, I know

616
00:38:31,905 --> 00:38:34,165
Speaker 3:  Hey, we're gonna be back with Joanna Stern to talk about all the Apple News.

617
00:38:34,165 --> 00:38:34,685
Speaker 3:  We'll be right back.

618
00:38:39,215 --> 00:38:42,005
Speaker 3:  We're back. Joanna Stern is here. Welcome Joanna.

619
00:38:42,225 --> 00:38:43,885
Speaker 6:  I'm here. Thank you for having me.

620
00:38:44,215 --> 00:38:48,045
Speaker 3:  We're excited to talk to you. There's, I mean it's Apple Intelligence has

621
00:38:48,045 --> 00:38:51,085
Speaker 3:  arrived with iOS 18.1. All of our lives are different. You're a robot now.

622
00:38:53,235 --> 00:38:53,515
Speaker 6:  I am.

623
00:38:53,845 --> 00:38:56,715
Speaker 3:  There was what came before and now there's today.

624
00:38:57,175 --> 00:39:00,955
Speaker 6:  Tim Cook did tell the Wall Street Journal that it did change his life.

625
00:39:02,615 --> 00:39:03,035
Speaker 6:  He did.

626
00:39:03,535 --> 00:39:07,275
Speaker 3:  So there's actually a lot of Apple needs to go through with you. Apple had

627
00:39:07,275 --> 00:39:10,955
Speaker 3:  its Mac Week. They announced a Mac Mini with an M four chip. It's

628
00:39:11,105 --> 00:39:14,035
Speaker 3:  tiny and cute. We gotta talk about, it's everything's on the bottom. The

629
00:39:14,035 --> 00:39:17,995
Speaker 3:  power button's on the bottom of the Mac Mini, the USBC port is still on the

630
00:39:17,995 --> 00:39:21,795
Speaker 3:  bottom on the new Magic Mouse. There's new iMac, very colorful,

631
00:39:22,145 --> 00:39:26,075
Speaker 3:  also has an M four chip in it. And then iOS 18.1

632
00:39:26,075 --> 00:39:29,555
Speaker 3:  hit on Monday with the first shreds of Apple

633
00:39:29,555 --> 00:39:33,155
Speaker 3:  Intelligence. and it is true, Tim Cook said that having his emails

634
00:39:33,435 --> 00:39:36,515
Speaker 3:  summarized for him changed his life. Let's just start with Apple Intelligence

635
00:39:36,905 --> 00:39:40,835
Speaker 3:  because honestly we can get through it in 30 seconds David.

636
00:39:42,215 --> 00:39:45,875
Speaker 4:  It took me three and a half days after installing

637
00:39:46,295 --> 00:39:49,635
Speaker 4:  iOS 18.1 to realize that I had it on my phone

638
00:39:50,425 --> 00:39:53,795
Speaker 4:  because I opened up the mail app to look for something and was like, oh,

639
00:39:53,945 --> 00:39:57,835
Speaker 4:  it's doing some of the things. And that's the extent of my

640
00:39:57,835 --> 00:40:00,835
Speaker 4:  experience so far with the mail app. There's been a lot of like

641
00:40:01,475 --> 00:40:04,555
Speaker 4:  productivity apps out there that are very excited about integrating all of

642
00:40:04,555 --> 00:40:08,475
Speaker 4:  the writing tools. I'm sure they are fine and useful for some

643
00:40:08,475 --> 00:40:12,115
Speaker 4:  people. The notification summaries seem fine. I like, I cannot,

644
00:40:12,875 --> 00:40:16,315
Speaker 4:  I was prepared to be disappointed by how little was actually going on in

645
00:40:16,315 --> 00:40:20,035
Speaker 4:  this first round of Apple Intelligence and it's actually even less

646
00:40:20,395 --> 00:40:22,475
Speaker 4:  exciting than I was afraid of.

647
00:40:22,785 --> 00:40:25,155
Speaker 6:  Wait, but you use the Apple Mail app?

648
00:40:25,495 --> 00:40:29,395
Speaker 4:  No, I use it when occasionally I have to search and Gmail

649
00:40:29,975 --> 00:40:33,815
Speaker 4:  is busted. Gmail search is sometimes very good and sometimes a

650
00:40:33,815 --> 00:40:36,775
Speaker 4:  nightmare. And for whatever reason Apple Mail search is actually

651
00:40:37,535 --> 00:40:40,535
Speaker 4:  occasionally very good. So every once in a while I just wander through my

652
00:40:40,535 --> 00:40:41,215
Speaker 4:  inbox. Okay.

653
00:40:41,215 --> 00:40:44,575
Speaker 6:  Yeah. I don't use the Apple Mail app and I'm always, it's just wild to me

654
00:40:44,575 --> 00:40:47,975
Speaker 6:  that If, you use Gmail, you use the Apple Mail app, but that is not the point

655
00:40:47,975 --> 00:40:48,815
Speaker 6:  of this conversation.

656
00:40:49,845 --> 00:40:52,855
Speaker 4:  Well, but it kind of is and I think I, I've been thinking about this Tim

657
00:40:52,855 --> 00:40:56,575
Speaker 4:  Cook thing a lot since that story came out. and we, we made a lot of fun

658
00:40:56,575 --> 00:41:00,215
Speaker 4:  of Tim Cook on this show for saying he uses every Apple product every day.

659
00:41:00,995 --> 00:41:04,175
Speaker 4:  But the thing about Apple Intelligence is I think If, you

660
00:41:04,615 --> 00:41:08,415
Speaker 4:  religiously and exclusively use Apple apps, it is probably

661
00:41:08,415 --> 00:41:11,735
Speaker 4:  appearing in your life in some way. You're getting some of the writing tools,

662
00:41:11,795 --> 00:41:15,015
Speaker 4:  the keyboard stuff is popping up. It's at least like,

663
00:41:15,705 --> 00:41:19,615
Speaker 4:  maybe slightly more present. But like I do

664
00:41:19,615 --> 00:41:23,335
Speaker 4:  most of my email in Gmail, which offers me lots of other weird

665
00:41:23,555 --> 00:41:27,135
Speaker 4:  AI things that I don't need. But has essentially no awareness of Apple

666
00:41:27,135 --> 00:41:30,695
Speaker 4:  Intelligence, which is just like the, the splitting of this

667
00:41:30,695 --> 00:41:32,215
Speaker 4:  ecosystem is just getting weirder and

668
00:41:32,215 --> 00:41:35,325
Speaker 6:  Weirder. Well I think that's one of the reasons the notification stuff did

669
00:41:35,325 --> 00:41:38,645
Speaker 6:  kind of go so viral. 'cause it's like right there on your lock screen and

670
00:41:38,645 --> 00:41:42,365
Speaker 6:  you have AI straight in your face summarizing things in a

671
00:41:42,575 --> 00:41:44,605
Speaker 6:  funny or disappointing way. Right.

672
00:41:44,625 --> 00:41:48,125
Speaker 3:  But, but like, what an incredible example of how AI is not

673
00:41:48,645 --> 00:41:49,365
Speaker 3:  actually intelligent.

674
00:41:51,965 --> 00:41:55,225
Speaker 3:  That's the first thing that everyone is experiencing is notification summaries

675
00:41:55,225 --> 00:41:59,025
Speaker 3:  that have literally no context or relevance

676
00:41:59,565 --> 00:42:03,305
Speaker 3:  or understanding of what is happening. Like my ring camera

677
00:42:03,395 --> 00:42:07,385
Speaker 3:  every morning, the notification summaries just crack me up. 'cause it, it

678
00:42:07,385 --> 00:42:10,385
Speaker 3:  sounds like there's a home invasion every single day in

679
00:42:10,385 --> 00:42:13,065
Speaker 4:  My house. What was the one you shared yesterday? It was like people at the

680
00:42:13,065 --> 00:42:14,465
Speaker 4:  front door and back door and inside. Yeah. Several

681
00:42:14,465 --> 00:42:16,585
Speaker 3:  People at the front door, back door and driveway.

682
00:42:17,185 --> 00:42:20,705
Speaker 6:  Mine is right now literally And So I. Actually this I, this is why I'm here.

683
00:42:20,795 --> 00:42:24,105
Speaker 6:  Let's be honest. I'm here to talk about the ring notifications that I, that

684
00:42:24,105 --> 00:42:27,985
Speaker 6:  I, that I talked about with Craig Federighi. Well that was

685
00:42:27,985 --> 00:42:31,825
Speaker 6:  the garage notifications. But the smart home notifications are the

686
00:42:31,825 --> 00:42:35,185
Speaker 6:  best part. I don't care if they're not intelligent. They're amazing. This

687
00:42:35,185 --> 00:42:37,585
Speaker 6:  is mine from Ring right now. I'm gonna, we should, we should bring up the

688
00:42:37,585 --> 00:42:40,625
Speaker 6:  screenshot Missing dog with 99 on its back.

689
00:42:42,305 --> 00:42:45,425
Speaker 6:  Multiple people at the front door two minutes ago. Yeah. Multiple people

690
00:42:45,445 --> 00:42:49,425
Speaker 6:  are there. Yeah. Now it is a Halloween as we're taping this,

691
00:42:49,565 --> 00:42:52,945
Speaker 6:  but there's no, I'm looking at my camera. No one is there and one person

692
00:42:52,945 --> 00:42:53,465
Speaker 6:  showed up.

693
00:42:53,815 --> 00:42:54,105
Speaker 3:  Yeah,

694
00:42:54,455 --> 00:42:57,585
Speaker 6:  Well it's just, and that's because, yeah, it's because there were, you know,

695
00:42:57,585 --> 00:43:01,425
Speaker 6:  people going in and out of the house from 8:00 AM on and it

696
00:43:01,625 --> 00:43:01,905
Speaker 6:  summarizes.

697
00:43:01,925 --> 00:43:04,865
Speaker 4:  So there was one person and there was one person and there was a dog. and

698
00:43:04,865 --> 00:43:08,105
Speaker 4:  it goes, there are multiple people and a dog outside of your house. Yes.

699
00:43:08,885 --> 00:43:12,705
Speaker 3:  And it, it's funny because that is, if there was actual

700
00:43:12,705 --> 00:43:16,505
Speaker 3:  intelligence sort of noisy, smart home sensor

701
00:43:16,505 --> 00:43:20,265
Speaker 3:  notifications are exactly what you would want that intelligence to help you

702
00:43:20,265 --> 00:43:24,105
Speaker 3:  sort through. My back door opens and closes

703
00:43:24,375 --> 00:43:27,945
Speaker 3:  500 times a day and I only want

704
00:43:27,945 --> 00:43:29,105
Speaker 3:  notifications sometimes.

705
00:43:31,055 --> 00:43:34,755
Speaker 3:  And you would think in AI would be like, okay, like we see this

706
00:43:34,755 --> 00:43:38,395
Speaker 3:  pattern. We're going to, we're gonna pair this down and be like,

707
00:43:38,655 --> 00:43:41,835
Speaker 3:  the normal stuff happened this morning. This one didn't happen at the right

708
00:43:41,835 --> 00:43:44,915
Speaker 3:  time. And maybe that should be in Ring. Maybe the smart home vendor should

709
00:43:44,915 --> 00:43:48,875
Speaker 3:  do it. Maybe it should be somewhere else. But Apple Intelligence as it summarizes

710
00:43:48,875 --> 00:43:52,835
Speaker 3:  notifications, it, it's just the clearest demonstration

711
00:43:53,185 --> 00:43:56,675
Speaker 3:  that it doesn't actually know any like a, these LLMs don't actually know

712
00:43:56,675 --> 00:43:57,155
Speaker 3:  what they're talking about.

713
00:43:57,415 --> 00:44:00,755
Speaker 6:  The part that I talked about with Feder in my interview was the example I

714
00:44:00,755 --> 00:44:04,275
Speaker 6:  gave him, which was working really well for me and still does, is the garage

715
00:44:04,585 --> 00:44:08,555
Speaker 6:  because it's very, it's up and open and close and

716
00:44:08,555 --> 00:44:12,205
Speaker 6:  that's it. It open and closes all day long. And then

717
00:44:12,235 --> 00:44:16,205
Speaker 6:  there's a summary. It says it repeatedly opened and closed

718
00:44:16,345 --> 00:44:20,245
Speaker 6:  and then it was recently closed. And that usually is

719
00:44:20,245 --> 00:44:22,445
Speaker 6:  like, that's very helpful to me. Yeah.

720
00:44:22,695 --> 00:44:26,605
Speaker 4:  Isn't that exactly the same thing as just putting the one that says

721
00:44:26,635 --> 00:44:29,765
Speaker 4:  it's closed at the top of the stack, which is what it would chronologically

722
00:44:29,785 --> 00:44:32,925
Speaker 4:  do. Like what, what new problem is this solving for you?

723
00:44:33,275 --> 00:44:37,245
Speaker 6:  That I know it was opened and closed a lot of times by my family and

724
00:44:37,245 --> 00:44:39,325
Speaker 6:  then it was recently closed.

725
00:44:39,805 --> 00:44:42,805
Speaker 3:  I guess here's the question that I've been thinking a lot about and it, every

726
00:44:42,805 --> 00:44:45,685
Speaker 3:  time I'm forced to reconsider the amount of smart home notifications I get,

727
00:44:46,445 --> 00:44:49,165
Speaker 3:  I ask myself, do I need to know this?

728
00:44:50,265 --> 00:44:54,125
Speaker 3:  Do I need to know that Max went in and outta the house 50 times through the

729
00:44:54,125 --> 00:44:57,485
Speaker 3:  back door? Like that's just, my parents didn't know that in the eighties.

730
00:44:57,555 --> 00:45:01,275
Speaker 3:  They, they had no idea where I was to be clear.

731
00:45:01,735 --> 00:45:05,195
Speaker 3:  And I'm like, actually I don't need all this additional help and this AI

732
00:45:06,095 --> 00:45:08,955
Speaker 3:  and we should get off smart home notification. 'cause it's a, it's a little

733
00:45:08,955 --> 00:45:12,635
Speaker 3:  corner case. It is very funny. I do think it's a good demonstration of the

734
00:45:12,635 --> 00:45:16,275
Speaker 3:  fact that LMS don't actually know what they're talking about, but in this

735
00:45:16,275 --> 00:45:20,195
Speaker 3:  case it's almost blinding how useless most of these

736
00:45:20,195 --> 00:45:22,915
Speaker 3:  notifications are. And the only thing that's happened is because they're

737
00:45:22,995 --> 00:45:25,355
Speaker 3:  slightly different. You're paying attention to them again and you're like,

738
00:45:25,355 --> 00:45:28,875
Speaker 3:  oh, this is still useless. And I will just quickly start tuning them out

739
00:45:29,295 --> 00:45:32,035
Speaker 3:  the way that I tune out most of my smart home notifications,

740
00:45:32,395 --> 00:45:36,365
Speaker 6:  I was just on the road for 10 days and I didn't turn off my smart

741
00:45:36,365 --> 00:45:40,255
Speaker 6:  home notifications. Oh my God. And maybe there's

742
00:45:40,255 --> 00:45:44,135
Speaker 6:  an emotional attach, like I feel a deeply emotional like

743
00:45:44,135 --> 00:45:47,895
Speaker 6:  with these because I'm not at home deeply emotional. Some

744
00:45:47,895 --> 00:45:49,975
Speaker 6:  emotional attachment to these smart home notifications, your

745
00:45:49,985 --> 00:45:51,495
Speaker 3:  Connection to your family, to your

746
00:45:51,515 --> 00:45:55,215
Speaker 6:  Two children. My only connection to my family for 10, 10 days, and that's

747
00:45:55,215 --> 00:45:59,135
Speaker 6:  where I'm going with this, was was seeing these smart home

748
00:45:59,135 --> 00:46:03,055
Speaker 6:  notifications went so dark. This

749
00:46:03,055 --> 00:46:06,855
Speaker 6:  is really symbolic and they mean a lot to me. And I'm not going to let them

750
00:46:06,875 --> 00:46:10,695
Speaker 6:  go. And I would like to thank Apple Intelligence for resurfacing

751
00:46:10,695 --> 00:46:11,375
Speaker 6:  them in my life.

752
00:46:11,815 --> 00:46:15,215
Speaker 3:  I feel like my children are here. You give a speech

753
00:46:16,275 --> 00:46:17,895
Speaker 4:  Closed, you know, Joanna's like, oh,

754
00:46:17,915 --> 00:46:21,695
Speaker 3:  20 years ago when I saw that first smart notification

755
00:46:21,695 --> 00:46:25,225
Speaker 3:  with your, with your partner. I knew they were the one.

756
00:46:25,965 --> 00:46:28,905
Speaker 4:  Joanna, I'm gonna make you like a yearbook of your kids. But it's just gonna

757
00:46:28,905 --> 00:46:30,665
Speaker 4:  be smart home notifications about what they're

758
00:46:30,665 --> 00:46:34,025
Speaker 6:  Doing. It's so true. It'll be like, it'll be like child playing

759
00:46:34,025 --> 00:46:36,665
Speaker 6:  basketball on front, on front garage or

760
00:46:38,435 --> 00:46:42,385
Speaker 6:  child now driving to prom. Yeah. It's

761
00:46:42,535 --> 00:46:46,305
Speaker 6:  child's now bringing home man or woman and

762
00:46:46,305 --> 00:46:49,465
Speaker 3:  They're gonna play that one Green Day song in the background as we do a slides

763
00:46:49,465 --> 00:46:50,145
Speaker 3:  show. It's gonna be

764
00:46:50,145 --> 00:46:53,945
Speaker 6:  Amazing. And Apple intelligence will slowly get more intelligent. As

765
00:46:53,945 --> 00:46:57,905
Speaker 6:  Craig Federici said, this is a decades long arc Yeah. To getting it

766
00:46:57,905 --> 00:46:59,025
Speaker 6:  better. That's a direct quote.

767
00:46:59,645 --> 00:47:02,705
Speaker 3:  So I, I wanna come back to that conversation after Craig, which was a couple

768
00:47:02,705 --> 00:47:06,545
Speaker 3:  weeks ago at the WSJ Tech live conference. I just wanna say notification

769
00:47:06,545 --> 00:47:10,225
Speaker 3:  summaries for one more second outside of smart home stuff. The other promise

770
00:47:10,365 --> 00:47:14,065
Speaker 3:  is we're gonna summarize your emails, we're gonna summarize Slack, whatever

771
00:47:14,075 --> 00:47:18,065
Speaker 3:  other notifications you are getting. Has that been useful? Because

772
00:47:18,345 --> 00:47:21,505
Speaker 3:  I will tell you, I laughed at it for a day or two and then turned them off

773
00:47:21,975 --> 00:47:25,945
Speaker 3:  because I actually found those notifications because I actually found the

774
00:47:25,945 --> 00:47:29,765
Speaker 3:  summaries to be more confusing. Like ultimately they were more distracting.

775
00:47:29,885 --> 00:47:33,165
Speaker 3:  'cause I was like, what is going on here? I got one from the family group

776
00:47:33,165 --> 00:47:36,845
Speaker 3:  chat that just said my niece was jealous and felt left out and it

777
00:47:37,065 --> 00:47:40,445
Speaker 3:  all, it was, was her friends were going to an event.

778
00:47:40,995 --> 00:47:43,725
Speaker 3:  Like she was just saying, I'm they're going and I'm jealous and I'm not going

779
00:47:43,725 --> 00:47:46,485
Speaker 3:  to this concert. And that was it. and it was like other otherwise totally

780
00:47:46,845 --> 00:47:50,765
Speaker 3:  normal except the summary made it seem like the highest stakes thing

781
00:47:50,765 --> 00:47:51,085
Speaker 3:  in the world.

782
00:47:51,395 --> 00:47:55,325
Speaker 6:  Yeah. My mom sent me like a really emotional text. She had to go to a funeral

783
00:47:55,465 --> 00:47:59,405
Speaker 6:  and it was a whole thing and then it just said expresses gratitude and

784
00:47:59,405 --> 00:48:03,245
Speaker 6:  it was like really, really long, like very long amount of

785
00:48:03,335 --> 00:48:07,285
Speaker 6:  texts and I was like, oh, okay. I mean, yeah, I think the question

786
00:48:07,285 --> 00:48:10,885
Speaker 6:  is they're funny and the point of them is to save time,

787
00:48:11,505 --> 00:48:14,725
Speaker 6:  but they're not saving any time because you then go and read the full thing

788
00:48:14,825 --> 00:48:18,085
Speaker 6:  anyway, so it doesn't really achieve anything. Well

789
00:48:18,085 --> 00:48:21,885
Speaker 4:  It's that, it's that okay thing that is actually, I think in a weird way,

790
00:48:21,885 --> 00:48:25,765
Speaker 4:  like the intended response and is also why I hate it

791
00:48:25,765 --> 00:48:29,645
Speaker 4:  for texting. I actually think it's useful for email in the sense that you

792
00:48:29,645 --> 00:48:33,565
Speaker 4:  get a lot of email and a huge portion of it. All you really need to know

793
00:48:33,565 --> 00:48:37,365
Speaker 4:  is that it exists. Yeah. Right. Like it, it is, it is some piece of

794
00:48:37,365 --> 00:48:40,845
Speaker 4:  information that you need to be made aware of or some kind of like confirmation

795
00:48:40,845 --> 00:48:44,125
Speaker 4:  or status check. And that's the kind of thing you can take from a giant long

796
00:48:44,125 --> 00:48:46,965
Speaker 4:  email into eight words and I can just be like tight and go on living my life.

797
00:48:47,275 --> 00:48:50,565
Speaker 4:  What I have discovered with the AI summaries for text messages is they've

798
00:48:50,565 --> 00:48:54,245
Speaker 4:  made me such a worse texter really. And I'm a bad texter

799
00:48:54,265 --> 00:48:58,245
Speaker 4:  anyway, but the just the thing where I have to open a message in order

800
00:48:58,245 --> 00:49:02,125
Speaker 4:  to understand what is in the message goes a long way toward

801
00:49:02,145 --> 00:49:06,085
Speaker 4:  me being a reliable responder to that message. And so now I'm getting

802
00:49:06,125 --> 00:49:09,845
Speaker 4:  a lot of things where it's just like, the message is just like mom

803
00:49:10,105 --> 00:49:13,885
Speaker 4:  on her way. And I'm like, all right. And I just move on and I'm like, no

804
00:49:13,885 --> 00:49:15,005
Speaker 4:  crap, I have to respond. All

805
00:49:15,005 --> 00:49:16,365
Speaker 3:  You are to me is a status update.

806
00:49:17,255 --> 00:49:21,165
Speaker 4:  Right. It's like it's, it's, it's not even as good as

807
00:49:21,165 --> 00:49:25,125
Speaker 4:  like the tap back emojis. It's just, it's just me saying, okay, I

808
00:49:25,125 --> 00:49:29,005
Speaker 4:  can now move on because I've been given this personality free piece of

809
00:49:29,005 --> 00:49:32,005
Speaker 4:  information and then it's like, oh no, that's a text from my mom. I should

810
00:49:32,005 --> 00:49:35,805
Speaker 4:  go respond to that. And that, that is, I turned that off immediately because

811
00:49:35,805 --> 00:49:39,405
Speaker 4:  it was like preventing me from actually engaging, I actually think with messages

812
00:49:39,625 --> 00:49:42,565
Speaker 6:  And to, yeah, to that point, So I found the text from my mom. It was really

813
00:49:42,565 --> 00:49:44,805
Speaker 6:  long. It was, it was, you know, it's like one of those from your parents.

814
00:49:44,805 --> 00:49:47,445
Speaker 6:  It's like, you know, they don't send it in chunks, they just send it all.

815
00:49:47,445 --> 00:49:49,485
Speaker 6:  Like, they wrote a long, long letter. I don't know if,

816
00:49:49,555 --> 00:49:51,285
Speaker 4:  Does she sign her messages at the end? She she

817
00:49:51,285 --> 00:49:54,005
Speaker 6:  Does. She's she's better about that. But it, it just said, reflecting on

818
00:49:54,005 --> 00:49:57,485
Speaker 6:  life, expressing gratitude and wishing a safe trip home.

819
00:49:58,465 --> 00:50:02,005
Speaker 6:  And I found that so funny that I sent her the, the summary

820
00:50:02,945 --> 00:50:06,005
Speaker 6:  and said, look how this summarized it. And I never actually responded to

821
00:50:06,005 --> 00:50:07,285
Speaker 6:  her long thoughtful note.

822
00:50:09,705 --> 00:50:09,925
Speaker 6:  You

823
00:50:09,925 --> 00:50:11,045
Speaker 4:  Just sent her a screenshot.

824
00:50:11,325 --> 00:50:12,725
Speaker 6:  I was like, look how it edited you.

825
00:50:13,625 --> 00:50:14,805
Speaker 4:  You're like, this is so meaningful.

826
00:50:14,825 --> 00:50:17,885
Speaker 6:  And she wrote back, she's like, I guess I could have been shorter. You know,

827
00:50:17,885 --> 00:50:18,125
Speaker 6:  like,

828
00:50:19,545 --> 00:50:23,045
Speaker 3:  So, you know, it's funny is a bigger feature in iOS 18 for me is send later

829
00:50:23,185 --> 00:50:25,925
Speaker 3:  in messages. Oh yeah. Because I never

830
00:50:27,155 --> 00:50:31,085
Speaker 3:  want to be the person who replies instantly, even though I see a

831
00:50:31,085 --> 00:50:34,445
Speaker 3:  lot of things. And yeah, I just being able to like send this in five more

832
00:50:34,445 --> 00:50:38,365
Speaker 3:  minutes makes me reply to more messages. It's a little hidden. They got

833
00:50:38,365 --> 00:50:41,365
Speaker 3:  it wrong. They got the UI wrong. They should have done it the way that Slack

834
00:50:41,365 --> 00:50:45,205
Speaker 3:  does it, which is you just hold down the send button and it, like, once you

835
00:50:45,365 --> 00:50:47,645
Speaker 3:  schedule it, you gotta like dig through the menus. Find

836
00:50:47,645 --> 00:50:49,085
Speaker 6:  You gotta go to the plus button. Yeah.

837
00:50:49,155 --> 00:50:52,205
Speaker 3:  Yeah. It's a little, it's a little messy, but it works. And that is like,

838
00:50:52,625 --> 00:50:55,925
Speaker 3:  to your point, David, it makes, it takes me out of the this as a status message.

839
00:50:56,515 --> 00:51:00,005
Speaker 3:  I've like seen and done it. I've taken the action and then I've moved on.

840
00:51:00,225 --> 00:51:03,845
Speaker 3:  And because there's, I might be bonkers about this, but

841
00:51:04,185 --> 00:51:08,005
Speaker 3:  my feeling is like, if there's a little delay in the response, it makes it

842
00:51:08,005 --> 00:51:10,965
Speaker 3:  so that we are not about to have a conversation. Like I've just answered

843
00:51:11,035 --> 00:51:11,805
Speaker 3:  your question. That's

844
00:51:11,805 --> 00:51:14,285
Speaker 6:  So smart. I was about to say like, who are you playing it cool with?

845
00:51:14,865 --> 00:51:17,965
Speaker 3:  But then I play cool with everybody all the time. Yeah. All of NE's texts

846
00:51:17,965 --> 00:51:21,805
Speaker 3:  say, send this in three tickets. Sorry, I didn't see this. I

847
00:51:21,805 --> 00:51:24,885
Speaker 3:  write, sorry, I didn't see this immediately. And then schedule it for a couple

848
00:51:24,885 --> 00:51:25,365
Speaker 3:  days from now.

849
00:51:25,585 --> 00:51:29,445
Speaker 6:  But actually that's genius because you are, you are indicating to the, to

850
00:51:29,445 --> 00:51:33,205
Speaker 6:  the receiver, Hey, I'm not like available right now. Like, oh,

851
00:51:33,205 --> 00:51:36,205
Speaker 6:  like I'm in the middle of something super important even though I just sat

852
00:51:36,205 --> 00:51:40,125
Speaker 6:  here and scheduled my message. But you're, you're, you're unavailable. Like

853
00:51:40,125 --> 00:51:43,045
Speaker 6:  you're available but you're not available. Your is your signal, which

854
00:51:43,045 --> 00:51:45,885
Speaker 3:  Is Right. I'm, I'm being responsive. But this is not about to be a chat.

855
00:51:45,955 --> 00:51:48,925
Speaker 3:  Like, I'm just letting you know that they, and I have a, the, an infinite

856
00:51:48,925 --> 00:51:52,645
Speaker 3:  amount of incoming where I just need to deliver an answer

857
00:51:53,145 --> 00:51:57,085
Speaker 3:  and not have like a 25 minute conversation. And that's fine. And like

858
00:51:57,085 --> 00:52:00,165
Speaker 3:  people always see screenshots of my home screen. And it's always just like

859
00:52:00,865 --> 00:52:04,405
Speaker 3:  so many unreads and it's like, this is what the

860
00:52:04,665 --> 00:52:07,925
Speaker 3:  AI should help me do is be like, you're just gonna parse through all of these.

861
00:52:07,925 --> 00:52:10,165
Speaker 3:  We figured out the ones you need to answer. We're gonna help you get through

862
00:52:10,165 --> 00:52:13,565
Speaker 3:  it. And instead these summaries I think are just not useful. And I,

863
00:52:14,285 --> 00:52:17,845
Speaker 3:  I, I keep coming back to like, we've invented LLMs. We are

864
00:52:17,845 --> 00:52:21,605
Speaker 3:  desperate for them to solve problems. This problem seems

865
00:52:21,605 --> 00:52:25,125
Speaker 3:  solvable. And then you like sit here holding the solution in your hand and

866
00:52:25,125 --> 00:52:28,895
Speaker 3:  you're like, yeah, the door opened and closed a lot. Right. You know,

867
00:52:28,895 --> 00:52:32,775
Speaker 3:  like, actually send later, which we could have invented 10 years ago,

868
00:52:33,315 --> 00:52:36,455
Speaker 3:  is much more useful than the notification summary. Apple

869
00:52:36,535 --> 00:52:40,335
Speaker 6:  Intelligence does include in this, the prioritize priority

870
00:52:40,335 --> 00:52:44,255
Speaker 6:  notifications where the, it is supposed to help. I haven't used it

871
00:52:44,255 --> 00:52:47,375
Speaker 6:  a lot. In fact, I probably should have turned that on here instead of do

872
00:52:47,375 --> 00:52:48,415
Speaker 6:  not disturb for the podcast.

873
00:52:49,935 --> 00:52:52,735
Speaker 6:  I used it once during, I was on a video shoot and it did, I mean, it did

874
00:52:52,805 --> 00:52:56,775
Speaker 6:  send, it did prioritize like notifications for my wife and family

875
00:52:57,195 --> 00:53:00,215
Speaker 6:  and like group chats over Slacks.

876
00:53:00,575 --> 00:53:02,935
Speaker 3:  Children continue to grow up in the background

877
00:53:03,205 --> 00:53:07,175
Speaker 6:  Over my ring notifications that I, I'm deeply emotionally attached

878
00:53:07,175 --> 00:53:07,375
Speaker 6:  to.

879
00:53:09,505 --> 00:53:11,115
Speaker 6:  Yeah. I'm gonna put that on right now. Have

880
00:53:11,115 --> 00:53:15,075
Speaker 3:  You used any of the other IS 18.1 Apple Intelligence

881
00:53:15,355 --> 00:53:17,955
Speaker 3:  features? For real? I feel like the notifications are the ones everyone's

882
00:53:17,955 --> 00:53:20,275
Speaker 3:  using for real because of what you said, Joanna, they're just in your face.

883
00:53:21,015 --> 00:53:23,675
Speaker 3:  But the writing tools, the image tools

884
00:53:25,835 --> 00:53:29,725
Speaker 3:  fine. Like I'm, I'm a very precious writer.

885
00:53:29,865 --> 00:53:33,805
Speaker 3:  I'm just, I'm not really fond of letting AI write for me. I I've avoided

886
00:53:33,805 --> 00:53:36,605
Speaker 3:  them mostly. They're a little buried. They're not in your face.

887
00:53:37,485 --> 00:53:40,145
Speaker 4:  No, they're not. But I will say I've, I've just come to realize that I'm

888
00:53:40,205 --> 00:53:43,665
Speaker 4:  not the target audience for the writing tools and that's fun. Yep. Right.

889
00:53:43,685 --> 00:53:47,065
Speaker 4:  Agreed. We're we're three people who write sentences for a living and that

890
00:53:47,065 --> 00:53:50,065
Speaker 4:  is not actually most people. And so like, I'm, that's just, that's fine.

891
00:53:50,065 --> 00:53:53,865
Speaker 6:  Yeah. I've used it like in notes. Like I'll sometimes draft like PR

892
00:53:54,435 --> 00:53:58,225
Speaker 6:  notes and stuff in notes and so I've used it there, but I don't find it that

893
00:53:58,225 --> 00:54:01,945
Speaker 6:  it's like doing much for me. I mean, I use notes a lot.

894
00:54:02,105 --> 00:54:05,545
Speaker 6:  I use the Notes app a lot. But that's another place, like, like

895
00:54:06,025 --> 00:54:09,745
Speaker 6:  I felt, I felt like the list and the summarization tool might be helpful.

896
00:54:10,465 --> 00:54:13,505
Speaker 6:  'cause like sometimes I like make sloppy lists and like, okay, clean up the

897
00:54:13,505 --> 00:54:17,145
Speaker 6:  list. But then it just, like, it adds bullets in front of my dashes

898
00:54:17,365 --> 00:54:21,305
Speaker 6:  and like, I've already had dashes in my list and then I

899
00:54:21,305 --> 00:54:22,065
Speaker 6:  just had put

900
00:54:22,065 --> 00:54:25,945
Speaker 3:  List, these are problems that the very basic algorithms in Microsoft Word

901
00:54:25,945 --> 00:54:27,985
Speaker 3:  solved 25 years ago. Yeah.

902
00:54:28,045 --> 00:54:30,945
Speaker 6:  But then it added bullets in front of my dashes and that's, I never used

903
00:54:30,945 --> 00:54:31,305
Speaker 6:  it again.

904
00:54:31,525 --> 00:54:35,505
Speaker 3:  I'm just telling you like if there were podcasts in like 1986, we would've

905
00:54:35,505 --> 00:54:39,265
Speaker 3:  been like, I don't know, it's this, it is New Mac, like sadden

906
00:54:39,265 --> 00:54:40,385
Speaker 3:  dashes to the bullets.

907
00:54:42,465 --> 00:54:46,145
Speaker 3:  I have used the call recorder with the AI transcription. Oh yeah. It's very

908
00:54:46,145 --> 00:54:46,385
Speaker 3:  good.

909
00:54:46,935 --> 00:54:49,265
Speaker 4:  It's really, it's very, yeah, that was the one I was gonna say too. And you

910
00:54:49,265 --> 00:54:52,545
Speaker 4:  can do a voice memo and dump it into notes with the transcription, which

911
00:54:52,545 --> 00:54:54,825
Speaker 4:  is very handy. Like yes. That stuff is very cool. Well,

912
00:54:55,305 --> 00:54:58,785
Speaker 6:  I would say the summary is not good. I don't know. If you found the summary

913
00:54:58,845 --> 00:55:02,705
Speaker 6:  to be good, which is the actual intelligence. Yeah. But just having the

914
00:55:02,705 --> 00:55:05,865
Speaker 6:  transcription there, which is not an Apple intelligence feature, and you

915
00:55:05,865 --> 00:55:09,225
Speaker 6:  can get that, I think going back to iPhone thirteens or something like that.

916
00:55:09,225 --> 00:55:10,145
Speaker 6:  There's a cutoff on

917
00:55:10,145 --> 00:55:13,825
Speaker 3:  This. Wait, they're, they're not using any LLM stuff to make the transcriptions

918
00:55:13,825 --> 00:55:17,775
Speaker 3:  better because like, you know, like OpenAI has Whisper, which is

919
00:55:17,795 --> 00:55:21,255
Speaker 3:  its AI powered transcription. Right. and it, there are some reports that

920
00:55:21,255 --> 00:55:23,935
Speaker 3:  it's inaccurate in some of its cases. I think there was one about people

921
00:55:23,935 --> 00:55:24,975
Speaker 3:  using hospitals, right.

922
00:55:24,975 --> 00:55:25,615
Speaker 6:  In hospitals. Yeah.

923
00:55:25,635 --> 00:55:28,975
Speaker 3:  And it's not being great, which is not great. And also just a classic AI

924
00:55:29,025 --> 00:55:32,935
Speaker 3:  story, but it's better. I think the, the stat I saw is that the

925
00:55:33,195 --> 00:55:37,055
Speaker 3:  AI transcription systems are now on average better than

926
00:55:37,055 --> 00:55:38,775
Speaker 3:  the worst. Human transcriptions

927
00:55:39,245 --> 00:55:43,015
Speaker 4:  Whisper's really good, right? Like I've, I've been using Whisper a ton. We

928
00:55:43,015 --> 00:55:46,815
Speaker 4:  use it a ton for Vergecast stuff and it's really good. I'm not

929
00:55:46,815 --> 00:55:50,695
Speaker 4:  surprised, like a hospital is the ultimate stress test of anything. It's

930
00:55:50,695 --> 00:55:53,895
Speaker 4:  just full of words that don't exist outside of hospitals.

931
00:55:54,915 --> 00:55:57,415
Speaker 4:  And so that's always gonna be tough and you should never rely on these systems

932
00:55:57,495 --> 00:56:01,175
Speaker 4:  a hundred percent. But like all of this speech to text and

933
00:56:01,365 --> 00:56:04,775
Speaker 4:  even basic summarization stuff has gotten pretty good.

934
00:56:05,545 --> 00:56:09,535
Speaker 4:  Apple intelligence, I would not say is leading the summarization game.

935
00:56:09,535 --> 00:56:12,495
Speaker 4:  Yeah. But a lot of that stuff is, is pretty good at this point.

936
00:56:12,735 --> 00:56:16,615
Speaker 6:  I mean, this is it. I do think that there's no AI

937
00:56:16,615 --> 00:56:20,215
Speaker 6:  in the, I mean there's obviously an AI model that is on device that's doing

938
00:56:20,215 --> 00:56:23,885
Speaker 6:  the transcription, but like anyone, you don't need Apple intelligence to

939
00:56:23,885 --> 00:56:24,085
Speaker 6:  do that,

940
00:56:24,295 --> 00:56:24,645
Speaker 3:  Right?

941
00:56:25,225 --> 00:56:27,565
Speaker 6:  As that's what I'm reading right now, just to confirm what I said before.

942
00:56:27,585 --> 00:56:30,485
Speaker 6:  So yes, the summarization part is Apple intelligence

943
00:56:30,925 --> 00:56:32,005
Speaker 3:  And that's the part that's not very

944
00:56:32,005 --> 00:56:34,645
Speaker 6:  Good and that's the part that's not very good. But the part that is really

945
00:56:34,645 --> 00:56:38,005
Speaker 6:  good, that is, it really is a game changer for me. It's like, yeah, some,

946
00:56:38,025 --> 00:56:41,605
Speaker 6:  you know, source just calls or I'm doing a quick and I'm Oh, hit record,

947
00:56:42,305 --> 00:56:45,805
Speaker 6:  it works great and the transcription's fine. It Yeah. You know, you at least

948
00:56:45,805 --> 00:56:48,485
Speaker 6:  can go like, it's great for scrolling and saying, oh, that's the part I need

949
00:56:48,485 --> 00:56:48,645
Speaker 6:  to talk

950
00:56:48,645 --> 00:56:51,205
Speaker 3:  To. Yeah. To find the audio I need. Yep. Right. Yep. And this is very, again,

951
00:56:51,265 --> 00:56:54,125
Speaker 3:  to David's point, this is three people who just like do this task all the

952
00:56:54,125 --> 00:56:57,885
Speaker 3:  time. And this is very useful, but it is a useful upgrade

953
00:56:57,945 --> 00:57:01,685
Speaker 3:  to iOS 18. Everybody who has a pixel phone or an Android

954
00:57:01,685 --> 00:57:04,605
Speaker 3:  phone. Yes. I'm aware that these phones have had this stuff and it has been

955
00:57:04,605 --> 00:57:07,605
Speaker 3:  great for a long time. Yeah. I'm just looking at this sweep of things that

956
00:57:07,605 --> 00:57:11,325
Speaker 3:  have been added to my phone with iOS 18.1 and Apple Intelligence.

957
00:57:11,705 --> 00:57:15,525
Speaker 3:  And it's like this stuff, which I just keep coming back to is the

958
00:57:15,525 --> 00:57:19,205
Speaker 3:  basics. Yeah. Should we be able to figure out when to add bullets instead

959
00:57:19,205 --> 00:57:22,125
Speaker 3:  of dashes instead of adding them both solved problem?

960
00:57:23,025 --> 00:57:25,925
Speaker 3:  Should we be able to send messages later solved problem?

961
00:57:26,665 --> 00:57:29,485
Speaker 3:  Should my phone app have a call recorder and it that does reasonably good

962
00:57:29,485 --> 00:57:32,925
Speaker 3:  transition solve problem? But now we're bundling them all up into Apple intelligence,

963
00:57:33,225 --> 00:57:36,365
Speaker 3:  but obviously the developer betas of iOS 18.2

964
00:57:37,145 --> 00:57:40,965
Speaker 3:  out at the same time. So there's a real mash of what people are

965
00:57:40,965 --> 00:57:44,045
Speaker 3:  looking at, what people are talking about. The more interesting features

966
00:57:44,045 --> 00:57:47,405
Speaker 3:  are in 18.2, visual intelligence chat, CBT integration,

967
00:57:48,485 --> 00:57:52,285
Speaker 3:  I guess, we'll, we'll wait on that, but it's here. You know, we, we, a,

968
00:57:52,485 --> 00:57:56,205
Speaker 3:  a big conversation we were having, and Joan, I'm curious how you have thought

969
00:57:56,205 --> 00:57:59,525
Speaker 3:  about this is we reviewed the phones without Apple intelligence in them 'cause

970
00:57:59,525 --> 00:58:02,845
Speaker 3:  of our rule review what's in the box. And then we're like, maybe we have

971
00:58:02,845 --> 00:58:06,805
Speaker 3:  to re-review them now that it's here. And I'm kind of like, but you don't,

972
00:58:07,225 --> 00:58:11,005
Speaker 3:  no, because there's nothing like, I don't know what to say about that. What

973
00:58:11,005 --> 00:58:12,365
Speaker 3:  are you gonna do? Oh

974
00:58:12,785 --> 00:58:16,025
Speaker 6:  No, I'm, I'm, I'm done with coverage. We've, we done now

975
00:58:16,765 --> 00:58:17,385
Speaker 6:  we done now

976
00:58:18,405 --> 00:58:18,625
Speaker 3:  All

977
00:58:18,625 --> 00:58:22,145
Speaker 6:  Done 18.2. Yeah. I'll revisit

978
00:58:22,405 --> 00:58:25,985
Speaker 6:  and maybe there's some significant stuff there. Let's just talk about the

979
00:58:25,985 --> 00:58:29,815
Speaker 6:  most important thing that was added in 18.1. And I, I

980
00:58:29,815 --> 00:58:31,655
Speaker 6:  mentioned this when I did your installer.

981
00:58:33,405 --> 00:58:37,255
Speaker 6:  When I, what's my installer thing that I submitted the, anyway, I don't know

982
00:58:37,255 --> 00:58:39,535
Speaker 6:  your home, just your home screen. My home screen that yeah, that section

983
00:58:40,235 --> 00:58:44,015
Speaker 6:  in 18.1. You can finally in control center, add

984
00:58:44,655 --> 00:58:45,935
Speaker 6:  a wifi widget.

985
00:58:47,455 --> 00:58:47,675
Speaker 4:  Yes.

986
00:58:47,775 --> 00:58:51,755
Speaker 6:  Or control. So again, probably something they would've talked about

987
00:58:52,055 --> 00:58:54,835
Speaker 6:  in, what was it, 86 you mentioned on the podcast

988
00:58:55,535 --> 00:58:56,595
Speaker 3:  You had a wifi widget

989
00:58:56,815 --> 00:59:00,795
Speaker 6:  On the screen. You can actually just do the wifi and now

990
00:59:00,795 --> 00:59:02,595
Speaker 6:  you can just do the wifi and it's amazing.

991
00:59:04,405 --> 00:59:08,125
Speaker 4:  Strongly agree. It's control center. I set mine up

992
00:59:08,535 --> 00:59:11,685
Speaker 4:  after you sent me your home screen being like, control center's. The greatest

993
00:59:11,685 --> 00:59:13,765
Speaker 4:  thing that ever happened to me. I was like, all right, cool. Whatever Joanna,

994
00:59:14,185 --> 00:59:17,765
Speaker 4:  you're right. It's great. I now spend a lot of time just like mucking around

995
00:59:17,765 --> 00:59:18,365
Speaker 4:  in control center

996
00:59:18,365 --> 00:59:19,845
Speaker 6:  Doing stuff because smart home stuff,

997
00:59:20,405 --> 00:59:24,305
Speaker 3:  I feel like the control center is Apple with. They're like, fine, you

998
00:59:24,305 --> 00:59:28,025
Speaker 3:  want customization? Here's what it's like. And then next year they'll be

999
00:59:28,025 --> 00:59:31,785
Speaker 3:  like, we're we're going back to telling you exactly how this works because

1000
00:59:31,855 --> 00:59:34,025
Speaker 3:  it's obviously crazy to do it this way.

1001
00:59:34,415 --> 00:59:36,065
Speaker 6:  Well there's one like me Murphy, it's

1002
00:59:36,075 --> 00:59:37,465
Speaker 3:  Going arounds. You're getting what you wished for

1003
00:59:38,085 --> 00:59:41,705
Speaker 6:  And somebody's just put wifi controls, the entire control center's wifi

1004
00:59:41,705 --> 00:59:44,945
Speaker 6:  controls. and it's like, that's dream. That's exactly what you're talking

1005
00:59:44,945 --> 00:59:47,385
Speaker 6:  about. And you're like, they're like, you wanted customization. Look at this.

1006
00:59:47,415 --> 00:59:49,185
Speaker 6:  Look at this asshole. Look what he's done. Yeah. Oh yeah.

1007
00:59:49,185 --> 00:59:51,545
Speaker 4:  It's the same with all the colors and stuff. Oh. They're like, oh, you, you

1008
00:59:51,545 --> 00:59:54,105
Speaker 4:  want your phone to be ugly? Knock yourself out. Have an ugly phone. Finally

1009
00:59:54,155 --> 00:59:55,305
Speaker 4:  enjoy your ugly phone. Finally, the

1010
00:59:55,305 --> 00:59:56,345
Speaker 3:  IPhone is brown. Like

1011
00:59:56,725 --> 01:00:00,665
Speaker 4:  You'll never ever figure out how to do it except by accident. But

1012
01:00:00,905 --> 01:00:01,465
Speaker 4:  Godspeed.

1013
01:00:02,005 --> 01:00:05,985
Speaker 3:  All right. That's iOS 18.1 Apple intelligence. It is a baby

1014
01:00:06,055 --> 01:00:09,585
Speaker 3:  step. As Craig told Joanna, you shall go watch that video of that interview.

1015
01:00:09,585 --> 01:00:13,425
Speaker 3:  It's very good. We gotta mostly talk about his garage door open our situation.

1016
01:00:13,425 --> 01:00:17,385
Speaker 3:  But we'll come to that. The other Apple news is the

1017
01:00:17,385 --> 01:00:20,745
Speaker 3:  week of max, which is mostly just spec bumps.

1018
01:00:21,245 --> 01:00:23,985
Speaker 3:  The new IMAX have an M four chip in them.

1019
01:00:24,775 --> 01:00:28,545
Speaker 3:  They're very nice. The new MacBook Pros have M four Pros and M four Max chips

1020
01:00:28,545 --> 01:00:31,985
Speaker 3:  in them. Very nice. There's new colors on the imax, which are very bold.

1021
01:00:31,985 --> 01:00:34,625
Speaker 3:  We have some beautiful pictures that Vier and we took of them, you know,

1022
01:00:34,625 --> 01:00:37,345
Speaker 3:  look at those. But they're the same. They're just spec bumps, right? New

1023
01:00:37,345 --> 01:00:40,815
Speaker 3:  chips. It's the MAC mini that's got everybody just

1024
01:00:41,075 --> 01:00:44,975
Speaker 3:  raving. It's like little baby Mac M four chip in

1025
01:00:44,975 --> 01:00:48,855
Speaker 3:  it. It's very small. It's, it's the same volume I think as the outgoing

1026
01:00:48,855 --> 01:00:52,485
Speaker 3:  Mac Mini, but it's taller instead of, it's like they un smed the

1027
01:00:52,485 --> 01:00:52,885
Speaker 3:  pancake.

1028
01:00:53,505 --> 01:00:56,965
Speaker 6:  I'm sorry to interrupt, but I did put on the priority

1029
01:00:56,965 --> 01:01:00,885
Speaker 6:  notifications or the whatever it is, reduced interruptions where Apple intelligence

1030
01:01:00,885 --> 01:01:04,805
Speaker 6:  is supposed to then surface the important notifications. And this is

1031
01:01:04,805 --> 01:01:08,365
Speaker 6:  just a chain of moms talking about when we are gonna be going trick or treating.

1032
01:01:08,905 --> 01:01:11,005
Speaker 3:  And that's a priority to interrupt our whole show with.

1033
01:01:11,145 --> 01:01:15,005
Speaker 6:  And I never ever respond quickly to these chain of moms to be clear,

1034
01:01:15,245 --> 01:01:19,005
Speaker 6:  I mean, if the chain of moms are listening to this, I'm sorry

1035
01:01:19,595 --> 01:01:22,125
Speaker 6:  that I usually mute the channel, but

1036
01:01:22,985 --> 01:01:25,445
Speaker 3:  Joanna, first of all, I don't think you understand how many New Jersey moms

1037
01:01:25,445 --> 01:01:27,885
Speaker 3:  listen to our show. That's a demo. I

1038
01:01:28,065 --> 01:01:30,925
Speaker 6:  Why, why I'm here. I'm here to bring them to the show.

1039
01:01:31,515 --> 01:01:35,045
Speaker 3:  Also, chain of Moms sounds like a doop group. And you should

1040
01:01:35,405 --> 01:01:36,605
Speaker 3:  absolutely start that immediately

1041
01:01:36,605 --> 01:01:40,405
Speaker 6:  Anyway. If we are doing a live review of Apple Intelligence, which I thought

1042
01:01:40,405 --> 01:01:43,485
Speaker 6:  we were doing on this show, I interrupt the show to tell you this chain of

1043
01:01:43,555 --> 01:01:46,365
Speaker 6:  moms is, it's now blowing up my phone and Apple Intelligence seems to think

1044
01:01:46,445 --> 01:01:50,285
Speaker 6:  I care. It says maybe important, maybe I, it's actually

1045
01:01:50,285 --> 01:01:51,245
Speaker 6:  really not important.

1046
01:01:51,725 --> 01:01:54,725
Speaker 3:  I do like our new segment where you just read us your notifications from

1047
01:01:54,725 --> 01:01:56,445
Speaker 3:  time to time on the air. We're gonna keep that going.

1048
01:01:56,955 --> 01:01:58,325
Speaker 6:  It's the new Joanna's on the case.

1049
01:01:58,605 --> 01:02:01,565
Speaker 3:  Joanna's on the case with the, with New Jersey moms. I'm

1050
01:02:01,565 --> 01:02:04,725
Speaker 4:  Realizing you both get a lot more notifications than I do. Maybe it's just

1051
01:02:04,725 --> 01:02:08,685
Speaker 4:  because I don't have the smart home stuff, but I have like systematically

1052
01:02:08,805 --> 01:02:12,485
Speaker 4:  turned off basically every notification that isn't texts

1053
01:02:12,515 --> 01:02:16,445
Speaker 4:  from people responsible for the life of my child. Like that's, that's essentially

1054
01:02:16,465 --> 01:02:19,125
Speaker 4:  it. Almost no one else gets to send me notifications.

1055
01:02:19,305 --> 01:02:21,965
Speaker 3:  I'm gonna install a ring camera in your house just to send you notifications

1056
01:02:22,025 --> 01:02:25,685
Speaker 3:  so that you can, it feels like a home invasion every single morning. We need

1057
01:02:25,685 --> 01:02:27,125
Speaker 3:  to talk about the Mac mini, which is actually the

1058
01:02:27,125 --> 01:02:28,525
Speaker 6:  New, I'm sorry, I'm very sorry we're going back.

1059
01:02:28,525 --> 01:02:31,045
Speaker 3:  We're we're It's fine. Tell the New Jersey moms that you're about to talk

1060
01:02:31,045 --> 01:02:31,605
Speaker 3:  about the Mac Mini.

1061
01:02:31,785 --> 01:02:35,645
Speaker 6:  I'm gonna buy them all one for for saying that I never respond to them and

1062
01:02:35,645 --> 01:02:36,805
Speaker 6:  muting their chain all the time.

1063
01:02:37,195 --> 01:02:37,485
Speaker 3:  Okay.

1064
01:02:37,785 --> 01:02:40,005
Speaker 4:  And you can, it's only $599. Right.

1065
01:02:40,005 --> 01:02:43,765
Speaker 3:  So David, the thing about this MAC Mini, you have been talking about wanting

1066
01:02:43,765 --> 01:02:47,085
Speaker 3:  to upgrade your M1 Mac mini that I basically cajoled you into buying

1067
01:02:47,725 --> 01:02:49,645
Speaker 3:  Correct. For a long time. Is this gonna do it?

1068
01:02:49,915 --> 01:02:53,445
Speaker 4:  Yeah. Oh yeah. This is, I mean this is the M mini people wanted.

1069
01:02:54,615 --> 01:02:58,605
Speaker 4:  There are a couple of little less than ideal things. I think it's a bummer

1070
01:02:58,605 --> 01:03:01,885
Speaker 4:  that it doesn't have an ST card reader. You'd obviously like there to be

1071
01:03:02,155 --> 01:03:05,525
Speaker 4:  more IO all the time. This one has three

1072
01:03:05,885 --> 01:03:09,405
Speaker 4:  USBC ports on the back and two USBC ports on the front.

1073
01:03:09,675 --> 01:03:11,965
Speaker 3:  Well, no, it's Thunderbolt on the back. Thunderbolt four on the back and

1074
01:03:12,245 --> 01:03:14,845
Speaker 3:  SBC on the front, which is very confusing 'cause the ports are

1075
01:03:15,025 --> 01:03:17,885
Speaker 4:  The same. Oh, that's, yeah. Okay. That's actually a good distinction. I was

1076
01:03:17,885 --> 01:03:21,805
Speaker 4:  about to make a face at you for trying to distinguish all the dumb thunderbolt

1077
01:03:21,805 --> 01:03:25,325
Speaker 4:  stuff, but that's, that's a good distinction. But anyway, kill me.

1078
01:03:26,945 --> 01:03:30,605
Speaker 4:  So like more IO would be good. I personally, there are two things about this

1079
01:03:30,605 --> 01:03:34,285
Speaker 4:  thing that I don't care about at all, and I would just like to say them out

1080
01:03:34,285 --> 01:03:38,125
Speaker 4:  loud so that we can then move on. I don't care that it's smaller. The, the

1081
01:03:38,185 --> 01:03:42,085
Speaker 4:  Mac mini, the size that it was was fine. And I guess if you're

1082
01:03:42,085 --> 01:03:45,885
Speaker 4:  like rolling giant stacks of them into a server

1083
01:03:46,015 --> 01:03:49,005
Speaker 4:  array, so you can run a weird third party messaging app, hypothetically,

1084
01:03:49,755 --> 01:03:53,685
Speaker 4:  this would be very useful to you. I don't care. I'm going to stick

1085
01:03:53,685 --> 01:03:56,365
Speaker 4:  it where my current Mac mini is. It's going to take up slightly less space.

1086
01:03:56,375 --> 01:03:59,085
Speaker 4:  It'll be fine. That's thing number one I don't care about. Thing number two

1087
01:03:59,085 --> 01:04:02,765
Speaker 4:  I don't care about is that the power button is on the bottom. I just, I just

1088
01:04:02,855 --> 01:04:06,685
Speaker 4:  don't care. I also, I should say this out loud, don't care that you charge

1089
01:04:06,685 --> 01:04:09,485
Speaker 4:  the Magic Mouse on the bottom. Don't care about that either. That one I do

1090
01:04:09,485 --> 01:04:12,325
Speaker 4:  care. These are not problems. The, this is we, we can,

1091
01:04:12,505 --> 01:04:14,405
Speaker 3:  We can argue separate these about all these Let's separate, let's separate

1092
01:04:14,405 --> 01:04:14,685
Speaker 3:  these two.

1093
01:04:14,795 --> 01:04:18,565
Speaker 4:  Yeah. So the power button is on the bottom of the MAC mini. That is fine.

1094
01:04:18,865 --> 01:04:22,845
Speaker 4:  Agreed. Would it be cooler if it were on the front? Sure.

1095
01:04:22,985 --> 01:04:26,245
Speaker 4:  Do I have any feelings about it at all? No. What I think is great is that

1096
01:04:26,245 --> 01:04:30,085
Speaker 4:  this thing is still 509 $9. It now starts with 16 gigs of ram.

1097
01:04:30,085 --> 01:04:33,045
Speaker 4:  Yep. Which is awesome. It has an M four chip, which is awesome.

1098
01:04:33,795 --> 01:04:37,125
Speaker 4:  Like this. This thing is just what it is supposed to be, which I think is

1099
01:04:37,125 --> 01:04:40,605
Speaker 4:  the thing that Apple is starting to do really well with Max is it just gives

1100
01:04:40,605 --> 01:04:44,485
Speaker 4:  you the computer that you feel like you should have. Right? Like this is

1101
01:04:44,485 --> 01:04:48,245
Speaker 4:  the one with the newest chip. It has most of the IO that I want. It still

1102
01:04:48,245 --> 01:04:51,845
Speaker 4:  has an ethernet port. It'll still plug into HDMI. Like this is just the computer

1103
01:04:51,845 --> 01:04:55,255
Speaker 4:  that I want and that is delightful. Yeah.

1104
01:04:55,435 --> 01:04:59,295
Speaker 3:  You know, it's interesting because they spent so much time trying so hard

1105
01:04:59,395 --> 01:05:03,255
Speaker 3:  to reinvent Macs or to kill them in favor of the iPad

1106
01:05:03,255 --> 01:05:06,935
Speaker 3:  or whatever they were doing. Just scattershot Mac ideas.

1107
01:05:07,045 --> 01:05:10,695
Speaker 3:  What if the keyboard sucked? Like just right. What if they were so thin the

1108
01:05:10,895 --> 01:05:14,255
Speaker 3:  batteries only lasted five minutes and now they're just like, they're really

1109
01:05:14,255 --> 01:05:17,285
Speaker 3:  good computers and we're just gonna keep iterating them, which is all they

1110
01:05:17,285 --> 01:05:20,885
Speaker 3:  needed to do. It's also kind of a sign that all of their most

1111
01:05:20,885 --> 01:05:24,085
Speaker 3:  innovative ideas are pointed elsewhere, which is kind of weird, right? Like,

1112
01:05:25,785 --> 01:05:29,125
Speaker 3:  you would like them to have one Mac that was just

1113
01:05:29,595 --> 01:05:32,325
Speaker 3:  bananas. But I don't think that Mac should be the, the Mac mini, to be clear,

1114
01:05:32,865 --> 01:05:36,405
Speaker 3:  it just, the thing you're talking about is just very obvious to the point

1115
01:05:36,405 --> 01:05:40,135
Speaker 3:  where the new MacBook pros, they didn't even update the wallpapers. They

1116
01:05:40,135 --> 01:05:43,655
Speaker 3:  were just like, here, here it is again. You know, like Yeah. And all that's

1117
01:05:43,655 --> 01:05:47,615
Speaker 3:  fine. Like I, I'm with you. I think this Mac mini is great. I do, I will

1118
01:05:47,615 --> 01:05:51,535
Speaker 3:  say there are a lot of people who deploy Mac Minis in things like racks

1119
01:05:52,155 --> 01:05:56,135
Speaker 3:  in other weird places where having to take the

1120
01:05:56,135 --> 01:05:59,575
Speaker 3:  thing out and turn it over in case something goes wrong and reboot it

1121
01:05:59,885 --> 01:06:01,015
Speaker 3:  will be a pain in the ass.

1122
01:06:01,405 --> 01:06:02,535
Speaker 4:  Sure. Fair. Yeah. Totally

1123
01:06:02,535 --> 01:06:06,135
Speaker 6:  Agree. But that's not like, not the complaint. Like I tweeted about this

1124
01:06:06,275 --> 01:06:10,135
Speaker 6:  and I always regret that. But, and also on Andreas, like,

1125
01:06:10,975 --> 01:06:14,495
Speaker 6:  I mean, just the anger of some people being like that this is on the bottom

1126
01:06:14,555 --> 01:06:18,495
Speaker 6:  and that like, 'cause I just asked a basic question, which is how often are

1127
01:06:18,495 --> 01:06:21,895
Speaker 6:  you people restarting or turning off your, your max?

1128
01:06:22,635 --> 01:06:25,495
Speaker 6:  and it turns out like there's a lot of people that turn off their max. I

1129
01:06:25,495 --> 01:06:28,695
Speaker 6:  don't, I don't know why. I mean, these are not built to be turned off every

1130
01:06:28,695 --> 01:06:32,575
Speaker 6:  day. At the end of the day, this is again, not a podcast in 1986,

1131
01:06:33,075 --> 01:06:36,975
Speaker 6:  but people do it and seem very angry about the

1132
01:06:37,215 --> 01:06:37,375
Speaker 6:  location.

1133
01:06:38,185 --> 01:06:38,475
Speaker 3:  Yeah.

1134
01:06:39,035 --> 01:06:39,515
Speaker 6:  I don't get it.

1135
01:06:39,715 --> 01:06:42,955
Speaker 4:  I will say I briefly went through a phase where I would shut down my computer

1136
01:06:43,015 --> 01:06:46,875
Speaker 4:  at the end of the day just as a like symbolic. My, my

1137
01:06:47,155 --> 01:06:50,075
Speaker 4:  computer day is now over thing and it was kind of great to be honest. There's

1138
01:06:50,235 --> 01:06:53,395
Speaker 4:  something nice about, like, I have now turned my computer off even though

1139
01:06:53,395 --> 01:06:57,275
Speaker 4:  it takes a grand total of like six seconds to boot a Mac now. Like it's not

1140
01:06:58,185 --> 01:07:02,075
Speaker 4:  slow, it's fine. But I, I don't know, I probably

1141
01:07:02,185 --> 01:07:06,075
Speaker 4:  restart my Mac mini once every two weeks and I

1142
01:07:06,075 --> 01:07:09,955
Speaker 4:  do it by software. Like I don't ever

1143
01:07:10,015 --> 01:07:13,155
Speaker 4:  hit the, I can't reach the power button on my Mac mini from where I'm sitting

1144
01:07:13,155 --> 01:07:13,355
Speaker 4:  right

1145
01:07:13,355 --> 01:07:14,315
Speaker 6:  Now. How do you turn it on?

1146
01:07:15,115 --> 01:07:17,515
Speaker 4:  I restart it. I literally don't think I've turned it on from

1147
01:07:17,585 --> 01:07:20,355
Speaker 6:  Dead. Oh. Like you haven't turned it shut down. You haven't done like shut

1148
01:07:20,355 --> 01:07:21,475
Speaker 6:  down. No.

1149
01:07:21,475 --> 01:07:24,635
Speaker 4:  Yeah. In a a year maybe. Yeah.

1150
01:07:25,115 --> 01:07:25,725
Speaker 3:  Sometimes

1151
01:07:25,725 --> 01:07:28,445
Speaker 4:  The power goes out and I have to like pull the thing out. So I can reach

1152
01:07:28,445 --> 01:07:31,805
Speaker 4:  behind, but that's it. Like, I just don't think this is a real problem. And

1153
01:07:31,805 --> 01:07:34,285
Speaker 4:  again, for the people who use these things in server rack and stuff, I, I

1154
01:07:34,285 --> 01:07:37,885
Speaker 4:  grant that it's an issue. You're not the target customer, right? Like

1155
01:07:38,195 --> 01:07:40,925
Speaker 4:  this is not, that's not who Apple is making this thing for.

1156
01:07:41,265 --> 01:07:45,045
Speaker 3:  No, actually for the, the many, the many is the one where everyone

1157
01:07:45,065 --> 01:07:48,605
Speaker 3:  is the target customer in apple's own marketing kind of demonstrates this,

1158
01:07:48,605 --> 01:07:52,045
Speaker 3:  right? They're, they're showing here's this modular little box that you can

1159
01:07:52,305 --> 01:07:55,685
Speaker 3:  put in all these different environments and they can't, they have to, it's

1160
01:07:55,685 --> 01:07:59,365
Speaker 3:  Apple, right? So it has to be like a person with a guitar and a person

1161
01:07:59,365 --> 01:08:02,965
Speaker 3:  who's drawing. and it's never like the person who's running the third party

1162
01:08:02,965 --> 01:08:06,565
Speaker 3:  messaging service that hijacks iMessage. But like there are a lot of Mac

1163
01:08:06,615 --> 01:08:09,365
Speaker 3:  minis and server racks. This is a thing that these computers are used for

1164
01:08:09,365 --> 01:08:13,325
Speaker 3:  for sure. And fine. I, my thing that I don't understand about turning

1165
01:08:13,325 --> 01:08:17,285
Speaker 3:  off the computer is that actually whenever I cold boot a Mac, it

1166
01:08:17,285 --> 01:08:21,125
Speaker 3:  takes forever for it to just be fast again. Do you guys not

1167
01:08:21,125 --> 01:08:21,765
Speaker 3:  notice this? You

1168
01:08:21,765 --> 01:08:24,805
Speaker 4:  Gotta, you gotta, you gotta delete some login items, my man.

1169
01:08:24,805 --> 01:08:27,245
Speaker 6:  Yeah. Yeah. I have the same, but like, it's because I, yeah. I have some

1170
01:08:27,245 --> 01:08:29,165
Speaker 6:  startup items that I just, like it's starting.

1171
01:08:30,075 --> 01:08:33,965
Speaker 3:  Yeah. Whatever. I was just like, it's slower. I do think the idea that I

1172
01:08:33,965 --> 01:08:37,845
Speaker 3:  should keep my computer in like a library room or like a computer room

1173
01:08:37,845 --> 01:08:41,725
Speaker 3:  with like that weird eighties oak furniture and I should turn it

1174
01:08:41,745 --> 01:08:44,885
Speaker 3:  off every time I'm done using it. That might make me healthier. That might

1175
01:08:44,885 --> 01:08:46,445
Speaker 3:  be better for all of us. That will save America.

1176
01:08:46,795 --> 01:08:50,645
Speaker 6:  Yeah. That's, that's David's version of the emotional notifications.

1177
01:08:51,485 --> 01:08:55,165
Speaker 4:  A hundred percent. Yeah. I, I get to walk into my computer room and sit down

1178
01:08:55,165 --> 01:08:58,965
Speaker 4:  at my computer chair in front of my giant computer box and it's great.

1179
01:08:59,315 --> 01:09:02,725
Speaker 4:  Wait, the, the point you just made about the way Apple is talking about this

1180
01:09:02,725 --> 01:09:06,445
Speaker 4:  thing, did that feel really different to you? Because my memory of the Mac

1181
01:09:06,445 --> 01:09:09,965
Speaker 4:  Mini was that it was always like kind of the iPhone SE that it's just like

1182
01:09:09,965 --> 01:09:13,645
Speaker 4:  a thing that some people like, but it's kind of over here and we're never

1183
01:09:13,645 --> 01:09:17,525
Speaker 4:  gonna really talk about it or pay much attention to it. Whereas this

1184
01:09:17,525 --> 01:09:21,365
Speaker 4:  time it feels very like front and center. This is a

1185
01:09:21,375 --> 01:09:24,805
Speaker 4:  mainstream Mac. Like they talk about this thing and market it and are putting

1186
01:09:24,805 --> 01:09:28,005
Speaker 4:  it in pictures the way that they do with like the MacBook Air. Yeah. Which

1187
01:09:28,005 --> 01:09:29,045
Speaker 4:  just really surprised me.

1188
01:09:29,805 --> 01:09:33,445
Speaker 3:  I think that's a weird post pandemic work

1189
01:09:33,515 --> 01:09:36,105
Speaker 3:  from home change.

1190
01:09:37,635 --> 01:09:41,025
Speaker 3:  There are lots of people out there who bought three monitors to work from

1191
01:09:41,025 --> 01:09:44,945
Speaker 3:  home in the pandemic. There are, we, we cover desk setups

1192
01:09:44,945 --> 01:09:48,625
Speaker 3:  on our own site all the time. There are lots of people who spend a lot of

1193
01:09:48,625 --> 01:09:52,545
Speaker 3:  time buying mechanical keyboards and like cool aesthetic monitors.

1194
01:09:52,845 --> 01:09:55,785
Speaker 3:  And I think how do you put a Mac into that mix?

1195
01:09:56,575 --> 01:09:59,545
Speaker 3:  This is the answer. You can just swap out whatever you have and here's this

1196
01:09:59,545 --> 01:10:02,985
Speaker 3:  little modular Mac and now it's part of a whole lifestyle. And I think that

1197
01:10:03,605 --> 01:10:07,425
Speaker 3:  the Mac mini before was like a utility computer

1198
01:10:07,445 --> 01:10:11,385
Speaker 3:  and now it is a lifestyle computer and it's be, I I really do

1199
01:10:11,385 --> 01:10:14,985
Speaker 3:  think that's just a change. Like even when I've had like CEOs from

1200
01:10:14,985 --> 01:10:17,625
Speaker 3:  peripheral companies like Logitech or whatever on decoder, they're talking

1201
01:10:17,625 --> 01:10:21,545
Speaker 3:  about this as a market. Like people are building desk setups, they're

1202
01:10:21,665 --> 01:10:25,545
Speaker 3:  building a gaming PC setup next to a productivity setup. They want them to

1203
01:10:25,545 --> 01:10:29,505
Speaker 3:  be beautiful. It's just a, people spend all day watching movies in these

1204
01:10:29,605 --> 01:10:33,305
Speaker 3:  setups now. It's like there's a lot going on in the computer room, which

1205
01:10:33,305 --> 01:10:34,025
Speaker 3:  is now every room.

1206
01:10:34,575 --> 01:10:38,425
Speaker 6:  Yeah. I also think one thing that happened was that

1207
01:10:38,425 --> 01:10:41,865
Speaker 6:  they discontinued the 27 inch iMac. And

1208
01:10:42,485 --> 01:10:46,145
Speaker 6:  so That's fair I when that happened and they just went to

1209
01:10:46,145 --> 01:10:49,665
Speaker 6:  24 inches, I heard from a lot of readers who were pissed. Yep. And so the

1210
01:10:49,665 --> 01:10:52,585
Speaker 6:  best option was a Mac mini and a big monitor.

1211
01:10:53,365 --> 01:10:53,585
Speaker 4:  Yep.

1212
01:10:53,725 --> 01:10:57,625
Speaker 6:  Versus getting a Mac with a studio. Was it the Mac

1213
01:10:57,625 --> 01:10:58,385
Speaker 6:  studio? The

1214
01:10:58,885 --> 01:10:59,745
Speaker 3:  The studio display.

1215
01:11:00,005 --> 01:11:03,425
Speaker 6:  The studio, yeah. Well I, and I don't think a lot of people are buying, like

1216
01:11:03,425 --> 01:11:06,985
Speaker 6:  if you're getting a Mac mini, you wanted a, like an iMac competitor. Either

1217
01:11:06,985 --> 01:11:10,025
Speaker 6:  you're getting a studio display or just getting a cheaper 27 inch display

1218
01:11:10,025 --> 01:11:14,005
Speaker 6:  or bigger display. And I think that kind of took that market. So yeah,

1219
01:11:14,555 --> 01:11:15,525
Speaker 6:  that kind of became the

1220
01:11:15,525 --> 01:11:19,165
Speaker 4:  Yeah, I did that for my, in-laws maybe a year ago. They had like an

1221
01:11:19,165 --> 01:11:23,125
Speaker 4:  ancient 27 inch iMac and really did not wanna go down to 24 inches.

1222
01:11:23,625 --> 01:11:27,605
Speaker 4:  And so like every three months my father-in-law would hit me

1223
01:11:27,605 --> 01:11:31,005
Speaker 4:  up. He'd be like, so 27 inch iMac, when's it gonna happen? And I eventually

1224
01:11:31,005 --> 01:11:33,565
Speaker 4:  was like, I was like, Roger, I don't think it's gonna happen. No.

1225
01:11:33,565 --> 01:11:37,525
Speaker 3:  Do you remember Apple gave us the rare on the record statement, right?

1226
01:11:37,525 --> 01:11:38,405
Speaker 6:  Saying no. Oh yeah.

1227
01:11:38,405 --> 01:11:40,605
Speaker 3:  Saying we're not making another 27 trimac.

1228
01:11:40,605 --> 01:11:44,365
Speaker 6:  And but think about it. You're that person. You're, what was his name? You're

1229
01:11:44,615 --> 01:11:48,085
Speaker 6:  Roger. Roger. You're Roger. Roger and I, a lot of Rogers read the Wall Street

1230
01:11:48,085 --> 01:11:51,885
Speaker 6:  Journal and they really want a new desktop and

1231
01:11:52,235 --> 01:11:55,925
Speaker 6:  they are not gonna go get the Mac Studio, which costs $2,000,

1232
01:11:56,065 --> 01:11:59,845
Speaker 6:  but they're gonna get an iMac, so Okay. Makes it more mainstream.

1233
01:11:59,845 --> 01:12:03,645
Speaker 6:  They're gonna pair that with a display that they, you know, buy on Amazon

1234
01:12:03,645 --> 01:12:05,725
Speaker 6:  of Samsung or whatnot. Done.

1235
01:12:06,955 --> 01:12:09,765
Speaker 4:  Yeah. Well and it was, it was very funny going to that process with him because

1236
01:12:09,765 --> 01:12:13,445
Speaker 4:  he was really annoyed by the fact that the computer

1237
01:12:14,305 --> 01:12:18,005
Speaker 4:  inside of the iMac was old and slow and outdated. I know, but the screen

1238
01:12:18,005 --> 01:12:20,845
Speaker 4:  was awesome. He was like, why can't I just use this as an monitor, put another

1239
01:12:21,085 --> 01:12:23,285
Speaker 4:  computer inside of the screen. And I was like, what a terrific point that

1240
01:12:23,285 --> 01:12:26,445
Speaker 4:  you're making. And so it, it made it, it made it actually easier to sell

1241
01:12:26,445 --> 01:12:29,405
Speaker 4:  him on the idea of like, okay, we're gonna buy you a Mac mini and we're gonna

1242
01:12:29,405 --> 01:12:33,365
Speaker 4:  buy you a really nice 27 inch monitor and this monitor is

1243
01:12:33,365 --> 01:12:35,845
Speaker 4:  gonna sit here for a very long time and you can just upgrade this little

1244
01:12:36,045 --> 01:12:38,765
Speaker 4:  computer as you need to. And he's, he's been very happy with my

1245
01:12:38,765 --> 01:12:42,615
Speaker 3:  2015 iMac is in the corner over there and, and

1246
01:12:42,655 --> 01:12:46,615
Speaker 3:  I have all the parts to turn it into just a monitor and I have

1247
01:12:46,615 --> 01:12:50,175
Speaker 3:  to sit around and get it unglued and do all the stuff and

1248
01:12:50,915 --> 01:12:54,335
Speaker 3:  I'm gonna do it one day. But that is the plan for that machine. Actually

1249
01:12:54,335 --> 01:12:56,855
Speaker 3:  we should just have a party. We should have a bringing your iMac to turn

1250
01:12:56,855 --> 01:13:00,775
Speaker 3:  it into a monitor. It's a very nerdy kind of RG chess party. But I think

1251
01:13:00,775 --> 01:13:03,895
Speaker 3:  we could get people to come to it. And I know a lot of people who are sitting

1252
01:13:03,895 --> 01:13:07,255
Speaker 3:  around with old 27 inch iMac who are like, I can just turn this into this

1253
01:13:07,255 --> 01:13:11,055
Speaker 3:  way because the panel is the same as the panel in the studio display. Yep.

1254
01:13:11,105 --> 01:13:14,775
Speaker 3:  Apple has not meaningfully updated that LG panel for the studio display.

1255
01:13:14,775 --> 01:13:18,215
Speaker 3:  It's the same as the 27 inch iMac. Which I think we should talk about the

1256
01:13:18,215 --> 01:13:21,415
Speaker 3:  24 inch iMac, which was also just Rev to have an M four chip in it.

1257
01:13:22,205 --> 01:13:26,135
Speaker 3:  It's kind of weird that they're, that they just landed this thing at

1258
01:13:26,135 --> 01:13:29,495
Speaker 3:  24 inches. It is very colorful. It is very thin

1259
01:13:30,155 --> 01:13:34,095
Speaker 3:  in many ways. It's like an apex idea of the iMac. Like

1260
01:13:34,335 --> 01:13:37,935
Speaker 3:  I don't know where you go after this. Like it is as thin as any computer

1261
01:13:37,995 --> 01:13:41,685
Speaker 3:  can be to be that thing. But I feel like if they just made it

1262
01:13:41,685 --> 01:13:45,585
Speaker 3:  27 inches, like lots of more people would just buy 'em. Like you would just

1263
01:13:45,585 --> 01:13:49,265
Speaker 3:  buy, this would be the thing you would buy. And at 24, I think everyone has

1264
01:13:49,265 --> 01:13:50,265
Speaker 3:  that. I don't know.

1265
01:13:51,415 --> 01:13:55,325
Speaker 4:  It has to just be a price thing. Right? Like I I think keeping the

1266
01:13:55,475 --> 01:13:59,325
Speaker 4:  iMac as relatively speaking affordable as possible

1267
01:13:59,945 --> 01:14:03,565
Speaker 4:  is very important because this thing is like, it is such a family

1268
01:14:04,005 --> 01:14:07,645
Speaker 4:  computer. It's a, it's a like thing on the

1269
01:14:07,845 --> 01:14:11,805
Speaker 4:  reception desk at fancy doctor's offices. Like, it, it's, it's in so

1270
01:14:11,805 --> 01:14:14,805
Speaker 4:  many of those places that I think If, you have a bigger screen

1271
01:14:15,385 --> 01:14:19,085
Speaker 4:  that's good, but if it's suddenly $500 more expensive, you've kind of killed

1272
01:14:19,085 --> 01:14:22,765
Speaker 4:  the value prop of the thing. Yeah. And I was so surprised when they made

1273
01:14:22,765 --> 01:14:25,205
Speaker 4:  this change in the first place because my assumption would've always been

1274
01:14:25,475 --> 01:14:29,165
Speaker 4:  anybody wants an iMac is gonna want the bigger one. And that, I mean

1275
01:14:29,935 --> 01:14:33,405
Speaker 4:  Apple is not like famous for making stupid business decisions. So, I think

1276
01:14:33,515 --> 01:14:37,325
Speaker 4:  clearly that was not the case. But the fact that it is so locked in on

1277
01:14:37,325 --> 01:14:41,085
Speaker 4:  this one thing at this one size and it, especially with these colors,

1278
01:14:41,115 --> 01:14:44,925
Speaker 4:  like it just indicates there is, this is a very different Mac that

1279
01:14:44,925 --> 01:14:48,845
Speaker 4:  serves a very different kind of person than anything else in the

1280
01:14:48,845 --> 01:14:49,845
Speaker 4:  Mac lineup at this point.

1281
01:14:50,315 --> 01:14:53,405
Speaker 3:  It's interesting the way you describe it. 'cause it, lemme just throw this

1282
01:14:53,405 --> 01:14:57,165
Speaker 3:  idea out here. It sounds like we're describing the Mac Mini as the Go-to

1283
01:14:57,345 --> 01:15:01,285
Speaker 3:  Mac desktop, the lifestyle computer and the iMac is the

1284
01:15:01,285 --> 01:15:04,805
Speaker 3:  weird utility computer that goes in the receptionist desk

1285
01:15:05,455 --> 01:15:09,085
Speaker 4:  Maybe. Yeah. It's certainly the like plug and play

1286
01:15:09,565 --> 01:15:13,365
Speaker 4:  simplest version of that for Apple, right? Like the, there is

1287
01:15:13,425 --> 01:15:17,245
Speaker 4:  no easier Mac to just insert into a

1288
01:15:17,525 --> 01:15:20,325
Speaker 4:  receptionist's office than a doctor's appointment at a doctor's office than

1289
01:15:20,325 --> 01:15:23,845
Speaker 4:  an iMac. Yeah. You don't need other peripherals. You just sit the thing down,

1290
01:15:23,875 --> 01:15:27,645
Speaker 4:  plug it in and turn it on. And I think that's really enticing to a lot of

1291
01:15:27,645 --> 01:15:31,565
Speaker 4:  people. I think it's also limiting and problematic in the

1292
01:15:31,565 --> 01:15:35,435
Speaker 4:  ways that we're just talking about. But I get the appeal. What I don't

1293
01:15:35,435 --> 01:15:38,235
Speaker 4:  understand is why this is the only one that comes in purple. Right. And it's

1294
01:15:38,235 --> 01:15:40,875
Speaker 4:  like, who is this? And not just because I want them all to come in purple,

1295
01:15:40,895 --> 01:15:44,155
Speaker 4:  but like what is so different about the iMac audience that it gets

1296
01:15:44,825 --> 01:15:48,675
Speaker 4:  such an unbelievably different set of like aesthetic

1297
01:15:49,195 --> 01:15:50,595
Speaker 4:  decisions than any other Mac?

1298
01:15:50,595 --> 01:15:54,435
Speaker 6:  Well I think that's like where if they were to go to the 27 inch, I think

1299
01:15:54,435 --> 01:15:58,395
Speaker 6:  they would wanna attach a pro name to it. Hmm. And a pro

1300
01:15:58,445 --> 01:15:59,795
Speaker 6:  isn't coming purple because

1301
01:15:59,825 --> 01:16:02,475
Speaker 3:  Only professionals need slightly more screen

1302
01:16:03,265 --> 01:16:05,395
Speaker 6:  Because a pro does not come in purple.

1303
01:16:05,985 --> 01:16:06,275
Speaker 3:  Yeah,

1304
01:16:06,505 --> 01:16:09,635
Speaker 6:  That is No, definitely not. That's the tagline there. So they,

1305
01:16:10,155 --> 01:16:12,955
Speaker 3:  That's how you know that you work at the Wall Street Journal and we work

1306
01:16:12,955 --> 01:16:16,195
Speaker 3:  at The Verge 'cause I'm like, our professionals come in purple. That's what

1307
01:16:16,195 --> 01:16:19,635
Speaker 3:  we do here. We're, we're purple to the Wall Street Journal. You do have a

1308
01:16:19,635 --> 01:16:20,915
Speaker 3:  lot of purple oppressive gray.

1309
01:16:21,515 --> 01:16:24,875
Speaker 6:  I I like purple, purple for everyone.

1310
01:16:25,215 --> 01:16:28,875
Speaker 3:  Joanna, you and I have kids around the same age. Are you going to,

1311
01:16:29,255 --> 01:16:32,635
Speaker 3:  I'm assuming they will just be sort of like given Chromebooks in your school

1312
01:16:32,835 --> 01:16:33,715
Speaker 3:  district that will happen.

1313
01:16:33,715 --> 01:16:34,315
Speaker 6:  Yeah, they were already

1314
01:16:34,845 --> 01:16:38,075
Speaker 3:  Right. And so then, okay, there's your like laptop for school. I've been

1315
01:16:38,215 --> 01:16:41,235
Speaker 3:  asking myself, am I gonna get max a laptop

1316
01:16:42,125 --> 01:16:45,825
Speaker 3:  or would I want a desktop like this to be like, this is here

1317
01:16:46,365 --> 01:16:50,345
Speaker 3:  and then when you go to your room it doesn't go with you. It's not

1318
01:16:50,425 --> 01:16:53,905
Speaker 3:  a portable computer. And maybe coming back to that like computer room idea

1319
01:16:54,325 --> 01:16:57,945
Speaker 3:  and I feel like that's part of this right? It, it's all part of that mix

1320
01:16:58,165 --> 01:17:00,865
Speaker 3:  is like people are expressing what they want computers to be and how they

1321
01:17:00,865 --> 01:17:03,985
Speaker 3:  want them to used very differently than just a few years ago.

1322
01:17:04,795 --> 01:17:05,085
Speaker 4:  Yeah.

1323
01:17:05,085 --> 01:17:07,805
Speaker 3:  Yeah. Like obviously very differently than just a few years ago. And part

1324
01:17:07,805 --> 01:17:11,005
Speaker 3:  of this is like this computer is stationary and friendly

1325
01:17:11,705 --> 01:17:15,685
Speaker 3:  and it, but it doesn't go with you and your laptop has to be rugged. If

1326
01:17:15,725 --> 01:17:19,605
Speaker 3:  a laptop was purple it would probably look like crap after a while

1327
01:17:19,625 --> 01:17:23,405
Speaker 3:  in a way that aluminum just looks worn in a nice way.

1328
01:17:23,925 --> 01:17:26,765
Speaker 3:  I dunno that I, I've been thinking about this a lot. Like, oh maybe I'll

1329
01:17:26,765 --> 01:17:29,405
Speaker 3:  just get the iMac the first time out and the fact that it's purple makes

1330
01:17:29,405 --> 01:17:31,445
Speaker 3:  it friendly and like that will be fun.

1331
01:17:32,125 --> 01:17:34,805
Speaker 4:  I think that's the move personally. I mean, and you even look at the way

1332
01:17:34,805 --> 01:17:38,645
Speaker 4:  Apple is marketing this thing. Like I'm, I'm just on the iMac page on

1333
01:17:38,645 --> 01:17:42,325
Speaker 4:  Apple's website and the images are like an iMac

1334
01:17:42,785 --> 01:17:46,485
Speaker 4:  on a counter in a coffee shop or in a bakery. There's one

1335
01:17:46,795 --> 01:17:50,405
Speaker 4:  that looks like it's in some cool like surfboard sales

1336
01:17:50,715 --> 01:17:53,765
Speaker 4:  shop. There's one that's clearly in a living room right next to the couch.

1337
01:17:53,795 --> 01:17:57,725
Speaker 4:  It's like these are, these are furniture in a way that no other Mac

1338
01:17:57,785 --> 01:18:01,405
Speaker 4:  is furniture. Yeah. Which I just find fascinating and I I

1339
01:18:02,125 --> 01:18:05,925
Speaker 4:  I have like, the older I get the more I believe in the idea of a computer

1340
01:18:05,945 --> 01:18:09,805
Speaker 4:  as like a place rather than a thing you carry around. So like

1341
01:18:09,805 --> 01:18:12,125
Speaker 4:  bring back the computer room. Honestly that's it as far

1342
01:18:12,125 --> 01:18:14,285
Speaker 3:  As I'm concerned. Actually the time when Vergecast listeners were sending

1343
01:18:14,285 --> 01:18:17,845
Speaker 3:  us pictures of their computer rooms so good was the best. Joanna you were

1344
01:18:17,845 --> 01:18:18,005
Speaker 3:  gonna say

1345
01:18:18,005 --> 01:18:20,205
Speaker 4:  Please keep doing that Vergecast at the virtual.com in 19 send

1346
01:18:20,205 --> 01:18:21,845
Speaker 6:  Us computer actually sent this computer room picture.

1347
01:18:22,065 --> 01:18:24,645
Speaker 3:  No, we asked people for pictures of the computer rooms when they were kids

1348
01:18:24,645 --> 01:18:27,205
Speaker 3:  and we got so many of them and they're all so cool and

1349
01:18:27,205 --> 01:18:30,285
Speaker 4:  Then we and they all look the same. Everybody had the same computer

1350
01:18:30,285 --> 01:18:33,845
Speaker 3:  Room. Everybody went to had the same soder, woodworking, computer

1351
01:18:33,975 --> 01:18:37,845
Speaker 3:  hutch like down the line. It was great. Okay. I wanna end by

1352
01:18:37,845 --> 01:18:40,845
Speaker 3:  talking about two things. One is a rumor that is my favorite rumor and two

1353
01:18:40,865 --> 01:18:44,725
Speaker 3:  is Joanna's garage door. The rumor is Apple

1354
01:18:44,745 --> 01:18:48,485
Speaker 3:  is working on a smart home display there. Mark

1355
01:18:48,645 --> 01:18:51,405
Speaker 3:  Erman has also reported that they're really gonna do it in this smart home

1356
01:18:51,545 --> 01:18:55,325
Speaker 3:  now they're gonna, they're gonna, they got matter out the door. The standard

1357
01:18:55,345 --> 01:18:58,325
Speaker 3:  is there, everyone's using it. There's the array of accessories. You can

1358
01:18:58,325 --> 01:19:02,125
Speaker 3:  buy all the stuff and they're gonna go for it. Sure.

1359
01:19:03,345 --> 01:19:06,925
Speaker 3:  But then they'll have a smart home display. And the other rumor is that

1360
01:19:07,265 --> 01:19:11,085
Speaker 3:  it will have, the display will be on an arm like the iMac G four, which is

1361
01:19:11,085 --> 01:19:13,365
Speaker 3:  the single greatest iMac ever made. The

1362
01:19:13,445 --> 01:19:15,925
Speaker 4:  G four is the, the one that kinda looks like the Pixar lamp. Yeah. Right.

1363
01:19:15,925 --> 01:19:18,285
Speaker 4:  Where it has like sun ball with the bottom and then the I loved

1364
01:19:18,285 --> 01:19:20,805
Speaker 3:  That. That was the best one. So if they make one of those, I'll buy that

1365
01:19:20,805 --> 01:19:24,605
Speaker 3:  right away and, and then I will, I will give my entire smart home to Apple.

1366
01:19:25,105 --> 01:19:29,085
Speaker 3:  My question is actually much simpler about this. What can

1367
01:19:29,085 --> 01:19:32,565
Speaker 3:  Apple actually do with a smart home display that hasn't been done by every

1368
01:19:32,565 --> 01:19:36,205
Speaker 3:  other company except have it be made by Apple? Because I have thought

1369
01:19:37,195 --> 01:19:41,065
Speaker 3:  about what I use my, my Nest hubs for. I've

1370
01:19:41,085 --> 01:19:44,905
Speaker 3:  got the Alexa displays for a while. When we were renovating

1371
01:19:44,965 --> 01:19:47,865
Speaker 3:  the kitchen, I was like, I'll put a tablet in the wall. Then I was like,

1372
01:19:47,905 --> 01:19:51,305
Speaker 3:  I will never use this tablet and I just didn't do it. I don't know that smart

1373
01:19:51,305 --> 01:19:53,705
Speaker 3:  home displays are actually a thing. I don't know. They're actually that useful.

1374
01:19:54,225 --> 01:19:58,185
Speaker 6:  I mean I guess I, I don't have a, I don't have a smart home

1375
01:19:58,185 --> 01:20:00,905
Speaker 6:  display. Everything is audio. It's mostly through

1376
01:20:02,195 --> 01:20:06,065
Speaker 6:  Sonos or my phone. I don't have any like what what are you

1377
01:20:06,065 --> 01:20:09,285
Speaker 6:  looking on on the display? I mean I guess like your camera feeds If, you

1378
01:20:09,285 --> 01:20:09,885
Speaker 6:  wanted to see them.

1379
01:20:10,315 --> 01:20:13,285
Speaker 3:  Sure. And everyone wants in the middle of their, but like their kitchen is

1380
01:20:13,285 --> 01:20:15,845
Speaker 3:  like a, like a security guard shack showing you

1381
01:20:15,845 --> 01:20:18,485
Speaker 6:  Live camera feeds and also how many camera feeds can actually go into Home

1382
01:20:18,505 --> 01:20:19,965
Speaker 6:  Kit and into the home app.

1383
01:20:20,335 --> 01:20:21,245
Speaker 3:  Quite a few. So,

1384
01:20:21,345 --> 01:20:23,325
Speaker 6:  But like, so but that's doesn't, that's

1385
01:20:23,325 --> 01:20:27,085
Speaker 4:  The problem is like if, if Apple you you,

1386
01:20:27,085 --> 01:20:30,005
Speaker 4:  like if I were to Galaxy Brain this moment, right, like If, you wanna look

1387
01:20:30,005 --> 01:20:33,885
Speaker 4:  at what is the closest to where the cell phone market was

1388
01:20:33,885 --> 01:20:37,445
Speaker 4:  right before the iPhone. It's definitely smart home,

1389
01:20:37,695 --> 01:20:40,565
Speaker 4:  right? Like there's tons of stuff out there. People are interested, but it

1390
01:20:40,565 --> 01:20:44,445
Speaker 4:  is just abject chaos everywhere you look. There are a

1391
01:20:44,445 --> 01:20:48,325
Speaker 4:  million competing operating systems and, and like in theory, someone

1392
01:20:48,335 --> 01:20:51,685
Speaker 4:  could come in and put it all together and everything would be amazing. Except

1393
01:20:51,705 --> 01:20:55,625
Speaker 4:  the difference is yes, you can't, you can't, it's not, not possible. The

1394
01:20:55,625 --> 01:20:59,505
Speaker 6:  Difference is not possible is that we have old crap that just doesn't

1395
01:20:59,535 --> 01:21:00,305
Speaker 6:  work with

1396
01:21:01,305 --> 01:21:01,655
Speaker 4:  Right.

1397
01:21:01,655 --> 01:21:04,135
Speaker 6:  Different stuff. Thus Apple

1398
01:21:04,135 --> 01:21:06,935
Speaker 4:  Would have to immediately turn HomeKit into the most

1399
01:21:07,875 --> 01:21:11,735
Speaker 4:  wildly compatible open and yet perfect and

1400
01:21:11,735 --> 01:21:15,215
Speaker 4:  closed and correct ecosystem in history. And that is not possible.

1401
01:21:15,445 --> 01:21:19,375
Speaker 4:  Like it's, I just don't, I just, I literally don't see how anyone Apple

1402
01:21:19,435 --> 01:21:23,375
Speaker 4:  or otherwise can like wrap their arms around the entirety of the

1403
01:21:23,375 --> 01:21:26,495
Speaker 4:  smart home right now in such a way that it's gonna work. Which is why matter

1404
01:21:26,595 --> 01:21:29,695
Speaker 4:  is in theory like the answer because it means you don't have to because it

1405
01:21:29,695 --> 01:21:31,575
Speaker 4:  means it all sort of sorts itself out. But like

1406
01:21:31,715 --> 01:21:32,695
Speaker 3:  It doesn't though we're not close to

1407
01:21:32,925 --> 01:21:33,735
Speaker 6:  Yeah. It really doesn't.

1408
01:21:34,215 --> 01:21:38,135
Speaker 3:  IIII run what is effectively a home kit house because if the

1409
01:21:38,135 --> 01:21:42,055
Speaker 3:  controls are not on Becky's phone, they don't exist. So

1410
01:21:42,055 --> 01:21:45,455
Speaker 3:  if I, if I want her to be able to change the temperature in her house,

1411
01:21:45,925 --> 01:21:49,535
Speaker 3:  it's, it's gotta be Home Kit. Your point about Ring Joanna, like I

1412
01:21:50,495 --> 01:21:52,175
Speaker 3:  I bridge everything through Home Bridge.

1413
01:21:52,295 --> 01:21:53,815
Speaker 6:  I bridge to get it Home Kit. So do I And

1414
01:21:53,815 --> 01:21:55,575
Speaker 3:  You bridge it in hoops, right? The other one?

1415
01:21:56,075 --> 01:21:58,055
Speaker 6:  Yes. and it fails

1416
01:21:58,475 --> 01:22:00,895
Speaker 3:  And it and we have you gotta switch to Home Bridge. I'm just telling you

1417
01:22:00,895 --> 01:22:01,015
Speaker 3:  right

1418
01:22:01,015 --> 01:22:04,855
Speaker 4:  Now. Do you think if I name this episode, I bridge it in hoops that anyone

1419
01:22:04,855 --> 01:22:05,495
Speaker 4:  will listen to it.

1420
01:22:06,755 --> 01:22:09,895
Speaker 3:  That's like when Neil and we get together to, we talk about the word hoops

1421
01:22:09,895 --> 01:22:10,535
Speaker 3:  a lot and it hilarious.

1422
01:22:10,915 --> 01:22:14,735
Speaker 6:  We talk about hoops a lot. I talk about IIII used to love hoops

1423
01:22:14,835 --> 01:22:16,135
Speaker 6:  and now I don't love hoops.

1424
01:22:18,235 --> 01:22:18,895
Speaker 3:  I'm so sorry.

1425
01:22:19,355 --> 01:22:23,055
Speaker 6:  And now I'm in a deep, I mean I'm really just em emotionally

1426
01:22:23,275 --> 01:22:26,815
Speaker 6:  so emotional on this podcast. Yeah. About my hoops, about my notifications.

1427
01:22:27,615 --> 01:22:30,575
Speaker 3:  I think Joanna like didn't they give you like an exclusive on like Hoops

1428
01:22:30,635 --> 01:22:30,855
Speaker 3:  Pro?

1429
01:22:33,075 --> 01:22:36,975
Speaker 3:  So just the, the brief history here is that If,

1430
01:22:36,975 --> 01:22:40,055
Speaker 3:  you wanna get stuff that do isn't supported HomeKit. In HomeKit there's just

1431
01:22:40,095 --> 01:22:43,295
Speaker 3:  a bunch of like middleware adapters. One of them is called HomeBridge,

1432
01:22:44,235 --> 01:22:47,535
Speaker 3:  that's the one I use. And then Hubs is like a commercial fork of HomeBridge.

1433
01:22:47,535 --> 01:22:50,335
Speaker 3:  There's a little open source fight and everybody makes the plugins and they

1434
01:22:50,335 --> 01:22:53,095
Speaker 3:  kind of work on both. And I think a lot of the plugins are secretly made

1435
01:22:53,095 --> 01:22:56,215
Speaker 3:  by Apple engineers 'cause they all wanna use their stuff in HomeKit.

1436
01:22:57,255 --> 01:22:58,275
Speaker 3:  I'm just saying we

1437
01:22:58,275 --> 01:22:59,115
Speaker 6:  Should report that out.

1438
01:22:59,985 --> 01:23:01,395
Speaker 3:  It's, it's just a rumor that I've

1439
01:23:01,395 --> 01:23:02,235
Speaker 6:  Heard a lot for the three of us

1440
01:23:02,575 --> 01:23:06,525
Speaker 3:  And So I, I have a, a raspberry pie in my, it's sitting right in

1441
01:23:06,525 --> 01:23:10,445
Speaker 3:  front of me that runs Home Bridge. It has my ring off in

1442
01:23:10,445 --> 01:23:14,085
Speaker 3:  it. It has my extremely garbage Honeywell

1443
01:23:14,575 --> 01:23:18,095
Speaker 3:  thermostat for the heaters in the basement. Fine.

1444
01:23:18,795 --> 01:23:22,335
Speaker 3:  It has some other stuff in it and all that stuff shows up in HomeKit. It

1445
01:23:22,335 --> 01:23:25,215
Speaker 3:  shows up in control center on my phone. And that is the problem. I would

1446
01:23:25,215 --> 01:23:28,255
Speaker 3:  have to tear out all that stuff and replace it with Matter compatible accessories.

1447
01:23:28,515 --> 01:23:32,415
Speaker 3:  And I have no inclination to replace the garbage Honeywell

1448
01:23:32,415 --> 01:23:35,935
Speaker 3:  thermostat in the basement with a new matter thermostat for

1449
01:23:36,315 --> 01:23:40,295
Speaker 3:  no upside. Like there's just no upside of me doing that. So I have to run

1450
01:23:40,755 --> 01:23:44,575
Speaker 3:  the home bridge. Joanna has to deal with hoops. This is very

1451
01:23:44,575 --> 01:23:48,445
Speaker 6:  Funny. Sorry to cut you off here in insert. Yeah. Is Home Bridge better

1452
01:23:48,445 --> 01:23:49,805
Speaker 6:  than hoops right now? Is what you're telling

1453
01:23:49,805 --> 01:23:51,285
Speaker 3:  Me? I think Home Bridge. Home Bridge is more stable.

1454
01:23:51,965 --> 01:23:53,735
Speaker 6:  Okay. So, I gotta get rid of my hoops.

1455
01:23:54,155 --> 01:23:57,335
Speaker 3:  But you can just re you can just install it on the same Raspberry pie. It's

1456
01:23:57,335 --> 01:24:01,135
Speaker 3:  fine. and we, and this is all like whatever.

1457
01:24:01,555 --> 01:24:05,495
Speaker 3:  But then you get to other stuff like garage

1458
01:24:05,495 --> 01:24:09,375
Speaker 3:  door openers where Chamberlain, which is the garage door

1459
01:24:09,735 --> 01:24:13,535
Speaker 3:  monopoly in the United States, which is ridiculous, wants

1460
01:24:13,775 --> 01:24:14,935
Speaker 3:  everyone to use my queue,

1461
01:24:15,315 --> 01:24:16,015
Speaker 6:  My queue and,

1462
01:24:16,315 --> 01:24:20,255
Speaker 3:  And they have my canceled. We actually, Jen two TUI broke the story.

1463
01:24:20,315 --> 01:24:24,215
Speaker 3:  Yep. They canceled not only their home kit support, they made a little adapter,

1464
01:24:24,445 --> 01:24:27,775
Speaker 3:  they broke the MyQ API so that

1465
01:24:28,235 --> 01:24:32,175
Speaker 3:  the Home bridge adapters, the hub adapters, the plugins would

1466
01:24:32,175 --> 01:24:35,775
Speaker 3:  stop working so that you would have to pay a subscription for MyQ.

1467
01:24:36,395 --> 01:24:40,175
Speaker 3:  That's like, that's where at in this smart home market. So

1468
01:24:40,175 --> 01:24:43,895
Speaker 3:  Apple cans show up with like a beautiful screen and be like matters

1469
01:24:44,035 --> 01:24:47,655
Speaker 3:  the real deal. And then you're stuck with even the

1470
01:24:47,825 --> 01:24:50,815
Speaker 3:  hacks to make it all work together or being broken. So you have to pay a

1471
01:24:50,975 --> 01:24:52,695
Speaker 3:  subscription fee to your garage door opener.

1472
01:24:53,235 --> 01:24:56,935
Speaker 6:  My dream in life is just to be able to drive away from my house

1473
01:24:57,355 --> 01:24:59,615
Speaker 6:  and say, Siri close the garage.

1474
01:25:00,575 --> 01:25:01,455
Speaker 3:  I can So I can,

1475
01:25:01,715 --> 01:25:02,815
Speaker 6:  You can help me with that. I know.

1476
01:25:02,815 --> 01:25:05,775
Speaker 3:  Look at me Johanna, I can solve this problem for you. So the best hack to

1477
01:25:05,775 --> 01:25:09,615
Speaker 3:  solve this problem, and this is where I want to get to your Craig Federici

1478
01:25:09,615 --> 01:25:10,255
Speaker 3:  conversation. But,

1479
01:25:10,255 --> 01:25:12,975
Speaker 6:  But, but what second? I just wanna, before you get to what could I used to

1480
01:25:12,975 --> 01:25:16,735
Speaker 6:  have this, I had this when home with when Hoops

1481
01:25:16,795 --> 01:25:20,495
Speaker 6:  was working with what you just described. Then Chamberlain

1482
01:25:20,495 --> 01:25:22,855
Speaker 6:  breaks that and now I have to use their,

1483
01:25:24,495 --> 01:25:27,575
Speaker 6:  I will not insert the word app. Okay.

1484
01:25:28,355 --> 01:25:32,185
Speaker 6:  And So I can no longer do this. Now you can go on,

1485
01:25:32,595 --> 01:25:36,545
Speaker 3:  Right? So the, the solution or all these little adapters you can buy on Amazon,

1486
01:25:36,575 --> 01:25:39,785
Speaker 3:  they're mostly made by a company called Miros. It seems like this is one

1487
01:25:39,785 --> 01:25:43,585
Speaker 3:  of those situations where one company made the thing and then 500

1488
01:25:43,595 --> 01:25:46,965
Speaker 3:  other companies rebrand it. Do you know what I'm talking about? You go on

1489
01:25:46,965 --> 01:25:49,565
Speaker 3:  Amazon, you're like HomeBridge or you go on Amazon and you type in like home

1490
01:25:49,565 --> 01:25:51,405
Speaker 3:  kit adapter for garage store and you see the same and

1491
01:25:51,405 --> 01:25:51,965
Speaker 6:  Then they all look the same.

1492
01:25:52,265 --> 01:25:54,965
Speaker 3:  You see the same product from 50 companies. Miros is the one that everybody

1493
01:25:55,075 --> 01:25:58,925
Speaker 3:  uses and it is just a little relay with a wifi

1494
01:25:59,035 --> 01:26:02,605
Speaker 3:  chip in it that connects to HomeKit and all it does is it

1495
01:26:02,925 --> 01:26:05,845
Speaker 3:  connects the two wires and pushes the button on your garage door

1496
01:26:05,845 --> 01:26:08,805
Speaker 6:  For you. Okay, am I installing this? I have to get up on a ladder and put

1497
01:26:08,805 --> 01:26:09,845
Speaker 6:  it onto my

1498
01:26:10,585 --> 01:26:13,085
Speaker 3:  Master. Have no, you have to invite your friend Neli to your house

1499
01:26:13,945 --> 01:26:15,805
Speaker 6:  And Neli will get onto the ladder.

1500
01:26:15,805 --> 01:26:18,645
Speaker 3:  I'll get on a ladder and I'll do, I mean we can do it together as, as this

1501
01:26:18,645 --> 01:26:18,925
Speaker 3:  is a service

1502
01:26:19,225 --> 01:26:21,965
Speaker 4:  He provide for all vergecast listeners. By the way, NELI will come

1503
01:26:21,965 --> 01:26:24,085
Speaker 6:  Your house. Here's my true payment for appearing on here. Yeah,

1504
01:26:24,555 --> 01:26:25,045
Speaker 3:  Exactly.

1505
01:26:25,905 --> 01:26:26,685
Speaker 6:  So, but

1506
01:26:26,685 --> 01:26:27,005
Speaker 3:  You have

1507
01:26:27,005 --> 01:26:27,205
Speaker 6:  To plug

1508
01:26:27,345 --> 01:26:29,765
Speaker 3:  But you have but you have to wire it into your garage door opener.

1509
01:26:29,905 --> 01:26:31,205
Speaker 6:  I'm going to get on a ladder. Yeah,

1510
01:26:31,205 --> 01:26:33,845
Speaker 3:  Yeah. You get on a ladder, you gotta find the screws, you gotta plug it into

1511
01:26:33,845 --> 01:26:37,685
Speaker 3:  the terminals and you gotta run a sensor wire to the door itself so it knows

1512
01:26:37,685 --> 01:26:39,645
Speaker 3:  when the doors open or closed. You can't

1513
01:26:40,325 --> 01:26:41,165
Speaker 4:  Possibly think that is like

1514
01:26:41,205 --> 01:26:44,365
Speaker 3:  A reasonable thing for a person. Can't. But I'm, that's where we're at. When

1515
01:26:44,365 --> 01:26:48,325
Speaker 3:  Craig Fedi is telling Joanna that he uses Siri

1516
01:26:48,325 --> 01:26:52,045
Speaker 3:  to open his garage door, you gotta watch this video. Joanna is like,

1517
01:26:52,375 --> 01:26:55,605
Speaker 3:  how's Siri doing with Apple Intelligence? And he is like, Siri's great. We

1518
01:26:56,165 --> 01:26:59,325
Speaker 3:  a billion queries a day. I use it to open my garage door and just,

1519
01:26:59,325 --> 01:27:02,005
Speaker 6:  Well that's 'cause I had also asked about the garage I'd given the example

1520
01:27:02,005 --> 01:27:05,885
Speaker 6:  of the garage. 'cause again, I do think Apple and Touch saying is very helpful

1521
01:27:05,905 --> 01:27:06,605
Speaker 6:  for the garage door. But I'm,

1522
01:27:06,605 --> 01:27:10,405
Speaker 3:  But but I'm saying If, you just sit in, the guy who runs all of software

1523
01:27:10,405 --> 01:27:13,965
Speaker 3:  at Apple is asking his phone to open his garage door. What it takes to

1524
01:27:14,405 --> 01:27:17,205
Speaker 3:  actually get there is so complicated.

1525
01:27:17,425 --> 01:27:21,405
Speaker 6:  But Craig and I did talk after, but he did say it has HomeKit

1526
01:27:21,405 --> 01:27:25,285
Speaker 6:  integrated, which leads me to believe that he had an old model that

1527
01:27:25,285 --> 01:27:27,925
Speaker 6:  when LiftMaster was like friendly,

1528
01:27:27,925 --> 01:27:28,685
Speaker 3:  There was never

1529
01:27:29,635 --> 01:27:33,015
Speaker 6:  No they did. They had some old model that had some HomeKit integration.

1530
01:27:33,905 --> 01:27:36,725
Speaker 3:  All right, so here's my two theories and again, v has listeners can help

1531
01:27:36,725 --> 01:27:40,645
Speaker 3:  me figure this out. We believe there are only a few options here.

1532
01:27:40,975 --> 01:27:44,845
Speaker 3:  Craig has a secret model of garage door opener, like the

1533
01:27:44,945 --> 01:27:48,325
Speaker 3:  big motor thing, right? That has home kid in it that no one else has ever

1534
01:27:48,325 --> 01:27:51,885
Speaker 3:  had in their lives. Right? He's got a custom, custom

1535
01:27:52,025 --> 01:27:55,965
Speaker 3:  garage door opener two, he's got a home

1536
01:27:55,965 --> 01:27:57,725
Speaker 3:  bridge in his house, which would be hilarious.

1537
01:27:59,605 --> 01:28:03,195
Speaker 3:  Truly hilarious. Like he's, he's running a, a little

1538
01:28:03,435 --> 01:28:07,235
Speaker 3:  raspberry pie Tamagotchi or three, some Apple engineer

1539
01:28:07,385 --> 01:28:10,675
Speaker 3:  came to set up Craig's house, put in one of these MIAs adapters and never

1540
01:28:10,675 --> 01:28:11,475
Speaker 3:  told him about it.

1541
01:28:13,135 --> 01:28:16,985
Speaker 3:  The those are your choices. 'cause there isn't a garage door

1542
01:28:16,985 --> 01:28:18,265
Speaker 3:  opener with HomeKit built into it.

1543
01:28:18,395 --> 01:28:22,225
Speaker 6:  There wasn't like, I don't know, no seven years ago and they were like,

1544
01:28:22,225 --> 01:28:25,305
Speaker 6:  Hey, you can get HomeKit and it had the nice little like logo on everything.

1545
01:28:25,945 --> 01:28:29,825
Speaker 6:  I I'm pretty sure there was a, either it was a lift master or something

1546
01:28:29,825 --> 01:28:30,865
Speaker 6:  that had that. I

1547
01:28:30,925 --> 01:28:34,905
Speaker 3:  I'm I'm, I'm asking the listeners my this is what The Vergecast is for.

1548
01:28:35,135 --> 01:28:38,865
Speaker 3:  Okay. We are crowdsourcing whether or not the big motor

1549
01:28:38,955 --> 01:28:40,705
Speaker 3:  thing with home kitten it existed

1550
01:28:40,855 --> 01:28:42,425
Speaker 6:  Because look, I should have gone further.

1551
01:28:42,495 --> 01:28:43,185
Speaker 3:  What do you think Craig Feder

1552
01:28:43,805 --> 01:28:44,985
Speaker 6:  My 20 minute interview.

1553
01:28:45,495 --> 01:28:47,825
Speaker 3:  Yeah, actually, and the other thing is like, can you imagine Craig's garage

1554
01:28:47,825 --> 01:28:50,465
Speaker 3:  door? Like do you think it like opens with like a light display

1555
01:28:51,805 --> 01:28:53,585
Speaker 3:  in my, it's like a Batman's house.

1556
01:28:55,025 --> 01:28:55,145
Speaker 6:  I,

1557
01:28:57,115 --> 01:29:00,935
Speaker 6:  he, I I should have a, I'm now regretting that I did not spend the 20 minutes

1558
01:29:00,965 --> 01:29:04,645
Speaker 6:  that I had with him really going deep on this. But I did ask him

1559
01:29:04,745 --> 01:29:07,285
Speaker 6:  at the end and he said, yeah, I've had one with home kit integrated.

1560
01:29:08,435 --> 01:29:08,725
Speaker 3:  Yeah.

1561
01:29:08,975 --> 01:29:12,445
Speaker 4:  Craig, if you're listening and I know that you are as you always do, hi Craig,

1562
01:29:13,195 --> 01:29:14,525
Speaker 4:  come on the show and tell us about your

1563
01:29:14,525 --> 01:29:15,685
Speaker 3:  Garage door. It's, I'm telling you,

1564
01:29:15,685 --> 01:29:19,245
Speaker 6:  Write us email just telling us how the ho the how it's integrated.

1565
01:29:19,355 --> 01:29:19,845
Speaker 6:  There's

1566
01:29:19,845 --> 01:29:22,565
Speaker 3:  Only three options. Yeah. He's got, he has one that no one's ever heard of.

1567
01:29:22,745 --> 01:29:25,365
Speaker 3:  No four options. He's got one that no one's ever heard of, which would be

1568
01:29:25,365 --> 01:29:28,165
Speaker 3:  incredible. Craig, please come on the show and tell us about your custom

1569
01:29:28,565 --> 01:29:32,205
Speaker 3:  engineered home kit. Garage door opener. He has the discontinued

1570
01:29:32,425 --> 01:29:36,365
Speaker 3:  MyQ home kit bridge. He's got a home bridge or hoops

1571
01:29:36,865 --> 01:29:39,245
Speaker 3:  or he is got one of these Mi Ross adapters. Those are the only choices.

1572
01:29:39,625 --> 01:29:43,485
Speaker 6:  Oh, the bridge. So sorry, choice number two is that, who made that

1573
01:29:43,485 --> 01:29:43,725
Speaker 6:  bridge

1574
01:29:44,225 --> 01:29:46,805
Speaker 3:  My queue before? And they di but they discontinued it. So it's not a choice.

1575
01:29:46,805 --> 01:29:46,965
Speaker 3:  So

1576
01:29:46,965 --> 01:29:48,165
Speaker 6:  It doesn't work with the API anymore.

1577
01:29:48,165 --> 01:29:50,285
Speaker 3:  Right? So if you're gonna be like, I, you seared open my thing all the time,

1578
01:29:50,465 --> 01:29:52,365
Speaker 3:  you can't get it. It's not a choice anymore.

1579
01:29:52,445 --> 01:29:52,925
Speaker 6:  'cause they cut that off.

1580
01:29:52,925 --> 01:29:53,725
Speaker 3:  Because they cut it off.

1581
01:29:55,005 --> 01:29:55,775
Speaker 4:  This is the worst

1582
01:29:55,865 --> 01:29:59,055
Speaker 3:  Smart home commercial in the history of universe. This is what I'm saying,

1583
01:29:59,055 --> 01:30:01,735
Speaker 3:  the universe, you can make the display and then you get all the way to, I

1584
01:30:01,735 --> 01:30:04,575
Speaker 6:  Also talk about this with my boss by the way, all the time. The, the deputy

1585
01:30:04,575 --> 01:30:08,255
Speaker 6:  editor in chief of the Wall Street Journal also has this problem. I really

1586
01:30:08,255 --> 01:30:10,935
Speaker 6:  think a lot of people have this problem and and they're not talking about

1587
01:30:10,935 --> 01:30:13,495
Speaker 6:  it, right? We need to talk about it. We need to

1588
01:30:13,495 --> 01:30:15,095
Speaker 3:  Talk, we need to raise awareness. Joanna,

1589
01:30:15,635 --> 01:30:19,215
Speaker 6:  We need to talk about this more and we need to talk about the

1590
01:30:19,255 --> 01:30:23,215
Speaker 6:  symbolic. I I just wanna drive away and not have

1591
01:30:23,215 --> 01:30:27,005
Speaker 6:  to tap a button. Let's just be clear by the way, like they did

1592
01:30:27,005 --> 01:30:30,045
Speaker 6:  solve this problem decades ago with a button.

1593
01:30:30,275 --> 01:30:34,115
Speaker 3:  Okay, we gotta wrap this up. I'm starting a small consulting company

1594
01:30:34,175 --> 01:30:36,075
Speaker 3:  to help people get their garage doors and the home kit.

1595
01:30:36,915 --> 01:30:38,095
Speaker 6:  And I'm his first client.

1596
01:30:38,285 --> 01:30:41,735
Speaker 3:  This is my exit plan. Joanna, we were gonna have you around for the lightning

1597
01:30:41,735 --> 01:30:44,295
Speaker 3:  round, but we did this for so long that you have to go.

1598
01:30:45,265 --> 01:30:49,125
Speaker 6:  I'm sorry, I have to go see my child in a parade. A

1599
01:30:49,125 --> 01:30:49,845
Speaker 6:  Halloween parade.

1600
01:30:50,345 --> 01:30:54,165
Speaker 3:  All right, well, we'll, we'll we'll figure out how to fix

1601
01:30:54,405 --> 01:30:55,685
Speaker 3:  your garage door until later time. Thank

1602
01:30:55,685 --> 01:30:59,305
Speaker 6:  You so much. And I just also wanna say that I have gotten

1603
01:30:59,535 --> 01:31:03,145
Speaker 6:  many notifications in this podcast that were not

1604
01:31:03,145 --> 01:31:06,705
Speaker 6:  important to me and were not a priority.

1605
01:31:06,925 --> 01:31:09,825
Speaker 3:  All of them were from Liam, the producer being like, stop talking about the

1606
01:31:09,825 --> 01:31:10,105
Speaker 3:  garage

1607
01:32:46,135 --> 01:32:48,445
Speaker 3:  We'll let the AI figure out which ones to send you. I would

1608
01:32:48,445 --> 01:32:50,725
Speaker 6:  Like them to come to my house to fix my garage. Goodbye.

1609
01:32:50,815 --> 01:32:51,445
Speaker 3:  We'll be right back.

1610
01:32:56,385 --> 01:32:57,045
Speaker 3:  All right, we're back.

1611
01:32:59,265 --> 01:33:02,425
Speaker 3:  I don't know what you heard in that last segment.

1612
01:33:03,785 --> 01:33:07,145
Speaker 3:  I don't know how much we're gonna keep. I just want you to know

1613
01:33:08,015 --> 01:33:11,825
Speaker 3:  that the garage door conversation with Joanna went on for

1614
01:33:12,085 --> 01:33:12,705
Speaker 3:  so long.

1615
01:33:13,125 --> 01:33:13,745
Speaker 4:  Oh my God.

1616
01:33:15,225 --> 01:33:18,795
Speaker 3:  Like however long you think that actually went for or whatever you just

1617
01:33:18,795 --> 01:33:22,435
Speaker 3:  experienced. It was at least three times as long.

1618
01:33:24,635 --> 01:33:28,325
Speaker 4:  Yeah. We made Joanna late for her child because we were talking about garage

1619
01:33:28,325 --> 01:33:28,765
Speaker 4:  door openers

1620
01:33:28,845 --> 01:33:31,445
Speaker 3:  A child that she only experiences through smartphone notification

1621
01:33:31,705 --> 01:33:33,645
Speaker 4:  Who is named child according to her phone.

1622
01:33:33,755 --> 01:33:37,605
Speaker 3:  Yeah. Alright. That also means the show is way

1623
01:33:37,625 --> 01:33:41,485
Speaker 3:  too long, so we gotta get through this lightning out real fast. David, do

1624
01:33:41,485 --> 01:33:41,845
Speaker 3:  you wanna start?

1625
01:33:42,395 --> 01:33:46,285
Speaker 4:  Yeah, So I. Just want to really quickly mention this

1626
01:33:46,285 --> 01:33:50,205
Speaker 4:  new thing Netflix launched called Moments, which basically lets

1627
01:33:50,205 --> 01:33:54,005
Speaker 4:  you just link to a specific part of a

1628
01:33:54,065 --> 01:33:56,765
Speaker 4:  TV show or movie. And on the one hand,

1629
01:33:57,745 --> 01:33:59,655
Speaker 4:  incredibly boring feature. Yeah. Right? Like

1630
01:33:59,845 --> 01:34:03,095
Speaker 3:  Netflix launches, anchor links. Yeah. 1986.

1631
01:34:03,875 --> 01:34:07,855
Speaker 4:  Yes, very true. Completely agree. On the other hand, Netflix has

1632
01:34:07,855 --> 01:34:11,215
Speaker 4:  been so incredibly averse to any

1633
01:34:11,565 --> 01:34:15,455
Speaker 4:  kind of social interaction with its product

1634
01:34:15,485 --> 01:34:18,935
Speaker 4:  over the years that I just find the existence of anything like this really

1635
01:34:19,215 --> 01:34:22,455
Speaker 4:  fascinating. Like we've talked many times on this show over the years about

1636
01:34:22,455 --> 01:34:26,255
Speaker 4:  how weird it is that you can't screenshot a Netflix show. Like in

1637
01:34:26,255 --> 01:34:28,335
Speaker 4:  in a, in the world in which we live where

1638
01:34:28,335 --> 01:34:28,935
Speaker 3:  On a, a phone,

1639
01:34:29,345 --> 01:34:32,975
Speaker 4:  Right? Sure. Yeah, you can, you can do it, you can hack your way into it.

1640
01:34:32,975 --> 01:34:36,335
Speaker 4:  But like if I'm watching something on Netflix and I'm like, whoa, and I wanna

1641
01:34:36,335 --> 01:34:40,135
Speaker 4:  send it to someone, you can't. It's, it's illegal and not

1642
01:34:40,135 --> 01:34:41,135
Speaker 4:  allowed and impossible.

1643
01:34:41,325 --> 01:34:45,095
Speaker 3:  Well, people do it on lap. I just wanna be clear on mobile devices

1644
01:34:45,155 --> 01:34:49,055
Speaker 3:  and TV devices on laptops. People are screenshotting and sharing

1645
01:34:49,055 --> 01:34:49,895
Speaker 3:  Netflix all over the place.

1646
01:34:50,085 --> 01:34:53,695
Speaker 4:  Sure. I don't think that's the primary place most people are

1647
01:34:53,895 --> 01:34:54,735
Speaker 4:  interacting with Netflix.

1648
01:34:55,615 --> 01:34:58,150
Speaker 3:  I guess the, the, there's like a weird measurement bias there because the

1649
01:34:58,150 --> 01:35:00,165
Speaker 3:  only screenshots I see of Netflix are from people with apps.

1650
01:35:00,835 --> 01:35:03,965
Speaker 4:  This is, this is the point, right? Yeah. But I think, and, and I think if,

1651
01:35:03,965 --> 01:35:07,685
Speaker 4:  if Netflix had better tooling to prevent you from doing it on a laptop, it

1652
01:35:07,685 --> 01:35:11,525
Speaker 4:  would do so too. That is all neither here nor there. Just the fact

1653
01:35:11,525 --> 01:35:15,125
Speaker 4:  that Netflix is engaging more in society

1654
01:35:15,305 --> 01:35:18,205
Speaker 4:  in this way I think is really interesting, right? Like there's a, there's

1655
01:35:18,205 --> 01:35:22,085
Speaker 4:  an alternate future of Netflix where it engaged much more and there

1656
01:35:22,085 --> 01:35:25,365
Speaker 4:  was like shorts inside of Netflix that creators were starting to do and Netflix

1657
01:35:25,475 --> 01:35:29,445
Speaker 4:  just like leaned into like we're gonna be premium TikTok in, in a

1658
01:35:29,445 --> 01:35:33,285
Speaker 4:  way that Netflix really talks about itself now as premium YouTube even

1659
01:35:33,505 --> 01:35:37,405
Speaker 4:  on their earnings calls. Like that's how the company frames itself in

1660
01:35:37,405 --> 01:35:41,365
Speaker 4:  very real ways. It's how they're selling ads. It's like Netflix sees

1661
01:35:41,365 --> 01:35:44,965
Speaker 4:  itself as high-end YouTube in so many real ways and

1662
01:35:45,745 --> 01:35:49,005
Speaker 4:  yet has tried so hard to be this little tiny insular, like this is where

1663
01:35:49,005 --> 01:35:52,925
Speaker 4:  you watch shows and nothing else universe. And so any tiny

1664
01:35:52,925 --> 01:35:56,805
Speaker 4:  moment where you can like capture something else and

1665
01:35:56,805 --> 01:36:00,045
Speaker 4:  take it out of Netflix, I just think is really interesting. I dunno if anyone

1666
01:36:00,045 --> 01:36:01,045
Speaker 4:  will use this feature, but I think it's

1667
01:36:01,045 --> 01:36:03,725
Speaker 3:  Really interesting. Here's my conspiracy theory, okay? This is pure conspiracy

1668
01:36:03,725 --> 01:36:07,455
Speaker 3:  theory. Love it. The single best discovery app

1669
01:36:07,455 --> 01:36:11,285
Speaker 3:  Netflix could launch would be TikTok for Netflix, right?

1670
01:36:11,295 --> 01:36:15,005
Speaker 3:  Where you just flip through clips. Yeah. and it just shows you this way that

1671
01:36:15,005 --> 01:36:18,605
Speaker 3:  people are watching pirate movies on TikTok today and they don't know what

1672
01:36:18,615 --> 01:36:21,525
Speaker 3:  clips to pick and they can't go through the whole catalog and pick everything.

1673
01:36:21,545 --> 01:36:25,125
Speaker 3:  Oh. So you watch a feature like this where people are bookmarking their favorite

1674
01:36:25,125 --> 01:36:28,925
Speaker 3:  parts of shows and suddenly you have a library of places to clip from. Oh.

1675
01:36:29,225 --> 01:36:32,405
Speaker 4:  And then that becomes the thing also when you go to the home screen and it

1676
01:36:32,405 --> 01:36:35,045
Speaker 4:  like, you know how it starts playing, maybe it starts playing a clip that

1677
01:36:35,045 --> 01:36:38,365
Speaker 4:  everybody likes. That's a good theory. If Netflix isn't doing that, they

1678
01:36:38,365 --> 01:36:40,725
Speaker 4:  should be and they should pay it. Me as consulting firm,

1679
01:36:42,145 --> 01:36:46,005
Speaker 3:  I'm gonna go to Ted Strand's house. We're gonna do, we're gonna work on the

1680
01:36:46,005 --> 01:36:48,765
Speaker 3:  garage door opener. I'm gonna pitch him TikTok for Netflix. I would love

1681
01:36:48,765 --> 01:36:52,405
Speaker 3:  that. We had Greg Peters the, the product CEO of Netflix on

1682
01:36:52,435 --> 01:36:55,885
Speaker 3:  decoder. Every time I have a streaming service, CEOI ask him about TikTok

1683
01:36:55,885 --> 01:36:59,365
Speaker 3:  and piracy to TikTok and whether there's a TikTok to streaming service

1684
01:36:59,725 --> 01:37:02,485
Speaker 3:  pipeline or whether they would build a TikTok and they all just sort of,

1685
01:37:03,145 --> 01:37:05,885
Speaker 3:  you know, they, they Westworld at me, they're like, doesn't look like anything

1686
01:37:05,885 --> 01:37:09,235
Speaker 3:  to me, and I'm gonna break through one of these days.

1687
01:37:09,465 --> 01:37:12,675
Speaker 4:  Yeah. There's just no way. It's true. And, and yeah, you would think I have

1688
01:37:12,675 --> 01:37:16,395
Speaker 4:  watched, so here's a fun example. I was home from work sick

1689
01:37:16,455 --> 01:37:20,195
Speaker 4:  on Monday, and I watched the movie in time with Justin Timberlake. Oh man,

1690
01:37:20,195 --> 01:37:21,995
Speaker 4:  that's, do you know why that's a great movie? Do you know why I watched that

1691
01:37:21,995 --> 01:37:25,915
Speaker 4:  movie? Because I've seen so many 62nd clips of

1692
01:37:25,915 --> 01:37:28,995
Speaker 4:  it on TikTok that I was like, I literally, I got to the point, I was like,

1693
01:37:28,995 --> 01:37:32,715
Speaker 4:  I need to just watch this damn movie. So I was at home and I watched it

1694
01:37:32,855 --> 01:37:36,715
Speaker 4:  and it rips and everyone should watch it. It's possible that I was

1695
01:37:36,715 --> 01:37:37,795
Speaker 4:  just sick and delirious. But

1696
01:37:38,015 --> 01:37:41,635
Speaker 3:  The movie, you have to be slightly altered to be like, this movie rips,

1697
01:37:41,745 --> 01:37:45,355
Speaker 3:  like, it's good. It's an underrated gem of a movie. It's a good time. Yeah.

1698
01:37:45,535 --> 01:37:49,475
Speaker 3:  The central conceit is good. The jokes are good. And then the cars are

1699
01:37:49,475 --> 01:37:52,315
Speaker 3:  awesome. And I'm pretty confident Hyundai is designing all of its cars to

1700
01:37:52,315 --> 01:37:54,995
Speaker 3:  look like they can bring the movie in time. Oh, they are. See what I'm saying?

1701
01:37:55,005 --> 01:37:55,365
Speaker 3:  Saying, whoa,

1702
01:37:55,705 --> 01:37:58,605
Speaker 4:  That's totally true. But no, but I think that that connection

1703
01:37:59,805 --> 01:38:03,585
Speaker 4:  is real. And, and I think it's the, in the same way that with music,

1704
01:38:03,585 --> 01:38:06,305
Speaker 4:  right? That it's always like, why isn't there just a listen to this on Spotify

1705
01:38:06,305 --> 01:38:09,905
Speaker 4:  button next to every TikTok video. And TikTok is in fact building a music

1706
01:38:09,925 --> 01:38:13,785
Speaker 4:  app to do just that. There is connection there that should exist

1707
01:38:13,805 --> 01:38:16,905
Speaker 4:  and it makes sense that Netflix might wanna do more of it on purpose. Yeah.

1708
01:38:17,645 --> 01:38:18,065
Speaker 3:  What's

1709
01:38:18,065 --> 01:38:18,265
Speaker 4:  Yours?

1710
01:38:18,895 --> 01:38:22,865
Speaker 3:  Mine is just a clip of our friend Tony Fidel. So it was

1711
01:38:22,865 --> 01:38:26,465
Speaker 3:  Tech Crunch Disrupt this week, big conference, famous

1712
01:38:27,535 --> 01:38:31,065
Speaker 3:  Matt Malig was on stage there. He said A fork of WordPress would be fine.

1713
01:38:31,195 --> 01:38:34,385
Speaker 3:  We're gonna keep hovering that somehow. I'm just, I'm letting you, there's

1714
01:38:34,385 --> 01:38:37,665
Speaker 3:  zero things that happen in TechCrunch Disrupt. And then Tony Fadell who

1715
01:38:38,105 --> 01:38:41,785
Speaker 3:  worked at Apple for ages was one of the

1716
01:38:41,975 --> 01:38:45,785
Speaker 3:  contested fathers of the iPod. That's a big fight. That's fun to talk about.

1717
01:38:46,605 --> 01:38:50,425
Speaker 3:  But he did the bring up of the iPod. He worked on the iPhone for several

1718
01:38:50,465 --> 01:38:54,105
Speaker 3:  generations and he left, he founded Nest, he sold it to Google. He fought

1719
01:38:54,105 --> 01:38:57,665
Speaker 3:  with everybody at Google, and now he's a vc. This is the short version of

1720
01:38:57,665 --> 01:39:00,345
Speaker 3:  Tony. Phil. Tony's a character. He's been on decoder a number of times. We've

1721
01:39:00,345 --> 01:39:04,265
Speaker 3:  known Tony forever. He's on stage a tech conscious disrupt talking

1722
01:39:04,265 --> 01:39:07,105
Speaker 3:  about ai, and he basically says, Sam Altman is full of shit.

1723
01:39:08,285 --> 01:39:10,195
Speaker 3:  We're just run the clip. Just run the clip.

1724
01:39:10,895 --> 01:39:14,755
Speaker 7:  We are using this stuff and we don't even know how it works. And believe

1725
01:39:14,755 --> 01:39:18,435
Speaker 7:  me, I understand. I've been doing AI for 15 years. People So, I, I'm, I'm

1726
01:39:18,435 --> 01:39:21,875
Speaker 7:  not just spouting shit. I'm not Sam Altman. Okay.

1727
01:39:22,855 --> 01:39:26,595
Speaker 7:  So, so seriously, you gotta know what you're

1728
01:39:26,595 --> 01:39:30,395
Speaker 7:  hiring here. You gotta know what you're using. Yeah. And if we don't have

1729
01:39:30,395 --> 01:39:34,355
Speaker 7:  transparency on data, we don't have transparency on hallucinations,

1730
01:39:35,095 --> 01:39:37,555
Speaker 7:  you are setting yourself up for a fucking disaster.

1731
01:39:38,175 --> 01:39:40,675
Speaker 3:  So I Wanna be clear? I love Tony Fidel.

1732
01:39:40,975 --> 01:39:44,675
Speaker 4:  My only note on this would be that when we were talking about this link in

1733
01:39:44,685 --> 01:39:48,515
Speaker 4:  Slack, and I forget who it was, but somebody was like, is this,

1734
01:39:48,615 --> 01:39:52,155
Speaker 4:  is this like what Tony is always like? And without missing a beat, Mila just

1735
01:39:52,155 --> 01:39:52,915
Speaker 4:  goes, yeah, this is Tony.

1736
01:39:53,305 --> 01:39:54,515
Speaker 3:  This is what Tony is always like,

1737
01:39:54,515 --> 01:39:55,155
Speaker 4:  This is a Tony.

1738
01:39:55,435 --> 01:39:58,235
Speaker 3:  I had Tony and Decoder talk about his book about how to be a good leader.

1739
01:39:58,255 --> 01:40:02,075
Speaker 3:  and it was this, yeah, you should go listen to that episode. He's

1740
01:40:02,075 --> 01:40:05,935
Speaker 3:  not wrong. He's not wrong. Right. Yeah. We, we,

1741
01:40:06,235 --> 01:40:10,215
Speaker 3:  we, I keep describing the current state of ai. We, we talked about this all

1742
01:40:10,215 --> 01:40:12,135
Speaker 3:  the beginning of the show, but I keep describing the current state of AI

1743
01:40:12,135 --> 01:40:15,735
Speaker 3:  is like, we are spending billions of dollars to build Bluetooth. And

1744
01:40:15,955 --> 01:40:19,415
Speaker 3:  no one knows what the headphones are gonna look like. Like no one can be

1745
01:40:19,415 --> 01:40:21,895
Speaker 3:  like, I'm gonna make really good headphones outta this. It's more like, these

1746
01:40:21,895 --> 01:40:25,775
Speaker 3:  headphones might kill you. We have to build Bluetooth as expensively as

1747
01:40:25,975 --> 01:40:29,935
Speaker 3:  possible. It's a great clip. I I, you know, readers are gonna say,

1748
01:40:29,935 --> 01:40:33,535
Speaker 3:  what does Tony know about ai? Fine. Whatever. It's not, I don't think my

1749
01:40:33,535 --> 01:40:36,815
Speaker 3:  Nest thermostat is a platform shift that threatens Google.

1750
01:40:37,675 --> 01:40:40,535
Speaker 3:  It did threaten Google for other reasons. It was a disaster of an acquisition.

1751
01:40:40,535 --> 01:40:43,415
Speaker 3:  Yeah, it did do that. It is effectively come to nothing for that company.

1752
01:40:44,995 --> 01:40:48,695
Speaker 3:  But Sam Altman's spouting shit, man. That's some fighting words.

1753
01:40:49,205 --> 01:40:52,855
Speaker 4:  It's, it's pretty good. And you could tell he knew it was a line too. He

1754
01:40:52,855 --> 01:40:56,285
Speaker 4:  said it and then like kind of grins and sort of leans back in his chair a

1755
01:40:56,285 --> 01:40:57,485
Speaker 4:  little bit and he's like, yeah. Got him.

1756
01:40:57,755 --> 01:41:01,525
Speaker 3:  Yeah. And then he stands up and starts screaming again. It's great. All right,

1757
01:41:01,525 --> 01:41:05,485
Speaker 3:  we gotta end with this one. Tim Walls and a OC played Madden on Twitch

1758
01:41:05,605 --> 01:41:09,445
Speaker 3:  together last week. I whatever. You got a campaign,

1759
01:41:09,465 --> 01:41:12,085
Speaker 3:  how we're gonna campaign or everyone's going on podcast, we're do a thing.

1760
01:41:12,445 --> 01:41:15,405
Speaker 3:  I just wanna point out, and I just wanna say this because I know David understands

1761
01:41:15,405 --> 01:41:19,365
Speaker 3:  this as deeply as I do. Playing Madden with an audience is

1762
01:41:19,785 --> 01:41:23,565
Speaker 3:  one of the most high stakes things you can do because Madden 24 is

1763
01:41:23,665 --> 01:41:24,205
Speaker 3:  so hard.

1764
01:41:24,625 --> 01:41:28,565
Speaker 4:  It, it really, it is such an intricate game that it's

1765
01:41:28,565 --> 01:41:32,085
Speaker 4:  like, it it, they should have just played Overwatch. Like it would've been

1766
01:41:32,085 --> 01:41:33,405
Speaker 4:  less complicated. They

1767
01:41:33,405 --> 01:41:37,085
Speaker 3:  Did at, at the end they started playing Crazy Taxi. That's after, after my

1768
01:41:37,085 --> 01:41:39,525
Speaker 3:  prediction came to pass, Tim wa threw an interception.

1769
01:41:40,265 --> 01:41:42,525
Speaker 4:  Didn't neither of them score. Like it's, it's

1770
01:41:42,525 --> 01:41:45,085
Speaker 3:  Pretty embarrassing. This game is too hard. I play this game almost every

1771
01:41:45,085 --> 01:41:49,045
Speaker 3:  night to unwind. I've been playing it since I was a child. I've won

1772
01:41:49,085 --> 01:41:53,005
Speaker 3:  a Game Cube playing Madden in a

1773
01:41:53,005 --> 01:41:56,485
Speaker 3:  Madden tournament in a bar hammered. I was good at this game. The new version

1774
01:41:56,585 --> 01:41:57,285
Speaker 3:  is so,

1775
01:41:57,805 --> 01:41:59,265
Speaker 4:  Yeah. Yeah.

1776
01:41:59,865 --> 01:42:02,625
Speaker 3:  I just thought it was the, the riskiest campaign event I've ever seen. And

1777
01:42:02,625 --> 01:42:06,025
Speaker 3:  Indeed Tim Wall's Vikings fan tried to gun into

1778
01:42:06,045 --> 01:42:09,145
Speaker 3:  Justin Jefferson and immediately through an interception, which is,

1779
01:42:09,945 --> 01:42:13,105
Speaker 3:  I can't encapsulate what the new Madden is like. More than that.

1780
01:42:14,485 --> 01:42:18,185
Speaker 4:  It was very good. I I appreciated both the like

1781
01:42:18,605 --> 01:42:22,185
Speaker 4:  effort and the immediate understanding of, oh, this is not going to go very

1782
01:42:22,185 --> 01:42:22,425
Speaker 4:  well.

1783
01:42:23,285 --> 01:42:24,345
Speaker 3:  You shouldn't do this.

1784
01:42:24,345 --> 01:42:25,865
Speaker 4:  They just bailed. They didn't even finish the

1785
01:42:25,865 --> 01:42:27,185
Speaker 3:  Game. It just gave

1786
01:42:27,185 --> 01:42:28,985
Speaker 4:  Up. Which is, I've done that many times.

1787
01:42:29,365 --> 01:42:31,105
Speaker 3:  We are so over. We gotta wrap this

1788
01:42:31,105 --> 01:42:33,385
Speaker 4:  Thing up. Oh wait, before we go though, one, what re should just talk about

1789
01:42:33,385 --> 01:42:37,185
Speaker 4:  this real fast. It's an election on Tuesday. We did a whole

1790
01:42:37,185 --> 01:42:41,145
Speaker 4:  package of election stuff. The package is very good. You, you

1791
01:42:41,145 --> 01:42:45,025
Speaker 4:  wrote a big fiery endorsement that has caused a lot of feelings

1792
01:42:45,045 --> 01:42:48,745
Speaker 4:  on the internet. Should we talk about that? I'm like, I'm both, I want to

1793
01:42:48,745 --> 01:42:49,905
Speaker 4:  and I don't want to at the same time.

1794
01:42:50,445 --> 01:42:52,225
Speaker 3:  We, we can talk about it for a minute. Okay.

1795
01:42:53,785 --> 01:42:57,155
Speaker 3:  Wait, I got a lot of notes are like, let let politics bleed into the more,

1796
01:42:57,175 --> 01:43:01,035
Speaker 3:  and sometimes I do. There was a net neutrality hearing today. I

1797
01:43:01,155 --> 01:43:04,995
Speaker 3:  I can talk about that all day long. That's very political. But in this

1798
01:43:04,995 --> 01:43:08,315
Speaker 3:  case, I'll just say two things about the endorsement. One,

1799
01:43:09,055 --> 01:43:12,115
Speaker 3:  we, like every news organization we actually like went back and forth and

1800
01:43:12,115 --> 01:43:14,795
Speaker 3:  whether to do it. But that's just the thing that happened. Those were meetings

1801
01:43:14,795 --> 01:43:18,435
Speaker 3:  we were in. We published a lot of them before So I. Think we

1802
01:43:18,475 --> 01:43:22,315
Speaker 3:  endorsed Obama in 2012. We endorsed Biden last time

1803
01:43:22,475 --> 01:43:26,355
Speaker 3:  I wrote those. We did not endorse Hillary or Trump in 2016. And I'm

1804
01:43:26,355 --> 01:43:28,955
Speaker 3:  sorry, I'm sorry for that outcome. I think I could have swayed that election.

1805
01:43:30,075 --> 01:43:33,555
Speaker 3:  I would've really bounced out the Comey letter. I don't know.

1806
01:43:34,135 --> 01:43:37,155
Speaker 3:  We didn't. So that's the history. Those are the ones we've done in the past.

1807
01:43:37,255 --> 01:43:40,955
Speaker 3:  You can read the ones in the past that one of Biden in

1808
01:43:40,955 --> 01:43:44,395
Speaker 3:  2020, very similar to the one ever wrote today. It just, the thing that got

1809
01:43:44,395 --> 01:43:47,515
Speaker 3:  me and the thing I've been thinking about, we write about policy all the

1810
01:43:47,515 --> 01:43:51,365
Speaker 3:  time in The Verge, which all the time, and they are just systems, right?

1811
01:43:51,435 --> 01:43:55,325
Speaker 3:  Like the legal system is a system and congress

1812
01:43:55,345 --> 01:43:59,285
Speaker 3:  is a system. And when we describe the systems to the

1813
01:43:59,565 --> 01:44:03,365
Speaker 3:  audience of The Verge, who is, who are, which is comprised of a lot of people

1814
01:44:03,365 --> 01:44:06,565
Speaker 3:  who build things and make things and care about how things are made, fine.

1815
01:44:06,885 --> 01:44:10,605
Speaker 3:  Everyone gets it. And then the the turn is, but these aren't computers. They're

1816
01:44:10,605 --> 01:44:14,525
Speaker 3:  not predictable for any given set of inputs. You don't get a predictable

1817
01:44:14,525 --> 01:44:18,445
Speaker 3:  set of outputs. Right? And now in the age of ai, who knows? But Right. But

1818
01:44:18,545 --> 01:44:21,325
Speaker 3:  for the most part, people who like work with computers expect the systems

1819
01:44:21,545 --> 01:44:24,745
Speaker 3:  to be predictable. And the government isn't,

1820
01:44:25,435 --> 01:44:29,215
Speaker 3:  the legal system isn't. So that has always, that's always been the

1821
01:44:29,235 --> 01:44:31,975
Speaker 3:  key to how we cover policy here. We describe the system and then we point

1822
01:44:31,975 --> 01:44:35,695
Speaker 3:  out like, this isn't predictable. Like actual people have to just keep doing

1823
01:44:35,695 --> 01:44:38,535
Speaker 3:  it. Right? and it just really occurred to me that

1824
01:44:39,815 --> 01:44:43,795
Speaker 3:  all for all of the babbling about democracy that everyone is doing, no one

1825
01:44:43,795 --> 01:44:47,275
Speaker 3:  has explained like why it's important or like why that's the system. Yeah.

1826
01:44:47,615 --> 01:44:51,355
Speaker 3:  So that was the approach I took with f-bombs. 'cause I, you know, I'm me,

1827
01:44:52,635 --> 01:44:56,035
Speaker 3:  I hope it worked, it, the feedback was great. I was expecting chaos

1828
01:44:56,635 --> 01:45:00,555
Speaker 3:  a nightmare. And I am just very encouraged and heartened that what I got

1829
01:45:00,575 --> 01:45:03,835
Speaker 3:  was the most comments on any article since we switched to Coral.

1830
01:45:05,815 --> 01:45:09,355
Speaker 3:  Mostly entirely respectful. Obviously we did some moderating into our house

1831
01:45:09,355 --> 01:45:12,555
Speaker 3:  Yeah. To keep it clean, but mostly respectful, mostly engaged. The feedback

1832
01:45:12,555 --> 01:45:16,115
Speaker 3:  from the social networks was mostly good. Obviously it's very distracting

1833
01:45:16,355 --> 01:45:20,195
Speaker 3:  at there. Like there are other things to talk about, but I am just, I was

1834
01:45:20,195 --> 01:45:23,715
Speaker 3:  very proud of our audience Yeah. For engaging with the thing. And I know

1835
01:45:23,715 --> 01:45:26,075
Speaker 3:  I gave it this like incredibly spicy headline, but I stand by the headline,

1836
01:45:26,075 --> 01:45:28,915
Speaker 3:  the argument and the piece is the headline. Yeah. And so I'm, I'm just happy

1837
01:45:28,915 --> 01:45:32,545
Speaker 3:  people took it seriously. They read it. They're paying attention.

1838
01:45:33,345 --> 01:45:37,275
Speaker 3:  They're bought into America, which is I think, important. So

1839
01:45:37,275 --> 01:45:40,635
Speaker 3:  yeah, that's, I don't, I don't, I don't wanna like overdo it. I, I said what

1840
01:45:40,675 --> 01:45:44,115
Speaker 3:  I needed to say, I published in text because I'm still a writer at heart

1841
01:45:44,115 --> 01:45:47,835
Speaker 3:  and I hope the internet continues to be a place for text to live. Yeah. I

1842
01:45:47,835 --> 01:45:49,195
Speaker 3:  don't, I don't know if there's much more to say.

1843
01:45:49,265 --> 01:45:51,875
Speaker 4:  Yeah, fair enough. Yeah, it's, we'll, we'll link all the stuff in the show

1844
01:45:51,875 --> 01:45:55,475
Speaker 4:  notes. The, the package is really great. Gabby DelVal, just one other shout

1845
01:45:55,475 --> 01:45:59,395
Speaker 4:  out, wrote a piece for us today, Thursday about all the tech leaders who

1846
01:45:59,395 --> 01:46:02,555
Speaker 4:  have basically fallen all over themselves to cozy up to Trump just in case

1847
01:46:02,555 --> 01:46:06,235
Speaker 4:  he wins. That is something we could spend many hours talking about. And I

1848
01:46:06,235 --> 01:46:09,315
Speaker 4:  super don't want to, so let's not, but go read that piece. It's very good.

1849
01:46:09,315 --> 01:46:13,035
Speaker 4:  We'll put all that in the show notes too. But yeah, it was, it was good.

1850
01:46:13,155 --> 01:46:16,475
Speaker 4:  I really liked the endorsement. It was a, it was a, it was a project for

1851
01:46:16,475 --> 01:46:20,235
Speaker 4:  you to get that thing done and, and out. And I think saying all those words

1852
01:46:20,235 --> 01:46:24,035
Speaker 4:  in a row takes a lot out of you sometimes. But it was very good.

1853
01:46:24,145 --> 01:46:24,515
Speaker 4:  It's good

1854
01:46:24,515 --> 01:46:28,075
Speaker 3:  Stuff. You know, it's funny, I'll just end on this note and just,

1855
01:46:29,105 --> 01:46:32,955
Speaker 3:  there's like, we have a lot of friends and colleagues who have gone off to

1856
01:46:32,955 --> 01:46:36,475
Speaker 3:  go be indies on various platforms in various ways, and we wish them well.

1857
01:46:36,675 --> 01:46:40,555
Speaker 3:  I, I, I hope people can see, we actively try to support all of

1858
01:46:40,555 --> 01:46:44,355
Speaker 3:  our former coworkers who have gone on to start things. I want them to succeed.

1859
01:46:45,305 --> 01:46:47,605
Speaker 3:  And that's a trend, right? Everyone's talking about that trend. This is what

1860
01:46:47,605 --> 01:46:51,385
Speaker 3:  you should go do for me to do this. Like, if I

1861
01:46:51,445 --> 01:46:54,225
Speaker 3:  ran a substack, I think it would be pretty empty. I don't know if it would

1862
01:46:54,225 --> 01:46:57,625
Speaker 3:  go anywhere. Like you need the platform, you need the group work.

1863
01:46:58,145 --> 01:47:02,065
Speaker 3:  I needed an art department that went and hired an amazing artist to put that

1864
01:47:02,065 --> 01:47:04,745
Speaker 3:  piece of art at the top of that and every other part of our package. And

1865
01:47:04,785 --> 01:47:08,185
Speaker 3:  I desperately needed a huge group of editors

1866
01:47:08,765 --> 01:47:12,465
Speaker 3:  who I trust to fight with me on almost every single sentence to make sure

1867
01:47:12,465 --> 01:47:15,705
Speaker 3:  the sentences were great. And that's, and then we needed the, you know, the

1868
01:47:15,705 --> 01:47:18,825
Speaker 3:  Virg logo and our big website and all this stuff. And that is important.

1869
01:47:19,325 --> 01:47:23,235
Speaker 3:  And like that, I just, I, we've talked a lot

1870
01:47:23,485 --> 01:47:27,395
Speaker 3:  about both garage doors and the future of media on this episode of Vergecast.

1871
01:47:27,735 --> 01:47:31,595
Speaker 3:  That's what we do here. That's, that's us. We published

1872
01:47:31,635 --> 01:47:34,075
Speaker 3:  a presidential endorsement on the same day as like a new Mac mini.

