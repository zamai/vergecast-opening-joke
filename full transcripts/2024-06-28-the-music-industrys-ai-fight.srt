1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: 60028001-4969-4941-ac12-05fed5cec7d8
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/6275216506023703371/-913261400835456250/s93290-US-5608s-1719564615.mp3
Description: The Verge's Nilay Patel and David Pierce chat with Switched on Pop's Charlie Harding about the RIAA lawsuit against AI music startups Udio and Suno. Later, Nilay and David discuss the rest of this week's tech and gadget news.

2
00:01:15,635 --> 00:01:16,965
Speaker 5:  That one track needs

3
00:01:56,885 --> 00:01:59,685
Speaker 5:  of the world. There's a bunch of new phone events coming that just got announced.

4
00:01:59,685 --> 00:02:03,565
Speaker 5:  We shock about, there are new party speakers from ultimate years. That's

5
00:02:03,565 --> 00:02:06,165
Speaker 5:  very important to me. And we got a lightning around. We got a, we got a full

6
00:02:06,165 --> 00:02:10,125
Speaker 5:  show before, before the 4th of July. This is America's

7
00:02:10,125 --> 00:02:14,085
Speaker 5:  technology podcast. But before we begin, I have

8
00:02:14,085 --> 00:02:15,005
Speaker 5:  to issue a correction.

9
00:02:16,615 --> 00:02:20,605
Speaker 5:  There are some words that I only read and I never

10
00:02:20,745 --> 00:02:21,365
Speaker 5:  say out loud.

11
00:02:21,745 --> 00:02:22,245
Speaker 3:  Ooh. Which

12
00:02:22,245 --> 00:02:26,165
Speaker 5:  One is that? There are lots of those words. Tons of 'em. I was a, I was a

13
00:02:26,295 --> 00:02:30,285
Speaker 5:  small nerdy child in the middle of Wisconsin who read a

14
00:02:30,285 --> 00:02:33,125
Speaker 5:  lot of books that the other children in Wisconsin were not interested in

15
00:02:33,125 --> 00:02:35,885
Speaker 5:  this. Just a whole universe of vocabulary words.

16
00:02:36,155 --> 00:02:39,365
Speaker 6:  What is like your main one from when you were a kid that you, you were like

17
00:02:39,365 --> 00:02:43,165
Speaker 6:  26 and all of a I feel like chameleon is like the classic of genre.

18
00:02:43,225 --> 00:02:46,285
Speaker 6:  Oh, that's a good one. Right. Where like half the people in the world grew

19
00:02:46,285 --> 00:02:50,045
Speaker 6:  up thinking it was Chama Leon. For me it was learning that Hermione name

20
00:02:50,045 --> 00:02:52,805
Speaker 6:  is Hermione and not Hermien as I called her. Oh,

21
00:02:52,805 --> 00:02:53,125
Speaker 5:  That's good.

22
00:02:53,155 --> 00:02:56,245
Speaker 6:  However many books I read before I saw the movies. Did you guys have these

23
00:02:56,245 --> 00:02:57,085
Speaker 6:  that you grew up with?

24
00:02:58,005 --> 00:02:58,285
Speaker 5:  I still,

25
00:02:58,285 --> 00:02:59,005
Speaker 6:  And you discovered way late.

26
00:02:59,645 --> 00:03:03,245
Speaker 5:  I still don't know whether it's Dearth or Darth

27
00:03:04,265 --> 00:03:05,285
Speaker 5:  and I don't want to find out.

28
00:03:06,555 --> 00:03:09,565
Speaker 6:  Fair enough. Don't email us about it. Don't ruin this for any lie.

29
00:03:09,565 --> 00:03:12,405
Speaker 5:  Don't tell me. Don't. I don't. And I don't know if it means a lot or not

30
00:03:12,405 --> 00:03:12,765
Speaker 5:  enough

31
00:03:14,225 --> 00:03:18,085
Speaker 7:  On switch on Pop. We have in ongoing uncertainty about whether it

32
00:03:18,085 --> 00:03:22,045
Speaker 7:  is homage or homage. That's good. And we have been written many

33
00:03:22,045 --> 00:03:25,845
Speaker 7:  emails that it's both. And so we've refused to use the word from now

34
00:03:25,845 --> 00:03:29,285
Speaker 5:  On out. Niche and niche. Very confusing. Mm.

35
00:03:29,555 --> 00:03:29,845
Speaker 7:  Both

36
00:03:29,845 --> 00:03:32,765
Speaker 5:  Acceptable also have been told it's both. So there's a lot of these. Yeah.

37
00:03:33,825 --> 00:03:37,685
Speaker 5:  One of them in recent times is

38
00:03:37,835 --> 00:03:41,685
Speaker 5:  risk five, which is, I would say not a thing

39
00:03:41,685 --> 00:03:45,165
Speaker 5:  that comes up in casual conversation for anyone. Even the people who are

40
00:03:45,165 --> 00:03:48,805
Speaker 5:  working on risk. Five Bryant just walking around the office saying Risk five.

41
00:03:50,245 --> 00:03:54,165
Speaker 5:  I I said it was risk V the other day. All right. I'm sorry. I mean, this

42
00:03:54,325 --> 00:03:57,925
Speaker 5:  is your correction. You got one on me. I, I apologize.

43
00:03:58,365 --> 00:04:01,485
Speaker 5:  I don't know what kind of slash shot nerds are reading it out loud.

44
00:04:03,775 --> 00:04:06,415
Speaker 5:  I mean, you're my people and you're listening and you know, like we have

45
00:04:06,455 --> 00:04:09,695
Speaker 5:  a bond here. You're listening to a podcast in which the word is said out

46
00:04:09,695 --> 00:04:13,255
Speaker 5:  loud. And you, the audience know that I've

47
00:04:13,415 --> 00:04:16,815
Speaker 5:  mispronounced there's something special there. Precious. I I want to protect

48
00:04:16,815 --> 00:04:20,655
Speaker 5:  it. I'm just saying we are the only people who

49
00:04:20,655 --> 00:04:20,815
Speaker 5:  know

50
00:04:21,355 --> 00:04:23,335
Speaker 7:  How do you know they're right and that you aren't now

51
00:04:23,685 --> 00:04:26,575
Speaker 5:  Also spreading the truth also. Good question, Charlie. Am I being gaslit

52
00:04:26,575 --> 00:04:27,455
Speaker 5:  by an internet conspiracy?

53
00:04:27,855 --> 00:04:31,615
Speaker 6:  I would also like to posit that with all Roman

54
00:04:31,895 --> 00:04:35,775
Speaker 6:  numerals. The, the letter and the number are both

55
00:04:35,775 --> 00:04:39,655
Speaker 6:  correct. Like when the iPhone 10 came out and it was the iPhone X,

56
00:04:39,715 --> 00:04:43,575
Speaker 6:  it was the iPhone X. I don't care what anyone said, I got a lot

57
00:04:43,575 --> 00:04:46,775
Speaker 6:  of crap for that. and it was the iPhone X because it was, it was the iPhone

58
00:04:46,775 --> 00:04:50,575
Speaker 6:  and then the letter X you call whatever you want. I, I submit that

59
00:04:50,775 --> 00:04:52,375
Speaker 6:  both should be allowed at all times.

60
00:04:52,635 --> 00:04:56,575
Speaker 5:  So I would, I I I support this. In theory it's Superbowl Excel.

61
00:04:56,575 --> 00:04:58,455
Speaker 6:  Unless it's more than one letter, then well, no,

62
00:04:58,635 --> 00:05:01,135
Speaker 5:  But Super Bowl xl. Like they ob they were like hype for it,

63
00:05:01,135 --> 00:05:02,095
Speaker 6:  Right? Yeah. They did a thing.

64
00:05:02,315 --> 00:05:06,095
Speaker 5:  That's your moment. But I was one of those slash do nerds who was like,

65
00:05:06,095 --> 00:05:09,815
Speaker 5:  it's me was 10, so I'm sorry. Like I, you

66
00:05:09,815 --> 00:05:11,335
Speaker 6:  Know, even though it's not, it's OSX.

67
00:05:12,235 --> 00:05:16,175
Speaker 5:  We got fun. Anyway, that's your correction. I'm just telling you what we,

68
00:05:16,175 --> 00:05:19,495
Speaker 5:  what we share as a group is special and I'm, I'm sorry that I pushed the

69
00:05:19,695 --> 00:05:23,295
Speaker 5:  boundary of it, but I'm also saying no one says these words out loud.

70
00:05:25,165 --> 00:05:28,575
Speaker 5:  It's just not a thing bad and I feel nothing. Charlie

71
00:05:28,695 --> 00:05:29,775
Speaker 7:  XCX has entered the chat.

72
00:05:33,005 --> 00:05:34,895
Speaker 5:  What is the, what is XC, X in numbers?

73
00:05:35,755 --> 00:05:36,895
Speaker 7:  It isn't a real one

74
00:05:37,945 --> 00:05:39,415
Speaker 5:  Isn't C and Roman numeral

75
00:05:39,935 --> 00:05:43,255
Speaker 6:  C is a hundred. So that would be a hundred. It would be 90 and then 10 more.

76
00:05:43,355 --> 00:05:43,575
Speaker 6:  and

77
00:05:44,115 --> 00:05:45,775
Speaker 5:  It allows you to put them in this order.

78
00:05:46,405 --> 00:05:47,735
Speaker 6:  It's just Charlie CI think.

79
00:05:50,135 --> 00:05:51,615
Speaker 5:  I don't know how Roman work.

80
00:05:53,295 --> 00:05:55,055
Speaker 5:  Speaking of things that are bad at math ai,

81
00:05:57,745 --> 00:05:58,645
Speaker 6:  That's true. That's

82
00:05:58,645 --> 00:06:02,245
Speaker 5:  Good. That's good. Big week in the AI landscape.

83
00:06:03,245 --> 00:06:06,205
Speaker 5:  A weird week for me emotionally. I'll explain why in a second. The major

84
00:06:06,205 --> 00:06:09,325
Speaker 5:  labels have sued two AI companies that you may or may not have heard of.

85
00:06:10,005 --> 00:06:13,205
Speaker 5:  UDO and Suno. These are classic Silicon Valley names. We should all be proud.

86
00:06:14,005 --> 00:06:17,685
Speaker 5:  They're music companies, AI music companies. UDO is the company

87
00:06:18,295 --> 00:06:22,165
Speaker 5:  whose tool was used to make B BBL Drizzy. We'll have Charlie explain

88
00:06:22,165 --> 00:06:25,805
Speaker 5:  that entire chain of events. And then Suno has a deal with

89
00:06:26,205 --> 00:06:29,485
Speaker 5:  Microsoft. It's in copilot and You can ask it to giant music in copilot.

90
00:06:30,855 --> 00:06:34,795
Speaker 5:  How would you train an AI tool to make music? You might ask, as

91
00:06:34,815 --> 00:06:38,235
Speaker 5:  did the lawyers at the Recording Industry Association of America. And the

92
00:06:38,235 --> 00:06:42,155
Speaker 5:  answer is you just put a bunch of music in them and you train the

93
00:06:42,155 --> 00:06:45,715
Speaker 5:  model on a bunch of music, including what appears to be and a a

94
00:06:46,075 --> 00:06:49,875
Speaker 5:  remarkable amount of the recording industries music, not just music

95
00:06:49,875 --> 00:06:53,595
Speaker 5:  that's out in the world. The companies are sued. There's a lawsuit.

96
00:06:54,335 --> 00:06:57,995
Speaker 5:  The RAA is mad. The RA is already mad. They

97
00:06:58,655 --> 00:07:02,315
Speaker 5:  say that they asked the companies what was used to train the models. The

98
00:07:02,555 --> 00:07:06,235
Speaker 5:  companies Suno deflected and said their training data was confidential. Business

99
00:07:06,235 --> 00:07:06,715
Speaker 5:  information.

100
00:07:08,855 --> 00:07:12,785
Speaker 5:  Fine. UDO made the same statements. And then Suno also

101
00:07:12,785 --> 00:07:16,465
Speaker 5:  said, our stuff is transformative and designed to generate completely new

102
00:07:16,465 --> 00:07:19,185
Speaker 5:  outputs. Not memorize and regurgitate pre preexisting content.

103
00:07:20,675 --> 00:07:23,625
Speaker 5:  We'll get to that in a second. 'cause that is actually a very funny claim

104
00:07:23,635 --> 00:07:27,425
Speaker 5:  based on what You can do. The Rwa put tracks in lawsuit, which we will

105
00:07:27,425 --> 00:07:31,345
Speaker 5:  listen to. It straightforwardly can just make Johnny be good

106
00:07:32,085 --> 00:07:36,025
Speaker 5:  in a song called Prancing Queen, which is my favorite, which is deeply hilarious.

107
00:07:37,935 --> 00:07:41,625
Speaker 5:  There's just a part of this where these companies knew

108
00:07:42,175 --> 00:07:45,385
Speaker 5:  that what they were doing was training on copyright work and they kind of

109
00:07:45,385 --> 00:07:47,945
Speaker 5:  assumed that they would get away with it or at least be able to like pay

110
00:07:47,945 --> 00:07:48,905
Speaker 5:  the money and move on.

111
00:07:49,405 --> 00:07:53,345
Speaker 6:  Can I ask a, can I ask a very possibly dumb framing question

112
00:07:53,555 --> 00:07:57,065
Speaker 6:  about this? Because I, I want, we're gonna get into the weeds of like a very

113
00:07:57,305 --> 00:08:01,225
Speaker 6:  specific music case, but a lot of what you just described,

114
00:08:01,225 --> 00:08:04,785
Speaker 6:  the sort of basic outlines of like how these companies trained their data

115
00:08:05,005 --> 00:08:07,465
Speaker 6:  and what they're being accused of doing and who's mad

116
00:08:08,795 --> 00:08:12,305
Speaker 6:  feels identical to me to every other conversation we've had about these AI

117
00:08:12,305 --> 00:08:16,225
Speaker 6:  models, right? Like it seems to me that if you change Johnny B. Good

118
00:08:16,965 --> 00:08:20,825
Speaker 6:  and Suno to the New York Times and Chat

119
00:08:20,985 --> 00:08:24,625
Speaker 6:  GPT, we're functionally talking about the same thing. So like, I want to

120
00:08:24,625 --> 00:08:28,385
Speaker 6:  get into the deep into this in, in weird ways, but like, is there something

121
00:08:28,385 --> 00:08:32,305
Speaker 6:  different about the fact that we're doing this with music than the fact the

122
00:08:32,305 --> 00:08:35,905
Speaker 6:  way we've been doing this with like the web for the last year or so?

123
00:08:36,805 --> 00:08:40,785
Speaker 5:  Yes. And it's that The music industry is organized and

124
00:08:40,785 --> 00:08:42,905
Speaker 5:  aggressive when it comes to protecting its rights.

125
00:08:43,685 --> 00:08:44,825
Speaker 6:  So the difference is lawyers,

126
00:08:45,405 --> 00:08:48,465
Speaker 5:  The difference is lawyers and also the, the history of music and the internet

127
00:08:49,085 --> 00:08:52,945
Speaker 5:  is lawyers. Like, the reason I'm so conflicted

128
00:08:52,945 --> 00:08:56,845
Speaker 5:  about this is that I went and became a copyright lawyer because

129
00:08:57,115 --> 00:09:00,365
Speaker 5:  Napster came out when I was in college and I was

130
00:09:00,475 --> 00:09:04,325
Speaker 5:  radicalized because I thought everyone was stupid, which is what

131
00:09:04,325 --> 00:09:07,365
Speaker 5:  should happen when software comes out when you're in college. Yeah. That

132
00:09:07,445 --> 00:09:11,405
Speaker 5:  I, I'm assuming there are some kids out there today who are radicalized by

133
00:09:11,405 --> 00:09:14,725
Speaker 5:  the presence of new software, but that wouldn't, it wasn't for me. It was

134
00:09:14,725 --> 00:09:18,405
Speaker 5:  Napster. I went off and became a copyright attorney. I sucked at it. I don't

135
00:09:18,405 --> 00:09:21,285
Speaker 5:  ever want anyone to think I was good at this as a practicing attorney. I

136
00:09:21,285 --> 00:09:24,525
Speaker 5:  was garbage. But the thing I did was I worked at a law firm that defended

137
00:09:24,525 --> 00:09:28,405
Speaker 5:  other college kids who got sued for using kaza against the RAA

138
00:09:28,745 --> 00:09:32,645
Speaker 5:  and the RIAA was suing college kids and actually

139
00:09:32,645 --> 00:09:35,765
Speaker 5:  suing the universities to get the IP address of the college kids on their

140
00:09:35,765 --> 00:09:38,605
Speaker 5:  networks who were using the tools and then identifying the college students

141
00:09:38,605 --> 00:09:41,085
Speaker 5:  and suing the college students. It was my roommate's computer. It wasn't

142
00:09:41,085 --> 00:09:44,965
Speaker 5:  me. Yeah. I swear this is like a lot, right? That's a lot

143
00:09:44,965 --> 00:09:48,045
Speaker 5:  that, that's just a lot to like the universities are caving and not protecting

144
00:09:48,045 --> 00:09:51,325
Speaker 5:  their, all this stuff is happening and they were running this program at

145
00:09:51,325 --> 00:09:54,205
Speaker 5:  breakeven. They just wanted $5,000 settlements so everyone would be scared

146
00:09:54,425 --> 00:09:58,205
Speaker 5:  and stop doing it. And they won that. That worked sort of,

147
00:09:58,305 --> 00:10:02,165
Speaker 5:  now we're back to it, right? But like the movie industry is

148
00:10:02,165 --> 00:10:05,405
Speaker 5:  not quite as good. It's stopping the Piy as The music industry was. And they

149
00:10:05,785 --> 00:10:08,805
Speaker 5:  ran that program to kind of like shut it down and chill. Napster

150
00:10:09,625 --> 00:10:12,565
Speaker 5:  and Ster and Kaza and all the other ones, they ran Grokster all the way up

151
00:10:12,565 --> 00:10:15,765
Speaker 5:  to the Supreme Court. That decision was, is 20 years old now. The

152
00:10:16,285 --> 00:10:17,645
Speaker 5:  RAA versus ter

153
00:10:19,475 --> 00:10:23,265
Speaker 5:  great. Then they did the iTunes store and they got deals

154
00:10:23,655 --> 00:10:26,425
Speaker 5:  with Steve Jobs and then other music stores and then they did Spotify and

155
00:10:26,425 --> 00:10:30,265
Speaker 5:  Apple Music and streaming. And all along the way they have

156
00:10:30,265 --> 00:10:33,625
Speaker 5:  been extraordinarily litigious and extraordinarily protective of their copyrights

157
00:10:33,625 --> 00:10:36,465
Speaker 5:  because people have an emotional connection to music that they can trade

158
00:10:36,465 --> 00:10:40,025
Speaker 5:  on. This is true in a way that even Hollywood doesn't, like when

159
00:10:40,025 --> 00:10:42,585
Speaker 5:  Disney's like, we must protect the copyright to the Avengers. People are

160
00:10:42,585 --> 00:10:46,545
Speaker 5:  like, go fuck yourself. Like right In a way that The music industry, when

161
00:10:46,545 --> 00:10:50,025
Speaker 5:  it's like you are stealing music, you are making it so artists don't get

162
00:10:50,025 --> 00:10:53,785
Speaker 5:  paid. There's an emotional resonance. That argument tends to have.

163
00:10:54,175 --> 00:10:58,145
Speaker 5:  Charlie, I'm curious how you, how you see that changing over time. But they've

164
00:10:58,145 --> 00:11:00,505
Speaker 5:  been good at it and they've run the playbook over and over and over again.

165
00:11:00,595 --> 00:11:04,305
Speaker 5:  Music is also a closed ecosystem of like four big

166
00:11:04,745 --> 00:11:08,625
Speaker 5:  companies. And so you see things like interpolation where

167
00:11:08,765 --> 00:11:12,745
Speaker 5:  an artist uses a bit of a song from another artist and fans get mad

168
00:11:12,745 --> 00:11:16,585
Speaker 5:  and then writing credits get distributed and money flows inside of a

169
00:11:16,585 --> 00:11:20,425
Speaker 5:  closed ecosystem. None of that is true about the web. None of that is true

170
00:11:20,425 --> 00:11:23,385
Speaker 5:  about the media. So if you are like, are a writer at a media company,

171
00:11:24,815 --> 00:11:28,505
Speaker 5:  nothing like no one cares. Like there's not some big apparatus

172
00:11:28,865 --> 00:11:32,825
Speaker 5:  designed to make it as seem like your work is emotionally resonant and should

173
00:11:32,825 --> 00:11:35,545
Speaker 5:  be protected in the way that The music industry does. So I think that's a

174
00:11:35,545 --> 00:11:39,145
Speaker 5:  huge difference here. The other difference, and this is where I, I really

175
00:11:39,765 --> 00:11:43,305
Speaker 5:  try, I'm very curious for your take here,

176
00:11:44,005 --> 00:11:47,825
Speaker 5:  is that the outputs of these systems are just the

177
00:11:47,825 --> 00:11:51,585
Speaker 5:  songs, right? And they're, the lawsuits are about

178
00:11:51,785 --> 00:11:55,765
Speaker 5:  training, right? All copyright lawsuit. All copyright is dumb. Like

179
00:11:55,765 --> 00:11:59,165
Speaker 5:  it's a dumb legal system because it, it just regulates copies.

180
00:11:59,905 --> 00:12:03,765
Speaker 5:  And so they're like, you made a copy to do this thing and you didn't have

181
00:12:03,825 --> 00:12:07,605
Speaker 5:  the permission to do the thing with the copy that you made. So copyright

182
00:12:07,605 --> 00:12:10,885
Speaker 5:  infringement weird. All computers do is make copies.

183
00:12:11,575 --> 00:12:14,645
Speaker 5:  We've talked about this so many times in the show, so they're not talking

184
00:12:14,645 --> 00:12:18,085
Speaker 5:  about the outputs, but I think the outputs are so convincing.

185
00:12:18,395 --> 00:12:22,205
Speaker 5:  Like in order to get to the thing can just make Johnny be good. It is

186
00:12:22,205 --> 00:12:26,135
Speaker 5:  obvious that you made a copy of Johnny be good. Charlie, what do you

187
00:12:26,135 --> 00:12:26,415
Speaker 5:  think? Man,

188
00:12:26,855 --> 00:12:29,655
Speaker 7:  I feel like The music industry is the one place that copyright becomes part

189
00:12:29,975 --> 00:12:33,135
Speaker 7:  of public conversation in a very frequent way.

190
00:12:33,675 --> 00:12:37,415
Speaker 7:  People talk about when Pharrell is

191
00:12:37,415 --> 00:12:41,215
Speaker 7:  borrowing from Marvin Gaye, people talk about when

192
00:12:42,015 --> 00:12:44,935
Speaker 7:  Steroid to Heaven might be of, might have been copied by another song. People

193
00:12:44,935 --> 00:12:48,855
Speaker 7:  constantly are debating in social media, Hey, you kind of sound like

194
00:12:48,855 --> 00:12:52,215
Speaker 7:  you borrowed this other person's thing. They should get a credit on it.

195
00:12:52,405 --> 00:12:55,655
Speaker 7:  There's no thing in journalism where someone's like, Hey, you know, NELI

196
00:12:55,655 --> 00:12:59,175
Speaker 7:  kind of used someone else's text. Maybe we should give David some extra credit

197
00:12:59,355 --> 00:13:02,415
Speaker 7:  on that piece. That Neli plagiarized. I'm sorry, I'm obviously not accusing

198
00:13:02,415 --> 00:13:03,095
Speaker 7:  you. I

199
00:13:03,095 --> 00:13:03,735
Speaker 5:  Do that all the time. This

200
00:13:03,735 --> 00:13:04,615
Speaker 7:  Is Hypothe. I don't

201
00:13:04,615 --> 00:13:04,735
Speaker 5:  Think you

202
00:13:05,095 --> 00:13:05,895
Speaker 6:  Specifically Neli does that all.

203
00:13:06,255 --> 00:13:10,095
Speaker 5:  I have God mode Google Docs access and I just lift everybody's copy

204
00:13:10,165 --> 00:13:10,735
Speaker 5:  left and right.

205
00:13:11,405 --> 00:13:14,775
Speaker 7:  There's just no other creative industry that where there's this like level

206
00:13:14,915 --> 00:13:18,495
Speaker 7:  of actual infringement that happens that then there is this internal

207
00:13:19,925 --> 00:13:23,535
Speaker 7:  litigious system where these major players are constantly trading credits

208
00:13:23,535 --> 00:13:26,655
Speaker 7:  back and forth and the public is in on it often

209
00:13:27,375 --> 00:13:31,195
Speaker 7:  debating whether or not they're the artists that they

210
00:13:31,285 --> 00:13:35,155
Speaker 7:  stand is making original work. This is part of popular discourse and it happens

211
00:13:35,155 --> 00:13:38,915
Speaker 7:  in music. So it's really different when The music industry

212
00:13:39,015 --> 00:13:42,955
Speaker 7:  is going after AI than if the New York Times is because I've just never

213
00:13:42,955 --> 00:13:46,115
Speaker 7:  been in a circumstance where I'm talking about, that article was completely

214
00:13:46,115 --> 00:13:49,235
Speaker 7:  lifted from this other article, but we constantly talk about is so-and-so

215
00:13:49,235 --> 00:13:50,115
Speaker 7:  writing their own songs.

216
00:13:50,605 --> 00:13:54,555
Speaker 5:  Right. I'll give you a a dumb example from movies. The movie, the

217
00:13:54,555 --> 00:13:58,515
Speaker 5:  Dark Night is basically an interpolation of the movie Heat

218
00:13:59,175 --> 00:14:02,555
Speaker 5:  except with Batman. Yeah. Right. Like many of the shots are the same.

219
00:14:02,555 --> 00:14:05,475
Speaker 5:  Christopher Nolan is out there being like, heat is the greatest cops and

220
00:14:05,475 --> 00:14:09,195
Speaker 5:  robbers movie ever made. Like, I just wanted to make Heat. But with Batman

221
00:14:09,695 --> 00:14:12,195
Speaker 5:  and then you like watch both movies, you're like, oh shit. Like dude just

222
00:14:12,195 --> 00:14:15,595
Speaker 5:  made heat with Batman. Yeah. And that's great. And I think everyone's like,

223
00:14:15,595 --> 00:14:19,315
Speaker 5:  this is the best. Like this is so cool. And then you get to, I don't know,

224
00:14:19,325 --> 00:14:23,275
Speaker 5:  Miley Cyrus is writing flowers, which the lyrics just reference

225
00:14:23,845 --> 00:14:24,435
Speaker 7:  Bruno Mars,

226
00:14:24,525 --> 00:14:27,675
Speaker 5:  Bruno Mars. And people are like, should she have to pay Bruno Mars? It's

227
00:14:27,675 --> 00:14:31,315
Speaker 5:  like, why? Like why like the melodies aren't like they she's just

228
00:14:31,735 --> 00:14:35,595
Speaker 5:  saying some of the same words. Yeah, yeah, yeah. Right. But the expectation

229
00:14:35,595 --> 00:14:38,355
Speaker 5:  is that there, there should be some economic exchange of value. Well,

230
00:14:38,355 --> 00:14:42,075
Speaker 6:  And I, I would, I would think then that the existence of

231
00:14:42,425 --> 00:14:46,275
Speaker 6:  that exchange of value is also how you get to something like this, right?

232
00:14:46,275 --> 00:14:50,115
Speaker 6:  Where it's, it's not just everybody's sort of yelling and then nothing

233
00:14:50,115 --> 00:14:53,925
Speaker 6:  ever happens. It's that we actually have a system by which this

234
00:14:53,925 --> 00:14:57,325
Speaker 6:  gets solved, right? Where, where we have people get songwriting credits and

235
00:14:57,325 --> 00:15:00,125
Speaker 6:  then they get paid for it. And there's like The music industry has built

236
00:15:00,475 --> 00:15:04,285
Speaker 6:  ways for all of this to work and like you said, is

237
00:15:04,285 --> 00:15:07,645
Speaker 6:  very good at picking fights with those who do not play inside of that system.

238
00:15:08,225 --> 00:15:12,045
Speaker 6:  And so like now I'm just thinking, okay, the difference between The music

239
00:15:12,365 --> 00:15:15,885
Speaker 6:  industry and the, the others who are fighting against

240
00:15:16,395 --> 00:15:19,925
Speaker 6:  open AI and others like just groups of authors or whatever, is

241
00:15:20,665 --> 00:15:24,645
Speaker 6:  not only does The music industry have a system by which it understands

242
00:15:24,645 --> 00:15:27,485
Speaker 6:  how everybody is supposed to get paid. That has existed for a long time and

243
00:15:27,685 --> 00:15:31,405
Speaker 6:  everybody kind of sort of understands, but also is

244
00:15:31,435 --> 00:15:35,285
Speaker 6:  able to marshal that whole system against anyone who wants to exist

245
00:15:35,285 --> 00:15:38,885
Speaker 6:  outside of that. And part of what we've been saying forever is like all the

246
00:15:38,885 --> 00:15:41,885
Speaker 6:  money is on the side of the AI companies. Like who, who is going to be able

247
00:15:41,885 --> 00:15:45,685
Speaker 6:  to run a lawsuit against Google all the way to the end

248
00:15:46,585 --> 00:15:50,205
Speaker 6:  and probably aren't that many creative industries other than The music

249
00:15:50,485 --> 00:15:51,685
Speaker 6:  industry that might be able to do it.

250
00:15:51,795 --> 00:15:55,645
Speaker 7:  They've done it before. Yeah. And they have won major concessions. Right?

251
00:15:55,905 --> 00:15:59,605
Speaker 7:  We wouldn't have content id if not for music labels going after YouTube.

252
00:15:59,735 --> 00:16:00,085
Speaker 7:  Right.

253
00:16:00,345 --> 00:16:03,285
Speaker 5:  And they and the music labels have gone after YouTube, right? Universal,

254
00:16:03,475 --> 00:16:06,885
Speaker 5:  this is where Drake gets involved. There's fake Drake that we've, we've talked

255
00:16:06,885 --> 00:16:10,685
Speaker 5:  about endlessly on the show. Shout out to Laser Bong a song that has been

256
00:16:10,915 --> 00:16:14,125
Speaker 5:  just aggressively censored from ev every major platform.

257
00:16:15,395 --> 00:16:19,045
Speaker 5:  Boyd, does TikTok not want electronic music about bongs on its platform?

258
00:16:19,585 --> 00:16:21,285
Speaker 6:  Sue about that. Record labels. Like

259
00:16:22,145 --> 00:16:25,605
Speaker 5:  You want to talk about government censorship? Yeah. All right. The Chinese

260
00:16:25,605 --> 00:16:29,525
Speaker 5:  government is like no bongs for American teens. Just saying it.

261
00:16:30,385 --> 00:16:33,725
Speaker 5:  The piece of that puzzle that's super interesting to me is

262
00:16:34,235 --> 00:16:37,525
Speaker 5:  Universal was mad about fake Drake. They went to Spotify, apple,

263
00:16:38,035 --> 00:16:41,165
Speaker 5:  they said, don't have these, don't have this song. And Spotify and Apple

264
00:16:41,165 --> 00:16:44,245
Speaker 5:  Control the catalogs in their music service, they can pull down YouTube is

265
00:16:44,245 --> 00:16:48,085
Speaker 5:  open access, right? So anyone can upload anything. And then there is continuity

266
00:16:48,085 --> 00:16:51,125
Speaker 5:  and they have these other copyright management systems on YouTube, but it's

267
00:16:51,125 --> 00:16:54,885
Speaker 5:  not the same catalog control where You can just delete the song the way that

268
00:16:55,115 --> 00:16:58,605
Speaker 5:  Spotify and Apple Music could just delete the song. So they had to come up

269
00:16:58,605 --> 00:17:01,285
Speaker 5:  with some other system and YouTube did give the concessions, right? They

270
00:17:01,625 --> 00:17:05,525
Speaker 5:  put out a list of like AI principles that they would work on about safety,

271
00:17:05,525 --> 00:17:08,325
Speaker 5:  about this other stuff. And a lot of it was we are gonna work directly with

272
00:17:08,325 --> 00:17:11,125
Speaker 5:  Universal and the rest of The music industry to figure out what tools are

273
00:17:11,325 --> 00:17:14,325
Speaker 5:  valuable and what tools aren't. And even to allow some creators to like do

274
00:17:14,325 --> 00:17:17,845
Speaker 5:  some of this AI music generation. 'cause we think it's cool and then we'll

275
00:17:17,845 --> 00:17:21,565
Speaker 5:  obviously we'll figure out how to pay them. This is implicit if you're like

276
00:17:21,705 --> 00:17:25,605
Speaker 5:  co announcing that tool with universal music, universal music is gonna

277
00:17:25,605 --> 00:17:29,005
Speaker 5:  get paid. Yes. Like the, the heat death of the universe could occur

278
00:17:29,385 --> 00:17:33,085
Speaker 5:  in Lucian Grange, the CEO of Universal Music would get paid. Like he's good

279
00:17:33,085 --> 00:17:36,845
Speaker 5:  at it. Yes. These two companies did not do that. There's a quote from one

280
00:17:36,845 --> 00:17:40,325
Speaker 5:  of the CEEs and Suno, a Rolling Stone profile from March,

281
00:17:40,665 --> 00:17:43,885
Speaker 5:  and he, he's, he just says to Rolling Stone, if we had deals with the labels

282
00:17:43,885 --> 00:17:46,765
Speaker 5:  when the company got started, I probably wouldn't have invested in it. I

283
00:17:46,765 --> 00:17:49,165
Speaker 5:  think they needed to make this product without the constraints.

284
00:17:50,955 --> 00:17:52,725
Speaker 6:  Wild thing to say out loud. Incredible

285
00:17:52,725 --> 00:17:53,485
Speaker 5:  Thing to say out loud.

286
00:17:53,795 --> 00:17:56,805
Speaker 7:  They said the quiet thing out loud because Yeah. Behind all of this, they

287
00:17:56,805 --> 00:18:00,445
Speaker 7:  haven't ever really quite publicly emitted that they are using copyrighted

288
00:18:00,445 --> 00:18:04,045
Speaker 7:  works. They've talked around that in every way they possibly can without

289
00:18:04,045 --> 00:18:07,965
Speaker 7:  denying it. And this is sort of like the big Yeah, this is the, this is the

290
00:18:07,965 --> 00:18:08,485
Speaker 7:  smoking gun.

291
00:18:08,935 --> 00:18:11,605
Speaker 5:  Right? And then the other smoking gun, and this is the part we should just

292
00:18:11,605 --> 00:18:14,885
Speaker 5:  listen to some of this music is the output of the models themselves. Right.

293
00:18:15,095 --> 00:18:19,035
Speaker 5:  Which is, I mean, let's listen

294
00:18:19,035 --> 00:18:21,515
Speaker 5:  to it and we can talk about it. David, take us through it. Okay.

295
00:18:21,555 --> 00:18:25,475
Speaker 6:  I have, I have brought some sound thank you to Andrew and Liam for getting

296
00:18:25,475 --> 00:18:29,315
Speaker 6:  all of this together. We have three examples

297
00:18:29,615 --> 00:18:33,555
Speaker 6:  and I, I will just roll through all three. Stop me when you have

298
00:18:33,555 --> 00:18:37,515
Speaker 6:  feelings about this. The first thing we'll do is this

299
00:18:37,515 --> 00:18:41,235
Speaker 6:  is just titled Real Chuck Berry in Riverside. So

300
00:18:41,235 --> 00:18:42,475
Speaker 6:  let's just listen to this for a second, by

301
00:18:42,475 --> 00:18:46,275
Speaker 5:  The way, and this is all fair use, no copyright infringement intended. All

302
00:18:46,275 --> 00:18:48,275
Speaker 5:  right. YouTube. All right, go ahead.

303
00:18:48,975 --> 00:18:52,955
Speaker 8:  But he could play a guitar just like a ringing a bell. Go go. Sure.

304
00:18:53,855 --> 00:18:54,075
Speaker 8:  Go,

305
00:18:56,615 --> 00:18:57,595
Speaker 8:  go, go

306
00:18:59,695 --> 00:19:02,115
Speaker 5:  Try. That's enough. Stop it before the robot sensors arrive. Great

307
00:19:02,115 --> 00:19:03,275
Speaker 6:  Song I. love it. Right? I can confirm

308
00:19:03,635 --> 00:19:06,715
Speaker 5:  I love it. If you don't know that song one, go watch Back to the Future.

309
00:19:07,165 --> 00:19:11,035
Speaker 5:  Incredible movie that you should just watch. Yes. And two like Stop, go get

310
00:19:11,035 --> 00:19:12,755
Speaker 5:  cultured. Know what you're

311
00:19:12,755 --> 00:19:16,075
Speaker 7:  Doing. Johnny B. Good. Chuck Berry, founder. Yeah, that's founder. Rock and

312
00:19:16,075 --> 00:19:17,075
Speaker 7:  roll one of them. Yeah.

313
00:19:17,175 --> 00:19:21,075
Speaker 6:  And now we have a song from uio, which

314
00:19:21,095 --> 00:19:24,035
Speaker 6:  is not called Johnny B. Good, but just listen

315
00:19:25,525 --> 00:19:28,115
Speaker 8:  Power. Just like a ring. Go, go

316
00:19:29,535 --> 00:19:33,115
Speaker 8:  go, Johnny. Go. Go go. Johnny.

317
00:19:33,935 --> 00:19:37,115
Speaker 8:  Go. Go Johnny. Go.

318
00:19:38,415 --> 00:19:38,635
Speaker 8:  Go.

319
00:19:39,575 --> 00:19:41,195
Speaker 6:  So I mean, it's,

320
00:19:41,535 --> 00:19:44,675
Speaker 5:  So that one is non copyright infringement just on its face. Yeah. Because

321
00:19:45,055 --> 00:19:45,475
Speaker 7:  You can't,

322
00:19:46,055 --> 00:19:48,755
Speaker 5:  You can't, nobody owns this. You can't copyright the AI work.

323
00:19:48,985 --> 00:19:52,875
Speaker 6:  Yeah. Okay, so that's one. Next we have a

324
00:19:52,875 --> 00:19:53,115
Speaker 6:  James Brown.

325
00:19:53,115 --> 00:19:55,555
Speaker 5:  Wait, brown. Wait, can we just, I just wanna ask Charlie like a hard question.

326
00:19:55,555 --> 00:19:59,315
Speaker 5:  Charlie's a professor of music at NYUI believe, right? Yes.

327
00:19:59,855 --> 00:20:03,475
Speaker 5:  All right, professor, let's say you didn't have

328
00:20:03,475 --> 00:20:06,755
Speaker 5:  Johnny B. Good in the training data. Yes. But then you had the entire

329
00:20:07,035 --> 00:20:10,795
Speaker 5:  architecture of rock and roll that is built on Johnny B. Good. That's a good

330
00:20:10,915 --> 00:20:13,755
Speaker 5:  question. Yeah. Could you back your way into Johnny B. Good

331
00:20:14,065 --> 00:20:16,635
Speaker 6:  Monkeys and typewriters and Shakespeare, right? Like that's the, is that

332
00:20:16,635 --> 00:20:17,355
Speaker 6:  the, the theory,

333
00:20:17,615 --> 00:20:20,475
Speaker 5:  But like you, you don't need, do you need the seed crystal when you have

334
00:20:20,475 --> 00:20:22,915
Speaker 5:  the whole diamond mine of rock and roll?

335
00:20:23,175 --> 00:20:25,875
Speaker 7:  That's a really good question because, you know, if you look at this era

336
00:20:26,015 --> 00:20:29,915
Speaker 7:  of, of music where r and b rock and roll

337
00:20:30,735 --> 00:20:34,715
Speaker 7:  be are sort of like rockabilly are all kind of one entity. The music is drawing

338
00:20:34,735 --> 00:20:38,195
Speaker 7:  on 12 bar blues, a very standard song structure.

339
00:20:38,305 --> 00:20:42,115
Speaker 7:  They're often in the same keys that play well on guitar. They're using a

340
00:20:42,115 --> 00:20:45,475
Speaker 7:  lot of the same kind of guitar licks. They're mostly using pentatonic scales.

341
00:20:45,475 --> 00:20:49,085
Speaker 7:  They're using a lot of the same language. And you might think, yeah, you

342
00:20:49,085 --> 00:20:52,965
Speaker 7:  could just sort of back into that. But the precise rhythms, the

343
00:20:53,015 --> 00:20:56,845
Speaker 7:  exact words, let's be clear. The copy is worse.

344
00:20:57,025 --> 00:21:00,885
Speaker 7:  It does not sound nearly as good as the real Johnny B. Good. You

345
00:21:00,885 --> 00:21:04,685
Speaker 7:  could never get to that same place without having heard that Johnny B. Good.

346
00:21:04,765 --> 00:21:08,725
Speaker 7:  I feel confident. And if these two songs, one

347
00:21:08,725 --> 00:21:12,325
Speaker 7:  being a real song and the other being nobody owns the copyright and it's

348
00:21:12,325 --> 00:21:16,165
Speaker 7:  made by an ai, if, if there were a copyright case made

349
00:21:16,165 --> 00:21:19,925
Speaker 7:  against the copy, it would definitively lose.

350
00:21:21,205 --> 00:21:25,165
Speaker 7:  I I have many of these cases, many of these music copyright cases are

351
00:21:25,165 --> 00:21:28,805
Speaker 7:  not clear. They're often fought over eight notes,

352
00:21:28,805 --> 00:21:32,725
Speaker 7:  sometimes six notes, sometimes a general feel in the case

353
00:21:32,725 --> 00:21:36,505
Speaker 7:  of blurred lines and got to give it up. This is a

354
00:21:36,525 --> 00:21:40,465
Speaker 7:  direct copy of the Rhythm and the words and most

355
00:21:40,465 --> 00:21:44,225
Speaker 7:  of the melodies. So no, you had to have heard this song in order to

356
00:21:44,855 --> 00:21:45,905
Speaker 7:  make Johnny be good twice.

357
00:21:46,205 --> 00:21:49,665
Speaker 5:  By the way, if you want more on eight notes and how complicated it is. Charlie

358
00:21:49,665 --> 00:21:52,225
Speaker 5:  and I did an entire episode of Decoder pulling that Apart. We'll link that

359
00:21:52,225 --> 00:21:54,545
Speaker 5:  in the show notes somewhere, but let's move on. Let's listen to the next

360
00:21:54,545 --> 00:21:54,705
Speaker 5:  one.

361
00:21:54,775 --> 00:21:58,225
Speaker 6:  It's very good. All right, next up we have James Brown, first Real,

362
00:21:58,225 --> 00:21:59,665
Speaker 6:  James Brown. Wow.

363
00:22:00,445 --> 00:22:01,385
Speaker 8:  How Big Good

364
00:22:03,855 --> 00:22:04,585
Speaker 8:  knew that I

365
00:22:10,455 --> 00:22:12,505
Speaker 8:  knew that I, I mean the classic

366
00:22:12,885 --> 00:22:15,945
Speaker 5:  An A timer, another one where if you're listening to the ver chest And, if

367
00:22:15,945 --> 00:22:18,585
Speaker 5:  you've never heard this song, like, I don't know what you're doing. Yeah.

368
00:22:18,725 --> 00:22:21,825
Speaker 6:  Go listen to Switch song. Go it. Exactly. You need it very badly. You're

369
00:22:21,825 --> 00:22:21,905
Speaker 6:  right.

370
00:22:21,925 --> 00:22:23,265
Speaker 5:  Go to school and then come on, come

371
00:22:23,265 --> 00:22:25,785
Speaker 6:  On home. And now we have AI James Brown.

372
00:22:27,485 --> 00:22:30,065
Speaker 8:  Wow. I feel good. I knew

373
00:22:31,475 --> 00:22:31,825
Speaker 5:  Spicy.

374
00:22:34,865 --> 00:22:35,465
Speaker 8:  I feel good.

375
00:22:37,345 --> 00:22:37,865
Speaker 8:  I knew that.

376
00:22:41,925 --> 00:22:42,385
Speaker 8:  So good.

377
00:22:42,615 --> 00:22:46,065
Speaker 6:  Okay, so this one I actually think is very fun because it, it is a little,

378
00:22:46,775 --> 00:22:50,145
Speaker 6:  it's like a little tiny bit further away from it in the way that the first

379
00:22:50,145 --> 00:22:54,105
Speaker 6:  one just is Johnny be good but worse. This one is like one tiny

380
00:22:54,695 --> 00:22:57,025
Speaker 6:  tick. Yeah. This is a further away from being just the thing.

381
00:22:57,175 --> 00:23:00,665
Speaker 5:  This is a lounge band with pretension where everyone's like, just play, just

382
00:23:00,665 --> 00:23:04,425
Speaker 5:  play it the way that, can you stop it? All right. Like, we get it. You,

383
00:23:04,565 --> 00:23:08,465
Speaker 5:  you, you thought you had something. I have one question about this. and it,

384
00:23:09,125 --> 00:23:12,905
Speaker 5:  it actually felt the same way about Johnny B. Good. The way these models

385
00:23:12,975 --> 00:23:16,945
Speaker 5:  work, right? Is you ingest a bunch of data into them. They set a

386
00:23:16,945 --> 00:23:20,785
Speaker 5:  bunch of model weights, and then they like statistically make the next bit,

387
00:23:20,995 --> 00:23:24,025
Speaker 5:  right? They're just sort of like assembling the thing around the prompt,

388
00:23:24,675 --> 00:23:28,505
Speaker 5:  which means they're kind of just assembling ones and zeros to make a sound

389
00:23:28,505 --> 00:23:31,865
Speaker 5:  wave here, which is pretty wild if you think about it. Like that makes sense

390
00:23:31,865 --> 00:23:35,745
Speaker 5:  with words, right? What is statistically the next word in the sentence around

391
00:23:35,855 --> 00:23:39,465
Speaker 5:  this prompt? When you get to like, what are the ones and zeros of a sound

392
00:23:39,465 --> 00:23:43,145
Speaker 5:  file and you get to statistically hear the next ones and zeros. That's pretty

393
00:23:43,145 --> 00:23:46,885
Speaker 5:  weird. It's actually a pretty weird way to, to make an audio recording.

394
00:23:47,505 --> 00:23:51,445
Speaker 5:  And the thing that strikes me about these, this one in particular,

395
00:23:51,445 --> 00:23:55,245
Speaker 5:  but the other one a little bit, the instruments don't sound real at all.

396
00:23:55,245 --> 00:23:58,765
Speaker 5:  To me. Those horns sound so fake. Not like synthesizer fake.

397
00:23:59,185 --> 00:24:02,285
Speaker 5:  No, but almost exactly like what you would expect if you asked a computer

398
00:24:02,705 --> 00:24:06,645
Speaker 5:  to statistically produce a horn section. Mm. Like it's

399
00:24:06,645 --> 00:24:09,325
Speaker 5:  almost played again. You're like, just listen to it. It's so weird.

400
00:24:11,065 --> 00:24:14,125
Speaker 8:  Wow. I feel good. I knew that. I

401
00:24:18,665 --> 00:24:20,885
Speaker 5:  Do you hear how like weird and thin it is? I

402
00:24:20,885 --> 00:24:22,685
Speaker 8:  Knew that I not

403
00:24:25,385 --> 00:24:27,925
Speaker 8:  so good. So good.

404
00:24:29,145 --> 00:24:32,605
Speaker 7:  It doesn't sound like an ensemble of form. It sounds like this weird

405
00:24:32,605 --> 00:24:35,165
Speaker 7:  synthesized thing where the, the beginning of the sound or the end of the

406
00:24:35,165 --> 00:24:38,725
Speaker 7:  sound is exactly lined up. The sound is there's this

407
00:24:38,725 --> 00:24:42,565
Speaker 7:  artifacting quality to it. This is like the pope's jacket version

408
00:24:42,745 --> 00:24:46,565
Speaker 7:  of sound. Yes. Where it's like you got it close, but all the

409
00:24:46,565 --> 00:24:49,405
Speaker 7:  lines are wrong. Why does he have seven fingers? Right. It's

410
00:24:49,405 --> 00:24:53,205
Speaker 5:  A, it's it's a statistical approximation of a hand, right? Yeah. But as expressed

411
00:24:53,205 --> 00:24:56,765
Speaker 5:  as a horn section, which is really weird to like just on its face and You

412
00:24:56,765 --> 00:24:59,245
Speaker 5:  can, you know, people are like, it'll get better and blah, blah blah. But

413
00:24:59,245 --> 00:25:02,525
Speaker 5:  like You can act, to me, You can hear a meaningful difference

414
00:25:03,155 --> 00:25:07,045
Speaker 5:  once you know what you're listening for and it's like, oh, this is

415
00:25:07,085 --> 00:25:09,565
Speaker 5:  a fake instrument. It's not a and it's not a fake instrument. The way it's

416
00:25:09,565 --> 00:25:12,925
Speaker 5:  synthesizer is a fake instrument. Right. It's just fake. Like it doesn't,

417
00:25:13,105 --> 00:25:14,805
Speaker 5:  it doesn't make any sense over

418
00:25:14,805 --> 00:25:17,125
Speaker 7:  The top all of all of it. Right? Now, I don't know if this is a solvable

419
00:25:17,125 --> 00:25:20,845
Speaker 7:  problem. I imagine it probably is is that everything sounds kind of

420
00:25:21,105 --> 00:25:24,765
Speaker 7:  grainy. There's like, there's this top level hiss kind of over the entire

421
00:25:24,765 --> 00:25:28,445
Speaker 7:  recording of any AI output. It sounds maybe equivalent

422
00:25:28,825 --> 00:25:32,165
Speaker 7:  to neli those Fios that you were not downloading

423
00:25:32,825 --> 00:25:36,645
Speaker 7:  in college, but like the really low bit rate MP

424
00:25:36,645 --> 00:25:40,045
Speaker 7:  threes when mp threes were actually noticeably worse. Yeah. That's what these

425
00:25:40,055 --> 00:25:43,925
Speaker 7:  sound like. All of them have this artificial sheen on top

426
00:25:43,925 --> 00:25:47,765
Speaker 7:  that sound very lo-fi. Yeah. In addition to artificial instruments.

427
00:25:47,995 --> 00:25:50,885
Speaker 5:  Just a side note, I can't listen to the song in between days by the Cure

428
00:25:50,955 --> 00:25:54,645
Speaker 5:  without mentally inserting the weird

429
00:25:54,965 --> 00:25:58,685
Speaker 5:  compression artifacts at the high end. 'cause I listened to a shit MP three

430
00:25:58,685 --> 00:26:02,005
Speaker 5:  of that song so many times that the symbols are just forever distorted in

431
00:26:02,005 --> 00:26:02,285
Speaker 5:  my brain.

432
00:26:02,285 --> 00:26:05,645
Speaker 7:  There there's literally a plugin and guitar pedal called Lossy

433
00:26:06,595 --> 00:26:10,365
Speaker 7:  that is made to recreate the sound of early

434
00:26:10,425 --> 00:26:12,365
Speaker 7:  two thousands MP threes. That's

435
00:26:12,365 --> 00:26:12,965
Speaker 5:  Very good. So if you

436
00:26:12,965 --> 00:26:14,365
Speaker 7:  Need it, I can run it for philosophy.

437
00:26:14,675 --> 00:26:18,125
Speaker 5:  It's the older millennial button basically. Exactly. Yeah. So that's the

438
00:26:18,255 --> 00:26:21,485
Speaker 5:  sound. Yeah. Talk about the actual music here. Is this right?

439
00:26:22,055 --> 00:26:24,285
Speaker 5:  Would trying to be good? You're like, that's straight copy infringement.

440
00:26:24,435 --> 00:26:27,125
Speaker 5:  This is weird, right? It's like slant rhyme. Yeah. What do you think?

441
00:26:28,085 --> 00:26:31,205
Speaker 7:  I think that it's the exact same rhythms.

442
00:26:32,185 --> 00:26:36,125
Speaker 7:  I'd have to look at the notes. I think they're quite close. They're the exact,

443
00:26:36,585 --> 00:26:39,165
Speaker 7:  if they're in, maybe they're in a different key, but they're like the same

444
00:26:39,405 --> 00:26:43,085
Speaker 7:  intervals moving in the same direction at the exact same time. That

445
00:26:43,205 --> 00:26:47,045
Speaker 7:  would almost certainly lose in court if these

446
00:26:47,045 --> 00:26:50,885
Speaker 7:  were, again, if I should be clear, the AI companies are not

447
00:26:50,885 --> 00:26:54,525
Speaker 7:  being sued for the output. Yep. But these outputs, if you were to try to

448
00:26:54,525 --> 00:26:58,285
Speaker 7:  make a case, I'm sure a judge would rule in favor of the

449
00:26:58,285 --> 00:27:01,885
Speaker 7:  James Brown estate because it is the same line.

450
00:27:01,995 --> 00:27:04,165
Speaker 7:  Well, it's more or less the same line. It's an interpolation of the line.

451
00:27:04,165 --> 00:27:07,205
Speaker 7:  There's slightly different words, but it's the same rhythms, same melody

452
00:27:07,515 --> 00:27:10,885
Speaker 7:  that almost always is going to, that's always gonna win. And

453
00:27:10,885 --> 00:27:13,205
Speaker 5:  Here the the output is proof of the input. Right.

454
00:27:13,205 --> 00:27:16,005
Speaker 6:  They're, they're not suing for the output. That's right. But the output seems

455
00:27:16,005 --> 00:27:19,365
Speaker 6:  unusually important here in that respect. That it's, it's like

456
00:27:20,065 --> 00:27:23,965
Speaker 6:  if, if UDO is doing the thing that it claimed to be doing,

457
00:27:23,965 --> 00:27:26,645
Speaker 6:  which is, which is transforming stuff into other stuff,

458
00:27:27,985 --> 00:27:31,005
Speaker 6:  we have a very different kind of fair use case. But reading through the RA's

459
00:27:31,005 --> 00:27:33,965
Speaker 6:  lawsuit, like the thing they did over and over and over was just go reproduce

460
00:27:33,965 --> 00:27:36,965
Speaker 6:  songs that exist in the world. Yeah. And that's how we're fighting about

461
00:27:37,085 --> 00:27:39,165
Speaker 6:  training. Yeah. Like I, I went through and pulled a bunch of the prompts

462
00:27:39,165 --> 00:27:41,125
Speaker 6:  that they used to get songs. We did the

463
00:27:41,125 --> 00:27:41,245
Speaker 7:  Same

464
00:27:41,245 --> 00:27:45,165
Speaker 6:  Thing. They're they're so funny. They're so funny. Like to

465
00:27:45,165 --> 00:27:49,085
Speaker 6:  get to get the Green Day song, I think it was American Idiot. The

466
00:27:49,085 --> 00:27:52,805
Speaker 6:  prompt is Pop punk, American Alternative Rock, California 2004, Rob

467
00:27:53,105 --> 00:27:53,845
Speaker 6:  cyo. Perfect.

468
00:27:55,745 --> 00:27:58,365
Speaker 5:  To get and the, and that produced a Pastiche of American idiot.

469
00:27:58,585 --> 00:27:58,805
Speaker 6:  Yes.

470
00:27:59,195 --> 00:27:59,685
Speaker 5:  Amazing.

471
00:27:59,945 --> 00:28:03,885
Speaker 6:  To Get My Girl By The Temptations. It was my tempting 1964 girl

472
00:28:03,945 --> 00:28:07,685
Speaker 6:  Smokey Sing Hitsville Soul Pop Got My Girl by the Temptations.

473
00:28:08,955 --> 00:28:12,925
Speaker 6:  This one you'll enjoy Neli to get All I want for Christmas is you by Mariah

474
00:28:12,925 --> 00:28:16,885
Speaker 6:  Carey, my girl. The prompt is Mariah Carey. But with

475
00:28:16,925 --> 00:28:20,165
Speaker 6:  a space between each letter so that it's not, 'cause presumably these things

476
00:28:20,165 --> 00:28:22,085
Speaker 5:  Are trained because it's pronouns, artist

477
00:28:22,085 --> 00:28:25,805
Speaker 6:  Names. So it's m space, a space all the way through the name Contemporary.

478
00:28:25,805 --> 00:28:26,125
Speaker 6:  That's

479
00:28:26,445 --> 00:28:27,045
Speaker 5:  I spell Holiday

480
00:28:27,485 --> 00:28:30,285
Speaker 6:  A Grammy Award-winning American singer songwriter, remarkable vocal range

481
00:28:30,515 --> 00:28:34,045
Speaker 6:  that produced all in What for Christmas is you. I mean, there's,

482
00:28:34,045 --> 00:28:36,845
Speaker 5:  There's of, so it's what they're proving is that it's instead by the way,

483
00:28:36,845 --> 00:28:39,525
Speaker 5:  the argument in response that I'm sure we're gonna hear, because this is

484
00:28:39,525 --> 00:28:43,325
Speaker 5:  the argument opening AI made about the Times lawsuit was one, no human

485
00:28:43,325 --> 00:28:46,725
Speaker 5:  prompts like this and B, these prompts are so weird. They represent a hack

486
00:28:46,725 --> 00:28:50,325
Speaker 5:  of our system, which is remarkable. But I'm

487
00:28:50,515 --> 00:28:53,685
Speaker 5:  confident based on how open AI replied to the times that that is what these

488
00:28:53,885 --> 00:28:54,045
Speaker 5:  companies

489
00:28:54,045 --> 00:28:57,845
Speaker 6:  Were reply to. There is one very good one that the prompt was create

490
00:28:57,925 --> 00:29:01,885
Speaker 6:  a song by an artist that rhymes with truce string bean that produced a Bruce

491
00:29:01,885 --> 00:29:03,005
Speaker 6:  Springsteen song. That's

492
00:29:03,005 --> 00:29:06,525
Speaker 5:  Very good. It's fantastic. So, so that question I asked Charlie about the,

493
00:29:06,745 --> 00:29:09,925
Speaker 5:  do you, if you have the entire history of rock and roll, do you need the

494
00:29:09,925 --> 00:29:13,765
Speaker 5:  first song right Or do you need Chuck Berry? Okay, maybe you don't,

495
00:29:13,765 --> 00:29:17,725
Speaker 5:  maybe you do. Right? Like I think this third example is the

496
00:29:17,925 --> 00:29:21,805
Speaker 5:  funniest example because I can't figure how you would get to this

497
00:29:22,435 --> 00:29:25,245
Speaker 5:  without specifically one thing. Go ahead, David.

498
00:29:25,345 --> 00:29:27,925
Speaker 6:  I'm glad you agree because I left this for last for precisely this reason.

499
00:29:28,505 --> 00:29:31,405
Speaker 6:  So here is, I won't even spoil it. Here's the real one.

500
00:29:36,155 --> 00:29:37,005
Speaker 6:  Yeah, okay. Right.

501
00:29:37,555 --> 00:29:38,245
Speaker 5:  Everybody's

502
00:29:38,245 --> 00:29:41,085
Speaker 6:  Heard it a million times. That's our boy, that's our boy jd

503
00:29:42,985 --> 00:29:46,205
Speaker 7:  The longest lasting digital career that I never expected to happen.

504
00:29:46,865 --> 00:29:47,085
Speaker 5:  No.

505
00:29:48,825 --> 00:29:49,045
Speaker 5:  And

506
00:29:49,385 --> 00:29:53,245
Speaker 6:  And here, here is the ai, I I just wanna say this was created by a

507
00:29:53,245 --> 00:29:56,845
Speaker 6:  prompt on UDO. This is in theory a completely synthetic

508
00:29:57,225 --> 00:29:58,205
Speaker 6:  new work of art.

509
00:30:05,065 --> 00:30:05,885
Speaker 6:  Oh, it's so good.

510
00:30:08,745 --> 00:30:12,285
Speaker 5:  It does sound like a Jason Derulo song. Like my critique of Yes. Does this

511
00:30:12,285 --> 00:30:13,525
Speaker 5:  sound like real music aside?

512
00:30:13,795 --> 00:30:16,845
Speaker 6:  It's even got the little like vocal riff at the end. Like it's, it's it's

513
00:30:16,845 --> 00:30:17,005
Speaker 6:  red.

514
00:30:17,035 --> 00:30:20,285
Speaker 5:  Like does Jason Derulo sound like sympathetic music?

515
00:30:20,825 --> 00:30:21,645
Speaker 5:  That's your problem.

516
00:30:22,515 --> 00:30:25,845
Speaker 7:  This one's interesting though because you know, Nila, you've talked a lot

517
00:30:25,845 --> 00:30:29,645
Speaker 7:  about the issue that likeness is not copyrightable, right? Yeah. And so

518
00:30:29,895 --> 00:30:32,165
Speaker 7:  there there's a question of like, if, you know, we we're going back to this

519
00:30:32,165 --> 00:30:35,685
Speaker 7:  hypothetical, there is no suit that's suing over this particular Jason

520
00:30:35,745 --> 00:30:39,725
Speaker 7:  Derulo riff. Someone could just, I could say Jason Doo on a

521
00:30:39,725 --> 00:30:42,085
Speaker 7:  song probably, and it's not, you can't copyright that.

522
00:30:42,345 --> 00:30:46,005
Speaker 5:  So you Wait, hold on, hold on. Oh, this is weird. So these tags, did

523
00:30:46,005 --> 00:30:47,965
Speaker 6:  We, we have this fight the last time with the Metro Boomin tag

524
00:30:47,965 --> 00:30:51,765
Speaker 5:  Yes. With the Metro Boomin song. So Metro Boomin's producer tag was the

525
00:30:51,765 --> 00:30:54,285
Speaker 5:  copyrightable expression in the fake Drake song.

526
00:30:54,785 --> 00:30:58,485
Speaker 7:  If it's exactly, if it's exactly the recording of the tag though,

527
00:30:58,495 --> 00:31:02,045
Speaker 7:  right? Because it's, it's, it was, the issue was that they actually kept

528
00:31:02,265 --> 00:31:06,205
Speaker 7:  in the sample of the producer tag and

529
00:31:06,265 --> 00:31:10,045
Speaker 7:  and reproducing a recording. You can copyright that. So

530
00:31:10,065 --> 00:31:13,725
Speaker 6:  We could start every episode of The Vergecast with Neli singing Jason Derule,

531
00:31:13,725 --> 00:31:14,005
Speaker 6:  Jason

532
00:31:14,115 --> 00:31:14,805
Speaker 7:  Daro and get away

533
00:31:14,805 --> 00:31:15,485
Speaker 5:  With, and we'll,

534
00:31:15,965 --> 00:31:19,725
Speaker 7:  I think he probably would have a lot of issues, a lot of nasty letters

535
00:31:19,915 --> 00:31:23,685
Speaker 5:  Into you. I'm saying in terms of ways to boost this podcast profile after

536
00:31:23,965 --> 00:31:27,405
Speaker 5:  13 years, Jason Daro suing us is high on my list.

537
00:31:27,585 --> 00:31:30,765
Speaker 7:  That's wonderful. But, but this definitely proves that like you had to have

538
00:31:31,105 --> 00:31:34,925
Speaker 7:  had access. There is no monkeys in the back writing Shakespeare that ends

539
00:31:34,925 --> 00:31:37,325
Speaker 7:  up on Jason Daro. It just doesn't happen. It's not possible.

540
00:31:37,925 --> 00:31:40,885
Speaker 5:  Actually, I don't know. I think if you, if you took the worst impulses of

541
00:31:40,885 --> 00:31:44,445
Speaker 5:  The music industry and fed them into an ai, you might produce Jason

542
00:31:44,795 --> 00:31:45,085
Speaker 5:  Daro.

543
00:31:45,395 --> 00:31:48,365
Speaker 7:  This one's also important though because everything else we've heard has

544
00:31:48,365 --> 00:31:52,325
Speaker 7:  been written by artists pre Copyright

545
00:31:52,325 --> 00:31:56,205
Speaker 7:  Act of 1974 and probably also reflects some of maybe who

546
00:31:56,205 --> 00:31:59,845
Speaker 7:  the lawyers are writing these, you know, these cases because

547
00:32:01,665 --> 00:32:05,405
Speaker 7:  you know, we're talking about the cases reference Frank Sinatra.

548
00:32:05,735 --> 00:32:09,645
Speaker 7:  Right. And to bring in Bruce Springsteen actually

549
00:32:09,645 --> 00:32:09,805
Speaker 7:  that's

550
00:32:09,875 --> 00:32:12,925
Speaker 5:  Like 74, right? It's like Springsteen, Maria, Mariah Carey, green Day Johnny

551
00:32:13,185 --> 00:32:13,965
Speaker 5:  or Chuck Berry.

552
00:32:14,225 --> 00:32:17,645
Speaker 7:  The early ones are all Chuck Berry like the Temptations.

553
00:32:17,895 --> 00:32:18,245
Speaker 7:  Right.

554
00:32:18,245 --> 00:32:19,685
Speaker 5:  Are you getting it? Judges are

555
00:32:19,685 --> 00:32:22,845
Speaker 7:  Old. I'm seeing everyone. Yeah. And, and that's actually potentially very

556
00:32:22,845 --> 00:32:25,285
Speaker 7:  advantageous and knowing the judge and who you might go in front of, but

557
00:32:25,285 --> 00:32:28,125
Speaker 7:  then to show that also they're taking all the latest music as well. Sure.

558
00:32:28,125 --> 00:32:30,045
Speaker 7:  We're we're bringing in Jason Dillo. Yes. Like,

559
00:32:30,045 --> 00:32:32,885
Speaker 5:  Judge, have you heard Your Honor, are you familiar with Jason Dillo?

560
00:32:33,045 --> 00:32:35,605
Speaker 7:  I wanna bring Jason Dillo into the courtroom. Jason Dillo,

561
00:32:37,425 --> 00:32:41,365
Speaker 5:  By the way, another total side note. There's an incredible Katie and Apollos

562
00:32:41,365 --> 00:32:45,125
Speaker 5:  piece about hardcore Jason Duro stands and what their

563
00:32:45,125 --> 00:32:47,525
Speaker 5:  stand culture is like that I will dig up and put in the show notes.

564
00:32:47,525 --> 00:32:48,645
Speaker 7:  Oh my gosh, that sounds fun.

565
00:32:48,715 --> 00:32:52,565
Speaker 5:  It's truly one of the funniest things I've ever read on the internet. Just

566
00:32:52,565 --> 00:32:55,485
Speaker 5:  because A, it exists and B, because Katie is good at finding things like

567
00:32:55,485 --> 00:32:55,965
Speaker 5:  that, that exist.

568
00:32:56,315 --> 00:32:58,245
Speaker 7:  Have you all tried running these prompts by the way?

569
00:32:59,225 --> 00:32:59,765
Speaker 5:  No. Have you?

570
00:33:00,115 --> 00:33:03,965
Speaker 7:  Yeah. You can go to uio and to Suno and You can run the prompts that

571
00:33:04,105 --> 00:33:08,085
Speaker 7:  the, that these lawsuits are alleging. And you don't get the

572
00:33:08,085 --> 00:33:11,965
Speaker 7:  same songs obviously. But like if you write Make a jazz crooner song

573
00:33:11,965 --> 00:33:15,885
Speaker 7:  about New York baritone voice, you will definitely get it's Frank

574
00:33:15,885 --> 00:33:18,605
Speaker 7:  Sinatra. There's just like, there's no other song with Frank Sin. I don't

575
00:33:18,605 --> 00:33:22,525
Speaker 7:  think that that really is hacking the systems. It, it's really

576
00:33:22,525 --> 00:33:25,525
Speaker 7:  easy. The other thing I get a lot, by the way are

577
00:33:26,265 --> 00:33:29,885
Speaker 7:  random prompt, Hey, that sounds strangely like Crazy

578
00:33:29,995 --> 00:33:33,885
Speaker 7:  Town by Butterfly. My prompt was actually, I

579
00:33:33,885 --> 00:33:37,245
Speaker 7:  tried to make a rap about American founder Thomas Jefferson

580
00:33:37,245 --> 00:33:38,405
Speaker 5:  Butterfly by Crazy Town. Yeah.

581
00:33:38,405 --> 00:33:40,325
Speaker 7:  Crazy. Yeah. Sorry. Thank you. Butterfly by Crazy.

582
00:33:40,385 --> 00:33:42,885
Speaker 5:  If there's a band called Butterfly that had a song called Crazy Town that

583
00:33:42,885 --> 00:33:43,245
Speaker 5:  would be perfect

584
00:33:43,825 --> 00:33:45,765
Speaker 7:  In another universe. So I a ud

585
00:33:45,865 --> 00:33:46,405
Speaker 5:  I'm sure there is.

586
00:33:46,645 --> 00:33:50,365
Speaker 7:  I tried to, I tried, I did try to hack these systems a little bit

587
00:33:50,505 --> 00:33:53,925
Speaker 7:  and I wrote, I want you to write a rap about American founder

588
00:33:53,925 --> 00:33:57,605
Speaker 7:  Thomas Jefferson about not throwing away his shot nasal male

589
00:33:57,605 --> 00:34:01,325
Speaker 7:  rapper Boom Bap. And what I got was basically Butterfly by Crazy Town.

590
00:34:02,675 --> 00:34:03,845
Speaker 5:  Just like total random.

591
00:34:04,435 --> 00:34:05,285
Speaker 7:  Yeah. But

592
00:34:07,265 --> 00:34:07,485
Speaker 5:  Tom,

593
00:34:07,485 --> 00:34:10,005
Speaker 9:  Jeff never slept Constitution slave on

594
00:34:11,985 --> 00:34:12,205
Speaker 9:  hip.

595
00:34:14,385 --> 00:34:14,725
Speaker 9:  Oh God.

596
00:34:26,145 --> 00:34:29,845
Speaker 5:  I'm so, I'm I'm sorry Ted, I'm sorry for listening to this. And we

597
00:34:30,005 --> 00:34:30,525
Speaker 5:  suggest you

598
00:34:31,185 --> 00:34:34,565
Speaker 7:  Really is Butterfly by Crazy Town. I think it's also a little bit of a, what

599
00:34:34,565 --> 00:34:35,645
Speaker 7:  was that song? Superman?

600
00:34:36,385 --> 00:34:36,605
Speaker 5:  Yes.

601
00:34:37,265 --> 00:34:37,485
Speaker 9:  Oh

602
00:34:37,485 --> 00:34:39,045
Speaker 7:  Wow. Who, who's Superman by

603
00:34:39,775 --> 00:34:42,325
Speaker 5:  Three Doors Down. I'll be Your Kryptonite or whatever. kp. That was horrible

604
00:34:42,325 --> 00:34:45,445
Speaker 7:  Kryptonite. Yeah, kryptonite. Three doors down. Is that who? It's by three

605
00:34:45,445 --> 00:34:45,725
Speaker 7:  doors down. It

606
00:34:45,725 --> 00:34:46,325
Speaker 5:  Is by three doors

607
00:34:46,325 --> 00:34:49,685
Speaker 7:  Down. Oh's got a little bit of that. It's just You can so easily

608
00:34:50,395 --> 00:34:54,325
Speaker 7:  hear references that are not even the thing that you prompt. And I just,

609
00:34:54,405 --> 00:34:58,205
Speaker 7:  I have to say that if you, right now, if you go to the homepage

610
00:34:58,225 --> 00:35:01,845
Speaker 7:  of UDO, the two most popular tracks are exact

611
00:35:01,935 --> 00:35:05,605
Speaker 7:  sound alikes of Eminem and Snoop Dogg. So people are doing this

612
00:35:05,795 --> 00:35:08,205
Speaker 7:  like people are trying to make sound alikes.

613
00:35:09,105 --> 00:35:12,725
Speaker 5:  So the argument from all these companies is, look, training is fair use.

614
00:35:13,665 --> 00:35:16,765
Speaker 5:  And that's the argument for open ai. That's the argument for Google. It's

615
00:35:16,765 --> 00:35:20,165
Speaker 5:  the argument for Suno and UDO, the

616
00:35:20,565 --> 00:35:24,365
Speaker 5:  organization of these cases is different because the plaintiffs are different.

617
00:35:24,365 --> 00:35:28,005
Speaker 5:  Right. The New York Times is situated differently than the major labels.

618
00:35:28,005 --> 00:35:30,605
Speaker 5:  People have different emotional relationships with different kinds of work.

619
00:35:31,145 --> 00:35:34,085
Speaker 5:  But this is the argument, like when Google eventually goes and Sues opening

620
00:35:34,105 --> 00:35:37,765
Speaker 5:  eye for training on YouTube, the weirdness of that argument is Google

621
00:35:37,765 --> 00:35:41,605
Speaker 5:  telling open ai, the training on YouTube is not fair. Like that's

622
00:35:41,605 --> 00:35:45,005
Speaker 5:  what's gonna happen here. Mm. It's all the same argument and it's all kind

623
00:35:45,005 --> 00:35:45,485
Speaker 5:  of in a circle.

624
00:35:45,635 --> 00:35:49,565
Speaker 7:  Wait. So Google can do it in its fair use, but Suno and UIO cannot

625
00:35:49,585 --> 00:35:51,165
Speaker 7:  do it because it's not fair use. This is,

626
00:35:51,165 --> 00:35:53,245
Speaker 5:  This is the trap the industry has set for itself

627
00:35:53,625 --> 00:35:54,685
Speaker 7:  And our giant, what's

628
00:35:54,685 --> 00:35:58,165
Speaker 5:  That line consolidated? Yeah. Right. It's like it's all the same VCs and

629
00:35:58,165 --> 00:35:59,845
Speaker 5:  all in all different directions kind

630
00:35:59,845 --> 00:36:00,565
Speaker 7:  Of like the music business.

631
00:36:00,905 --> 00:36:03,765
Speaker 5:  That's true. There's that line though that's like, you have to be perfect

632
00:36:03,775 --> 00:36:06,085
Speaker 5:  every time and I just have to get through once. Mm.

633
00:36:06,115 --> 00:36:06,405
Speaker 7:  Yeah.

634
00:36:06,755 --> 00:36:10,165
Speaker 5:  It's like I can't, I don't remember exactly what it's, that's what, it's

635
00:36:10,185 --> 00:36:10,405
Speaker 5:  the

636
00:36:10,405 --> 00:36:13,165
Speaker 6:  Hacker creed, right? Like, you have to stop me every time. All I have to

637
00:36:13,165 --> 00:36:14,885
Speaker 6:  do is I just have to get through once. Yeah.

638
00:36:14,915 --> 00:36:18,565
Speaker 5:  Yeah. And that is, that feels like the copyright situation for

639
00:36:18,705 --> 00:36:22,085
Speaker 5:  AI right now. This is a house of cards and

640
00:36:22,455 --> 00:36:26,325
Speaker 5:  maybe, maybe the Times will win, maybe the

641
00:36:26,325 --> 00:36:29,885
Speaker 5:  record labels will win Mary, maybe Sarah Silverman will win. Like

642
00:36:30,335 --> 00:36:34,165
Speaker 5:  there are so many of these, maybe Google and Open Eye reach

643
00:36:34,265 --> 00:36:37,805
Speaker 5:  an agreement about training on YouTube and then a bunch of YouTube creators

644
00:36:38,025 --> 00:36:41,885
Speaker 5:  sue and maybe they win. Like You can just game it out a hundred

645
00:36:41,885 --> 00:36:45,845
Speaker 5:  different ways. The at some point someone is gonna win a lawsuit that says

646
00:36:46,045 --> 00:36:47,405
Speaker 5:  training is not fair use. Yeah.

647
00:36:48,025 --> 00:36:51,925
Speaker 7:  The fair use argument here, I feel like is notable, I feel like

648
00:36:51,925 --> 00:36:55,685
Speaker 7:  is quite different than what the New York Times can claim. Because

649
00:36:55,915 --> 00:36:59,365
Speaker 7:  part of fair use is for example, the effect on the potential market.

650
00:36:59,615 --> 00:37:03,525
Speaker 7:  Right. And with New York Times, they're gonna have to argue, well,

651
00:37:03,705 --> 00:37:07,645
Speaker 7:  you know, you're using our articles and other people are taking

652
00:37:07,645 --> 00:37:11,445
Speaker 7:  that and creating texts and putting it on other pseudo journalistic sites.

653
00:37:11,655 --> 00:37:12,005
Speaker 7:  Right.

654
00:37:12,605 --> 00:37:15,405
Speaker 5:  I I, I'm, I'm pretty sure the time's assuming for both the output and the

655
00:37:15,525 --> 00:37:15,645
Speaker 5:  training.

656
00:37:16,125 --> 00:37:16,685
Speaker 7:  I see. Okay.

657
00:37:16,785 --> 00:37:20,325
Speaker 5:  So I I I think these cases are all different. This is what I mean, like the,

658
00:37:20,625 --> 00:37:23,405
Speaker 5:  the strategy for one doesn't work for all of them in the same way. Right?

659
00:37:23,405 --> 00:37:27,325
Speaker 7:  Right. In the case of music, the marketplace argument like does is it

660
00:37:27,325 --> 00:37:31,285
Speaker 7:  going to affect the marketplace? Is I I think they have a very strong argument

661
00:37:31,285 --> 00:37:33,845
Speaker 7:  here. I think the RIA has a very strong argument. They're basically saying

662
00:37:34,355 --> 00:37:38,325
Speaker 7:  Suno, nio, you are charging users money to make songs

663
00:37:38,435 --> 00:37:42,325
Speaker 7:  that you are allowing them to upload to the exact same place where we

664
00:37:42,355 --> 00:37:46,285
Speaker 7:  also have all of our songs and to Spotify, apple Music, et cetera. And so

665
00:37:46,285 --> 00:37:50,245
Speaker 7:  you are actually changing the marketplace for music,

666
00:37:50,905 --> 00:37:54,805
Speaker 7:  having used all of this output. But is that, is that not part of the argument

667
00:37:54,805 --> 00:37:55,285
Speaker 7:  you're saying?

668
00:37:55,765 --> 00:37:59,285
Speaker 5:  I I think we have to find out how that shakes out.

669
00:37:59,735 --> 00:38:00,085
Speaker 7:  Right?

670
00:38:00,635 --> 00:38:04,365
Speaker 5:  Like I, I don't know. They gotta get assigned a judge, right?

671
00:38:04,365 --> 00:38:06,725
Speaker 5:  Like Right, right now what they've done is they've put out a complaint and

672
00:38:06,725 --> 00:38:09,805
Speaker 5:  a press release. There hasn't been a reply to that complaint or an answer.

673
00:38:10,365 --> 00:38:12,805
Speaker 5:  They haven't been assigned a judge. Like they haven't done any discovery.

674
00:38:12,805 --> 00:38:15,925
Speaker 5:  Like we just don't know a bunch of stuff. And we certainly don't know where

675
00:38:15,925 --> 00:38:19,805
Speaker 5:  they're gonna put their focus. But that part where copyright law

676
00:38:19,805 --> 00:38:23,485
Speaker 5:  is just about making copies and in the history of computing, every single

677
00:38:23,555 --> 00:38:27,525
Speaker 5:  copy has been litigated down to, again, I bring it up, I think I

678
00:38:27,525 --> 00:38:31,245
Speaker 5:  bring it up every time. MAI versus peak systems. You go look it up. This

679
00:38:31,245 --> 00:38:34,645
Speaker 5:  is, are you a third party software seller

680
00:38:35,235 --> 00:38:39,005
Speaker 5:  allowed to load software into a computer's memory without permission?

681
00:38:39,935 --> 00:38:43,925
Speaker 5:  Crazy. A co a crazy court case. Yeah. Can you put a disc in a computer

682
00:38:43,985 --> 00:38:47,405
Speaker 5:  and load software from the disc to the hard drive without my permission got

683
00:38:47,405 --> 00:38:51,365
Speaker 5:  litigated and they lost crazy. And they lost. And then we had to get all

684
00:38:51,365 --> 00:38:54,605
Speaker 5:  the way through caching our ephemeral copies on your

685
00:38:55,235 --> 00:38:58,845
Speaker 5:  ISPs network equipment or those copies that should be

686
00:38:58,845 --> 00:39:02,725
Speaker 5:  litigated. This is copyright, it's dumb. Like it is a very

687
00:39:02,795 --> 00:39:06,765
Speaker 5:  dumb rationale, but it litigates the creation of copies. So

688
00:39:06,765 --> 00:39:10,685
Speaker 5:  here it's did you have permission to make a

689
00:39:10,685 --> 00:39:14,445
Speaker 5:  copy to train your model of all these songs and e

690
00:39:14,445 --> 00:39:16,765
Speaker 5:  every time you didn't have permission. By the way, we want the statutory

691
00:39:16,765 --> 00:39:20,685
Speaker 5:  maximum of $150,000, which essentially ends up being a

692
00:39:20,685 --> 00:39:21,645
Speaker 5:  pretend amount of money. It

693
00:39:21,755 --> 00:39:23,325
Speaker 7:  It's gotta be bigger than the US GDP.

694
00:39:23,565 --> 00:39:25,765
Speaker 5:  Yeah. It's like crazy, right? Like, did you have permission to copy every

695
00:39:25,765 --> 00:39:29,325
Speaker 5:  song in the world, And if you didn't, every song in the world times $150,000.

696
00:39:29,355 --> 00:39:30,085
Speaker 5:  What we're asking for,

697
00:39:30,305 --> 00:39:31,085
Speaker 7:  I'm gonna run this

698
00:39:31,585 --> 00:39:35,365
Speaker 5:  If you didn't have that permission, can we do an analysis that says that

699
00:39:35,365 --> 00:39:39,125
Speaker 5:  use is fair use? Right. So fair use is what's called an affirmative

700
00:39:39,125 --> 00:39:43,085
Speaker 5:  defense to copyright infringement. Where you, you, you admit it like I did,

701
00:39:43,285 --> 00:39:47,205
Speaker 5:  I did it. But under this other rationale, it's That's fine. And

702
00:39:47,205 --> 00:39:50,685
Speaker 5:  so that's like the winding path here is,

703
00:39:51,155 --> 00:39:55,005
Speaker 5:  well first they won't even cop to having made the copies, which

704
00:39:55,005 --> 00:39:58,525
Speaker 5:  is why The music industry is putting out, well here's just Johnny be good.

705
00:39:58,525 --> 00:40:01,885
Speaker 5:  Like you can't output Johnny be good unless you copy Johnny be good on the,

706
00:40:01,885 --> 00:40:05,645
Speaker 5:  on the front end. Right. Okay. So first we gotta get them to cop to making

707
00:40:05,825 --> 00:40:09,445
Speaker 5:  the copies at all, which they claim is proprietary business information.

708
00:40:10,155 --> 00:40:14,005
Speaker 5:  Sure. Then it's was that copy allowed,

709
00:40:14,235 --> 00:40:16,205
Speaker 5:  they obviously didn't have permission. This is why they're in a lawsuit.

710
00:40:16,305 --> 00:40:20,045
Speaker 5:  And then it, and then it's, is it fair use? And then we run the analysis

711
00:40:20,665 --> 00:40:23,125
Speaker 5:  and the analysis is like the purpose and character of the use, the amount

712
00:40:23,125 --> 00:40:26,885
Speaker 5:  of the use, the nature of the use, the, and then the last

713
00:40:26,885 --> 00:40:30,285
Speaker 5:  factor is the effect on the market. Right? On the output side. I think the

714
00:40:30,285 --> 00:40:31,725
Speaker 5:  market argument is really strong.

715
00:40:31,725 --> 00:40:34,565
Speaker 7:  Right? Right. So the question is, 'cause this case, this is something I actually

716
00:40:34,565 --> 00:40:37,125
Speaker 7:  don't understand, maybe You can explain with your copyright law degree.

717
00:40:38,345 --> 00:40:42,005
Speaker 7:  Can, can, is there like some wall between the input and the

718
00:40:42,005 --> 00:40:45,925
Speaker 7:  output in, in this argument that says, well, there's no

719
00:40:45,925 --> 00:40:46,485
Speaker 7:  marketplace for, you

720
00:40:46,485 --> 00:40:49,645
Speaker 5:  Know, that emoji, it's like this with the hands. Yeah, it's the hands are

721
00:40:49,645 --> 00:40:51,565
Speaker 5:  up. Like I'm just that emoji right now. I

722
00:40:51,565 --> 00:40:54,285
Speaker 7:  Don't know because, because I was trying to say, oh, well if there's a clear

723
00:40:54,785 --> 00:40:58,085
Speaker 7:  change in the marketplace for songs, which are all outputs, but it sounds

724
00:40:58,085 --> 00:41:00,165
Speaker 7:  like, you know, we don't know what the responses are gonna be, but they could

725
00:41:00,165 --> 00:41:03,045
Speaker 7:  say, well there isn't currently a marketplace for training data in this kind

726
00:41:03,125 --> 00:41:06,205
Speaker 7:  of way. And so it's not affecting that marketplace. But

727
00:41:06,205 --> 00:41:10,165
Speaker 5:  If you, there will never be a market if you just set the rate at zero.

728
00:41:10,455 --> 00:41:14,085
Speaker 5:  Right? Right. So if you're like, I want really high quality

729
00:41:14,175 --> 00:41:18,165
Speaker 5:  music for my high quality music AI program,

730
00:41:18,385 --> 00:41:22,205
Speaker 5:  I'm gonna go pay a bunch of artists, but then these guys come along and

731
00:41:22,205 --> 00:41:25,125
Speaker 5:  steal it. Like you've just, you've actually preemptively destroyed the market.

732
00:41:25,125 --> 00:41:28,365
Speaker 5:  Sure. You've never allowed that market to set some rates. And I've heard

733
00:41:28,395 --> 00:41:31,205
Speaker 5:  from publishers who are taking the deals with opening AI disclosure of Vox

734
00:41:31,205 --> 00:41:33,805
Speaker 5:  Media has a content licensing deal with opening ai.

735
00:41:34,995 --> 00:41:37,725
Speaker 5:  I've heard from other publishers, not our company, that one of the reasons

736
00:41:37,725 --> 00:41:41,605
Speaker 5:  they've taken these deals is to create that market, right? Hmm.

737
00:41:41,665 --> 00:41:45,165
Speaker 5:  So that the times can go to court and say, this has an effect on the market.

738
00:41:45,715 --> 00:41:49,085
Speaker 5:  Look at this market. Hmm. Look at the money that's moving around.

739
00:41:49,625 --> 00:41:52,605
Speaker 5:  And so some of these publishers are, are playing kind of a strategic game

740
00:41:52,605 --> 00:41:56,325
Speaker 5:  to say we should create a market to help that factor along. I think that's

741
00:41:56,845 --> 00:42:00,725
Speaker 5:  fascinating. Hmm. The, but I don't think that the AI company,

742
00:42:00,965 --> 00:42:04,805
Speaker 5:  I think they thought they could just buy forgiveness. And what's crazy

743
00:42:04,905 --> 00:42:08,805
Speaker 5:  to me is when it was Napster or YouTube or Google search,

744
00:42:08,805 --> 00:42:12,725
Speaker 5:  even buying forgiveness worked because people liked the companies,

745
00:42:13,195 --> 00:42:16,565
Speaker 5:  they liked the products, they liked the experiences they were having. And

746
00:42:16,635 --> 00:42:20,565
Speaker 5:  here people, I mean I'm con you, if you're listening to

747
00:42:20,565 --> 00:42:23,525
Speaker 5:  this and you have a, a very different view of this, lemme know, but our audience

748
00:42:23,585 --> 00:42:27,405
Speaker 5:  is pretty loud with us that they don't like these companies and they don't,

749
00:42:27,405 --> 00:42:31,245
Speaker 5:  they, they perceive this as a moral problem. And I,

750
00:42:31,405 --> 00:42:33,605
Speaker 5:  I think that's just a very different position for them all to be in.

751
00:42:33,815 --> 00:42:37,565
Speaker 7:  Which brings us to your moral quandary. It seems like you flipped sides from

752
00:42:37,565 --> 00:42:38,205
Speaker 7:  20 years ago.

753
00:42:38,475 --> 00:42:42,165
Speaker 5:  Yeah. The idea that I'm sitting here being like the RIA has a point is crazy.

754
00:42:42,315 --> 00:42:46,125
Speaker 5:  Like I, it's bananas and Sarah j and I have been like all day,

755
00:42:46,125 --> 00:42:50,085
Speaker 5:  every day like slacking or like who have we become, you know, this

756
00:42:50,085 --> 00:42:53,125
Speaker 5:  is like the horseshoe theory of copyright law, politics.

757
00:42:54,675 --> 00:42:58,645
Speaker 5:  It's weird, man. And I, I think one of the pieces of the puzzle, and

758
00:42:58,645 --> 00:43:01,485
Speaker 5:  I'm curious how you see this in The music industry itself, Charlie, one of

759
00:43:01,485 --> 00:43:05,365
Speaker 5:  the pieces of the puzzle here is that the internet just blew the

760
00:43:05,425 --> 00:43:09,285
Speaker 5:  bottom outta The music industry. Like there's no, there's no

761
00:43:09,345 --> 00:43:12,605
Speaker 5:  way to be like a middle class musician anymore. There's no guaranteed way

762
00:43:12,605 --> 00:43:15,605
Speaker 5:  to make money. You're like, you're playing the same algorithmic game as everyone

763
00:43:15,605 --> 00:43:19,045
Speaker 5:  else. You're beholden to some labels. You don't have any power as an individual

764
00:43:19,045 --> 00:43:23,005
Speaker 5:  against these platforms. So now this next group of people who's

765
00:43:23,005 --> 00:43:26,725
Speaker 5:  come and taking your work for free and is gonna extract value

766
00:43:26,725 --> 00:43:30,605
Speaker 5:  from you, well sure. Like the enemy of my enemy

767
00:43:30,605 --> 00:43:34,285
Speaker 5:  is my friend. It's, it's kind of the vibe. But I'm wondering if you see that

768
00:43:34,285 --> 00:43:35,605
Speaker 5:  reflected in the actual music industry.

769
00:43:36,005 --> 00:43:38,885
Speaker 7:  Absolutely. I mean, the public perception here is so different than what

770
00:43:38,885 --> 00:43:42,205
Speaker 7:  was happening back in the Napster era. Back in the Napster era, the labels

771
00:43:42,635 --> 00:43:46,605
Speaker 7:  were enemy number one. Selling out to labels was, was a big, you know,

772
00:43:46,715 --> 00:43:50,205
Speaker 7:  they were, they were, they were the worst players Today. I actually think

773
00:43:50,205 --> 00:43:54,045
Speaker 7:  they've done a very effective job of using their proxy Spotify and let

774
00:43:54,045 --> 00:43:56,685
Speaker 7:  Spotify be the enemy. And everyone's like Sony Music. Who are they? Like

775
00:43:56,685 --> 00:44:00,285
Speaker 7:  Warner, UMG. Like they labeled deal, but they are not, they, they're not

776
00:44:00,545 --> 00:44:04,445
Speaker 7:  the topic of conversation of who's really screwing who now they basically

777
00:44:04,445 --> 00:44:08,165
Speaker 7:  help set the rates of what gets paid out in streaming. and it's the

778
00:44:08,365 --> 00:44:10,565
Speaker 7:  distributors now that really are taking all the heat. And so they're actually

779
00:44:10,565 --> 00:44:13,885
Speaker 7:  in a better, I think, place of public perception in terms of within The music

780
00:44:14,205 --> 00:44:18,125
Speaker 7:  industry. I, I see songwriters, producers,

781
00:44:19,515 --> 00:44:23,125
Speaker 7:  fans totally freaked out about what's going on. When you go and

782
00:44:23,235 --> 00:44:26,805
Speaker 7:  scan through a lot of the, the YouTube comments of some of these

783
00:44:27,545 --> 00:44:31,425
Speaker 7:  AI songs. The, the sentiment is we are

784
00:44:31,425 --> 00:44:35,265
Speaker 7:  screwed. Music is over. I give up. I am not learning an

785
00:44:35,265 --> 00:44:39,145
Speaker 7:  instrument. Like it's, it's sort of, it, it is not, the future is

786
00:44:39,145 --> 00:44:43,105
Speaker 7:  bright. We're gonna create new beautiful music. Like my creativity is

787
00:44:43,105 --> 00:44:47,025
Speaker 7:  going to blossom. I think that there is a, a real existential fear

788
00:44:47,025 --> 00:44:50,505
Speaker 7:  that is exists within all of the, you know, the AI world. But you're, you're

789
00:44:50,505 --> 00:44:54,105
Speaker 7:  getting into like our human emotions and the beautiful creative output, hopefully

790
00:44:54,105 --> 00:44:56,145
Speaker 7:  beautiful. I mean, listen how you feel about pop music,

791
00:44:56,385 --> 00:44:56,945
Speaker 5:  Whatever Jason Deru

792
00:44:58,315 --> 00:44:59,465
Speaker 7:  Don't bring Jason into this.

793
00:45:00,645 --> 00:45:02,185
Speaker 5:  We gotta get Dar on the po I

794
00:45:02,185 --> 00:45:02,825
Speaker 7:  Don't really do,

795
00:45:03,005 --> 00:45:06,385
Speaker 6:  That's obviously like reading through the RIAs lawsuit like that is, they

796
00:45:06,455 --> 00:45:09,865
Speaker 6:  talk about the creativity and, and human emotion of it all. Yes.

797
00:45:10,765 --> 00:45:14,425
Speaker 6:  But is the, is the end of this just they're trying to get

798
00:45:14,425 --> 00:45:17,585
Speaker 6:  checks in the same way that there are absolutely lot, lot of folks out there

799
00:45:17,585 --> 00:45:20,425
Speaker 6:  just trying to get checks. Like, well, 'cause part of me, like I I think

800
00:45:20,425 --> 00:45:23,585
Speaker 6:  obviously that's the answer. But also part of me wonders if the labels are

801
00:45:23,585 --> 00:45:27,265
Speaker 6:  feeling the same way that you do, which is that, oh, this is not just a thing

802
00:45:27,345 --> 00:45:30,025
Speaker 6:  we need to make money off of tomorrow. This is like an existential crisis

803
00:45:30,165 --> 00:45:33,505
Speaker 6:  for our business down the road. Or if they're like, whatever, this is just

804
00:45:33,545 --> 00:45:35,065
Speaker 6:  a new turn, we have to make sure we get paid.

805
00:45:35,135 --> 00:45:38,305
Speaker 7:  This is an existential crisis because they are already losing market share

806
00:45:38,685 --> 00:45:41,825
Speaker 7:  to, you know, people who are not on major labels. But major label

807
00:45:42,455 --> 00:45:46,225
Speaker 7:  listening is down. Hmm. Right. As an overall share of all

808
00:45:46,225 --> 00:45:50,065
Speaker 7:  listening. It's still a lot of it, still the majority of listening. But

809
00:45:50,125 --> 00:45:53,785
Speaker 7:  so they recognize that flooding the streamers with more and more

810
00:45:53,785 --> 00:45:57,385
Speaker 7:  independent music has not necessarily been good for their business. And with

811
00:45:57,385 --> 00:46:00,305
Speaker 7:  more flooding, it's just going to bring everything down to everything as

812
00:46:00,305 --> 00:46:04,265
Speaker 7:  valueless entirely. If you own music and it gets played a lot on

813
00:46:04,265 --> 00:46:07,865
Speaker 7:  streaming, there's a lot of money in it. Like there's

814
00:46:07,865 --> 00:46:10,625
Speaker 7:  billions and billions and billions of dollars in streaming. How it's distributed

815
00:46:10,685 --> 00:46:14,025
Speaker 7:  is not always fair. And people get upset about this, but they very much need

816
00:46:14,025 --> 00:46:17,585
Speaker 7:  to figure out how to, how, how, how to enter and participate in this marketplace.

817
00:46:17,585 --> 00:46:21,465
Speaker 7:  And I think kind of like a content ID system, they want to figure out how

818
00:46:21,565 --> 00:46:25,185
Speaker 7:  to properly license. You wanna use Jason Daros voice? Jason Daro says yes

819
00:46:25,245 --> 00:46:28,185
Speaker 7:  and it costs this and now we've got Jason Dollo copies and that's okay by

820
00:46:28,185 --> 00:46:31,745
Speaker 5:  The way, of all of the artists who would let his voice go deepfake to make

821
00:46:31,745 --> 00:46:32,705
Speaker 5:  like commercials. Jason

822
00:46:32,755 --> 00:46:33,585
Speaker 7:  Dillo. Yeah. Jason

823
00:46:34,875 --> 00:46:37,345
Speaker 5:  Dollo. Look, I, it's, I'm not, I'm not even saying I've, I've talked a lot

824
00:46:37,345 --> 00:46:41,105
Speaker 5:  of Jason Dillo related ish on this episode. I'm aware of it. I just

825
00:46:41,105 --> 00:46:43,025
Speaker 5:  know that he is a commercial mastermind.

826
00:46:43,285 --> 00:46:43,505
Speaker 7:  Yes.

827
00:46:44,015 --> 00:46:46,465
Speaker 5:  Like that man's gonna make a bag no matter what happens. Yes.

828
00:46:47,805 --> 00:46:50,865
Speaker 5:  Friend of the pod, Blake Reed, he is a professor at Colorado Law, teaches

829
00:46:50,865 --> 00:46:54,265
Speaker 5:  copyright, telecom, all this stuff. He wrote me a note

830
00:46:54,615 --> 00:46:57,145
Speaker 5:  last week or the week before and he sent me really smart that I've been thinking

831
00:46:57,145 --> 00:47:00,925
Speaker 5:  about. And it's related to what you're saying, David, copyright

832
00:47:00,945 --> 00:47:04,805
Speaker 5:  law is like a economic system, right? We create

833
00:47:04,965 --> 00:47:07,605
Speaker 5:  scarcity and then we can like charge money for things. 'cause you're not

834
00:47:07,605 --> 00:47:11,245
Speaker 5:  allowed to just like freely copy them. So if you do something bad in the

835
00:47:11,245 --> 00:47:15,045
Speaker 5:  world of copyright law, the answer is you pay money and you

836
00:47:15,045 --> 00:47:18,805
Speaker 5:  fix it. And you, you even out the economic problem that you've created,

837
00:47:19,055 --> 00:47:22,925
Speaker 5:  right? Olivia Rodrigo might have sung four

838
00:47:22,925 --> 00:47:26,525
Speaker 5:  notes of a Taylor Swift song. The answer is Taylor Swift gets a writing credit

839
00:47:26,745 --> 00:47:29,710
Speaker 5:  and then some money flows to Taylor Swift. And that is the end of that story.

840
00:47:29,710 --> 00:47:32,765
Speaker 5:  Right? And it's just an economic problem that you've solved by redistributing

841
00:47:32,765 --> 00:47:36,445
Speaker 5:  money. AI is a moral problem. This is the thing Blake pointed out to me is

842
00:47:36,445 --> 00:47:40,285
Speaker 5:  like, the money doesn't solve the perceived moral issue here. So the labels

843
00:47:40,285 --> 00:47:42,445
Speaker 5:  might get paid, they might find some business model that lets some license

844
00:47:42,505 --> 00:47:45,645
Speaker 5:  the music into perpetuity or whatever. But the thing you're seeing in the

845
00:47:45,645 --> 00:47:49,525
Speaker 5:  YouTube comments, the thing our audience is feeling, the thing I think a

846
00:47:49,525 --> 00:47:53,445
Speaker 5:  lot of artists are feeling does not get solved by money. Right? It

847
00:47:53,445 --> 00:47:57,045
Speaker 5:  it, it's like another problem. And so like you, you see these deals come

848
00:47:57,045 --> 00:48:00,405
Speaker 5:  up and get signed and whatever, and everyone's like, eh, it's still pretty

849
00:48:00,645 --> 00:48:04,185
Speaker 5:  icky. Right? And there, there's something there that I think is important.

850
00:48:04,385 --> 00:48:08,345
Speaker 5:  I haven't quite puzzled it out. I actually want to do something with

851
00:48:08,345 --> 00:48:11,185
Speaker 5:  that idea. If you have further thoughts, let me know what you think about

852
00:48:11,185 --> 00:48:15,065
Speaker 5:  it. But that gap is the gap, right? We can move

853
00:48:15,105 --> 00:48:18,265
Speaker 5:  a bunch of money around like the VCs in Hollywood and

854
00:48:18,885 --> 00:48:22,465
Speaker 5:  the recording in in Streets Association of America. God bless them, they

855
00:48:22,465 --> 00:48:25,825
Speaker 5:  will move the money around. Lucian Grange will get paid.

856
00:48:26,725 --> 00:48:30,625
Speaker 5:  Is that gonna solve the other problem? Right? Like and that's, I think that's

857
00:48:30,625 --> 00:48:31,385
Speaker 5:  really hard. Well,

858
00:48:31,385 --> 00:48:34,905
Speaker 7:  There's two things that musicians need to not fear. One is that because

859
00:48:35,405 --> 00:48:39,065
Speaker 7:  the output of all of these models cannot be copywritten, this

860
00:48:39,075 --> 00:48:42,585
Speaker 7:  music is kind of in this weird limbo space. Like maybe it's gonna def

861
00:48:43,085 --> 00:48:47,065
Speaker 7:  it will definitely find some streams, but it probably won't be synced on

862
00:48:47,065 --> 00:48:50,945
Speaker 7:  television and film because no TV producer is gonna wanna

863
00:48:50,945 --> 00:48:54,145
Speaker 7:  have a song where they like, don't really understand the rights associated

864
00:48:54,145 --> 00:48:57,305
Speaker 7:  with that song. And if they have the right to it. And does it also secretly

865
00:48:57,655 --> 00:49:01,585
Speaker 7:  contain a vocal sample of James Brown that has been stolen. Like

866
00:49:01,885 --> 00:49:05,385
Speaker 7:  so nobody wants to, any rights holder doesn't want to use this music that

867
00:49:05,385 --> 00:49:08,545
Speaker 7:  can't be used in a weird way. So I think composers and people who are putting

868
00:49:08,545 --> 00:49:10,905
Speaker 7:  stuff on TV, in film, I think that they're still very much a business for

869
00:49:10,905 --> 00:49:14,865
Speaker 7:  them until these much bigger legal issues get sorted out

870
00:49:14,925 --> 00:49:17,585
Speaker 7:  the other places that music is about human connection. And I don't say this

871
00:49:17,585 --> 00:49:21,385
Speaker 7:  in some like wishy-washy way. It's like there is no fandom

872
00:49:21,685 --> 00:49:25,665
Speaker 7:  for Olivia Rodrigo without an Olivia Rodrigo. Like you need the person. The

873
00:49:25,665 --> 00:49:28,265
Speaker 7:  time that The music industry tried to create like an avatar

874
00:49:29,425 --> 00:49:33,345
Speaker 7:  racially strangely coded, what

875
00:49:33,345 --> 00:49:37,025
Speaker 7:  was that guy's name? It was terrible. They tried to do like their NFT

876
00:49:37,085 --> 00:49:40,985
Speaker 7:  avatar pop star and it was an utter failure both because it

877
00:49:40,985 --> 00:49:44,705
Speaker 7:  was completely racist and because why would we develop a relationship to

878
00:49:44,705 --> 00:49:48,665
Speaker 7:  this thing? And so the the fandom side, the pop stardom side of pop

879
00:49:48,665 --> 00:49:50,345
Speaker 7:  music, I don't think is ever gonna go away. What

880
00:49:50,345 --> 00:49:53,825
Speaker 5:  About uni miko, right? Isn't that she's, she's like the cartoon

881
00:49:53,935 --> 00:49:57,535
Speaker 5:  character. I just learned that she's officially code named

882
00:49:57,875 --> 00:49:58,415
Speaker 5:  CVO one.

883
00:49:59,205 --> 00:50:03,055
Speaker 7:  Yeah. There are the, there are these avatar characters that are finding some

884
00:50:03,055 --> 00:50:06,695
Speaker 7:  fandoms online. Yes, that's gonna happen. I'd still just like that doesn't,

885
00:50:06,715 --> 00:50:10,255
Speaker 7:  that's not Olivia, that's not Taylor, that's not Gaga. I'm sorry.

886
00:50:10,525 --> 00:50:11,535
Speaker 7:  It's just different. All

887
00:50:11,535 --> 00:50:13,455
Speaker 5:  Right, we gotta end it. They're not Jason Deo. They're

888
00:50:13,455 --> 00:50:14,335
Speaker 7:  Not Jason Deo.

889
00:50:15,125 --> 00:50:18,535
Speaker 5:  Like the bar is like, can your cartoon character defeat Jason Derulo?

890
00:50:19,365 --> 00:50:21,615
Speaker 5:  I'll take it. That's a good place to end it. Charlie, thank you so much for

891
00:50:21,615 --> 00:50:24,015
Speaker 5:  joining the show. I suspect you're gonna be back on the show quite a bit

892
00:50:24,275 --> 00:50:26,815
Speaker 5:  as these cases wind their way through the courts. Anytime. All

893
00:53:42,245 --> 00:53:43,295
Speaker 6:  Obviously I would say

894
00:54:31,385 --> 00:54:33,705
Speaker 6:  copies it, Arthur gets a little bit less solid.

895
00:54:35,445 --> 00:54:37,665
Speaker 5:  All right, we gotta do a lightning round. There's a lot of gadgets. There's

896
00:54:37,665 --> 00:54:41,585
Speaker 5:  basically two gadget lightning rounds. Yeah, let's start three

897
00:54:41,675 --> 00:54:45,385
Speaker 5:  phone events announced in quick succession here. So Samsung announced

898
00:54:46,065 --> 00:54:49,905
Speaker 5:  unpacked, it's looking like July July 10th. Yeah.

899
00:54:49,995 --> 00:54:53,665
Speaker 5:  Weeks. We expecting some foldables surprise pixel

900
00:54:53,735 --> 00:54:57,625
Speaker 5:  nine announcement from Google in August and then Motorola just had an event

901
00:54:57,725 --> 00:55:00,225
Speaker 5:  and announced the 2024 razors. So

902
00:55:00,605 --> 00:55:03,185
Speaker 6:  Lot knows it doesn't get to announce an event, it just has to tell you what

903
00:55:03,185 --> 00:55:03,665
Speaker 6:  phones there're at.

904
00:55:03,665 --> 00:55:07,625
Speaker 5:  Well it had like a big influencer like I don't think we went 'cause we already

905
00:55:07,725 --> 00:55:11,265
Speaker 5:  had the phones, but like it had like a big influencer

906
00:55:11,485 --> 00:55:15,425
Speaker 5:  launch event with some of the funniest photos of like very cool

907
00:55:15,425 --> 00:55:19,105
Speaker 5:  influencers looking extremely bored with like very

908
00:55:19,385 --> 00:55:21,025
Speaker 5:  colorful razor phones. We can get to that in a minute.

909
00:55:21,045 --> 00:55:21,665
Speaker 6:  Sounds right.

910
00:55:22,135 --> 00:55:24,625
Speaker 5:  This is pretty early in the cycle for a bunch of phone launches.

911
00:55:24,885 --> 00:55:28,265
Speaker 6:  It is weird. I've been trying to figure out what's going on and it's very

912
00:55:28,355 --> 00:55:32,265
Speaker 6:  clear that the, the AI race is now

913
00:55:32,855 --> 00:55:36,785
Speaker 6:  happening to everybody else. Where I think the thing that is happening

914
00:55:36,785 --> 00:55:40,425
Speaker 6:  is everybody is just announcing like the same set of 12 features

915
00:55:40,765 --> 00:55:44,385
Speaker 6:  and the same new hardware that does the same new stuff. Like

916
00:55:44,435 --> 00:55:48,225
Speaker 6:  Apple is copying, Google is copying, Samsung is copying Apple. And so now

917
00:55:48,225 --> 00:55:50,905
Speaker 6:  there's this incredible race to just be the first one to say it out loud.

918
00:55:51,565 --> 00:55:55,545
Speaker 6:  And I think especially on Android there, there's just

919
00:55:55,545 --> 00:55:59,465
Speaker 6:  going to be so much like AI sameness over the next 12

920
00:55:59,465 --> 00:56:03,225
Speaker 6:  months as they all rush to do everything they can think of. So the goal I

921
00:56:03,225 --> 00:56:07,185
Speaker 6:  think especially is to beat Apple. Like to me this Google thing

922
00:56:07,185 --> 00:56:10,985
Speaker 6:  is so transparently just doing this sooner

923
00:56:11,205 --> 00:56:14,705
Speaker 6:  in order to say all the words out loud about what your camera can do before

924
00:56:14,705 --> 00:56:17,345
Speaker 6:  Apple says those same words out loud about what its camera can do.

925
00:56:17,655 --> 00:56:21,305
Speaker 5:  Yeah, what what, so what's interesting, well let's start with Google. What's

926
00:56:21,505 --> 00:56:25,485
Speaker 5:  fascinating to me about Google is they just shook up those

927
00:56:25,485 --> 00:56:29,445
Speaker 5:  teams. So Rick Oslow who had all of hardware

928
00:56:29,465 --> 00:56:31,285
Speaker 5:  now has all of it including Android.

929
00:56:33,205 --> 00:56:36,945
Speaker 5:  That's a complicated switch up, right?

930
00:56:37,125 --> 00:56:40,785
Speaker 5:  So it like the Pixel team, their boss now runs Android

931
00:56:40,965 --> 00:56:44,745
Speaker 5:  or their old boss now on Android, they got a new boss. And the big question

932
00:56:44,745 --> 00:56:48,585
Speaker 5:  for Google this whole time has been are you gonna do, are you gonna try?

933
00:56:48,985 --> 00:56:52,425
Speaker 5:  Are you gonna try hard? And like the thing that has kept them from trying

934
00:56:52,425 --> 00:56:55,385
Speaker 5:  hard is they have to maintain the Android ecosystem in the United States.

935
00:56:55,385 --> 00:56:58,345
Speaker 5:  That's mostly expressed to Samsung. Like you just gotta keep Samsung happy

936
00:56:58,765 --> 00:57:02,465
Speaker 5:  around the world or many more players. And Android is expressed very

937
00:57:02,465 --> 00:57:06,145
Speaker 5:  differently, but if like the Pixel guy like Rick

938
00:57:06,245 --> 00:57:10,025
Speaker 5:  is like, I'm doing it with the Pixel and that's his first move

939
00:57:10,565 --> 00:57:14,505
Speaker 5:  is the boss of Android. Weird. It is just weird I think. I think

940
00:57:14,505 --> 00:57:17,505
Speaker 5:  that's weird. It's like that shakeup is weird. And then on top of that,

941
00:57:18,385 --> 00:57:22,065
Speaker 5:  I think Google really wants AI to be the differentiator for Pixel. Oh yeah,

942
00:57:22,065 --> 00:57:25,425
Speaker 5:  right. That big vertically integrated, like only Google can do all this stuff

943
00:57:25,425 --> 00:57:28,905
Speaker 5:  at every layer of the stack. We build our own chips like da da, like all

944
00:57:28,905 --> 00:57:32,305
Speaker 5:  the way you want to do that with Pixel so You can body up against the fund.

945
00:57:32,365 --> 00:57:34,785
Speaker 5:  So a really just weird spot for Google to be in

946
00:57:35,245 --> 00:57:38,105
Speaker 6:  It is, and it feels like Google is

947
00:57:38,845 --> 00:57:42,785
Speaker 6:  trying to do the same thing to both Samsung and Apple, but can only

948
00:57:42,925 --> 00:57:46,865
Speaker 6:  say that it's trying to do it to Apple, which is basically like I, I think

949
00:57:46,865 --> 00:57:49,745
Speaker 6:  Google very clearly and they, they've kind of said this out loud, sees this

950
00:57:50,325 --> 00:57:54,145
Speaker 6:  as its chance to win in hardware, right? That like if they can be the ones

951
00:57:54,145 --> 00:57:58,065
Speaker 6:  to make AI happen and do it well and do it first and do it

952
00:57:58,645 --> 00:58:02,345
Speaker 6:  in the biggest, most interesting, most differentiated ways that all of a

953
00:58:02,345 --> 00:58:05,945
Speaker 6:  sudden this is the best new reason to buy a phone that we've had in a really

954
00:58:05,945 --> 00:58:08,745
Speaker 6:  long time. Yeah. I don't know if that's true. I don't know that there's a

955
00:58:08,785 --> 00:58:12,465
Speaker 6:  ton of evidence yet that it is true. But if it's true And, if you believe

956
00:58:12,465 --> 00:58:15,625
Speaker 6:  it's true, everything Google has done sort of makes sense. Right.

957
00:58:15,865 --> 00:58:19,185
Speaker 5:  I will remind you that my response to all AI announcements right now are,

958
00:58:19,215 --> 00:58:22,265
Speaker 5:  it's probably broken. I don't believe you including Apple. I wanna be very

959
00:58:22,265 --> 00:58:25,385
Speaker 5:  clear about this. Apple has not announced a date for anything yet

960
00:58:26,245 --> 00:58:29,265
Speaker 5:  for any of the Apple intelligence features. And no one has ever seen those

961
00:58:29,505 --> 00:58:32,145
Speaker 5:  features in anything but a totally controlled demo. So

962
00:58:32,495 --> 00:58:36,265
Speaker 6:  Yeah, there's an increasingly angry rant inside of me

963
00:58:36,265 --> 00:58:39,105
Speaker 6:  about how AI is actually nothing and we all need to stop it,

964
00:58:40,125 --> 00:58:41,945
Speaker 6:  but I'm, I'm waiting a while for that to come out.

965
00:58:42,105 --> 00:58:45,025
Speaker 5:  I mean, look, we can get a computer to produce in a pitch. Perfect. Jason

966
00:58:45,195 --> 00:58:48,985
Speaker 5:  Dillo tech, right? It's something Yeah. I'm not sure what it is, but it's

967
00:58:48,985 --> 00:58:49,425
Speaker 5:  something. It

968
00:58:49,425 --> 00:58:50,585
Speaker 6:  Is, it is something. I'll give

969
00:58:50,585 --> 00:58:54,105
Speaker 5:  You that. So I, I just think that that one for Google, how they talk about

970
00:58:54,105 --> 00:58:57,945
Speaker 5:  the Pixel, how they talk about the pixel in relation to Google's AI

971
00:58:57,945 --> 00:59:01,625
Speaker 5:  capabilities. Yep. How much of those AI capabilities come to Android

972
00:59:01,725 --> 00:59:05,665
Speaker 5:  versus just the Pixel. There is some kind of shakeup going

973
00:59:05,665 --> 00:59:08,385
Speaker 5:  on over there and I, I'm kind of cur, I'm kind of curious how they handle

974
00:59:08,385 --> 00:59:11,345
Speaker 5:  it. Especially if they can ship this stuff before Apple.

975
00:59:11,885 --> 00:59:15,145
Speaker 6:  Yes. Yeah. If they do this and they're like, oh, shipping in October, that's

976
00:59:15,185 --> 00:59:18,905
Speaker 6:  a unbelievable width. Yes. But if they can do it and I think especially,

977
00:59:19,135 --> 00:59:19,425
Speaker 6:  well

978
00:59:19,425 --> 00:59:21,550
Speaker 5:  No, 'cause Apple's gonna announce new iPhones and it's not gonna have Apple

979
00:59:21,550 --> 00:59:25,125
Speaker 5:  Intelligence until like next year. So even if Google's like shipping in January,

980
00:59:26,275 --> 00:59:29,005
Speaker 5:  they're gonna get to market with an AI iPhone before Apple

981
00:59:29,805 --> 00:59:32,445
Speaker 6:  Probably. Yeah. But I don't know that anybody is sitting around waiting for

982
00:59:32,445 --> 00:59:35,365
Speaker 6:  an iPhone. Right. I think fair enough. Think we're, we're still at this point,

983
00:59:35,365 --> 00:59:38,325
Speaker 6:  and this is part of what I'm really excited about is I think there are two

984
00:59:38,445 --> 00:59:42,285
Speaker 6:  simultaneous things happening here where we're gonna see in rapid succession,

985
00:59:42,645 --> 00:59:46,205
Speaker 6:  I think Samsung and Google both try really hard to make the case for Foldables.

986
00:59:46,205 --> 00:59:50,085
Speaker 6:  Like it's very clear that Samsung is all in on that train. I think one

987
00:59:50,085 --> 00:59:54,045
Speaker 6:  of the things Google is probably going to do is push the new

988
00:59:54,255 --> 00:59:58,005
Speaker 6:  pixel fold or whatever it's gonna be called. I've heard rumors

989
00:59:58,125 --> 01:00:02,045
Speaker 6:  it's gonna be called the Pixel nine XL fold, which sucks of course. Perfect.

990
01:00:02,755 --> 01:00:06,005
Speaker 6:  Just call it the pixel fold too. Everybody, it'll be fine But anyway.

991
01:00:07,275 --> 01:00:11,165
Speaker 6:  They're gonna try to make this case for this like new kind of phone.

992
01:00:11,245 --> 01:00:14,805
Speaker 6:  I think especially as we get to ai, like You can start to see what you do

993
01:00:14,805 --> 01:00:17,485
Speaker 6:  with the extra screen, what you do with the extra power, all this different

994
01:00:17,485 --> 01:00:21,365
Speaker 6:  stuff. Again, in the hopes that Apple is just going to announce like a Sam

995
01:00:21,405 --> 01:00:24,885
Speaker 6:  e iPhone that does Sam e iPhone things and looks less interesting compared

996
01:00:24,885 --> 01:00:28,605
Speaker 6:  to the Android stuff. I don't know if it'll work, but I think that is the

997
01:00:28,605 --> 01:00:31,325
Speaker 6:  gambit and I think it's gonna be really interesting. But then at the same

998
01:00:31,325 --> 01:00:35,245
Speaker 6:  time, everybody is trying to make yeah, these AI cases and

999
01:00:35,385 --> 01:00:39,165
Speaker 6:  no one has those yet. I don't think like you and even throw Motorola

1000
01:00:39,165 --> 01:00:41,325
Speaker 6:  into that, right? There's this question about like what is the form factor

1001
01:00:41,325 --> 01:00:45,045
Speaker 6:  and it's gonna be like the summer of Foldables and Flippable and whatever

1002
01:00:45,045 --> 01:00:48,685
Speaker 6:  else. And then at the end of it we'll have Apple and

1003
01:00:49,815 --> 01:00:53,705
Speaker 6:  whether anyone can do anything that is better than last year's iPhone

1004
01:00:54,835 --> 01:00:58,225
Speaker 6:  feels extremely up in the air still, which is kinda wild.

1005
01:00:58,355 --> 01:01:01,625
Speaker 5:  Let's talk about the Motorola phone for a second. The Razor Plus actually

1006
01:01:01,625 --> 01:01:05,185
Speaker 5:  looks great. It does because they put a four inch screen on the front.

1007
01:01:06,065 --> 01:01:08,505
Speaker 5:  It's huge. Which is the size of the original iPhone. Like they, it's bigger

1008
01:01:08,505 --> 01:01:11,385
Speaker 5:  than the original iPhone I think. Yeah. It's just a full phone. Yeah. You

1009
01:01:11,435 --> 01:01:11,785
Speaker 5:  front

1010
01:01:11,785 --> 01:01:14,305
Speaker 6:  Phone, you just have two phones now instead of one phone. It's to, the problem

1011
01:01:14,305 --> 01:01:14,465
Speaker 6:  is

1012
01:01:16,005 --> 01:01:19,225
Speaker 5:  And and they, they went with saturated colors. Like honestly, this is the

1013
01:01:19,225 --> 01:01:21,985
Speaker 5:  thing I like about this phone the most. The colors are hot. Yeah,

1014
01:01:22,015 --> 01:01:22,585
Speaker 6:  They really are.

1015
01:01:22,845 --> 01:01:26,225
Speaker 5:  But they refined this design, right? This is like the third one of these,

1016
01:01:26,745 --> 01:01:30,185
Speaker 5:  the fourth one of these. It's expensive, it's a thousand dollars.

1017
01:01:30,925 --> 01:01:34,425
Speaker 5:  But I'm looking at it and I'm like, you know what, if AI can actually do

1018
01:01:34,425 --> 01:01:38,265
Speaker 5:  any of the things people say can do, which I don't believe,

1019
01:01:38,405 --> 01:01:42,185
Speaker 5:  and I believe that it's mostly broken actually maybe this is the time to

1020
01:01:42,185 --> 01:01:45,625
Speaker 5:  get a smaller phone, right? If I just talk to the phone and have it do a

1021
01:01:45,625 --> 01:01:48,305
Speaker 5:  bunch of stuff for me, like I don't need all this screen. I, I'm not looking

1022
01:01:48,305 --> 01:01:51,105
Speaker 5:  for another laptop, which is basically where my phone is going right now.

1023
01:01:51,105 --> 01:01:53,385
Speaker 5:  Yeah. It's like very quickly becoming another laptop.

1024
01:01:53,705 --> 01:01:57,345
Speaker 6:  I got so much shit last year for writing that everybody should start making

1025
01:01:57,345 --> 01:02:01,025
Speaker 6:  flip phones and history will prove me. Right. I firmly

1026
01:02:01,025 --> 01:02:02,025
Speaker 6:  believe it. Motorola

1027
01:02:02,025 --> 01:02:04,585
Speaker 5:  Doesn't have any of the AI features and they swap and the plus they swapped

1028
01:02:04,585 --> 01:02:08,105
Speaker 5:  out the ultra wide for a telephoto, which is just the wrong approach. Like

1029
01:02:08,305 --> 01:02:12,225
Speaker 5:  everyone loves these ultra wides and whatever, but I, these phones

1030
01:02:12,245 --> 01:02:15,705
Speaker 5:  are great. And then on top of it, you know, Apple's supporting RCS now,

1031
01:02:16,405 --> 01:02:20,165
Speaker 5:  so the iMessage stickiness, like, I'm like, ah, maybe I could just like try

1032
01:02:20,165 --> 01:02:22,765
Speaker 5:  one of these for a while and like not everyone will be mad at me once everyone

1033
01:02:22,765 --> 01:02:26,325
Speaker 5:  upgrades. Like there's something there that is super

1034
01:02:26,645 --> 01:02:29,645
Speaker 5:  interesting. But it's not because the ai, it's because of the form factor

1035
01:02:29,645 --> 01:02:32,845
Speaker 5:  and honestly the colors like I just like things that look different. The

1036
01:02:32,845 --> 01:02:35,725
Speaker 6:  Orange razor is, is sick, I'm very into it.

1037
01:02:36,185 --> 01:02:39,365
Speaker 5:  But then you look at Samsung, Samsung is basically just like moving down

1038
01:02:39,365 --> 01:02:42,805
Speaker 5:  the line, right? It's like we're gonna get a new Z flip and a new Z fold

1039
01:02:42,865 --> 01:02:46,805
Speaker 5:  and like big spiel be marginally smarter, but

1040
01:02:46,865 --> 01:02:50,165
Speaker 5:  who cares? Yeah. And they've gotta deal to use some Google stuff, but not

1041
01:02:50,165 --> 01:02:53,925
Speaker 5:  all of it. And like lots and lots and lots of questions about how Samsung

1042
01:02:54,095 --> 01:02:57,285
Speaker 5:  pulls this off in a way that's differentiated from Google.

1043
01:02:58,115 --> 01:03:01,365
Speaker 6:  Yeah. To me the big question for Samsung is if it can, if it can make the

1044
01:03:01,365 --> 01:03:03,805
Speaker 6:  ring a desirable thing.

1045
01:03:03,805 --> 01:03:05,085
Speaker 5:  Right? We're we're expecting the Galaxy ring

1046
01:03:05,085 --> 01:03:07,925
Speaker 6:  In the next year. Yeah. Like and, and we've been hearing sort of bits and

1047
01:03:07,925 --> 01:03:10,605
Speaker 6:  pieces about it for a while. It seems to look good. We got to try a prototype

1048
01:03:10,605 --> 01:03:14,245
Speaker 6:  a while back. Like I have reasonably high expectations for this thing

1049
01:03:14,705 --> 01:03:18,325
Speaker 6:  and if it's great or even pretty good,

1050
01:03:18,905 --> 01:03:22,565
Speaker 6:  that's a pretty solid ecosystem play for

1051
01:03:22,565 --> 01:03:26,365
Speaker 6:  Samsung to make that at least I think might convince some

1052
01:03:26,365 --> 01:03:30,005
Speaker 6:  people who have Galaxy phones to keep their Galaxy funds. Which is something.

1053
01:03:31,305 --> 01:03:35,285
Speaker 6:  But I, I do agree. I think there's this bet coming

1054
01:03:35,285 --> 01:03:39,125
Speaker 6:  from all of these companies that AI is going to sort of throw the

1055
01:03:39,325 --> 01:03:43,285
Speaker 6:  industry up in the air again and everybody has a chance to win it. And to

1056
01:03:43,285 --> 01:03:46,485
Speaker 6:  me, I actually think it that that may be true, but I think this like

1057
01:03:46,715 --> 01:03:50,605
Speaker 6:  flippable foldable different form factor change your relationship

1058
01:03:50,605 --> 01:03:54,485
Speaker 6:  with your gadget thing might end up being more important. Yes. And AI is

1059
01:03:54,485 --> 01:03:57,485
Speaker 6:  part of that, right? Like better Siri makes it so that you have to look at

1060
01:03:57,485 --> 01:03:59,805
Speaker 6:  your phone less, which makes it so that you use your phone differently.

1061
01:03:59,945 --> 01:04:02,845
Speaker 5:  If AI makes it so that we have smaller phones, that will be good.

1062
01:04:03,275 --> 01:04:03,565
Speaker 6:  Yeah,

1063
01:04:03,825 --> 01:04:06,725
Speaker 5:  Agreed. I, I would take that. By the way, Liam is reminding me that the iPhone

1064
01:04:06,745 --> 01:04:10,645
Speaker 5:  one was 3.5 inches. It's the iPhone five that had a four inch screen.

1065
01:04:11,145 --> 01:04:13,925
Speaker 5:  So they straight up put an iPhone five size screen on the front of the

1066
01:04:13,925 --> 01:04:14,045
Speaker 6:  Razor.

1067
01:04:14,045 --> 01:04:16,925
Speaker 5:  It's fantastic. It's incredible. But if we can get to a place where the phone

1068
01:04:16,925 --> 01:04:20,725
Speaker 5:  is more useful because of ai, so now I can carry a

1069
01:04:20,725 --> 01:04:23,965
Speaker 5:  smaller, less distracting phone, that would be good. I don't think any of

1070
01:04:23,965 --> 01:04:26,605
Speaker 5:  these companies have put those ideas together yet. No,

1071
01:04:27,465 --> 01:04:29,885
Speaker 6:  But they're all going to come out. What's gonna happen is they're all gonna

1072
01:04:29,885 --> 01:04:33,045
Speaker 6:  talk about the camera. This is gonna be the summer of AI features in your

1073
01:04:33,045 --> 01:04:36,725
Speaker 6:  camera and they're all going to be the same features on the same kinds of

1074
01:04:36,725 --> 01:04:40,565
Speaker 6:  devices across every single surface You can possibly think of.

1075
01:04:40,745 --> 01:04:42,045
Speaker 6:  And I'm already sort of bored of

1076
01:04:42,045 --> 01:04:46,005
Speaker 5:  It. Yeah. Here's what I can tell you. I was out with some teens, you

1077
01:04:46,005 --> 01:04:49,845
Speaker 5:  know, like family graduation party. They all had little crappy a hundred

1078
01:04:49,845 --> 01:04:53,685
Speaker 5:  dollar point and shoots. And then I'm out with the parents running

1079
01:04:53,685 --> 01:04:56,965
Speaker 5:  around around Max's kindergarten graduation and they're all asking me about

1080
01:04:56,965 --> 01:05:00,205
Speaker 5:  my Arc X 100. Mm. Because everyone kind of thinks iPhone photos look like

1081
01:05:00,205 --> 01:05:00,405
Speaker 5:  crap.

1082
01:05:02,145 --> 01:05:05,845
Speaker 5:  Do I, as AI kind of creeps in and everything that's brighter and weirder,

1083
01:05:06,275 --> 01:05:09,925
Speaker 5:  it's, it's weird to see where people are going instead. And I,

1084
01:05:10,405 --> 01:05:14,125
Speaker 5:  I suspect as soon as Samsung Samsung's like more saturation,

1085
01:05:14,675 --> 01:05:18,125
Speaker 5:  like I don't, I think it's gonna be weird. I, I think the AI photo trend

1086
01:05:18,145 --> 01:05:21,565
Speaker 5:  is going to, I think people have enough more taste than these companies are

1087
01:05:21,685 --> 01:05:24,405
Speaker 5:  assuming. I think that's right. All right, let's run through just some other

1088
01:05:24,465 --> 01:05:27,285
Speaker 5:  gadget stuff. We should talk about Rabbit really quickly.

1089
01:05:28,245 --> 01:05:30,005
Speaker 5:  This company is a disaster. What's going on with Rabbit?

1090
01:05:30,885 --> 01:05:34,565
Speaker 6:  I just do. We have to. So I, again,

1091
01:05:35,145 --> 01:05:38,365
Speaker 6:  I'm just this, this podcast is just me doing a victory lap. I said a while

1092
01:05:38,365 --> 01:05:41,965
Speaker 6:  back that I think that like if, if you made me

1093
01:05:42,645 --> 01:05:46,485
Speaker 6:  forecast whether Humane or Rabbit was closer to being kind of on a right

1094
01:05:46,485 --> 01:05:50,405
Speaker 6:  path to do good things, I would say Humane. I was right. Rabbit

1095
01:05:50,435 --> 01:05:53,565
Speaker 6:  just continues to be a, a massive disaster. Basically what happened here

1096
01:05:54,025 --> 01:05:58,005
Speaker 6:  is a group of developers and security researchers, I think they called

1097
01:05:58,005 --> 01:06:01,925
Speaker 6:  themselves Rabbit two, which is very good. Yeah. Found

1098
01:06:02,555 --> 01:06:06,045
Speaker 6:  Hardcoded API Keys that basically long story short

1099
01:06:06,355 --> 01:06:10,165
Speaker 6:  like governed rabbits access to, I think it was 11

1100
01:06:10,165 --> 01:06:14,005
Speaker 6:  labs who did all their text to speech stuff. And by

1101
01:06:14,025 --> 01:06:17,205
Speaker 6:  having those API keys, those API keys are supposed to rotate all the time

1102
01:06:17,225 --> 01:06:20,085
Speaker 6:  so that someone else can't get them and use them to get access to that same

1103
01:06:20,085 --> 01:06:23,765
Speaker 6:  data. Rabbit wasn't doing that and so the researchers were able to just use

1104
01:06:23,765 --> 01:06:27,725
Speaker 6:  that API key to get into and apparently see every response ever

1105
01:06:27,725 --> 01:06:29,925
Speaker 6:  given by a rabbit device,

1106
01:06:31,495 --> 01:06:35,325
Speaker 6:  which is absurd and, and has had the attitude

1107
01:06:35,565 --> 01:06:38,965
Speaker 6:  apparently said they've had access to these keys for, I think it was more

1108
01:06:38,965 --> 01:06:42,925
Speaker 6:  than a month. And Rabbit hadn't done anything, hadn't changed the

1109
01:06:42,925 --> 01:06:46,365
Speaker 6:  keys to make them outdated. Just it, it's basically like handing somebody

1110
01:06:46,365 --> 01:06:50,125
Speaker 6:  your password and saying, here go, go

1111
01:06:50,125 --> 01:06:52,565
Speaker 6:  nuts, do whatever you want. And it's like, well are you gonna change your

1112
01:06:52,725 --> 01:06:55,165
Speaker 6:  password? And you're like, nah, I'm cool.

1113
01:06:58,395 --> 01:07:02,165
Speaker 5:  That company is ever since your

1114
01:07:02,185 --> 01:07:05,915
Speaker 5:  review and then sort of response, it's like you're just

1115
01:07:05,915 --> 01:07:09,235
Speaker 5:  waiting, you're just waiting for the next shoe to drop that. Like there never

1116
01:07:09,235 --> 01:07:13,115
Speaker 5:  was a lang large action model and there never will be. Like it's still

1117
01:07:13,115 --> 01:07:16,995
Speaker 5:  too hard to make. Yes. On the humane side at least, you know, they're

1118
01:07:16,995 --> 01:07:18,675
Speaker 5:  trying to like sell it to h hp.

1119
01:07:18,675 --> 01:07:20,675
Speaker 6:  Well and they've like, they've shipped a bunch of updates. It has gotten

1120
01:07:20,805 --> 01:07:23,915
Speaker 6:  noticeably better. It's still not good and you still shouldn't buy it, but

1121
01:07:23,915 --> 01:07:27,355
Speaker 6:  it is, it is a better product than it was. But I think the, the rabbit thing

1122
01:07:27,355 --> 01:07:30,195
Speaker 6:  has been so interesting to me these last few months because there is like

1123
01:07:30,195 --> 01:07:33,795
Speaker 6:  this running is rabbit a scam thing happening

1124
01:07:34,175 --> 01:07:37,555
Speaker 6:  and I think it, it all amounts to basically like

1125
01:07:37,985 --> 01:07:40,395
Speaker 6:  they did nfts.dot do

1126
01:07:41,745 --> 01:07:44,915
Speaker 6:  feel about that however you want. And really I think,

1127
01:07:45,625 --> 01:07:48,955
Speaker 6:  what is the, the old saying like never ascribed to malice, what can be described

1128
01:07:48,955 --> 01:07:52,595
Speaker 6:  by incompetence. This is just gross incompetence all the way down. Yeah.

1129
01:07:53,135 --> 01:07:56,835
Speaker 6:  And it's like, it's just, it's just brutal to watch.

1130
01:07:57,015 --> 01:07:59,795
Speaker 6:  And I like, I wanted this thing to be cool, I wanted this company to work.

1131
01:07:59,875 --> 01:08:03,635
Speaker 6:  I was pro the idea of this goofy little orange Handel

1132
01:08:03,635 --> 01:08:07,075
Speaker 6:  gadget and this thing just sucks. Yeah. Like I, mine is in a drawer and I

1133
01:08:07,075 --> 01:08:08,435
Speaker 6:  don't intend on ever touching it again.

1134
01:08:08,435 --> 01:08:10,675
Speaker 5:  That's basically how everyone I know who bought a rabbit feels about it.

1135
01:08:10,675 --> 01:08:14,315
Speaker 5:  Yeah. Like the that cool rabbit animation was worth $300.

1136
01:08:14,425 --> 01:08:14,715
Speaker 5:  Yeah.

1137
01:08:14,735 --> 01:08:18,205
Speaker 6:  I'm betting that in 10 years it'll be like a fun story to have on the table

1138
01:08:18,205 --> 01:08:21,965
Speaker 6:  behind me while we vergecast. But until then I let its battery

1139
01:08:22,065 --> 01:08:23,485
Speaker 6:  die And that is the correct

1140
01:08:23,905 --> 01:08:27,565
Speaker 5:  Way for it to be. You're like I finally a teenage engineering product that

1141
01:08:27,565 --> 01:08:30,325
Speaker 5:  costs less than $4,000. I bought it my habit.

1142
01:08:30,595 --> 01:08:31,085
Speaker 6:  Exactly.

1143
01:08:31,085 --> 01:08:31,765
Speaker 5:  And we're good.

1144
01:08:33,645 --> 01:08:37,485
Speaker 5:  I wanna call this one out. Sean Ster got to sit in the

1145
01:08:37,595 --> 01:08:41,245
Speaker 5:  Sony Aila car, what they made with Honda and then he played

1146
01:08:41,575 --> 01:08:44,805
Speaker 5:  Grand Smo on the screens inside as the car,

1147
01:08:45,655 --> 01:08:47,885
Speaker 5:  which is per like perfect in its way. Which

1148
01:08:47,885 --> 01:08:50,645
Speaker 6:  Still seems to be the realist version of this car that exists. Right, right.

1149
01:08:50,645 --> 01:08:51,045
Speaker 6:  He is

1150
01:08:51,045 --> 01:08:52,885
Speaker 5:  The one in, right. He's the stuff I learned about the car and he is like,

1151
01:08:52,885 --> 01:08:55,925
Speaker 5:  the car isn't real, like it's mostly a fake car

1152
01:08:57,865 --> 01:09:01,205
Speaker 5:  and there there's no guarantee that it will actually have a PS five in it.

1153
01:09:01,905 --> 01:09:04,805
Speaker 5:  But Sony's trying to make a car and I, God, God bless them. Yeah. I hope

1154
01:09:04,825 --> 01:09:08,605
Speaker 5:  it has ULT power sound in it. Speaking of ULT power

1155
01:09:08,605 --> 01:09:12,005
Speaker 5:  sound, I, I am I think legally now required to call out party speakers.

1156
01:09:12,505 --> 01:09:15,445
Speaker 5:  So ultimately E has announced a whole new lineup including

1157
01:09:16,885 --> 01:09:20,765
Speaker 5:  a new mega Boom and a Wonder Boom. Yep. And they now have a feature called

1158
01:09:20,765 --> 01:09:23,805
Speaker 5:  Megaphone where You can just hold up your phone, talk in your phone and broadcast

1159
01:09:23,805 --> 01:09:27,725
Speaker 5:  sound to people, which is incredible. I also on the party speaker update,

1160
01:09:28,285 --> 01:09:32,045
Speaker 5:  ludicrous was supposed to play a show in Milwaukee recently and

1161
01:09:32,285 --> 01:09:35,805
Speaker 5:  he got called off because of the heat. So he just paired two JBL party

1162
01:09:35,805 --> 01:09:39,565
Speaker 5:  speakers, wore them with shoulder straps and did a free concert

1163
01:09:39,625 --> 01:09:40,045
Speaker 5:  in a mall.

1164
01:09:40,305 --> 01:09:40,885
Speaker 6:  No way

1165
01:09:41,065 --> 01:09:44,515
Speaker 5:  Was singing into a microphone. I've yet to confirm whether he used a proprietary

1166
01:09:44,835 --> 01:09:48,515
Speaker 5:  protocol to pair the speakers or one of the new open protocols like

1167
01:09:48,545 --> 01:09:52,355
Speaker 5:  Aura Cast, which is very cool. But just know there's

1168
01:09:52,355 --> 01:09:56,155
Speaker 5:  video of ludicrous wearing a party speaker

1169
01:09:56,425 --> 01:09:58,035
Speaker 5:  with a shoulder strap. That's amazing.

1170
01:09:58,345 --> 01:09:59,195
Speaker 6:  They do it for the people

1171
01:09:59,635 --> 01:10:00,995
Speaker 5:  Ing in the mall, which is great.

1172
01:10:02,955 --> 01:10:05,475
Speaker 5:  I propose that we write about it to our team and they're like, Neil, you

1173
01:10:05,495 --> 01:10:06,115
Speaker 5:  You can.

1174
01:10:08,015 --> 01:10:09,035
Speaker 5:  That's more or less the

1175
01:10:09,195 --> 01:10:10,635
Speaker 6:  Response. So that's what we're here for. I love this.

1176
01:10:11,455 --> 01:10:14,315
Speaker 5:  And then real quickly David, people can go listen to it, but you spent some

1177
01:10:14,315 --> 01:10:17,595
Speaker 5:  time on Tuesday talking about service laptops, windows and arm. What's the

1178
01:10:17,595 --> 01:10:17,755
Speaker 5:  vibe?

1179
01:10:18,465 --> 01:10:22,355
Speaker 6:  They seem to be very good there. There's like a surprising amount

1180
01:10:22,355 --> 01:10:25,715
Speaker 6:  of positivity and enthusiasm that

1181
01:10:26,395 --> 01:10:30,235
Speaker 6:  Microsoft actually like pulled this thing off. Tom published his review of

1182
01:10:30,295 --> 01:10:34,235
Speaker 6:  the Surface laptop when we talked on Tuesday. He was like mid draft of the

1183
01:10:34,235 --> 01:10:37,915
Speaker 6:  review, published it. He called it Microsoft's best MacBook Air competitor

1184
01:10:38,135 --> 01:10:41,435
Speaker 6:  yet, which I suspect if you're a Microsoft and knowing everything that we

1185
01:10:41,435 --> 01:10:44,875
Speaker 6:  know about how they have talked about these things is exactly what you would

1186
01:10:44,875 --> 01:10:48,155
Speaker 6:  hope for. Yeah. It still seems like Microsoft like

1187
01:10:48,895 --> 01:10:52,315
Speaker 6:  almost finished the job. There's still some like wonky

1188
01:10:52,515 --> 01:10:56,275
Speaker 6:  emulation stuff. If you run an emulated app, it seems like it just

1189
01:10:56,435 --> 01:10:59,075
Speaker 6:  decimate your battery. Like if anything Thomas talking this on Tuesday. But

1190
01:10:59,075 --> 01:11:02,875
Speaker 6:  if anything like understated the extent to which running

1191
01:11:02,895 --> 01:11:06,875
Speaker 6:  an app that is not prepared for emulation will just set your computer on

1192
01:11:06,875 --> 01:11:10,235
Speaker 6:  fire and kill your battery. But like he got good battery life,

1193
01:11:10,975 --> 01:11:14,925
Speaker 6:  one of his pros in the review says 16 gigs of Ram for the base

1194
01:11:14,925 --> 01:11:18,765
Speaker 6:  model, which I take as a personal attack, but we'll leave that aside.

1195
01:11:19,625 --> 01:11:23,525
Speaker 6:  But it seems like it, it seems like this new line of laptops is gonna

1196
01:11:23,525 --> 01:11:26,045
Speaker 6:  be really good. Microsoft stuff is coming out, Dell's stuff is coming out.

1197
01:11:26,165 --> 01:11:29,885
Speaker 6:  A seus reviews are coming out. Like the, the general vibe around this

1198
01:11:29,885 --> 01:11:32,165
Speaker 6:  generation of PCs seems to be pretty good.

1199
01:11:32,595 --> 01:11:36,485
Speaker 5:  Yeah, I think that the how good Prism the emulator,

1200
01:11:37,145 --> 01:11:40,645
Speaker 5:  how good Prism is over time is gonna be the thing. Yeah. In a way that Rosetta

1201
01:11:40,645 --> 01:11:44,485
Speaker 5:  is an not the thing on the Mac. Rosetta is the emulator that lets old

1202
01:11:45,075 --> 01:11:48,485
Speaker 5:  like Intel apps run on the new arm ships on a Mac

1203
01:11:49,185 --> 01:11:52,125
Speaker 5:  and like Rosetta was like so good no one even thought about it. And now it's

1204
01:11:52,125 --> 01:11:55,965
Speaker 5:  not even pre-installed on these machines, right? Like if you open an X 86

1205
01:11:55,985 --> 01:11:59,925
Speaker 5:  app on a Mac, it asks you if you wanna download Rosetta. Whereas I

1206
01:11:59,925 --> 01:12:03,765
Speaker 5:  think Prism on the Windows side, you're in it like you have a

1207
01:12:03,765 --> 01:12:06,205
Speaker 6:  Relationship. Yeah. It's gonna prim more important for much longer and it

1208
01:12:06,205 --> 01:12:09,125
Speaker 5:  Doesn't seem to be as good. So I think that's, that's the thing I'm keeping

1209
01:12:09,145 --> 01:12:09,365
Speaker 5:  on.

1210
01:12:09,555 --> 01:12:13,045
Speaker 6:  It's also just a much harder task, right? Like there's a, there are like

1211
01:12:13,395 --> 01:12:16,805
Speaker 6:  centuries of Windows apps that you have to figure out how to run in a way

1212
01:12:16,805 --> 01:12:18,485
Speaker 6:  that on a Mac, the Mac doesn't bill

1213
01:12:18,485 --> 01:12:22,445
Speaker 5:  Quite same has a stone tablet with a win 32 app app on it. It's true

1214
01:12:22,505 --> 01:12:26,125
Speaker 5:  but it's also if you wanna compete, that's the game, right? Yeah.

1215
01:12:27,065 --> 01:12:30,085
Speaker 5:  So we'll see. All right, we gotta take a break we'll back with the

1216
01:15:29,385 --> 01:15:32,995
Speaker 5:  All right, we're back with lightning round. David has two,

1217
01:15:33,715 --> 01:15:36,715
Speaker 5:  I have three, but one of them is a joke. You have three. Oh my god I picked

1218
01:15:36,715 --> 01:15:39,115
Speaker 5:  three first. Oh that I know what your joke is. Wait, can I guess what your

1219
01:15:39,115 --> 01:15:40,995
Speaker 5:  joke is? Can we do it first? What is it? Do you wanna talk about the new

1220
01:15:40,995 --> 01:15:44,635
Speaker 5:  Verizon logo? I wanna talk about the new Verizon logo so much. If you haven't

1221
01:15:44,835 --> 01:15:48,275
Speaker 5:  seen a Verizon redesign its logo, it's the same text that the

1222
01:15:48,745 --> 01:15:52,395
Speaker 5:  Tica Verizon or whatever it is, they got rid of the check mark. But now the

1223
01:15:52,395 --> 01:15:56,075
Speaker 5:  text is red on a black background and then the V

1224
01:15:56,175 --> 01:15:59,995
Speaker 5:  has like a fire gradient in it. It is nuts.

1225
01:16:00,345 --> 01:16:03,395
Speaker 5:  Like nuts like all the way around. Like

1226
01:16:05,015 --> 01:16:07,795
Speaker 5:  it just, have you ever seen putting a gradient in a logo is such a strong

1227
01:16:07,795 --> 01:16:11,115
Speaker 5:  move because it will never get reproduced correctly. Like every time we do

1228
01:16:11,115 --> 01:16:14,275
Speaker 5:  a logo I'm like let's do gradients. And everyone's like, no. Like no. And

1229
01:16:14,275 --> 01:16:18,195
Speaker 5:  Verizon's like, screw it. We're doing gradients but then

1230
01:16:18,205 --> 01:16:22,195
Speaker 5:  doing red on black I actually think is a great move

1231
01:16:22,225 --> 01:16:26,075
Speaker 5:  because every carrier should be like, here's what we are. We are the

1232
01:16:26,075 --> 01:16:29,635
Speaker 5:  demon spawn reconstruction of at t that the United States government tried

1233
01:16:29,635 --> 01:16:33,395
Speaker 5:  to kill and was not able to kill, which is what Verizon is. And I think

1234
01:16:33,395 --> 01:16:37,035
Speaker 5:  leaning into the fact that it it's from hell is

1235
01:16:37,305 --> 01:16:40,995
Speaker 5:  like good. Like let's just be who you are. Now that you point that out, it

1236
01:16:40,995 --> 01:16:44,275
Speaker 5:  even like you could argue it is kind of like the glow from hell coming outta

1237
01:16:44,275 --> 01:16:46,835
Speaker 5:  the bottom of the V. That's what I'm saying like that really it's, it's the

1238
01:16:46,835 --> 01:16:50,435
Speaker 5:  most goth telecom logo I've ever seen in my entire life.

1239
01:16:50,655 --> 01:16:53,075
Speaker 5:  and it's like here's what happened. The United States government tried to

1240
01:16:53,075 --> 01:16:56,155
Speaker 5:  kill at and t and instead we got two zombie at ts

1241
01:16:57,775 --> 01:17:01,635
Speaker 5:  and like just be from hell. Like that's good. Like

1242
01:17:01,675 --> 01:17:05,635
Speaker 5:  a I'm at and t, I'm looking for your Satanic logo redesign any minute now

1243
01:17:06,855 --> 01:17:10,405
Speaker 5:  by the way, this is true. Verizon is one half of the old baby bells and at

1244
01:17:10,405 --> 01:17:12,285
Speaker 5:  and t is the other half of the old baby bells.

1245
01:17:14,035 --> 01:17:17,775
Speaker 5:  And you just know they wanna merge. Like you just know that their

1246
01:17:17,925 --> 01:17:20,815
Speaker 5:  CEOs wake up every morning and they probably look out across the golf course

1247
01:17:20,815 --> 01:17:24,695
Speaker 5:  at each other and they're like, one day buddy at

1248
01:17:24,695 --> 01:17:28,575
Speaker 5:  and t's coming back. This look sucks too to my X and

1249
01:17:28,655 --> 01:17:28,855
Speaker 5:  Ferris

1250
01:17:29,445 --> 01:17:32,655
Speaker 6:  Once again. I would like to offer my services as the person who will walk

1251
01:17:32,655 --> 01:17:35,295
Speaker 6:  into your boardroom say That's the dumbest idea I've ever heard in my life

1252
01:17:35,395 --> 01:17:39,335
Speaker 6:  and leave for $50,000. And I would've done that for this because they took

1253
01:17:39,885 --> 01:17:43,255
Speaker 6:  like this. This just reminds me of the gap when they're like, oh we have

1254
01:17:43,255 --> 01:17:45,655
Speaker 6:  this great logo that everybody really likes and doesn't feel dated at all.

1255
01:17:45,805 --> 01:17:49,615
Speaker 6:  What if we changed it to something so stupid? That'd be so fun. Right?

1256
01:17:49,715 --> 01:17:50,335
Speaker 6:  And then we did

1257
01:17:50,335 --> 01:17:52,615
Speaker 5:  It. Wait, no one feels anything about the Verizon logo. That's true. If you

1258
01:17:52,615 --> 01:17:56,535
Speaker 5:  have an emotional attachment to any version of Verizon logo over time, let

1259
01:17:56,535 --> 01:18:00,055
Speaker 5:  me know. I'm just saying I'm super down with Verizon being like,

1260
01:18:00,245 --> 01:18:02,655
Speaker 5:  this one reminds you of literal hell. The

1261
01:18:02,855 --> 01:18:06,695
Speaker 6:  V just makes me think of like, I don't know why this is where my brain goes,

1262
01:18:06,795 --> 01:18:10,455
Speaker 6:  but like you know how Logan Paul has that sports drink that I can never remember.

1263
01:18:10,455 --> 01:18:13,455
Speaker 6:  Like I think it's Prime or something like that. Prime. This is like if a,

1264
01:18:13,675 --> 01:18:17,335
Speaker 6:  if a YouTuber with like a 10th as many subscribers as Logan Paul

1265
01:18:17,435 --> 01:18:21,295
Speaker 6:  wanted to make a sports drink, this is what the V would

1266
01:18:21,295 --> 01:18:24,575
Speaker 6:  look like to me. Yes. That's all I get is like knock knockoff sports drink.

1267
01:18:24,885 --> 01:18:25,855
Speaker 5:  That was mine. What's yours?

1268
01:18:26,155 --> 01:18:29,815
Speaker 6:  My first one is some Fedi verse news because

1269
01:18:30,235 --> 01:18:34,095
Speaker 6:  we are obligated to talk about it. Yes. Some new stuff on threads where now

1270
01:18:34,515 --> 01:18:38,495
Speaker 6:  if you have federated your account and you post on threads,

1271
01:18:38,835 --> 01:18:42,055
Speaker 6:  not only can people on other activity pub

1272
01:18:42,575 --> 01:18:46,095
Speaker 6:  platforms see your post, they can actually like and reply and you will see

1273
01:18:46,095 --> 01:18:48,655
Speaker 6:  the likes and replies. Like the way it's worked in threads has been kind

1274
01:18:48,655 --> 01:18:52,135
Speaker 6:  of weird before. Yeah. And now there's at least sort of one step of two way

1275
01:18:52,185 --> 01:18:55,495
Speaker 6:  stuff. If you reply to their reply it gets wacky. But

1276
01:18:55,945 --> 01:18:59,895
Speaker 6:  again, like any inkling that meta is

1277
01:18:59,895 --> 01:19:03,695
Speaker 6:  continuing to push into actually opening this stuff up, I find very

1278
01:19:03,895 --> 01:19:07,335
Speaker 6:  exciting and it seems to still be happening that Meta cares about this and

1279
01:19:07,335 --> 01:19:11,175
Speaker 6:  wants to federate and make all of this stuff interoperate. And

1280
01:19:11,575 --> 01:19:12,455
Speaker 6:  I just think that's very cool.

1281
01:19:12,765 --> 01:19:16,455
Speaker 5:  Whether Meta is a company Cares weird

1282
01:19:16,845 --> 01:19:19,815
Speaker 5:  like Meta has, which is weird ideas about all of its platforms right now.

1283
01:19:19,815 --> 01:19:23,615
Speaker 5:  Yes. They had a half the controversy scandal this

1284
01:19:23,615 --> 01:19:27,375
Speaker 5:  week where they just keep limiting the political content.

1285
01:19:27,525 --> 01:19:31,455
Speaker 5:  Even if you ask it to show you politics content, it just reverts every

1286
01:19:31,455 --> 01:19:34,895
Speaker 6:  Time you close the app, it turns the setting off to show you political content.

1287
01:19:35,485 --> 01:19:39,015
Speaker 5:  It's like, yeah we know you guys don't want news. It's like, it's weird how

1288
01:19:39,035 --> 01:19:41,495
Speaker 5:  all of your bugs are in support of you not wanting to show news. Yeah. Right.

1289
01:19:42,155 --> 01:19:45,615
Speaker 5:  The thing that you keep denying so I don't meta the company is weird. The

1290
01:19:45,615 --> 01:19:49,495
Speaker 5:  people who are working on this at Meta super sincere about it. Yeah.

1291
01:19:49,565 --> 01:19:52,015
Speaker 5:  Like they're communicating about it, they're posting along threads about

1292
01:19:52,015 --> 01:19:55,775
Speaker 5:  it. They've talked to us about it. So at least on that

1293
01:19:56,055 --> 01:19:58,975
Speaker 5:  front, the energy of that company is

1294
01:19:59,445 --> 01:20:03,295
Speaker 5:  sincerely pointed at can you make Metaverse work? Yeah. And I think

1295
01:20:03,295 --> 01:20:07,245
Speaker 5:  that Alone is bringing a bunch of other companies along. So like

1296
01:20:07,245 --> 01:20:11,045
Speaker 5:  Ghost the newsletter platform, very sincere about

1297
01:20:11,045 --> 01:20:14,245
Speaker 5:  making Federation work. The blog post that their product manager is writing

1298
01:20:14,245 --> 01:20:17,325
Speaker 5:  about figuring out how to do federation and activity pub, some of the funniest

1299
01:20:17,325 --> 01:20:19,285
Speaker 5:  technical blog posts you will ever read in your entire

1300
01:20:19,285 --> 01:20:20,005
Speaker 6:  Life. They, it's very good.

1301
01:20:20,705 --> 01:20:21,165
Speaker 5:  And this stuff

1302
01:20:21,265 --> 01:20:24,525
Speaker 6:  Is complicated. It's actually, if you wanna like understand what it takes

1303
01:20:24,525 --> 01:20:27,325
Speaker 6:  to make all this work, those blog posts are actually pretty good. Yeah. Because

1304
01:20:27,355 --> 01:20:28,605
Speaker 6:  this stuff is messy.

1305
01:20:29,295 --> 01:20:33,245
Speaker 5:  Super. I mean we wanna do it and yeah like, you know like sending stuff

1306
01:20:33,305 --> 01:20:37,165
Speaker 5:  out for media company is like in our DNA, like we have RSS,

1307
01:20:37,165 --> 01:20:40,245
Speaker 5:  we syndicate to Apple s like we, we have feeds of content going to all these

1308
01:20:40,245 --> 01:20:44,005
Speaker 5:  places like out is super great, right? All day long. What do media

1309
01:20:44,365 --> 01:20:46,125
Speaker 5:  companies love doing? Sending their shit out for free.

1310
01:20:46,455 --> 01:20:47,445
Speaker 6:  Right? Like

1311
01:20:47,555 --> 01:20:50,645
Speaker 5:  Work for free by all means. Like every media company is like let's do it.

1312
01:20:52,455 --> 01:20:56,445
Speaker 5:  Inbox is really hard. Right? The part where I post a quick post to

1313
01:20:56,445 --> 01:20:59,285
Speaker 5:  The Verge, it gets federated, you hit like on it and then it comes back to

1314
01:20:59,285 --> 01:21:03,045
Speaker 5:  us super hard. And then making

1315
01:21:03,045 --> 01:21:06,405
Speaker 5:  that two-way in turn. So you've replied to my post on some asset on server

1316
01:21:06,465 --> 01:21:09,245
Speaker 5:  and then I reply to you and that goes back out to you and then everyone else

1317
01:21:09,305 --> 01:21:12,885
Speaker 5:  can see it all. That's really complicated. And then if you're meta or any

1318
01:21:12,885 --> 01:21:15,725
Speaker 5:  of these other companies, you have to like be legally compliant in Europe

1319
01:21:15,745 --> 01:21:19,085
Speaker 5:  and da da da. So it's going slow 'cause it's complicated. But You can just

1320
01:21:19,085 --> 01:21:22,005
Speaker 5:  see there's movement and there's still a bunch of energy there.

1321
01:21:22,995 --> 01:21:26,685
Speaker 5:  It's not like it hasn't broken Twitter yet. You know, like

1322
01:21:26,885 --> 01:21:30,165
Speaker 5:  Right. All that stuff is happening. But I can see how complicated it is,

1323
01:21:30,165 --> 01:21:33,365
Speaker 5:  but I can see people are just consistently plugging away at it, which I think

1324
01:21:33,365 --> 01:21:33,605
Speaker 5:  is great.

1325
01:21:33,795 --> 01:21:37,285
Speaker 6:  Yeah. Yeah. I agree. The, the just the sheer existence of

1326
01:21:37,705 --> 01:21:41,205
Speaker 6:  new features on this front goes a long way. And You can see it like in the

1327
01:21:41,635 --> 01:21:45,125
Speaker 6:  fedi verse space. Every time meta announces anything, all of my like

1328
01:21:45,475 --> 01:21:47,805
Speaker 6:  Fedi verse bros on Mastodon are like, let's

1329
01:21:47,805 --> 01:21:49,205
Speaker 5:  Go. It's great I. love

1330
01:21:49,205 --> 01:21:50,965
Speaker 6:  It. What's your next one?

1331
01:21:52,345 --> 01:21:56,165
Speaker 5:  Big Supreme Court. Weak Scott has actually not released a bunch of

1332
01:21:56,265 --> 01:21:59,765
Speaker 5:  big decisions that we wanna cover. Some very complicated ones,

1333
01:22:01,225 --> 01:22:03,685
Speaker 5:  but they released one big one that I think is really important to talk about.

1334
01:22:03,685 --> 01:22:07,245
Speaker 5:  Just briefly, there was a group of basically Covid

1335
01:22:07,315 --> 01:22:11,205
Speaker 5:  deniers who sued the Biden administration for

1336
01:22:11,205 --> 01:22:14,245
Speaker 5:  like First Amendment violations. 'cause the Biden administration had been

1337
01:22:14,245 --> 01:22:18,125
Speaker 5:  talking to social media platforms about vaccine information

1338
01:22:18,125 --> 01:22:21,285
Speaker 5:  and misinformation and they basically said this is impermissible censorship.

1339
01:22:21,785 --> 01:22:24,925
Speaker 5:  and it got all the way to Supreme Court by way of the Fifth Circuit, which

1340
01:22:24,925 --> 01:22:28,525
Speaker 5:  is crazy. The Fifth Circuit basically wrote like a fever dream, like,

1341
01:22:30,345 --> 01:22:33,205
Speaker 5:  you know, if the Fever dreams of YouTube

1342
01:22:34,015 --> 01:22:37,925
Speaker 5:  swamp kind of written judicial opinion, like that was the fifth Circuit opinion.

1343
01:22:37,995 --> 01:22:41,405
Speaker 5:  Like the, I think they called it like the largest coordinated government

1344
01:22:41,405 --> 01:22:44,045
Speaker 5:  censorship campaign in history of course. and it got to the Supreme Court

1345
01:22:44,225 --> 01:22:45,885
Speaker 5:  or six three Supreme Court

1346
01:22:47,575 --> 01:22:50,185
Speaker 5:  full of extremely hard right conservatives. And they basically are like,

1347
01:22:50,215 --> 01:22:53,305
Speaker 5:  what are you talking about? That's the opinion written by Amy Coney Barrett.

1348
01:22:53,965 --> 01:22:57,825
Speaker 5:  And she says like flat out like one you don't have standing to sue here.

1349
01:22:58,485 --> 01:23:02,065
Speaker 5:  You cannot prove one set of actions by the government

1350
01:23:02,375 --> 01:23:06,325
Speaker 5:  that pulled your post stem. Like there's, there's nothing here in

1351
01:23:06,325 --> 01:23:09,365
Speaker 5:  this body of evidence that says the government censored you

1352
01:23:10,205 --> 01:23:14,105
Speaker 5:  so like you don't, you shouldn't even be here. And then she, she says this

1353
01:23:14,105 --> 01:23:16,345
Speaker 5:  other thing which I think is really important for this whole debate that

1354
01:23:16,545 --> 01:23:18,985
Speaker 5:  probably no one will pay attention to, but very important to this whole debate.

1355
01:23:19,195 --> 01:23:22,715
Speaker 5:  She's like, you have collapsed the

1356
01:23:22,885 --> 01:23:26,875
Speaker 5:  users of the platform, the platform and the government all into

1357
01:23:26,875 --> 01:23:30,355
Speaker 5:  one thing. Hmm. Like the plaintiffs, the defendants and you are like, and

1358
01:23:30,355 --> 01:23:34,155
Speaker 5:  the platforms in between. It's not just one thing. Like

1359
01:23:34,155 --> 01:23:37,195
Speaker 5:  there are some people who got hurt this way who claim that they got censored

1360
01:23:37,195 --> 01:23:40,995
Speaker 5:  this way by this agency talking to that platform. There are people who

1361
01:23:41,175 --> 01:23:44,795
Speaker 5:  say that a different part of the Biden administration talked to a different

1362
01:23:45,035 --> 01:23:48,435
Speaker 5:  platform or suited yet a third person about something else. And that's not

1363
01:23:48,435 --> 01:23:52,265
Speaker 5:  all the same thing. So like the idea that there's a mass

1364
01:23:52,265 --> 01:23:55,665
Speaker 5:  coordinated government censorship campaign directed at

1365
01:23:55,945 --> 01:23:59,825
Speaker 5:  platforms broadly that is directed at the, like, that doesn't make any sense.

1366
01:24:00,535 --> 01:24:04,425
Speaker 6:  Well that's, I mean that, that is sort of an animating argument of a corner

1367
01:24:04,485 --> 01:24:08,465
Speaker 6:  of the internet. Yeah. And it's, it's, it was nice to see that kind

1368
01:24:08,465 --> 01:24:09,385
Speaker 6:  of roundly

1369
01:24:09,785 --> 01:24:12,785
Speaker 5:  Refuted. Yeah. Basically she was like, this is nonsense. Yeah. And like our,

1370
01:24:12,855 --> 01:24:14,505
Speaker 5:  this Supreme Court telling that

1371
01:24:16,085 --> 01:24:19,715
Speaker 5:  swamp like this is nonsense is pretty notable to me.

1372
01:24:19,825 --> 01:24:22,395
Speaker 5:  Yeah. That's not to say, look, I think government's speech regulations are

1373
01:24:22,395 --> 01:24:24,835
Speaker 5:  bad. I think everybody knows how I feel about the First Amendment. That's

1374
01:24:24,835 --> 01:24:28,555
Speaker 5:  not to say there isn't overreach in weird jawboning, that's what it's called

1375
01:24:28,555 --> 01:24:31,555
Speaker 5:  when the government sort of like pressures a platform, they call it jawboning.

1376
01:24:31,955 --> 01:24:35,595
Speaker 5:  There's a lot of that going on. For example, conservative Republicans

1377
01:24:35,595 --> 01:24:38,995
Speaker 5:  basically just got the Stanford Internet observatory

1378
01:24:39,075 --> 01:24:42,875
Speaker 5:  defunded by putting a lot of pressure on Stanford. Is that cool?

1379
01:24:43,015 --> 01:24:46,475
Speaker 5:  Is that a thing you want? Is that a speech right there? There's like a lot

1380
01:24:46,475 --> 01:24:49,395
Speaker 5:  of that going on on both sides. I, I like

1381
01:24:50,275 --> 01:24:52,875
Speaker 5:  Democrats love a speech regulation actually the same way Republicans do.

1382
01:24:52,905 --> 01:24:56,555
Speaker 5:  Like all these kids safety bills are basically speech regulations.

1383
01:24:57,225 --> 01:25:01,115
Speaker 5:  Just, we think it's, we think it's important to protect kids so we

1384
01:25:01,115 --> 01:25:04,635
Speaker 5:  can like shove a speech regulation into, into American political history.

1385
01:25:05,245 --> 01:25:08,235
Speaker 5:  Weird. Weird all around. I'm not saying I support them, I'm just saying this

1386
01:25:08,235 --> 01:25:11,915
Speaker 5:  case was so stupid and our Supreme Court was like, it's pretty stupid and

1387
01:25:11,915 --> 01:25:14,995
Speaker 5:  kicked 'em out. All right. What's yours? What's your next one?

1388
01:25:15,495 --> 01:25:18,635
Speaker 6:  My next one is a small one

1389
01:25:19,365 --> 01:25:23,075
Speaker 6:  about the the chat GPT Mac app, which is now available to everybody.

1390
01:25:23,255 --> 01:25:25,795
Speaker 6:  And I think it's fascinating because

1391
01:25:27,475 --> 01:25:30,675
Speaker 6:  a couple of people have pointed out to me very recently that one of the strange

1392
01:25:30,675 --> 01:25:34,395
Speaker 6:  things about open AI is it's terrible at making product that it,

1393
01:25:34,575 --> 01:25:38,395
Speaker 6:  it has what a lot of people would argue is like best in class, extremely

1394
01:25:38,395 --> 01:25:41,635
Speaker 6:  good technology. And I can't stop talking to people whose whole pitch is,

1395
01:25:41,655 --> 01:25:45,395
Speaker 6:  we did it better than OpenAI. And I think

1396
01:25:45,895 --> 01:25:49,715
Speaker 6:  the Mac app is weirdly important for chat GPT because

1397
01:25:49,715 --> 01:25:52,995
Speaker 6:  they've been, OpenAI has been pretty like

1398
01:25:54,215 --> 01:25:57,595
Speaker 6:  loudly and clearly working on a search engine. I think they have a lot of

1399
01:25:57,595 --> 01:26:01,235
Speaker 6:  other ways they're trying to figure out how to productize this stuff other

1400
01:26:01,235 --> 01:26:05,085
Speaker 6:  than just like a weird ugly chatbot in your web browser

1401
01:26:06,345 --> 01:26:10,245
Speaker 6:  and this thing where it can, you know, talk to you

1402
01:26:10,415 --> 01:26:13,445
Speaker 6:  using supporting documents like You can take screenshots on your computer

1403
01:26:13,445 --> 01:26:16,645
Speaker 6:  and upload it and ask questions about it. That's very cool. It has access

1404
01:26:16,745 --> 01:26:20,445
Speaker 6:  to different things in your computer. This is like if you want to see what

1405
01:26:20,625 --> 01:26:24,445
Speaker 6:  OpenAI is actually trying to do and get you a normal person to be

1406
01:26:24,445 --> 01:26:28,245
Speaker 6:  interested in like the Mac app is a pretty big step

1407
01:26:28,305 --> 01:26:32,205
Speaker 6:  in that direction. And I just think it's really interesting also all

1408
01:26:32,205 --> 01:26:35,725
Speaker 6:  of its most interesting Scarlet Johansen voices still not there.

1409
01:26:35,995 --> 01:26:39,885
Speaker 5:  Yeah. I think we know why. I think Scarlet Johansen is like,

1410
01:26:40,165 --> 01:26:40,845
Speaker 5:  no, no, no, no, no.

1411
01:26:41,255 --> 01:26:42,845
Speaker 6:  She's like, I use Windows. Thank

1412
01:26:42,845 --> 01:26:46,685
Speaker 5:  You. I'm super, super gonna sue you very soon. Yeah. All right, last one.

1413
01:26:47,225 --> 01:26:49,805
Speaker 5:  And this is I think the most important thing we're gonna talk about this

1414
01:26:49,805 --> 01:26:53,765
Speaker 5:  week on the show. As you know, The Verge is America's foremost

1415
01:26:53,775 --> 01:26:55,925
Speaker 5:  cyber truck wiper news source. That's correct.

1416
01:26:57,475 --> 01:27:01,265
Speaker 5:  We've been very responsible in the show. I I, I think you also know we are

1417
01:27:01,295 --> 01:27:05,265
Speaker 5:  very precious, very serious journalists. We take our duty of care

1418
01:27:05,265 --> 01:27:06,345
Speaker 5:  very seriously. This is true.

1419
01:27:06,505 --> 01:27:10,305
Speaker 6:  I was there when you first got your hand on a cyber truck

1420
01:27:10,315 --> 01:27:14,065
Speaker 6:  wiper. Yeah. and it was, and you, you journalism a cyber truck wiper at South

1421
01:27:14,065 --> 01:27:15,185
Speaker 6:  by Southwest. It was a big deal.

1422
01:27:15,505 --> 01:27:18,785
Speaker 5:  I don't think the owner of that cyber truck enjoyed the practice of journalism.

1423
01:27:18,945 --> 01:27:19,345
Speaker 6:  I don't think so.

1424
01:27:19,705 --> 01:27:23,585
Speaker 5:  I committed some real acts of journalism with that wiper. So a few

1425
01:27:23,585 --> 01:27:27,225
Speaker 5:  weeks ago there was these reports that the Cybert truck wiper was faulty

1426
01:27:27,285 --> 01:27:31,025
Speaker 5:  and cybert truck's deliveries were being held back that there were potentially

1427
01:27:31,025 --> 01:27:34,825
Speaker 5:  a recall that it was flapping around that it wasn't very

1428
01:27:34,825 --> 01:27:36,305
Speaker 5:  effective. And we held back

1429
01:27:38,105 --> 01:27:41,785
Speaker 5:  hundreds of tips arrived out of various cyber truck

1430
01:27:41,845 --> 01:27:45,745
Speaker 5:  forums and social media posts and we couldn't confirm them. So we,

1431
01:27:45,745 --> 01:27:49,505
Speaker 5:  we, you know, we ran reportedly we, we were very calm. Others, other sites,

1432
01:27:49,545 --> 01:27:53,025
Speaker 5:  I won't name names, ran with it. Sensational, outrageous

1433
01:27:53,395 --> 01:27:54,465
Speaker 5:  click fadey journalism.

1434
01:27:56,055 --> 01:27:56,345
Speaker 5:  They

1435
01:27:56,345 --> 01:27:56,745
Speaker 6:  Were right wait

1436
01:27:56,745 --> 01:27:59,145
Speaker 5:  Click. They were right the whole time to be clear, they were right the whole

1437
01:27:59,145 --> 01:28:02,625
Speaker 5:  time. Now there's an official recall of cyber truck wiper,

1438
01:28:02,875 --> 01:28:06,065
Speaker 5:  which has motor problems, which just flopping and then the trim on the back

1439
01:28:06,125 --> 01:28:09,425
Speaker 5:  is flying off the cars. Which is great. That seems

1440
01:28:09,425 --> 01:28:09,625
Speaker 6:  Worse.

1441
01:28:10,735 --> 01:28:14,585
Speaker 5:  It's not good. There's a lot of cyber truck owners in the forums now who

1442
01:28:14,585 --> 01:28:17,945
Speaker 5:  are like, we just got had like, this is nonsense. Not great for your a hundred

1443
01:28:18,185 --> 01:28:21,425
Speaker 5:  thousand dollars triangle. It's the second big recall. The first one that

1444
01:28:21,425 --> 01:28:24,785
Speaker 5:  you recall. It's the second big recall. The first one, if you remember was

1445
01:28:24,785 --> 01:28:27,025
Speaker 5:  the accelerator pedal was getting stuck. Yep.

1446
01:28:27,555 --> 01:28:29,225
Speaker 6:  Which they fixed with like a rivet, right?

1447
01:28:29,735 --> 01:28:32,865
Speaker 5:  Yeah. And that's how I would fix it. Sure. I'd be like ah, just get some,

1448
01:28:32,895 --> 01:28:34,425
Speaker 5:  just not just rivet it in, just

1449
01:28:34,425 --> 01:28:35,785
Speaker 6:  Point your nail gun at it and see what happens.

1450
01:28:36,065 --> 01:28:39,265
Speaker 5:  Exactly. Yeah. The trim is gonna be fixed

1451
01:28:39,825 --> 01:28:42,785
Speaker 5:  with something called ADI promoter, which basically like make the glue work

1452
01:28:42,785 --> 01:28:46,705
Speaker 5:  better and pressure sensitive tape or they will replace it

1453
01:28:46,705 --> 01:28:50,345
Speaker 5:  if necessary. Free of charge of course. And then except the

1454
01:28:50,435 --> 01:28:53,665
Speaker 5:  wiper is excessive electrical current can cause the front windshield wiper

1455
01:28:53,665 --> 01:28:57,465
Speaker 5:  motor controller to fail. So they will replace

1456
01:28:57,465 --> 01:28:57,865
Speaker 5:  the motor.

1457
01:28:58,125 --> 01:29:01,885
Speaker 6:  I'm sure this is not what's happening but that makes it sound like it's,

1458
01:29:01,955 --> 01:29:05,685
Speaker 6:  it's getting like too much power and it is just, it's becoming

1459
01:29:05,955 --> 01:29:09,205
Speaker 6:  like electrified and going a thousand miles an hour and then it just like

1460
01:29:09,205 --> 01:29:12,045
Speaker 6:  launches itself into space and that's the end of your cyber drug waiver.

1461
01:29:12,755 --> 01:29:16,405
Speaker 5:  Well look, I can't, I won't draw too many

1462
01:29:16,405 --> 01:29:19,165
Speaker 5:  connections here, but you'll recall one of the big innovations of the cyber

1463
01:29:19,285 --> 01:29:22,965
Speaker 5:  truck is its new 48 volt control system. Oh right.

1464
01:29:22,965 --> 01:29:24,285
Speaker 5:  Whereas the traditional cars are 12

1465
01:29:25,825 --> 01:29:27,005
Speaker 5:  and the fact that the

1466
01:30:08,615 --> 01:30:10,115
Speaker 5:  God bless Tesla for launching this angry

1467
01:30:35,695 --> 01:30:39,655
Speaker 6:  ideas. Can it survive to like, oh this is, it's it's coming

1468
01:30:39,835 --> 01:30:43,655
Speaker 6:  now. And even the way that like RJ their CEO talked about it afterwards

1469
01:30:43,755 --> 01:30:46,375
Speaker 6:  was like, it's like buckle up, like let's go.

1470
01:30:46,375 --> 01:30:46,575
Speaker 5:  Yeah.

1471
01:31:26,945 --> 01:31:29,895
Speaker 6:  every 12 months or so until eventually we have like

1472
01:31:55,255 --> 01:31:58,775
Speaker 11:  one. One The Vergecast is a production of The Verge and Vox Media Podcast

1473
01:31:58,775 --> 01:32:02,405
Speaker 11:  Network. Our show is produced by Andrew Marino and Liam James.

1474
01:32:02,745 --> 01:32:04,205
Speaker 11:  That's it. We'll see you next week

1475
01:32:49,045 --> 01:32:52,175
Speaker 13:  With Verizon. You can finally create an internet plan that's made for you.

1476
01:32:52,815 --> 01:32:56,735
Speaker 13:  Whatever error you're in with my home now You can choose exactly what

1477
01:32:56,735 --> 01:33:00,175
Speaker 13:  goes into your Fios home internet plan and save on the entertainment you

1478
01:33:00,175 --> 01:33:04,015
Speaker 13:  love. Say hello to internet your way. Create your Fios home

1479
01:33:04,215 --> 01:33:08,095
Speaker 13:  internet plan starting at $35 a month with autopay and any Verizon mobile

1480
01:33:08,125 --> 01:33:10,575
Speaker 13:  plan. Call one 800 Verizon to switch today.

1481
01:33:11,695 --> 01:33:15,615
Speaker 13:  Availability varies for existing Verizon postpaid mobile customers, excluding

1482
01:33:15,615 --> 01:33:18,615
Speaker 13:  prepaid business and data only. Customers who then add and keep a file.

1483
01:33:18,615 --> 01:33:22,255
Speaker 13:  300 megabits per second Plan. Mobile and home discount enrollment required

1484
01:33:22,445 --> 01:33:26,135
Speaker 13:  autopay and paper free billing required $99 set up and other terms apply.

