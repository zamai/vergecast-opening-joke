1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: cb6e359a-f3fd-491a-b26d-98f765fa8f58
Status: Done
Stage: Done
Audio URL: https://jfe93e.s3.amazonaws.com/-4929868331226918152/-4523534272599170979/s93290-US-4427s-1716767983.mp3
Description: Today on the flagship podcast of Arm-based chipsets:
03:08 - The Verge’s Tom Warren and David Pierce discuss the announcements from Microsoft’s Surface event, including the new Arm-powered Surface Laptop, and Copilot Plus PCs.

Microsoft’s Surface AI event: news, rumors, and lots of Qualcomm laptops 

Microsoft announces an Arm-powered Surface Laptop

Microsoft’s new Surface Pro gets an OLED display for the first time

Microsoft announces Copilot Plus PCs with built-in AI hardware


The new, faster Surface Pro is Microsoft's all-purpose AI PC 

Recall is Microsoft’s key to unlocking the future of PCs


27:29 -Verge senior AI reporter Kylie Robison joins the show to chat about OpenAI’s GPT-4o demo and where we’re headed in the next few years of AI. 

ChatGPT is getting a Mac app

OpenAI’s custom GPT Store is now open to all for free

OpenAI releases GPT-4o, a faster model that’s free for all ChatGPT users 

ChatGPT will be able to talk to you like Scarlett Johansson in Her 

OpenAI pulls its Scarlett Johansson-like voice for ChatGPT 

OpenAI chief scientist Ilya Sutskever is officially leaving

OpenAI researcher resigns, claiming safety has taken ‘a backseat to shiny products’


We tried out the Project Astra demo at Google I/O which worked well un... | tech | TikTok 


57:40 - Nilay Patel answers a question about iPads for this week’s Vergecast Hotline.
Apple iPad Pro (2024) review: the best tablet money can buy

Email us at vergecast@theverge.com or call us at 866-VERGE11, we love hearing from you.
Learn more about your ad choices. Visit podcastchoices.com/adchoices
Ad Filtering: Enabled (35 ads detected)

2
00:00:02,435 --> 00:00:06,005
Speaker 2:  Welcome To The Vergecast, the flagship podcast of Arm based chipsets.

3
00:00:06,225 --> 00:00:09,925
Speaker 2:  I'm your friend David Pierce and I am currently in the woods in the middle

4
00:00:09,925 --> 00:00:13,805
Speaker 2:  of nowhere in Virginia at an Airbnb. So the last seven

5
00:00:13,805 --> 00:00:17,325
Speaker 2:  days have been my wife's birthday, mother's Day and our wedding

6
00:00:17,325 --> 00:00:21,125
Speaker 2:  anniversary all in the course of a week. If, you get to choose

7
00:00:21,185 --> 00:00:24,405
Speaker 2:  in your life to do all those things at once or spread them out through the

8
00:00:24,405 --> 00:00:28,085
Speaker 2:  year. I highly recommend spreading them out through the year, but this is

9
00:00:28,085 --> 00:00:31,725
Speaker 2:  what we have. So every year we try to like combine all these

10
00:00:31,725 --> 00:00:35,565
Speaker 2:  celebrations and just go find a place in the woods with bad internet

11
00:00:35,565 --> 00:00:39,085
Speaker 2:  and no cell connectivity and just relax for a couple of days.

12
00:00:39,645 --> 00:00:43,605
Speaker 2:  I cannot recommend enough every once in a while just finding somewhere where

13
00:00:43,605 --> 00:00:47,445
Speaker 2:  you can't be online, whether you want to or not and just lean into it

14
00:00:47,445 --> 00:00:51,325
Speaker 2:  for a couple days. It's the best, but I'm in the woods. But The

15
00:00:51,405 --> 00:00:54,525
Speaker 2:  Vergecast goes on. We have an awesome show for you today. We actually have

16
00:00:54,725 --> 00:00:58,605
Speaker 2:  a lot to get to. It is like the Newsiest time in

17
00:00:58,625 --> 00:01:02,565
Speaker 2:  recent memory and there's a lot of fun stuff to talk about today on the show,

18
00:01:02,565 --> 00:01:05,605
Speaker 2:  we're gonna talk about two things. We're gonna talk about the surface event

19
00:01:05,605 --> 00:01:09,325
Speaker 2:  that just happened where Microsoft kind of unveiled both its new

20
00:01:09,325 --> 00:01:13,125
Speaker 2:  devices, but also what seems to be an entirely new generation

21
00:01:13,425 --> 00:01:17,245
Speaker 2:  of laptops and Windows PCs. There's a lot going on. There's some big

22
00:01:17,395 --> 00:01:20,445
Speaker 2:  huge promises. We're gonna talk about all of it. We're also gonna talk about

23
00:01:20,665 --> 00:01:24,485
Speaker 2:  OpenAI. I know we've been talking about the OpenAI event from last week and

24
00:01:24,485 --> 00:01:28,245
Speaker 2:  Google, Gemini and this whole AI space that we're in right now. A lot

25
00:01:28,245 --> 00:01:31,525
Speaker 2:  over the last couple of weeks, but I can't stop thinking about it, especially

26
00:01:31,555 --> 00:01:35,405
Speaker 2:  what OpenAI believes is the future and how we're gonna talk

27
00:01:35,405 --> 00:01:38,765
Speaker 2:  to computers going forward. Lots to get to. On that front, we're gonna talk

28
00:01:38,765 --> 00:01:42,605
Speaker 2:  to Kylie Robinson, our new AI reporter about all of it. We also have a

29
00:01:42,725 --> 00:01:45,925
Speaker 2:  question about iPads on The Vergecast hotline because we also can't stop

30
00:01:45,925 --> 00:01:49,685
Speaker 2:  talking about iPads. Lots to do in this episode. All that is coming up in

31
00:01:49,685 --> 00:01:53,565
Speaker 2:  just a second, but I just heard the hot tub motor go off, which

32
00:01:53,565 --> 00:01:56,845
Speaker 2:  means it's hot enough, which means it's hot tub time. This is The Vergecast.

33
00:01:56,895 --> 00:01:57,685
Speaker 2:  We'll see you in a sec.

34
00:03:56,165 --> 00:03:59,725
Speaker 2:  build them with 5G and other connectivity because people will actually take

35
00:03:59,725 --> 00:04:03,405
Speaker 2:  them away from the charger. Windows tablets would suddenly make a lot more

36
00:04:03,405 --> 00:04:07,125
Speaker 2:  sense for a lot of people. So would more portable Windows gaming devices.

37
00:04:07,545 --> 00:04:11,525
Speaker 2:  It all sounds awesome. It also, I should say is a thing we have

38
00:04:11,525 --> 00:04:15,325
Speaker 2:  been promised many, many times. Qualcomm has

39
00:04:15,325 --> 00:04:19,205
Speaker 2:  been claiming that the next one was the one for years. Everything was gonna

40
00:04:19,205 --> 00:04:22,445
Speaker 2:  be the year of Windows on arm. I'm skeptical of all of it.

41
00:04:22,915 --> 00:04:26,405
Speaker 2:  Well yesterday that new generation of PCs showed up.

42
00:04:27,045 --> 00:04:29,925
Speaker 2:  Microsoft had a big event to launch new surfaces. Lots of other companies

43
00:04:29,925 --> 00:04:33,565
Speaker 2:  announced Snapdragon devices of their own. Our own Tom Warren

44
00:04:33,705 --> 00:04:37,045
Speaker 2:  is at the event in Seattle to catch us up on all of it. Hi Tom.

45
00:04:37,215 --> 00:04:37,805
Speaker 7:  Hello there.

46
00:04:38,015 --> 00:04:38,845
Speaker 2:  How's life in Seattle?

47
00:04:39,195 --> 00:04:41,685
Speaker 7:  Yeah, it's good. It's sunny. It's not raining so I can't complain.

48
00:04:42,805 --> 00:04:45,805
Speaker 2:  I did appreciate that the weather came up like three times at the beginning

49
00:04:45,905 --> 00:04:48,285
Speaker 2:  of the event this morning. They were very happy that it was a sunny day in

50
00:04:48,285 --> 00:04:49,125
Speaker 2:  Seattle. Yeah,

51
00:04:49,315 --> 00:04:53,245
Speaker 7:  Yeah, I mean the last, they put us all in the tent today, so the last time

52
00:04:53,245 --> 00:04:56,565
Speaker 7:  they did that it was like mudslides all around the tent. So I'm, I'm, I'm

53
00:04:56,565 --> 00:04:57,405
Speaker 7:  glad that's not happened.

54
00:04:57,785 --> 00:05:01,245
Speaker 2:  Oh boy. Yeah. So tell me a little bit about this event. This was a, an event

55
00:05:01,245 --> 00:05:04,445
Speaker 2:  we've known was coming for a while. It's the day before Microsoft build,

56
00:05:04,665 --> 00:05:08,525
Speaker 2:  but it's not Microsoft build like give me the vibes of the event

57
00:05:08,605 --> 00:05:08,885
Speaker 2:  a little bit.

58
00:05:09,395 --> 00:05:12,805
Speaker 7:  Yeah, so obviously we kind of knew that that they'd been working on these

59
00:05:12,805 --> 00:05:16,405
Speaker 7:  sort of like arm powered PCs and kind of like the event sort of

60
00:05:16,465 --> 00:05:20,125
Speaker 7:  talked us through this sort of reinvention of Windows, which is

61
00:05:20,445 --> 00:05:24,165
Speaker 7:  Microsoft's promised a bunch on on sort of Windows on arm previously. But

62
00:05:24,165 --> 00:05:27,485
Speaker 7:  it does feel like it's slightly different this time mainly because these

63
00:05:27,485 --> 00:05:31,085
Speaker 7:  devices have got more performance and battery life, all that sort of stuff.

64
00:05:31,085 --> 00:05:34,925
Speaker 7:  But also because all the OEMs are actually doing their own variants of what

65
00:05:34,925 --> 00:05:38,725
Speaker 7:  they're calling these copilot plus PCs and they're actually like the

66
00:05:38,725 --> 00:05:42,045
Speaker 7:  top tier variants of their, their Windows laptops. So it's not like they're

67
00:05:42,045 --> 00:05:45,405
Speaker 7:  just shoving these chips into some mid-range laptops and just coordinated

68
00:05:45,405 --> 00:05:49,245
Speaker 7:  that. They're like I quote all in on these copilot

69
00:05:49,245 --> 00:05:53,085
Speaker 7:  plus PCs. So the event kind of ran that down. Why those, why that matters,

70
00:05:53,145 --> 00:05:56,325
Speaker 7:  the performance versus the map care. 'cause Microsoft thinks that this is

71
00:05:56,355 --> 00:05:59,445
Speaker 7:  kind of like their moment to sort of beat the microcare, which is kind of

72
00:05:59,605 --> 00:06:02,845
Speaker 7:  interesting. And then some of the AI sort of features that these, these new

73
00:06:02,845 --> 00:06:04,285
Speaker 7:  laptops enable. Yeah,

74
00:06:04,285 --> 00:06:07,485
Speaker 2:  There's a lot of confidence coming outta Microsoft in this event. Like I

75
00:06:07,485 --> 00:06:11,085
Speaker 2:  feel like normally I'm used to sort of the the Panos pane era where he would

76
00:06:11,085 --> 00:06:14,605
Speaker 2:  come out and sort of tell you how lovely a device is and try to convince

77
00:06:14,625 --> 00:06:18,565
Speaker 2:  you of how wonderful it is and how much the team cared about it. And this

78
00:06:18,565 --> 00:06:21,085
Speaker 2:  felt like a very different Microsoft. They just came out and were like, we

79
00:06:21,085 --> 00:06:24,405
Speaker 2:  did it folks like here, here's the stuff. Check it out, let's go. Was that

80
00:06:24,405 --> 00:06:25,525
Speaker 2:  what it felt like in the room?

81
00:06:25,795 --> 00:06:29,005
Speaker 7:  Yeah, it definitely felt a a little bit different than some because the previous

82
00:06:29,005 --> 00:06:31,925
Speaker 7:  surface event that they had last year, it was like literally like days after

83
00:06:31,985 --> 00:06:34,965
Speaker 7:  we knew panels were leaving and that felt like, oh that's right. It was like

84
00:06:34,965 --> 00:06:38,645
Speaker 7:  a kind of like a funeral to surface. It felt like the like Surface was dying

85
00:06:38,665 --> 00:06:41,685
Speaker 7:  or something. It was, it was a really odd event. This one, it just feels

86
00:06:41,685 --> 00:06:45,405
Speaker 7:  like the surface is like the, the platform, like the essentially the the

87
00:06:45,405 --> 00:06:49,245
Speaker 7:  showpiece for this platform for these new advances on Windows and

88
00:06:49,245 --> 00:06:53,085
Speaker 7:  arm and that's kind of, they didn't make surface like the most

89
00:06:53,085 --> 00:06:56,085
Speaker 7:  important thing, but it wasn't the least important thing. It was kind of,

90
00:06:56,185 --> 00:06:59,445
Speaker 7:  you know, just just there to sort of back up that that that they are serious

91
00:06:59,495 --> 00:07:00,885
Speaker 7:  about this transition to arm.

92
00:07:01,195 --> 00:07:04,805
Speaker 2:  Yeah. So talk to me about the, the copilot plus PCs thing because

93
00:07:05,465 --> 00:07:08,565
Speaker 2:  you and I have been on this show for the last couple of months, I would say

94
00:07:09,055 --> 00:07:12,805
Speaker 2:  relatively consistently making fun of the idea of an AI

95
00:07:13,105 --> 00:07:17,005
Speaker 2:  pc, right? Which just generally means nothing. But this

96
00:07:17,005 --> 00:07:20,765
Speaker 2:  time Microsoft came out and and much more clearly tried to define

97
00:07:21,235 --> 00:07:25,205
Speaker 2:  what a copilot plus PC is and what makes it different and what makes it

98
00:07:25,205 --> 00:07:29,165
Speaker 2:  special and why this kind of deserves its own category of

99
00:07:30,065 --> 00:07:33,645
Speaker 2:  PCs. Like what, what makes a copilot plus pc? A copilot plus

100
00:07:33,865 --> 00:07:34,085
Speaker 2:  pc?

101
00:07:34,515 --> 00:07:38,365
Speaker 7:  Yeah, exactly. Like they previously had these AI PCs that were

102
00:07:38,365 --> 00:07:41,725
Speaker 7:  kind of like, they were trying to sell it on this AI vision or Windows, but

103
00:07:41,755 --> 00:07:45,285
Speaker 7:  they didn't quite have the performance essentially inside for them to actually

104
00:07:45,285 --> 00:07:49,125
Speaker 7:  enable these AI features that a part of these copilot plus pieces. So

105
00:07:49,125 --> 00:07:52,045
Speaker 7:  essentially what they are is, I think the way Microsoft's define them is

106
00:07:52,045 --> 00:07:55,925
Speaker 7:  that the NPU The new processing units, it's a new chip or I wouldn't say

107
00:07:55,925 --> 00:07:59,685
Speaker 7:  it's necessarily new, but it's new to sort of Windows a new chip

108
00:07:59,685 --> 00:08:03,445
Speaker 7:  that will basically accelerate these AI tasks. So they've got this new

109
00:08:03,545 --> 00:08:07,325
Speaker 7:  recall feature which essentially say you are working on your laptop

110
00:08:07,385 --> 00:08:10,925
Speaker 7:  and like you saw an elephant two weeks ago and you're like, where, where

111
00:08:10,925 --> 00:08:14,725
Speaker 7:  did I see that damn elephant? Was it in a tab, like was it in an email? Like

112
00:08:15,075 --> 00:08:18,205
Speaker 7:  sure I saw it. And then you can just type in Elephant and it will be like,

113
00:08:18,395 --> 00:08:21,565
Speaker 7:  okay, I saw this in your email and it doesn't need to like see the words

114
00:08:21,635 --> 00:08:25,045
Speaker 7:  that you've typed like Elephant it, it will literally understand that that

115
00:08:25,245 --> 00:08:29,125
Speaker 7:  is an elephant. So it's quite good for, for recalling like those memories

116
00:08:29,445 --> 00:08:33,045
Speaker 7:  from your everyday use of, of Windows very similar to a a Mac

117
00:08:33,225 --> 00:08:36,925
Speaker 7:  OS app called Rewind, which does a similar thing but obviously this is built

118
00:08:36,925 --> 00:08:40,405
Speaker 7:  in, it's leveraging the actual N Ps, it's not hitting the CPU or GPU to sort

119
00:08:40,405 --> 00:08:43,885
Speaker 7:  of do this. So you can just do these whilst you're watching videos or

120
00:08:43,935 --> 00:08:47,285
Speaker 7:  processing, I don't know, like Premier Pro or something like that and it's

121
00:08:47,285 --> 00:08:50,245
Speaker 7:  not gonna hit that performance. There's also like live captions and they

122
00:08:50,245 --> 00:08:54,205
Speaker 7:  showed like translation there, which was, was pretty cool, but you can't

123
00:08:54,205 --> 00:08:57,485
Speaker 7:  like save that stuff. So it's just, so say you wanted to watch a sort listen

124
00:08:57,505 --> 00:09:00,405
Speaker 7:  or watch to a podcast that was in Japanese, you could literally just load

125
00:09:00,405 --> 00:09:03,605
Speaker 7:  it up and it would just do that life life translation for you. So that that,

126
00:09:03,605 --> 00:09:04,325
Speaker 7:  that was pretty cool.

127
00:09:04,645 --> 00:09:08,485
Speaker 2:  I have to say I thought recall was really cool. Yeah. And I actually thought

128
00:09:08,485 --> 00:09:12,045
Speaker 2:  in general Microsoft did a really good job of not only explaining

129
00:09:12,785 --> 00:09:16,725
Speaker 2:  why you want lots of power on your computer but also

130
00:09:17,035 --> 00:09:20,205
Speaker 2:  showing the kinds of features that you can do on your device

131
00:09:20,755 --> 00:09:23,765
Speaker 2:  when you have this stuff. Like the translation was a good example where you

132
00:09:23,765 --> 00:09:27,245
Speaker 2:  were able to have like multiple languages being translated to each other

133
00:09:27,305 --> 00:09:30,365
Speaker 2:  in multiple, in real time on a video call, which is the kind of thing you

134
00:09:30,365 --> 00:09:33,845
Speaker 2:  genuinely only can do on device 'cause you're sending all that to the cloud,

135
00:09:33,845 --> 00:09:37,365
Speaker 2:  it just falls apart. Right. But, and with, with the live captions and some

136
00:09:37,365 --> 00:09:40,005
Speaker 2:  of the edit image editing stuff, they did a really good job of saying like,

137
00:09:40,005 --> 00:09:43,885
Speaker 2:  this is actually what you need all of that power locally in order to do.

138
00:09:43,945 --> 00:09:47,525
Speaker 2:  And I feel like for me recall, which is I think if I remember correctly,

139
00:09:47,665 --> 00:09:51,045
Speaker 2:  all private, all on device, not uploaded anywhere. Not even leaving your

140
00:09:51,205 --> 00:09:55,085
Speaker 2:  computer like really, really smart way to show this

141
00:09:55,085 --> 00:09:57,965
Speaker 2:  is what you can do when you have this thing on your computer. Like I found

142
00:09:57,965 --> 00:09:58,765
Speaker 2:  that very compelling.

143
00:09:58,915 --> 00:10:02,245
Speaker 7:  Yeah, I think recall was probably the, is their sort of flagship feature

144
00:10:02,265 --> 00:10:06,085
Speaker 7:  for, for this AI stuff. But they did also show, which was just kind of

145
00:10:06,115 --> 00:10:10,045
Speaker 7:  more forward looking and wasn't like a complete demo experience, but

146
00:10:10,115 --> 00:10:13,845
Speaker 7:  they showed some of the stuff where you could have like this copilot experience

147
00:10:13,865 --> 00:10:17,765
Speaker 7:  in a game like an Xbox game on Windows. So there was like a

148
00:10:17,765 --> 00:10:20,645
Speaker 7:  really cool demo and I dunno if this, this came through very well on the

149
00:10:20,645 --> 00:10:24,165
Speaker 7:  live blog, so definitely check out their demo of it. But it was essentially

150
00:10:24,165 --> 00:10:27,365
Speaker 7:  someone was playing Minecraft and then the copilot was like

151
00:10:28,005 --> 00:10:31,085
Speaker 7:  teaching the person how to craft in the game 'cause it could actually see

152
00:10:31,085 --> 00:10:34,965
Speaker 7:  obviously what what you were seeing. So it it, it knew and that was like,

153
00:10:35,075 --> 00:10:38,485
Speaker 7:  that was pretty cool and it was like a zombie in Minecraft appeared and they

154
00:10:38,485 --> 00:10:41,085
Speaker 7:  were like, oh no, there's a zombie, you better run away. Like it was like

155
00:10:41,085 --> 00:10:43,645
Speaker 7:  literally guiding them around the game as if they, it was like their friend

156
00:10:43,645 --> 00:10:47,525
Speaker 7:  sitting beside them. So that was like a really good hint at

157
00:10:47,525 --> 00:10:50,685
Speaker 7:  where this could go when you've got all this sort of on-device AI models

158
00:10:50,685 --> 00:10:53,845
Speaker 7:  running in the background and can actually see everything you're doing. And

159
00:10:53,845 --> 00:10:55,685
Speaker 7:  I thought that one was, that one was particularly cool.

160
00:10:56,075 --> 00:11:00,045
Speaker 2:  That is really cool. Yeah. On the recall one, we, we talked when you were

161
00:11:00,045 --> 00:11:03,085
Speaker 2:  reporting on this, I think it was called AI Explorer was the code name that

162
00:11:03,085 --> 00:11:04,725
Speaker 2:  you had found out about, is that right?

163
00:11:04,905 --> 00:11:05,565
Speaker 7:  Yes, that's right.

164
00:11:05,865 --> 00:11:09,565
Speaker 2:  We were debating whether it was gonna seem very cool or

165
00:11:09,635 --> 00:11:13,445
Speaker 2:  very creepy having seen the thing in action. Where do you land cool or creepy?

166
00:11:13,805 --> 00:11:17,525
Speaker 7:  I think it's in the middle. Right? Okay. Definitely. Because it is kind of

167
00:11:17,525 --> 00:11:20,485
Speaker 7:  creepy that they are taking basically a snapshot of everything you do on

168
00:11:20,485 --> 00:11:23,685
Speaker 7:  your pc. They say there's obviously a way to manage that. You can like disable

169
00:11:23,705 --> 00:11:27,685
Speaker 7:  it per app or on particular websites and stuff. But there, there is

170
00:11:27,685 --> 00:11:31,565
Speaker 7:  still the fact that it's running at all times in the background and and capturing

171
00:11:31,565 --> 00:11:35,005
Speaker 7:  everything you do. But then again, so is like your web browsing history,

172
00:11:35,005 --> 00:11:38,805
Speaker 7:  you know, that's always captured in in your browser. Not quite to the degree

173
00:11:38,805 --> 00:11:42,605
Speaker 7:  of like seeing it per se. So I think there, there is definitely

174
00:11:42,965 --> 00:11:46,885
Speaker 7:  a a, a creepiness to it, but I, I wonder if people will sort of

175
00:11:46,885 --> 00:11:49,845
Speaker 7:  see past that for the, for the, for the actual functionality that it enables.

176
00:11:49,905 --> 00:11:53,885
Speaker 7:  And it's all local. I am speaking to one of their security VPs

177
00:11:53,885 --> 00:11:57,485
Speaker 7:  shortly, so to sort of find out how they're gonna protect against malicious

178
00:11:57,765 --> 00:12:00,885
Speaker 7:  activity. 'cause you can imagine someone getting in through some sort of

179
00:12:00,885 --> 00:12:04,845
Speaker 7:  flaw and then, I don't know, using these AI models to cause chaos on

180
00:12:04,845 --> 00:12:08,165
Speaker 7:  your PC and search for stuff. Sure. And there's, there's potential there.

181
00:12:08,385 --> 00:12:12,285
Speaker 7:  So I'm curious how they've actually secured it beyond the sort of vague promises

182
00:12:12,285 --> 00:12:15,525
Speaker 7:  that they had on on stage. But yeah, I think it's definitely in, in between.

183
00:12:15,605 --> 00:12:18,125
Speaker 7:  I think there's gonna be a bunch of people that will disable this on the

184
00:12:18,325 --> 00:12:21,765
Speaker 7:  hardware that they buy. But then I think the, the things that it enables

185
00:12:21,765 --> 00:12:24,685
Speaker 7:  particularly around that like sort of Minecraft demo in the future, I think,

186
00:12:25,205 --> 00:12:28,205
Speaker 7:  I think it's gonna be worth the trade off. Right. As long as they can keep

187
00:12:28,205 --> 00:12:29,285
Speaker 7:  it secure. Yeah,

188
00:12:29,325 --> 00:12:33,205
Speaker 2:  I mean the the demos like that where it, it can collaborate with

189
00:12:33,205 --> 00:12:36,885
Speaker 2:  you as you're using your computer is like, that's the stuff that both Microsoft

190
00:12:36,905 --> 00:12:40,565
Speaker 2:  and others show these bits and pieces of that I'm always like, oh I get it

191
00:12:40,565 --> 00:12:44,485
Speaker 2:  now. Like that's, yeah, that's the kind of stuff I actually want AI for

192
00:12:44,665 --> 00:12:47,845
Speaker 2:  not to, you know, write me business emails but like help me do the things

193
00:12:47,905 --> 00:12:51,205
Speaker 2:  I'm trying to do better. Yeah. And in a sort of automated

194
00:12:51,715 --> 00:12:53,245
Speaker 2:  proactive way like that, that's pretty

195
00:12:53,245 --> 00:12:57,165
Speaker 7:  Cool. Yeah. Being being assistive and sort of like helping you along

196
00:12:57,165 --> 00:13:00,805
Speaker 7:  your way is, is definitely the way that I would prefer to see AI go than

197
00:13:01,065 --> 00:13:04,125
Speaker 7:  try and sort of replace you essentially. Right. Totally.

198
00:13:04,355 --> 00:13:08,325
Speaker 2:  Yeah. So let's talk about the devices. So the two big new ones from

199
00:13:08,565 --> 00:13:11,845
Speaker 2:  Microsoft, the Surface Laptop and the Surface Pro. No numbers,

200
00:13:12,215 --> 00:13:16,005
Speaker 2:  which really throws me off. Were just, it's just this No, are there numbers?

201
00:13:16,435 --> 00:13:20,125
Speaker 7:  They're sneaky numbers. So the Surface Pros called the Surface Pro

202
00:13:20,525 --> 00:13:24,085
Speaker 7:  11th Edition, which is very Microsoft as you can imagine, but they're, they're

203
00:13:24,085 --> 00:13:24,205
Speaker 7:  very

204
00:13:24,365 --> 00:13:24,525
Speaker 2:  Microsoft.

205
00:13:24,715 --> 00:13:28,365
Speaker 7:  They're kind of just referring it to as the Surface Pro right. Or the Copilot

206
00:13:28,365 --> 00:13:32,045
Speaker 7:  plus Surface Pro If. you want to get even more Microsoft. But yeah, like

207
00:13:32,195 --> 00:13:33,525
Speaker 7:  essentially there are no numbers.

208
00:13:34,155 --> 00:13:37,645
Speaker 2:  Okay. You've seen them both. I would say my takeaway just from

209
00:13:37,755 --> 00:13:40,885
Speaker 2:  reading the live blog and and seeing the specs and stuff is

210
00:13:41,195 --> 00:13:45,125
Speaker 2:  basically similar-ish footprints. Like I think the

211
00:13:45,125 --> 00:13:48,445
Speaker 2:  Surface Pro in particular is exactly the same size as before and the whole

212
00:13:48,445 --> 00:13:52,365
Speaker 2:  pitch is like gigantic massive internal upgrade that kind of changes

213
00:13:52,365 --> 00:13:54,285
Speaker 2:  everything. Is that reasonable?

214
00:13:54,595 --> 00:13:57,965
Speaker 7:  Yeah, I I mean on the Surface Pro they've got new ed

215
00:13:58,275 --> 00:14:02,005
Speaker 7:  display model, which is, which is nice. That's good to have OLED on there.

216
00:14:02,285 --> 00:14:05,885
Speaker 7:  It's not tandem like the I iPad Pro. I think that that Dell's

217
00:14:05,885 --> 00:14:09,685
Speaker 7:  XPS actually is. So you've got The new display option there. But

218
00:14:09,685 --> 00:14:13,565
Speaker 7:  yeah, overall the actual device looks very similar. But they have done

219
00:14:13,745 --> 00:14:17,245
Speaker 7:  one really cool thing that I like is the, the type cover now, you know from

220
00:14:17,345 --> 00:14:21,205
Speaker 7:  Review needs for years, the, the whole lap ability argument with the

221
00:14:21,285 --> 00:14:25,125
Speaker 7:  Surface Pros raged for like a decade now. Yep. And they've actually,

222
00:14:25,155 --> 00:14:28,925
Speaker 7:  what they've done is they've reinforced it. So there's actually, I

223
00:14:29,165 --> 00:14:31,805
Speaker 7:  I couldn't really get it to bounce honestly when I was using on a desk.

224
00:14:31,985 --> 00:14:32,405
Speaker 2:  Really?

225
00:14:32,835 --> 00:14:36,485
Speaker 7:  Yeah, and you know how it usually flexes and you get that weird bounce. It's

226
00:14:36,485 --> 00:14:39,565
Speaker 7:  really annoying when you're trying to write like a, a long document. Yeah.

227
00:14:39,565 --> 00:14:42,645
Speaker 2:  As soon you start typing fast the whole thing sort of feels like it's wiggling

228
00:14:42,645 --> 00:14:43,365
Speaker 2:  underneath you. Yeah,

229
00:14:43,365 --> 00:14:46,965
Speaker 7:  Yeah. Like it doesn't do that anymore. There's still that a very

230
00:14:46,985 --> 00:14:50,805
Speaker 7:  slight flex, but like it's not really near as bad and I tried up my,

231
00:14:50,805 --> 00:14:54,645
Speaker 7:  my lap as well. Same it, it was the same and it's because they basically

232
00:14:55,045 --> 00:14:58,725
Speaker 7:  reinforce the, the base of the the surface keyboard. They put a battery in

233
00:14:58,725 --> 00:15:01,925
Speaker 7:  it now. So, so the actual track pad is a little bit larger and it has haptic

234
00:15:02,205 --> 00:15:05,565
Speaker 7:  feedback and it has a Bluetooth chip inside there. So you pull it away from

235
00:15:05,565 --> 00:15:08,165
Speaker 7:  the display and you can actually use it wirelessly. So it's not like just

236
00:15:08,165 --> 00:15:11,805
Speaker 7:  this dumb keyboard when you, when you pull it off anymore. So some pretty

237
00:15:11,805 --> 00:15:14,845
Speaker 7:  cool keyboard upgrades and you can also use the old keyboards If you, If

238
00:15:14,845 --> 00:15:18,525
Speaker 7:  you want to. Yeah. And that, that and the display, I'd say are the biggest

239
00:15:18,525 --> 00:15:21,645
Speaker 7:  things that you would notice on the outside. It's obviously the inside is

240
00:15:21,645 --> 00:15:25,085
Speaker 7:  they're actually Qualcomm power now. So it's Windows and Arm, the Snapdragon

241
00:15:25,245 --> 00:15:28,525
Speaker 7:  X Elite and, and the plus in, in the Surface Pro depending on, you know,

242
00:15:28,525 --> 00:15:32,165
Speaker 7:  which model you go for and playing around with it for like a good, you know,

243
00:15:32,265 --> 00:15:36,045
Speaker 7:  10, 20 minutes. It does, it just does feel like a regular Windows

244
00:15:36,185 --> 00:15:40,165
Speaker 7:  laptop. Right. Especially when everything is running native on there. I we

245
00:15:40,165 --> 00:15:43,565
Speaker 7:  really need to review these to like check out these, these big claims that

246
00:15:43,805 --> 00:15:47,405
Speaker 7:  Microsoft's making. But yeah, it feels like super slick and, and and fast

247
00:15:47,425 --> 00:15:50,645
Speaker 7:  and speedy as you would kind of expect you, I don't think you'd necessarily

248
00:15:50,645 --> 00:15:52,805
Speaker 7:  think that this was an arm laptop. Put it that way.

249
00:15:52,985 --> 00:15:56,645
Speaker 2:  That's really exciting. I mean, and I think that sounds, as you say it almost

250
00:15:56,645 --> 00:16:00,085
Speaker 2:  like faint praise, but I just wanna make sure like it's, it's really not

251
00:16:00,085 --> 00:16:03,605
Speaker 2:  faint praise. No. Given what we've seen from Windows

252
00:16:03,905 --> 00:16:07,605
Speaker 2:  on Arm in the past, like you could tell on the last

253
00:16:07,605 --> 00:16:11,205
Speaker 2:  generation Surface Pro whether you were using the Intel model or the

254
00:16:11,325 --> 00:16:15,005
Speaker 2:  Qualcomm model. Yes. Like immediately, like immediately you could tell the

255
00:16:15,005 --> 00:16:18,405
Speaker 2:  difference. Yeah. And so just the fact that you pick it up and it just feels

256
00:16:18,405 --> 00:16:21,605
Speaker 2:  like a Windows laptop is already an enormous win. Yeah,

257
00:16:21,675 --> 00:16:25,605
Speaker 7:  Exactly. Like it does it, I couldn't get it to like really lag,

258
00:16:25,785 --> 00:16:29,165
Speaker 7:  you know? I know I wasn't really pushing it and we will, like I say faint

259
00:16:29,165 --> 00:16:32,765
Speaker 7:  praise because we have to check this out when we review it. But for, from

260
00:16:32,765 --> 00:16:35,965
Speaker 7:  everything I can see it does look like they might have done it this time,

261
00:16:36,145 --> 00:16:38,685
Speaker 7:  but it really is gonna come down to the app compatibility and they, they,

262
00:16:38,685 --> 00:16:42,605
Speaker 7:  they've made some big promises about you emulator and I think just the

263
00:16:42,605 --> 00:16:45,805
Speaker 7:  pure fact that these chips are a lot better, they're sort of brute forcing

264
00:16:45,805 --> 00:16:48,645
Speaker 7:  their way through this in, in many ways, but they're not doing it in a way

265
00:16:48,645 --> 00:16:51,725
Speaker 7:  that's gonna kill the battery life either. Which is interesting 'cause they're

266
00:16:51,725 --> 00:16:54,685
Speaker 7:  making big claims about that as well. It's like 16 hours browsing the web,

267
00:16:54,685 --> 00:16:58,325
Speaker 7:  like 20 hour plus hours If you're watching local video. So if that

268
00:16:58,685 --> 00:17:02,565
Speaker 7:  actually holds up or anywhere close to it, then yeah that's gonna

269
00:17:02,565 --> 00:17:05,965
Speaker 7:  be very competitive compared to sort of the MacBook Air. Whereas usually,

270
00:17:06,025 --> 00:17:09,885
Speaker 7:  but when Microsoft says they have like a 10 hour battery life pc, it's usually

271
00:17:09,885 --> 00:17:11,885
Speaker 7:  five hours, you know, so

272
00:17:12,155 --> 00:17:15,845
Speaker 2:  Well and you got to see, if I remember correctly, like you actually got to

273
00:17:15,845 --> 00:17:19,685
Speaker 2:  see them run these demos next to a

274
00:17:19,685 --> 00:17:22,925
Speaker 2:  MacBook Air. Right. I find Microsoft's whole fascination right now with the

275
00:17:22,925 --> 00:17:25,925
Speaker 2:  MacBook Air and the M three chip in particular really fascinating, but just

276
00:17:25,925 --> 00:17:29,685
Speaker 2:  the fact that they put you in a room and tested the

277
00:17:29,685 --> 00:17:33,525
Speaker 2:  MacBook Air next to The new surfaces is just wild

278
00:17:33,525 --> 00:17:33,845
Speaker 2:  to me.

279
00:17:34,155 --> 00:17:38,005
Speaker 7:  Yeah. I spent an hour watching a ton of demos that's ranging

280
00:17:38,075 --> 00:17:42,005
Speaker 7:  from like CNA Bench and Geek Bench, you know, like the sort of the, the basic

281
00:17:42,265 --> 00:17:45,885
Speaker 7:  PC benchmarks all the way up to like they, they made scripts for like

282
00:17:45,975 --> 00:17:49,245
Speaker 7:  doing Photoshop filters, which I, they showed some of those on stage and

283
00:17:49,245 --> 00:17:53,165
Speaker 7:  then some AI tasks and yeah, I'd say out of that hour, probably

284
00:17:53,185 --> 00:17:55,965
Speaker 7:  at least every five minutes the MacBook Air was mentioned. Like, I'm not

285
00:17:55,965 --> 00:17:58,565
Speaker 7:  joking, I'm not over exaggerating. It was literally wow, relentless.

286
00:17:59,225 --> 00:18:01,485
Speaker 2:  Why is Microsoft so obsessed with the MacBook Air? I

287
00:18:01,485 --> 00:18:04,925
Speaker 7:  Think because they know that they've fallen behind that like premium

288
00:18:05,785 --> 00:18:09,645
Speaker 7:  set of devices over the past few years since, since Apple transitioned

289
00:18:09,665 --> 00:18:13,485
Speaker 7:  to the M1. They, they've really been behind and Intel hasn't

290
00:18:13,515 --> 00:18:17,045
Speaker 7:  like got them there on battery life or performance to sort of match that,

291
00:18:17,075 --> 00:18:20,525
Speaker 7:  that kind of great offering from from Apple. So they, they, I think their

292
00:18:20,525 --> 00:18:23,885
Speaker 7:  confidence is like, yeah, we're finally here, you know, we, we can be competitive

293
00:18:23,985 --> 00:18:27,925
Speaker 7:  or if not better and we can do it with all these AI sort of features on top.

294
00:18:28,175 --> 00:18:32,125
Speaker 7:  There you go Apple, you know, we're here. Yeah. So it's definitely a

295
00:18:32,125 --> 00:18:33,325
Speaker 7:  new level of confidence.

296
00:18:33,435 --> 00:18:36,725
Speaker 2:  Yeah, that makes sense. And speaking of that, actually I was very confused

297
00:18:36,745 --> 00:18:40,405
Speaker 2:  by the fact that Microsoft, at the beginning of the event set a bunch about

298
00:18:40,465 --> 00:18:44,125
Speaker 2:  how all the OEMs, all the chip makers, everybody's in that

299
00:18:44,445 --> 00:18:47,925
Speaker 2:  this co-pilot plus PCs thing is, is like an industry

300
00:18:48,235 --> 00:18:51,885
Speaker 2:  wide move and then spent the whole rest of the hour

301
00:18:51,885 --> 00:18:55,805
Speaker 2:  talking about Qualcomm power devices. What, what is, what do you make of

302
00:18:55,805 --> 00:18:55,925
Speaker 2:  that?

303
00:18:56,275 --> 00:18:59,885
Speaker 7:  Yeah, they kind of did this thing like there was like oh A MD and, and then

304
00:18:59,885 --> 00:19:03,685
Speaker 7:  you're all gonna gonna have these co-pilot plus PCs, you know, soon, but,

305
00:19:03,865 --> 00:19:07,325
Speaker 7:  but not right now. So we, we, we've been partnering with Qualcomm to do this.

306
00:19:07,405 --> 00:19:10,365
Speaker 7:  I think they're kind of, I think they're downplaying a little bit their arm

307
00:19:10,365 --> 00:19:13,725
Speaker 7:  transition there because obviously they want this to be all partner focused.

308
00:19:13,745 --> 00:19:17,405
Speaker 7:  That's the whole idea of Windows. But they, they've made such a big effort

309
00:19:17,645 --> 00:19:21,445
Speaker 7:  even in all those demos. Like there was no mention of Intel and, and a MD,

310
00:19:21,625 --> 00:19:24,645
Speaker 7:  you know, like it was all about these Qualcomm devices all about the transition

311
00:19:24,645 --> 00:19:28,205
Speaker 7:  to Arm, like all about how they've recompiled the kernel and

312
00:19:28,355 --> 00:19:31,565
Speaker 7:  done all this, this work in the background so that they're confident that

313
00:19:31,585 --> 00:19:35,445
Speaker 7:  ARM is finally gonna be, you know, competitive with the Intel

314
00:19:35,445 --> 00:19:38,285
Speaker 7:  based models that, that we have of, of surface devices right now.

315
00:19:39,225 --> 00:19:43,045
Speaker 7:  So I think they, they kind of had to throw a bone to Intel and a MD and had

316
00:19:43,045 --> 00:19:46,685
Speaker 7:  to have them included obviously in this event. And I'm not, that's not terribly

317
00:19:46,685 --> 00:19:50,605
Speaker 7:  surprising, but their stage presence was, was very little compared to

318
00:19:50,705 --> 00:19:53,725
Speaker 7:  all the arm talk that they had on stage. Right. It was all, all of those

319
00:19:53,905 --> 00:19:57,525
Speaker 7:  AI experiences were lit up by a combination of these new chips.

320
00:19:58,065 --> 00:20:01,965
Speaker 7:  So it's gonna be interesting to see when Intel and a MD can actually have

321
00:20:01,965 --> 00:20:05,845
Speaker 7:  an answer with the NPUs that are as performant. 'cause

322
00:20:05,845 --> 00:20:09,525
Speaker 7:  they're already, like they're talking these chips are 45 tops

323
00:20:09,525 --> 00:20:13,485
Speaker 7:  whereas the Intel ones are like less than 10 right now. So by the

324
00:20:13,485 --> 00:20:17,365
Speaker 7:  time Intel matches will Qualcomm then jump ahead. Like it's gonna be

325
00:20:17,645 --> 00:20:21,125
Speaker 7:  interesting to see where the roadmap sort of pans out here.

326
00:20:21,565 --> 00:20:25,365
Speaker 2:  I did enjoy this wasn't the spec heaviest event

327
00:20:25,365 --> 00:20:27,605
Speaker 2:  ever, which I thought was really interesting. They spent a lot of time doing

328
00:20:27,605 --> 00:20:30,885
Speaker 2:  like app demos and a lot less time talking about

329
00:20:31,585 --> 00:20:35,045
Speaker 2:  the details of how these chips work and all that stuff. Right. But they did

330
00:20:35,275 --> 00:20:39,085
Speaker 2:  keep talking about 45 trillion operations per second

331
00:20:39,155 --> 00:20:42,525
Speaker 2:  over and over and over. Yes. That was like the one spec they said like 10

332
00:20:42,525 --> 00:20:43,925
Speaker 2:  times. Yeah they did. It

333
00:20:43,925 --> 00:20:44,125
Speaker 7:  Was very

334
00:20:44,125 --> 00:20:47,445
Speaker 2:  Funny. It was like they are, they're like, our chip is so fast and we're,

335
00:20:47,445 --> 00:20:51,165
Speaker 2:  we're going to remind you 11 times during this event

336
00:20:51,345 --> 00:20:53,925
Speaker 2:  how fast our chips are. 'cause they're so proud of their fast chips.

337
00:20:54,285 --> 00:20:57,925
Speaker 7:  Exactly. And depending on how they calculate it and we'll have to see, I

338
00:20:57,925 --> 00:21:01,605
Speaker 7:  think it will be faster for AI operations than the M four perhaps. So

339
00:21:01,795 --> 00:21:05,365
Speaker 7:  it's gonna be interesting when that roadmap shakes out. 'cause

340
00:21:05,365 --> 00:21:08,525
Speaker 7:  obviously Qualcomm have had arm chips for years and they've never been quite

341
00:21:08,525 --> 00:21:12,325
Speaker 7:  this performant and, and they acquired Nuvia and I think that is the key

342
00:21:12,545 --> 00:21:15,645
Speaker 7:  to why these chips are different. And I think that's, that's the key 'cause

343
00:21:15,645 --> 00:21:19,485
Speaker 7:  that, that those Nuvia chips were, were built by X apple engineers. So it's

344
00:21:19,485 --> 00:21:23,405
Speaker 7:  almost like Right. Yeah. That, so they, they're building the windows silicon.

345
00:21:23,985 --> 00:21:26,925
Speaker 7:  So I think, I think that is the key to why this all feels a little bit different

346
00:21:27,305 --> 00:21:31,045
Speaker 7:  is that the chips are actually performing like you would expect them to.

347
00:21:31,705 --> 00:21:35,605
Speaker 2:  So does all that add up to this being the moment

348
00:21:36,085 --> 00:21:39,485
Speaker 2:  Microsoft seems to want it to be like the, the sense I got reading your reporting

349
00:21:39,505 --> 00:21:41,805
Speaker 2:  and, and from talking to you about this for the last couple of months is

350
00:21:41,805 --> 00:21:45,685
Speaker 2:  that this is kind of a day Microsoft has had circled on the

351
00:21:45,845 --> 00:21:49,805
Speaker 2:  calendar for two years as like yeah this is the beginning of The new era

352
00:21:49,905 --> 00:21:53,325
Speaker 2:  of Windows. We have the power, we have the AI stuff.

353
00:21:53,475 --> 00:21:57,205
Speaker 2:  Copilot is starting to get there. Like the there along with this, there were,

354
00:21:57,365 --> 00:22:01,245
Speaker 2:  I think every OEM on planet Earth announced a bunch of copilot

355
00:22:01,245 --> 00:22:04,845
Speaker 2:  plus PCs. Like right. This, this was clearly designed

356
00:22:05,025 --> 00:22:08,565
Speaker 2:  to be sort of the beginning of an era of Windows PCs.

357
00:22:08,875 --> 00:22:11,045
Speaker 2:  Yeah. Do you think it got what it was trying to do?

358
00:22:11,515 --> 00:22:14,845
Speaker 7:  Yeah, I think so. I think I, I was surprised by some of the AI features that

359
00:22:14,845 --> 00:22:17,925
Speaker 7:  they showed on stage. I think those, those looked really promising. So I

360
00:22:17,925 --> 00:22:21,805
Speaker 7:  wasn't expecting as much of the AI features as, as they showed and

361
00:22:21,805 --> 00:22:25,525
Speaker 7:  just coming to campus this morning, it's like they literally have like

362
00:22:25,525 --> 00:22:29,285
Speaker 7:  signage everywhere. It's like The new AI of era has is is here

363
00:22:29,285 --> 00:22:33,245
Speaker 7:  sort of thing. So they, they're obviously like very confident in it and what

364
00:22:33,245 --> 00:22:36,165
Speaker 7:  they showed and just, just playing around with the devices. It, it does feel

365
00:22:36,835 --> 00:22:40,485
Speaker 7:  like something is different here. Like this is definitely different from

366
00:22:40,485 --> 00:22:44,365
Speaker 7:  like the 2018 push and definitely different from the Surface RT push. So

367
00:22:44,635 --> 00:22:47,765
Speaker 7:  yeah, I mean I wanna try 'em out. I wanna review them next month and, and

368
00:22:47,825 --> 00:22:51,685
Speaker 7:  and give them a good sort of spin just to see if this is actually, you know,

369
00:22:51,795 --> 00:22:55,605
Speaker 7:  this can replace my own laptop and see that if, if they can really

370
00:22:55,605 --> 00:22:59,445
Speaker 7:  nail that battery life, then yeah. I dunno, I dunno what Intel and a

371
00:22:59,525 --> 00:23:03,045
Speaker 7:  MD are gonna do. 'cause I know Qualcomm might have delivered it.

372
00:23:03,315 --> 00:23:06,245
Speaker 2:  Yeah. I feel like you and I are in exactly the same Headspace, which is like,

373
00:23:06,325 --> 00:23:10,045
Speaker 2:  I desperately want this to be everything that they said it would be. 'cause

374
00:23:10,045 --> 00:23:13,445
Speaker 2:  it would be so much fun if the whole Windows ecosystem just kind of leveled

375
00:23:13,445 --> 00:23:17,205
Speaker 2:  up. But also we've been burned on this specific promise several times in

376
00:23:17,205 --> 00:23:17,525
Speaker 2:  the past.

377
00:23:18,035 --> 00:23:21,405
Speaker 7:  It's like, if I sound cautious, it's because of those two burn moments in

378
00:23:21,405 --> 00:23:21,645
Speaker 7:  the past.

379
00:23:21,875 --> 00:23:25,365
Speaker 2:  Exactly. But it does, I I think if it's, if it's ever gonna happen, it feels

380
00:23:25,365 --> 00:23:26,405
Speaker 2:  like it might happen right now.

381
00:23:26,715 --> 00:23:30,365
Speaker 7:  Yeah. I think if it, if it doesn't happen right now, then I mean they've

382
00:23:30,365 --> 00:23:33,685
Speaker 7:  blown it, right? Like everything that they've showed in all the, all these

383
00:23:33,685 --> 00:23:37,565
Speaker 7:  big promises, it'll be pretty crazy if if they, it doesn't

384
00:23:37,565 --> 00:23:41,005
Speaker 7:  live up to that. You know, if, if the performance isn't there, these AI features

385
00:23:41,015 --> 00:23:44,765
Speaker 7:  don't work properly or like the battery life just sucks, then Microsoft's

386
00:23:44,765 --> 00:23:48,685
Speaker 7:  blown it. Right? So they kind of have to have done it this time. Otherwise

387
00:23:48,685 --> 00:23:51,525
Speaker 7:  there's a lot on the line given the way that they've been talking and the,

388
00:23:51,545 --> 00:23:53,765
Speaker 7:  the confidence that they're, that they're putting into this.

389
00:23:53,875 --> 00:23:57,845
Speaker 2:  Totally. Yeah. I realized going in that there were a

390
00:23:57,845 --> 00:24:01,805
Speaker 2:  bunch of people who bought iPad Pros last week who were looking at the Surface

391
00:24:01,945 --> 00:24:05,525
Speaker 2:  Pro this week being like, oh maybe I wanna surface Pro. And it's like, oh,

392
00:24:05,545 --> 00:24:07,845
Speaker 2:  if Microsoft's doing that, they've done it, they're back.

393
00:24:07,985 --> 00:24:11,685
Speaker 7:  That's true. Yeah. It's not, it's not as thin and and like as sexy

394
00:24:12,125 --> 00:24:15,005
Speaker 7:  hardware as the iPad Pro I'd say. But yeah, I mean,

395
00:24:15,145 --> 00:24:16,045
Speaker 2:  But it runs all my apps

396
00:24:16,145 --> 00:24:19,285
Speaker 7:  Tom. Yeah, it runs all your apps. You can actually use it. Yeah. So and you,

397
00:24:19,285 --> 00:24:23,165
Speaker 7:  when you're processing in video and you tap a notification, it's not

398
00:24:23,165 --> 00:24:26,645
Speaker 7:  gonna kill that video in the background like it's an actual os. So

399
00:24:26,955 --> 00:24:30,645
Speaker 2:  Yeah, a hundred percent. Alright Tom, you got meetings to get to. Thank you

400
00:24:30,705 --> 00:24:34,045
Speaker 2:  for, for jumping on and doing this. I appreciate it. Yeah, no worries. Good

401
00:24:34,045 --> 00:24:35,525
Speaker 2:  luck with the rest of your stuff in Redmond.

402
00:24:35,525 --> 00:24:36,805
Speaker 7:  Alright, thank you. I'll speak to you soon.

403
00:24:37,395 --> 00:24:40,765
Speaker 2:  Alright, we gotta take a break. But actually real quick before we do, you

404
00:24:40,765 --> 00:24:44,485
Speaker 2:  can subscribe now to Tom's new newsletter called Notepad about all things

405
00:24:44,845 --> 00:24:45,685
Speaker 2:  Microsoft. I'll put a

406
00:27:59,475 --> 00:28:03,195
Speaker 2:  last Monday in which the company announced s GPT four oh and a

407
00:28:03,195 --> 00:28:06,635
Speaker 2:  super personable, maybe even flirty voice assistant.

408
00:28:07,015 --> 00:28:07,235
Speaker 2:  Hey,

409
00:28:07,555 --> 00:28:09,235
Speaker 9:  T s GPT, I'm Mark. How are you?

410
00:28:10,095 --> 00:28:14,075
Speaker 10:  Oh, mark, I'm doing great. Thanks for asking. How

411
00:28:14,075 --> 00:28:15,875
Speaker 10:  about you? So I'm on stage right

412
00:28:15,875 --> 00:28:19,275
Speaker 2:  Now, If, you hear that clip and you're like, oh, weird. That sounds like

413
00:28:19,275 --> 00:28:22,795
Speaker 2:  Scarlett Johannson in her. Well, so did everybody else.

414
00:28:23,475 --> 00:28:24,995
Speaker 2:  I mean, listen to this from her.

415
00:28:25,465 --> 00:28:28,675
Speaker 11:  Okay, let's start with your emails. You have several thousand emails regarding

416
00:28:28,735 --> 00:28:30,555
Speaker 11:  LA Weekly, but it looks like you haven't worked there in many years.

417
00:28:31,015 --> 00:28:33,435
Speaker 2:  And now this clip from the OpenAI event.

418
00:28:34,135 --> 00:28:38,075
Speaker 10:  Ah, I see it now. You wrote down three

419
00:28:38,315 --> 00:28:40,835
Speaker 10:  x plus one equals four. Yep.

420
00:28:40,885 --> 00:28:42,315
Speaker 12:  Let's work. Exactly. So what's

421
00:28:42,315 --> 00:28:46,155
Speaker 2:  The first? I could do this forever because the similarities are deeply uncanny.

422
00:28:46,215 --> 00:28:50,195
Speaker 2:  But here's just one more. This is from the s GPT four oh demo. When one

423
00:28:50,195 --> 00:28:54,155
Speaker 2:  of the researchers wrote iHeart Chat s GPT on a piece of paper and then held

424
00:28:54,155 --> 00:28:55,955
Speaker 2:  up his phone camera so it could see it.

425
00:28:56,495 --> 00:29:00,075
Speaker 10:  Of course. I'd love to see what you wrote. Show it to me. Whenever you're

426
00:29:00,075 --> 00:29:00,195
Speaker 10:  ready.

427
00:29:00,625 --> 00:29:02,675
Speaker 12:  Okay, so this is what I wrote down. What do you see?

428
00:29:04,765 --> 00:29:08,745
Speaker 10:  Oh, I see. I love chat s GPT. That's so

429
00:29:08,745 --> 00:29:09,345
Speaker 10:  sweet of you.

430
00:29:10,005 --> 00:29:11,825
Speaker 2:  And now here's a moment from her.

431
00:29:12,285 --> 00:29:13,065
Speaker 13:  You're beautiful.

432
00:29:15,395 --> 00:29:16,585
Speaker 13:  Thank you Theodore.

433
00:29:18,845 --> 00:29:19,825
Speaker 13:  I'm kissing your head.

434
00:29:21,455 --> 00:29:25,385
Speaker 2:  Side note by the way, her is such a good movie, If. you haven't

435
00:29:25,385 --> 00:29:29,265
Speaker 2:  seen it or haven't seen it in a while. Do it. It's even better than I remembered.

436
00:29:29,325 --> 00:29:32,865
Speaker 2:  And given everything that has happened with AI over the last couple of years,

437
00:29:33,205 --> 00:29:37,145
Speaker 2:  it hits different now anyway, other than the fact that the actual product

438
00:29:37,175 --> 00:29:40,785
Speaker 2:  that exists in the world doesn't work quite as well and sounds a little more

439
00:29:40,785 --> 00:29:44,565
Speaker 2:  robotic than the one in the movie. I mean, the vibes here are very

440
00:29:44,565 --> 00:29:48,165
Speaker 2:  similar, both in the product in general and in the Voice

441
00:29:48,805 --> 00:29:52,205
Speaker 2:  specifically to the point where actually over the weekend, OpenAI pulled

442
00:29:52,205 --> 00:29:55,285
Speaker 2:  the voice that you're hearing here, which was named Sky from the product

443
00:29:55,605 --> 00:29:59,285
Speaker 2:  altogether. OpenAI said it wasn't trying to mimic Scarlett Johansen

444
00:29:59,465 --> 00:30:03,045
Speaker 2:  in her, which I find very hard to believe for reasons we'll get into. But

445
00:30:03,045 --> 00:30:06,605
Speaker 2:  then on Monday night, just before this episode went out, Scarlett

446
00:30:06,605 --> 00:30:09,765
Speaker 2:  Johanssen actually gave a statement saying that last September,

447
00:30:10,505 --> 00:30:14,325
Speaker 2:  OpenAI had contacted her about being the voice of s GPT four oh.

448
00:30:14,585 --> 00:30:18,405
Speaker 2:  And as many as two days before, like two days

449
00:30:18,465 --> 00:30:22,365
Speaker 2:  before the event in which they revealed s GPT four oh with this

450
00:30:22,365 --> 00:30:26,285
Speaker 2:  new voice, with this new flirty personality. They were still contacting

451
00:30:26,285 --> 00:30:30,125
Speaker 2:  her, trying to get her to reconsider and do the voice. It's all very strange.

452
00:30:30,265 --> 00:30:33,205
Speaker 2:  And this is the kind of thing we just don't have a lot of history of dealing

453
00:30:33,205 --> 00:30:36,605
Speaker 2:  with. There's just not a lot of precedent for this kind of story.

454
00:30:36,985 --> 00:30:40,525
Speaker 2:  And in general, there are a lot of questions here about what we learned from

455
00:30:40,525 --> 00:30:44,205
Speaker 2:  that s GPT four oh demo and what OpenAI is really up to here

456
00:30:44,625 --> 00:30:48,485
Speaker 2:  and where we're headed in the next few years of ai. And to talk through all

457
00:30:48,485 --> 00:30:51,965
Speaker 2:  of that stuff and more, I grabbed Kylie Robinson, the verges new senior AI

458
00:30:52,245 --> 00:30:54,405
Speaker 2:  reporter, Kylie Robinson. Welcome To. The Vergecast.

459
00:30:54,655 --> 00:30:55,805
Speaker 14:  Thank you for having me.

460
00:30:56,155 --> 00:30:59,605
Speaker 2:  This is what day nine for you at The Verge as we're recording this?

461
00:31:00,155 --> 00:31:01,005
Speaker 14:  Precisely, yes.

462
00:31:01,225 --> 00:31:05,125
Speaker 2:  And you've already been in like 465 news cycles.

463
00:31:05,555 --> 00:31:09,245
Speaker 14:  That is a hundred percent correct. Maybe one more today, but yes,

464
00:31:09,245 --> 00:31:09,725
Speaker 14:  exactly.

465
00:31:10,225 --> 00:31:13,445
Speaker 2:  Has it been so far? How is, how are your first nine days at The Verge?

466
00:31:13,945 --> 00:31:17,565
Speaker 14:  It is so fantastic. It's pure chaos and I think a lot of people looking

467
00:31:17,625 --> 00:31:20,965
Speaker 14:  are like, why are you doing all this? Are they killing you? No, it's because

468
00:31:20,965 --> 00:31:24,365
Speaker 14:  it's so fun and I can't stop agreeing to write stuff. So it's been great.

469
00:31:24,715 --> 00:31:28,085
Speaker 2:  Yeah, you fit in very well in that respect. Mostly I wanna talk about OpenAI.

470
00:31:28,085 --> 00:31:31,965
Speaker 2:  Yeah, there's a lot going on, but I think to me, like what's been

471
00:31:32,165 --> 00:31:35,645
Speaker 2:  interesting is there's been a ton of news the last two weeks and the only

472
00:31:35,645 --> 00:31:39,285
Speaker 2:  thing I can think about is that OpenAI demo, oh my God. 27

473
00:31:39,285 --> 00:31:43,125
Speaker 2:  minutes of just like super awkward OpenAI

474
00:31:43,365 --> 00:31:47,245
Speaker 2:  interactions and I can't stop thinking about it. I don't know. So I'm mostly

475
00:31:47,245 --> 00:31:50,365
Speaker 2:  just curious. You've been covering a OpenAI for a long time. You've been

476
00:31:50,365 --> 00:31:52,485
Speaker 2:  thinking about this company, you've been thinking about AI for a while. You're

477
00:31:52,485 --> 00:31:56,205
Speaker 2:  our senior AI reporter. What did you make of that event? There were all these

478
00:31:56,205 --> 00:31:59,925
Speaker 2:  rumors leading up to this about what OpenAI was gonna do. They did it

479
00:32:00,175 --> 00:32:04,125
Speaker 2:  ahead of Google io. I have to assume deliberately, there were lots of

480
00:32:04,125 --> 00:32:06,725
Speaker 2:  rumors. None of those rumors turned out to be true. This was like this other

481
00:32:06,725 --> 00:32:09,925
Speaker 2:  thing. Like what, where was your head during that event? What were you thinking

482
00:32:09,925 --> 00:32:10,045
Speaker 2:  about?

483
00:32:10,355 --> 00:32:14,285
Speaker 14:  Well, I was really excited for it to be this huge, huge thing.

484
00:32:14,355 --> 00:32:18,205
Speaker 14:  They, they built it up so much. So you know, the rumors were,

485
00:32:18,235 --> 00:32:21,525
Speaker 14:  it's gonna be a search engine that rivals perplexity in Google. It's going

486
00:32:21,525 --> 00:32:25,445
Speaker 14:  to be s GPT five. So when we got s GPT four, oh it's

487
00:32:25,445 --> 00:32:29,125
Speaker 14:  cool. It is how natural this is. It's very sci-fi.

488
00:32:29,465 --> 00:32:33,165
Speaker 14:  But I, I did my first TikTok for The Verge and my

489
00:32:33,325 --> 00:32:37,205
Speaker 14:  takeaway was this is so flirty. Do do we need flirty ai?

490
00:32:37,405 --> 00:32:41,045
Speaker 14:  I don't think so. Just like, you know, not to throw OpenAI completely under

491
00:32:41,045 --> 00:32:44,805
Speaker 14:  the bus. I said the same about X AI's grok. Like do we need a

492
00:32:44,915 --> 00:32:48,645
Speaker 14:  sarcastic snarky ai? I'm not sure. Like

493
00:32:48,755 --> 00:32:51,965
Speaker 14:  yeah, let's get, let's get some other advancements first before it starts

494
00:32:52,525 --> 00:32:56,445
Speaker 14:  being mean and flirty. Some people in the TikTok comments did not agree.

495
00:32:56,445 --> 00:32:59,645
Speaker 14:  These Gen Zers were like, do not take away my, my AI girlfriend please.

496
00:33:00,665 --> 00:33:04,325
Speaker 14:  The announcements. It was interesting. It's not a huge leap forward. I think

497
00:33:04,325 --> 00:33:08,005
Speaker 14:  they definitely wanted to get in front of io. I did talk to the

498
00:33:08,085 --> 00:33:12,005
Speaker 14:  CTO Mira Mirati in a very short briefing after the launch and

499
00:33:12,045 --> 00:33:15,805
Speaker 14:  I asked like, Hey, why today? And she's like, you're asking because of

500
00:33:15,905 --> 00:33:19,405
Speaker 14:  io. And I'm like, well of course. And she said, you know, we didn't even

501
00:33:19,405 --> 00:33:21,325
Speaker 14:  know IO was happening. I'm like, okay,

502
00:33:21,635 --> 00:33:24,605
Speaker 2:  Yeah, cool. I mean that's just, just a lie. That's like not even a good,

503
00:33:25,435 --> 00:33:25,725
Speaker 2:  yeah,

504
00:33:26,585 --> 00:33:30,245
Speaker 14:  I'm like, okay, we're not taking the bait. All right, moving on. But yeah,

505
00:33:30,465 --> 00:33:34,445
Speaker 14:  so it was interesting. Obviously I went to IO and I thought,

506
00:33:34,745 --> 00:33:38,085
Speaker 14:  you know, this stuff is really cool. It was a two hour long keynote. I was

507
00:33:38,085 --> 00:33:41,885
Speaker 14:  there in person. Pretty brutal. But yeah, s GPT

508
00:33:41,885 --> 00:33:45,805
Speaker 14:  4.0, it's cool. It has a long way to go. It kind of feels like the rumors

509
00:33:46,265 --> 00:33:50,085
Speaker 14:  in the AI reporting world is that they had something bigger

510
00:33:50,115 --> 00:33:54,085
Speaker 14:  that wasn't ready in time. So they're like, here's 4.0 Microsoft build

511
00:33:54,105 --> 00:33:57,725
Speaker 14:  is coming up at the end of this month. So I'm kind of

512
00:33:57,725 --> 00:34:00,725
Speaker 14:  expecting something bigger for that. But yeah, it was an interesting demo.

513
00:34:01,065 --> 00:34:01,485
Speaker 14:  Flirty,

514
00:34:01,675 --> 00:34:04,525
Speaker 2:  Talk to me about the flirty thing because I, I confessed, this is the thing

515
00:34:04,525 --> 00:34:06,565
Speaker 2:  I can't stop thinking about. Right. And like you pointed out in the middle

516
00:34:06,565 --> 00:34:10,325
Speaker 2:  of it, like this is just her. And I think Sam Altman even said like

517
00:34:10,725 --> 00:34:14,365
Speaker 2:  referenced her before Mira ti was like, no we're not doing a her thing. Which

518
00:34:14,365 --> 00:34:18,005
Speaker 2:  is like again, obviously not true. Yeah, they're obviously doing a her thing.

519
00:34:18,545 --> 00:34:21,885
Speaker 2:  I'm so torn on this and I'm curious how you're thinking about it. On the

520
00:34:21,885 --> 00:34:25,565
Speaker 2:  one hand, I totally understand why it makes sense for these things to like

521
00:34:25,565 --> 00:34:29,085
Speaker 2:  be fun to talk to. Right. And I don't know if flirty is the correct

522
00:34:29,555 --> 00:34:33,525
Speaker 2:  version of fun to talk to. But again, I think this, this push towards like

523
00:34:33,525 --> 00:34:36,325
Speaker 2:  if you're gonna spend all your time interacting with this thing, it should

524
00:34:36,325 --> 00:34:40,165
Speaker 2:  be enjoyable to interact with and not just some like cold metal robot

525
00:34:40,275 --> 00:34:44,245
Speaker 2:  that you talk to. I totally understand that. I also think that is like a

526
00:34:44,245 --> 00:34:47,965
Speaker 2:  mess. Yeah. And just is for OpenAI and for everybody else will

527
00:34:47,965 --> 00:34:51,365
Speaker 2:  cause as many problems as it solves maybe more

528
00:34:51,865 --> 00:34:55,685
Speaker 2:  and is gonna make all of this really weird before the technology is

529
00:34:55,685 --> 00:34:59,405
Speaker 2:  nearly good enough to actually have any of this work. Like her is a fun

530
00:34:59,405 --> 00:35:03,125
Speaker 2:  example because like she doesn't get basic facts wrong all the time in her.

531
00:35:03,145 --> 00:35:06,845
Speaker 2:  Yes. Like importantly, it's very good technology. Yes. It's not

532
00:35:07,035 --> 00:35:10,925
Speaker 2:  just like flirty Scarlett Johansson but very dumb. Like

533
00:35:10,925 --> 00:35:14,205
Speaker 2:  that's not, that's not what they're doing. And I don't know, I just cannot

534
00:35:14,315 --> 00:35:18,285
Speaker 2:  wrap my head around whether this like 11-year-old movie

535
00:35:18,335 --> 00:35:22,285
Speaker 2:  about a voice assistant is the correct place for us

536
00:35:22,285 --> 00:35:25,965
Speaker 2:  to be going even though I kind of understand why we're going that way. I

537
00:35:25,965 --> 00:35:28,525
Speaker 2:  don't know. And I feel like everybody has had very visceral reactions to

538
00:35:28,525 --> 00:35:30,765
Speaker 2:  it. So I'm curious what, what yours has been.

539
00:35:31,385 --> 00:35:35,085
Speaker 14:  You know, a lot of tech reporters have said like please for the love of

540
00:35:35,085 --> 00:35:39,045
Speaker 14:  God, can these tech executives finish the movies? Like see how it ends,

541
00:35:39,215 --> 00:35:43,045
Speaker 14:  right? Yeah, no, not convinced. We need flirty AI

542
00:35:43,145 --> 00:35:46,765
Speaker 14:  before we have accurate ai. And something I noticed during Google

543
00:35:47,025 --> 00:35:50,245
Speaker 14:  io is that when they were demoing their similar

544
00:35:50,575 --> 00:35:54,285
Speaker 14:  assistance, it was on video, it was not live. And versus

545
00:35:54,395 --> 00:35:58,005
Speaker 14:  open AI's demo was live. So you got to see all the flubs and

546
00:35:58,465 --> 00:36:01,765
Speaker 14:  if the listeners have seen Neli break the

547
00:36:02,585 --> 00:36:03,085
Speaker 14:  AI product,

548
00:36:03,495 --> 00:36:05,805
Speaker 2:  We'll put it in the show notes. It's very good. If, you haven't seen it.

549
00:36:06,035 --> 00:36:08,525
Speaker 14:  It's very good. I was sitting in the press lounge and they came back, they're

550
00:36:08,525 --> 00:36:12,405
Speaker 14:  like, NELI broke it twice. Which is what I expected. That's the goal. Yeah.

551
00:36:12,625 --> 00:36:16,125
Speaker 14:  Yes, exactly. So yeah, flirty AI

552
00:36:16,425 --> 00:36:19,765
Speaker 14:  as a tech reporter, it just makes me like, okay, can we, can we do better

553
00:36:19,765 --> 00:36:23,725
Speaker 14:  than this? I don't wanna completely drag them because it is cool that

554
00:36:23,775 --> 00:36:27,285
Speaker 14:  we're finally getting like a working Siri. I was just thinking before we

555
00:36:27,285 --> 00:36:31,205
Speaker 14:  started this episode, when I use Siri almost exclusively as a timer

556
00:36:31,205 --> 00:36:35,045
Speaker 14:  because it doesn't work for anything else. I do laundry and it's

557
00:36:35,045 --> 00:36:38,645
Speaker 14:  50 minutes every time and it always thinks 15 minutes no matter how hard

558
00:36:38,685 --> 00:36:42,565
Speaker 14:  I try. That's how mostly useless it is. So I have to say 55.

559
00:36:42,755 --> 00:36:46,205
Speaker 14:  Yeah. Yeah. So flirty AI not super useful. Feels

560
00:36:46,205 --> 00:36:49,925
Speaker 14:  purposeful. Obviously MIRIs said, you know, not the case.

561
00:36:50,565 --> 00:36:53,685
Speaker 14:  She said someone else in the audience asked me that. I don't know, I don't

562
00:36:53,685 --> 00:36:56,445
Speaker 14:  know where they're getting that from. It's just sounds so natural. And I'm

563
00:36:56,445 --> 00:36:59,725
Speaker 14:  like, and and then meanwhile Altman is like her on Twitter.

564
00:36:59,725 --> 00:37:01,925
Speaker 2:  Yeah. He just tweeted the word her, didn't he? Yes

565
00:37:02,025 --> 00:37:05,685
Speaker 14:  He did. Yeah. So, and he said, I've been at, I think it was a

566
00:37:05,685 --> 00:37:08,485
Speaker 14:  Dreamforce or something at a conference and he said her was his favorite

567
00:37:08,495 --> 00:37:11,565
Speaker 14:  movie and all his tech reporters were like, noted.

568
00:37:12,305 --> 00:37:16,085
Speaker 14:  So yeah, I think they're trying to inch towards that reality. I don't know,

569
00:37:16,365 --> 00:37:18,685
Speaker 14:  I feel a bunch of different ways about it. What, what were you thinking

570
00:37:18,685 --> 00:37:19,765
Speaker 14:  when you saw it?

571
00:37:20,285 --> 00:37:24,045
Speaker 2:  I thought it was really impressive and I, I just keep coming back to

572
00:37:24,045 --> 00:37:27,805
Speaker 2:  like the immediate reaction. Everybody had to chat s GPT,

573
00:37:27,855 --> 00:37:31,805
Speaker 2:  which is like, I can't believe it's this good. Which is yes,

574
00:37:32,115 --> 00:37:35,845
Speaker 2:  both a compliment and an insult. Right? Like it's not very good. Yes. But

575
00:37:35,845 --> 00:37:39,805
Speaker 2:  it is genuinely impressive that it is as good as it is. Yes. And I feel like

576
00:37:40,205 --> 00:37:43,205
Speaker 2:  I, I've spent a lot of time reporting on AI in the last year and a half and

577
00:37:43,265 --> 00:37:47,205
Speaker 2:  trying to constantly calibrate that, that it's impressive that it's

578
00:37:47,205 --> 00:37:50,925
Speaker 2:  as good as it is and it's also not very good. Like both of those things

579
00:37:51,065 --> 00:37:54,805
Speaker 2:  are true. And it is so hard to hold both of the idea, both of those

580
00:37:54,805 --> 00:37:58,445
Speaker 2:  ideas in your head at the same time. And this to me was like that too. Like

581
00:37:58,485 --> 00:38:01,605
Speaker 2:  I actually went back and watched, it's like a 26 minute video. Everybody

582
00:38:01,605 --> 00:38:05,365
Speaker 2:  should watch it. It's, it's weird and awkward and delightful, but it's

583
00:38:05,725 --> 00:38:09,445
Speaker 2:  actually like, it screws up a lot like a lot in the demo. And again

584
00:38:09,445 --> 00:38:12,245
Speaker 2:  that's like, it's fine. This is new early technology, they're having fun.

585
00:38:12,275 --> 00:38:15,205
Speaker 2:  This is not, they didn't promise that it was perfect. They just sort of showed

586
00:38:15,225 --> 00:38:18,325
Speaker 2:  how it worked. But it screwed up a lot and nobody talked about it. Right?

587
00:38:18,325 --> 00:38:21,925
Speaker 2:  Everybody came to the end of that thing and all over the internet, the immediate

588
00:38:22,245 --> 00:38:26,005
Speaker 2:  reaction was basically like OpenAI just destroyed all of the

589
00:38:26,105 --> 00:38:29,765
Speaker 2:  AI competitors forever. It is leaps and bounds ahead of everybody else.

590
00:38:30,355 --> 00:38:34,205
Speaker 2:  This is the only thing that there is forever and ever. And I just don't

591
00:38:34,335 --> 00:38:38,165
Speaker 2:  think that's true. Like it's cool and it, it, it's a good

592
00:38:38,195 --> 00:38:42,165
Speaker 2:  demo and the fact that it feels it all like a person and does

593
00:38:42,495 --> 00:38:46,405
Speaker 2:  convincing, sounding like ums and laughs and yes. What

594
00:38:46,405 --> 00:38:50,325
Speaker 2:  was it he showed the like I iHeart Yeah. s GPT four. Oh. And

595
00:38:50,325 --> 00:38:54,125
Speaker 2:  it was like, oh that's so sweet. Like yeah. That is both impressive

596
00:38:54,185 --> 00:38:56,725
Speaker 2:  and nothing simultaneously. Exactly.

597
00:38:57,195 --> 00:39:00,885
Speaker 14:  Exactly. I think a really good example of that too, it's like an

598
00:39:00,945 --> 00:39:04,845
Speaker 14:  OpenAI effect is with soa people are like, this has just put all

599
00:39:04,845 --> 00:39:08,325
Speaker 14:  of these text to video AI companies out of business and people like to say

600
00:39:08,325 --> 00:39:12,285
Speaker 14:  they launched it, but neither of us can use it. None. It's still in demo

601
00:39:12,395 --> 00:39:16,045
Speaker 14:  mode. So you know, people are like, wow, OpenAI destroyed everyone. It's,

602
00:39:16,145 --> 00:39:19,885
Speaker 14:  you know, this technology is not even out yet and clearly it

603
00:39:19,945 --> 00:39:23,685
Speaker 14:  has a long way to go when you see it breaking in demos. So yes,

604
00:39:23,755 --> 00:39:27,725
Speaker 14:  it's very hard to hold both of those at the same time. And day nine at The

605
00:39:27,845 --> 00:39:29,725
Speaker 14:  Verge, I'm still figuring out how to balance that.

606
00:39:30,075 --> 00:39:33,165
Speaker 2:  It's, it's tough and I'm curious, I think the SOA thing is actually an interesting

607
00:39:33,165 --> 00:39:37,125
Speaker 2:  example because OpenAI was perceived to have this big lead, right? Like

608
00:39:37,125 --> 00:39:40,085
Speaker 2:  it, it kicked off a lot of this stuff with Chat s GPT, it has been the company

609
00:39:40,105 --> 00:39:43,885
Speaker 2:  we have talked about the most as we talk about ai. But now, like you said,

610
00:39:43,885 --> 00:39:46,645
Speaker 2:  we're in developer conference season, Google just announced, I would say

611
00:39:46,645 --> 00:39:50,445
Speaker 2:  in a significant lead, more polished and less interesting

612
00:39:50,465 --> 00:39:54,285
Speaker 2:  way. Yeah. A lot of the same stuff that OpenAI and Chat s

613
00:39:54,305 --> 00:39:58,125
Speaker 2:  GPT have been doing for a while. Microsoft today, as you're hearing this,

614
00:39:58,305 --> 00:40:01,285
Speaker 2:  is presumably gonna launch some of the same stuff potentially with its own

615
00:40:01,285 --> 00:40:04,725
Speaker 2:  technology. Apple is likely to do some of the same stuff potentially with

616
00:40:04,865 --> 00:40:08,205
Speaker 2:  OpenAI and Thro is out here doing stuff. There's just a million competitors

617
00:40:08,205 --> 00:40:10,925
Speaker 2:  now. So I feel like, one thing I've been thinking about and I'm, I'm curious

618
00:40:11,105 --> 00:40:14,885
Speaker 2:  how you are thinking about this as you like try to sort of map out this

619
00:40:14,885 --> 00:40:18,765
Speaker 2:  space in your mind. Like where is OpenAI in the

620
00:40:18,905 --> 00:40:22,245
Speaker 2:  AI world right now? Is it still winning the race? Does it feel like

621
00:40:22,665 --> 00:40:24,405
Speaker 14:  In the hype perhaps Fair?

622
00:40:24,435 --> 00:40:24,725
Speaker 2:  Yeah,

623
00:40:24,955 --> 00:40:28,405
Speaker 14:  They get, they get a lot of hype, rightfully so. They do deliver a lot of

624
00:40:28,715 --> 00:40:32,525
Speaker 14:  mind bending sci-fi kind of stuff. And that's part of why I joined this

625
00:40:32,525 --> 00:40:35,805
Speaker 14:  beat. 'cause wow, I, you know, I loved reading sci-fi books. This is all

626
00:40:35,805 --> 00:40:39,725
Speaker 14:  very weird and fun. Totally. I was speaking to someone at a major AI

627
00:40:39,725 --> 00:40:42,925
Speaker 14:  company who said that essentially everyone's just you this year, you're

628
00:40:42,925 --> 00:40:46,325
Speaker 14:  just gonna see them leapfrog over each other as they all go towards the

629
00:40:46,325 --> 00:40:50,165
Speaker 14:  same thing. You know, they're all sort of training models in the same

630
00:40:50,185 --> 00:40:54,045
Speaker 14:  way. They're all trying to deliver the same products. So it's

631
00:40:54,045 --> 00:40:57,685
Speaker 14:  hard to say like, tomorrow things can change this, this

632
00:40:57,755 --> 00:41:01,645
Speaker 14:  beat, this technology moves so fast. I felt this way when Sora

633
00:41:01,645 --> 00:41:05,525
Speaker 14:  came out because I had just interviewed the CEO of Runway for

634
00:41:05,525 --> 00:41:05,885
Speaker 14:  a piece.

635
00:41:06,065 --> 00:41:06,645
Speaker 2:  What's Runway?

636
00:41:06,985 --> 00:41:10,805
Speaker 14:  Runway is a text to video startup, AI

637
00:41:10,805 --> 00:41:14,565
Speaker 14:  generative startup. And they helped create everything

638
00:41:14,565 --> 00:41:18,445
Speaker 14:  everywhere all at once. So some of the AI tech was used in that. So

639
00:41:18,445 --> 00:41:21,365
Speaker 14:  they're a very cool company and I thought when I saw their demo, this is

640
00:41:22,085 --> 00:41:25,805
Speaker 14:  Sci-Fi and cool. But then SOA came out and I was like, oh my god,

641
00:41:25,805 --> 00:41:29,005
Speaker 14:  this is crazy. And I sent it to the runway CEO and he was like, welcome

642
00:41:29,145 --> 00:41:32,725
Speaker 14:  to our world. Like things change so quickly every day.

643
00:41:33,585 --> 00:41:37,525
Speaker 14:  So who, how is AI in the race? Like where are they in the, in the

644
00:41:37,525 --> 00:41:41,445
Speaker 14:  race there's still leaps and bounds ahead of maybe you know,

645
00:41:41,445 --> 00:41:44,965
Speaker 14:  someone like Amazon. But things can change at any point

646
00:41:45,365 --> 00:41:47,645
Speaker 14:  and I think we're gonna see that a lot this year. Yeah,

647
00:41:47,725 --> 00:41:51,525
Speaker 2:  I do. I've come to think that that is why it's so chaotic

648
00:41:51,745 --> 00:41:55,645
Speaker 2:  is because there is this sense that this is like a land grab moment and

649
00:41:55,675 --> 00:41:59,485
Speaker 2:  it's all happening so fast that you actually still kind of can

650
00:41:59,485 --> 00:42:03,085
Speaker 2:  catch up. Like I, I remember a year ago hearing stories from people that

651
00:42:03,085 --> 00:42:05,605
Speaker 2:  were like, oh only a few companies are gonna be able to do this training

652
00:42:05,605 --> 00:42:08,165
Speaker 2:  the models is so expensive and so hard it's not gonna work. Yeah. And I think

653
00:42:08,165 --> 00:42:11,965
Speaker 2:  there's some truth to that, but also there is so much open

654
00:42:12,015 --> 00:42:15,845
Speaker 2:  space in this market right now and there's so much money in it that it feels

655
00:42:15,845 --> 00:42:19,485
Speaker 2:  like we're probably at least a couple of years away from any of this feeling

656
00:42:19,665 --> 00:42:22,845
Speaker 2:  at all settled. And so if you're a company that is like, we wanna find a

657
00:42:22,845 --> 00:42:25,805
Speaker 2:  place to make a lot of money very quickly and we kind of think we can win

658
00:42:25,805 --> 00:42:29,445
Speaker 2:  because no one really has yet. Yeah. This is probably the place to do it

659
00:42:29,825 --> 00:42:30,845
Speaker 2:  for better and for worse.

660
00:42:30,975 --> 00:42:32,765
Speaker 14:  Definitely. I agree. So

661
00:42:32,765 --> 00:42:36,125
Speaker 2:  You mentioned all of these companies sort of working towards the same thing

662
00:42:36,125 --> 00:42:38,965
Speaker 2:  like that the, the North Star is coming into view. What do you feel like

663
00:42:38,965 --> 00:42:41,165
Speaker 2:  that thing is that everybody has pointed towards,

664
00:42:41,545 --> 00:42:45,405
Speaker 14:  You know, as an avid Vergecast, a fan and listener, I've been hearing

665
00:42:45,665 --> 00:42:49,565
Speaker 14:  you talk about hardware in your ears and I think

666
00:42:49,565 --> 00:42:52,845
Speaker 14:  it was Meta a scoop came out from the information about Meta doing like

667
00:42:52,845 --> 00:42:56,645
Speaker 14:  headphones or ai. Yes. I thought I was at

668
00:42:56,805 --> 00:43:00,485
Speaker 14:  a south by party and we were going around asking questions about technology

669
00:43:00,545 --> 00:43:03,645
Speaker 14:  and something I said that's way ahead of its time is hardware, like this

670
00:43:03,825 --> 00:43:07,605
Speaker 14:  AI hardware. Which turned out to be true. That was a couple months before

671
00:43:07,605 --> 00:43:10,845
Speaker 14:  we saw the R one and the humane pin. Something that was really shocking

672
00:43:10,845 --> 00:43:14,605
Speaker 14:  to me as I joined this beat is how much these AI companies are

673
00:43:14,605 --> 00:43:18,405
Speaker 14:  investing in robotics and bringing this AI into like a physical plane. 'cause

674
00:43:18,405 --> 00:43:21,805
Speaker 14:  I thought that that's way off. We're not gonna be there anytime soon. But

675
00:43:21,805 --> 00:43:25,405
Speaker 14:  they're seemingly investing quite hard into

676
00:43:25,715 --> 00:43:29,125
Speaker 14:  like you, you have the Ray Band meta, the Meta Ray bands. It looks like

677
00:43:29,225 --> 00:43:32,765
Speaker 14:  Sam Altman is doing something with Love from, which is Johnny

678
00:43:32,995 --> 00:43:36,725
Speaker 14:  Ives startup. So where is this headed? I think we're gonna see more of those

679
00:43:36,725 --> 00:43:39,925
Speaker 14:  conversational AI assistance we have

680
00:43:40,475 --> 00:43:44,245
Speaker 14:  what we saw at Google io. I would kind of love this world where

681
00:43:44,395 --> 00:43:47,205
Speaker 14:  AI's doing everything for me. 'cause I have too many emails and too many

682
00:43:47,205 --> 00:43:50,605
Speaker 14:  notifications, but I'm also pretty torn on how they're using

683
00:43:51,065 --> 00:43:54,685
Speaker 14:  my data. Yeah. Obviously. But yeah, so I think we're gonna see

684
00:43:54,795 --> 00:43:57,965
Speaker 14:  more advances in in hardware. I'm

685
00:43:57,965 --> 00:44:00,485
Speaker 2:  So surprised to hear you say you think hardware is the thing. Like it's,

686
00:44:00,545 --> 00:44:04,125
Speaker 2:  it is music to my gadget loving years. But like

687
00:44:04,475 --> 00:44:08,285
Speaker 2:  I've been wondering at this moment after Humane

688
00:44:08,285 --> 00:44:11,605
Speaker 2:  failed so badly and Rabbit failed so badly and like those companies aren't

689
00:44:11,605 --> 00:44:14,965
Speaker 2:  dead and this stuff moves fast. Yes. And like the My Rabbit R one updates

690
00:44:14,965 --> 00:44:18,925
Speaker 2:  like every other day at this point and it's ridiculous. But that one

691
00:44:18,935 --> 00:44:22,725
Speaker 2:  particular version of that kind of thing is just clearly not

692
00:44:22,735 --> 00:44:26,365
Speaker 2:  gonna work. Right? Yes. And I think it was very telling to me that that OpenAI

693
00:44:26,365 --> 00:44:29,765
Speaker 2:  demo, they're just sitting there talking into a phone. Yes. And I, I saw

694
00:44:29,765 --> 00:44:33,645
Speaker 2:  a bunch of people pointing that out out that like, this is actually the

695
00:44:33,645 --> 00:44:36,685
Speaker 2:  way that we do this is we sit here and I hold my phone in my hand and I talk

696
00:44:36,685 --> 00:44:40,525
Speaker 2:  to it. And that is the interface for AI that we are doing right now. And

697
00:44:41,165 --> 00:44:44,485
Speaker 2:  I have a lot of theories about why that's not the case forever. But I did

698
00:44:44,485 --> 00:44:47,965
Speaker 2:  kind of wonder like, are we, are we gonna put off the stream for five years

699
00:44:48,745 --> 00:44:52,325
Speaker 2:  in order to let some of that stuff get better and then we'll worry about

700
00:44:52,325 --> 00:44:54,445
Speaker 2:  the hardware because phones are great and they'll get us where we need to

701
00:44:54,445 --> 00:44:58,325
Speaker 2:  go. But I have to say, I find it's very exciting to me that these companies

702
00:44:58,325 --> 00:45:02,245
Speaker 2:  are still buying into the idea that hardware is part of

703
00:45:02,245 --> 00:45:05,085
Speaker 2:  the equation. If maybe not the whole thing. At least not for now.

704
00:45:05,505 --> 00:45:09,405
Speaker 14:  See this is where you, you know a lot about this, but I

705
00:45:09,405 --> 00:45:12,325
Speaker 14:  was surprised obviously that they're doing anything in hardware that they

706
00:45:12,335 --> 00:45:16,125
Speaker 14:  still think that this is the case because the humane pin and the R one

707
00:45:16,345 --> 00:45:19,885
Speaker 14:  as nifty as they seem to be, I, I kind of think they're just

708
00:45:20,045 --> 00:45:24,005
Speaker 14:  destined to be in drawers collecting dust and not really the next big thing.

709
00:45:24,105 --> 00:45:27,645
Speaker 14:  But Yep. I'm wondering If, you have any tinfoil hat theories about it being

710
00:45:27,645 --> 00:45:31,405
Speaker 14:  an iPhone on stage? 'cause I thought, you know, there is for, for the listener,

711
00:45:31,405 --> 00:45:35,245
Speaker 14:  there's reports that OpenAI and Apple are gonna do this deal where

712
00:45:35,315 --> 00:45:39,125
Speaker 14:  chat s GPT is integrated into the iPhone, which everyone's like, oh my God,

713
00:45:39,155 --> 00:45:42,805
Speaker 14:  once again Siri might work. That could be great. I do see the future

714
00:45:43,435 --> 00:45:47,205
Speaker 14:  just, I mean who, who doesn't wanna just carry their iPhone instead of multiple

715
00:45:47,205 --> 00:45:50,805
Speaker 14:  devices? Like you've mentioned, when I say hardware, just as you've

716
00:45:50,915 --> 00:45:54,885
Speaker 14:  said on The, Vergecast headphones, glasses, I think you said you're

717
00:45:54,885 --> 00:45:58,045
Speaker 14:  not into the glasses idea. I wear glasses, so seems perfect to me.

718
00:45:58,285 --> 00:46:02,205
Speaker 2:  I think If, you wear glasses, it is like a perfect obvious place to

719
00:46:02,205 --> 00:46:06,165
Speaker 2:  go for me. Like I have the, I have the Meta ray band glasses and my

720
00:46:06,165 --> 00:46:09,045
Speaker 2:  problem is, I don't know how long it takes, this is just gonna be, David

721
00:46:09,365 --> 00:46:13,085
Speaker 2:  complains about wearing glasses for a minute. But my problem is how long

722
00:46:13,085 --> 00:46:15,925
Speaker 2:  does it take to wear glasses before you stop noticing that you're wearing

723
00:46:15,925 --> 00:46:18,765
Speaker 2:  glasses? Because I have these, they have like, they have clear lenses, they're

724
00:46:18,765 --> 00:46:21,325
Speaker 2:  transitions, they're actually really useful. I like having a mom all day,

725
00:46:21,385 --> 00:46:24,685
Speaker 2:  but I never stop noticing that I'm wearing glasses and it drives me kind

726
00:46:24,685 --> 00:46:27,525
Speaker 2:  of nuts. And part of that is 'cause they're heavy. But part of that I think

727
00:46:27,525 --> 00:46:30,365
Speaker 2:  is also just like, it's going to be hard to convince people who don't wear

728
00:46:30,365 --> 00:46:31,685
Speaker 2:  glasses to wear glasses.

729
00:46:31,955 --> 00:46:32,245
Speaker 14:  Sure.

730
00:46:32,345 --> 00:46:34,685
Speaker 2:  But maybe I just need to wear them longer. Like do I just need to put these

731
00:46:34,685 --> 00:46:37,005
Speaker 2:  on for three days and I'll get used to it? Well

732
00:46:37,005 --> 00:46:40,885
Speaker 14:  It's taken me about 20 years of wearing glasses to

733
00:46:41,005 --> 00:46:44,965
Speaker 14:  be fair. So I don't even notice them on my face. But Well the

734
00:46:44,965 --> 00:46:48,845
Speaker 14:  answer to that is if meta makes this earbud push, I don't know, If you read

735
00:46:48,845 --> 00:46:51,325
Speaker 14:  the article, but they're still working out some of the kinks reportedly,

736
00:46:51,395 --> 00:46:51,685
Speaker 14:  well

737
00:46:51,765 --> 00:46:54,605
Speaker 2:  'cause it was earbuds with cameras in them, right? Yeah. Which is just the

738
00:46:54,605 --> 00:46:55,885
Speaker 2:  wildest idea. But

739
00:46:55,885 --> 00:46:58,925
Speaker 14:  You feel like they're like found out that If, you have long hair, the cameras

740
00:46:59,185 --> 00:47:03,045
Speaker 14:  are gonna be covered because obviously, and one of my favorite parts

741
00:47:03,065 --> 00:47:06,565
Speaker 14:  is that they're figuring out how to stop it from being too hot, which is,

742
00:47:06,885 --> 00:47:09,885
Speaker 14:  I think something that was experienced with the, the humane pin is that

743
00:47:09,885 --> 00:47:13,285
Speaker 14:  people were like, this is getting really hot. So, you know, catching fire

744
00:47:13,305 --> 00:47:16,325
Speaker 14:  in your ears doesn't sound like a great product. I hope they work that out,

745
00:47:16,325 --> 00:47:18,285
Speaker 14:  especially for you since you can't wear glasses.

746
00:47:18,835 --> 00:47:21,845
Speaker 2:  Yeah. I'm bullish on the idea of headphones being the next thing. Yeah. But

747
00:47:21,845 --> 00:47:24,925
Speaker 2:  again, it's partly just as a, as a conduit to your phone, which I think works

748
00:47:24,925 --> 00:47:28,125
Speaker 2:  fine. Exactly. I wanna go back to your point about the iPhone because one

749
00:47:28,125 --> 00:47:31,605
Speaker 2:  of the things that OpenAI, I think this was Sam Altman who said it,

750
00:47:31,995 --> 00:47:35,885
Speaker 2:  that there's a new chat s GPT app for the Mac. And there were a lot

751
00:47:35,885 --> 00:47:39,325
Speaker 2:  of people who I would say reasonably asked, where's the Windows app?

752
00:47:39,965 --> 00:47:42,765
Speaker 2:  Microsoft owns an enormous percentage of your company. You have been partners

753
00:47:42,765 --> 00:47:46,685
Speaker 2:  with them for forever. Like, what the hell? And I think it was

754
00:47:46,745 --> 00:47:50,165
Speaker 2:  Sam, right? Who just said sort of offhandedly like, oh, Mac is just where

755
00:47:50,165 --> 00:47:53,805
Speaker 2:  our users are. Yeah. And then there's an iPhone on stage and it's like, how

756
00:47:53,805 --> 00:47:57,325
Speaker 2:  many conspiracy theories should I read into Yes. Those two facts You tell

757
00:47:57,325 --> 00:47:57,485
Speaker 2:  me.

758
00:47:57,905 --> 00:48:01,445
Speaker 14:  You know, okay. My, my tinfoil hat is that there's beef, I've been told

759
00:48:01,445 --> 00:48:04,925
Speaker 14:  that it's not necessarily true, not by anyone, like just from

760
00:48:05,205 --> 00:48:08,605
Speaker 14:  coworkers from Tom. Tom was like, I have opinions about this, but

761
00:48:10,365 --> 00:48:14,125
Speaker 14:  I just think that there's beef. I I was covering OpenAI during

762
00:48:14,145 --> 00:48:17,965
Speaker 14:  the, the Ouster, the meltdown, and I'm just imagining Satya during

763
00:48:17,985 --> 00:48:21,445
Speaker 14:  his Thanksgiving week, like, dammit, like, why do I have to deal with this?

764
00:48:21,445 --> 00:48:24,685
Speaker 14:  He's on Pivot, he's on like CNBC.

765
00:48:25,305 --> 00:48:29,125
Speaker 14:  So I think what we are, we're seeing with inflection, them

766
00:48:29,325 --> 00:48:33,125
Speaker 14:  bringing in inflection, it seems like there's sort of this potential

767
00:48:33,125 --> 00:48:36,885
Speaker 14:  Apple deal that it feels like there's this decoupling because both are

768
00:48:36,885 --> 00:48:40,485
Speaker 14:  realizing that they've relied so much on the other, and that it's like a

769
00:48:40,875 --> 00:48:44,285
Speaker 14:  codependent relationship. They're like, maybe we should take some time apart

770
00:48:44,425 --> 00:48:47,965
Speaker 14:  is where I see this going, especially with the iPhone on stage, the Mac

771
00:48:48,065 --> 00:48:51,605
Speaker 14:  app. It feels like there's a lot of signs, but that's just my like tinfoil

772
00:48:51,665 --> 00:48:52,445
Speaker 14:  hat for now.

773
00:48:52,885 --> 00:48:56,645
Speaker 2:  I do think it is generally true that companies do that kind of stuff

774
00:48:56,665 --> 00:48:59,845
Speaker 2:  on purpose, I think is is a thing that I have learned over the years is that

775
00:48:59,845 --> 00:49:02,965
Speaker 2:  you, you wanna just think, oh, they just like brought up their phone and

776
00:49:02,965 --> 00:49:05,885
Speaker 2:  did it. And it's like, no. Even the stuff that looks like it's not thought

777
00:49:05,885 --> 00:49:09,405
Speaker 2:  through and rehearsed is usually pretty thought through and rehearsed and

778
00:49:09,405 --> 00:49:13,285
Speaker 2:  is not an accident. And exactly. There was a conversation about what

779
00:49:13,285 --> 00:49:16,645
Speaker 2:  phone they would use for that demo. I'm very confident about that fact. And

780
00:49:16,645 --> 00:49:19,765
Speaker 2:  I think, I mean, to your point, like part of the reason I find this space

781
00:49:19,785 --> 00:49:22,605
Speaker 2:  so fascinating right now is it feels like that uncoupling you're talking

782
00:49:22,605 --> 00:49:26,125
Speaker 2:  about is literally happening like right now in real time at Insane

783
00:49:26,585 --> 00:49:30,485
Speaker 2:  Speeds. Yes. Like between Google IO and WWDC,

784
00:49:30,575 --> 00:49:34,405
Speaker 2:  which is essentially what, like four weeks, we are going to potentially

785
00:49:34,405 --> 00:49:38,005
Speaker 2:  like completely upend the economics of the AI industry.

786
00:49:38,225 --> 00:49:42,125
Speaker 2:  It it like insane, like you think about what the Google search deal

787
00:49:42,545 --> 00:49:45,365
Speaker 2:  has done for Apple and all the regulatory stuff that, that has causing the

788
00:49:45,365 --> 00:49:48,805
Speaker 2:  amount of money that changes hands. And like If, you put something like that

789
00:49:48,995 --> 00:49:52,605
Speaker 2:  into the iPhone through OpenAI, it blows up that whole industry in a crazy

790
00:49:52,605 --> 00:49:55,485
Speaker 2:  way. Or if they just like randomly pick Anthropic, which to me is the most

791
00:49:55,955 --> 00:49:58,285
Speaker 2:  chaotic answer and I would love for that to happen.

792
00:49:58,285 --> 00:49:59,805
Speaker 14:  Delicious. Yes. Just

793
00:49:59,825 --> 00:50:03,525
Speaker 2:  Go open source, be like we went with Meta, we, we did Llama like Apple

794
00:50:03,635 --> 00:50:07,445
Speaker 2:  Siri powered by Llama and just blow up the world. It'd be amazing. But it

795
00:50:07,445 --> 00:50:11,245
Speaker 2:  just feels like all of this was starting not to settle,

796
00:50:11,385 --> 00:50:14,605
Speaker 2:  but to sort of be understandable. You kind of knew where everybody was and

797
00:50:14,605 --> 00:50:18,445
Speaker 2:  what they were working on. And now it feels like between all these relationships

798
00:50:18,465 --> 00:50:22,325
Speaker 2:  and I think especially with Apple, kind of, all of the balls are up in the

799
00:50:22,325 --> 00:50:23,805
Speaker 2:  air again, in a really interesting way.

800
00:50:24,185 --> 00:50:27,965
Speaker 14:  Yes. And something I've been thinking about a lot is sometimes these

801
00:50:28,065 --> 00:50:31,565
Speaker 14:  AI researchers are like, we're building s GPT five. And it's hard to predict

802
00:50:31,565 --> 00:50:34,925
Speaker 14:  what it's gonna do. It's hard to predict what any of this is gonna do. And

803
00:50:34,945 --> 00:50:38,525
Speaker 14:  that's strange as a reporter and just a human in this world. Like,

804
00:50:38,865 --> 00:50:42,045
Speaker 14:  we don't know how this is going to change our lives at any point. Do

805
00:50:42,045 --> 00:50:45,765
Speaker 2:  You think that's part of why they're leaning in on the like

806
00:50:45,785 --> 00:50:49,725
Speaker 2:  flirty personality side of it? Because if it's, if it's delightful, you don't,

807
00:50:49,865 --> 00:50:53,765
Speaker 2:  it doesn't matter that like, yes, having fun with it becomes the

808
00:50:53,765 --> 00:50:57,045
Speaker 2:  point and not the, is it any good at tasks, which is what they wanna get

809
00:50:57,045 --> 00:50:57,565
Speaker 2:  to eventually.

810
00:50:57,955 --> 00:51:01,725
Speaker 14:  I've heard this point before and you know, starting as an AI reporter, people

811
00:51:01,755 --> 00:51:05,525
Speaker 14:  told me not to anthropomorphize the the

812
00:51:05,525 --> 00:51:09,365
Speaker 14:  technology because then it takes the blame off the company

813
00:51:09,425 --> 00:51:13,325
Speaker 14:  and they can blame the ai. So I'm so cognizant of that as I report

814
00:51:13,385 --> 00:51:16,245
Speaker 14:  and then they come out with Flirty AI and it's like,

815
00:51:17,795 --> 00:51:21,605
Speaker 14:  like I'm confused because I think OpenAI also said at some points,

816
00:51:21,665 --> 00:51:25,605
Speaker 14:  you know, it's tech, it's not human. And we saw that

817
00:51:25,605 --> 00:51:29,245
Speaker 14:  with the Google guy who was like, this is real and it's human and

818
00:51:29,665 --> 00:51:33,605
Speaker 14:  you know, so you know, to see all of that and

819
00:51:33,605 --> 00:51:37,565
Speaker 14:  then go, here's your flirty AI girlfriend, like her, it feels

820
00:51:37,565 --> 00:51:41,245
Speaker 14:  strange. But yes, I do think it's an interesting

821
00:51:41,885 --> 00:51:45,765
Speaker 14:  critique to have, like, look over here, this is fun. Don't pay attention

822
00:51:45,765 --> 00:51:48,885
Speaker 14:  to how it barely works, I think is part of the point.

823
00:51:49,235 --> 00:51:53,165
Speaker 2:  Yeah, I, I agree. I will say by the way, that The new York Times has cornered

824
00:51:53,165 --> 00:51:56,365
Speaker 2:  the horny AI beat, so we're gonna have to find, we have to find something

825
00:51:56,365 --> 00:51:59,645
Speaker 2:  else for you to do. I'm really sorry you just, you were too late to the game

826
00:51:59,665 --> 00:52:02,285
Speaker 2:  for the horny AI beat. It's just you can't have it.

827
00:52:02,645 --> 00:52:05,485
Speaker 14:  I was wondering if I could say this on The Vergecast. I, this is a huge

828
00:52:05,485 --> 00:52:09,165
Speaker 14:  day for Kevin Rus. I forgot to message him about it. Yes. He's gonna have

829
00:52:09,165 --> 00:52:10,805
Speaker 14:  10 more girlfriends by the time we finish this.

830
00:52:11,695 --> 00:52:14,805
Speaker 2:  Kevin Rus vindicated every day just gets better and better to be Kevin Rus.

831
00:52:15,055 --> 00:52:18,605
Speaker 2:  Kevin, we love you. Come on The Verge cast. One more thing before I let you

832
00:52:18,605 --> 00:52:22,565
Speaker 2:  go. You mentioned the, the brief Sam Ouster and the one

833
00:52:22,565 --> 00:52:26,245
Speaker 2:  other bit of OpenAI News last week was that Ilya

834
00:52:26,395 --> 00:52:29,605
Speaker 2:  Suki, who was a big part of that story is leaving

835
00:52:30,265 --> 00:52:33,205
Speaker 2:  OpenAI for Good. What do you, what do you make of that story? What do you

836
00:52:33,205 --> 00:52:34,485
Speaker 2:  know about what's going on there? Oh

837
00:52:34,485 --> 00:52:38,125
Speaker 14:  My God, that was about 4:00 PM while I was at Google io and I was like,

838
00:52:38,125 --> 00:52:41,485
Speaker 14:  oh my God. Oh no, no more news. Please. Yeah,

839
00:52:41,835 --> 00:52:45,685
Speaker 14:  that seemed to have caused other people to leave OpenAI as

840
00:52:45,685 --> 00:52:48,965
Speaker 14:  well. The sort of IA cult inside of OpenAI.

841
00:52:49,725 --> 00:52:53,445
Speaker 14:  I don't know, I think I'm really hoping we get some fun

842
00:52:53,445 --> 00:52:57,365
Speaker 14:  discovery maybe from the XAI lawsuit against them to figure out

843
00:52:57,435 --> 00:53:01,405
Speaker 14:  what went down. Not to be totally off course, but when the

844
00:53:01,405 --> 00:53:04,565
Speaker 14:  government is deciding to ban TikTok and everyone's like, where's the receipts?

845
00:53:04,795 --> 00:53:08,645
Speaker 14:  What, what happened? Similarly here, what is happening at

846
00:53:08,745 --> 00:53:12,165
Speaker 14:  OpenAI that caused all this drama and now Ilya is leaving and

847
00:53:12,665 --> 00:53:16,565
Speaker 14:  it all feels very strange. My thoughts are we need

848
00:53:16,765 --> 00:53:20,205
Speaker 14:  a lot more information. I think that is sort of owed

849
00:53:20,625 --> 00:53:24,445
Speaker 14:  as this changes people's lives and how they interact with technology.

850
00:53:25,185 --> 00:53:29,085
Speaker 14:  The meme is what, what does Ilya know? Where is Ilya? I think

851
00:53:29,145 --> 00:53:32,245
Speaker 14:  we deserve some answers there. I don't think we're gonna get them from OpenAI.

852
00:53:32,245 --> 00:53:36,005
Speaker 14:  We're gonna get them from great AI reporters who dig into it. But

853
00:53:36,715 --> 00:53:38,085
Speaker 14:  it's strange. It's really strange.

854
00:53:38,445 --> 00:53:42,285
Speaker 2:  I mean, I, I would think the, the most simple way to read it is

855
00:53:42,285 --> 00:53:46,125
Speaker 2:  that that divide that everyone sort of ascribed

856
00:53:46,385 --> 00:53:50,205
Speaker 2:  the issues to but then kind of waved off was the like doing

857
00:53:50,545 --> 00:53:54,325
Speaker 2:  AI for good versus doing AI for profit. The fact that not only did

858
00:53:54,625 --> 00:53:58,365
Speaker 2:  IA leave, but then a bunch of people, like you said in the IA cult

859
00:53:58,435 --> 00:54:02,205
Speaker 2:  also left suggest to me that that divide or whatever the

860
00:54:02,205 --> 00:54:05,845
Speaker 2:  divide was still exists. And there was some reporting that said

861
00:54:05,915 --> 00:54:09,685
Speaker 2:  Ilya basically never came back to work after all of this. And so it, it,

862
00:54:09,685 --> 00:54:13,485
Speaker 2:  it, it definitely suggests to me that whatever happened last fall is

863
00:54:13,505 --> 00:54:17,005
Speaker 2:  not done happening. Like Sam won in whatever that looks like.

864
00:54:17,625 --> 00:54:21,405
Speaker 2:  But whatever is going on inside of that company seems to still be going on

865
00:54:21,405 --> 00:54:22,165
Speaker 2:  inside of that company.

866
00:54:22,845 --> 00:54:26,685
Speaker 14:  I agree. I think that Rift is still there. The reporting suggests that

867
00:54:26,825 --> 00:54:30,645
Speaker 14:  it was like what EAC versus the Decels people who want this to

868
00:54:30,645 --> 00:54:34,485
Speaker 14:  move fast and people who want this to be a research lab that's

869
00:54:34,485 --> 00:54:37,645
Speaker 14:  for good. I think that Rift is still there and I think that's something

870
00:54:37,645 --> 00:54:41,445
Speaker 14:  you're gonna continue to see in this AI race. I think

871
00:54:41,465 --> 00:54:45,045
Speaker 14:  the people who wanna make money are gonna continue coming out on top as

872
00:54:45,045 --> 00:54:45,765
Speaker 14:  we see here though.

873
00:54:45,995 --> 00:54:49,485
Speaker 2:  Yeah, the, I mean as of right now, I think just thinking about Google io,

874
00:54:49,515 --> 00:54:52,005
Speaker 2:  it's like why did they make any of these choices? And the answer is like,

875
00:54:52,005 --> 00:54:55,485
Speaker 2:  oh 'cause there's so much money in it right now, right this minute, there's

876
00:54:55,485 --> 00:54:59,445
Speaker 2:  so much money in it. And will there be forever? Who knows? But there

877
00:54:59,445 --> 00:55:02,805
Speaker 2:  is a lot right now and it is making everybody do truly wild stuff.

878
00:55:03,305 --> 00:55:04,645
Speaker 14:  Yes, exactly that.

879
00:55:04,875 --> 00:55:07,645
Speaker 2:  Fair enough. All right, well we're gonna have to have you come back on when

880
00:55:07,645 --> 00:55:11,205
Speaker 2:  we get more stuff from Apple and Build and everybody else. So

881
00:55:11,235 --> 00:55:15,085
Speaker 2:  welcome to hell. And by hell I mean The Vergecast. Kylie, thank you for being

882
00:55:15,085 --> 00:55:15,285
Speaker 2:  here.

883
00:55:15,695 --> 00:55:16,245
Speaker 14:  Thank you.

884
00:55:16,945 --> 00:55:17,525
Speaker 2:  All right, we gotta

885
00:58:00,665 --> 00:58:02,065
Speaker 16:  you at today explained.

886
00:58:08,795 --> 00:58:11,815
Speaker 2:  All right, we're back. Let's get to the hotline as always. The number is

887
00:58:11,815 --> 00:58:15,775
Speaker 2:  8 6 6 VERGE one one. The email is vergecast at The Verge dot com.

888
00:58:15,845 --> 00:58:19,815
Speaker 2:  Send us all of your questions. We've gotten a lot of iPad questions and I

889
00:58:19,815 --> 00:58:22,975
Speaker 2:  think at some point here we're gonna stop answering iPad questions but we

890
00:58:22,975 --> 00:58:25,855
Speaker 2:  try to do at least one on the show every week and at some point we'll stop

891
00:58:25,855 --> 00:58:29,775
Speaker 2:  talking about iPads but this week we have a question about iPads and it comes

892
00:58:29,775 --> 00:58:30,335
Speaker 2:  from Clifton.

893
00:58:31,275 --> 00:58:35,095
Speaker 18:  Hi, this is Clifton from Tacoma, Washington. I was just listening to

894
00:58:35,375 --> 00:58:39,295
Speaker 18:  the case for the iPad Pro podcast and in your comparison

895
00:58:39,515 --> 00:58:43,135
Speaker 18:  to the iPad and the MacBook, I was wondering do you think that

896
00:58:43,475 --> 00:58:47,375
Speaker 18:  the majority of that want for Mac OS on the iPad would go away if Apple

897
00:58:47,405 --> 00:58:51,175
Speaker 18:  just made a touch screen MacBook also on the same token,

898
00:58:51,195 --> 00:58:54,975
Speaker 18:  do you think that if they made a two in one that the work

899
00:58:55,285 --> 00:58:58,935
Speaker 18:  case for pros on the iPad would go away and it would probably just go back

900
00:58:58,935 --> 00:59:02,495
Speaker 18:  as a media consumption device? I think it is similar to

901
00:59:02,665 --> 00:59:06,135
Speaker 18:  Apple thinking. They know what customers want instead of actually doing

902
00:59:06,245 --> 00:59:09,255
Speaker 18:  what customers want. Thanks, I appreciate it. So

903
00:59:09,315 --> 00:59:13,035
Speaker 2:  There's like a big thinky thing at the end there that I kind of wanna ignore

904
00:59:13,095 --> 00:59:17,075
Speaker 2:  for now. Neli Patella is here. Hi Neli. Hey we've like talked

905
00:59:17,075 --> 00:59:20,835
Speaker 2:  around this for two weeks and also like 10 years. So like

906
00:59:20,835 --> 00:59:23,885
Speaker 2:  let's just talk about this like what what do we want from Apple is? I feel

907
00:59:23,885 --> 00:59:27,045
Speaker 2:  like basically the question being asked here, there's the iPad, there's the

908
00:59:27,045 --> 00:59:30,725
Speaker 2:  MacBook and somewhere in the middle there is this idea of like a perfect

909
00:59:30,725 --> 00:59:33,245
Speaker 2:  device that would solve all of our problems. What is it?

910
00:59:33,725 --> 00:59:37,365
Speaker 19:  I think it's an iPad that doesn't have a totally restricted application

911
00:59:37,365 --> 00:59:41,085
Speaker 19:  model. Like that's the problem. The problem is not that it doesn't run Mac

912
00:59:41,145 --> 00:59:45,125
Speaker 19:  Os, what Mac OS represents to people is freedom, right? I can just use this

913
00:59:45,125 --> 00:59:49,045
Speaker 19:  thing like a computer and developers can show up and fill the

914
00:59:49,045 --> 00:59:52,925
Speaker 19:  gaps that Apple has left open. You cannot do that on an iPad.

915
00:59:53,465 --> 00:59:57,245
Speaker 19:  So it's just whatever Apple wants you to do. And if they would just

916
00:59:57,705 --> 01:00:01,365
Speaker 19:  let go, I think these things would evolve on very different

917
01:00:01,525 --> 01:00:05,245
Speaker 19:  trajectories and they just won't let go. Which I guess comes

918
01:00:05,245 --> 01:00:06,925
Speaker 19:  back to what do we want Apple to do?

919
01:00:07,475 --> 01:00:11,365
Speaker 2:  Well I think I, I largely agree like I got a bunch of crap on

920
01:00:11,475 --> 01:00:15,005
Speaker 2:  threads because I posted something to the effect of like I agree that I don't

921
01:00:15,115 --> 01:00:18,445
Speaker 2:  want huge sweeping changes to the iPad but it would be nice to be able to

922
01:00:18,445 --> 01:00:21,245
Speaker 2:  put Windows where I want them to. And a bunch of people like you could put

923
01:00:21,245 --> 01:00:24,165
Speaker 2:  Windows wherever you want and I'm looking at it right now. I can see nine

924
01:00:24,165 --> 01:00:27,965
Speaker 2:  different apps on my Mac right now. I can see them all And that is not how

925
01:00:27,965 --> 01:00:30,445
Speaker 2:  it works on the iPad and there are like a million little things like that

926
01:00:30,465 --> 01:00:34,445
Speaker 2:  to me. But the evolution thing, I'm curious how you think about it.

927
01:00:34,565 --> 01:00:37,365
Speaker 2:  'cause I think the case a lot of people would make is that If, you just let

928
01:00:37,365 --> 01:00:41,165
Speaker 2:  both of these things kind of be everything that eventually

929
01:00:41,165 --> 01:00:43,845
Speaker 2:  they would just crash into each other and the iPad and the Mac would essentially

930
01:00:43,845 --> 01:00:46,005
Speaker 2:  be the same thing. But you don't think that's the case?

931
01:00:46,445 --> 01:00:49,445
Speaker 19:  I don't. I think about a lot of iPad use cases that I see that I think are

932
01:00:49,445 --> 01:00:53,325
Speaker 19:  really interesting. I'm married to a lawyer. Some lawyers show up at

933
01:00:53,565 --> 01:00:57,525
Speaker 19:  meetings with iPads just to sign contracts and get through them. You

934
01:00:57,525 --> 01:01:00,525
Speaker 19:  don't need a Mac laptop for that, right? You don't even, you don't even

935
01:01:00,525 --> 01:01:01,485
Speaker 19:  need the keyboard case for that.

936
01:01:01,495 --> 01:01:05,325
Speaker 2:  Right. And also the fact by the way that it lies flat on a desk or

937
01:01:05,325 --> 01:01:08,125
Speaker 2:  table is actually really important. Like I was thinking about this just form

938
01:01:08,125 --> 01:01:10,525
Speaker 2:  factor wise, right? Like If, you just put a touchscreen on the Mac, does

939
01:01:10,525 --> 01:01:13,885
Speaker 2:  it suddenly solve all of your iPad problems? And like no, because drawing

940
01:01:13,885 --> 01:01:17,765
Speaker 2:  like that sucks. Signing things like that sucks. Like having a

941
01:01:17,765 --> 01:01:21,565
Speaker 2:  thing that just lies down like a piece of paper on a table does change things.

942
01:01:21,765 --> 01:01:22,205
Speaker 2:  I think you're

943
01:01:22,205 --> 01:01:25,205
Speaker 19:  Right. I will note that you have to put a case on some of these iPads so

944
01:01:25,305 --> 01:01:28,205
Speaker 19:  you can actually live fly. But you know, I, I agree with you. There's just

945
01:01:28,205 --> 01:01:32,085
Speaker 19:  a bunch of places where you want to computer in a tablet form factor. That

946
01:01:32,105 --> 01:01:35,925
Speaker 19:  is where the interface is natively touch. Great. Again, we

947
01:01:35,945 --> 01:01:38,805
Speaker 19:  get notes from people who are like interior designers and architects who

948
01:01:38,805 --> 01:01:41,805
Speaker 19:  are like, this thing is my computer. I walk around taking pictures with

949
01:01:41,805 --> 01:01:45,325
Speaker 19:  it and showing people things and drawing on it all day long

950
01:01:45,625 --> 01:01:48,845
Speaker 19:  and I, I kill a battery in my iPad every day, which is admittedly not so

951
01:01:49,125 --> 01:01:53,005
Speaker 19:  hard to do, but there's just a world of use cases that way.

952
01:01:53,425 --> 01:01:56,885
Speaker 19:  And then there's a world of use cases for the laptop form factor. And I

953
01:01:56,885 --> 01:02:00,765
Speaker 19:  think the problem is Apple thinks the form factor

954
01:02:00,865 --> 01:02:04,645
Speaker 19:  is important and not the use cases. Hmm. So they're like, we'll just make

955
01:02:04,645 --> 01:02:08,205
Speaker 19:  it a laptop and now it's a laptop replacement. And I think most people are

956
01:02:08,205 --> 01:02:10,765
Speaker 19:  like, well I use my laptop for all these things and it can't do those things.

957
01:02:11,015 --> 01:02:14,925
Speaker 19:  Right. And then I I, this is just me imposing

958
01:02:14,965 --> 01:02:18,765
Speaker 19:  a belief on Apple. I think Apple wants computers to be

959
01:02:18,765 --> 01:02:22,565
Speaker 19:  easier than the market wants them to be. You know, like people

960
01:02:22,785 --> 01:02:26,765
Speaker 19:  you give a kid a laptop like just crazy stuff starts happening. Yeah. Right.

961
01:02:26,765 --> 01:02:30,445
Speaker 19:  Like they, they start to expand on the boundary of what you can even do

962
01:02:30,445 --> 01:02:33,925
Speaker 19:  with some of these applications. That's really cool. I've seen

963
01:02:34,425 --> 01:02:38,125
Speaker 19:  entire graphic design businesses that have existed

964
01:02:38,265 --> 01:02:41,965
Speaker 19:  by teenagers using the Instagram create mode in ways that no

965
01:02:41,965 --> 01:02:45,605
Speaker 19:  Instagram product manager ever thought that thing would be used. That's

966
01:02:45,785 --> 01:02:49,525
Speaker 19:  the beauty of computers. And to whatever extent that has not

967
01:02:49,765 --> 01:02:52,525
Speaker 19:  happened on the iPad. I think that's the tragedy. And I think it's because

968
01:02:52,525 --> 01:02:54,765
Speaker 19:  of the restrictions in the operating system. Yeah,

969
01:02:54,845 --> 01:02:58,365
Speaker 2:  I I tend to agree but I think something you said at the, at the very beginning

970
01:02:58,365 --> 01:03:01,605
Speaker 2:  of this I think is is very striking. Which is the assumption that the best

971
01:03:01,605 --> 01:03:05,445
Speaker 2:  version of this thing is closer to an iPad that does

972
01:03:05,555 --> 01:03:09,365
Speaker 2:  more stuff than it is to a Mac with a touchscreen. Right. Because I think

973
01:03:09,365 --> 01:03:11,285
Speaker 2:  like If you, just to boil this question all the way down, it's like does

974
01:03:11,325 --> 01:03:14,965
Speaker 2:  a Mac with a touchscreen solve all of our problems? And I think the answer

975
01:03:14,965 --> 01:03:18,805
Speaker 2:  is clearly no. And I'm not even sure it solves many of our

976
01:03:18,805 --> 01:03:21,765
Speaker 2:  problems. Like I actually, I look at my Mac and I'm like, I don't know how

977
01:03:21,765 --> 01:03:25,405
Speaker 2:  often I want a touchscreen on this thing. And I think to me when I look at

978
01:03:25,405 --> 01:03:29,365
Speaker 2:  the iPad, the best version of that is so much more interesting than

979
01:03:29,395 --> 01:03:33,245
Speaker 2:  kind of the next version of a Mac. If that makes sense.

980
01:03:34,025 --> 01:03:37,005
Speaker 19:  I'm confident the criticism we will get, because you said that is from a

981
01:03:37,005 --> 01:03:40,405
Speaker 19:  bunch of Windows people who use touchscreens on their Windows PCs all day

982
01:03:40,405 --> 01:03:43,245
Speaker 19:  long and they're like, this is great. Sure. Actually being able to, I think

983
01:03:43,265 --> 01:03:45,645
Speaker 19:  Tom Warren has published a version of this piece. Again, we've had this

984
01:03:45,645 --> 01:03:48,965
Speaker 19:  conversation for so long, I can't tell you if it was a decade ago or yesterday,

985
01:03:48,965 --> 01:03:52,845
Speaker 19:  right. Tom Warren published like touching the screen on a

986
01:03:52,865 --> 01:03:55,885
Speaker 19:  PC is pretty good 'cause we've been talking about it for a long time and

987
01:03:55,885 --> 01:03:59,125
Speaker 19:  it is pretty good. The people who use computers that way, they get used

988
01:03:59,125 --> 01:04:02,925
Speaker 19:  to it. They like it. To me it's, it's really just about the application

989
01:04:02,925 --> 01:04:06,725
Speaker 19:  model and in particular on the Mac because the web browsers are so

990
01:04:06,755 --> 01:04:10,605
Speaker 19:  good and you can run different web browsing engines and

991
01:04:10,605 --> 01:04:14,445
Speaker 19:  Chrome and Safari and whatever else. There's a richness to the experience

992
01:04:14,445 --> 01:04:17,925
Speaker 19:  that you just get. You can just have a lot of the latest things on a Mac

993
01:04:18,115 --> 01:04:21,725
Speaker 19:  because all of the latest things tend to run in the web browser. All of

994
01:04:21,725 --> 01:04:25,445
Speaker 19:  the AI in the world is happening in web browsers. Right. You cannot do that

995
01:04:25,465 --> 01:04:28,645
Speaker 19:  on an iPad like the web browser still pretty much mobile safari. They fake

996
01:04:28,645 --> 01:04:32,085
Speaker 19:  it in different ways. Right. And it's just that, it's that, right? It's

997
01:04:32,175 --> 01:04:36,005
Speaker 19:  Apple has just restricted a bunch of stuff maybe to protect

998
01:04:36,005 --> 01:04:38,885
Speaker 19:  Apple's business model maybe 'cause they have an idealistic vision of what

999
01:04:39,145 --> 01:04:42,125
Speaker 19:  an iPad user should do or how they should work or how easy it should be

1000
01:04:42,125 --> 01:04:45,885
Speaker 19:  or to keep you safe or secure, whatever you want to believe about

1001
01:04:45,905 --> 01:04:49,565
Speaker 19:  why this has happened. It has happened. And I think those are the limits

1002
01:04:49,565 --> 01:04:53,445
Speaker 19:  that people keep bopping up against and saying, oh just let this be a Mac.

1003
01:04:53,805 --> 01:04:57,205
Speaker 19:  'cause the, the Mac represents those limits going away and I, I really do

1004
01:04:57,205 --> 01:05:01,125
Speaker 19:  think you can see it, you know, on other kinds of tablets that If

1005
01:05:01,125 --> 01:05:05,045
Speaker 19:  you let that form factor evolve, it will head

1006
01:05:05,045 --> 01:05:07,925
Speaker 19:  towards different places. Like I think it would be really interesting if

1007
01:05:08,025 --> 01:05:11,365
Speaker 19:  the solution to the input problem, especially with all the AI we have now,

1008
01:05:11,455 --> 01:05:15,365
Speaker 19:  isn't just put a keyboard on it. Right. Like we, we, we just haven't

1009
01:05:15,395 --> 01:05:19,325
Speaker 19:  like tried. Yeah. Because we are like maybe the, maybe everything

1010
01:05:19,325 --> 01:05:22,845
Speaker 19:  will just, you know how like everything evolves into be a crab. It's like

1011
01:05:22,845 --> 01:05:25,365
Speaker 19:  everything is evolving to be a laptop again and like, I don't know, maybe

1012
01:05:25,365 --> 01:05:26,085
Speaker 19:  there's some other ways to do

1013
01:05:26,085 --> 01:05:29,365
Speaker 2:  It. Well yeah and that's the thing I think like when, when people have asked

1014
01:05:29,365 --> 01:05:32,165
Speaker 2:  me over the last few weeks like why are you so hung up on the idea that Apple

1015
01:05:32,745 --> 01:05:36,645
Speaker 2:  should or could or ought to make this thing more like a laptop. I just

1016
01:05:36,645 --> 01:05:39,725
Speaker 2:  find myself wanting to hold the thing up with the magic keyboard and be like,

1017
01:05:39,725 --> 01:05:42,965
Speaker 2:  because Apple made it a laptop. Like The two

1018
01:05:43,035 --> 01:05:46,845
Speaker 2:  accessories this company has invested in are a pencil which makes perfect

1019
01:05:46,845 --> 01:05:50,805
Speaker 2:  sense and is extremely iPad and I actually think is like iPad plus pencil

1020
01:05:50,865 --> 01:05:54,845
Speaker 2:  is by far the most compelling case for an iPad in

1021
01:05:54,845 --> 01:05:58,765
Speaker 2:  every way you can imagine. Or it's a laptop. Yeah. Like they just, it just

1022
01:05:58,765 --> 01:06:02,645
Speaker 2:  looks like a laptop. It acts like a laptop but the Gmail app is worse. Like

1023
01:06:02,885 --> 01:06:06,685
Speaker 2:  that's just, that's the difference and I'm sort of with you in that sense.

1024
01:06:06,825 --> 01:06:10,645
Speaker 2:  But like to the Windows point, right, the Surface rhymes

1025
01:06:10,645 --> 01:06:14,445
Speaker 2:  with an iPad. I would say almost more than it rhymes with a

1026
01:06:14,445 --> 01:06:17,405
Speaker 2:  Mac, right? Like it runs Windows and it can do all the stuff. But in terms

1027
01:06:17,405 --> 01:06:21,325
Speaker 2:  of like the spirit of that device, it's so much an

1028
01:06:21,395 --> 01:06:24,565
Speaker 2:  iPad. Yeah. And I think actually like Microsoft got that really right And

1029
01:06:24,565 --> 01:06:27,565
Speaker 2:  just has not really solved a lot of the software stuff around Windows. Like

1030
01:06:27,825 --> 01:06:31,805
Speaker 2:  the surface isn't everything. It could be because of Windows in the same

1031
01:06:31,805 --> 01:06:35,605
Speaker 2:  way that iPad is like hamstrung by iPad os but in completely radically separate

1032
01:06:35,635 --> 01:06:36,525
Speaker 2:  ways. Well

1033
01:06:36,525 --> 01:06:40,485
Speaker 19:  It's two companies reacting to the web in totally different ways. Microsoft

1034
01:06:40,485 --> 01:06:44,285
Speaker 19:  just lost to the web. Yeah. No one's developing hot shit win 32

1035
01:06:44,285 --> 01:06:48,005
Speaker 19:  applications for the the surface outside of games. Right? You just have

1036
01:06:48,005 --> 01:06:51,805
Speaker 19:  to like set those aside. But like the hottest new applications

1037
01:06:51,805 --> 01:06:55,485
Speaker 19:  in the world happen on the web. Like that is a thing that's just true.

1038
01:06:55,925 --> 01:06:59,365
Speaker 19:  The web has become the dominant place to deploy desktop applications.

1039
01:06:59,975 --> 01:07:03,245
Speaker 19:  Great. Microsoft reacted to it by just letting go, by being like, you know

1040
01:07:03,245 --> 01:07:06,765
Speaker 19:  what? We built Azure, put your web applications on our cloud service and

1041
01:07:06,865 --> 01:07:10,645
Speaker 19:  run OpenAI on our cloud service and we'll make the money there and whatever.

1042
01:07:10,655 --> 01:07:14,325
Speaker 19:  We'll just try to get you to use Edge. Yeah. And that is one reaction

1043
01:07:14,565 --> 01:07:16,885
Speaker 19:  a big company I make especially 'cause they lost in mobile, they basically

1044
01:07:16,885 --> 01:07:20,605
Speaker 19:  had no choice. Apple's response to it is like, no, no that

1045
01:07:20,605 --> 01:07:24,205
Speaker 19:  won't happen at all sir. Right. And on our tablet you will

1046
01:07:24,345 --> 01:07:27,725
Speaker 19:  deploy applications for the iPad, you will use the app store

1047
01:07:28,145 --> 01:07:32,085
Speaker 19:  and indeed there are some cool iPad apps because of it. That's

1048
01:07:32,085 --> 01:07:35,805
Speaker 19:  great. Like procreate is an entire company that exists to develop

1049
01:07:35,955 --> 01:07:38,685
Speaker 19:  iPad apps and use the iPad in the way that Apple wants people to use. That

1050
01:07:38,705 --> 01:07:42,125
Speaker 19:  is great. That's a success story. But there's not a lot of great iPad apps.

1051
01:07:42,125 --> 01:07:44,445
Speaker 19:  Like they squeeze the balloon and it didn't get a lot bigger.

1052
01:07:45,995 --> 01:07:49,725
Speaker 19:  Like mostly the air went out. There's some balance in there. But you can

1053
01:07:49,725 --> 01:07:51,565
Speaker 19:  see those are two reactions to the same problem.

1054
01:07:52,145 --> 01:07:55,805
Speaker 2:  All I keep thinking as you say that is like, boy it's ridiculous that Google

1055
01:07:55,895 --> 01:07:59,525
Speaker 2:  never figured out how to make decent hardware out of this that like

1056
01:07:59,635 --> 01:08:03,605
Speaker 2:  this circling Google did around Chromebooks and Android tablets

1057
01:08:03,605 --> 01:08:06,565
Speaker 2:  and all this stuff. Like nobody should be more incentivized to figure out

1058
01:08:06,565 --> 01:08:09,325
Speaker 2:  how to do this well than Google. And it just didn't. And that makes me angry.

1059
01:08:09,425 --> 01:08:12,285
Speaker 2:  And I just look at my Pixel book and I'm like, God, you could have been something.

1060
01:08:12,505 --> 01:08:12,725
Speaker 2:  It

1061
01:08:12,725 --> 01:08:16,085
Speaker 19:  Could have been great. I mean I famously bought my mother a Chromebook Pixel

1062
01:08:16,265 --> 01:08:19,325
Speaker 19:  the thousand dollar Chromebook several years ago. She still uses it. Yeah.

1063
01:08:19,325 --> 01:08:22,805
Speaker 19:  Because it was easier to use than a Windows PC or a Mac.

1064
01:08:23,035 --> 01:08:27,005
Speaker 19:  Like you open a Mac today, it has 50 different interface paradigms all happening

1065
01:08:27,005 --> 01:08:30,325
Speaker 19:  at you at once. There's a launchpad and Mac apps and a web browser and it's

1066
01:08:30,325 --> 01:08:32,925
Speaker 19:  trying to get you to use Safari and all this other stuff has ha And you

1067
01:08:32,925 --> 01:08:36,405
Speaker 19:  can run iPad apps and it has an app store but you can also, and it's like

1068
01:08:36,545 --> 01:08:40,005
Speaker 19:  that's too much. Like actually just go to a bunch of

1069
01:08:40,005 --> 01:08:43,005
Speaker 19:  webpages and use whatever you need to use. There is, and here's a really

1070
01:08:43,005 --> 01:08:46,845
Speaker 19:  nice piece of hardware to do. It is pretty good. And I think you

1071
01:08:46,845 --> 01:08:48,965
Speaker 19:  look at kind of all the like the steam decks of the world that are running

1072
01:08:48,965 --> 01:08:52,925
Speaker 19:  games and Linux now and you're like, oh you could build a kick ass Chromebook

1073
01:08:52,925 --> 01:08:56,845
Speaker 19:  right now and is any, is anyone gonna do it? It's like, I don't know. Like

1074
01:08:57,145 --> 01:08:59,485
Speaker 19:  we, we've come a long way from the iPad where I'm like, you could build

1075
01:08:59,485 --> 01:09:03,325
Speaker 19:  a kick ass Chromebook. But that feels like one version of computing

1076
01:09:03,325 --> 01:09:06,805
Speaker 19:  where the restraints are lifted and it does everything everyone wants. And

1077
01:09:06,985 --> 01:09:10,525
Speaker 19:  the simplicity that Apple's chasing with the iPad is still there.

1078
01:09:10,755 --> 01:09:14,725
Speaker 2:  Yeah. I really do agree with, and you said this on last Friday, show that

1079
01:09:15,005 --> 01:09:18,525
Speaker 2:  a desktop web browser, like a true great desktop web

1080
01:09:18,525 --> 01:09:22,125
Speaker 2:  browsing environment would immediately solve a lot of people's iPad problems.

1081
01:09:22,365 --> 01:09:23,685
Speaker 2:  I think that's, I think that's really real.

1082
01:09:23,915 --> 01:09:27,005
Speaker 19:  Yeah. Let us just run Chrome. Look honestly, maybe it'll destroy the battery,

1083
01:09:27,455 --> 01:09:31,205
Speaker 19:  it'll light on fire. Like Chrome has a lot of problems. But If, you just

1084
01:09:31,225 --> 01:09:35,205
Speaker 19:  let me use an iPad like a Chromebook, eh, you know, like

1085
01:09:35,205 --> 01:09:38,125
Speaker 19:  I would still buy the hardware, I would still pay for Apple's various services.

1086
01:09:38,445 --> 01:09:41,885
Speaker 19:  I would still need iCloud storage. Like you'll make your money Tim. But

1087
01:09:41,885 --> 01:09:44,245
Speaker 19:  like, let me use the computer the way I want to. So

1088
01:09:44,245 --> 01:09:47,845
Speaker 2:  Maybe, maybe part of the reason people want a touchscreen MacBook

1089
01:09:48,145 --> 01:09:51,965
Speaker 2:  is that that seems like the more likely way to get

1090
01:09:51,965 --> 01:09:54,885
Speaker 2:  closer to that perfect middle. Because I think the iPad thing you're describing

1091
01:09:54,885 --> 01:09:57,285
Speaker 2:  is like, what if we just blew up the whole way Apple thinks about itself

1092
01:09:57,665 --> 01:10:01,525
Speaker 2:  and that'd be cool but seems less likely than there

1093
01:10:01,525 --> 01:10:05,365
Speaker 2:  might be a touchscreen on a MacBook. And Mark Germin has reported

1094
01:10:05,365 --> 01:10:09,165
Speaker 2:  that Apple's considering that again like it, it has seemed anathema to Apple

1095
01:10:09,185 --> 01:10:12,285
Speaker 2:  for a long time. But I, I would track that as probably a more likely

1096
01:10:12,955 --> 01:10:16,605
Speaker 2:  sort of nudge towards the perfect all things for all people computer

1097
01:10:16,995 --> 01:10:19,245
Speaker 2:  than let's upend the app model entirely.

1098
01:10:19,675 --> 01:10:23,045
Speaker 19:  Well I think there's two ways of thinking about it. One, at some point you're

1099
01:10:23,045 --> 01:10:26,285
Speaker 19:  just like, it's an M four and it's a keyboard and a screen.

1100
01:10:26,755 --> 01:10:27,685
Speaker 19:  They should be the same.

1101
01:10:27,965 --> 01:10:30,605
Speaker 2:  I mean I would assume by the way that they will be like, I suspect we are

1102
01:10:30,605 --> 01:10:33,925
Speaker 2:  going to get a Mac with basically these exact same specs before very long.

1103
01:10:34,075 --> 01:10:36,445
Speaker 19:  Yeah. The only difference between a Mac and an iPad is that Mac doesn't

1104
01:10:36,445 --> 01:10:38,365
Speaker 19:  have a random LIDAR sensor and a camera on the back. Sure,

1105
01:10:38,765 --> 01:10:39,525
Speaker 2:  Yeah. Fine.

1106
01:10:40,145 --> 01:10:44,045
Speaker 19:  But I think the other thing that is happening is in Europe

1107
01:10:44,045 --> 01:10:47,165
Speaker 19:  there's a bunch of regulations that say you have to let other web browsers

1108
01:10:47,225 --> 01:10:51,205
Speaker 19:  on these devices with their own engines and maybe someone just makes a

1109
01:10:51,205 --> 01:10:54,645
Speaker 19:  great desktop web browser with the desktop Chrome engine

1110
01:10:54,935 --> 01:10:58,565
Speaker 19:  maybe. And like and I, I think as we've already seen with emulators, it

1111
01:10:58,565 --> 01:11:02,485
Speaker 19:  really recontextualizes what you can do when you get out of apple's

1112
01:11:02,485 --> 01:11:05,485
Speaker 19:  restrictions or those restrictions fade away and other people are allowed

1113
01:11:05,485 --> 01:11:09,285
Speaker 19:  to use the hardware to their advantage. So I think that's, the iPad is in

1114
01:11:09,285 --> 01:11:11,725
Speaker 19:  all the regulations now there, you know, there's some back and forth on

1115
01:11:11,725 --> 01:11:14,645
Speaker 19:  it but they the Europeans or Europeans and they're like, no, we're taking

1116
01:11:14,645 --> 01:11:17,525
Speaker 19:  that too. Great. So I, I just think there's something else that might

1117
01:11:57,585 --> 01:12:00,285
Speaker 19:  but people still use their laptops. Like I, I can look at our own

1118
01:12:25,885 --> 01:12:29,805
Speaker 2:  MacBook. It would all be fine. Alright, we should go Neli. Thank you as always.

1119
01:12:30,145 --> 01:12:30,485
Speaker 19:  See ya.

1120
01:12:33,275 --> 01:12:36,205
Speaker 2:  Alright, that is it for The Vergecast today. Thanks to everybody who came

1121
01:12:36,205 --> 01:12:39,605
Speaker 2:  on the show and thank you especially as always for listening. There's lots

1122
01:12:39,605 --> 01:12:42,605
Speaker 2:  more on everything we talked about at The Verge dot com, tons from the surface

1123
01:12:42,695 --> 01:12:46,205
Speaker 2:  event and all The new Microsoft things, all of our OpenAI coverage,

1124
01:12:46,205 --> 01:12:49,925
Speaker 2:  everything about iPads, all of it. We'll put it in the show notes, but also

1125
01:12:49,955 --> 01:12:53,845
Speaker 2:  read The Verge dot com. It is just a crazy newsy week. Microsoft build

1126
01:12:53,865 --> 01:12:57,645
Speaker 2:  is today. Developer conferences are everywhere. AI stuff is everywhere. There's

1127
01:12:57,645 --> 01:13:00,885
Speaker 2:  just a ton going on. As always. If, you have thoughts, questions, feelings,

1128
01:13:00,945 --> 01:13:04,885
Speaker 2:  or PC recommendations for me? You can always email us at vergecast

1129
01:13:04,905 --> 01:13:08,725
Speaker 2:  at The Verge dot com or keep calling the hotline. 8 6 6 VERGE one. One.

1130
01:13:08,725 --> 01:13:12,685
Speaker 2:  Like I said, I love hearing from you. We have a Slack room that just pumps

1131
01:13:12,685 --> 01:13:16,005
Speaker 2:  in every voicemail and we get to listen to it. It's so much fun. It is my

1132
01:13:16,285 --> 01:13:19,565
Speaker 2:  absolute favorite thing both about maybe my job and definitely about being

1133
01:13:19,565 --> 01:13:23,045
Speaker 2:  in Slack. If, you've got ideas, thoughts, questions. Keep it all coming.

1134
01:13:23,315 --> 01:13:26,885
Speaker 2:  This show is produced by Angel Marino, Liam James, and Will Pour The. Vergecast

1135
01:13:26,885 --> 01:13:30,245
Speaker 2:  is VERGE production and part of the Vox Media podcast network. Neli Alex

1136
01:13:30,265 --> 01:13:34,005
Speaker 2:  and I will be back on Friday to talk more about, build more about AI and

1137
01:13:34,005 --> 01:13:36,965
Speaker 2:  everything else going on in tech this week. We'll see you then. Rock and

1138
01:13:36,965 --> 01:13:37,085
Speaker 2:  roll.

