1
00:00:00,000 --> 00:00:05,000
# Transcript
ID: eaae2493-1b84-4e55-969a-151e9938def6
Status: Done
Stage: Done
Title: Instagram Threads is here to crush Twitter
Audio URL: https://jfe93e.s3.amazonaws.com/7196297431523671109/-7402524581217851141/s93290-US-5170s-1688804316.mp3
Description: The Verge's David Pierce, Alex Cranz, and Alex Heath discuss Meta's launch of Threads, a new competitor to Twitter. Later, Nilay Patel calls in to give his take.

2
00:01:19,370 --> 00:01:23,300
Speaker 5:  Welcome to The Vergecast, the flagship podcast of cloning other people's

3
00:01:23,300 --> 00:01:26,720
Speaker 5:  apps and calling them slightly different names. I'm your friend David Pierce

4
00:01:26,720 --> 00:01:30,060
Speaker 5:  and that is all we're gonna talk about today. Alex Cranz is here. Hi

5
00:01:30,060 --> 00:01:30,880
Speaker 5:  Alex.

6
00:01:30,880 --> 00:01:33,940
Speaker 6:  I'm your friend who wants to start a new website called The

7
00:01:33,940 --> 00:01:36,380
Speaker 6:  Splurge. It's fine. It's about flirts.

8
00:01:36,380 --> 00:01:38,080
Speaker 5:  It's like a flirty Verge. Yeah.

9
00:01:38,080 --> 00:01:40,420
Speaker 6:  Ooh, I like that better. There you go. Better. That's better. Love

10
00:01:40,420 --> 00:01:44,090
Speaker 5:  It. Alex. Heath is here from I think a studio or

11
00:01:44,090 --> 00:01:47,860
Speaker 5:  just a surprisingly soundproof place. I don't know what's going on. It's

12
00:01:47,860 --> 00:01:51,300
Speaker 7:  Not that secret. It's our's, our LA office. But yes, I

13
00:01:51,300 --> 00:01:54,120
Speaker 7:  suppose, I suppose secret for all intensive purposes.

14
00:01:54,120 --> 00:01:57,300
Speaker 5:  We have to make sure Adam Maser can't find you. That's, that's the important

15
00:01:57,300 --> 00:01:58,140
Speaker 5:  thing.

16
00:01:58,140 --> 00:02:01,860
Speaker 7:  I am here and I have too many damn apps on my phone. I'm not sure what to

17
00:02:01,860 --> 00:02:03,420
Speaker 7:  do about it. I don't know about you all. I

18
00:02:03,420 --> 00:02:06,620
Speaker 5:  Think it was Walt Mossberg who posted something today with just a folder

19
00:02:06,620 --> 00:02:09,940
Speaker 5:  of apps called New Twitter question mark. Yeah. And over like 10 apps in

20
00:02:09,940 --> 00:02:13,300
Speaker 5:  there. It's like, yeah, this is, this is the world we live in now. I

21
00:02:13,300 --> 00:02:16,740
Speaker 5:  suspect we are going to spend the entirety of this show talking about Instagram

22
00:02:16,740 --> 00:02:20,580
Speaker 5:  Threads. So anyone who is expecting anything else, I'm so very sorry

23
00:02:20,580 --> 00:02:21,640
Speaker 5:  this is what we're doing here.

24
00:02:21,640 --> 00:02:23,660
Speaker 7:  We just lost half the audience, but yeah,

25
00:02:23,660 --> 00:02:24,940
Speaker 5:  It's, it's fine. We got a

26
00:02:24,940 --> 00:02:26,580
Speaker 6:  Lightning round. Stick around for the lightning round.

27
00:02:26,580 --> 00:02:29,830
Speaker 5:  Yeah, listen, if, if you want me to have strong feelings about nothing, phone

28
00:02:29,830 --> 00:02:32,140
Speaker 5:  leaks, just wait two or three hours and we'll be

29
00:02:32,140 --> 00:02:36,060
Speaker 5:  there. But let's, let's just get into this. So as

30
00:02:36,060 --> 00:02:38,780
Speaker 5:  we're recording this, it's Thursday afternoon. This app has been live for

31
00:02:38,780 --> 00:02:42,490
Speaker 5:  less than 24 hours and kind of already feels like it has taken

32
00:02:42,490 --> 00:02:46,340
Speaker 5:  over the universe. Heath, you've been, you've been tracking this kind of

33
00:02:46,340 --> 00:02:49,740
Speaker 5:  minute to minute as it has launched. Where do we stand? How is this thing

34
00:02:49,740 --> 00:02:50,690
Speaker 5:  going so far?

35
00:02:50,690 --> 00:02:54,420
Speaker 7:  Yeah, so as we're recording this, mark Zuckerberg shared on Threads

36
00:02:54,420 --> 00:02:57,920
Speaker 7:  this morning that they have surpassed 30 million

37
00:02:57,920 --> 00:03:01,580
Speaker 7:  signups, which I want to be clear blows away the internal

38
00:03:01,580 --> 00:03:05,420
Speaker 7:  projections they had for this thing by a crazy multiple. They're now

39
00:03:05,420 --> 00:03:09,220
Speaker 7:  internally at Meta talking about can we beat the chat G p t

40
00:03:09,220 --> 00:03:13,100
Speaker 7:  record for the fastest Oh wow. Consumer software product at

41
00:03:13,100 --> 00:03:16,980
Speaker 7:  a hundred million users. So that's the, that's the scale of Threads

42
00:03:16,980 --> 00:03:20,607
Speaker 7:  right now. There have been over 95 million

43
00:03:20,990 --> 00:03:24,940
Speaker 7:  posts or I guess Threads, they're called spools, whatever you wanna

44
00:03:24,940 --> 00:03:25,470
Speaker 7:  call them.

45
00:03:25,470 --> 00:03:27,290
Speaker 5:  We're gonna get to that, don't you worry.

46
00:03:27,290 --> 00:03:31,100
Speaker 7:  Yeah. On Threads to date and according to some internal data

47
00:03:31,100 --> 00:03:34,900
Speaker 7:  I reported on this morning on the site, and that sounds like a huge

48
00:03:34,900 --> 00:03:38,520
Speaker 7:  number, but what I think it shows is if you actually map it

49
00:03:38,520 --> 00:03:42,310
Speaker 7:  to the publicly stated signups, you're seeing a similar

50
00:03:42,310 --> 00:03:46,170
Speaker 7:  thing happen to Twitter where, and this has been true of Twitter

51
00:03:46,170 --> 00:03:49,830
Speaker 7:  from the earliest days, the a very small percent of the overall

52
00:03:49,830 --> 00:03:53,500
Speaker 7:  users contribute much of the content and that similar

53
00:03:53,500 --> 00:03:57,180
Speaker 7:  dynamic is starting to play out on Threads even you know before it's a week

54
00:03:57,180 --> 00:03:57,730
Speaker 7:  old.

55
00:03:57,730 --> 00:04:00,980
Speaker 5:  Yeah. So let's actually go back a bunch cuz it, the launch was super fascinating.

56
00:04:00,980 --> 00:04:04,620
Speaker 5:  We were all in sort of watching people roll in. I was gonna say we should

57
00:04:04,620 --> 00:04:07,260
Speaker 5:  all compare numbers of who got in first, but Heath, you won so that's no

58
00:04:07,260 --> 00:04:08,620
Speaker 5:  fun. Yeah, Heath cheated

59
00:04:08,620 --> 00:04:12,410
Speaker 7:  Though. These are 2,770 something.

60
00:04:12,410 --> 00:04:12,920
Speaker 7:  Damn.

61
00:04:12,920 --> 00:04:15,490
Speaker 5:  Wow. Look at you. Look at that flex.

62
00:04:15,490 --> 00:04:19,250
Speaker 7:  It's a flex. So backstory on this, like there were

63
00:04:19,250 --> 00:04:23,120
Speaker 7:  only about a thousand people on this app. All mostly internal Meta people

64
00:04:23,120 --> 00:04:27,020
Speaker 7:  and some friends on the 4th of July. They were at just under

65
00:04:27,020 --> 00:04:30,760
Speaker 7:  3000 users when I came on and this was probably four, four or five hours

66
00:04:30,760 --> 00:04:34,740
Speaker 7:  before public launch. They really moved quickly on this thing. They weren't

67
00:04:34,740 --> 00:04:37,780
Speaker 7:  actually planning to release Threads this week. They were planning to do

68
00:04:37,780 --> 00:04:41,420
Speaker 7:  it next week. And what happened is they saw the Elon rate

69
00:04:41,420 --> 00:04:45,200
Speaker 7:  limit fiasco on Twitter over the 4th of July weekend

70
00:04:45,200 --> 00:04:48,900
Speaker 7:  and rushed it out and and employees started working on the holiday to, to

71
00:04:48,900 --> 00:04:51,860
Speaker 7:  get it out. They wanted to have more time for celebs to get

72
00:04:51,860 --> 00:04:55,540
Speaker 7:  onboarded. Celebs didn't get onboarded until about a day before public

73
00:04:55,540 --> 00:04:58,300
Speaker 7:  launch. So this is all moving really fast.

74
00:04:58,300 --> 00:05:01,940
Speaker 5:  I had wondered about that actually because you could not have

75
00:05:01,940 --> 00:05:05,720
Speaker 5:  imagined a more perfect time to launch an app like this

76
00:05:05,720 --> 00:05:09,700
Speaker 5:  and there have been a lot of these sort of fortuitous moments to

77
00:05:09,700 --> 00:05:13,180
Speaker 5:  try and compete with Twitter over the last eight months or so. But this one

78
00:05:13,180 --> 00:05:16,960
Speaker 5:  in particular because I think, what was it Saturday the second I think

79
00:05:16,960 --> 00:05:20,220
Speaker 5:  was when Elon tweeted were rate limiting people and if you're not paying

80
00:05:20,220 --> 00:05:24,100
Speaker 5:  you only get to see 600 tweets a day. They put up the login things so you

81
00:05:24,100 --> 00:05:27,780
Speaker 5:  couldn't see tweets unless you were logged in And there was this very clear

82
00:05:27,780 --> 00:05:31,540
Speaker 5:  like closing down the walls of Twitter thing that everybody, some

83
00:05:31,540 --> 00:05:34,420
Speaker 5:  combination of thought was stupid and ruthlessly made fun of both of which

84
00:05:34,420 --> 00:05:38,380
Speaker 5:  I think were correct responses to those moves. But then I was just thinking

85
00:05:38,380 --> 00:05:41,780
Speaker 5:  about this yesterday as this launch happened, like holy god, what a perfect

86
00:05:41,780 --> 00:05:45,740
Speaker 5:  moment. If I'm a Meta executive sitting there saying we're about to

87
00:05:45,740 --> 00:05:49,180
Speaker 5:  launch a thing that kind of looks a lot like Twitter and if they had launched

88
00:05:49,180 --> 00:05:51,740
Speaker 5:  this four years ago, everybody would've been like, oh God, they launched

89
00:05:51,740 --> 00:05:54,580
Speaker 5:  Twitter but now they pick this perfect moment and everybody's like, oh my

90
00:05:54,580 --> 00:05:57,860
Speaker 5:  god, they launched Twitter. Like it's the best news of all time.

91
00:05:57,860 --> 00:05:58,860
Speaker 5:  Somehow I thought

92
00:05:58,860 --> 00:06:02,370
Speaker 6:  It was impressive that they got around. Like a lot of people might have assumed

93
00:06:02,370 --> 00:06:06,260
Speaker 6:  that the rate limiting and everything was in reaction to the impending

94
00:06:06,260 --> 00:06:09,990
Speaker 6:  launch and it was like, no, this is very clearly these guys suck.

95
00:06:09,990 --> 00:06:13,160
Speaker 6:  We're gonna do it too and hopefully we suck less.

96
00:06:13,160 --> 00:06:16,890
Speaker 7:  How weird is it that we're talking about Meta and like the context of a

97
00:06:16,890 --> 00:06:20,260
Speaker 7:  good guy almost right, right now. Yeah, it's very strange. I

98
00:06:20,260 --> 00:06:24,060
Speaker 6:  Think that's like, I don't wanna call them a good guy, but a more

99
00:06:24,060 --> 00:06:25,460
Speaker 6:  pleasing alternative

100
00:06:25,460 --> 00:06:29,380
Speaker 7:  A more, okay, that's more fair I guess. But like Zuck is on Threads like

101
00:06:29,380 --> 00:06:33,260
Speaker 7:  boasting about how many hours he gets to sleep a night and posting

102
00:06:33,260 --> 00:06:36,850
Speaker 7:  pics of him spending time with his baby in the morning and his meanwhile

103
00:06:36,850 --> 00:06:40,640
Speaker 7:  like record signups. Like it's just this level

104
00:06:40,640 --> 00:06:44,540
Speaker 7:  of like them feeling good and getting really

105
00:06:44,540 --> 00:06:48,500
Speaker 7:  positive energy that I haven't seen in a very, very long time for

106
00:06:48,500 --> 00:06:48,920
Speaker 7:  Meta.

107
00:06:48,920 --> 00:06:52,780
Speaker 5:  It is really fascinating. And that's actually, you talked to Adam Maser I

108
00:06:52,780 --> 00:06:55,380
Speaker 5:  think in like the hours running up to the launch. Yeah and that was one of

109
00:06:55,380 --> 00:06:58,020
Speaker 5:  the things you guys talked about, right? Because there were, there are two

110
00:06:58,020 --> 00:07:01,650
Speaker 5:  things about being Meta that are very funny to me here. One is that like

111
00:07:01,650 --> 00:07:05,580
Speaker 5:  over the last say half decade, I can't think of a company, more people

112
00:07:05,580 --> 00:07:08,770
Speaker 5:  have said oh maybe they shouldn't be in charge of all of our social networks.

113
00:07:08,770 --> 00:07:12,300
Speaker 5:  Like Meta has not been a company you want running your social life over the

114
00:07:12,300 --> 00:07:16,090
Speaker 5:  last several years. And then on the flip side, Meta's history of

115
00:07:16,090 --> 00:07:19,940
Speaker 5:  launching new apps is like as bad as any company other than

116
00:07:19,940 --> 00:07:23,300
Speaker 5:  Google that I can think of it launched a thing called Threads

117
00:07:23,300 --> 00:07:27,140
Speaker 5:  already and killed it. Yeah. But you were talking to Adam and the, the sense

118
00:07:27,140 --> 00:07:31,100
Speaker 5:  I got was there's, there's a lot of confidence inside that company for

119
00:07:31,100 --> 00:07:32,650
Speaker 5:  how they can do something like this right now.

120
00:07:32,650 --> 00:07:35,860
Speaker 7:  Yeah, I think they were confident but they were at least publicly trying

121
00:07:35,860 --> 00:07:39,620
Speaker 7:  to project the sense of like Adam told me it was a risky bet

122
00:07:39,620 --> 00:07:43,020
Speaker 7:  that they know that launching a new app in the year 2023 has a

123
00:07:43,020 --> 00:07:46,280
Speaker 7:  much more likely chance of failing than not

124
00:07:46,280 --> 00:07:50,000
Speaker 7:  versus tacking it on to an existing app like Instagram that already

125
00:07:50,000 --> 00:07:53,980
Speaker 7:  has over a billion users. I think they're being proven in their

126
00:07:53,980 --> 00:07:57,700
Speaker 7:  early signups that the instinct was right to to split it

127
00:07:57,700 --> 00:08:01,480
Speaker 7:  off. And as Moser kind of explained it to me, the main reason

128
00:08:01,480 --> 00:08:05,320
Speaker 7:  for doing so is they wanted to give equal weight to

129
00:08:05,320 --> 00:08:09,100
Speaker 7:  not only the posts but the comments And on Instagram

130
00:08:09,100 --> 00:08:12,900
Speaker 7:  there that's just really not an intuitive experience. It doesn't make sense

131
00:08:12,900 --> 00:08:16,730
Speaker 7:  on Instagram and it's really Twitter's magic and

132
00:08:16,730 --> 00:08:19,740
Speaker 7:  Threads I mean it's called Threads. They want the Threads to be the most

133
00:08:19,740 --> 00:08:22,940
Speaker 7:  prominent thing and they realized to do that, they wanted to split it out.

134
00:08:22,940 --> 00:08:25,640
Speaker 7:  They've been trying to simplify Instagram, they didn't want to add another

135
00:08:25,640 --> 00:08:29,520
Speaker 7:  tab, which I am very much in favor for and it's smart to

136
00:08:29,520 --> 00:08:32,980
Speaker 7:  use the Instagram social graph as the kickoff here and let you bring your

137
00:08:32,980 --> 00:08:36,840
Speaker 7:  Instagram onto Threads because the kinds of people on Instagram

138
00:08:36,840 --> 00:08:40,740
Speaker 7:  who are active posters probably maps the closest to Twitter's most

139
00:08:40,740 --> 00:08:43,530
Speaker 7:  active posters then any of Meta's properties.

140
00:08:43,530 --> 00:08:47,220
Speaker 5:  Yeah, I think if it had tried to pull your Facebook friends it would've vibed

141
00:08:47,220 --> 00:08:50,380
Speaker 5:  very differently. Yeah. And I was just thinking about this as I was going

142
00:08:50,380 --> 00:08:52,980
Speaker 5:  through cuz I think one of the first things you have to do is basically decide

143
00:08:52,980 --> 00:08:56,940
Speaker 5:  like do you wanna bring your Instagram graph in with you when you sign up

144
00:08:56,940 --> 00:09:00,620
Speaker 5:  for it? If I'm remembering it right, this is all so long ago now you have

145
00:09:00,620 --> 00:09:04,060
Speaker 5:  to use your Instagram handle. Yes. But then you sort of get to choose what

146
00:09:04,060 --> 00:09:06,780
Speaker 5:  else from Instagram you wanna bring in, right? There's like a button that's

147
00:09:06,780 --> 00:09:08,940
Speaker 5:  like, do you want your Instagram bio? There's another button that's like,

148
00:09:08,940 --> 00:09:12,580
Speaker 5:  do you want your followers and and follows. Yeah. And I was just thinking

149
00:09:12,580 --> 00:09:16,260
Speaker 5:  about it and I was like my Facebook friend

150
00:09:16,260 --> 00:09:19,310
Speaker 5:  graph I just have not like thought about or touched in

151
00:09:19,310 --> 00:09:23,090
Speaker 5:  years. And so it's like all of my

152
00:09:23,090 --> 00:09:26,600
Speaker 5:  exes and people I don't talk to from high school

153
00:09:26,600 --> 00:09:30,490
Speaker 5:  and like my random relatives who I don't

154
00:09:30,490 --> 00:09:34,400
Speaker 5:  ever talk to otherwise who have crazy political opinions, I don't want that

155
00:09:34,400 --> 00:09:35,520
Speaker 5:  in another social app.

156
00:09:35,520 --> 00:09:39,380
Speaker 7:  You don't want your college classmates' opinions on RFK Junior and

157
00:09:39,380 --> 00:09:40,730
Speaker 7:  Threads.

158
00:09:40,730 --> 00:09:42,260
Speaker 5:  Yeah, believe it or not. Come on

159
00:09:42,260 --> 00:09:42,820
Speaker 7:  David.

160
00:09:42,820 --> 00:09:45,740
Speaker 5:  I went to college in the south, let's just say that. That's all Same. That's

161
00:09:45,740 --> 00:09:46,290
Speaker 5:  awesome. Yeah,

162
00:09:46,290 --> 00:09:47,980
Speaker 7:  Same. That's why I said that. I think all of us

163
00:09:47,980 --> 00:09:48,800
Speaker 6:  Did.

164
00:09:48,800 --> 00:09:52,780
Speaker 5:  But yeah, Instagram seems to be the kind of place people curate

165
00:09:52,780 --> 00:09:56,200
Speaker 5:  a little more and pay a little more attention to and I think that for me

166
00:09:56,200 --> 00:10:00,020
Speaker 5:  was like the, the startup there was really nice in that I just hit the like

167
00:10:00,020 --> 00:10:03,010
Speaker 5:  follow everybody and it has mostly been okay so far.

168
00:10:03,010 --> 00:10:06,660
Speaker 7:  Yeah, there's something about Meta's relationship with the news industry

169
00:10:06,660 --> 00:10:09,420
Speaker 7:  here that I think it's important for us to talk about early on and I'm curious

170
00:10:09,420 --> 00:10:13,250
Speaker 7:  what you guys think of that. I know they really do not

171
00:10:13,250 --> 00:10:16,860
Speaker 7:  want to, I guess, embrace the news industry on

172
00:10:16,860 --> 00:10:20,600
Speaker 7:  Threads even though they know that that's critical to actually killing Twitter.

173
00:10:20,600 --> 00:10:24,540
Speaker 7:  That's Twitter's, at least up until Elon, that was Twitter's lifeblood was

174
00:10:24,540 --> 00:10:28,380
Speaker 7:  the fact that news broke on Twitter. Meta has been

175
00:10:28,380 --> 00:10:31,460
Speaker 7:  actively trying to distance itself from the news industry, right? For the

176
00:10:31,460 --> 00:10:35,180
Speaker 7:  last several years they've been literally deprioritizing news in the

177
00:10:35,180 --> 00:10:39,080
Speaker 7:  feed on Facebook and Instagram and they didn't do

178
00:10:39,080 --> 00:10:42,420
Speaker 7:  any, you know, concerted outreach to big media brands to

179
00:10:42,420 --> 00:10:45,940
Speaker 7:  journalists ahead of this besides me and a handful of others getting

180
00:10:45,940 --> 00:10:49,180
Speaker 7:  access a few hours early just to just to see it, to write about

181
00:10:49,180 --> 00:10:52,820
Speaker 7:  it. And I think for this thing to succeed, they have to

182
00:10:52,820 --> 00:10:56,640
Speaker 7:  embrace the news industry if they want Threads to be the kind of,

183
00:10:56,640 --> 00:11:00,580
Speaker 7:  as they say, public conversation platform news is such a critical part of

184
00:11:00,580 --> 00:11:04,080
Speaker 7:  that and it's what people got a lot of value out of Twitter

185
00:11:04,080 --> 00:11:07,860
Speaker 7:  for. I think they hope that Threads will just be this kind of

186
00:11:07,860 --> 00:11:11,280
Speaker 7:  text version of Instagram with all the creators on Instagram, the athletes,

187
00:11:11,280 --> 00:11:15,260
Speaker 7:  the celebrities, the influencers and all of that. But I,

188
00:11:15,260 --> 00:11:18,120
Speaker 7:  I think for Threads to really be the Twitter killer, it has to nail news

189
00:11:18,120 --> 00:11:22,100
Speaker 7:  and I'm not sure Meta has the institutional appetite to

190
00:11:22,100 --> 00:11:24,370
Speaker 7:  embrace that right now. And I'm not sure what that means.

191
00:11:24,370 --> 00:11:27,580
Speaker 6:  Well I think they're, they're scared of it, right? Because like when they

192
00:11:27,580 --> 00:11:30,220
Speaker 6:  embraced news there was congressional hearings,

193
00:11:30,220 --> 00:11:33,860
Speaker 7:  I mean they're literally being like sued and forced by the Canadian government

194
00:11:33,860 --> 00:11:36,900
Speaker 7:  and others to pay news publishers for links. And they're saying we were literally

195
00:11:36,900 --> 00:11:40,760
Speaker 7:  just turn off news in your country rather than pay you to,

196
00:11:40,760 --> 00:11:43,780
Speaker 7:  to post links. Which we could. That's a whole nother, I actually think they're

197
00:11:43,780 --> 00:11:45,610
Speaker 7:  right on that, but that's a whole nother discussion.

198
00:11:45,610 --> 00:11:49,060
Speaker 6:  There's an interesting cuz there's an opportunity here for them because this

199
00:11:49,060 --> 00:11:52,740
Speaker 6:  is a different product because it is treated differently by the

200
00:11:52,740 --> 00:11:56,260
Speaker 6:  users so far and and and kind of perceived

201
00:11:56,260 --> 00:12:00,120
Speaker 6:  differently by everyone. There's a real opportunity here

202
00:12:00,120 --> 00:12:03,260
Speaker 6:  to make that pivot and to actually like be a good

203
00:12:03,260 --> 00:12:06,860
Speaker 6:  partner with news organizations. But I think you're right there, there's

204
00:12:06,860 --> 00:12:09,890
Speaker 6:  doesn't seem to be any appetite and I don't now how they get that.

205
00:12:09,890 --> 00:12:13,740
Speaker 7:  There's two parts to that. Do news organizations want to be partners with

206
00:12:13,740 --> 00:12:16,150
Speaker 7:  Meta? I can tell you no. Yeah,

207
00:12:16,150 --> 00:12:16,960
Speaker 6:  Right. Yeah,

208
00:12:16,960 --> 00:12:20,860
Speaker 7:  No. Do journalists want a Twitter alternative? Absolutely. So it may be this

209
00:12:20,860 --> 00:12:24,780
Speaker 7:  bottom up kind of bubbling thing that forces the big publishers to

210
00:12:24,780 --> 00:12:25,660
Speaker 7:  embrace it.

211
00:12:25,660 --> 00:12:28,500
Speaker 6:  Honestly, I think that's the way they get out of it too, right? Like, like

212
00:12:28,500 --> 00:12:32,490
Speaker 6:  the problem that they're, they're terrified of is are we

213
00:12:32,490 --> 00:12:36,310
Speaker 6:  putting, you know, Ms NBC at the top rather than Fox News and thus

214
00:12:36,310 --> 00:12:39,340
Speaker 6:  we're like censoring people, right? Like that's the terror there. That's,

215
00:12:39,340 --> 00:12:42,700
Speaker 6:  that's the fear is that they're gonna be accused of censorship from one side

216
00:12:42,700 --> 00:12:46,580
Speaker 6:  or the other of this mass politicization of news and you

217
00:12:46,580 --> 00:12:50,400
Speaker 6:  can get around that by like just not being a part of that

218
00:12:50,400 --> 00:12:54,270
Speaker 6:  by also de-emphasizing algorithms and doing that stuff.

219
00:12:54,270 --> 00:12:58,060
Speaker 6:  Which the algorithm side of this is kind of interesting, right? Like the,

220
00:12:58,060 --> 00:13:01,880
Speaker 6:  that main feed no like do you know what's going on there?

221
00:13:01,880 --> 00:13:03,860
Speaker 6:  Cuz no one on thread stepss are

222
00:13:03,860 --> 00:13:07,480
Speaker 5:  Y'all's feeds like 97% people you don't know. Mine is

223
00:13:07,480 --> 00:13:09,770
Speaker 5:  overwhelmingly no people. I don't know.

224
00:13:09,770 --> 00:13:12,780
Speaker 6:  Mine starts people I know and then the further I go they're like, all right,

225
00:13:12,780 --> 00:13:15,140
Speaker 6:  I'm just gonna start throwing you some other people.

226
00:13:15,140 --> 00:13:19,020
Speaker 7:  I followed a lot of people right before it went to public launch, so I

227
00:13:19,020 --> 00:13:22,460
Speaker 7:  may have a skewed like version of this, but I've been following people pretty

228
00:13:22,460 --> 00:13:25,900
Speaker 7:  quickly. I don't actually, they actually hide how many people you're following,

229
00:13:25,900 --> 00:13:28,980
Speaker 7:  which is an interesting choice. I follow a lot of people. It's actually been

230
00:13:28,980 --> 00:13:32,340
Speaker 7:  pretty good also at surfacing people that I would want to follow that people

231
00:13:32,340 --> 00:13:35,460
Speaker 7:  I follow have responded to and I can see the little plus icon and tap it

232
00:13:35,460 --> 00:13:39,100
Speaker 7:  in the feed. I do definitely get you, you're already seeing the Instagram,

233
00:13:39,100 --> 00:13:42,850
Speaker 7:  LinkedIn type thirst trap influencer. Yeah, that was me yesterday on there.

234
00:13:42,850 --> 00:13:44,610
Speaker 7:  It's it's crazy. The hustle

235
00:13:44,610 --> 00:13:45,500
Speaker 5:  Bros found it so

236
00:13:45,500 --> 00:13:48,700
Speaker 7:  Fast. Yeah, so fast. As the network builds, I have a feeling that we'll get

237
00:13:48,700 --> 00:13:51,580
Speaker 7:  sorted out and they're gonna keep, there's no one who understands tweaking

238
00:13:51,580 --> 00:13:55,140
Speaker 7:  algorithms better than Meta to produce outcomes. So they're doing a very

239
00:13:55,140 --> 00:13:58,940
Speaker 7:  light ranked version of base, basically the Instagram feed for this in terms

240
00:13:58,940 --> 00:14:02,820
Speaker 7:  of what is prioritized, this is built off of Instagram's tech stack.

241
00:14:02,820 --> 00:14:06,220
Speaker 7:  This is basically a a a different version of Instagram. Yeah.

242
00:14:06,220 --> 00:14:07,240
Speaker 6:  So no boobies,

243
00:14:07,240 --> 00:14:10,860
Speaker 7:  No boobies, no nudity at all. Yeah. Which is actually a very key

244
00:14:10,860 --> 00:14:14,720
Speaker 7:  difference to Twitter and I saw a very funny tweet today that just said Twitter

245
00:14:14,720 --> 00:14:18,600
Speaker 7:  may just become Tumblr for in sells after all this.

246
00:14:18,600 --> 00:14:22,500
Speaker 7:  But yeah, there's, there's no nudity. This is the Instagram code

247
00:14:22,500 --> 00:14:26,420
Speaker 7:  of conduct community guidelines. There are, I saw some internal docs on this

248
00:14:26,420 --> 00:14:30,130
Speaker 7:  where very severe violations, so sharing

249
00:14:30,130 --> 00:14:34,100
Speaker 7:  csam, that sort of thing on Threads will result in penalties

250
00:14:34,100 --> 00:14:36,880
Speaker 7:  on your Instagram account. But for the vast majority of things,

251
00:14:36,880 --> 00:14:40,520
Speaker 7:  misinformation, bullying, that sort of thing,

252
00:14:40,520 --> 00:14:43,380
Speaker 7:  the penalties and strikes you get on Threads will not ported over to your

253
00:14:43,380 --> 00:14:46,820
Speaker 7:  Instagram account. So for now at least they are treating the apps even though

254
00:14:46,820 --> 00:14:50,680
Speaker 7:  they're sharing account data as separate things to moderate,

255
00:14:50,680 --> 00:14:54,400
Speaker 6:  How is that moderation gonna work? Because I feel like, like Instagram

256
00:14:54,400 --> 00:14:58,260
Speaker 6:  is less of a trash fire than a lot of the other social media products out

257
00:14:58,260 --> 00:15:01,930
Speaker 6:  there, right? And it's because of that extensive moderation, but

258
00:15:01,930 --> 00:15:05,820
Speaker 6:  also how does that help foster the conversations that they seem to

259
00:15:05,820 --> 00:15:06,860
Speaker 6:  wanna foster? I

260
00:15:06,860 --> 00:15:10,820
Speaker 7:  Mean over a billion users, I don't know seems to be working. That's fair.

261
00:15:10,820 --> 00:15:13,580
Speaker 7:  I mean everyone has their own view of this, right? You could have a wildly

262
00:15:13,580 --> 00:15:17,340
Speaker 7:  different experience based on who you are, your race, your gender, your

263
00:15:17,340 --> 00:15:20,420
Speaker 7:  identity, all those things, right? This is the thing with these social networks

264
00:15:20,420 --> 00:15:24,240
Speaker 7:  is we have our own opinions that are based on our own view of them

265
00:15:24,240 --> 00:15:27,540
Speaker 7:  and we're really unable to see the full picture. The only one who sees the

266
00:15:27,540 --> 00:15:30,740
Speaker 7:  full picture is Mark Zuckerberg. They think they can make a nicer version

267
00:15:30,740 --> 00:15:34,020
Speaker 7:  of Twitter. Zuckerberg's been very clear about that publicly in

268
00:15:34,020 --> 00:15:37,680
Speaker 7:  Threads and sees the fact that Twitter has become

269
00:15:37,680 --> 00:15:41,340
Speaker 7:  meaner and I would say a much less friendly place to be in the last several

270
00:15:41,340 --> 00:15:45,140
Speaker 7:  months. And it's very just ironic to me that this is

271
00:15:45,140 --> 00:15:49,080
Speaker 7:  Meta now coming in and saying we're gonna make the nice social network. Yes,

272
00:15:49,080 --> 00:15:53,043
Speaker 7:  we contributed to people rioting January

273
00:15:53,300 --> 00:15:57,300
Speaker 7:  6th, but that was a long time ago. Let's forget about

274
00:15:57,300 --> 00:15:57,990
Speaker 7:  that. Let's move on.

275
00:15:57,990 --> 00:15:59,100
Speaker 6:  Don't worry about it. Don't worry about

276
00:15:59,100 --> 00:16:02,700
Speaker 5:  It. I just went back and found a big wired feature that happened when I was

277
00:16:02,700 --> 00:16:06,340
Speaker 5:  there when Kevin Strom was in charge of Instagram about how they wanted to

278
00:16:06,340 --> 00:16:09,420
Speaker 5:  make Instagram the nicer place and basically moderate more

279
00:16:09,420 --> 00:16:13,140
Speaker 5:  aggressively and push harder towards being a place

280
00:16:13,140 --> 00:16:16,700
Speaker 5:  where people are actually nice to each other. And I do think to some extent

281
00:16:16,700 --> 00:16:20,380
Speaker 5:  that worked. I also think the way Instagram is structured has

282
00:16:20,380 --> 00:16:24,270
Speaker 5:  hidden a lot of that, right? And that goes back to the like posts and comments

283
00:16:24,270 --> 00:16:28,240
Speaker 5:  thing. It's like the awful stuff people do to each other in replies

284
00:16:28,240 --> 00:16:32,040
Speaker 5:  to stories. Most people don't see like so much of what happens on Facebook,

285
00:16:32,040 --> 00:16:35,860
Speaker 5:  people see because it's there and on Twitter it's even more public so it's

286
00:16:35,860 --> 00:16:38,940
Speaker 5:  more obvious. Whereas Instagram is like, everything is kind of a couple of

287
00:16:38,940 --> 00:16:42,860
Speaker 5:  layers down. So just your exposure to the bad

288
00:16:42,860 --> 00:16:46,780
Speaker 5:  stuff that happens on Instagram as a bystander is just much less. Which

289
00:16:46,780 --> 00:16:49,660
Speaker 5:  I think is the thing that is so interesting about Threads. And back to your

290
00:16:49,660 --> 00:16:53,060
Speaker 5:  point about the, the news business coming in. This app is so

291
00:16:53,060 --> 00:16:56,820
Speaker 5:  deliberately public, right? Like there's no DMs, there's no groups, there's

292
00:16:56,820 --> 00:17:00,020
Speaker 5:  no community. Like, and and Moser keeps saying over and over like, we see

293
00:17:00,020 --> 00:17:03,740
Speaker 5:  this as a place for public conversations. And I think what that's

294
00:17:03,740 --> 00:17:07,620
Speaker 5:  gonna do is just show the whole platform to everybody and especially

295
00:17:07,620 --> 00:17:11,020
Speaker 5:  as they do things like improve search and if hashtags become a thing, like

296
00:17:11,020 --> 00:17:14,940
Speaker 5:  it's just gonna be easier to move around inside of Threads and as you

297
00:17:14,940 --> 00:17:18,660
Speaker 5:  do, whatever they don't do moderation

298
00:17:18,660 --> 00:17:22,420
Speaker 5:  wise is going to become really obvious really fast. And I wonder how that

299
00:17:22,420 --> 00:17:25,840
Speaker 5:  changes the way people feel about the platform when you can just

300
00:17:25,840 --> 00:17:26,490
Speaker 5:  see.

301
00:17:26,490 --> 00:17:30,340
Speaker 7:  Yeah, I will say that institutionally Meta is in a very much

302
00:17:30,340 --> 00:17:34,117
Speaker 7:  different spot than it was in 20 16, 20 17,

303
00:17:34,117 --> 00:17:37,920
Speaker 7:  20 18. They realized that they really over censored.

304
00:17:37,920 --> 00:17:41,780
Speaker 7:  At least they think that now in retrospect, even honestly

305
00:17:41,780 --> 00:17:45,420
Speaker 7:  through the Covid pandemic, I think they would do some of that differently.

306
00:17:45,420 --> 00:17:49,380
Speaker 7:  I think a lot of the big internet platforms would in terms of what was initially

307
00:17:49,380 --> 00:17:53,340
Speaker 7:  censored versus not. And I do think they want to be a little looser on

308
00:17:53,340 --> 00:17:57,120
Speaker 7:  the censorship this time. And that is a general sentiment in Silicon

309
00:17:57,120 --> 00:18:00,980
Speaker 7:  Valley at the big internet platforms that we are entering

310
00:18:00,980 --> 00:18:03,500
Speaker 7:  a, a looser phase of the internet in that regard.

311
00:18:03,500 --> 00:18:07,220
Speaker 5:  I also think if I'm Meta, I I have been sort of, I

312
00:18:07,220 --> 00:18:11,140
Speaker 5:  don't know, bullied into not caring anymore about some of these things now.

313
00:18:11,140 --> 00:18:14,580
Speaker 5:  Like Nick Clegg gets paid a lot of money to take everyone's heat about all

314
00:18:14,580 --> 00:18:17,620
Speaker 5:  things content moderation. And the rest of the company just doesn't have

315
00:18:17,620 --> 00:18:21,300
Speaker 5:  to care that much. Like Mark Zuckerberg is off doing other things. He's not,

316
00:18:21,300 --> 00:18:24,380
Speaker 5:  he's not picking political fights anymore. He's like, oh, you want, Congress

317
00:18:24,380 --> 00:18:27,540
Speaker 5:  wants to yell at us again. Like whatever, we're gonna keep doing our thing.

318
00:18:27,540 --> 00:18:31,220
Speaker 5:  I just think if I'm Meta they're like so iner to this at this point

319
00:18:31,220 --> 00:18:35,140
Speaker 5:  that I think that fear doesn't seem to exist within the company as

320
00:18:35,140 --> 00:18:36,290
Speaker 5:  much as it used to.

321
00:18:36,290 --> 00:18:39,140
Speaker 7:  Well for now until, until we have the Threads election. Well yeah,

322
00:18:39,140 --> 00:18:43,060
Speaker 5:  That's fair. Yeah. 2026 or I guess 2028

323
00:18:43,060 --> 00:18:45,780
Speaker 5:  election. It's gonna be, it's gonna be wild on Threads.

324
00:18:45,780 --> 00:18:48,160
Speaker 6:  You don't think it's gonna be 2024

325
00:18:48,160 --> 00:18:52,100
Speaker 7:  At this rate if they hit a hundred million users in a week, I mean

326
00:18:52,100 --> 00:18:54,400
Speaker 7:  is RFK Jr on there yet? I dunno.

327
00:18:54,400 --> 00:18:58,280
Speaker 5:  The Threads Chad G P T election is just gonna be outrageous. No one is ready

328
00:18:58,280 --> 00:19:01,960
Speaker 5:  for this Alex. Sh can we, can we talk about what we call these things

329
00:19:01,960 --> 00:19:03,500
Speaker 5:  yet? Alex Cranz. Yeah,

330
00:19:03,500 --> 00:19:05,540
Speaker 6:  I mean I have really strong opinions about it.

331
00:19:05,540 --> 00:19:06,260
Speaker 5:  I know you do. I

332
00:19:06,260 --> 00:19:07,000
Speaker 7:  Know you do Cranz

333
00:19:07,000 --> 00:19:10,050
Speaker 6:  And I know you guys all think I'm wrong, but we should just call 'em tweets,

334
00:19:10,050 --> 00:19:12,920
Speaker 5:  Make the case for this. I would like to come back to this, but I would you,

335
00:19:12,920 --> 00:19:15,140
Speaker 5:  you wrote the thing about it, so you get to go first.

336
00:19:15,140 --> 00:19:18,060
Speaker 6:  I wrote it and I was the, the best comment I got was somebody being like,

337
00:19:18,060 --> 00:19:21,380
Speaker 6:  I thought this was just gonna be memes and you actually had an argument.

338
00:19:21,380 --> 00:19:25,020
Speaker 6:  And I was like, yes, that's right. I thought about this for more than two

339
00:19:25,020 --> 00:19:27,380
Speaker 6:  minutes. At least three minutes. We

340
00:19:27,380 --> 00:19:30,540
Speaker 5:  Call that the crayon special. This seems like I'm just bullshitting you,

341
00:19:30,540 --> 00:19:33,640
Speaker 5:  but I actually have some thoughts here.

342
00:19:33,640 --> 00:19:37,530
Speaker 6:  But you know, tweets started as a thing that was

343
00:19:37,530 --> 00:19:41,320
Speaker 6:  necessary because an app needed to put something on there besides Post.

344
00:19:41,320 --> 00:19:44,720
Speaker 6:  Cuz I think post in that language was like weird. That's why it started.

345
00:19:44,720 --> 00:19:47,220
Speaker 6:  And they were like, oh you should just call it a, he was like calling it

346
00:19:47,220 --> 00:19:49,940
Speaker 6:  a tweet and everybody's like, that's stupid. Call it a tweet. And he's like,

347
00:19:49,940 --> 00:19:53,340
Speaker 6:  oh that's a real word. I'll just use that cuz it's a real word that already

348
00:19:53,340 --> 00:19:56,440
Speaker 6:  exists and everybody likes it and he knows what it means. And we, we've,

349
00:19:56,440 --> 00:19:59,380
Speaker 6:  we associated it with Twitter because they eventually trademarked

350
00:19:59,380 --> 00:20:03,180
Speaker 6:  it, so that's fair. But it originally started

351
00:20:03,180 --> 00:20:06,940
Speaker 6:  to just like, I need a way to like pop off a pithy response

352
00:20:06,940 --> 00:20:10,880
Speaker 6:  that's called a tweet. And I think like it's, it's surpassed

353
00:20:10,880 --> 00:20:14,660
Speaker 6:  the company that that trademarked it, right? Like a Kleenex. You're not checking

354
00:20:14,660 --> 00:20:18,370
Speaker 6:  what brand of Kleenex it is. It's just Kleenex. Same with E Ink.

355
00:20:18,370 --> 00:20:21,620
Speaker 6:  It's almost certainly e inked, but like you're not checking what brand of

356
00:20:21,620 --> 00:20:23,940
Speaker 6:  electronic paper it is. You're just gonna assume it's e ink.

357
00:20:23,940 --> 00:20:26,360
Speaker 5:  Google's really the example here, right? Like it's, Google

358
00:20:26,360 --> 00:20:27,640
Speaker 6:  Is the best example of this.

359
00:20:27,640 --> 00:20:30,740
Speaker 5:  You Google stuff on Bing now, like that's a thing people do. Yeah, they go

360
00:20:30,740 --> 00:20:32,950
Speaker 5:  to bing.com and they Google something. Google

361
00:20:32,950 --> 00:20:33,810
Speaker 6:  Hates that.

362
00:20:33,810 --> 00:20:35,170
Speaker 5:  Yeah, it's, it's hilarious.

363
00:20:35,170 --> 00:20:38,860
Speaker 6:  They hate it so much. I think it's a normal thing that the

364
00:20:38,860 --> 00:20:42,500
Speaker 6:  English language does. I think it's okay to accept it and embrace

365
00:20:42,500 --> 00:20:46,460
Speaker 6:  it. And I think that I'm really tired of every single time there's a

366
00:20:46,460 --> 00:20:49,820
Speaker 6:  new platform, everybody being like, I got the jokes, what are we gonna call

367
00:20:49,820 --> 00:20:53,260
Speaker 6:  this one? And then we have to have like this, this joke

368
00:20:53,260 --> 00:20:57,220
Speaker 6:  conversation for three, three cycles it feels like. And

369
00:20:57,220 --> 00:21:00,140
Speaker 6:  everybody's just like, ah, here's my jokes. And I'm like, no, just call 'em

370
00:21:00,140 --> 00:21:00,840
Speaker 6:  tweets.

371
00:21:00,840 --> 00:21:04,570
Speaker 5:  I'm, I worry sometimes that it's not a joke. Like Blue Sky users

372
00:21:04,570 --> 00:21:08,380
Speaker 5:  seem to think they're called skeets and on Macedon they are technically

373
00:21:08,380 --> 00:21:12,100
Speaker 5:  called tuts. Like this is the world we live in now. Like we, we

374
00:21:12,100 --> 00:21:14,620
Speaker 5:  can't let this happen. We can't. They

375
00:21:14,620 --> 00:21:18,240
Speaker 6:  Got rid of tuts once the guy, like the guy didn't know that it meant fart

376
00:21:18,240 --> 00:21:21,580
Speaker 6:  in English. And so like a YouTuber was like, Hey I'll pay your

377
00:21:21,580 --> 00:21:25,210
Speaker 6:  Patreon if you keep using Tut cuz it's so funny. And he's like,

378
00:21:25,210 --> 00:21:28,700
Speaker 6:  okay. And so he did. And then later he was like, oh I was saying farts all

379
00:21:28,700 --> 00:21:32,313
Speaker 6:  this time, that sucks. And he got rid of it like, it was like November, 2022.

380
00:21:32,580 --> 00:21:35,220
Speaker 6:  Okay. He was like, we get rid of Toots and the Mastodon users were like,

381
00:21:35,220 --> 00:21:38,920
Speaker 6:  not our toots. And it's like, I don't wanna be involved in that conversation.

382
00:21:38,920 --> 00:21:40,760
Speaker 6:  You're fighting for the word tut.

383
00:21:40,760 --> 00:21:44,540
Speaker 5:  If I ever pick it for anything, I'm gonna write not our toots on my

384
00:21:44,540 --> 00:21:47,540
Speaker 5:  sign. That's just, that's what the sign is gonna say. Heath, they really

385
00:21:47,540 --> 00:21:50,500
Speaker 5:  wanna call it Threads, right? Yes. That's the, that's the idea is that that's

386
00:21:50,500 --> 00:21:50,780
Speaker 5:  the

387
00:21:50,780 --> 00:21:51,200
Speaker 6:  Official,

388
00:21:51,200 --> 00:21:53,980
Speaker 7:  That's the official thing. You're gonna Threads on Threads. That

389
00:21:53,980 --> 00:21:55,940
Speaker 5:  Sucks, right? Like we don't, we don't like this or

390
00:21:55,940 --> 00:21:59,180
Speaker 7:  Just call it a post. Like we don't, you know, let's not overthink this like

391
00:21:59,180 --> 00:22:01,540
Speaker 7:  we're posting, we're posting on Maine, but

392
00:22:01,540 --> 00:22:02,220
Speaker 6:  They're little posts

393
00:22:02,220 --> 00:22:05,770
Speaker 5:  Posting on Maine. We're gonna open a diner called Posting on Maine.

394
00:22:05,770 --> 00:22:08,420
Speaker 7:  They're 500 characters. They're bigger than tweets. What are you talking

395
00:22:08,420 --> 00:22:09,540
Speaker 7:  about? Cranz 500

396
00:22:09,540 --> 00:22:11,050
Speaker 6:  Characters is not a lot,

397
00:22:11,050 --> 00:22:12,090
Speaker 7:  It's bigger than tweets.

398
00:22:12,090 --> 00:22:13,020
Speaker 5:  It's bigger, it's

399
00:22:13,020 --> 00:22:15,620
Speaker 6:  Bigger than tweets, but it's still, it's double smaller than a blog. What

400
00:22:15,620 --> 00:22:18,830
Speaker 7:  Is a blog anymore? It's they're, these are all posts, they're just posts.

401
00:22:18,830 --> 00:22:20,480
Speaker 7:  Don't call it tweet.

402
00:22:20,480 --> 00:22:23,810
Speaker 6:  We have to be able to drill down. We have to be able to be like, like micro,

403
00:22:23,810 --> 00:22:27,240
Speaker 6:  like no I don't wanna do micro blogs. No I don't wanna call 'em micro post.

404
00:22:27,240 --> 00:22:28,150
Speaker 6:  That's stupid.

405
00:22:28,150 --> 00:22:32,060
Speaker 7:  We're posting on Maine The Verge account Ruben, he's going wild right

406
00:22:32,060 --> 00:22:33,690
Speaker 7:  now. He's posting on Maine.

407
00:22:33,690 --> 00:22:36,220
Speaker 6:  He's calling him Zuck and I'm gonna fight Ruben.

408
00:22:36,220 --> 00:22:37,410
Speaker 7:  I kind of like Zucks.

409
00:22:37,410 --> 00:22:38,120
Speaker 6:  Nope. No

410
00:22:38,120 --> 00:22:38,540
Speaker 5:  I'm out on

411
00:22:38,540 --> 00:22:39,300
Speaker 6:  Zuck. I'm sorry I said

412
00:22:39,300 --> 00:22:43,000
Speaker 5:  It. Zucks is what Facebook has to call, its digital currency. So that is

413
00:22:43,000 --> 00:22:43,710
Speaker 5:  spoken for

414
00:22:43,710 --> 00:22:47,400
Speaker 7:  Which, which is dead now. So maybe it's good for this, it

415
00:22:47,400 --> 00:22:51,360
Speaker 7:  rhymes with, you know, great stuff. Fun fact, Cranz Twitter did

416
00:22:51,360 --> 00:22:55,280
Speaker 7:  not actually come up with the word tweet. The first popularization of that

417
00:22:55,280 --> 00:22:58,370
Speaker 7:  was terrific. A third party client.

418
00:22:58,370 --> 00:23:01,540
Speaker 6:  Yeah, it was the Twitter horrific guy was like, I need something to call

419
00:23:01,540 --> 00:23:05,100
Speaker 6:  it. Yeah. And so he called it twit and it was a Twitter employee who was

420
00:23:05,100 --> 00:23:08,600
Speaker 6:  also a Twitter horrific beta user who was like, Hey call 'em

421
00:23:08,600 --> 00:23:12,460
Speaker 6:  tweets. And he used it and then like a year and a half later Twitter was

422
00:23:12,460 --> 00:23:15,050
Speaker 6:  like, we also call them tweets.

423
00:23:15,050 --> 00:23:18,860
Speaker 7:  Yeah. Twitter famous for taking all of its early good ideas

424
00:23:18,860 --> 00:23:21,940
Speaker 7:  from its third party developers then it then killed in the cradle.

425
00:23:21,940 --> 00:23:25,740
Speaker 5:  Yeah. Weird. And then never having any other good ideas. Yeah. Ever again

426
00:23:25,740 --> 00:23:28,660
Speaker 5:  after that. Let's talk about the decentralization piece of this cuz this

427
00:23:28,660 --> 00:23:31,920
Speaker 5:  is, yes, like for, for me as a, as a open social

428
00:23:31,920 --> 00:23:35,180
Speaker 5:  web believer. Yeah. This is the thing I've been most looking forward to and

429
00:23:35,180 --> 00:23:38,420
Speaker 5:  you've been reporting for months that this is a thing that that Instagram's

430
00:23:38,420 --> 00:23:41,760
Speaker 5:  looking into for threats that it was gonna interoperate with Activity Pub

431
00:23:41,760 --> 00:23:44,200
Speaker 5:  and the masks that on people have been up in arms and

432
00:23:44,200 --> 00:23:45,250
Speaker 7:  Of course, yeah,

433
00:23:45,250 --> 00:23:47,820
Speaker 5:  Yeah. There's been a lot of feelings on the internet about what this thing

434
00:23:47,820 --> 00:23:51,420
Speaker 5:  was gonna be before anybody knew what it was gonna be. But it

435
00:23:51,420 --> 00:23:55,120
Speaker 5:  launched with no fediverse anything

436
00:23:55,120 --> 00:23:58,820
Speaker 5:  yet. But Moser in, you're talking to him, seemed to be more

437
00:23:58,820 --> 00:24:02,650
Speaker 5:  enthusiastic about Activity Pub than I even expected. Is that your read?

438
00:24:02,650 --> 00:24:06,570
Speaker 7:  Yeah. So I reported in Command Line last week my newsletter

439
00:24:06,570 --> 00:24:10,380
Speaker 7:  that they were telling big people in the fediverse that they were

440
00:24:10,380 --> 00:24:14,180
Speaker 7:  going to delay activity pub integration into Threads by several

441
00:24:14,180 --> 00:24:17,920
Speaker 7:  months. I have a feeling it may be later now we could be talking

442
00:24:17,920 --> 00:24:21,610
Speaker 7:  six plus months just given how much Threads has scaled beyond what they were

443
00:24:21,610 --> 00:24:25,500
Speaker 7:  initially expecting. They onboarded the entirety of the fediverse to

444
00:24:25,500 --> 00:24:29,420
Speaker 7:  Threads in like three hours. So give a sense of like the

445
00:24:29,420 --> 00:24:32,980
Speaker 7:  scale here. Yeah. Yes. They had been meeting with large

446
00:24:32,980 --> 00:24:36,630
Speaker 7:  server admins, the CO of Mastodon himself, big

447
00:24:36,630 --> 00:24:40,520
Speaker 7:  third party developers on activity pub for the last couple of weeks

448
00:24:40,520 --> 00:24:44,500
Speaker 7:  to talk about this. They wanna set up a round table of, you

449
00:24:44,500 --> 00:24:48,460
Speaker 7:  know, fediverse leaders to kind of inform them as they try to integrate into

450
00:24:48,460 --> 00:24:52,120
Speaker 7:  the network. I was kind of surprised, I guess though

451
00:24:52,120 --> 00:24:55,940
Speaker 7:  not entirely to hear Moster say that he thinks this is the

452
00:24:55,940 --> 00:24:59,620
Speaker 7:  direction that the internet is headed in these decentralized platforms, which

453
00:24:59,620 --> 00:25:03,380
Speaker 7:  I know David, your eyes must have gotten really huge when you saw that. It's

454
00:25:03,380 --> 00:25:05,610
Speaker 5:  Music to my ears man. Yeah,

455
00:25:05,610 --> 00:25:09,180
Speaker 7:  Yeah. And for Meta of course this is a, a

456
00:25:09,180 --> 00:25:13,100
Speaker 7:  creator thing where they think the pitch can be, if you're a creator

457
00:25:13,100 --> 00:25:17,060
Speaker 7:  and you build an audience on Threads, if we decide to shut down Threads

458
00:25:17,060 --> 00:25:20,060
Speaker 7:  like we did every other standalone app we've ever launched as a company that

459
00:25:20,060 --> 00:25:23,460
Speaker 7:  we didn't acquire, you'll at least be able to take everything with you to

460
00:25:23,460 --> 00:25:27,300
Speaker 7:  Mastodon or to another activity pub client. That's, that's at least the

461
00:25:27,300 --> 00:25:30,020
Speaker 7:  pitch. Whether they follow through with that and that all works as planned

462
00:25:30,020 --> 00:25:33,340
Speaker 7:  remains to be seen. And there's obviously, you know, you should have plenty

463
00:25:33,340 --> 00:25:37,320
Speaker 7:  of skepticism with the largest centralized social media platform in the world

464
00:25:37,320 --> 00:25:41,180
Speaker 7:  saying it's gonna embrace a decentralized protocol. Yeah. I do think

465
00:25:41,180 --> 00:25:45,010
Speaker 7:  the fact that they're doing it with Threads with a new app and not Instagram

466
00:25:45,010 --> 00:25:48,930
Speaker 7:  signals that they're serious about this and in most series retelling to me

467
00:25:48,930 --> 00:25:52,700
Speaker 7:  they really can't retroactively and embrace Activity pub on

468
00:25:52,700 --> 00:25:56,060
Speaker 7:  an existing app that's at that kind of scale. They needed to have something

469
00:25:56,060 --> 00:25:59,900
Speaker 7:  fresh and it's pretty clear that he drove this. I was re-watching a Ted Talk

470
00:25:59,900 --> 00:26:03,790
Speaker 7:  he gave last year about this and about how creators will inevitably

471
00:26:03,790 --> 00:26:07,380
Speaker 7:  brace embrace these open protocols for a lot of these reasons. This is something

472
00:26:07,380 --> 00:26:11,020
Speaker 7:  he's been saying even before Threads was a, was a twinkle in Meta's

473
00:26:11,020 --> 00:26:14,440
Speaker 7:  eye. I do think they're gonna be met with extreme

474
00:26:14,440 --> 00:26:17,860
Speaker 7:  fierce backlash in the fediverse. They know this, they're already getting

475
00:26:17,860 --> 00:26:21,400
Speaker 7:  this. I've been hearing from people in the fediverse that

476
00:26:21,400 --> 00:26:24,340
Speaker 7:  you're supposed to just say fediverse not the fediverse. I'm, I'm gonna get

477
00:26:24,340 --> 00:26:25,980
Speaker 7:  a bunch of angry tweets about that. Oh,

478
00:26:25,980 --> 00:26:29,460
Speaker 5:  People from fediverse? No, I'm out on that. Yeah, that's like, it's like

479
00:26:29,460 --> 00:26:30,940
Speaker 5:  Brooklyn. It's like a neighborhood.

480
00:26:30,940 --> 00:26:33,900
Speaker 7:  I I'm all for it. I think activity pub's a great idea. I will say the

481
00:26:33,900 --> 00:26:37,250
Speaker 7:  early pro powerful community on

482
00:26:37,250 --> 00:26:41,050
Speaker 7:  fediverse, y'all are a little too anal on your terms. Like

483
00:26:41,050 --> 00:26:44,900
Speaker 7:  just like, let's just loosen up a little bit. But yeah, there's,

484
00:26:44,900 --> 00:26:48,780
Speaker 7:  there's no trust of Meta here. I tend to side with John Gruber on, if

485
00:26:48,780 --> 00:26:52,460
Speaker 7:  you're gonna really say that this is an open protocol, you need to treat

486
00:26:52,460 --> 00:26:56,140
Speaker 7:  it as one and you need to let anyone come on and not just be already

487
00:26:56,140 --> 00:26:59,980
Speaker 7:  talking about blocking them at least see, see what they're gonna do. But

488
00:26:59,980 --> 00:27:03,940
Speaker 6:  I mean that's like the beauty of fediverse. I'm trying to embrace

489
00:27:03,940 --> 00:27:05,540
Speaker 5:  That. I hate that already. No, there's

490
00:27:05,540 --> 00:27:06,690
Speaker 6:  An article that should go there

491
00:27:06,690 --> 00:27:10,180
Speaker 5:  That was awful. I didn't, it's like, it's like when Tim Cook says we, this

492
00:27:10,180 --> 00:27:13,940
Speaker 5:  is iPhone. Like no it's not, it it's the it's an iPhone. It's

493
00:27:13,940 --> 00:27:15,620
Speaker 5:  the, it is the fediverse. Yeah.

494
00:27:15,620 --> 00:27:19,480
Speaker 6:  But this is like, the point of the fediverse is that if you don't, like

495
00:27:19,480 --> 00:27:22,520
Speaker 6:  if you go and you build a big audience on Threads and it finally goes live

496
00:27:22,520 --> 00:27:26,300
Speaker 6:  and you don't like that you can't post Boobies, you can

497
00:27:26,300 --> 00:27:29,480
Speaker 6:  go to a server where you can post boobies.

498
00:27:29,480 --> 00:27:33,300
Speaker 7:  Except the boobies will not be on Threads. So where, right.

499
00:27:33,300 --> 00:27:37,020
Speaker 7:  What server has the biggest audience, it's going to be Threads by a

500
00:27:37,020 --> 00:27:40,980
Speaker 7:  factor of many acts. Yeah. So do you care about, you

501
00:27:40,980 --> 00:27:43,480
Speaker 7:  know, censorship, do you care about distribution?

502
00:27:43,480 --> 00:27:46,370
Speaker 6:  You're gonna have to make a choice. Threads are boobies.

503
00:27:46,370 --> 00:27:49,840
Speaker 7:  It's very clear. And of course Meta knows this better than any other company

504
00:27:49,840 --> 00:27:53,220
Speaker 7:  is that distribution trumps all. Yep. And I will

505
00:27:53,220 --> 00:27:57,100
Speaker 7:  say the earliest bull case for Threads is

506
00:27:57,100 --> 00:28:00,300
Speaker 7:  that the notifications are just popping off. Like I know Nilay and others

507
00:28:00,300 --> 00:28:02,540
Speaker 7:  were talking about this when they first got on.

508
00:28:02,540 --> 00:28:04,020
Speaker 6:  I thought my phone was ringing last

509
00:28:04,020 --> 00:28:07,860
Speaker 7:  Night. It's insane. I had to mute it in instantly because it's got that Instagram

510
00:28:07,860 --> 00:28:11,720
Speaker 7:  graph built in the day one distribution that you have on Threads

511
00:28:11,720 --> 00:28:15,530
Speaker 7:  is just, it's so much more than Mastodon. It's honestly more

512
00:28:15,530 --> 00:28:19,360
Speaker 7:  than Twitter these days. Like there are eyeballs there. Yep.

513
00:28:19,360 --> 00:28:22,360
Speaker 7:  And as a creator on one of these platforms, when you're not getting paid

514
00:28:22,360 --> 00:28:25,460
Speaker 7:  by the platform, guess what? You're gonna want to use the platform with the

515
00:28:25,460 --> 00:28:29,340
Speaker 7:  biggest reach. And so Meta knows this and I think even when they hook

516
00:28:29,340 --> 00:28:31,830
Speaker 7:  into Activity Pub, they know they're gonna be the server with the biggest

517
00:28:31,830 --> 00:28:35,800
Speaker 7:  reach. Yeah. And so they're going to buy that very fact

518
00:28:35,800 --> 00:28:39,760
Speaker 7:  be able to extend their policies, their way of doing things throughout

519
00:28:39,760 --> 00:28:43,540
Speaker 7:  the, the fediverse. And that's I think what's really

520
00:28:43,540 --> 00:28:47,500
Speaker 7:  getting a lot of the other server admins worried is that all of a

521
00:28:47,500 --> 00:28:51,420
Speaker 7:  sudden this giant open protocol may be just governed by the Instagram

522
00:28:51,420 --> 00:28:53,140
Speaker 7:  content guidelines. Are

523
00:28:53,140 --> 00:28:57,060
Speaker 6:  They gonna actually monetize Threads? Like Yes.

524
00:28:57,060 --> 00:28:59,860
Speaker 6:  Like Twitter was notoriously difficult to

525
00:28:59,860 --> 00:29:01,160
Speaker 6:  monetize.

526
00:29:01,160 --> 00:29:04,940
Speaker 7:  Yes. For many reasons. So I would say incompetence was up

527
00:29:04,940 --> 00:29:05,320
Speaker 7:  there.

528
00:29:05,320 --> 00:29:09,060
Speaker 6:  Is that really the play here or is it Yes. Just like we're,

529
00:29:09,060 --> 00:29:13,020
Speaker 6:  this is our Goodwill project now. You all like us go use Instagram

530
00:29:13,020 --> 00:29:14,510
Speaker 6:  and Facebook where we make our money.

531
00:29:14,510 --> 00:29:17,940
Speaker 7:  We're no longer in a zero interest rate environment. Alex

532
00:29:17,940 --> 00:29:21,820
Speaker 7:  grants? No, they're absolutely gonna put ads in this thing. I would

533
00:29:21,820 --> 00:29:25,620
Speaker 7:  say sooner than they had even expected given the scale. This is Met us Playbook.

534
00:29:25,620 --> 00:29:29,420
Speaker 7:  They wait for something to have the kind of velocity that it could hit, hit

535
00:29:29,420 --> 00:29:31,660
Speaker 7:  a billion users and then they do ads.

536
00:29:31,660 --> 00:29:35,120
Speaker 5:  I think Mon wants you to think that they're not interested in monetizing.

537
00:29:35,120 --> 00:29:38,610
Speaker 5:  He has said a couple of times, Like, he keeps calling it a champagne problem.

538
00:29:38,610 --> 00:29:42,300
Speaker 5:  Yeah. And it's like, well no, this is either gonna work and you're gonna

539
00:29:42,300 --> 00:29:44,940
Speaker 5:  make money off of it or you're gonna shut it down. Like there's no, there's

540
00:29:44,940 --> 00:29:47,500
Speaker 5:  no middle option where this thing continues to live without being

541
00:29:47,500 --> 00:29:51,210
Speaker 7:  Monetized. Yeah. They wanna make sure the product's sticky has good retention.

542
00:29:51,210 --> 00:29:54,520
Speaker 7:  They, they worry about retention. They kind of set the Indus industry benchmark

543
00:29:54,520 --> 00:29:57,820
Speaker 7:  for retention and social networks. They, they have the

544
00:29:57,820 --> 00:30:01,180
Speaker 7:  playbook that they invented that the rest of the industry follows for this.

545
00:30:01,180 --> 00:30:04,930
Speaker 7:  So they will use that playbook. They will add ads when it's at this nice

546
00:30:04,930 --> 00:30:08,310
Speaker 7:  kind of like self circulating, self building

547
00:30:08,310 --> 00:30:12,300
Speaker 7:  place. And yeah, it's gonna look like Instagram in terms of that.

548
00:30:12,300 --> 00:30:12,420
Speaker 7:  I

549
00:30:12,420 --> 00:30:15,870
Speaker 6:  Guess I just wonder how valuable that is because Twitter, in addition to

550
00:30:15,870 --> 00:30:19,460
Speaker 6:  being terrible at monetizing also was much

551
00:30:19,460 --> 00:30:23,300
Speaker 6:  smaller than a lot of these other ones. Right? Like, like it was way smaller

552
00:30:23,300 --> 00:30:26,900
Speaker 6:  than Facebook. It was way smaller than Instagram. And Threads, even if it

553
00:30:26,900 --> 00:30:30,740
Speaker 6:  gets to Twitter size is gonna still be way smaller

554
00:30:30,740 --> 00:30:31,890
Speaker 6:  than the cash cows.

555
00:30:31,890 --> 00:30:35,580
Speaker 7:  Yeah. But you have to approach this as a marketer. If it's another toggle,

556
00:30:35,580 --> 00:30:35,700
Speaker 7:  I

557
00:30:35,700 --> 00:30:37,570
Speaker 6:  Can never do that. So walk me through it, please.

558
00:30:37,570 --> 00:30:41,360
Speaker 7:  Okay. I talk, I I regrettably have to talk to these people for my job. Sorry.

559
00:30:41,360 --> 00:30:44,020
Speaker 7:  No, I'm just kidding. I, I love marketers. Keep, keep talking to me about

560
00:30:44,020 --> 00:30:47,780
Speaker 7:  the platforms. Please. If it's another toggle in your dashboard when you're

561
00:30:47,780 --> 00:30:51,740
Speaker 7:  running an ad on Instagram to run it in Threads and you can reach, you know,

562
00:30:51,740 --> 00:30:55,730
Speaker 7:  a hundred to 300 million people on there, you're gonna do it. It's,

563
00:30:55,730 --> 00:30:59,700
Speaker 7:  yeah, it's zero cost to you. It's all upside. This is where the benefits

564
00:30:59,700 --> 00:31:02,790
Speaker 7:  of scale and graphs kind of

565
00:31:02,790 --> 00:31:06,780
Speaker 7:  coalescing at the plus billion. Mark is going to just keep

566
00:31:06,780 --> 00:31:10,380
Speaker 7:  giving Meta kind of tremendous incumbent advantages at, with new

567
00:31:10,380 --> 00:31:12,460
Speaker 7:  products like this. And they know that this

568
00:31:12,460 --> 00:31:15,980
Speaker 6:  Is why we're not seeing it in Europe yet,

569
00:31:15,980 --> 00:31:19,820
Speaker 6:  right. Is like, cuz when when you first hear about it and you hear

570
00:31:19,820 --> 00:31:22,140
Speaker 6:  about Threads, you're like, well this should go in Europe. Cause I know they're

571
00:31:22,140 --> 00:31:24,240
Speaker 6:  afraid of the dma. But

572
00:31:24,240 --> 00:31:26,500
Speaker 5:  That's the first thing you think of when you think of Threads is this should

573
00:31:26,500 --> 00:31:27,340
Speaker 5:  go to Europe. Always

574
00:31:27,340 --> 00:31:28,500
Speaker 6:  Think of it. Threads

575
00:31:28,500 --> 00:31:29,680
Speaker 5:  Seems very,

576
00:31:29,680 --> 00:31:32,200
Speaker 6:  No, we've been talking a lot, like there's been a lot of noise today about

577
00:31:32,200 --> 00:31:35,940
Speaker 6:  how it's not in Europe yet. And that's, that's, that seems to be

578
00:31:35,940 --> 00:31:39,700
Speaker 6:  because of the dma, right? Like that's the fear is that, that they

579
00:31:39,700 --> 00:31:43,680
Speaker 6:  can't do it because of the dma. And what the

580
00:31:43,680 --> 00:31:47,100
Speaker 6:  DMA says is that like you, you have to be kind of open and honest. You have

581
00:31:47,100 --> 00:31:50,890
Speaker 6:  to like be good stewards and you need to let people

582
00:31:50,890 --> 00:31:53,900
Speaker 6:  take their, their followers where they wanna go and all of this. And that's

583
00:31:53,900 --> 00:31:56,940
Speaker 6:  like, okay, well that sounds like everything that Threads does. And then

584
00:31:56,940 --> 00:32:00,180
Speaker 6:  I guess the other side of that is that also it's part of Meta and Meta is

585
00:32:00,180 --> 00:32:03,540
Speaker 6:  huge and will inevitably swallow everything whole. Because when you're that

586
00:32:03,540 --> 00:32:07,140
Speaker 6:  big, that's just how you process everything.

587
00:32:07,140 --> 00:32:09,880
Speaker 5:  I just have one more thing to say on the monetization before we go, which

588
00:32:09,880 --> 00:32:13,190
Speaker 5:  is this is another place that it is very useful to be part of Instagram,

589
00:32:13,190 --> 00:32:16,980
Speaker 5:  which has a number of very good monetization tools for

590
00:32:16,980 --> 00:32:20,880
Speaker 5:  creators that would lend themselves very well to a product like Threads.

591
00:32:20,880 --> 00:32:24,780
Speaker 5:  Things like gifts and subscriptions and the tips stuff they can

592
00:32:24,780 --> 00:32:28,720
Speaker 5:  do and shopping. Like all that stuff is built and at scale

593
00:32:28,720 --> 00:32:31,940
Speaker 5:  and making huge amounts of money for lots of people. And you can just stick

594
00:32:31,940 --> 00:32:35,220
Speaker 5:  it into Threads without all that much work. I think the interface designers

595
00:32:35,220 --> 00:32:37,620
Speaker 5:  would have some work to do. I think the interface designers already have

596
00:32:37,620 --> 00:32:40,320
Speaker 5:  some work to do, which we can talk about about if you guys would like to.

597
00:32:40,320 --> 00:32:43,620
Speaker 5:  But let's, let's get into, I both wanna talk about the the Europe stuff and

598
00:32:43,620 --> 00:32:46,850
Speaker 5:  then I wanna get to some of the questions that you got about Threads on Threads.

599
00:32:46,850 --> 00:32:49,100
Speaker 5:  Yeah. But first let's take a break. We'll be right

600
00:32:49,100 --> 00:32:53,770
Speaker 5:  back.

601
00:35:04,630 --> 00:35:07,620
Speaker 5:  We're back. Let's talk about this Year Up thing. I don't wanna dwell on this

602
00:35:07,620 --> 00:35:10,900
Speaker 5:  for too long because it's boring policy, but it is worth

603
00:35:10,900 --> 00:35:14,660
Speaker 5:  explaining. And Heath, you, you talked to Moster specifically about

604
00:35:14,660 --> 00:35:18,140
Speaker 5:  this. What, what is your sense of why this thing didn't launch in

605
00:35:18,140 --> 00:35:18,770
Speaker 5:  Europe?

606
00:35:18,770 --> 00:35:22,700
Speaker 7:  Yeah, so Threads is not available in the EU, I'm sorry to everyone and

607
00:35:22,700 --> 00:35:25,440
Speaker 7:  the French countryside on vacation right now.

608
00:35:25,440 --> 00:35:28,460
Speaker 5:  And according to Cranz it's a very European app. So it's a real shake. Yes,

609
00:35:28,460 --> 00:35:29,050
Speaker 5:  it's very European,

610
00:35:29,050 --> 00:35:32,770
Speaker 7:  Everybody wants it. You have to cry into your cheese and your wine. But

611
00:35:32,770 --> 00:35:36,370
Speaker 7:  that does leave out a market of, you know, hundreds of millions of people.

612
00:35:36,370 --> 00:35:40,260
Speaker 7:  It's a huge missed market opportunity for Threads initially.

613
00:35:40,260 --> 00:35:44,220
Speaker 7:  And they know this, this is a really interesting example of what the EU

614
00:35:44,220 --> 00:35:47,980
Speaker 7:  is doing regulation wise with big tech. They have the Digital Markets Act,

615
00:35:47,980 --> 00:35:51,660
Speaker 7:  which is going into effect next year and it labels

616
00:35:51,660 --> 00:35:55,500
Speaker 7:  Meta and other big companies like Apple and Google as gatekeepers. And

617
00:35:55,500 --> 00:35:59,140
Speaker 7:  with that distinction comes a whole new host of compliance

618
00:35:59,140 --> 00:36:02,640
Speaker 7:  requirements that if are not met, result

619
00:36:02,640 --> 00:36:06,420
Speaker 7:  in insane fines. Like not just like your one-off fines that these

620
00:36:06,420 --> 00:36:09,660
Speaker 7:  companies happily pay, but debilitating fines, which is

621
00:36:09,660 --> 00:36:13,530
Speaker 6:  The way fines should actually function. Sure,

622
00:36:13,530 --> 00:36:17,260
Speaker 6:  sure. They should discourage whatever the things you're not supposed to do

623
00:36:17,260 --> 00:36:17,800
Speaker 6:  from doing.

624
00:36:17,800 --> 00:36:21,250
Speaker 7:  Yes, no, I agree. Fines should be proportional to the company size of Yeah,

625
00:36:21,250 --> 00:36:25,060
Speaker 7:  they, they've been parking tickets so far. This is not, you know, Meta's

626
00:36:25,060 --> 00:36:28,900
Speaker 7:  not alone here. I've heard people at Apple Google are also freaking out

627
00:36:28,900 --> 00:36:32,700
Speaker 7:  about how to comply with the dma. There's a lot of unknowns. There's a bunch

628
00:36:32,700 --> 00:36:36,620
Speaker 7:  of interoperability standards, there's self referencing standards

629
00:36:36,620 --> 00:36:40,540
Speaker 7:  that have to be met. I think with Threads in particular, they're

630
00:36:40,540 --> 00:36:44,060
Speaker 7:  worried about being compliant with the data sharing and the data leakage

631
00:36:44,060 --> 00:36:47,940
Speaker 7:  between Threads and the rest of Meta since Threads is this quasi

632
00:36:47,940 --> 00:36:51,580
Speaker 7:  separate thing, but it still is connected to Instagram. It has its own terms

633
00:36:51,580 --> 00:36:55,210
Speaker 7:  of service, but it also has, you know, Meta

634
00:36:55,210 --> 00:36:58,700
Speaker 7:  influence Meta content guidelines. They're definitely gonna be sharing that

635
00:36:58,700 --> 00:37:02,500
Speaker 7:  data and basically whatever Meta tests to how

636
00:37:02,500 --> 00:37:06,390
Speaker 7:  they operate this, they're very much liable to that at a station

637
00:37:06,390 --> 00:37:09,960
Speaker 7:  being accurate under the new dmma. And if not, they're gonna

638
00:37:09,960 --> 00:37:10,470
Speaker 7:  get

639
00:37:10,470 --> 00:37:13,820
Speaker 5:  Fined. And not only that, they have to be able to prove it like, like

640
00:37:13,820 --> 00:37:16,460
Speaker 5:  aggressively and constantly. Yeah, and that was one of the things most serious

641
00:37:16,460 --> 00:37:19,420
Speaker 5:  said that I thought was really interesting is that like the tooling just

642
00:37:19,420 --> 00:37:22,420
Speaker 5:  to be able to document this stuff is a huge amount of work.

643
00:37:22,420 --> 00:37:25,800
Speaker 7:  Yeah, it's a huge amount of work. This is one of the companies with perhaps

644
00:37:25,800 --> 00:37:29,380
Speaker 7:  the strongest global, if not one of the strongest global lobbying

645
00:37:29,380 --> 00:37:32,980
Speaker 7:  policy presences in the world. They've had more headroom on this than

646
00:37:32,980 --> 00:37:36,720
Speaker 7:  anyone and they, I think it's very interesting that they don't feel confident

647
00:37:36,720 --> 00:37:40,180
Speaker 7:  to launch what they think could be the fastest growing software product since

648
00:37:40,180 --> 00:37:43,880
Speaker 7:  Chad G P T in Europe. Even though the DMA does not go into

649
00:37:43,880 --> 00:37:47,870
Speaker 7:  effect until maybe spring of next year because they're that worried

650
00:37:47,870 --> 00:37:51,500
Speaker 7:  about potentially being liable. I think this means that other big

651
00:37:51,500 --> 00:37:55,340
Speaker 7:  product launches like this will also not go into the

652
00:37:55,340 --> 00:37:59,260
Speaker 7:  EU region initially as well. I don't think this will be the only one they

653
00:37:59,260 --> 00:38:02,840
Speaker 7:  do really want to get into the EU. I just think it's gonna take several months

654
00:38:02,840 --> 00:38:06,540
Speaker 7:  at minimum before they can make sure that they can hold up to their, you

655
00:38:06,540 --> 00:38:08,460
Speaker 7:  know, attestations of how they're using the data. So

656
00:38:08,460 --> 00:38:12,260
Speaker 6:  Kinda like video games going to Australia where they always have to wait

657
00:38:12,260 --> 00:38:15,720
Speaker 6:  forever because there's all the Australian regulation and they're like, okay,

658
00:38:15,720 --> 00:38:16,760
Speaker 6:  now I get to kill everybody.

659
00:38:16,760 --> 00:38:20,380
Speaker 7:  Or China as in, you know, China's an even more stringent example. Well

660
00:38:20,380 --> 00:38:24,200
Speaker 5:  And again, in this particular case Instagram was in such a rush

661
00:38:24,200 --> 00:38:27,820
Speaker 5:  to get this out. Yeah. That it was, it, it so clearly sensed a

662
00:38:27,820 --> 00:38:31,180
Speaker 5:  moment to do this. Yeah. That it made what seems like sort of a

663
00:38:31,180 --> 00:38:35,000
Speaker 5:  calculated decision to say this is a problem we could not solve

664
00:38:35,000 --> 00:38:38,793
Speaker 5:  by July 5th. So our option was either don't launch on July 5th

665
00:38:38,840 --> 00:38:41,610
Speaker 5:  or don't launch in the EU. And I think they just picked that.

666
00:38:41,610 --> 00:38:45,560
Speaker 7:  Yeah, Moster was very clear to me and others that they felt they

667
00:38:45,560 --> 00:38:48,980
Speaker 7:  had a very narrow window to launch this thing to really capitalize on the

668
00:38:48,980 --> 00:38:52,900
Speaker 7:  Twitter turmoil and they didn't wanna miss that window and their instinct

669
00:38:52,900 --> 00:38:56,120
Speaker 7:  was probably right there as hard as it is to not have a massive

670
00:38:56,120 --> 00:39:00,080
Speaker 7:  market that can use the app. What do you guys think about that?

671
00:39:00,080 --> 00:39:03,300
Speaker 7:  Do you I mean? I think there's a lot of people, we've had people in our Slack

672
00:39:03,300 --> 00:39:07,010
Speaker 7:  that are a little more sympathetic to the EU

673
00:39:07,010 --> 00:39:10,670
Speaker 7:  here versus, you know, Meta. Obviously Meta doesn't have a great

674
00:39:10,670 --> 00:39:14,580
Speaker 7:  track record with privacy. People think that, you know, what the EU

675
00:39:14,580 --> 00:39:18,340
Speaker 7:  is doing is generally good. I don't really know, I haven't formed a full

676
00:39:18,340 --> 00:39:22,020
Speaker 7:  opinion on that. I think GDPR has been widely considered

677
00:39:22,020 --> 00:39:25,940
Speaker 7:  a disaster and did not actually make the internet more private. And if

678
00:39:25,940 --> 00:39:29,700
Speaker 7:  anything just kind of solidified incumbents who could pay for

679
00:39:29,700 --> 00:39:31,860
Speaker 7:  the internal tooling and all of that to, but you

680
00:39:31,860 --> 00:39:33,050
Speaker 6:  Get to click a little button.

681
00:39:33,050 --> 00:39:33,990
Speaker 7:  Yeah, sure.

682
00:39:33,990 --> 00:39:36,580
Speaker 6:  Every time you go to a new website you click that

683
00:39:36,580 --> 00:39:39,800
Speaker 7:  Button. Do you feel like your data is more protected because of that button?

684
00:39:39,800 --> 00:39:41,970
Speaker 6:  No, I feel like I'm annoyed I have to click the button.

685
00:39:41,970 --> 00:39:45,700
Speaker 7:  Yeah. This, you know, the last big sweeping regulation was was that pop-up

686
00:39:45,700 --> 00:39:49,080
Speaker 7:  that the EU gave us. And I haven't seen

687
00:39:49,080 --> 00:39:52,940
Speaker 7:  any independent analysis that what the DMA is

688
00:39:52,940 --> 00:39:56,700
Speaker 7:  proposing will result in anything substantially better. I hope it will.

689
00:39:56,700 --> 00:40:00,540
Speaker 7:  I I think these gatekeepers need to have more incentives to allow for

690
00:40:00,540 --> 00:40:03,950
Speaker 7:  competition. It's just very tough to craft this kind of

691
00:40:03,950 --> 00:40:05,930
Speaker 7:  regulation. Very tough.

692
00:40:05,930 --> 00:40:09,920
Speaker 6:  They're trying to cover a lot of different companies with one

693
00:40:09,920 --> 00:40:13,260
Speaker 6:  law. Yeah. And like every one of these companies is very different. They

694
00:40:13,260 --> 00:40:16,580
Speaker 6:  all have different goals. They all have different like size of customer bases,

695
00:40:16,580 --> 00:40:20,410
Speaker 6:  they, the different stuff that they do really, really poorly

696
00:40:20,410 --> 00:40:24,060
Speaker 6:  that, that destroys our privacy. Like there, there's not a lot of consist

697
00:40:24,060 --> 00:40:27,710
Speaker 6:  there's consistency there and I think it

698
00:40:27,710 --> 00:40:31,460
Speaker 6:  makes sense that Meta said, no, we're not gonna go in there and we're not

699
00:40:31,460 --> 00:40:34,180
Speaker 6:  gonna, we're not gonna challenge this right now. We are gonna acknowledge

700
00:40:34,180 --> 00:40:37,660
Speaker 6:  it. I think like that feels like it's working exactly how it's

701
00:40:37,660 --> 00:40:41,430
Speaker 6:  intended and hopefully European users

702
00:40:41,430 --> 00:40:45,420
Speaker 6:  don't get mad and be like, well we just should get rid of this law so I

703
00:40:45,420 --> 00:40:49,280
Speaker 6:  can have give Meta my data. And I'm sure Meta would love it

704
00:40:49,280 --> 00:40:52,900
Speaker 6:  if, if all the users rose up and were like, give us, give us threats. But

705
00:40:52,900 --> 00:40:56,620
Speaker 6:  I'm like, I think this is working exactly how it's intended and I wish other

706
00:40:56,620 --> 00:41:00,160
Speaker 6:  countries would be thinking more about legislating this stuff, not necessarily

707
00:41:00,160 --> 00:41:02,780
Speaker 6:  in the DMA way. Cause I don't know enough about it to like have a really

708
00:41:02,780 --> 00:41:06,540
Speaker 6:  strong opinion on it beyond, it sounds nice at like first

709
00:41:06,540 --> 00:41:10,260
Speaker 6:  glance and like, I would love more legislation that sounds nice

710
00:41:10,260 --> 00:41:14,120
Speaker 6:  and actually works and actually provides fines that me are meaningful

711
00:41:14,120 --> 00:41:17,580
Speaker 6:  and, and do things like, like I think that's working great. The fact that

712
00:41:17,580 --> 00:41:21,520
Speaker 6:  Meta looked at and was like, I don't wanna risk the fines. I wanna figure

713
00:41:21,520 --> 00:41:25,100
Speaker 6:  out and make sure that we're complying with this law. Like that's wonderful,

714
00:41:25,100 --> 00:41:28,490
Speaker 6:  that's working exactly how it's intended and that's great.

715
00:41:28,490 --> 00:41:32,100
Speaker 5:  Yeah. I I tend to agree. I think if I'm the European Commission and the folks

716
00:41:32,100 --> 00:41:35,980
Speaker 5:  who wrote the dma, they're, they're probably thrilled that this is how it

717
00:41:35,980 --> 00:41:39,860
Speaker 5:  went down because a big part of the goal is to make these

718
00:41:39,860 --> 00:41:43,020
Speaker 5:  companies sit down and think about the consequences of their

719
00:41:43,020 --> 00:41:46,980
Speaker 5:  actions. And I think that the challenge for a lot of these regulators is

720
00:41:46,980 --> 00:41:50,400
Speaker 5:  that they've always been somewhere between like one and 65 steps

721
00:41:50,400 --> 00:41:54,340
Speaker 5:  behind the tech industry. They're regulating and litigating old

722
00:41:54,340 --> 00:41:57,680
Speaker 5:  problems while all these other companies are out talking about like crypto

723
00:41:57,680 --> 00:42:01,660
Speaker 5:  and ai and then they skip right past privacy and try to regulate AI and

724
00:42:01,660 --> 00:42:05,620
Speaker 5:  they will have moved on to something else. And the DMA basically swung such

725
00:42:05,620 --> 00:42:08,840
Speaker 5:  a big hammer that it was like, okay, we're gonna stop everybody for a minute.

726
00:42:08,840 --> 00:42:12,700
Speaker 5:  And I think this seems like, from what I've heard from folks, the

727
00:42:12,700 --> 00:42:16,560
Speaker 5:  kind of policy that is gonna play out really slowly over time

728
00:42:16,560 --> 00:42:20,020
Speaker 5:  and is only gonna be sort of answered as it gets litigated and questions

729
00:42:20,020 --> 00:42:23,300
Speaker 5:  about like, who is a gatekeeper and what does that mean and how do we decide

730
00:42:23,300 --> 00:42:26,600
Speaker 5:  who has that power and who doesn't like that stuff is gonna take a while

731
00:42:26,600 --> 00:42:30,450
Speaker 5:  to really shake out. But I think just the fact that it

732
00:42:30,450 --> 00:42:34,400
Speaker 5:  made Meta take its time on this, I think they're gonna see as a big victory.

733
00:42:34,400 --> 00:42:37,620
Speaker 5:  And again, this is kind of an unusual situation in

734
00:42:37,620 --> 00:42:41,380
Speaker 5:  that they didn't have time to iron out some of the

735
00:42:41,380 --> 00:42:44,900
Speaker 5:  policy issues for a global launch. The question for me will

736
00:42:44,900 --> 00:42:48,720
Speaker 5:  be whether that becomes the thing like you're talking about,

737
00:42:48,720 --> 00:42:52,540
Speaker 5:  if, if the move becomes these companies take longer to launch their global

738
00:42:52,540 --> 00:42:56,120
Speaker 5:  products as a result of trying to get the regulation right

739
00:42:56,120 --> 00:42:59,380
Speaker 5:  versus everybody launches everything and then launches it a year later in

740
00:42:59,380 --> 00:43:02,260
Speaker 5:  the EU when they can figure out how to do the paperwork correctly. I have

741
00:43:02,260 --> 00:43:05,300
Speaker 5:  no idea which one of those is gonna play out, but one of those is going to

742
00:43:05,300 --> 00:43:09,260
Speaker 5:  be politically significantly less popular among European people than

743
00:43:09,260 --> 00:43:10,000
Speaker 5:  the other

744
00:43:10,000 --> 00:43:13,880
Speaker 7:  People really want their tech and their services and especially

745
00:43:13,880 --> 00:43:17,840
Speaker 7:  things like networks that have a global kind of u utility

746
00:43:17,840 --> 00:43:21,680
Speaker 7:  to them. And I'm very curious to see if the EU gets blow back

747
00:43:21,680 --> 00:43:22,500
Speaker 7:  in that regard.

748
00:43:22,500 --> 00:43:25,580
Speaker 5:  I just keep thinking about all the Instagram users. Like there, there's a

749
00:43:25,580 --> 00:43:29,260
Speaker 5:  thing on your Instagram badge now that shows what

750
00:43:29,260 --> 00:43:33,040
Speaker 5:  number user you were on Threads and I, I

751
00:43:33,040 --> 00:43:36,720
Speaker 5:  bet you there is a not insubstantial number of people in the EU who are pissed

752
00:43:36,720 --> 00:43:39,540
Speaker 5:  at how, not how high their number is going to be. Maybe they'll

753
00:43:39,540 --> 00:43:42,860
Speaker 6:  Give them like a special one. Like they have their, their official thread

754
00:43:42,860 --> 00:43:44,680
Speaker 6:  number and then their EU thread number.

755
00:43:44,680 --> 00:43:45,940
Speaker 5:  Oh that's, that's fun. I like that.

756
00:43:45,940 --> 00:43:48,620
Speaker 6:  That's so that way they can still have a little bragging rights, but not

757
00:43:48,620 --> 00:43:50,020
Speaker 6:  as much as Keith.

758
00:43:50,020 --> 00:43:53,580
Speaker 7:  I wanna get into Threads reader questions, but I also quickly, I quickly,

759
00:43:53,580 --> 00:43:56,900
Speaker 7:  I want to address, I've just seen a lot of commentary on this and have been

760
00:43:56,900 --> 00:43:59,780
Speaker 7:  asked this directly, why didn't ask most sir about this? People have been

761
00:43:59,780 --> 00:44:03,620
Speaker 7:  pointing to the app store privacy labels for Threads and all of the

762
00:44:03,620 --> 00:44:07,420
Speaker 7:  data they collect and we could talk, we should actually

763
00:44:07,420 --> 00:44:11,260
Speaker 7:  do like a what has been the impact of Apple's privacy labels in the

764
00:44:11,260 --> 00:44:15,220
Speaker 7:  app store segment at some point? There's a lot to unpack here. Newsflash,

765
00:44:15,220 --> 00:44:19,140
Speaker 7:  they have not really worked and they don't

766
00:44:19,140 --> 00:44:21,220
Speaker 7:  actually mean anything.

767
00:44:21,220 --> 00:44:24,100
Speaker 5:  I was just gonna say, I actually think there's nothing to unpack here. I

768
00:44:24,100 --> 00:44:26,580
Speaker 5:  think the answer is it's basically security theater.

769
00:44:26,580 --> 00:44:30,260
Speaker 7:  I think the simplest thing we can say now is that if you already use

770
00:44:30,260 --> 00:44:33,880
Speaker 7:  Instagram, if you, you are an Instagram user, you have absolutely no reason

771
00:44:33,880 --> 00:44:37,660
Speaker 7:  to be complaining or saying you're not signing up for Threads because of

772
00:44:37,660 --> 00:44:41,340
Speaker 7:  these privacy labels. You're already using Instagram, which is

773
00:44:41,340 --> 00:44:45,220
Speaker 7:  governed under the exact same data policy as Threads. So that's,

774
00:44:45,220 --> 00:44:49,020
Speaker 7:  that's my short answer. We should absolutely talk more about privacy labels

775
00:44:49,020 --> 00:44:52,380
Speaker 7:  and maybe talk to some developers who have gone through it later. But I just

776
00:44:52,380 --> 00:44:53,600
Speaker 7:  wanted to get that outta the way.

777
00:44:53,600 --> 00:44:57,500
Speaker 5:  No, I that that's exactly right. And I think the argument of is this company

778
00:44:57,500 --> 00:45:00,930
Speaker 5:  collecting way too much data on you? Is the the answer is yes. Right? Like

779
00:45:00,930 --> 00:45:04,740
Speaker 5:  Neil, I posted in Slack, he got a thing from Threads asking to connect to

780
00:45:04,740 --> 00:45:08,620
Speaker 5:  other devices on his local network, which is like insane, right?

781
00:45:08,620 --> 00:45:12,540
Speaker 5:  Like this app wants everything you will give it including like your health

782
00:45:12,540 --> 00:45:16,500
Speaker 5:  and fitness information, but if you've ever used a Meta app,

783
00:45:16,500 --> 00:45:20,280
Speaker 5:  you're already giving it that information. Yeah. Like this is not a new problem

784
00:45:20,280 --> 00:45:24,080
Speaker 7:  If you're mad at still about meta's data collection. Like save like

785
00:45:24,080 --> 00:45:28,020
Speaker 7:  10% of that anger for the data brokers who literally actually sell

786
00:45:28,020 --> 00:45:31,610
Speaker 7:  your data Yeah. To companies without your knowledge that are completely

787
00:45:31,610 --> 00:45:35,410
Speaker 7:  unregulated still in the US because they so effectively lobby the government

788
00:45:35,410 --> 00:45:36,140
Speaker 7:  like they're

789
00:45:36,140 --> 00:45:36,740
Speaker 6:  Terrifying.

790
00:45:36,740 --> 00:45:40,580
Speaker 7:  D direct a little bit of a anger towards that versus Meta. And we may

791
00:45:40,580 --> 00:45:42,970
Speaker 7:  actually actually, you know, solve a lot of these problems.

792
00:45:42,970 --> 00:45:46,330
Speaker 6:  Weren't those the brokers that, like the NSA and CIA

793
00:45:46,330 --> 00:45:49,340
Speaker 6:  were revealed a couple of weeks ago that they were buying data from? They're

794
00:45:49,340 --> 00:45:51,340
Speaker 6:  like, oh yeah, we buy it from them already. Don't worry

795
00:45:51,340 --> 00:45:54,460
Speaker 5:  About it. Like we're, we're veering dangerously close to me giving a long

796
00:45:54,460 --> 00:45:57,740
Speaker 5:  rant about how Cambridge Analytica was a fake made up scandal that actually

797
00:45:57,740 --> 00:45:59,020
Speaker 5:  had nothing to do with anything. So

798
00:45:59,020 --> 00:46:00,780
Speaker 7:  I'm here for it. Let's just, let's

799
00:46:00,780 --> 00:46:04,660
Speaker 5:  Save that for another day. Heath, you asked on Threads

800
00:46:04,660 --> 00:46:07,580
Speaker 5:  for people to ask you Threads questions for us to answer on The Vergecast.

801
00:46:07,580 --> 00:46:09,140
Speaker 5:  Let's do a bunch of 'em. Let's, what, what do

802
00:46:09,140 --> 00:46:11,460
Speaker 7:  You got? Yeah, so this is a great one. I'm really curious what you guys think

803
00:46:11,460 --> 00:46:15,170
Speaker 7:  about this. Do you think the discourse can be different

804
00:46:15,170 --> 00:46:19,060
Speaker 7:  here on Threads than on Twitter? Or will the format eventually produce the

805
00:46:19,060 --> 00:46:22,440
Speaker 7:  same results, aka hate

806
00:46:22,440 --> 00:46:25,980
Speaker 7:  speech, bullying, dunking, all that stuff?

807
00:46:25,980 --> 00:46:29,700
Speaker 6:  I think the format will definitely produce a lot of similar results, but

808
00:46:29,700 --> 00:46:33,510
Speaker 6:  the fact that we're getting the Instagram aggressive moderation

809
00:46:33,510 --> 00:46:35,180
Speaker 6:  might mitigate some of that.

810
00:46:35,180 --> 00:46:38,980
Speaker 5:  I think that's right. I mean, I think the, the thing that we've seen is that

811
00:46:38,980 --> 00:46:42,780
Speaker 5:  these platforms develop different norms really fast,

812
00:46:42,780 --> 00:46:46,400
Speaker 5:  right? Like Mastodon is different from Twitter, which is different from Blue

813
00:46:46,400 --> 00:46:50,380
Speaker 5:  Sky, which is different from, I don't know, telegram. Like these things

814
00:46:50,380 --> 00:46:54,220
Speaker 5:  where people send texts to one another do develop different

815
00:46:54,220 --> 00:46:58,100
Speaker 5:  cultures. I think Threads absolutely risks basically

816
00:46:58,100 --> 00:47:01,620
Speaker 5:  turning into Twitter and in a lot of ways and for a lot of people will, I

817
00:47:01,620 --> 00:47:05,500
Speaker 5:  also think a lot of people's Twitter experiences were

818
00:47:05,500 --> 00:47:09,260
Speaker 5:  sort of self-inflicted. I think who you decided to

819
00:47:09,260 --> 00:47:12,820
Speaker 5:  follow and engage with and what you decided to share. Like if you just went

820
00:47:12,820 --> 00:47:16,610
Speaker 5:  on and talked about nba, you had a very different version of Twitter

821
00:47:16,610 --> 00:47:20,220
Speaker 5:  than people who yelled about politics all day, right? And I think to some

822
00:47:20,220 --> 00:47:23,770
Speaker 5:  extent just having a sort of forced experience of starting

823
00:47:23,770 --> 00:47:27,580
Speaker 5:  over goes a really long way. And I think just that

824
00:47:27,580 --> 00:47:31,500
Speaker 5:  alone is going to change versions of the discourse. But like, are there going

825
00:47:31,500 --> 00:47:35,300
Speaker 5:  to be similarly horrible political fights and are there gonna be

826
00:47:35,300 --> 00:47:39,180
Speaker 5:  main characters on Threads who just get ruthlessly harassed until something

827
00:47:39,180 --> 00:47:41,240
Speaker 5:  horrible happens? Like yeah, it's, it's gonna happen.

828
00:47:41,240 --> 00:47:44,930
Speaker 6:  Are you guys changing how you use Threads versus Twitter? Like,

829
00:47:44,930 --> 00:47:48,600
Speaker 6:  like consciously? Because for me I definitely have like a different approach.

830
00:47:48,600 --> 00:47:52,110
Speaker 6:  I'm like, okay, I learned Twitter was where I could like kind of stumble

831
00:47:52,110 --> 00:47:52,760
Speaker 6:  along.

832
00:47:52,760 --> 00:47:54,720
Speaker 5:  Say more. What are you doing differently with Thread?

833
00:47:54,720 --> 00:47:57,020
Speaker 6:  I'm being more thoughtful about it. Okay. Like, like I'm being more thoughtful

834
00:47:57,020 --> 00:48:00,900
Speaker 6:  about what I post and like I have the urge to post all sorts of horrible

835
00:48:00,900 --> 00:48:04,880
Speaker 6:  shit posting and I usually do on Twitter and I'm like, maybe, maybe I don't

836
00:48:04,880 --> 00:48:08,800
Speaker 6:  on Threads. Maybe a bunch of people don't wanna hear these thoughts about

837
00:48:08,800 --> 00:48:12,160
Speaker 6:  toe hairs and I think they all should. But,

838
00:48:12,160 --> 00:48:14,130
Speaker 5:  But people on Twitter super did.

839
00:48:14,130 --> 00:48:15,290
Speaker 6:  They didn't. They didn't.

840
00:48:15,290 --> 00:48:17,530
Speaker 7:  That sounds like a Tumblr thing. France,

841
00:48:17,530 --> 00:48:21,220
Speaker 6:  That was really a Tumblr thing. I miss, I mistook the audience, but I, but

842
00:48:21,220 --> 00:48:25,100
Speaker 6:  I think that the audience feels clearer and at least in

843
00:48:25,100 --> 00:48:29,040
Speaker 6:  these early days, a thread of like what you can do and kind of

844
00:48:29,040 --> 00:48:32,590
Speaker 6:  how mean you can get, how weird you can get. And you always wanna like

845
00:48:32,590 --> 00:48:36,320
Speaker 6:  scale it back just a little bit. Don't get too mean, don't get too weird.

846
00:48:36,320 --> 00:48:39,200
Speaker 7:  And David, I think your point about, you know, the opportunity to start over

847
00:48:39,200 --> 00:48:42,620
Speaker 7:  is a big one, is totally spot on. And I think the early culture of these

848
00:48:42,620 --> 00:48:46,520
Speaker 7:  networks create matters as we've seen with Blue Sky already,

849
00:48:46,520 --> 00:48:50,380
Speaker 7:  for example, and Macedon in a different way. I do wanna just

850
00:48:50,380 --> 00:48:54,340
Speaker 7:  check our like white man privilege of like using these platforms.

851
00:48:54,340 --> 00:48:58,160
Speaker 7:  I do think because of the public nature of Twitter and Threads,

852
00:48:58,160 --> 00:49:01,980
Speaker 7:  if you are a minority or someone who is easily targetable,

853
00:49:01,980 --> 00:49:05,780
Speaker 7:  unfortunately on the internet you have a wildly different experience with

854
00:49:05,780 --> 00:49:09,700
Speaker 7:  these public platforms and you don't, it doesn't matter who you follow. Like

855
00:49:09,700 --> 00:49:12,480
Speaker 7:  it comes to you. Like I've seen enough examples,

856
00:49:12,480 --> 00:49:16,420
Speaker 6:  The mansplaining still appears in my d Yeah. In like

857
00:49:16,420 --> 00:49:17,660
Speaker 6:  my, my Threads and

858
00:49:17,660 --> 00:49:19,490
Speaker 5:  That's coming to Threads. It really is.

859
00:49:19,490 --> 00:49:22,420
Speaker 6:  It's already there. It's already there. It started last night like as almost

860
00:49:22,420 --> 00:49:25,180
Speaker 6:  immediately somebody was like, lemme tell you what you're saying. And I'm

861
00:49:25,180 --> 00:49:26,480
Speaker 6:  like, no, I, I said it.

862
00:49:26,480 --> 00:49:29,900
Speaker 7:  And, and crayons be honest, like the mansplaining is probably the best of

863
00:49:29,900 --> 00:49:33,380
Speaker 7:  the worst. you know? Like there's actually, there's far worse. Yeah.

864
00:49:33,380 --> 00:49:36,940
Speaker 6:  It was like this was, this was like fairly mild mansplaining. I've definitely

865
00:49:36,940 --> 00:49:40,180
Speaker 6:  had it way worse and I'm, I'm sure it's just gonna come. And I think that's

866
00:49:40,180 --> 00:49:44,000
Speaker 6:  just like, I think most people who, who go online and

867
00:49:44,000 --> 00:49:47,860
Speaker 6:  simply exist and people get mad at them, which is a

868
00:49:47,860 --> 00:49:51,780
Speaker 6:  lot of us unfortunately we're kind of accustomed to it by now. It sucks and

869
00:49:51,780 --> 00:49:54,260
Speaker 6:  it shouldn't happen and there should be tools and stuff, but I think that's

870
00:49:54,260 --> 00:49:58,200
Speaker 6:  a hard problem to figure out how you do those tools, how you balance them

871
00:49:58,200 --> 00:50:02,140
Speaker 6:  and don't turn into whatever happened to Facebook in 2016. You just

872
00:50:02,140 --> 00:50:05,890
Speaker 6:  kind of have to, to I mean, this is me saying it as an old

873
00:50:05,890 --> 00:50:09,840
Speaker 6:  haggard witch of a woman who's been on the internet a very long time.

874
00:50:09,840 --> 00:50:13,140
Speaker 6:  You kind of get used to it. You kinda learn to like what stuff to ignore

875
00:50:13,140 --> 00:50:14,520
Speaker 6:  and what stuff to report

876
00:50:14,520 --> 00:50:18,140
Speaker 7:  You shouldn't get used to it. Like these platforms should do better. Yeah,

877
00:50:18,140 --> 00:50:19,000
Speaker 6:  You shouldn't, but like,

878
00:50:19,000 --> 00:50:20,900
Speaker 7:  But yes, I know what you mean. That's

879
00:50:20,900 --> 00:50:24,700
Speaker 6:  A hard, like something like mansplaining, like how are you gonna report somebody

880
00:50:24,700 --> 00:50:28,580
Speaker 6:  for being like they think they know more than me, moderator fix it. Yeah,

881
00:50:28,580 --> 00:50:31,500
Speaker 6:  totally. That's not gonna work. It's just gonna be like, well yeah, I'm just

882
00:50:31,500 --> 00:50:34,780
Speaker 6:  not gonna engage with you. And at Twitter I probably would've engaged a few

883
00:50:34,780 --> 00:50:37,340
Speaker 6:  times, right? Like I probably would've been like, let me explain things to

884
00:50:37,340 --> 00:50:41,180
Speaker 6:  you. Let me be optimistic or eat shit asshole. And, and here I'm like,

885
00:50:41,180 --> 00:50:44,940
Speaker 6:  I've done this before I see you and I'm just not gonna feed the troll.

886
00:50:44,940 --> 00:50:48,740
Speaker 7:  I, I will say it was comforting to see that Threads had basic moderation.

887
00:50:48,740 --> 00:50:51,420
Speaker 7:  Things like blocking and muting built in on day one. Oh

888
00:50:51,420 --> 00:50:54,500
Speaker 6:  I, I've already blocked somebody. It was great. I was like ah beautiful.

889
00:50:54,500 --> 00:50:57,180
Speaker 6:  I won't, you can DM me and I'll tell you who I blocked but I'm not gonna

890
00:50:57,180 --> 00:51:00,820
Speaker 7:  Say it here. Yeah, so optimistic but cautious and we should definitely check

891
00:51:00,820 --> 00:51:04,500
Speaker 7:  back in on this. I thought it was a good question. Next one. Should we expect

892
00:51:04,500 --> 00:51:07,820
Speaker 7:  a high velocity of new feature additions and would that even be possible

893
00:51:07,820 --> 00:51:11,280
Speaker 7:  under the regulatory scrutiny that Facebook is correctly subject

894
00:51:11,280 --> 00:51:15,260
Speaker 7:  to? We kind of already touched on the regulatory scrutiny. I do think

895
00:51:15,260 --> 00:51:18,670
Speaker 7:  there's gonna be a high velocity of feature tweaks and changes to this product.

896
00:51:18,670 --> 00:51:22,260
Speaker 7:  Especially now that it has garnered so much attention

897
00:51:22,260 --> 00:51:25,900
Speaker 7:  that exceeded Meadow's wildest dreams. And what happens in these big

898
00:51:25,900 --> 00:51:29,620
Speaker 7:  companies is that these projects start as like small resource constrain

899
00:51:29,620 --> 00:51:33,610
Speaker 7:  things. Threads has like a few dozen people working on it and

900
00:51:33,610 --> 00:51:37,300
Speaker 7:  when they see that that it's working a bunch more people wanna work on it,

901
00:51:37,300 --> 00:51:40,700
Speaker 7:  a bunch of resources get thrown on it. Zuckerberg himself is very excited

902
00:51:40,700 --> 00:51:44,600
Speaker 7:  about it now. So I expect that the team building it will swell

903
00:51:44,600 --> 00:51:48,300
Speaker 7:  and they'll ship a lot faster. I already know for example, like the internal

904
00:51:48,300 --> 00:51:51,700
Speaker 7:  employee build lets you do things like tap on a profile and it expands to

905
00:51:51,700 --> 00:51:54,960
Speaker 7:  see it in full. Like they're already making a bunch of like small tweaks

906
00:51:54,960 --> 00:51:58,420
Speaker 7:  on the edges that will ship soon. And then yeah, Moser's already

907
00:51:58,420 --> 00:52:02,410
Speaker 7:  confirmed a following only list is in the works. He has

908
00:52:02,410 --> 00:52:06,020
Speaker 7:  told me and others that they don't plan to do DMs. I have a feeling they'll

909
00:52:06,020 --> 00:52:09,730
Speaker 7:  go back on that after they See how much of a loop, a powerful

910
00:52:09,730 --> 00:52:13,290
Speaker 7:  loop that is. At the very least they need to make it easier to share

911
00:52:13,290 --> 00:52:17,260
Speaker 7:  Threads to like Instagram DMs for example, or just

912
00:52:17,260 --> 00:52:21,040
Speaker 7:  other DM apps that's could be a lot smoother and they know that,

913
00:52:21,040 --> 00:52:22,490
Speaker 6:  Let me shit talk in piece.

914
00:52:22,490 --> 00:52:25,180
Speaker 7:  Yeah, any features you guys wanna see like quickly better

915
00:52:25,180 --> 00:52:28,820
Speaker 5:  Search is I think the biggest one and something that the company is

916
00:52:28,820 --> 00:52:31,580
Speaker 5:  relatively good at. So I suspect that's coming. But what I think is gonna

917
00:52:31,580 --> 00:52:35,340
Speaker 5:  be really interesting is to See how much they want

918
00:52:35,340 --> 00:52:39,200
Speaker 5:  to do here. Because I think one of the things that is true

919
00:52:39,200 --> 00:52:42,610
Speaker 5:  is that it is simple and that's part of what is good about it.

920
00:52:42,610 --> 00:52:46,400
Speaker 5:  Also he Moser said this to you Heath that Instagram

921
00:52:46,400 --> 00:52:49,980
Speaker 5:  the app is bloated and messy and too much and they're

922
00:52:49,980 --> 00:52:53,660
Speaker 5:  actually in the, and this is like this whole company goes through this constantly,

923
00:52:53,660 --> 00:52:56,300
Speaker 5:  right? They add a million things to the app and then they go, oh my god this

924
00:52:56,300 --> 00:52:58,980
Speaker 5:  app is a mess. And then they get rid of some stuff and simplify and then

925
00:52:58,980 --> 00:53:01,740
Speaker 5:  they add a bunch more stuff And this is just like, this is the Meta pendulum

926
00:53:01,740 --> 00:53:05,260
Speaker 5:  swing at all times. Yeah and they're in a sort of

927
00:53:05,260 --> 00:53:09,020
Speaker 5:  simplification phase right now. And I think also part of what has appealed

928
00:53:09,020 --> 00:53:12,990
Speaker 5:  to people about Threads already is that it's very straightforward and it

929
00:53:12,990 --> 00:53:16,380
Speaker 5:  works. And so I think the idea that they're gonna be like now you can make

930
00:53:16,380 --> 00:53:19,580
Speaker 5:  a podcast inside of Threads is like they'd be

931
00:53:19,580 --> 00:53:22,980
Speaker 5:  stupid to think that that is the answer, right? And so I

932
00:53:22,980 --> 00:53:26,690
Speaker 5:  think what we're gonna see is them try to figure out

933
00:53:26,690 --> 00:53:30,320
Speaker 5:  what is smart to take from Twitter and what

934
00:53:30,320 --> 00:53:34,210
Speaker 5:  is like actually not what makes the platform

935
00:53:34,210 --> 00:53:38,020
Speaker 5:  work. And I suspect we'll get a lot of stuff really fast. I think you're

936
00:53:38,020 --> 00:53:41,890
Speaker 5:  right because this team is actually just in a position to ship really fast,

937
00:53:41,890 --> 00:53:45,680
Speaker 5:  like building stuff just inside the org structure of something like Instagram

938
00:53:45,680 --> 00:53:49,420
Speaker 5:  and Facebook is hard and takes a long time and a lot of people and this is

939
00:53:49,420 --> 00:53:53,060
Speaker 5:  a team that just can make things and now has like a big win under attack

940
00:53:53,060 --> 00:53:55,060
Speaker 5:  and is gonna be able to make things faster. They

941
00:53:55,060 --> 00:53:55,727
Speaker 7:  Have Jane Wong.

942
00:53:55,780 --> 00:53:56,607
Speaker 5:  Yeah they got Jane Wong.

943
00:53:56,620 --> 00:54:00,540
Speaker 7:  Yeah, legendary app Scoop Jane Wong, which means she

944
00:54:00,540 --> 00:54:04,380
Speaker 7:  probably won't be posting her app dumps anymore, which is a

945
00:54:04,380 --> 00:54:05,080
Speaker 7:  huge bummer.

946
00:54:05,080 --> 00:54:08,340
Speaker 5:  Or they just hired her to be Threads exclusive, which would be a super

947
00:54:08,340 --> 00:54:09,430
Speaker 5:  cool,

948
00:54:09,430 --> 00:54:12,700
Speaker 7:  She's literally working on Threads. She's a Meta employee now. It's pretty

949
00:54:12,700 --> 00:54:16,020
Speaker 7:  wild. Okay, this is a good one too. How will journalists and other people

950
00:54:16,020 --> 00:54:19,850
Speaker 7:  who provide real time important info be able to be verified so users

951
00:54:19,850 --> 00:54:23,780
Speaker 7:  know the info being posted is legitimate. We've obviously seen how

952
00:54:23,780 --> 00:54:27,700
Speaker 7:  this has played out on Twitter since Elon changed the check marks.

953
00:54:27,700 --> 00:54:31,380
Speaker 7:  I am verified on Instagram because a media brand I worked at in

954
00:54:31,380 --> 00:54:35,340
Speaker 7:  2015 had a social media manager who knew someone at Facebook got everyone

955
00:54:35,340 --> 00:54:36,780
Speaker 7:  verified in the newsroom. That's

956
00:54:36,780 --> 00:54:38,100
Speaker 5:  How I got verified on Twitter.

957
00:54:38,100 --> 00:54:41,320
Speaker 7:  Anyone who's worked in a newsroom long enough knows that that's how it

958
00:54:41,320 --> 00:54:45,160
Speaker 7:  worked up until like a couple years ago. Meta

959
00:54:45,160 --> 00:54:48,820
Speaker 7:  has a paid verified program now, so I think they're phasing

960
00:54:48,820 --> 00:54:52,410
Speaker 7:  out the, you have to know somebody to get a check mark.

961
00:54:52,410 --> 00:54:55,620
Speaker 7:  They're gonna let people who got that check mark keep it. So thanks

962
00:54:55,620 --> 00:54:59,540
Speaker 7:  Meta. But yes, I think going forward metal will

963
00:54:59,540 --> 00:55:03,420
Speaker 7:  tell me if I'm wrong, but you need to pay to be verified on

964
00:55:03,420 --> 00:55:07,240
Speaker 7:  Instagram. They actually, I believe Id check you. So I think there's a level

965
00:55:07,240 --> 00:55:07,800
Speaker 7:  of

966
00:55:07,800 --> 00:55:11,600
Speaker 6:  Actual verification. Yeah. So I cannot make a neli

967
00:55:11,600 --> 00:55:13,040
Speaker 6:  burner account. Well

968
00:55:13,040 --> 00:55:15,180
Speaker 7:  You can try I mean I I

969
00:55:15,180 --> 00:55:16,300
Speaker 6:  I will try, but we

970
00:55:16,300 --> 00:55:16,880
Speaker 7:  Should try.

971
00:55:16,880 --> 00:55:18,930
Speaker 6:  I'm gonna wait until he is back on the show to do it.

972
00:55:18,930 --> 00:55:22,690
Speaker 7:  Yeah, but there is a level of actual scrutiny of someone's identity

973
00:55:22,690 --> 00:55:26,420
Speaker 7:  when you become verified on Instagram that far exceeds what Twitter is doing

974
00:55:26,420 --> 00:55:29,980
Speaker 7:  currently. So if you see a check mark on Threads, it's the real

975
00:55:29,980 --> 00:55:32,500
Speaker 7:  deal. Don't hold me to that though. I don't wanna be

976
00:55:32,500 --> 00:55:36,380
Speaker 7:  sued. But yeah. How do we feel about this? The, the check

977
00:55:36,380 --> 00:55:38,300
Speaker 7:  mark thing with Threads?

978
00:55:38,300 --> 00:55:42,180
Speaker 6:  I didn't know you could pay that seems Yeah, it it's basically

979
00:55:42,180 --> 00:55:46,100
Speaker 6:  like Twitter in that they're trying to get away from the, the check

980
00:55:46,100 --> 00:55:47,160
Speaker 6:  mark means

981
00:55:47,160 --> 00:55:48,380
Speaker 7:  You're special. Yeah,

982
00:55:48,380 --> 00:55:51,980
Speaker 6:  Special. Yeah. Which is honestly the only reason I ever liked the check mark.

983
00:55:51,980 --> 00:55:55,620
Speaker 6:  I love like very visual ways to validate myself. Thank

984
00:55:55,620 --> 00:55:56,520
Speaker 6:  you.

985
00:55:56,520 --> 00:56:00,090
Speaker 5:  But Meta is at least trying to make sure that not everyone

986
00:56:00,090 --> 00:56:01,200
Speaker 5:  demands a blue check,

987
00:56:01,200 --> 00:56:04,610
Speaker 6:  But yeah, Meta's actually checking, whereas like yeah

988
00:56:04,610 --> 00:56:08,580
Speaker 6:  Twitter's thing was like, oh you have a credit card you're in. And so that's

989
00:56:08,580 --> 00:56:12,300
Speaker 6:  good. Like I think that's actually how it should work. Not

990
00:56:12,300 --> 00:56:16,020
Speaker 6:  necessarily that you should have to pay, but that like they are

991
00:56:16,020 --> 00:56:19,500
Speaker 6:  actually checking and making sure that the person is the person. Like that's

992
00:56:19,500 --> 00:56:21,010
Speaker 6:  great. Go for it.

993
00:56:21,010 --> 00:56:24,650
Speaker 5:  Yeah, I think that's right and I think part of me wonders if the whole

994
00:56:24,650 --> 00:56:28,420
Speaker 5:  idea of the blue check is just being sort

995
00:56:28,420 --> 00:56:32,140
Speaker 5:  of beaten out of usefulness, Twitter kind of bastardized

996
00:56:32,140 --> 00:56:35,660
Speaker 5:  what it means. Tumblr would just like sell you one as a joke, which I thought

997
00:56:35,660 --> 00:56:37,500
Speaker 5:  was very funny and still love very much by

998
00:56:37,500 --> 00:56:39,640
Speaker 6:  20 if you want. Yeah.

999
00:56:39,640 --> 00:56:43,140
Speaker 5:  And so I, I kind of wonder if we're at a point where we're gonna need some

1000
00:56:43,140 --> 00:56:46,750
Speaker 5:  other connotation of this person is who they say they are. And to some extent

1001
00:56:46,750 --> 00:56:50,430
Speaker 5:  being connected to Instagram is useful in that way because

1002
00:56:50,430 --> 00:56:54,140
Speaker 5:  there are just more tools to verify people on

1003
00:56:54,140 --> 00:56:57,140
Speaker 5:  Instagram than there are on Threads or Twitter at this moment. And so I think

1004
00:56:57,140 --> 00:57:00,680
Speaker 5:  having those connections might be useful, but I don't know, I, I continue

1005
00:57:00,680 --> 00:57:04,620
Speaker 5:  to wonder if any kind of check is is gonna mean much to people for

1006
00:57:04,620 --> 00:57:05,480
Speaker 5:  very long.

1007
00:57:05,480 --> 00:57:09,340
Speaker 6:  At some point I feel like it's just gonna be a little like thing

1008
00:57:09,340 --> 00:57:11,700
Speaker 6:  you kind of look over and you're like, oh that person's really who they say

1009
00:57:11,700 --> 00:57:15,420
Speaker 6:  they are. Oh that's a parody account. Oh that's

1010
00:57:15,420 --> 00:57:19,260
Speaker 6:  just somebody who's too lazy or you know, a brand or

1011
00:57:19,260 --> 00:57:21,980
Speaker 6:  something like I hope so I think at some point we'll get that and that'd

1012
00:57:21,980 --> 00:57:25,250
Speaker 6:  be great but different way of working on the internet.

1013
00:57:25,250 --> 00:57:28,300
Speaker 5:  This is also, I would point out a potential upside of the fediverse is this

1014
00:57:28,300 --> 00:57:31,300
Speaker 5:  becomes a thing that not every platform has to do for itself. That we can

1015
00:57:31,300 --> 00:57:35,100
Speaker 5:  have bigger, broader cross system tools for

1016
00:57:35,100 --> 00:57:37,660
Speaker 5:  verifying people that actually make a lot more sense. Oh

1017
00:57:37,660 --> 00:57:41,380
Speaker 6:  My god, that's gonna be the first big fight between Meta and the fediverse.

1018
00:57:41,380 --> 00:57:44,920
Speaker 5:  I think one of my great conspiracy theories about Threads

1019
00:57:44,920 --> 00:57:48,860
Speaker 5:  and Activity Pub in general is that Meta actually has no interest in doing

1020
00:57:48,860 --> 00:57:52,380
Speaker 5:  things like that and only does it out of basically obligation because it

1021
00:57:52,380 --> 00:57:56,330
Speaker 5:  runs the platform. Meta doesn't care all that much about your content.

1022
00:57:56,330 --> 00:58:00,300
Speaker 5:  Your content is just annoying for Meta generally speaking, it wants your

1023
00:58:00,300 --> 00:58:02,380
Speaker 5:  activity, it wants you to be paying attention, it wants you to be on its

1024
00:58:02,380 --> 00:58:05,780
Speaker 5:  platform but it didn't really give a shit what your posts are. Oh it just

1025
00:58:05,780 --> 00:58:09,470
Speaker 5:  wants you to like hang out. So giving you a feeling that your posts are

1026
00:58:09,470 --> 00:58:13,260
Speaker 5:  yours and someone else can deal with all the hard work of doing

1027
00:58:13,260 --> 00:58:16,340
Speaker 5:  something like verifying that you are who you say you are but you can just

1028
00:58:16,340 --> 00:58:19,340
Speaker 5:  use Threads because it's a better app. They can just focus on making a good

1029
00:58:19,340 --> 00:58:23,100
Speaker 5:  app and all the stuff you do around it doesn't have to be their problem anymore.

1030
00:58:23,100 --> 00:58:26,300
Speaker 5:  I actually think that's an enormous win for Meta down the road.

1031
00:58:26,300 --> 00:58:29,150
Speaker 7:  I think you're right. Okay, one last question and then maybe we can call

1032
00:58:29,150 --> 00:58:32,800
Speaker 7:  Nilay, T B D. Will there be third party

1033
00:58:32,800 --> 00:58:36,260
Speaker 7:  API platform integration for other

1034
00:58:36,260 --> 00:58:39,910
Speaker 7:  developers on Threads? I highly highly

1035
00:58:39,910 --> 00:58:43,740
Speaker 7:  doubt it because Meta as a company, their last time they

1036
00:58:43,740 --> 00:58:47,680
Speaker 7:  tried to do a developer platform it resulted in Cambridge Analytica.

1037
00:58:47,680 --> 00:58:51,110
Speaker 7:  So they have decided as a company,

1038
00:58:51,110 --> 00:58:53,080
Speaker 5:  Jesus, when you say it like that,

1039
00:58:53,080 --> 00:58:53,580
Speaker 7:  No more

1040
00:58:53,580 --> 00:58:57,170
Speaker 6:  They could do it again. They didn't do a very good job that

1041
00:58:57,170 --> 00:59:01,060
Speaker 7:  Time. Well see Mark Zuckerberg still running the company, I think he remembers

1042
00:59:01,060 --> 00:59:04,880
Speaker 7:  those senate hearings and the lawsuits and the fines, the record fines.

1043
00:59:04,880 --> 00:59:05,460
Speaker 7:  But he took the

1044
00:59:05,460 --> 00:59:09,060
Speaker 6:  Wrong, he took the wrong thing from that instead of being like, oh really

1045
00:59:09,060 --> 00:59:12,540
Speaker 6:  I shouldn't collect as much data. He was like hmm, I guess that means no

1046
00:59:12,540 --> 00:59:13,640
Speaker 6:  third party apps. Like

1047
00:59:13,640 --> 00:59:17,180
Speaker 7:  Oh is this really David teases us? Are we really gonna have to explain Cambridge

1048
00:59:17,180 --> 00:59:18,280
Speaker 5:  Analytic? I'm not doing though.

1049
00:59:18,280 --> 00:59:21,620
Speaker 7:  No, Cambridge Analytica was not about your data, it was

1050
00:59:21,620 --> 00:59:25,500
Speaker 7:  because Facebook let third party developers use your data in ways

1051
00:59:25,500 --> 00:59:27,300
Speaker 7:  they shouldn't have. Okay, end of story. Go

1052
00:59:27,300 --> 00:59:30,320
Speaker 5:  Watch the documentary, the great hack. It gets almost everything wrong.

1053
00:59:30,320 --> 00:59:33,940
Speaker 7:  No, quickly just to summarize, no I do not think they will do a third party

1054
00:59:33,940 --> 00:59:37,780
Speaker 7:  platform because of that. It's probably a good idea. I don't, I would say

1055
00:59:37,780 --> 00:59:41,180
Speaker 7:  it's at the very, very end of their to-do list and probably something that

1056
00:59:41,180 --> 00:59:44,430
Speaker 7:  their senior leadership does actually just not wanna do at all. So

1057
00:59:44,430 --> 00:59:46,900
Speaker 7:  sorry but it's a good idea. But no, I think

1058
00:59:46,900 --> 00:59:50,820
Speaker 5:  That's right. My question would be Heath on on that respect I think because

1059
00:59:50,820 --> 00:59:53,220
Speaker 5:  I can't stop talking about Activity Pub, one of the things most area has

1060
00:59:53,220 --> 00:59:56,660
Speaker 5:  said a couple of times is that part of the upside of Activity Pub is you

1061
00:59:56,660 --> 01:00:00,610
Speaker 5:  can support the standard and kind of be part of the ecosystem, but you can

1062
01:00:00,610 --> 01:00:04,580
Speaker 5:  also build Threads only stuff just inside of

1063
01:00:04,580 --> 01:00:08,010
Speaker 5:  the app So. what I wonder is less like do they wanna support developers and

1064
01:00:08,010 --> 01:00:11,780
Speaker 5:  more, do you think they'll go the road of like, I would call it like the

1065
01:00:11,780 --> 01:00:15,180
Speaker 5:  iMessage thing where where it's like you can send SMSs through iMessage but

1066
01:00:15,180 --> 01:00:18,100
Speaker 5:  if your iMessage to iMessage you get this whole like universe of other stuff

1067
01:00:18,100 --> 01:00:20,500
Speaker 5:  you can do. Yes. Is that where Threads ends? Do

1068
01:00:20,500 --> 01:00:23,380
Speaker 7:  You think? That's totally where it's going and it's so ironic given that

1069
01:00:23,380 --> 01:00:27,340
Speaker 7:  Meta spends all its time shitting on iMessage whenever it gets a

1070
01:00:27,340 --> 01:00:31,040
Speaker 7:  chance in ads and in interviews. But yeah, Threads will be the blue bubble

1071
01:00:31,040 --> 01:00:33,900
Speaker 7:  of the fediverse and we're all gonna have to

1072
01:00:33,900 --> 01:00:37,120
Speaker 5:  Look that. That's that's good. That's very that's good. Yeah, I like that

1073
01:00:37,120 --> 01:00:37,460
Speaker 5:  you just

1074
01:00:37,460 --> 01:00:40,200
Speaker 6:  Made all the fediverse green bubbles so mad.

1075
01:00:40,200 --> 01:00:44,100
Speaker 7:  Get at me with your tweets guys furiously. Okay those are, those are

1076
01:00:44,100 --> 01:00:45,900
Speaker 7:  reader questions. What's next?

1077
01:00:45,900 --> 01:00:48,340
Speaker 5:  Let's, can we talk about the Twitter response just for a couple of minutes

1078
01:00:48,340 --> 01:00:52,060
Speaker 5:  before we throw to another break? Yeah, it, it got more aggressive over the

1079
01:00:52,060 --> 01:00:55,860
Speaker 5:  24 hours but basically the first response from Twitter,

1080
01:00:55,860 --> 01:00:59,400
Speaker 5:  well lemme just read you the tweets both from Elon Musk and from Linda

1081
01:00:59,400 --> 01:01:03,060
Speaker 5:  Yak the ceo. So Elon Musk said it is

1082
01:01:03,060 --> 01:01:06,140
Speaker 5:  infinitely preferable to be attacked by strangers on Twitter then indulge

1083
01:01:06,140 --> 01:01:09,620
Speaker 5:  in the false happiness of hide the pain Instagram. That's what Elon Musk

1084
01:01:09,620 --> 01:01:11,960
Speaker 5:  said and like what does that mean?

1085
01:01:11,960 --> 01:01:13,290
Speaker 7:  That's a sentence.

1086
01:01:13,290 --> 01:01:16,860
Speaker 5:  What Sure. And then the CEO Lin Aina said, we're often

1087
01:01:16,860 --> 01:01:20,220
Speaker 5:  imitated but the Twitter community can never be duplicated. That is a much

1088
01:01:20,220 --> 01:01:24,080
Speaker 5:  better line and a much better selling point I would argue and I think

1089
01:01:24,080 --> 01:01:28,040
Speaker 5:  is gonna be the thing, right? And like even Messer said this to you a couple

1090
01:01:28,040 --> 01:01:31,520
Speaker 5:  of times, Alex, he's like going way out of his way to give Twitter credit

1091
01:01:31,520 --> 01:01:34,820
Speaker 5:  for like pioneering the format. Which I think you could make a strong case.

1092
01:01:34,820 --> 01:01:37,780
Speaker 5:  It didn't really do that. Like there are things that look like Twitter before

1093
01:01:37,780 --> 01:01:41,730
Speaker 5:  Twitter but also that it is, it is a big community

1094
01:01:41,730 --> 01:01:45,060
Speaker 5:  full of engaged people and that's actually a hard thing to unseat and even

1095
01:01:45,060 --> 01:01:49,020
Speaker 5:  if Threads works, it probably won't kill Twitter. Both of those read a

1096
01:01:49,020 --> 01:01:52,740
Speaker 5:  lot. Like I'm not scared, I'm not scared, I'm not scared. Don't tell everybody

1097
01:01:52,740 --> 01:01:56,620
Speaker 5:  I was scared. Responses. Right. Is that, is that what you guys take from

1098
01:01:56,620 --> 01:01:57,140
Speaker 5:  this? Okay.

1099
01:01:57,140 --> 01:01:58,170
Speaker 7:  Pretty much.

1100
01:01:58,170 --> 01:02:02,060
Speaker 5:  Okay. Yes. Cool. And then just to prove it's not

1101
01:02:02,060 --> 01:02:05,980
Speaker 5:  scared, Twitter also threatened to sue Oh my

1102
01:02:05,980 --> 01:02:08,980
Speaker 5:  over Threads Heath you were looking at this just before we started recording.

1103
01:02:08,980 --> 01:02:10,240
Speaker 5:  Do you wanna explain what we know?

1104
01:02:10,240 --> 01:02:13,420
Speaker 7:  Oh my god, I was just reading it while you were saying that It is. So this

1105
01:02:13,420 --> 01:02:17,160
Speaker 7:  is Alex Spero must personal lawyer who has also been

1106
01:02:17,160 --> 01:02:21,060
Speaker 7:  taking point on them not paying rents et cetera. This

1107
01:02:21,060 --> 01:02:24,740
Speaker 7:  whole letter is hilarious but it's to Zuckerberg and it, the part that I

1108
01:02:24,740 --> 01:02:28,580
Speaker 7:  think is super relevant is that over the past year Meta has

1109
01:02:28,580 --> 01:02:32,060
Speaker 7:  hired dozens of former employees. Twitter knows that these employees previously

1110
01:02:32,060 --> 01:02:35,380
Speaker 7:  worked at Twitter that these employees had and continued to have access to

1111
01:02:35,380 --> 01:02:38,900
Speaker 7:  Twitter's trade secrets and other highly confidential information that these

1112
01:02:38,900 --> 01:02:42,340
Speaker 7:  employees owe ongoing obligations to Twitter and that many of these employees

1113
01:02:42,340 --> 01:02:45,770
Speaker 7:  have improperly retained Twitter documents and electronic

1114
01:02:45,770 --> 01:02:49,690
Speaker 7:  devices. That sounds like your problem. Alex Spero with that knowledge,

1115
01:02:49,690 --> 01:02:53,480
Speaker 7:  Meta deliberately assigned these employees to develop and a matter of months

1116
01:02:53,480 --> 01:02:56,940
Speaker 7:  met us copycat app with the specific intent that they use Twitter's trade

1117
01:02:56,940 --> 01:03:00,860
Speaker 7:  secrets, et cetera and violation of law, et cetera. So

1118
01:03:00,860 --> 01:03:04,080
Speaker 7:  this is I guess some vague threat of like a

1119
01:03:04,080 --> 01:03:07,350
Speaker 7:  IP software IP property rights lawsuit.

1120
01:03:07,350 --> 01:03:11,340
Speaker 7:  Which hate to break it to you Musk and Ox Spiro, but if there's

1121
01:03:11,340 --> 01:03:15,140
Speaker 7:  any company that has researched the actual legal

1122
01:03:15,140 --> 01:03:19,060
Speaker 7:  grounds for successfully winning a case on copying software, it is

1123
01:03:19,060 --> 01:03:22,660
Speaker 7:  Meta considering they have copied more software than any social media

1124
01:03:22,660 --> 01:03:25,170
Speaker 7:  company to date in a cumulative

1125
01:03:25,170 --> 01:03:28,500
Speaker 5:  Yeah, I think if Snap couldn't win a lawsuit, Twitter's probably not gonna

1126
01:03:28,500 --> 01:03:29,500
Speaker 5:  win a lawsuit. Yeah, he'd be

1127
01:03:29,500 --> 01:03:32,300
Speaker 7:  My guess this is the part of the show where if we had Neli, he would be going

1128
01:03:32,300 --> 01:03:35,230
Speaker 7:  on a rant about the state of copyright law in America.

1129
01:03:35,230 --> 01:03:36,460
Speaker 5:  Thank God he's not here,

1130
01:03:36,460 --> 01:03:37,660
Speaker 7:  Thank God he's not but but

1131
01:03:37,660 --> 01:03:41,570
Speaker 6:  It's not really a copyright thing. It's very much like a trade secrets

1132
01:03:41,570 --> 01:03:43,860
Speaker 6:  from employees thing. Which is

1133
01:03:43,860 --> 01:03:44,600
Speaker 7:  I guess,

1134
01:03:44,600 --> 01:03:47,600
Speaker 5:  And again the irony of that is like remember when Elon Musk took over Twitter

1135
01:03:47,600 --> 01:03:50,660
Speaker 5:  and promptly fired more than half the company? You're gonna

1136
01:03:50,660 --> 01:03:54,640
Speaker 6:  Have a hard time proving it. If you fired everybody, you didn't do

1137
01:03:54,640 --> 01:03:57,880
Speaker 6:  any due diligence to recover everything from them because you fired them

1138
01:03:57,880 --> 01:04:01,780
Speaker 6:  so quickly And like you have to prove what trade secrets that

1139
01:04:01,780 --> 01:04:05,740
Speaker 6:  they're using, which is pretty, in this particular case

1140
01:04:05,740 --> 01:04:08,900
Speaker 6:  probably gonna be pretty hard to do unless they're like in Slack saying L

1141
01:04:08,900 --> 01:04:12,380
Speaker 6:  M M O, I'm using this, I'm just gonna copy paste this stuff we used on

1142
01:04:12,380 --> 01:04:15,480
Speaker 6:  Twitter, which hopefully they didn't do but they might have.

1143
01:04:15,480 --> 01:04:19,460
Speaker 7:  Oh and here we go. Andy Stone, a Meta spokesperson has already, this is

1144
01:04:19,460 --> 01:04:23,140
Speaker 7:  so great. We're already seeing now. So when Meta people, they finally have

1145
01:04:23,140 --> 01:04:26,580
Speaker 7:  a place to respond to tweets that isn't Twitter, he

1146
01:04:26,580 --> 01:04:26,980
Speaker 5:  Threaded

1147
01:04:26,980 --> 01:04:30,740
Speaker 7:  It. I just got sent a thread for and Stone what a day

1148
01:04:30,740 --> 01:04:34,260
Speaker 7:  responding to this letter saying, to be clear no one on the Threads engineering

1149
01:04:34,260 --> 01:04:37,400
Speaker 7:  team is a former Twitter employee. That's just not a thing.

1150
01:04:37,400 --> 01:04:39,080
Speaker 6:  Oh that's great.

1151
01:04:39,080 --> 01:04:42,740
Speaker 7:  So I, yeah, I honestly like, I should have said this earlier, but a huge

1152
01:04:42,740 --> 01:04:46,240
Speaker 7:  part of Threads and why Met is so excited about this is that Mark Zuckerberg

1153
01:04:46,240 --> 01:04:49,890
Speaker 7:  and all their execs finally have a place to post

1154
01:04:49,890 --> 01:04:53,540
Speaker 7:  Twitter like content that isn't Twitter. I loved that. Like his

1155
01:04:53,540 --> 01:04:57,380
Speaker 7:  first tweet in 11 years was Zuckerberg posting the spider-man

1156
01:04:57,380 --> 01:04:58,900
Speaker 7:  pointing meme,

1157
01:04:58,900 --> 01:05:01,940
Speaker 5:  Unbelievable tweet, unbelievable like so good. The best possible thing he

1158
01:05:01,940 --> 01:05:04,140
Speaker 5:  could have tweeted who I was so impressed by that we're

1159
01:05:04,140 --> 01:05:06,780
Speaker 7:  Gonna enter this hole as a reporter. It's just like I'm gonna have to be

1160
01:05:06,780 --> 01:05:10,380
Speaker 7:  checking Twitter for the Twitter response to the story and then Threads for

1161
01:05:10,380 --> 01:05:12,870
Speaker 7:  the Meta response, whatever. This is the new world we live in.

1162
01:05:12,870 --> 01:05:15,260
Speaker 6:  Which one is getting more engagement?

1163
01:05:15,260 --> 01:05:18,140
Speaker 7:  That's a good question. I'll have to report back on that

1164
01:05:18,140 --> 01:05:22,000
Speaker 5:  X to that point, my one request, Adam ary, if you're listening

1165
01:05:22,000 --> 01:05:25,940
Speaker 5:  and I know that you are build a web app, I'm sure you're going to do

1166
01:05:25,940 --> 01:05:29,820
Speaker 5:  it first. Just I don't wanna have to spend all day at work looking

1167
01:05:29,820 --> 01:05:33,090
Speaker 5:  at my phone. I'm using my phone as my webcam right now. I can't be on Threads.

1168
01:05:33,090 --> 01:05:35,210
Speaker 5:  Come on. Help. Help it out. Help me out.

1169
01:05:35,210 --> 01:05:35,960
Speaker 9:  Well David,

1170
01:05:35,960 --> 01:05:39,860
Speaker 7:  To be fair, you can open Threads on web if there's a lot of

1171
01:05:39,860 --> 01:05:43,160
Speaker 7:  replies, it cuts off and tells you to get into the app, but you can at least

1172
01:05:43,160 --> 01:05:44,320
Speaker 7:  see them on the web.

1173
01:05:44,320 --> 01:05:47,840
Speaker 5:  I'm just gonna go guess Threads URLs and see if there are any sick posts

1174
01:05:47,840 --> 01:05:51,820
Speaker 5:  at whatever URL that's like, it's gonna be amazing. Alright, we need to take

1175
01:05:51,820 --> 01:05:55,740
Speaker 5:  one more break but before we do, NELI is pinging

1176
01:05:55,740 --> 01:05:59,500
Speaker 5:  me in Slack and apparently just landed and has some deep thoughts

1177
01:05:59,500 --> 01:06:02,780
Speaker 5:  about Threads he would like to share. So we're gonna call him up, I think

1178
01:06:02,780 --> 01:06:05,300
Speaker 5:  he's at baggage claim and hear what he has to

1179
01:06:05,300 --> 01:06:09,590
Speaker 5:  say.

1180
01:06:09,590 --> 01:06:12,280
Speaker 5:  Where in the world are you? Neli Patel,

1181
01:06:12,280 --> 01:06:16,150
Speaker 9:  I'm at the airport with Mags. Can you say hi Mags. Hi

1182
01:06:16,150 --> 01:06:19,580
Speaker 9:  we're waiting for our bags but I need to react to Instagram

1183
01:06:19,580 --> 01:06:23,500
Speaker 9:  Threads in a very deep meaningful way, like a

1184
01:06:23,500 --> 01:06:27,160
Speaker 9:  spiritual way, which is why I'm calling you from there to force my way onto

1185
01:06:27,160 --> 01:06:27,640
Speaker 9:  the show.

1186
01:06:27,640 --> 01:06:31,450
Speaker 5:  That's correct. So we, we've spent a long time on this podcast

1187
01:06:31,450 --> 01:06:35,260
Speaker 5:  talking about Threads already, but you, I want to know

1188
01:06:35,260 --> 01:06:38,940
Speaker 5:  because you are the guy who has been on this show specifically saying things

1189
01:06:38,940 --> 01:06:42,860
Speaker 5:  like, I don't want feed-based social media in my life. And then you just

1190
01:06:42,860 --> 01:06:46,170
Speaker 5:  showed up guns blazing on Threads, what's going on here?

1191
01:06:46,170 --> 01:06:50,130
Speaker 9:  Yeah, it's like six posts in a day already. I'm off the wagon. Yeah man

1192
01:06:50,130 --> 01:06:51,640
Speaker 9:  they're drinking straight from the hose

1193
01:06:51,640 --> 01:06:53,010
Speaker 5:  You're smoking again,

1194
01:06:53,010 --> 01:06:56,980
Speaker 9:  It's two things. One, you know I missed it. It's fun to post on a new social

1195
01:06:56,980 --> 01:07:00,600
Speaker 9:  network in that vibe. you know, I, I post on Blue Sky a little bit. I, I

1196
01:07:00,600 --> 01:07:04,400
Speaker 9:  tooted on Mastodon but here I think the activity

1197
01:07:04,400 --> 01:07:08,380
Speaker 9:  pub integration that Meta is promising is

1198
01:07:08,380 --> 01:07:12,010
Speaker 9:  actually really interesting in a way that I don't know if the at protocol

1199
01:07:12,010 --> 01:07:15,940
Speaker 9:  from Blue Sky will be successful or maybe it will be, but

1200
01:07:15,940 --> 01:07:19,700
Speaker 9:  I can just see a world in which having a presence on a large

1201
01:07:19,700 --> 01:07:23,480
Speaker 9:  decentralized social platform can connect directly

1202
01:07:23,480 --> 01:07:27,320
Speaker 9:  to our work and what we do. And I think that's really exciting and I'd rather

1203
01:07:27,320 --> 01:07:31,260
Speaker 9:  be invested in that sort of opportunity than just building on

1204
01:07:31,260 --> 01:07:33,930
Speaker 9:  someone else's close platform yet again.

1205
01:07:33,930 --> 01:07:37,300
Speaker 5:  What do you make of like the app itself? Heath and Cranz and I didn't talk

1206
01:07:37,300 --> 01:07:41,060
Speaker 5:  that much about like the actual mechanics of using the app. I kind of think

1207
01:07:41,060 --> 01:07:44,720
Speaker 5:  it's like it works but I kind of think it's like hideously ugly.

1208
01:07:44,720 --> 01:07:46,010
Speaker 5:  What's your sense?

1209
01:07:46,010 --> 01:07:49,220
Speaker 9:  It's a little bit ugly, right? Yeah it's a little bit ugly. Why

1210
01:07:49,220 --> 01:07:51,560
Speaker 5:  Are the share buttons so big? I don't understand

1211
01:07:51,560 --> 01:07:55,100
Speaker 9:  The button for reply and the button for whatever the paper airplane. I'm

1212
01:07:55,100 --> 01:07:57,780
Speaker 9:  just confused. I don't know what's going on at the bottom of every post.

1213
01:07:57,780 --> 01:08:01,340
Speaker 9:  I think they know some of it isn't there and needs to be improved. It's

1214
01:08:01,340 --> 01:08:05,100
Speaker 9:  just, it's hard to know how much this version you have to

1215
01:08:05,100 --> 01:08:09,040
Speaker 9:  take seriously right at this second. It, it's a very minimum

1216
01:08:09,040 --> 01:08:11,570
Speaker 9:  viable product and it, it shows yes

1217
01:08:11,570 --> 01:08:11,860
Speaker 5:  They,

1218
01:08:11,860 --> 01:08:15,660
Speaker 9:  They clearly rushed this out because of Twitter's rate limits. But I will

1219
01:08:15,660 --> 01:08:19,060
Speaker 9:  say this, I posted that the embeds were a little bit broken cuz we wanted

1220
01:08:19,060 --> 01:08:22,420
Speaker 9:  to put thread embeds in our stories and quick posts and the feed and all

1221
01:08:22,420 --> 01:08:26,100
Speaker 9:  this stuff and like three different Meta engineers, including the

1222
01:08:26,100 --> 01:08:30,060
Speaker 9:  person who wrote the embed product replied to me and then they fixed

1223
01:08:30,060 --> 01:08:33,170
Speaker 9:  it. And that's just like the most fun you can have.

1224
01:08:33,170 --> 01:08:37,060
Speaker 9:  It's everyone's building things together and talking about the products in

1225
01:08:37,060 --> 01:08:40,940
Speaker 9:  earnest and that's the fun part of making the

1226
01:08:40,940 --> 01:08:44,780
Speaker 9:  internet right. I keep saying the internet feels like 2011 again and that's

1227
01:08:44,780 --> 01:08:47,320
Speaker 9:  the part I really like and the part that I want back. Totally

1228
01:08:47,320 --> 01:08:50,580
Speaker 5:  And it feels I mean in a funny way. It feels like if you go back to that

1229
01:08:50,580 --> 01:08:54,340
Speaker 5:  era that's like the early Instagram era where all of this stuff was being

1230
01:08:54,340 --> 01:08:58,260
Speaker 5:  built the first time before it was a giant monolith that was

1231
01:08:58,260 --> 01:09:02,060
Speaker 5:  hard to ship new stuff into and before everything that changed got rolled

1232
01:09:02,060 --> 01:09:05,700
Speaker 5:  out in tiny little doses. This they're just back to like building it live

1233
01:09:05,700 --> 01:09:09,580
Speaker 5:  right in front of us, which I agree is, is fun and different and feels

1234
01:09:09,580 --> 01:09:13,260
Speaker 5:  really different from Meta. I wasn't sure Meta like had the muscle to be

1235
01:09:13,260 --> 01:09:14,730
Speaker 5:  this kind of company anymore.

1236
01:09:14,730 --> 01:09:17,940
Speaker 9:  Yeah, I think that same thing. I think they're excited. The energy is like

1237
01:09:17,940 --> 01:09:21,810
Speaker 9:  palpable. They have skyrocketing user growth. Again, I also just keep

1238
01:09:21,810 --> 01:09:25,440
Speaker 9:  listening how bad it must be in the like reality labs

1239
01:09:25,440 --> 01:09:29,270
Speaker 9:  and Horizon worlds division where they're just trying to

1240
01:09:29,270 --> 01:09:32,660
Speaker 9:  brute force the next version of like the metaverse internet into

1241
01:09:32,660 --> 01:09:36,240
Speaker 9:  existence and they're just like alone in their headsets. While Zuck

1242
01:09:36,240 --> 01:09:39,350
Speaker 9:  is a conquering hero, like posting Spider-Man

1243
01:09:39,350 --> 01:09:43,320
Speaker 9:  memes, maybe the answer was much simpler than they thought.

1244
01:09:43,320 --> 01:09:47,300
Speaker 5:  Yes, I do think it, it's gonna be interesting to See how the vibes

1245
01:09:47,300 --> 01:09:50,650
Speaker 5:  shift in like week two of this, right? Because right now it's very exciting,

1246
01:09:50,650 --> 01:09:54,540
Speaker 5:  it's kind of amazing that it works as well as it does. But I think the question

1247
01:09:54,540 --> 01:09:58,340
Speaker 5:  of like where are we gonna be seven days from now when opening this thing

1248
01:09:58,340 --> 01:10:01,220
Speaker 5:  is less exciting is gonna be really interesting. And we've seen this a few

1249
01:10:01,220 --> 01:10:04,780
Speaker 5:  times where it feels really cool and everybody like, is this, is this thing

1250
01:10:04,780 --> 01:10:08,500
Speaker 5:  gonna be be real or is this gonna be something more meaningful?

1251
01:10:08,500 --> 01:10:12,340
Speaker 9:  I think it just comes down to does it send anybody any traffic? Like

1252
01:10:12,340 --> 01:10:16,210
Speaker 9:  they did the growth hackiest growth hacky thing, which is they're just always

1253
01:10:16,210 --> 01:10:20,040
Speaker 9:  buzzing at you if you have notifications on, so the platform just feels alive

1254
01:10:20,040 --> 01:10:23,060
Speaker 9:  cuz it's constantly sending you notifications. I actually turned them off

1255
01:10:23,060 --> 01:10:26,780
Speaker 9:  like too much. This is everything I did not want about feed based

1256
01:10:26,780 --> 01:10:30,130
Speaker 9:  social media. But then even when you have them off, when you have the app

1257
01:10:30,130 --> 01:10:33,180
Speaker 9:  open, it still buzzes at you whenever you get a reply or a

1258
01:10:33,180 --> 01:10:36,810
Speaker 9:  notification and that's like pretty good. Like they built a

1259
01:10:36,810 --> 01:10:40,700
Speaker 9:  good feedback loop in there and I think that's gonna carry 'em, especially

1260
01:10:40,700 --> 01:10:44,170
Speaker 9:  if the pace of signups continues to just accelerate like we've seen.

1261
01:10:44,170 --> 01:10:47,860
Speaker 5:  Totally. All right, well before you go, I know you have more bags to pick

1262
01:10:47,860 --> 01:10:51,360
Speaker 5:  up and traveling to do the, the one of the last things we talked about before

1263
01:10:51,360 --> 01:10:54,900
Speaker 5:  we got on with you was, I dunno if you saw this while you're on the plane,

1264
01:10:54,900 --> 01:10:58,250
Speaker 5:  but Twitter is threatening to sue Instagram for

1265
01:10:58,250 --> 01:11:01,980
Speaker 5:  essentially ripping off the app. They're saying they, you know, hired a bunch

1266
01:11:01,980 --> 01:11:05,610
Speaker 5:  of people with devices and trade secrets and they came and built a

1267
01:11:05,610 --> 01:11:09,450
Speaker 5:  copycat app. I would just like to hear lawyer Eli's

1268
01:11:09,450 --> 01:11:13,220
Speaker 5:  initial impression of whether this is anything and the extent to which this

1269
01:11:13,220 --> 01:11:13,940
Speaker 5:  is nothing.

1270
01:11:13,940 --> 01:11:17,780
Speaker 9:  Yeah, it's the saddest shit I've ever read, man. Like what are they even

1271
01:11:17,780 --> 01:11:21,570
Speaker 9:  complaining about? Twitter's trade secrets? What are Twitter's trade secrets?

1272
01:11:21,570 --> 01:11:25,450
Speaker 9:  Twitter's IP stack is basically nothing. And then on top of that,

1273
01:11:25,450 --> 01:11:28,900
Speaker 9:  Twitter promised ages ago to never use its patents

1274
01:11:28,900 --> 01:11:32,660
Speaker 9:  offensively actually wrote a big story in 2013 about this thing called the

1275
01:11:32,660 --> 01:11:35,700
Speaker 9:  Innovator's patent agreement, the ipa, it was a big Twitter initiative where

1276
01:11:35,700 --> 01:11:38,900
Speaker 9:  they agreed to never use their patents against anyone except defensively.

1277
01:11:38,900 --> 01:11:42,260
Speaker 9:  And they try to get everyone else to agree to it as well. so like they got

1278
01:11:42,260 --> 01:11:45,960
Speaker 9:  nothing except quote unquote trade secrets and like good luck. If

1279
01:11:45,960 --> 01:11:49,580
Speaker 9:  I'm Quinn Emmanuel, like Elon's law firm, I would be totally embarrassed

1280
01:11:49,580 --> 01:11:53,540
Speaker 9:  by this desperate letter. They should have definitely told him not to do

1281
01:11:53,540 --> 01:11:54,030
Speaker 9:  this.

1282
01:11:54,030 --> 01:11:57,880
Speaker 5:  There you go. All right, go get your bags. Thank you for coming on. I suspect

1283
01:11:57,880 --> 01:12:01,640
Speaker 5:  we will have more chances to talk about threats very, very, very, very soon.

1284
01:12:01,640 --> 01:12:02,980
Speaker 9:  All right Max, you say goodbye. Bye

1285
01:12:02,980 --> 01:12:03,610
Speaker 5:  Mag.

1286
01:12:03,610 --> 01:12:04,910
Speaker 10:  Goodbye. Alright,

1287
01:12:04,910 --> 01:12:06,560
Speaker 9:  We're outta here.

1288
01:12:06,560 --> 01:12:09,740
Speaker 5:  All right. And with that we need to actually take a break and then we're

1289
01:12:09,740 --> 01:12:11,500
Speaker 5:  gonna come back and do a lightning round. We'll be right

1290
01:12:11,500 --> 01:12:17,410
Speaker 5:  back.

1291
01:12:17,410 --> 01:12:21,150
Speaker 4:  Fox Creative. This is advertiser content brought to you by

1292
01:12:21,150 --> 01:12:22,770
Speaker 4:  WhatsApp.

1293
01:12:22,770 --> 01:12:26,390
Speaker 10:  I'm Alyssa here in Hollywood trying to get complete strangers to read me

1294
01:12:26,390 --> 01:12:27,610
Speaker 10:  their private messages

1295
01:12:27,610 --> 01:12:30,650
Speaker 11:  Now y'all don't wanna see my text messages? I can.

1296
01:12:30,650 --> 01:12:32,810
Speaker 10:  Can I please read your private text messages?

1297
01:12:32,810 --> 01:12:33,330
Speaker 12:  No

1298
01:12:33,330 --> 01:12:34,940
Speaker 10:  You can't. No, no.

1299
01:12:34,940 --> 01:12:38,610
Speaker 4:  Clearly most of us wouldn't want a stranger to read our personal messages,

1300
01:12:38,610 --> 01:12:40,980
Speaker 4:  but how secure are they Once we hit send

1301
01:12:40,980 --> 01:12:42,790
Speaker 10:  Come on. What? You don't trust me?

1302
01:12:42,790 --> 01:12:43,940
Speaker 11:  No, I don't trust no one.

1303
01:12:43,940 --> 01:12:44,290
Speaker 5:  Well

1304
01:12:44,290 --> 01:12:47,090
Speaker 10:  How do you know your messages are are being sent privately?

1305
01:12:47,090 --> 01:12:47,550
Speaker 11:  Oh, you're

1306
01:12:47,550 --> 01:12:51,230
Speaker 10:  Right. If you're not using an end-to-end encryption app

1307
01:12:51,230 --> 01:12:54,290
Speaker 10:  like WhatsApp, then anyone can be reading your messages.

1308
01:12:54,290 --> 01:12:57,330
Speaker 12:  Got hacked. So I learned that lesson. Okay. Yeah.

1309
01:12:57,330 --> 01:12:59,450
Speaker 10:  And how did it feel getting a message hacked?

1310
01:12:59,450 --> 01:13:03,390
Speaker 12:  It was just like such an invasion of privacy. Yeah, honestly. So you

1311
01:13:03,390 --> 01:13:06,490
Speaker 12:  need to have two factor authentication. Yes. You need to have those things

1312
01:13:06,490 --> 01:13:10,070
Speaker 12:  in place. Like you're saying, the end-to-end encryption.

1313
01:13:10,070 --> 01:13:13,150
Speaker 4:  WhatsApp automatically encrypts your personal messages the moment you send

1314
01:13:13,150 --> 01:13:16,770
Speaker 4:  them. So they can only be read by the people you send them to. That means

1315
01:13:16,770 --> 01:13:20,100
Speaker 4:  no one outside the chat can read your messages. Not even WhatsApp.

1316
01:13:20,100 --> 01:13:23,090
Speaker 10:  Well you let me read your private text messages. No,

1317
01:13:23,090 --> 01:13:25,070
Speaker 11:  Why not? They're private. Okay.

1318
01:13:25,070 --> 01:13:26,890
Speaker 10:  And what if the whole internet could read them?

1319
01:13:26,890 --> 01:13:30,190
Speaker 11:  Oh my god, I don't know. It'd be over. It'd be game

1320
01:13:30,190 --> 01:13:31,430
Speaker 11:  over.

1321
01:13:31,430 --> 01:13:34,900
Speaker 10:  Wouldn't it feel better to be messaging through an encrypted app? WhatsApp?

1322
01:13:34,900 --> 01:13:37,490
Speaker 10:  It's private locked up. You can say whatever you want.

1323
01:13:37,490 --> 01:13:38,390
Speaker 11:  Oh, is that right? How

1324
01:13:38,390 --> 01:13:38,790
Speaker 10:  Does that sound?

1325
01:13:38,790 --> 01:13:40,040
Speaker 11:  That sounds great.

1326
01:13:40,040 --> 01:13:43,830
Speaker 4:  Enter a new era of privacy with automatic end-to-end encryption on all

1327
01:13:43,830 --> 01:13:47,780
Speaker 4:  your personal messages. WhatsApp always message privately

1328
01:13:47,780 --> 01:13:51,310
Speaker 10:  Just because it's Hollywood Boulevard and I'm running at you in heels. What?

1329
01:13:51,310 --> 01:13:53,640
Speaker 10:  You don't trust me.

1330
01:14:26,240 --> 01:14:30,020
Speaker 5:  All right, we're back. Let's stop with Threads for a minute and let's

1331
01:14:30,020 --> 01:14:33,600
Speaker 5:  do, let's do a little bit of a lightning round cuz it is July. so like news

1332
01:14:33,600 --> 01:14:37,300
Speaker 5:  is slow and news is going to be slow for a little while

1333
01:14:37,300 --> 01:14:40,300
Speaker 5:  because everybody's on vacation for the next several weeks. Have you guys

1334
01:14:40,300 --> 01:14:43,780
Speaker 5:  already started getting like the, the increase in out of office responses

1335
01:14:43,780 --> 01:14:46,840
Speaker 5:  from people? Mine has definitely spiked the last few days.

1336
01:14:46,840 --> 01:14:50,370
Speaker 6:  No, I I aggressively work hard to not email people

1337
01:14:50,370 --> 01:14:54,140
Speaker 6:  ever. It's not going well, but it's going well enough that I

1338
01:14:54,140 --> 01:14:55,100
Speaker 6:  haven't gotten any yet.

1339
01:14:55,100 --> 01:14:58,700
Speaker 5:  I respect that. Just carrier pigeons or nothing. Let's do a little bit of

1340
01:14:58,700 --> 01:15:01,580
Speaker 5:  lightning round. The only rule for this lightning round is you can pick anything

1341
01:15:01,580 --> 01:15:05,570
Speaker 5:  you want to talk about this week except Threads. Threads is off limits. Okay.

1342
01:15:05,570 --> 01:15:07,650
Speaker 5:  Crayons. You get to go first. What do you got?

1343
01:15:07,650 --> 01:15:11,580
Speaker 6:  Okay, so we're gonna talk about Daddy's lov, one of my favorite people

1344
01:15:11,580 --> 01:15:12,940
Speaker 6:  on the planet who

1345
01:15:12,940 --> 01:15:14,480
Speaker 5:  Has had quite a week that been,

1346
01:15:14,480 --> 01:15:18,420
Speaker 6:  He has had quite boy quite a week. We, we can go. Do we,

1347
01:15:18,420 --> 01:15:19,620
Speaker 6:  should we go into all of it? Should I

1348
01:15:19,620 --> 01:15:22,460
Speaker 5:  There's a few. Just give us the quick rundown cuz there's a bunch of stuff

1349
01:15:22,460 --> 01:15:23,890
Speaker 5:  happening simultaneously here.

1350
01:15:23,890 --> 01:15:27,720
Speaker 6:  Okay, here's the, here's the quick rundown. About two weeks ago,

1351
01:15:27,720 --> 01:15:31,620
Speaker 6:  Turner Classic movies lost a lot of employees. People

1352
01:15:31,620 --> 01:15:35,340
Speaker 6:  were very upset, particularly a lot of like big fans of old Hollywood

1353
01:15:35,340 --> 01:15:39,160
Speaker 6:  movies like Steven Spielberg and Scorsese and Wes Anderson

1354
01:15:39,160 --> 01:15:42,850
Speaker 6:  and they all complained and Zla was eventually like,

1355
01:15:42,850 --> 01:15:46,420
Speaker 6:  okay, but you guys can come and help us and be a part of

1356
01:15:46,420 --> 01:15:50,180
Speaker 6:  this and we won't fire everyone at Turner Classic movies and you guys can

1357
01:15:50,180 --> 01:15:53,740
Speaker 6:  like help us choose movies. And so that happened and everybody seemed to

1358
01:15:53,740 --> 01:15:57,450
Speaker 6:  settle. There was much joy in the kingdom. As much

1359
01:15:57,450 --> 01:15:59,970
Speaker 6:  joys can happen in the kingdom of Zaslav.

1360
01:15:59,970 --> 01:16:03,510
Speaker 5:  Yeah. Picking a fight with Turner Classic movies by the way. Weird move.

1361
01:16:03,510 --> 01:16:07,170
Speaker 6:  Weird mo. Well and also he allegedly loves Classic films.

1362
01:16:07,170 --> 01:16:10,930
Speaker 6:  Like he's a big fan of them. He's a huge fan of Turner Classic movie.

1363
01:16:10,930 --> 01:16:13,490
Speaker 5:  Yeah, but you know what he likes more Alex is tax breaks.

1364
01:16:13,490 --> 01:16:17,340
Speaker 6:  Yeah, exactly. He was like, I love them but I love tax breaks more. And

1365
01:16:17,340 --> 01:16:20,590
Speaker 6:  they came and were like, yeah, but do you ever wanna work with any of us

1366
01:16:20,590 --> 01:16:23,660
Speaker 6:  again? And he's like, I do so

1367
01:16:23,660 --> 01:16:27,450
Speaker 6:  nevermind. Tax breaks bey. So then

1368
01:16:27,450 --> 01:16:31,330
Speaker 6:  over the weekend GQ published a story

1369
01:16:31,330 --> 01:16:35,230
Speaker 6:  that, that talked a lot about this, but also talked about the fact that

1370
01:16:35,230 --> 01:16:38,350
Speaker 6:  Salov is it exactly known for like his film

1371
01:16:38,350 --> 01:16:41,930
Speaker 6:  taste? He, he, he's, you know, he's a guy who, who did

1372
01:16:41,930 --> 01:16:45,820
Speaker 6:  like the 27 kids and counting or whatever it's called. He did a

1373
01:16:45,820 --> 01:16:49,380
Speaker 6:  lot of reality show, a lot of reality TV that a lot of people consider trashy.

1374
01:16:49,380 --> 01:16:53,300
Speaker 6:  They don't like it. And, and this, this GQ article really took him

1375
01:16:53,300 --> 01:16:56,540
Speaker 6:  to task for, for that and the fact that he was that guy and now he's out

1376
01:16:56,540 --> 01:17:00,500
Speaker 6:  here running one of the largest movie studios in the world. And then the

1377
01:17:00,500 --> 01:17:02,170
Speaker 6:  story disappeared.

1378
01:17:02,170 --> 01:17:04,540
Speaker 5:  Well first it got aggressively edited, it

1379
01:17:04,540 --> 01:17:08,380
Speaker 6:  Came back aggressively edited, but with no byline on it and then

1380
01:17:08,380 --> 01:17:12,100
Speaker 6:  it totally disappeared. And it turns out that

1381
01:17:12,100 --> 01:17:16,050
Speaker 6:  someone on Zaslav camp reached out to GQ and were like,

1382
01:17:16,050 --> 01:17:19,400
Speaker 6:  this is really mean. And to be fair, it was a very mean article,

1383
01:17:19,400 --> 01:17:22,780
Speaker 5:  But it, as far as we know, didn't say anything that lots of people were not

1384
01:17:22,780 --> 01:17:24,290
Speaker 5:  already saying publicly. He was,

1385
01:17:24,290 --> 01:17:28,220
Speaker 6:  Yeah, there was nothing inaccurate in it. It was a lot of opinion and that

1386
01:17:28,220 --> 01:17:29,640
Speaker 6:  opinion was you suck.

1387
01:17:29,640 --> 01:17:33,440
Speaker 7:  It was not that bad. Like this is what you're gonna have your PR person

1388
01:17:33,440 --> 01:17:34,820
Speaker 7:  try to spike. Like really?

1389
01:17:34,820 --> 01:17:38,020
Speaker 6:  Yeah. So it sounds like what happened was that they, they reached out with

1390
01:17:38,020 --> 01:17:41,620
Speaker 6:  a whole list of things and PR does this a lot where they really dislike a

1391
01:17:41,620 --> 01:17:44,740
Speaker 6:  story but there's nothing actually inaccurate. So they just have a bunch

1392
01:17:44,740 --> 01:17:47,980
Speaker 6:  of things to like be like, well, but you could have also said that he loves

1393
01:17:47,980 --> 01:17:51,820
Speaker 6:  babies. Why didn't you talk about how he loves babies and

1394
01:17:51,820 --> 01:17:54,910
Speaker 6:  people at gq, they pulled the story. There was a lot of upset

1395
01:17:54,910 --> 01:17:58,880
Speaker 6:  folks. It turns out that the, the E IIC of

1396
01:17:58,880 --> 01:18:02,620
Speaker 6:  GQ is also producing a film that's being made, made at

1397
01:18:02,620 --> 01:18:06,460
Speaker 6:  Warner Brothers. Everybody looks terrifically stupid in this

1398
01:18:06,460 --> 01:18:10,420
Speaker 6:  situation. Salov just looks really, really thin-skinned and he is

1399
01:18:10,420 --> 01:18:14,340
Speaker 6:  still in negotiations with both SAG and the W G

1400
01:18:14,340 --> 01:18:18,240
Speaker 6:  A with all the other producers in Hollywood right now. So probably

1401
01:18:18,240 --> 01:18:21,820
Speaker 6:  not a great time to look really thin-skinned and like you hate the

1402
01:18:21,820 --> 01:18:24,040
Speaker 6:  movies and people

1403
01:18:24,040 --> 01:18:27,420
Speaker 5:  And also like truly excellent Streisand effect

1404
01:18:27,420 --> 01:18:31,270
Speaker 5:  example, oh my God, of taking a GQ story that I, I had not

1405
01:18:31,270 --> 01:18:34,680
Speaker 5:  heard about or seen and no one really paid that much attention to and turning

1406
01:18:34,680 --> 01:18:38,060
Speaker 5:  it into like front page news all over the internet. I didn't

1407
01:18:38,060 --> 01:18:41,730
Speaker 6:  Read it and until it had already been pulled and then I was like, oh,

1408
01:18:41,730 --> 01:18:42,820
Speaker 6:  this is what you went

1409
01:18:42,820 --> 01:18:45,740
Speaker 5:  After. Thank you to the Google cash for providing that.

1410
01:18:45,740 --> 01:18:49,220
Speaker 6:  I gotta be, I gotta be meaner in in my own stories about Warner Brothers

1411
01:18:49,220 --> 01:18:51,810
Speaker 6:  now. So yeah, we'll see what can happen.

1412
01:18:51,810 --> 01:18:55,100
Speaker 5:  Yeah. Big week for David Lov. Heath, have you picked one yet or do you want

1413
01:18:55,100 --> 01:18:55,890
Speaker 5:  me to go while you look?

1414
01:18:55,890 --> 01:18:59,220
Speaker 7:  Yeah, I have one. We wrote about this, Wes Davis wrote about this on the

1415
01:18:59,220 --> 01:19:02,770
Speaker 7:  site. The TSA is gonna be expanding its use of facial

1416
01:19:02,770 --> 01:19:06,060
Speaker 7:  recognition to over 400 airports. They claim a

1417
01:19:06,060 --> 01:19:09,340
Speaker 7:  97% effectiveness rate on the 25

1418
01:19:09,340 --> 01:19:13,260
Speaker 7:  airport pilot program they've been using so far. This is just

1419
01:19:13,260 --> 01:19:17,100
Speaker 7:  a bad idea. Can we just say beyond a shot of a doubt that like

1420
01:19:17,100 --> 01:19:19,480
Speaker 7:  we should not be giving the TSA our faces.

1421
01:19:19,480 --> 01:19:21,930
Speaker 6:  TSA shouldn't have anything. They shouldn't have funding.

1422
01:19:21,930 --> 01:19:25,280
Speaker 5:  Also 97% success rate on this is not impressive.

1423
01:19:25,280 --> 01:19:25,740
Speaker 7:  No it's

1424
01:19:25,740 --> 01:19:29,400
Speaker 5:  Not. Our security system misses three out of a hundred people. It's like

1425
01:19:29,400 --> 01:19:29,620
Speaker 5:  not

1426
01:19:29,620 --> 01:19:32,580
Speaker 7:  Good. Yeah. Like I've seen these things and I'm sure other people have going

1427
01:19:32,580 --> 01:19:36,300
Speaker 7:  through TSA, like I see it at LAX and I've seen it New York obviously

1428
01:19:36,300 --> 01:19:40,240
Speaker 7:  like avoid it at all costs. I really hope this stays

1429
01:19:40,240 --> 01:19:43,260
Speaker 7:  opt in. They should not mandate this. There is no

1430
01:19:43,260 --> 01:19:46,930
Speaker 7:  federal privacy law about facial recognition data.

1431
01:19:46,930 --> 01:19:50,500
Speaker 7:  There's no law that stipulates how the US government uses this

1432
01:19:50,500 --> 01:19:54,460
Speaker 7:  data. TSA claims they delete it. I do not believe them. I

1433
01:19:54,460 --> 01:19:58,020
Speaker 7:  think we have, we can be skeptical of the data

1434
01:19:58,020 --> 01:20:01,900
Speaker 7:  practices of private for-profit corporations that we choose to use all

1435
01:20:01,900 --> 01:20:05,680
Speaker 7:  the time. I'm not saying that that's bad. We should absolutely

1436
01:20:05,680 --> 01:20:09,500
Speaker 7:  be way more skeptical and concerned about government

1437
01:20:09,500 --> 01:20:13,340
Speaker 7:  agencies using our personal and face data. And so this is a

1438
01:20:13,340 --> 01:20:17,260
Speaker 7:  giant thumbs down for me. The TSA sucks and they should

1439
01:20:17,260 --> 01:20:18,690
Speaker 7:  not use our face data.

1440
01:20:18,690 --> 01:20:22,340
Speaker 6:  Well someone's gonna get a really good look in his bag next time he

1441
01:20:22,340 --> 01:20:23,240
Speaker 6:  flies. Yeah.

1442
01:20:23,240 --> 01:20:24,740
Speaker 5:  God, you just made a list somewhere for

1443
01:20:24,740 --> 01:20:28,010
Speaker 7:  Sure. I'm definitely on the list now. Whatever. I've got global entries.

1444
01:20:28,010 --> 01:20:30,190
Speaker 7:  Stop me bitches.

1445
01:20:30,190 --> 01:20:34,160
Speaker 5:  Clear bitches. Yeah, yeah, I love it. All right. Mine

1446
01:20:34,160 --> 01:20:37,760
Speaker 5:  is Google. You may have heard of it, changed its privacy

1447
01:20:37,760 --> 01:20:41,570
Speaker 5:  policy to say that it uses publicly

1448
01:20:41,570 --> 01:20:45,210
Speaker 5:  scraped web data to train things like

1449
01:20:45,210 --> 01:20:48,880
Speaker 5:  Bard and cloud ai. I believe those are the two things that added to the PO

1450
01:20:48,880 --> 01:20:52,170
Speaker 5:  to the privacy policy. This is one of those things that like everybody already

1451
01:20:52,170 --> 01:20:56,010
Speaker 5:  knew and Google is sort of retroactively being like, no, trust us.

1452
01:20:56,010 --> 01:20:58,660
Speaker 5:  It's super cool that we do this. It's no problem, don't worry about it at

1453
01:20:58,660 --> 01:21:02,580
Speaker 5:  all. And this sparked like a minor uproar

1454
01:21:02,580 --> 01:21:05,940
Speaker 5:  because it had a lot of people asking questions about like, okay, is Google

1455
01:21:05,940 --> 01:21:09,860
Speaker 5:  using my Google Docs to train AI

1456
01:21:09,860 --> 01:21:13,670
Speaker 5:  models? I believe the answer is no, because that doesn't actually

1457
01:21:13,670 --> 01:21:16,540
Speaker 5:  count as a thing on the public web. But I'm sure that's complicated. If you

1458
01:21:16,540 --> 01:21:20,080
Speaker 5:  like make it a public link, like who knows, all this stuff is a mess. And

1459
01:21:20,080 --> 01:21:23,660
Speaker 5:  the response to it, like updating your privacy policy is one of those things

1460
01:21:23,660 --> 01:21:27,510
Speaker 5:  you do when you hope no one will notice. Because who reads privacy policies

1461
01:21:27,510 --> 01:21:30,540
Speaker 5:  mercifully? There are people on the internet who have it set up so that when

1462
01:21:30,540 --> 01:21:34,460
Speaker 5:  Google changes its privacy policy, you get an email about it. Love those

1463
01:21:34,460 --> 01:21:38,150
Speaker 5:  tools. Congratulations everybody. But I think this is the kind of thing,

1464
01:21:38,150 --> 01:21:42,000
Speaker 5:  there are just gonna be a lot of moments like this in the immediate future

1465
01:21:42,000 --> 01:21:45,960
Speaker 5:  and there are a lot of questions about what it means that all of this

1466
01:21:45,960 --> 01:21:49,850
Speaker 5:  is happening and what it means for you as a person that

1467
01:21:49,850 --> 01:21:52,940
Speaker 5:  none of these companies are doing a good job of communicating. Obviously

1468
01:21:52,940 --> 01:21:56,580
Speaker 5:  none of this is regulated in any kind of meaningful way yet. And it's gonna

1469
01:21:56,580 --> 01:22:00,460
Speaker 5:  keep sparking all of these fights about all of these

1470
01:22:00,460 --> 01:22:02,900
Speaker 5:  companies. Like we went through this with the social networks. Do you guys

1471
01:22:02,900 --> 01:22:06,460
Speaker 5:  remember, I think it was Instagram actually changed its privacy policy a

1472
01:22:06,460 --> 01:22:10,180
Speaker 5:  bunch of years ago that it was like, we can use your images in marketing

1473
01:22:10,180 --> 01:22:12,980
Speaker 5:  materials or everything. And everybody's like, wait, what? You are gonna

1474
01:22:12,980 --> 01:22:16,680
Speaker 5:  use my photos in an Instagram ad? And Instagram was like,

1475
01:22:16,680 --> 01:22:20,420
Speaker 5:  why would we do that? That's ridiculous. We need it to be able to like propagate

1476
01:22:20,420 --> 01:22:24,220
Speaker 5:  your image across our services and this stuff. People just don't

1477
01:22:24,220 --> 01:22:27,860
Speaker 5:  understand how this stuff works and they shouldn't have to. And we are reaching

1478
01:22:27,860 --> 01:22:31,500
Speaker 5:  a point with all the AI stuff again, where it's gonna get real scary. There's

1479
01:22:31,500 --> 01:22:35,300
Speaker 5:  gonna be a lot like FUD out there as people panic about

1480
01:22:35,300 --> 01:22:38,260
Speaker 5:  it and it's just gonna get real messy and I'm not looking forward to it.

1481
01:22:38,260 --> 01:22:38,660
Speaker 5:  Well it

1482
01:22:38,660 --> 01:22:42,130
Speaker 6:  Was really weird for people to be upset about the scraping of this case because

1483
01:22:42,130 --> 01:22:45,980
Speaker 6:  like that's literally Google's business. Google, Google's business. Google

1484
01:22:45,980 --> 01:22:49,700
Speaker 6:  has always been to scrape the internet and monetize what it

1485
01:22:49,700 --> 01:22:53,330
Speaker 6:  does. Like, oh no, they're doing like have a debate.

1486
01:22:53,330 --> 01:22:56,420
Speaker 7:  Yeah. But this is a new product. This is a new product that

1487
01:22:56,420 --> 01:23:00,380
Speaker 7:  further abstracts the core content. The source content. That's

1488
01:23:00,380 --> 01:23:02,860
Speaker 7:  fair. That's fair. From the sourcing. I think that's the key thing here.

1489
01:23:02,860 --> 01:23:06,700
Speaker 7:  We're witnessing like potentially one of the greatest like copyright scams

1490
01:23:06,700 --> 01:23:08,420
Speaker 7:  in history with these models.

1491
01:23:08,420 --> 01:23:11,340
Speaker 6:  I mean if they're allowed to maintain copyrights with those models. Yeah.

1492
01:23:11,340 --> 01:23:12,550
Speaker 6:  Which they might not be able to.

1493
01:23:12,550 --> 01:23:14,070
Speaker 7:  Again, if Nili was here,

1494
01:23:14,070 --> 01:23:16,100
Speaker 5:  Thank God we already hung up on Nili. Yeah, yeah.

1495
01:23:16,100 --> 01:23:18,290
Speaker 7:  Thank God. Yeah.

1496
01:23:18,290 --> 01:23:21,540
Speaker 6:  He's calling back right now. Liam, don't let him in. Don't let him in. All

1497
01:23:21,540 --> 01:23:25,360
Speaker 5:  Right. We should go. This is enough Vergecast. We've gone Long

1498
01:23:25,360 --> 01:23:28,780
Speaker 5:  as we all want to do. Should we tell people how to find us on Threads? Is

1499
01:23:28,780 --> 01:23:32,240
Speaker 5:  that what we do now? We like stopped telling people our our Twitter handles.

1500
01:23:32,240 --> 01:23:33,960
Speaker 5:  Should we tell them our Threads?

1501
01:23:33,960 --> 01:23:37,920
Speaker 6:  Yes, we should. Because I want you to say Neli

1502
01:23:37,920 --> 01:23:38,760
Speaker 6:  cuz it's funny.

1503
01:23:38,760 --> 01:23:42,500
Speaker 5:  The thing is, I don't want to say the phrase Threads me because

1504
01:23:42,500 --> 01:23:46,260
Speaker 5:  that sucks. So maybe this is why, maybe tweets is the

1505
01:23:46,260 --> 01:23:50,100
Speaker 5:  answer. Tweet me on Threads. See I'm, I'm David Pierce

1506
01:23:50,100 --> 01:23:53,200
Speaker 5:  because I'm gonna kill whoever has David Pierce and then I'll be David Pierce.

1507
01:23:53,200 --> 01:23:55,900
Speaker 5:  But until then there's an I'm at the beginning of it that other

1508
01:23:55,900 --> 01:23:58,170
Speaker 6:  David Pierce dies in the next week.

1509
01:23:58,170 --> 01:24:02,100
Speaker 5:  He's like a lawyer in Phoenix and we are in a permanent war for David

1510
01:24:02,100 --> 01:24:03,000
Speaker 5:  Pearce usernames.

1511
01:24:03,000 --> 01:24:05,380
Speaker 7:  Is there an apostrophe there with the Im or no?

1512
01:24:05,380 --> 01:24:09,300
Speaker 5:  Just Im, no, just, just all Just letters all the way down. Alex. You're Alex

1513
01:24:09,300 --> 01:24:13,070
Speaker 5:  Heath, you know, whatever. Mr. Low number joined Alex

1514
01:24:13,070 --> 01:24:15,210
Speaker 5:  Cranz. Your Alex h Cranz, right? Yeah,

1515
01:24:15,210 --> 01:24:17,400
Speaker 6:  It's, that's what I used on Twitter. It seems fine.

1516
01:24:17,400 --> 01:24:19,440
Speaker 5:  The H stands for Hustle. Yes,

1517
01:24:19,440 --> 01:24:20,400
Speaker 6:  It does

1518
01:24:20,400 --> 01:24:24,220
Speaker 5:  Go to Cranz for all your hustle, bro. Content decoder is a podcast. NI's

1519
01:24:24,220 --> 01:24:26,740
Speaker 5:  not here, so don't listen to it. Decoder is awful. I hate it. The worst forever.

1520
01:24:26,740 --> 01:24:27,160
Speaker 5:  It's the worst.

1521
01:24:27,160 --> 01:24:29,850
Speaker 6:  But where we, where can you follow him? You didn't say where we can follow

1522
01:24:29,850 --> 01:24:30,280
Speaker 6:  Nili.

1523
01:24:30,280 --> 01:24:33,300
Speaker 5:  Oh yeah. Reckless Reckless. 1280 on

1524
01:24:33,300 --> 01:24:36,440
Speaker 5:  Threads because that's the year he was born.

1525
01:24:36,440 --> 01:24:40,340
Speaker 5:  1280. Next Wednesday on The Vergecast, we're gonna talk about ai. We're also

1526
01:24:40,340 --> 01:24:43,920
Speaker 5:  gonna talk about video games with Ash Parrish and Chris Plant from Polygon.

1527
01:24:43,920 --> 01:24:47,020
Speaker 5:  We talked about all our favorite games. It was very fun. And we're also gonna

1528
01:24:47,020 --> 01:24:50,650
Speaker 5:  talk about a whole bunch of new Apple software. We think it's all coming

1529
01:24:50,650 --> 01:24:54,620
Speaker 5:  very soon, so we're gonna talk about it until then. We'll see you on Threads.

1530
01:24:54,620 --> 01:24:56,300
Speaker 5:  That's it. That's The. Vergecast. Rock and

1531
01:24:56,300 --> 01:24:57,020
Speaker 7:  Roll. See you

1532
01:24:57,020 --> 01:25:02,320
Speaker 7:  guys.

1533
01:25:02,320 --> 01:25:05,700
Speaker 8:  And that's a wrap for Vergecast this week. We'd love to hear from you. Shoot

1534
01:25:05,700 --> 01:25:09,540
Speaker 8:  us an email at Vergecast at The Verge dot com. The Vergecast is a

1535
01:25:09,540 --> 01:25:13,100
Speaker 8:  production of The Verge and the Vox Media Podcast network. The show's produced

1536
01:25:13,100 --> 01:25:16,960
Speaker 8:  by me, Liam James, and our senior audio director, Andrew Marino.

1537
01:25:16,960 --> 01:25:20,580
Speaker 8:  Our editorial director is Brooke Minters. That's it. We'll see you next

1538
01:25:20,580 --> 01:25:36,610
Speaker 8:  week.

